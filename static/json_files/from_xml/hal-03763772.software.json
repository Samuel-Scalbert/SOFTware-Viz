{"application": "software-mentions", "version": "0.8.0", "date": "2024-03-20T16:24+0000", "md5": "03733441BDDF131062BE7F1A4029FB5C", "mentions": [{"type": "software", "software-type": "software", "software-name": {"rawForm": "code", "normalizedForm": "code", "offsetStart": 4, "offsetEnd": 8}, "context": "The code used for our experiments is written in Python 3.9 and PyTorch and is available in the repository https://github.com/Safa-98/patient-stay-analogy.", "mentionContextAttributes": {"used": {"value": true, "score": 0.998375415802002}, "created": {"value": false, "score": 0.0696982741355896}, "shared": {"value": true, "score": 0.9660310745239258}}, "documentContextAttributes": {"used": {"value": true, "score": 0.998375415802002}, "created": {"value": false, "score": 0.0696982741355896}, "shared": {"value": true, "score": 0.9660310745239258}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "DBOW", "normalizedForm": "DBOW", "offsetStart": 38, "offsetEnd": 42}, "context": "For the training algorithm, we use PV-DBOW (Paragraph vector-Distributed Bag of Words). ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9990113973617554}, "created": {"value": false, "score": 1.1205673217773438e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9990113973617554}, "created": {"value": false, "score": 1.1205673217773438e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}}, {"type": "software", "software-type": "software", "wikidataId": "Q47509047", "wikipediaExternalRef": 54022970, "lang": "en", "confidence": 0.7826, "software-name": {"rawForm": "PyTorch", "normalizedForm": "PyTorch", "wikidataId": "Q47509047", "wikipediaExternalRef": 54022970, "lang": "en", "confidence": 0.7826, "offsetStart": 63, "offsetEnd": 70}, "version": {"rawForm": "3.9", "normalizedForm": "3.9", "offsetStart": 55, "offsetEnd": 58}, "context": "The code used for our experiments is written in Python 3.9 and PyTorch and is available in the repository https://github.com/Safa-98/patient-stay-analogy.", "mentionContextAttributes": {"used": {"value": true, "score": 0.998375415802002}, "created": {"value": false, "score": 0.0696982741355896}, "shared": {"value": true, "score": 0.9660310745239258}}, "documentContextAttributes": {"used": {"value": true, "score": 0.998375415802002}, "created": {"value": false, "score": 0.0696982741355896}, "shared": {"value": true, "score": 0.9660310745239258}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "GloVe", "normalizedForm": "GloVe", "offsetStart": 106, "offsetEnd": 111}, "context": "Their architecture integrates the characteristics of analogies by design and relies heavily on pretrained GloVe embeddings [4]. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0001423358917236328}, "created": {"value": false, "score": 0.00040215253829956055}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.0001423358917236328}, "created": {"value": false, "score": 0.00040215253829956055}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "wikidataId": "Q5533567", "wikipediaExternalRef": 36473068, "lang": "en", "confidence": 0.4579, "software-name": {"rawForm": "Gensim", "normalizedForm": "Gensim", "wikidataId": "Q5533567", "wikipediaExternalRef": 36473068, "lang": "en", "confidence": 0.4579, "offsetStart": 234, "offsetEnd": 240}, "context": "We computed the median of notes per hospital admission to determine the number of clinical notes to extract For the unsupervised Doc2Vec model [18], we finetune it on the training set to obtain the document-level embeddings using the Gensim toolkit [23]. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999920129776001}, "created": {"value": false, "score": 7.62939453125e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999920129776001}, "created": {"value": false, "score": 7.62939453125e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "references": [{"label": "[23]", "normalizedForm": "[23]", "refKey": 23, "offsetStart": 18873, "offsetEnd": 18877}]}], "references": [{"refKey": 23, "tei": "<biblStruct xml:id=\"b23\">\n\t<analytic>\n\t\t<title level=\"a\" type=\"main\">Software Framework for Topic Modelling with Large Corpora</title>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">R</forename><surname>\u0158eh\u016f\u0159ek</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">P</forename><surname>Sojka</surname></persName>\n\t\t</author>\n\t</analytic>\n\t<monogr>\n\t\t<title level=\"m\">Proceedings of the LREC Workshop on New Challenges for NLP Frameworks</title>\n\t\t<meeting>the LREC Workshop on New Challenges for NLP Frameworks</meeting>\n\t\t<imprint>\n\t\t\t<date>2010</date>\n\t\t\t<biblScope unit=\"page\">50</biblScope>\n\t\t</imprint>\n\t</monogr>\n</biblStruct>\n"}], "runtime": 58662, "id": "125fff3121aa1cced0bbecccd93a1688cce4d109", "metadata": {"id": "125fff3121aa1cced0bbecccd93a1688cce4d109"}, "original_file_path": "../../datalake/Samuel/SV22/SV22_xml/hal-03763772.grobid.tei.xml", "file_name": "hal-03763772.grobid.tei.xml"}