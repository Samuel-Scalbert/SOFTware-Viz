{"application": "software-mentions", "version": "0.8.0", "date": "2024-03-21T10:04+0000", "md5": "27CDCA9DC8633986655517BEBF3E3071", "mentions": [{"type": "software", "software-type": "software", "software-name": {"rawForm": "PickNext", "normalizedForm": "PickNext", "offsetStart": 0, "offsetEnd": 8}, "context": "PickNext that picks, in each iteration, a reducible pair of T S .", "mentionContextAttributes": {"used": {"value": false, "score": 0.00121229887008667}, "created": {"value": false, "score": 1.5139579772949219e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.08447009325027466}, "created": {"value": false, "score": 0.09656381607055664}, "shared": {"value": false, "score": 3.5762786865234375e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "TreeChild", "normalizedForm": "TreeChild", "offsetStart": 0, "offsetEnd": 9}, "context": "TreeChild is a fixed-parameter (in the number of reticulations of the output) exact algorithm that reconstructs the best tree-child network, a restricted class of phylogenetic networks, and due to its fast-growing computation time cannot handle large instances either.", "mentionContextAttributes": {"used": {"value": false, "score": 6.151199340820312e-05}, "created": {"value": false, "score": 0.0021161437034606934}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999715089797974}, "created": {"value": false, "score": 0.012334227561950684}, "shared": {"value": false, "score": 4.76837158203125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Hybroscale", "normalizedForm": "Hybroscale", "offsetStart": 0, "offsetEnd": 10}, "context": "Hybroscale is an exact method performing an exhaustive search on the networks displaying the input trees, therefore it can only handle reasonably small instances in terms of number of input trees. ", "mentionContextAttributes": {"used": {"value": false, "score": 3.0040740966796875e-05}, "created": {"value": false, "score": 5.364418029785156e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999715089797974}, "created": {"value": false, "score": 0.012334227561950684}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "references": [{"label": "[1]", "normalizedForm": "[1]", "refKey": 1}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "TrivialRand", "normalizedForm": "TrivialRand", "offsetStart": 0, "offsetEnd": 11}, "language": {"rawForm": "Python", "normalizedForm": "Python"}, "context": "TrivialRand.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0017234086990356445}, "created": {"value": false, "score": 0.0003129243850708008}, "shared": {"value": false, "score": 1.5497207641601562e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999942779541016}, "created": {"value": true, "score": 0.9998072981834412}, "shared": {"value": false, "score": 1.5497207641601562e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CompleteSeq", "normalizedForm": "CompleteSeq", "offsetStart": 3, "offsetEnd": 14}, "context": "As CompleteSeq only appends pairs at the end of S, the result of this subroutine still reduces all trees in T S . ", "mentionContextAttributes": {"used": {"value": false, "score": 0.012538135051727295}, "created": {"value": false, "score": 1.2993812561035156e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9800965189933777}, "created": {"value": false, "score": 0.011954963207244873}, "shared": {"value": false, "score": 2.7418136596679688e-06}}}, {"type": "software", "software-type": "implicit", "software-name": {"rawForm": "code", "normalizedForm": "code", "offsetStart": 4, "offsetEnd": 8}, "context": "The code of all our heuristics, available at https://github.com/estherjulien/HybridML, is written in Python. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.11660504341125488}, "created": {"value": false, "score": 0.2618488669395447}, "shared": {"value": true, "score": 0.975430965423584}}, "documentContextAttributes": {"used": {"value": false, "score": 0.11660504341125488}, "created": {"value": false, "score": 0.2618488669395447}, "shared": {"value": true, "score": 0.975430965423584}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "PickNext", "normalizedForm": "PickNext", "offsetStart": 9, "offsetEnd": 17}, "context": "Function PickNext picks uniformly at random a reducible pair of T S .", "mentionContextAttributes": {"used": {"value": false, "score": 0.009089887142181396}, "created": {"value": false, "score": 4.649162292480469e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.08447009325027466}, "created": {"value": false, "score": 0.09656381607055664}, "shared": {"value": false, "score": 3.5762786865234375e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "PickNext", "normalizedForm": "PickNext", "offsetStart": 9, "offsetEnd": 17}, "context": "Function PickNext picks a reducible pair (x, y) with the lowest average of values h T (x,y) over all T \u2208 T S in which (x, y) is reducible (ties are broken randomly).", "mentionContextAttributes": {"used": {"value": false, "score": 0.009020686149597168}, "created": {"value": false, "score": 8.463859558105469e-06}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.08447009325027466}, "created": {"value": false, "score": 0.09656381607055664}, "shared": {"value": false, "score": 3.5762786865234375e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "PickNext", "normalizedForm": "PickNext", "offsetStart": 9, "offsetEnd": 17}, "context": "Function PickNext picks a trivial pair if there exists one, and otherwise picks a reducible pair of T S uniformly at random.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00481104850769043}, "created": {"value": false, "score": 7.987022399902344e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.08447009325027466}, "created": {"value": false, "score": 0.09656381607055664}, "shared": {"value": false, "score": 3.5762786865234375e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "PickNext", "normalizedForm": "PickNext", "offsetStart": 9, "offsetEnd": 17}, "context": "Function PickNext picks a random trivial pair, if there exists one; otherwise it uses the same rules as ML.", "mentionContextAttributes": {"used": {"value": false, "score": 0.002033054828643799}, "created": {"value": false, "score": 6.794929504394531e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.08447009325027466}, "created": {"value": false, "score": 0.09656381607055664}, "shared": {"value": false, "score": 3.5762786865234375e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CompleteSeq", "normalizedForm": "CompleteSeq", "offsetStart": 12, "offsetEnd": 23}, "context": "Algorithm 2 CompleteSeq.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9800965189933777}, "created": {"value": false, "score": 4.9948692321777344e-05}, "shared": {"value": false, "score": 2.7418136596679688e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9800965189933777}, "created": {"value": false, "score": 0.011954963207244873}, "shared": {"value": false, "score": 2.7418136596679688e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "TrivialRand", "normalizedForm": "TrivialRand", "offsetStart": 17, "offsetEnd": 28}, "language": {"rawForm": "Python", "normalizedForm": "Python"}, "context": "We tested ML and TrivialRand against Hybroscale and TreeChild using the same dataset used in [19], in turn taken from [3].", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999552965164185}, "created": {"value": false, "score": 1.430511474609375e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999942779541016}, "created": {"value": true, "score": 0.9998072981834412}, "shared": {"value": false, "score": 1.5497207641601562e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "TrivialRand", "normalizedForm": "TrivialRand", "offsetStart": 19, "offsetEnd": 30}, "language": {"rawForm": "Python", "normalizedForm": "Python"}, "context": "The best result of TrivialRand was (slightly) better than the result of ML only for the instance group (20,20).", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999090433120728}, "created": {"value": false, "score": 3.421306610107422e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999942779541016}, "created": {"value": true, "score": 0.9998072981834412}, "shared": {"value": false, "score": 1.5497207641601562e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Hybroscale", "normalizedForm": "Hybroscale", "offsetStart": 20, "offsetEnd": 30}, "context": "As a consequence of Hybroscale and TreeChild being exact methods (TreeChild only for a restricted class of networks), they performed better than both ML and TrivialRand on all instances they could solve, although the best results of TrivialRand are often close (no worse than 14%) and sometimes match the optimal value. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9954121708869934}, "created": {"value": false, "score": 1.9073486328125e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999715089797974}, "created": {"value": false, "score": 0.012334227561950684}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "references": [{"label": "[1]", "normalizedForm": "[1]", "refKey": 1}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "TrivialRand", "normalizedForm": "TrivialRand", "offsetStart": 30, "offsetEnd": 41}, "language": {"rawForm": "Python", "normalizedForm": "Python"}, "context": "Let S be the CPS outputted by TrivialRand with input T and let S contain j \u2265 0 trivial pairs.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999715089797974}, "created": {"value": false, "score": 1.1920928955078125e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999942779541016}, "created": {"value": true, "score": 0.9998072981834412}, "shared": {"value": false, "score": 1.5497207641601562e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "TrivialRand", "normalizedForm": "TrivialRand", "offsetStart": 31, "offsetEnd": 42}, "language": {"rawForm": "Python", "normalizedForm": "Python"}, "context": "In particular, whereas running TrivialRand several times and picking the best output appeared to be the winning strategies for most of the FTS instances (although ML and TrivialML performed almost as good), this is not the case for RTS, where it seems that machine learning often makes up for the lack of information in the input better than the randomised strategies. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.17253267765045166}, "created": {"value": false, "score": 3.5762786865234375e-06}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999942779541016}, "created": {"value": true, "score": 0.9998072981834412}, "shared": {"value": false, "score": 1.5497207641601562e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "TrivialRand", "normalizedForm": "TrivialRand", "offsetStart": 34, "offsetEnd": 45}, "language": {"rawForm": "Python", "normalizedForm": "Python"}, "context": "Suppose that at some iteration of TrivialRand, the subroutine PickNext returns the trivial pair (x, y).", "mentionContextAttributes": {"used": {"value": false, "score": 0.0009675025939941406}, "created": {"value": false, "score": 2.7418136596679688e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999942779541016}, "created": {"value": true, "score": 0.9998072981834412}, "shared": {"value": false, "score": 1.5497207641601562e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "TreeChild", "normalizedForm": "TreeChild", "offsetStart": 35, "offsetEnd": 44}, "context": "As a consequence of Hybroscale and TreeChild being exact methods (TreeChild only for a restricted class of networks), they performed better than both ML and TrivialRand on all instances they could solve, although the best results of TrivialRand are often close (no worse than 14%) and sometimes match the optimal value. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9954121708869934}, "created": {"value": false, "score": 1.9073486328125e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999715089797974}, "created": {"value": false, "score": 0.012334227561950684}, "shared": {"value": false, "score": 4.76837158203125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "TrivialRand", "normalizedForm": "TrivialRand", "offsetStart": 35, "offsetEnd": 46}, "language": {"rawForm": "Python", "normalizedForm": "Python"}, "context": "The randomised heuristics Rand and TrivialRand were run min{x(I), 1000} times for each instance I, where x(I) is the number of runs that can be executed in the same time as one run of ML on the same instance.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999629259109497}, "created": {"value": false, "score": 3.5762786865234375e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999942779541016}, "created": {"value": true, "score": 0.9998072981834412}, "shared": {"value": false, "score": 1.5497207641601562e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Hybroscale", "normalizedForm": "Hybroscale", "offsetStart": 37, "offsetEnd": 47}, "context": "We tested ML and TrivialRand against Hybroscale and TreeChild using the same dataset used in [19], in turn taken from [3].", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999552965164185}, "created": {"value": false, "score": 1.430511474609375e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999715089797974}, "created": {"value": false, "score": 0.012334227561950684}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "references": [{"label": "[1]", "normalizedForm": "[1]", "refKey": 1}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "PickNext", "normalizedForm": "PickNext", "offsetStart": 39, "offsetEnd": 47}, "context": "Given a threshold t \u2208 [0, 1), function PickNext picks the cherry with the highest predicted probability of being reducible in N , if this probability is at least t; or a random cherry if none of them have a probability of being reducible above the threshold.", "mentionContextAttributes": {"used": {"value": false, "score": 0.05579489469528198}, "created": {"value": false, "score": 1.239776611328125e-05}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.08447009325027466}, "created": {"value": false, "score": 0.09656381607055664}, "shared": {"value": false, "score": 3.5762786865234375e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "TrivialRand", "normalizedForm": "TrivialRand", "offsetStart": 41, "offsetEnd": 52}, "language": {"rawForm": "Python", "normalizedForm": "Python"}, "context": "In Section 5 we experimentally show that TrivialRand produces the best results among the proposed randomised heuristics. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.03931140899658203}, "created": {"value": true, "score": 0.9641530513763428}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999942779541016}, "created": {"value": true, "score": 0.9998072981834412}, "shared": {"value": false, "score": 1.5497207641601562e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "scikit-learn      package", "normalizedForm": "scikit-learn package", "offsetStart": 47, "offsetEnd": 72}, "publisher": {"rawForm": "Python", "normalizedForm": "Python", "offsetStart": 38, "offsetEnd": 44}, "context": "The random forest is implemented with Python's scikit-learn [13] package using default settings. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.12378233671188354}, "created": {"value": false, "score": 0.011229753494262695}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.12378233671188354}, "created": {"value": false, "score": 0.011229753494262695}, "shared": {"value": false, "score": 4.76837158203125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "TreeChild", "normalizedForm": "TreeChild", "offsetStart": 52, "offsetEnd": 61}, "context": "We tested ML and TrivialRand against Hybroscale and TreeChild using the same dataset used in [19], in turn taken from [3]. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999552965164185}, "created": {"value": false, "score": 1.430511474609375e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999715089797974}, "created": {"value": false, "score": 0.012334227561950684}, "shared": {"value": false, "score": 4.76837158203125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "PickNext", "normalizedForm": "PickNext", "offsetStart": 62, "offsetEnd": 70}, "context": "Suppose that at some iteration of TrivialRand, the subroutine PickNext returns the trivial pair (x, y).", "mentionContextAttributes": {"used": {"value": false, "score": 0.0009675025939941406}, "created": {"value": false, "score": 2.7418136596679688e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.08447009325027466}, "created": {"value": false, "score": 0.09656381607055664}, "shared": {"value": false, "score": 3.5762786865234375e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "TrivialRand", "normalizedForm": "TrivialRand", "offsetStart": 62, "offsetEnd": 73}, "language": {"rawForm": "Python", "normalizedForm": "Python"}, "context": "In the next section we introduce a further heuristic step for TrivialRand which improves the quality of the output even more.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00011157989501953125}, "created": {"value": true, "score": 0.9998072981834412}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999942779541016}, "created": {"value": true, "score": 0.9998072981834412}, "shared": {"value": false, "score": 1.5497207641601562e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "TreeChild", "normalizedForm": "TreeChild", "offsetStart": 66, "offsetEnd": 75}, "context": "As a consequence of Hybroscale and TreeChild being exact methods (TreeChild only for a restricted class of networks), they performed better than both ML and TrivialRand on all instances they could solve, although the best results of TrivialRand are often close (no worse than 14%) and sometimes match the optimal value. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9954121708869934}, "created": {"value": false, "score": 1.9073486328125e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999715089797974}, "created": {"value": false, "score": 0.012334227561950684}, "shared": {"value": false, "score": 4.76837158203125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Hybroscale", "normalizedForm": "Hybroscale", "offsetStart": 67, "offsetEnd": 77}, "context": "In Figure 9 we show results only for the instance groups for which Hybroscale or TreeChild could output a solution within 1 hour, consistent with the experiments in [19]. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999715089797974}, "created": {"value": false, "score": 3.0994415283203125e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999715089797974}, "created": {"value": false, "score": 0.012334227561950684}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "references": [{"label": "[1]", "normalizedForm": "[1]", "refKey": 1}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "TrivialRand", "normalizedForm": "TrivialRand", "offsetStart": 68, "offsetEnd": 79}, "language": {"rawForm": "Python", "normalizedForm": "Python"}, "context": "Let S i-1 be the partial CPS constructed in the first i -1 steps of TrivialRand, and let i be the first step in which we pick a trivial pair (x, y).", "mentionContextAttributes": {"used": {"value": true, "score": 0.9899875521659851}, "created": {"value": false, "score": 0.00015306472778320312}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999942779541016}, "created": {"value": true, "score": 0.9998072981834412}, "shared": {"value": false, "score": 1.5497207641601562e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "TreeChild", "normalizedForm": "TreeChild", "offsetStart": 70, "offsetEnd": 79}, "context": "We also compared our results with the algorithm from [19], denoted by TreeChild, and the algorithm from [1], denoted by Hybroscale, using the same datasets that were used to test the two methods in [19], which consist of rather small instances (|T | \u2264 8) .", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999699592590332}, "created": {"value": false, "score": 7.510185241699219e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999715089797974}, "created": {"value": false, "score": 0.012334227561950684}, "shared": {"value": false, "score": 4.76837158203125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "TrivialRand", "normalizedForm": "TrivialRand", "offsetStart": 71, "offsetEnd": 82}, "language": {"rawForm": "Python", "normalizedForm": "Python"}, "context": "For RTS instances, the result of ML was better than the best result of TrivialRand by up to 34% on average (for instances of 100 trees obtained from networks with 50 leaves), the difference being more marked for seemingly \"difficult\" instance groups, for which all the tested heuristics gave results diverging more from the reference value. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999586343765259}, "created": {"value": false, "score": 1.4543533325195312e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999942779541016}, "created": {"value": true, "score": 0.9998072981834412}, "shared": {"value": false, "score": 1.5497207641601562e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "TreeChild", "normalizedForm": "TreeChild", "offsetStart": 81, "offsetEnd": 90}, "context": "In Figure 9 we show results only for the instance groups for which Hybroscale or TreeChild could output a solution within 1 hour, consistent with the experiments in [19]. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999715089797974}, "created": {"value": false, "score": 3.0994415283203125e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999715089797974}, "created": {"value": false, "score": 0.012334227561950684}, "shared": {"value": false, "score": 4.76837158203125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Hybroscale", "normalizedForm": "Hybroscale", "offsetStart": 82, "offsetEnd": 92}, "context": "Previous practical algorithms for Hybridization include PIRN [21], PIRNs [11] and Hybroscale [1], exact methods that are only applicable to (very) small numbers of trees and/or to trees that can be combined into a network with a (very) small reticulation number.", "mentionContextAttributes": {"used": {"value": false, "score": 7.808208465576172e-05}, "created": {"value": false, "score": 0.00018996000289916992}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999715089797974}, "created": {"value": false, "score": 0.012334227561950684}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "references": [{"label": "[1]", "normalizedForm": "[1]", "refKey": 1, "offsetStart": 4770, "offsetEnd": 4773}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "PickNext", "normalizedForm": "PickNext", "offsetStart": 87, "offsetEnd": 95}, "context": "Based on Lemma 7, we then exploit the output of the classifier to define new functions PickNext, that in turn define new machine-learned heuristics in the class of CPH (Algorithm 1).", "mentionContextAttributes": {"used": {"value": false, "score": 0.08447009325027466}, "created": {"value": false, "score": 0.0349959135055542}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.08447009325027466}, "created": {"value": false, "score": 0.09656381607055664}, "shared": {"value": false, "score": 3.5762786865234375e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "TrivialRand", "normalizedForm": "TrivialRand", "offsetStart": 92, "offsetEnd": 103}, "language": {"rawForm": "Python", "normalizedForm": "Python"}, "context": "The results essentially confirm the ones we obtained for RTS instances: the best outputs of TrivialRand are quite close to the outputs of ML (and TrivialML), being up to 15% worse and up to 9% better on average, depending on the instance group.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999570846557617}, "created": {"value": false, "score": 6.556510925292969e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999942779541016}, "created": {"value": true, "score": 0.9998072981834412}, "shared": {"value": false, "score": 1.5497207641601562e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "TrivialRand", "normalizedForm": "TrivialRand", "offsetStart": 93, "offsetEnd": 104}, "language": {"rawForm": "Python", "normalizedForm": "Python", "wikidataId": "Q28865", "offsetStart": 101, "offsetEnd": 107}, "context": "We conducted experiments on both synthetic and real data, comparing the performance of Rand, TrivialRand, ML and TrivialML, using threshold t = 0. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999901056289673}, "created": {"value": false, "score": 0.0006400942802429199}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999942779541016}, "created": {"value": true, "score": 0.9998072981834412}, "shared": {"value": false, "score": 1.5497207641601562e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "TrivialRand", "normalizedForm": "TrivialRand", "offsetStart": 95, "offsetEnd": 106}, "language": {"rawForm": "Python", "normalizedForm": "Python"}, "context": "While just one run of ML or TrivialML gave better results than the average of multiple runs of TrivialRand (up to 64% on average), picking the best output over all the runs of TrivialRand seems to give the best results for FTS instances, TrivialRand being better than ML by up to 25% on average for instances obtained from networks with 20 leaves and 5 reticulations and yielding results only slightly better than ML and TrivialML in the rest of instance groups (ML being better by 3% on average than the best output of TrivialRand only for the instance group (100,7)). ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9997835755348206}, "created": {"value": false, "score": 1.5497207641601562e-06}, "shared": {"value": false, "score": 7.152557373046875e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999942779541016}, "created": {"value": true, "score": 0.9998072981834412}, "shared": {"value": false, "score": 1.5497207641601562e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "TrivialRand", "normalizedForm": "TrivialRand", "offsetStart": 99, "offsetEnd": 110}, "language": {"rawForm": "Python", "normalizedForm": "Python"}, "context": "We consistently chose to use this rule in all the heuristics that detect trivial cherries, namely, TrivialRand, TrivialML, and ML (although ML does not explicitly favour trivial cherries, it does check whether a selected cherry is trivial using feature number 2).", "mentionContextAttributes": {"used": {"value": true, "score": 0.8837895393371582}, "created": {"value": false, "score": 4.9233436584472656e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999942779541016}, "created": {"value": true, "score": 0.9998072981834412}, "shared": {"value": false, "score": 1.5497207641601562e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "PickNext", "normalizedForm": "PickNext", "offsetStart": 110, "offsetEnd": 118}, "context": "We define the following three heuristics in the CPH class, resulting from as many possible implementations of PickNext. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.07169938087463379}, "created": {"value": false, "score": 0.09656381607055664}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.08447009325027466}, "created": {"value": false, "score": 0.09656381607055664}, "shared": {"value": false, "score": 3.5762786865234375e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "TrivialRand", "normalizedForm": "TrivialRand", "offsetStart": 111, "offsetEnd": 122}, "language": {"rawForm": "Python", "normalizedForm": "Python"}, "context": "The results are then averaged within each group and divided by the reference value that we obtained by running TrivialRand 1000 times on each instance and taking the best outputs. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999374151229858}, "created": {"value": false, "score": 4.887580871582031e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999942779541016}, "created": {"value": true, "score": 0.9998072981834412}, "shared": {"value": false, "score": 1.5497207641601562e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "PickNext", "normalizedForm": "PickNext", "offsetStart": 114, "offsetEnd": 122}, "context": "The class of heuristics described in Algorithm 1 is concretised in different heuristics depending on the function PickNext at line 3, which is used to choose a reducible pair at each iteration.", "mentionContextAttributes": {"used": {"value": false, "score": 0.014388799667358398}, "created": {"value": false, "score": 5.459785461425781e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.08447009325027466}, "created": {"value": false, "score": 0.09656381607055664}, "shared": {"value": false, "score": 3.5762786865234375e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "TrivialRand", "normalizedForm": "TrivialRand", "offsetStart": 114, "offsetEnd": 125}, "language": {"rawForm": "Python", "normalizedForm": "Python"}, "context": "In Figure 10 we show the results obtained for the instance groups of Table 2. Like for FTS and RTS data, Rand and TrivialRand are executed min{x(I), 1000} times for each instance I, x(I) being the time required for executing ML once on instance I.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9982913136482239}, "created": {"value": false, "score": 4.291534423828125e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999942779541016}, "created": {"value": true, "score": 0.9998072981834412}, "shared": {"value": false, "score": 1.5497207641601562e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Hybroscale", "normalizedForm": "Hybroscale", "offsetStart": 120, "offsetEnd": 130}, "context": "We also compared our results with the algorithm from [19], denoted by TreeChild, and the algorithm from [1], denoted by Hybroscale, using the same datasets that were used to test the two methods in [19], which consist of rather small instances (|T | \u2264 8) .", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999699592590332}, "created": {"value": false, "score": 7.510185241699219e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999715089797974}, "created": {"value": false, "score": 0.012334227561950684}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "references": [{"label": "[1]", "normalizedForm": "[1]", "refKey": 1}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CompleteSeq", "normalizedForm": "CompleteSeq", "offsetStart": 139, "offsetEnd": 150}, "context": "These additional pairs do not affect the trees in T , that are already fully reduced by S. Algorithm 2 in Appendix A describes a procedure CompleteSeq that runs in time linear in the length of S.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0005629658699035645}, "created": {"value": false, "score": 2.467632293701172e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9800965189933777}, "created": {"value": false, "score": 0.011954963207244873}, "shared": {"value": false, "score": 2.7418136596679688e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "TrivialRand", "normalizedForm": "TrivialRand", "offsetStart": 157, "offsetEnd": 168}, "language": {"rawForm": "Python", "normalizedForm": "Python"}, "context": "As a consequence of Hybroscale and TreeChild being exact methods (TreeChild only for a restricted class of networks), they performed better than both ML and TrivialRand on all instances they could solve, although the best results of TrivialRand are often close (no worse than 14%) and sometimes match the optimal value. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9954120516777039}, "created": {"value": false, "score": 1.9073486328125e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999942779541016}, "created": {"value": true, "score": 0.9998072981834412}, "shared": {"value": false, "score": 1.5497207641601562e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "TreeChild", "normalizedForm": "TreeChild", "offsetStart": 162, "offsetEnd": 176}, "context": "For sufficiently small instances, we compared the results of our heuristics with the results of two existing tools for reconstructing networks from binary trees: TreeChild [19] and Hybroscale [1]. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999063014984131}, "created": {"value": false, "score": 0.012334227561950684}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999715089797974}, "created": {"value": false, "score": 0.012334227561950684}, "shared": {"value": false, "score": 4.76837158203125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "TrivialRand", "normalizedForm": "TrivialRand", "offsetStart": 176, "offsetEnd": 187}, "language": {"rawForm": "Python", "normalizedForm": "Python"}, "context": "While just one run of ML or TrivialML gave better results than the average of multiple runs of TrivialRand (up to 64% on average), picking the best output over all the runs of TrivialRand seems to give the best results for FTS instances, TrivialRand being better than ML by up to 25% on average for instances obtained from networks with 20 leaves and 5 reticulations and yielding results only slightly better than ML and TrivialML in the rest of instance groups (ML being better by 3% on average than the best output of TrivialRand only for the instance group (100,7)).", "mentionContextAttributes": {"used": {"value": true, "score": 0.9997835755348206}, "created": {"value": false, "score": 1.5497207641601562e-06}, "shared": {"value": false, "score": 7.152557373046875e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999942779541016}, "created": {"value": true, "score": 0.9998072981834412}, "shared": {"value": false, "score": 1.5497207641601562e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Hybroscale", "normalizedForm": "Hybroscale", "offsetStart": 181, "offsetEnd": 194}, "context": "For sufficiently small instances, we compared the results of our heuristics with the results of two existing tools for reconstructing networks from binary trees: TreeChild [19] and Hybroscale [1]. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999063014984131}, "created": {"value": false, "score": 0.012334227561950684}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999715089797974}, "created": {"value": false, "score": 0.012334227561950684}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "references": [{"label": "[1]", "normalizedForm": "[1]", "refKey": 1}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "TrivialRand", "normalizedForm": "TrivialRand", "offsetStart": 191, "offsetEnd": 202}, "language": {"rawForm": "Python", "normalizedForm": "Python"}, "context": "We synthetically generated 112 instances for each tree set size |T | \u2208 {5, 10, 20, 50, 100} (560 in total), all consisting of trees with 20 leaves each, and grouped them by |T |; we then ran TrivialRand 200 times (both with and without tree expansion) on each instance, selected the best output for each of them, and finally took the average of these results over each group of instances. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999812841415405}, "created": {"value": false, "score": 2.9802322387695312e-06}, "shared": {"value": false, "score": 5.960464477539062e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999942779541016}, "created": {"value": true, "score": 0.9998072981834412}, "shared": {"value": false, "score": 1.5497207641601562e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "TrivialRand", "normalizedForm": "TrivialRand", "offsetStart": 214, "offsetEnd": 225}, "language": {"rawForm": "Python", "normalizedForm": "Python"}, "context": "In the absence of the natural estimate on the optimal number of reticulations provided by the starting network, on real data we evaluated the performance of the heuristics using the best result obtained by running TrivialRand 1000 times as reference value.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999942779541016}, "created": {"value": false, "score": 8.58306884765625e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999942779541016}, "created": {"value": true, "score": 0.9998072981834412}, "shared": {"value": false, "score": 1.5497207641601562e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CompleteSeq", "normalizedForm": "CompleteSeq", "offsetStart": 220, "offsetEnd": 231}, "context": "Recall that T S denotes the set of trees T after reducing all trees with a (partial) CPS S. The while loop at lines 2-5 produces, in general, a partial CPS S, as shown in Example 4. To make it into a CPS, the subroutine CompleteSeq at line 6 appends at the end of S a sequence S \u2032 of pairs such that each second element in a pair of S \u2022 S \u2032 is a first element in a later pair (except for the last one), as required by the definition of CPS. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.8010634779930115}, "created": {"value": false, "score": 5.841255187988281e-06}, "shared": {"value": false, "score": 2.7418136596679688e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9800965189933777}, "created": {"value": false, "score": 0.011954963207244873}, "shared": {"value": false, "score": 2.7418136596679688e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "TrivialRand", "normalizedForm": "TrivialRand", "offsetStart": 223, "offsetEnd": 234}, "language": {"rawForm": "Python", "normalizedForm": "Python"}, "context": "The model that gave the best results for datasets of this type is the one trained with parameters max L = 100, M = 500 (see Figure 14a), so we chose to use this model for both ML and TrivialML, and compare them to Rand and TrivialRand. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9998382329940796}, "created": {"value": false, "score": 6.794929504394531e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999942779541016}, "created": {"value": true, "score": 0.9998072981834412}, "shared": {"value": false, "score": 1.5497207641601562e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "PickNext", "normalizedForm": "PickNext", "offsetStart": 230, "offsetEnd": 238}, "context": "We define a class of randomised heuristics that construct a CPS by picking one reducible pair of the input set T at a time and by appending this pair to a growing partial sequence, as described in Algorithm 1 (the two subroutines PickNext and CompleteSeq will be described in details below). ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0005087852478027344}, "created": {"value": false, "score": 0.011954963207244873}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.08447009325027466}, "created": {"value": false, "score": 0.09656381607055664}, "shared": {"value": false, "score": 3.5762786865234375e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "TrivialRand", "normalizedForm": "TrivialRand", "offsetStart": 233, "offsetEnd": 244}, "language": {"rawForm": "Python", "normalizedForm": "Python"}, "context": "As a consequence of Hybroscale and TreeChild being exact methods (TreeChild only for a restricted class of networks), they performed better than both ML and TrivialRand on all instances they could solve, although the best results of TrivialRand are often close (no worse than 14%) and sometimes match the optimal value.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9954120516777039}, "created": {"value": false, "score": 1.9073486328125e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999942779541016}, "created": {"value": true, "score": 0.9998072981834412}, "shared": {"value": false, "score": 1.5497207641601562e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "TrivialRand", "normalizedForm": "TrivialRand", "offsetStart": 238, "offsetEnd": 249}, "language": {"rawForm": "Python", "normalizedForm": "Python"}, "context": "While just one run of ML or TrivialML gave better results than the average of multiple runs of TrivialRand (up to 64% on average), picking the best output over all the runs of TrivialRand seems to give the best results for FTS instances, TrivialRand being better than ML by up to 25% on average for instances obtained from networks with 20 leaves and 5 reticulations and yielding results only slightly better than ML and TrivialML in the rest of instance groups (ML being better by 3% on average than the best output of TrivialRand only for the instance group (100,7)).", "mentionContextAttributes": {"used": {"value": true, "score": 0.9997835755348206}, "created": {"value": false, "score": 1.5497207641601562e-06}, "shared": {"value": false, "score": 7.152557373046875e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999942779541016}, "created": {"value": true, "score": 0.9998072981834412}, "shared": {"value": false, "score": 1.5497207641601562e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CompleteSeq", "normalizedForm": "CompleteSeq", "offsetStart": 243, "offsetEnd": 254}, "context": "We define a class of randomised heuristics that construct a CPS by picking one reducible pair of the input set T at a time and by appending this pair to a growing partial sequence, as described in Algorithm 1 (the two subroutines PickNext and CompleteSeq will be described in details below). ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0005087852478027344}, "created": {"value": false, "score": 0.011954963207244873}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9800965189933777}, "created": {"value": false, "score": 0.011954963207244873}, "shared": {"value": false, "score": 2.7418136596679688e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "TrivialRand", "normalizedForm": "TrivialRand", "offsetStart": 520, "offsetEnd": 531}, "language": {"rawForm": "Python", "normalizedForm": "Python"}, "context": "While just one run of ML or TrivialML gave better results than the average of multiple runs of TrivialRand (up to 64% on average), picking the best output over all the runs of TrivialRand seems to give the best results for FTS instances, TrivialRand being better than ML by up to 25% on average for instances obtained from networks with 20 leaves and 5 reticulations and yielding results only slightly better than ML and TrivialML in the rest of instance groups (ML being better by 3% on average than the best output of TrivialRand only for the instance group (100,7)). ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9997835755348206}, "created": {"value": false, "score": 1.5497207641601562e-06}, "shared": {"value": false, "score": 7.152557373046875e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999942779541016}, "created": {"value": true, "score": 0.9998072981834412}, "shared": {"value": false, "score": 1.5497207641601562e-06}}}], "references": [{"refKey": 1, "tei": "<biblStruct xml:id=\"b1\">\n\t<analytic>\n\t\t<title level=\"a\" type=\"main\">Computing all hybridization networks for multiple binary phylogenetic input trees</title>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Benjamin</forename><surname>Albrecht</surname></persName>\n\t\t</author>\n\t\t<idno type=\"DOI\">10.1186/s12859-015-0660-7</idno>\n\t</analytic>\n\t<monogr>\n\t\t<title level=\"j\">BMC Bioinformatics</title>\n\t\t<title level=\"j\" type=\"abbrev\">BMC Bioinformatics</title>\n\t\t<idno type=\"ISSNe\">1471-2105</idno>\n\t\t<imprint>\n\t\t\t<biblScope unit=\"volume\">16</biblScope>\n\t\t\t<biblScope unit=\"issue\">1</biblScope>\n\t\t\t<biblScope unit=\"page\">15</biblScope>\n\t\t\t<date type=\"published\" when=\"2015-07-30\">2015</date>\n\t\t\t<publisher>Springer Science and Business Media LLC</publisher>\n\t\t</imprint>\n\t</monogr>\n</biblStruct>\n"}], "runtime": 49991, "id": "3355b1a259a39e658bd3bfc9e1371cecaa60a855", "metadata": {"id": "3355b1a259a39e658bd3bfc9e1371cecaa60a855"}, "original_file_path": "../../datalake/Samuel/SV22/SV22_xml/hal-03832882.grobid.tei.xml", "file_name": "hal-03832882.grobid.tei.xml"}