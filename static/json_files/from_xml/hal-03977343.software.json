{"application": "software-mentions", "version": "0.8.0", "date": "2024-03-21T09:59+0000", "md5": "A6B7CDAD62C4F06E2418B3666036BC22", "mentions": [{"type": "software", "software-type": "software", "software-name": {"rawForm": "Flax", "normalizedForm": "Flax", "offsetStart": 0, "offsetEnd": 4}, "context": "Flax (https:// github.com/google/flax) ", "mentionContextAttributes": {"used": {"value": false, "score": 0.008826196193695068}, "created": {"value": false, "score": 2.562999725341797e-05}, "shared": {"value": true, "score": 0.9867836236953735}}, "documentContextAttributes": {"used": {"value": false, "score": 0.008826196193695068}, "created": {"value": false, "score": 2.562999725341797e-05}, "shared": {"value": true, "score": 0.9867836236953735}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "QCANet", "normalizedForm": "QCANet", "offsetStart": 0, "offsetEnd": 6}, "context": "QCANet uses two different models for bounding-box detection and segmentation, whereas NuSeT uses a single U-Net model to compute both. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.00017011165618896484}, "created": {"value": false, "score": 4.649162292480469e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.8480234146118164}, "created": {"value": false, "score": 0.00010633468627929688}, "shared": {"value": false, "score": 4.5299530029296875e-06}}, "references": [{"label": "(Yang et al., 2020)", "normalizedForm": "Yang et al., 2020", "refKey": 82}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Roboflow", "normalizedForm": "Roboflow", "offsetStart": 0, "offsetEnd": 8}, "context": "Roboflow (https://app. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.002521336078643799}, "created": {"value": false, "score": 4.684925079345703e-05}, "shared": {"value": true, "score": 0.9264793395996094}}, "documentContextAttributes": {"used": {"value": false, "score": 0.002521336078643799}, "created": {"value": false, "score": 4.684925079345703e-05}, "shared": {"value": true, "score": 0.9264793395996094}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Cellpose", "normalizedForm": "Cellpose", "offsetStart": 0, "offsetEnd": 8}, "context": "Cellpose (https://www.cellpose.org/) ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0009096860885620117}, "created": {"value": false, "score": 3.516674041748047e-05}, "shared": {"value": true, "score": 0.9903010129928589}}, "documentContextAttributes": {"used": {"value": true, "score": 0.8480234146118164}, "created": {"value": false, "score": 0.005615711212158203}, "shared": {"value": true, "score": 0.9903010129928589}}, "references": [{"label": "(Tokuoka et al., 2020)", "normalizedForm": "Tokuoka et al., 2020", "refKey": 71}, {"label": "(Yang et al., 2020)", "normalizedForm": "Yang et al., 2020", "refKey": 82}]}, {"type": "software", "software-type": "software", "wikidataId": "Q3598981", "wikipediaExternalRef": 16081497, "lang": "en", "confidence": 0.7874, "software-name": {"rawForm": "3D Slicer", "normalizedForm": "3D Slicer", "wikidataId": "Q3598981", "wikipediaExternalRef": 16081497, "lang": "en", "confidence": 0.7874, "offsetStart": 0, "offsetEnd": 9}, "context": "3D Slicer (https://www.slicer.org/), ", "mentionContextAttributes": {"used": {"value": false, "score": 0.00831371545791626}, "created": {"value": false, "score": 6.0558319091796875e-05}, "shared": {"value": true, "score": 0.988042950630188}}, "documentContextAttributes": {"used": {"value": false, "score": 0.00831371545791626}, "created": {"value": false, "score": 6.0558319091796875e-05}, "shared": {"value": true, "score": 0.988042950630188}}}, {"type": "software", "software-type": "software", "wikidataId": "Q3598981", "wikipediaExternalRef": 16081497, "lang": "en", "confidence": 0.7874, "software-name": {"rawForm": "3D Slicer", "normalizedForm": "3D Slicer", "wikidataId": "Q3598981", "wikipediaExternalRef": 16081497, "lang": "en", "confidence": 0.7874, "offsetStart": 0, "offsetEnd": 9}, "context": "3D Slicer or ITK-SNAP can be used for both 2D and 3D images.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0002186894416809082}, "created": {"value": false, "score": 9.059906005859375e-06}, "shared": {"value": false, "score": 7.152557373046875e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.00831371545791626}, "created": {"value": false, "score": 6.0558319091796875e-05}, "shared": {"value": true, "score": 0.988042950630188}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "DeepImageJ", "normalizedForm": "DeepImageJ", "offsetStart": 0, "offsetEnd": 10}, "context": "DeepImageJ works with the Bioimage.io ", "mentionContextAttributes": {"used": {"value": false, "score": 0.001362144947052002}, "created": {"value": false, "score": 0.008253991603851318}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.001362144947052002}, "created": {"value": false, "score": 0.008253991603851318}, "shared": {"value": false, "score": 3.5762786865234375e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "torchvision", "normalizedForm": "torchvision", "offsetStart": 0, "offsetEnd": 11}, "context": "torchvision (https://pytorch.org/vision/stable/index.html), mmDetection (https://github.com/open-mmlab/mmdetection), ", "mentionContextAttributes": {"used": {"value": false, "score": 0.003271937370300293}, "created": {"value": false, "score": 6.67572021484375e-06}, "shared": {"value": false, "score": 0.158361554145813}}, "documentContextAttributes": {"used": {"value": false, "score": 0.003271937370300293}, "created": {"value": false, "score": 6.67572021484375e-06}, "shared": {"value": false, "score": 0.158361554145813}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Google Colab", "normalizedForm": "Google Colab", "offsetStart": 0, "offsetEnd": 12}, "context": "Google Colab (https://research.google.com/colaboratory/),", "mentionContextAttributes": {"used": {"value": false, "score": 0.0011522769927978516}, "created": {"value": false, "score": 0.0002377629280090332}, "shared": {"value": true, "score": 0.9410967230796814}}, "documentContextAttributes": {"used": {"value": false, "score": 0.003955841064453125}, "created": {"value": false, "score": 0.0854610800743103}, "shared": {"value": true, "score": 0.9410967230796814}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "TensorFlow Hub", "normalizedForm": "TensorFlow Hub", "offsetStart": 0, "offsetEnd": 14}, "context": "TensorFlow Hub (https://tfhub.dev/), ", "mentionContextAttributes": {"used": {"value": false, "score": 0.03424888849258423}, "created": {"value": false, "score": 2.5987625122070312e-05}, "shared": {"value": true, "score": 0.9878097772598267}}, "documentContextAttributes": {"used": {"value": false, "score": 0.03424888849258423}, "created": {"value": false, "score": 2.5987625122070312e-05}, "shared": {"value": true, "score": 0.9878097772598267}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ZeroCostDL4Mic", "normalizedForm": "ZeroCostDL4Mic", "offsetStart": 0, "offsetEnd": 14}, "context": "ZeroCostDL4Mic (https://github.com/ ", "mentionContextAttributes": {"used": {"value": false, "score": 0.012839913368225098}, "created": {"value": false, "score": 3.1113624572753906e-05}, "shared": {"value": true, "score": 0.9908242225646973}}, "documentContextAttributes": {"used": {"value": false, "score": 0.012839913368225098}, "created": {"value": false, "score": 0.0854610800743103}, "shared": {"value": true, "score": 0.9908242225646973}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Cellpose", "normalizedForm": "Cellpose", "offsetStart": 0, "offsetEnd": 32}, "context": "Cellpose (Stringer et al., 2021) (Table S1) has also adapted this technique for 3D images. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0002574324607849121}, "created": {"value": false, "score": 0.005615711212158203}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.8480234146118164}, "created": {"value": false, "score": 0.005615711212158203}, "shared": {"value": true, "score": 0.9903010129928589}}, "references": [{"label": "(Tokuoka et al., 2020)", "normalizedForm": "Tokuoka et al., 2020", "refKey": 71}, {"label": "(Yang et al., 2020)", "normalizedForm": "Yang et al., 2020", "refKey": 82}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "fastai", "normalizedForm": "fastai", "offsetStart": 3, "offsetEnd": 9}, "context": "or fastai (https://www.fast.ai/), ", "mentionContextAttributes": {"used": {"value": false, "score": 0.00026994943618774414}, "created": {"value": false, "score": 3.504753112792969e-05}, "shared": {"value": true, "score": 0.9576743841171265}}, "documentContextAttributes": {"used": {"value": false, "score": 0.00026994943618774414}, "created": {"value": false, "score": 3.504753112792969e-05}, "shared": {"value": true, "score": 0.9576743841171265}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "NucleAIzer", "normalizedForm": "NucleAIzer", "offsetStart": 3, "offsetEnd": 13}, "url": {"rawForm": "https://www. nucleaizer.org", "normalizedForm": "https://www. nucleaizer.org", "offsetStart": 15, "offsetEnd": 42}, "context": "or NucleAIzer (https://www. nucleaizer.org/), ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0005578398704528809}, "created": {"value": false, "score": 2.0384788513183594e-05}, "shared": {"value": true, "score": 0.9788082838058472}}, "documentContextAttributes": {"used": {"value": false, "score": 0.0005578398704528809}, "created": {"value": false, "score": 2.0384788513183594e-05}, "shared": {"value": true, "score": 0.9788082838058472}}}, {"type": "software", "software-type": "software", "wikidataId": "Q1659584", "wikipediaExternalRef": 3793613, "lang": "en", "confidence": 0.7223, "software-name": {"rawForm": "ImageJ", "normalizedForm": "ImageJ", "wikidataId": "Q1659584", "wikipediaExternalRef": 3793613, "lang": "en", "confidence": 0.7223, "offsetStart": 4, "offsetEnd": 10}, "context": "The ImageJ plugin Qualitative Annotations (Thomas et al., 2021) is an annotation tool for classification, storing the manual annotations in a text file. ", "mentionContextAttributes": {"used": {"value": false, "score": 8.106231689453125e-05}, "created": {"value": false, "score": 9.965896606445312e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.0013543963432312012}, "created": {"value": false, "score": 0.01991826295852661}, "shared": {"value": false, "score": 5.328655242919922e-05}}, "references": [{"label": "(Schindelin et al., 2012)", "normalizedForm": "Schindelin et al., 2012", "refKey": 60}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "StarDist", "normalizedForm": "StarDist", "offsetStart": 4, "offsetEnd": 12}, "context": "The StarDist nucleus segmentation method (Weigert et al., 2020), for instance, instructs the model to look for 3D starshaped polyhedrons, because a nucleus can be assimilated to an invaginated ellipsoid, which can be modelled as a star-shaped polyhedron.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0001323223114013672}, "created": {"value": false, "score": 0.00013530254364013672}, "shared": {"value": false, "score": 5.960464477539062e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.034613192081451416}, "created": {"value": false, "score": 0.0001958012580871582}, "shared": {"value": false, "score": 4.5299530029296875e-06}}, "references": [{"label": "(Tofighi et al., 2018)", "normalizedForm": "Tofighi et al., 2018", "refKey": 70}, {"label": "(Xing et al., 2019)", "normalizedForm": "Xing et al., 2019", "refKey": 81}]}, {"type": "software", "software-type": "software", "wikidataId": "Q474635", "wikipediaExternalRef": 9057232, "lang": "en", "confidence": 0.9124, "software-name": {"rawForm": "ParaView", "normalizedForm": "ParaView", "wikidataId": "Q474635", "wikipediaExternalRef": 9057232, "lang": "en", "confidence": 0.9124, "offsetStart": 9, "offsetEnd": 38}, "context": "Finally, ParaView (Ahrens et al., 2005), which is designed for scientific visualization and volume rendering, allows the user to highlight object structures by applying a range of colours to 3D images using simple thresholds.", "mentionContextAttributes": {"used": {"value": false, "score": 2.491474151611328e-05}, "created": {"value": false, "score": 0.47975432872772217}, "shared": {"value": false, "score": 9.5367431640625e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 2.491474151611328e-05}, "created": {"value": false, "score": 0.47975432872772217}, "shared": {"value": false, "score": 9.5367431640625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "4Mic", "normalizedForm": "4Mic", "offsetStart": 10, "offsetEnd": 14}, "context": "ZeroCostDL4Mic; von Chamier et al., 2021). ", "mentionContextAttributes": {"used": {"value": false, "score": 0.008506059646606445}, "created": {"value": false, "score": 4.291534423828125e-05}, "shared": {"value": false, "score": 8.940696716308594e-06}}, "documentContextAttributes": {"used": {"value": false, "score": 0.008506059646606445}, "created": {"value": false, "score": 4.291534423828125e-05}, "shared": {"value": false, "score": 8.940696716308594e-06}}, "references": [{"label": "Chamier et al., 2021)", "normalizedForm": "Chamier et al., 2021)", "refKey": 75, "offsetStart": 28050, "offsetEnd": 28071}]}, {"type": "software", "software-type": "software", "wikidataId": "Q725967", "wikipediaExternalRef": 19961416, "lang": "en", "confidence": 0.595, "software-name": {"rawForm": "Azure", "normalizedForm": "Azure", "wikidataId": "Q725967", "wikipediaExternalRef": 19961416, "lang": "en", "confidence": 0.595, "offsetStart": 10, "offsetEnd": 15}, "publisher": {"rawForm": "Microsoft", "normalizedForm": "Microsoft", "offsetStart": 0, "offsetEnd": 9}, "context": "Microsoft Azure (https://azure.microsoft.com/en-us/services/machinelearning/) and Paperspace.com ", "mentionContextAttributes": {"used": {"value": false, "score": 0.00024002790451049805}, "created": {"value": false, "score": 3.9577484130859375e-05}, "shared": {"value": true, "score": 0.9869207143783569}}, "documentContextAttributes": {"used": {"value": false, "score": 0.00024002790451049805}, "created": {"value": false, "score": 3.9577484130859375e-05}, "shared": {"value": true, "score": 0.9869207143783569}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Project InnerEye", "normalizedForm": "Project InnerEye", "offsetStart": 10, "offsetEnd": 26}, "publisher": {"rawForm": "Microsoft", "normalizedForm": "Microsoft", "offsetStart": 0, "offsetEnd": 9}, "context": "Microsoft Project InnerEye (https:// www.microsoft.com/en-us/research/project/medical-image-analysis/) or Aivia (https://www.aivia-software.com/), ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0001443624496459961}, "created": {"value": false, "score": 0.0006557106971740723}, "shared": {"value": false, "score": 0.003996789455413818}}, "documentContextAttributes": {"used": {"value": false, "score": 0.0001443624496459961}, "created": {"value": false, "score": 0.0006557106971740723}, "shared": {"value": false, "score": 0.003996789455413818}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Gunpowder", "normalizedForm": "Gunpowder", "offsetStart": 11, "offsetEnd": 20}, "context": "yapic/) or Gunpowder (https://github.com/funkey/gunpowder), ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0010690093040466309}, "created": {"value": false, "score": 3.9458274841308594e-05}, "shared": {"value": true, "score": 0.6573518514633179}}, "documentContextAttributes": {"used": {"value": false, "score": 0.0010690093040466309}, "created": {"value": false, "score": 3.9458274841308594e-05}, "shared": {"value": true, "score": 0.6573518514633179}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ZeroCostDL4Mic", "normalizedForm": "ZeroCostDL4Mic", "offsetStart": 13, "offsetEnd": 27}, "context": "HenriquesLab/ZeroCostDL4Mic) is a set of implementations of DL methods for microscopy running in Google Colab.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0001379251480102539}, "created": {"value": false, "score": 0.0854610800743103}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.012839913368225098}, "created": {"value": false, "score": 0.0854610800743103}, "shared": {"value": true, "score": 0.9908242225646973}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "NuSeT", "normalizedForm": "NuSeT", "offsetStart": 14, "offsetEnd": 19}, "context": "Additionally, NuSeT provides a userfriendly interface.", "mentionContextAttributes": {"used": {"value": false, "score": 2.6345252990722656e-05}, "created": {"value": false, "score": 0.00012350082397460938}, "shared": {"value": false, "score": 0.00017660856246948242}}, "documentContextAttributes": {"used": {"value": true, "score": 0.8480234146118164}, "created": {"value": false, "score": 0.00012350082397460938}, "shared": {"value": false, "score": 0.00017660856246948242}}, "references": [{"label": "(Yang et al., 2020)", "normalizedForm": "Yang et al., 2020", "refKey": 82}, {"label": "(Yang et al., 2020)", "normalizedForm": "Yang et al., 2020", "refKey": 82}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "StarDist", "normalizedForm": "StarDist", "offsetStart": 14, "offsetEnd": 45}, "context": "It is used by StarDist (Weigert et al., 2020) (Table S1) for 2D and 3D images. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.034613192081451416}, "created": {"value": false, "score": 2.7060508728027344e-05}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.034613192081451416}, "created": {"value": false, "score": 0.0001958012580871582}, "shared": {"value": false, "score": 4.5299530029296875e-06}}, "references": [{"label": "(Tofighi et al., 2018)", "normalizedForm": "Tofighi et al., 2018", "refKey": 70}, {"label": "(Xing et al., 2019)", "normalizedForm": "Xing et al., 2019", "refKey": 81}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "3D-bat", "normalizedForm": "3D-bat", "offsetStart": 18, "offsetEnd": 24}, "context": "for 2D images and 3D-bat (https://github.com/walzimmer/3d-bat; ", "mentionContextAttributes": {"used": {"value": false, "score": 0.32743197679519653}, "created": {"value": false, "score": 1.800060272216797e-05}, "shared": {"value": true, "score": 0.7601367831230164}}, "documentContextAttributes": {"used": {"value": false, "score": 0.32743197679519653}, "created": {"value": false, "score": 1.800060272216797e-05}, "shared": {"value": true, "score": 0.7601367831230164}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Medical Imaging Interaction Toolkit", "normalizedForm": "Medical Imaging Interaction Toolkit", "offsetStart": 18, "offsetEnd": 53}, "context": "Tools such as the Medical Imaging Interaction Toolkit (MITK; Wolf et al., 2004) and Icy (De Chaumont et al., 2012) also incorporate well-adapted visualization features for 3D medical images and bioimages. ", "mentionContextAttributes": {"used": {"value": false, "score": 7.545948028564453e-05}, "created": {"value": false, "score": 0.0021033287048339844}, "shared": {"value": false, "score": 1.430511474609375e-06}}, "documentContextAttributes": {"used": {"value": false, "score": 7.545948028564453e-05}, "created": {"value": false, "score": 0.0021033287048339844}, "shared": {"value": false, "score": 1.430511474609375e-06}}, "references": [{"label": "Wolf et al., 2004)", "normalizedForm": "Wolf et al., 2004)", "refKey": 80, "offsetStart": 19709, "offsetEnd": 19727}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Google Drive", "normalizedForm": "Google Drive", "offsetStart": 19, "offsetEnd": 31}, "context": "Once uploaded on a Google Drive, a nucleus dataset can be used to train an object-detection model such as YOLO online. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.00010776519775390625}, "created": {"value": false, "score": 0.003058135509490967}, "shared": {"value": false, "score": 9.5367431640625e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.00010776519775390625}, "created": {"value": false, "score": 0.003058135509490967}, "shared": {"value": false, "score": 9.5367431640625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "TensorFlow", "normalizedForm": "TensorFlow", "offsetStart": 23, "offsetEnd": 33}, "context": "DL frameworks, such as TensorFlow, PyTorch, JAX (https://github.com/google/jax), ", "mentionContextAttributes": {"used": {"value": false, "score": 0.00040024518966674805}, "created": {"value": false, "score": 0.0002129673957824707}, "shared": {"value": false, "score": 0.003913402557373047}}, "documentContextAttributes": {"used": {"value": false, "score": 0.00040024518966674805}, "created": {"value": false, "score": 0.0002129673957824707}, "shared": {"value": false, "score": 0.003913402557373047}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Google AutoML Vision", "normalizedForm": "Google AutoML Vision", "offsetStart": 24, "offsetEnd": 44}, "context": "The most well-known are Google AutoML Vision (https://cloud.google.com/vision), ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0010165572166442871}, "created": {"value": false, "score": 0.006784260272979736}, "shared": {"value": true, "score": 0.7924311757087708}}, "documentContextAttributes": {"used": {"value": false, "score": 0.0010165572166442871}, "created": {"value": false, "score": 0.006784260272979736}, "shared": {"value": true, "score": 0.7924311757087708}}}, {"type": "software", "software-type": "software", "wikidataId": "Q1659584", "wikipediaExternalRef": 3793613, "lang": "en", "confidence": 0.7223, "software-name": {"rawForm": "ImageJ", "normalizedForm": "ImageJ", "wikidataId": "Q1659584", "wikipediaExternalRef": 3793613, "lang": "en", "confidence": 0.7223, "offsetStart": 26, "offsetEnd": 32}, "context": "This plugin relies on the ImageJ selection tools and can also be used for object detection by drawing bounding boxes around objects. ", "mentionContextAttributes": {"used": {"value": false, "score": 4.839897155761719e-05}, "created": {"value": false, "score": 0.0005954504013061523}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.0013543963432312012}, "created": {"value": false, "score": 0.01991826295852661}, "shared": {"value": false, "score": 5.328655242919922e-05}}, "references": [{"label": "(Schindelin et al., 2012)", "normalizedForm": "Schindelin et al., 2012", "refKey": 60}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Bioimage.io", "normalizedForm": "Bioimage.io", "offsetStart": 26, "offsetEnd": 37}, "context": "DeepImageJ works with the Bioimage.io ", "mentionContextAttributes": {"used": {"value": false, "score": 0.001362144947052002}, "created": {"value": false, "score": 0.008253991603851318}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.001362144947052002}, "created": {"value": false, "score": 0.008253991603851318}, "shared": {"value": false, "score": 3.5762786865234375e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "DeepCell", "normalizedForm": "DeepCell", "offsetStart": 31, "offsetEnd": 39}, "context": "Conversely, the method used by DeepCell, called Mesmer, relies on PanopticNet, a DL model designed to predict both nuclei centres and borders (Greenwald et al., 2021) (Table S1). ", "mentionContextAttributes": {"used": {"value": false, "score": 0.00018101930618286133}, "created": {"value": false, "score": 0.002514481544494629}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.848022997379303}, "created": {"value": true, "score": 0.6521539092063904}, "shared": {"value": true, "score": 0.5825142860412598}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Nvidia Clara Imaging", "normalizedForm": "Nvidia Clara Imaging", "offsetStart": 31, "offsetEnd": 51}, "url": {"rawForm": "https://developer. nvidia.com/clara-medical-imaging", "normalizedForm": "https://developer. nvidia.com/clara-medical-imaging", "offsetStart": 53, "offsetEnd": 104}, "context": "or business solutions, such as Nvidia Clara Imaging (https://developer. nvidia.com/clara-medical-imaging), ", "mentionContextAttributes": {"used": {"value": false, "score": 9.131431579589844e-05}, "created": {"value": false, "score": 0.11168766021728516}, "shared": {"value": false, "score": 0.0001233816146850586}}, "documentContextAttributes": {"used": {"value": false, "score": 9.131431579589844e-05}, "created": {"value": false, "score": 0.11168766021728516}, "shared": {"value": false, "score": 0.0001233816146850586}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ZeroCostDL4Mic", "normalizedForm": "ZeroCostDL4Mic", "offsetStart": 33, "offsetEnd": 47}, "context": "We advise non-programmers to use ZeroCostDL4Mic, which also contains DL models for segmentation, or alternatively either the U-Net (Falk et al., 2019) or DeepImageJ (G\u00f3mez-de-Mariscal et al., 2021) ImageJ/Fiji plugins, which both have a graphical interface. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0004298090934753418}, "created": {"value": false, "score": 0.0002925992012023926}, "shared": {"value": false, "score": 3.445148468017578e-05}}, "documentContextAttributes": {"used": {"value": false, "score": 0.012839913368225098}, "created": {"value": false, "score": 0.0854610800743103}, "shared": {"value": true, "score": 0.9908242225646973}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "PyTorch", "normalizedForm": "PyTorch", "offsetStart": 35, "offsetEnd": 42}, "context": "DL frameworks, such as TensorFlow, PyTorch, JAX (https://github.com/google/jax), ", "mentionContextAttributes": {"used": {"value": false, "score": 0.00040024518966674805}, "created": {"value": false, "score": 0.0002129673957824707}, "shared": {"value": false, "score": 0.003913402557373047}}, "documentContextAttributes": {"used": {"value": false, "score": 0.00040024518966674805}, "created": {"value": false, "score": 0.0002129673957824707}, "shared": {"value": false, "score": 0.003913402557373047}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "nnU-Net", "normalizedForm": "nnU-Net", "offsetStart": 42, "offsetEnd": 70}, "url": {"rawForm": "https://github.com/MIC-DKFZ/ nnUNet", "normalizedForm": "https://github.com/MIC-DKFZ/ nnUNet", "offsetStart": 73, "offsetEnd": 108}, "context": "For users more familiar with programming, nnU-Net (Isensee et al., 2021; https://github.com/MIC-DKFZ/ nnUNet) is recommended for 3D instance segmentation because it automatically handles the full model configuration and training, and for 2D images, implementation of most state-of-the-art methods for segmentation can be found on GitHub (https://github.com/qubvel/ ", "mentionContextAttributes": {"used": {"value": false, "score": 0.009253144264221191}, "created": {"value": false, "score": 1.239776611328125e-05}, "shared": {"value": false, "score": 0.012427449226379395}}, "documentContextAttributes": {"used": {"value": false, "score": 0.009253144264221191}, "created": {"value": false, "score": 1.239776611328125e-05}, "shared": {"value": false, "score": 0.012427449226379395}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CSBDeep                        toolbox", "normalizedForm": "CSBDeep toolbox", "offsetStart": 43, "offsetEnd": 81}, "context": "The first three solutions are based on the CSBDeep (Weigert et al., 2018) toolbox (Table S1) and have proven their efficiency with 2D nucleus images. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0021154284477233887}, "created": {"value": false, "score": 0.022743582725524902}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.0021154284477233887}, "created": {"value": false, "score": 0.022743582725524902}, "shared": {"value": false, "score": 1.1920928955078125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "JAX", "normalizedForm": "JAX", "offsetStart": 44, "offsetEnd": 47}, "context": "DL frameworks, such as TensorFlow, PyTorch, JAX (https://github.com/google/jax), ", "mentionContextAttributes": {"used": {"value": false, "score": 0.00040024518966674805}, "created": {"value": false, "score": 0.0002129673957824707}, "shared": {"value": false, "score": 0.003913402557373047}}, "documentContextAttributes": {"used": {"value": false, "score": 0.00040024518966674805}, "created": {"value": false, "score": 0.0002129673957824707}, "shared": {"value": false, "score": 0.003913402557373047}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "DeepSynth", "normalizedForm": "DeepSynth", "offsetStart": 44, "offsetEnd": 53}, "context": "However, only five provide a trained model: DeepSynth, QCANet, NuSeT, DeepCell and Cellpose.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00012803077697753906}, "created": {"value": false, "score": 0.00010633468627929688}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.00855785608291626}, "created": {"value": false, "score": 0.00010633468627929688}, "shared": {"value": false, "score": 4.5299530029296875e-06}}}, {"type": "software", "software-type": "software", "wikidataId": "Q17029215", "wikipediaExternalRef": 36480775, "lang": "en", "confidence": 0.7193, "software-name": {"rawForm": "Ilastik", "normalizedForm": "Ilastik", "wikidataId": "Q17029215", "wikipediaExternalRef": 36480775, "lang": "en", "confidence": 0.7193, "offsetStart": 51, "offsetEnd": 77}, "context": "Icy (De Chaumont et al., 2012) and, more recently, Ilastik (Berg et al., 2019). ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9463687539100647}, "created": {"value": false, "score": 0.0009347796440124512}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9463687539100647}, "created": {"value": false, "score": 0.003972530364990234}, "shared": {"value": false, "score": 2.1457672119140625e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "QCANet", "normalizedForm": "QCANet", "offsetStart": 55, "offsetEnd": 61}, "context": "However, only five provide a trained model: DeepSynth, QCANet, NuSeT, DeepCell and Cellpose.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00012803077697753906}, "created": {"value": false, "score": 0.00010633468627929688}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.8480234146118164}, "created": {"value": false, "score": 0.00010633468627929688}, "shared": {"value": false, "score": 4.5299530029296875e-06}}, "references": [{"label": "(Yang et al., 2020)", "normalizedForm": "Yang et al., 2020", "refKey": 82}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "mmDetection", "normalizedForm": "mmDetection", "offsetStart": 60, "offsetEnd": 71}, "context": "torchvision (https://pytorch.org/vision/stable/index.html), mmDetection (https://github.com/open-mmlab/mmdetection), ", "mentionContextAttributes": {"used": {"value": false, "score": 0.003271937370300293}, "created": {"value": false, "score": 6.67572021484375e-06}, "shared": {"value": false, "score": 0.158361554145813}}, "documentContextAttributes": {"used": {"value": false, "score": 0.003271937370300293}, "created": {"value": false, "score": 6.67572021484375e-06}, "shared": {"value": false, "score": 0.158361554145813}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "QCANet", "normalizedForm": "QCANet", "offsetStart": 60, "offsetEnd": 89}, "context": "The two main methods using this technique for 3D images are QCANet (Tokuoka et al., 2020) and NuSeT (Yang et al., 2020) (Table S1). ", "mentionContextAttributes": {"used": {"value": false, "score": 0.00019806623458862305}, "created": {"value": false, "score": 1.6927719116210938e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.8480234146118164}, "created": {"value": false, "score": 0.00010633468627929688}, "shared": {"value": false, "score": 4.5299530029296875e-06}}, "references": [{"label": "(Yang et al., 2020)", "normalizedForm": "Yang et al., 2020", "refKey": 82}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "NuSeT", "normalizedForm": "NuSeT", "offsetStart": 63, "offsetEnd": 68}, "context": "However, only five provide a trained model: DeepSynth, QCANet, NuSeT, DeepCell and Cellpose.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00012803077697753906}, "created": {"value": false, "score": 0.00010633468627929688}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.8480234146118164}, "created": {"value": false, "score": 0.00012350082397460938}, "shared": {"value": false, "score": 0.00017660856246948242}}, "references": [{"label": "(Yang et al., 2020)", "normalizedForm": "Yang et al., 2020", "refKey": 82}, {"label": "(Yang et al., 2020)", "normalizedForm": "Yang et al., 2020", "refKey": 82}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Anaconda", "normalizedForm": "Anaconda", "offsetStart": 65, "offsetEnd": 73}, "context": "Such an environment can be built with a package manager, such as Anaconda or Docker, if conflicts occur with the operating system (OS; orange) occur. ", "mentionContextAttributes": {"used": {"value": false, "score": 4.6253204345703125e-05}, "created": {"value": false, "score": 0.0004107356071472168}, "shared": {"value": false, "score": 5.960464477539062e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 4.6253204345703125e-05}, "created": {"value": false, "score": 0.0004107356071472168}, "shared": {"value": false, "score": 5.960464477539062e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "StarDist", "normalizedForm": "StarDist", "offsetStart": 66, "offsetEnd": 96}, "context": "Among these, only five provide a valid code with a trained model [StarDist (Schmidt et al., 2018), SP-CNN (Tofighi et al., 2018), KiNet (Xing et al., 2019), NucleiDetection (Valkonen et al., 2020) and QCANet (Tokuoka et al., 2020)], and only one works with 3D images (QCANet). ", "mentionContextAttributes": {"used": {"value": false, "score": 0.02047830820083618}, "created": {"value": false, "score": 4.410743713378906e-06}, "shared": {"value": false, "score": 1.430511474609375e-06}}, "documentContextAttributes": {"used": {"value": false, "score": 0.034613192081451416}, "created": {"value": false, "score": 0.0001958012580871582}, "shared": {"value": false, "score": 4.5299530029296875e-06}}, "references": [{"label": "(Tofighi et al., 2018)", "normalizedForm": "Tofighi et al., 2018", "refKey": 70, "offsetStart": 26874, "offsetEnd": 26896}, {"label": "(Xing et al., 2019)", "normalizedForm": "Xing et al., 2019", "refKey": 81, "offsetStart": 26904, "offsetEnd": 26923}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "DeepCell", "normalizedForm": "DeepCell", "offsetStart": 70, "offsetEnd": 78}, "context": "However, only five provide a trained model: DeepSynth, QCANet, NuSeT, DeepCell and Cellpose.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00012803077697753906}, "created": {"value": false, "score": 0.00010633468627929688}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.848022997379303}, "created": {"value": true, "score": 0.6521539092063904}, "shared": {"value": true, "score": 0.5825142860412598}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "TensorFlow", "normalizedForm": "TensorFlow", "offsetStart": 74, "offsetEnd": 84}, "context": "For image analysis studies, higherlevel frameworks are available, such as TensorFlow model (https:// github.com/tensorflow/models), ", "mentionContextAttributes": {"used": {"value": false, "score": 3.3974647521972656e-05}, "created": {"value": false, "score": 8.916854858398438e-05}, "shared": {"value": false, "score": 0.00033032894134521484}}, "documentContextAttributes": {"used": {"value": false, "score": 0.00040024518966674805}, "created": {"value": false, "score": 0.0002129673957824707}, "shared": {"value": false, "score": 0.003913402557373047}}}, {"type": "software", "software-type": "software", "wikidataId": "Q15206305", "wikipediaExternalRef": 40149201, "lang": "en", "confidence": 0.6895, "software-name": {"rawForm": "Docker", "normalizedForm": "Docker", "wikidataId": "Q15206305", "wikipediaExternalRef": 40149201, "lang": "en", "confidence": 0.6895, "offsetStart": 77, "offsetEnd": 83}, "context": "Such an environment can be built with a package manager, such as Anaconda or Docker, if conflicts occur with the operating system (OS; orange) occur. ", "mentionContextAttributes": {"used": {"value": false, "score": 4.6253204345703125e-05}, "created": {"value": false, "score": 0.0004107356071472168}, "shared": {"value": false, "score": 5.960464477539062e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.8394791483879089}, "created": {"value": false, "score": 0.0004107356071472168}, "shared": {"value": false, "score": 2.384185791015625e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Paperspace.com", "normalizedForm": "Paperspace.com", "offsetStart": 82, "offsetEnd": 96}, "context": "Microsoft Azure (https://azure.microsoft.com/en-us/services/machinelearning/) and Paperspace.com ", "mentionContextAttributes": {"used": {"value": false, "score": 0.00024002790451049805}, "created": {"value": false, "score": 3.9577484130859375e-05}, "shared": {"value": true, "score": 0.9869207143783569}}, "documentContextAttributes": {"used": {"value": false, "score": 0.00024002790451049805}, "created": {"value": false, "score": 3.9577484130859375e-05}, "shared": {"value": true, "score": 0.9869207143783569}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "DeepCell", "normalizedForm": "DeepCell", "offsetStart": 83, "offsetEnd": 91}, "context": "For the specific problem of nuclear image analysis, the best development tools are DeepCell and Cellpose.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00012922286987304688}, "created": {"value": false, "score": 0.0013003349304199219}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.848022997379303}, "created": {"value": true, "score": 0.6521539092063904}, "shared": {"value": true, "score": 0.5825142860412598}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Cellpose", "normalizedForm": "Cellpose", "offsetStart": 83, "offsetEnd": 91}, "context": "However, only five provide a trained model: DeepSynth, QCANet, NuSeT, DeepCell and Cellpose.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00012803077697753906}, "created": {"value": false, "score": 0.00010633468627929688}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.8480234146118164}, "created": {"value": false, "score": 0.005615711212158203}, "shared": {"value": true, "score": 0.9903010129928589}}, "references": [{"label": "(Tokuoka et al., 2020)", "normalizedForm": "Tokuoka et al., 2020", "refKey": 71}, {"label": "(Yang et al., 2020)", "normalizedForm": "Yang et al., 2020", "refKey": 82}]}, {"type": "software", "software-type": "implicit", "software-name": {"rawForm": "code", "normalizedForm": "code", "offsetStart": 84, "offsetEnd": 88}, "context": "for instance, offers free access to powerful GPUs and allows any user to run Python code online with minimal setup. ", "mentionContextAttributes": {"used": {"value": false, "score": 5.459785461425781e-05}, "created": {"value": false, "score": 0.00289994478225708}, "shared": {"value": false, "score": 0.00459444522857666}}, "documentContextAttributes": {"used": {"value": false, "score": 5.459785461425781e-05}, "created": {"value": false, "score": 0.00289994478225708}, "shared": {"value": false, "score": 0.00459444522857666}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "RMSProp", "normalizedForm": "RMSProp", "offsetStart": 84, "offsetEnd": 91}, "context": "The most used optimizers based on gradient descent are Stochastic Gradient Descent, RMSProp and Adam (Ruder, 2016 preprint).", "mentionContextAttributes": {"used": {"value": false, "score": 0.11234402656555176}, "created": {"value": false, "score": 6.556510925292969e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.11234402656555176}, "created": {"value": false, "score": 6.556510925292969e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "references": [{"label": "(Ruder, 2016 preprint)", "normalizedForm": "Ruder, 2016 preprint", "refKey": 0, "offsetStart": 6772, "offsetEnd": 6794}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "NuSeT", "normalizedForm": "NuSeT", "offsetStart": 86, "offsetEnd": 91}, "context": "QCANet uses two different models for bounding-box detection and segmentation, whereas NuSeT uses a single U-Net model to compute both. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.00017011165618896484}, "created": {"value": false, "score": 4.649162292480469e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.8480234146118164}, "created": {"value": false, "score": 0.00012350082397460938}, "shared": {"value": false, "score": 0.00017660856246948242}}, "references": [{"label": "(Yang et al., 2020)", "normalizedForm": "Yang et al., 2020", "refKey": 82}, {"label": "(Yang et al., 2020)", "normalizedForm": "Yang et al., 2020", "refKey": 82}]}, {"type": "software", "software-type": "software", "wikidataId": "Q2667535", "wikipediaExternalRef": 19099981, "lang": "en", "confidence": 0.5121, "software-name": {"rawForm": "TANGO", "normalizedForm": "TANGO", "wikidataId": "Q2667535", "wikipediaExternalRef": 19099981, "lang": "en", "confidence": 0.5121, "offsetStart": 86, "offsetEnd": 113}, "context": "Open-source tools dedicated to the quantitative description of the 3D nucleus include TANGO (Ollion et al., 2013) and NucleusJ (Dubos et al., 2020). ", "mentionContextAttributes": {"used": {"value": false, "score": 6.401538848876953e-05}, "created": {"value": false, "score": 0.002745211124420166}, "shared": {"value": false, "score": 1.3113021850585938e-06}}, "documentContextAttributes": {"used": {"value": false, "score": 6.401538848876953e-05}, "created": {"value": false, "score": 0.002745211124420166}, "shared": {"value": false, "score": 1.3113021850585938e-06}}}, {"type": "software", "software-type": "software", "wikidataId": "Q15206305", "wikipediaExternalRef": 40149201, "lang": "en", "confidence": 0.6895, "software-name": {"rawForm": "Docker", "normalizedForm": "Docker", "wikidataId": "Q15206305", "wikipediaExternalRef": 40149201, "lang": "en", "confidence": 0.6895, "offsetStart": 87, "offsetEnd": 93}, "context": "A good practice is to package them all into a development environment manager, such as Docker or Anaconda (Fig. 3B).", "mentionContextAttributes": {"used": {"value": false, "score": 0.00017386674880981445}, "created": {"value": false, "score": 0.0004017949104309082}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.8394791483879089}, "created": {"value": false, "score": 0.0004107356071472168}, "shared": {"value": false, "score": 2.384185791015625e-06}}}, {"type": "software", "software-type": "software", "wikidataId": "Q3598981", "wikipediaExternalRef": 16081497, "lang": "en", "confidence": 0.7874, "software-name": {"rawForm": "3D Slicer", "normalizedForm": "3D Slicer", "wikidataId": "Q3598981", "wikipediaExternalRef": 16081497, "lang": "en", "confidence": 0.7874, "offsetStart": 90, "offsetEnd": 99}, "context": "Visualizing the results of segmentation might be difficult using a slice-only viewer, and 3D Slicer, ITK-SNAP and ImageJ all have integrated tools for volume rendering. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0013543963432312012}, "created": {"value": false, "score": 1.71661376953125e-05}, "shared": {"value": false, "score": 5.960464477539062e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.00831371545791626}, "created": {"value": false, "score": 6.0558319091796875e-05}, "shared": {"value": true, "score": 0.988042950630188}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "DeepCell", "normalizedForm": "DeepCell", "offsetStart": 92, "offsetEnd": 100}, "context": "To conclude, if planning to segment 2D nuclei, we advise first trying the online version of DeepCell (https://www.deepcell.org/), ", "mentionContextAttributes": {"used": {"value": false, "score": 0.01635885238647461}, "created": {"value": true, "score": 0.6521539092063904}, "shared": {"value": true, "score": 0.5825142860412598}}, "documentContextAttributes": {"used": {"value": true, "score": 0.848022997379303}, "created": {"value": true, "score": 0.6521539092063904}, "shared": {"value": true, "score": 0.5825142860412598}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "webKnossos", "normalizedForm": "webKnossos", "offsetStart": 92, "offsetEnd": 102}, "context": "org/omero/; Allan et al., 2012), which can also be installed on any institution server; and webKnossos.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00015664100646972656}, "created": {"value": false, "score": 0.00014603137969970703}, "shared": {"value": true, "score": 0.7106627225875854}}, "documentContextAttributes": {"used": {"value": false, "score": 0.00015664100646972656}, "created": {"value": false, "score": 0.00014603137969970703}, "shared": {"value": true, "score": 0.7106627225875854}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ZeroCostDL4Mic", "normalizedForm": "ZeroCostDL4Mic", "offsetStart": 93, "offsetEnd": 107}, "context": "These models are currently non-retrainable, but some of the segmentation models created with ZeroCostDL4Mic are compatible with the plugin. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0003616809844970703}, "created": {"value": false, "score": 0.00039523839950561523}, "shared": {"value": false, "score": 1.430511474609375e-06}}, "documentContextAttributes": {"used": {"value": false, "score": 0.012839913368225098}, "created": {"value": false, "score": 0.0854610800743103}, "shared": {"value": true, "score": 0.9908242225646973}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "NuSeT", "normalizedForm": "NuSeT", "offsetStart": 94, "offsetEnd": 119}, "context": "The two main methods using this technique for 3D images are QCANet (Tokuoka et al., 2020) and NuSeT (Yang et al., 2020) (Table S1). ", "mentionContextAttributes": {"used": {"value": false, "score": 0.00019806623458862305}, "created": {"value": false, "score": 1.6927719116210938e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.8480234146118164}, "created": {"value": false, "score": 0.00012350082397460938}, "shared": {"value": false, "score": 0.00017660856246948242}}, "references": [{"label": "(Yang et al., 2020)", "normalizedForm": "Yang et al., 2020", "refKey": 82}, {"label": "(Yang et al., 2020)", "normalizedForm": "Yang et al., 2020", "refKey": 82}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Cellpose", "normalizedForm": "Cellpose", "offsetStart": 96, "offsetEnd": 104}, "context": "For the specific problem of nuclear image analysis, the best development tools are DeepCell and Cellpose.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00012922286987304688}, "created": {"value": false, "score": 0.0013003349304199219}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.8480234146118164}, "created": {"value": false, "score": 0.005615711212158203}, "shared": {"value": true, "score": 0.9903010129928589}}, "references": [{"label": "(Tokuoka et al., 2020)", "normalizedForm": "Tokuoka et al., 2020", "refKey": 71}, {"label": "(Yang et al., 2020)", "normalizedForm": "Yang et al., 2020", "refKey": 82}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Google Colab", "normalizedForm": "Google Colab", "offsetStart": 97, "offsetEnd": 109}, "context": "HenriquesLab/ZeroCostDL4Mic) is a set of implementations of DL methods for microscopy running in Google Colab.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0001379251480102539}, "created": {"value": false, "score": 0.0854610800743103}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.003955841064453125}, "created": {"value": false, "score": 0.0854610800743103}, "shared": {"value": true, "score": 0.9410967230796814}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SP-CNN", "normalizedForm": "SP-CNN", "offsetStart": 99, "offsetEnd": 127}, "context": "Among these, only five provide a valid code with a trained model [StarDist (Schmidt et al., 2018), SP-CNN (Tofighi et al., 2018), KiNet (Xing et al., 2019), NucleiDetection (Valkonen et al., 2020) and QCANet (Tokuoka et al., 2020)], and only one works with 3D images (QCANet). ", "mentionContextAttributes": {"used": {"value": false, "score": 0.02047830820083618}, "created": {"value": false, "score": 4.410743713378906e-06}, "shared": {"value": false, "score": 1.430511474609375e-06}}, "documentContextAttributes": {"used": {"value": false, "score": 0.02047830820083618}, "created": {"value": false, "score": 4.410743713378906e-06}, "shared": {"value": false, "score": 1.430511474609375e-06}}, "references": [{"label": "(Xing et al., 2019)", "normalizedForm": "Xing et al., 2019", "refKey": 81, "offsetStart": 26904, "offsetEnd": 26923}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "VGG Image Annotator", "normalizedForm": "VGG Image Annotator", "offsetStart": 100, "offsetEnd": 119}, "context": "which is designed for annotation of 3D biomedical images, or more general-purpose software, such as VGG Image Annotator (VIA; https://www.robots. ox.ac.uk/~vgg/software/via/; Dutta and Zisserman, 2019) or LabelImg (https://github.com/tzutalin/labelImg) ", "mentionContextAttributes": {"used": {"value": false, "score": 8.797645568847656e-05}, "created": {"value": false, "score": 3.0040740966796875e-05}, "shared": {"value": false, "score": 8.368492126464844e-05}}, "documentContextAttributes": {"used": {"value": false, "score": 8.797645568847656e-05}, "created": {"value": false, "score": 3.0040740966796875e-05}, "shared": {"value": false, "score": 8.368492126464844e-05}}}, {"type": "software", "software-type": "software", "wikidataId": "Q5974832", "wikipediaExternalRef": 13697814, "lang": "en", "confidence": 0.7636, "software-name": {"rawForm": "ITK-SNAP", "normalizedForm": "ITK-SNAP", "wikidataId": "Q5974832", "wikipediaExternalRef": 13697814, "lang": "en", "confidence": 0.7636, "offsetStart": 101, "offsetEnd": 109}, "context": "Visualizing the results of segmentation might be difficult using a slice-only viewer, and 3D Slicer, ITK-SNAP and ImageJ all have integrated tools for volume rendering. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0013543963432312012}, "created": {"value": false, "score": 1.71661376953125e-05}, "shared": {"value": false, "score": 5.960464477539062e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.0013543963432312012}, "created": {"value": false, "score": 1.71661376953125e-05}, "shared": {"value": false, "score": 5.960464477539062e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "StarDist", "normalizedForm": "StarDist", "offsetStart": 103, "offsetEnd": 133}, "context": "Examples of post-processing are sigmoid transform or more complex operations, such as those used in by StarDist (Weigert et al., 2020). ", "mentionContextAttributes": {"used": {"value": false, "score": 9.40561294555664e-05}, "created": {"value": false, "score": 0.0001354217529296875}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.034613192081451416}, "created": {"value": false, "score": 0.0001958012580871582}, "shared": {"value": false, "score": 4.5299530029296875e-06}}, "references": [{"label": "(Tofighi et al., 2018)", "normalizedForm": "Tofighi et al., 2018", "refKey": 70}, {"label": "(Xing et al., 2019)", "normalizedForm": "Xing et al., 2019", "refKey": 81}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ZeroCostDL4Mic", "normalizedForm": "ZeroCostDL4Mic", "offsetStart": 105, "offsetEnd": 119}, "context": "A version of U-Net also exists for 3D images (Cicek et al., 2016), and this has been integrated into the ZeroCostDL4Mic project.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00015652179718017578}, "created": {"value": false, "score": 0.0009119510650634766}, "shared": {"value": false, "score": 1.3113021850585938e-06}}, "documentContextAttributes": {"used": {"value": false, "score": 0.012839913368225098}, "created": {"value": false, "score": 0.0854610800743103}, "shared": {"value": true, "score": 0.9908242225646973}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Aivia", "normalizedForm": "Aivia", "offsetStart": 106, "offsetEnd": 111}, "context": "Microsoft Project InnerEye (https:// www.microsoft.com/en-us/research/project/medical-image-analysis/) or Aivia (https://www.aivia-software.com/), ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0001443624496459961}, "created": {"value": false, "score": 0.0006557106971740723}, "shared": {"value": false, "score": 0.003996789455413818}}, "documentContextAttributes": {"used": {"value": false, "score": 0.0001443624496459961}, "created": {"value": false, "score": 0.0006557106971740723}, "shared": {"value": false, "score": 0.003996789455413818}}}, {"type": "software", "software-type": "software", "wikidataId": "Q364", "wikipediaExternalRef": 18545292, "lang": "en", "confidence": 0.912, "software-name": {"rawForm": "GitHub", "normalizedForm": "GitHub", "wikidataId": "Q364", "wikipediaExternalRef": 18545292, "lang": "en", "confidence": 0.912, "offsetStart": 109, "offsetEnd": 115}, "context": "Aside from the datasets (see below), sharing this information can be done on code-sharing platforms, such as GitHub or GitLab, or environment-sharing platforms such as DockerHub.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0072803497314453125}, "created": {"value": false, "score": 9.691715240478516e-05}, "shared": {"value": false, "score": 0.02665609121322632}}, "documentContextAttributes": {"used": {"value": false, "score": 0.009253263473510742}, "created": {"value": false, "score": 9.691715240478516e-05}, "shared": {"value": false, "score": 0.02665609121322632}}}, {"type": "software", "software-type": "software", "wikidataId": "Q1659584", "wikipediaExternalRef": 3793613, "lang": "en", "confidence": 0.7766, "software-name": {"rawForm": "ImageJ", "normalizedForm": "ImageJ", "wikidataId": "Q1659584", "wikipediaExternalRef": 3793613, "lang": "en", "confidence": 0.7766, "offsetStart": 114, "offsetEnd": 120}, "context": "Visualizing the results of segmentation might be difficult using a slice-only viewer, and 3D Slicer, ITK-SNAP and ImageJ all have integrated tools for volume rendering. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0013543963432312012}, "created": {"value": false, "score": 1.71661376953125e-05}, "shared": {"value": false, "score": 5.960464477539062e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.0013543963432312012}, "created": {"value": false, "score": 0.01991826295852661}, "shared": {"value": false, "score": 5.328655242919922e-05}}, "references": [{"label": "(Schindelin et al., 2012)", "normalizedForm": "Schindelin et al., 2012", "refKey": 60}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "NucleusJ", "normalizedForm": "NucleusJ", "offsetStart": 118, "offsetEnd": 146}, "context": "Open-source tools dedicated to the quantitative description of the 3D nucleus include TANGO (Ollion et al., 2013) and NucleusJ (Dubos et al., 2020). ", "mentionContextAttributes": {"used": {"value": false, "score": 6.401538848876953e-05}, "created": {"value": false, "score": 0.002745211124420166}, "shared": {"value": false, "score": 1.3113021850585938e-06}}, "documentContextAttributes": {"used": {"value": false, "score": 6.401538848876953e-05}, "created": {"value": false, "score": 0.002745211124420166}, "shared": {"value": false, "score": 1.3113021850585938e-06}}}, {"type": "software", "software-type": "software", "wikidataId": "Q16639197", "wikipediaExternalRef": 44209778, "lang": "en", "confidence": 0.9161, "software-name": {"rawForm": "GitLab", "normalizedForm": "GitLab", "wikidataId": "Q16639197", "wikipediaExternalRef": 44209778, "lang": "en", "confidence": 0.9161, "offsetStart": 119, "offsetEnd": 125}, "context": "Aside from the datasets (see below), sharing this information can be done on code-sharing platforms, such as GitHub or GitLab, or environment-sharing platforms such as DockerHub.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0072803497314453125}, "created": {"value": false, "score": 9.691715240478516e-05}, "shared": {"value": false, "score": 0.02665609121322632}}, "documentContextAttributes": {"used": {"value": false, "score": 0.0072803497314453125}, "created": {"value": false, "score": 9.691715240478516e-05}, "shared": {"value": false, "score": 0.02665609121322632}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "VIA", "normalizedForm": "VIA", "offsetStart": 121, "offsetEnd": 124}, "url": {"rawForm": "https://www.robots. ox.ac.uk/~vgg/software/via/", "normalizedForm": "https://www.robots. ox.ac.uk/~vgg/software/via", "offsetStart": 126, "offsetEnd": 173}, "context": "which is designed for annotation of 3D biomedical images, or more general-purpose software, such as VGG Image Annotator (VIA; https://www.robots. ox.ac.uk/~vgg/software/via/; Dutta and Zisserman, 2019) or LabelImg (https://github.com/tzutalin/labelImg) ", "mentionContextAttributes": {"used": {"value": false, "score": 8.797645568847656e-05}, "created": {"value": false, "score": 3.0040740966796875e-05}, "shared": {"value": false, "score": 8.368492126464844e-05}}, "documentContextAttributes": {"used": {"value": false, "score": 8.797645568847656e-05}, "created": {"value": false, "score": 3.0040740966796875e-05}, "shared": {"value": false, "score": 8.368492126464844e-05}}, "references": [{"label": "Dutta and Zisserman, 2019)", "normalizedForm": "Dutta and Zisserman, 2019)", "refKey": 20, "offsetStart": 18359, "offsetEnd": 18385}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "U-Net", "normalizedForm": "U-Net", "offsetStart": 125, "offsetEnd": 150}, "context": "We advise non-programmers to use ZeroCostDL4Mic, which also contains DL models for segmentation, or alternatively either the U-Net (Falk et al., 2019) or DeepImageJ (G\u00f3mez-de-Mariscal et al., 2021) ImageJ/Fiji plugins, which both have a graphical interface. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0004298090934753418}, "created": {"value": false, "score": 0.0002925992012023926}, "shared": {"value": false, "score": 3.445148468017578e-05}}, "documentContextAttributes": {"used": {"value": false, "score": 0.0004298090934753418}, "created": {"value": false, "score": 0.0002925992012023926}, "shared": {"value": false, "score": 3.445148468017578e-05}}}, {"type": "software", "software-type": "software", "wikidataId": "Q1659584", "wikipediaExternalRef": 3793613, "lang": "en", "confidence": 0.7223, "software-name": {"rawForm": "ImageJ", "normalizedForm": "ImageJ", "wikidataId": "Q1659584", "wikipediaExternalRef": 3793613, "lang": "en", "confidence": 0.7223, "offsetStart": 130, "offsetEnd": 136}, "context": "Many platforms and libraries dedicated to the analysis of images from microscopy have been developed, of which the best known are ImageJ/Fiji (Schindelin et al., 2012), CellProfiler (Carpenter et al., 2006), Imaris (Oxford Instruments; https://imaris. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.00012099742889404297}, "created": {"value": false, "score": 0.01991826295852661}, "shared": {"value": false, "score": 5.328655242919922e-05}}, "documentContextAttributes": {"used": {"value": false, "score": 0.0013543963432312012}, "created": {"value": false, "score": 0.01991826295852661}, "shared": {"value": false, "score": 5.328655242919922e-05}}, "references": [{"label": "(Schindelin et al., 2012)", "normalizedForm": "Schindelin et al., 2012", "refKey": 60, "offsetStart": 944, "offsetEnd": 969}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "KiNet", "normalizedForm": "KiNet", "offsetStart": 130, "offsetEnd": 154}, "context": "Among these, only five provide a valid code with a trained model [StarDist (Schmidt et al., 2018), SP-CNN (Tofighi et al., 2018), KiNet (Xing et al., 2019), NucleiDetection (Valkonen et al., 2020) and QCANet (Tokuoka et al., 2020)], and only one works with 3D images (QCANet). ", "mentionContextAttributes": {"used": {"value": false, "score": 0.02047830820083618}, "created": {"value": false, "score": 4.410743713378906e-06}, "shared": {"value": false, "score": 1.430511474609375e-06}}, "documentContextAttributes": {"used": {"value": false, "score": 0.02047830820083618}, "created": {"value": false, "score": 4.410743713378906e-06}, "shared": {"value": false, "score": 1.430511474609375e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "DeepSynth", "normalizedForm": "DeepSynth", "offsetStart": 131, "offsetEnd": 159}, "context": "Among those, only 35 provide an open-source implementation, and of these, ten can handle 3D nuclei: CDeep3M (Haberl et al., 2018), DeepSynth (Dunn et al., 2019), 3D U-Net (Cicek et al., 2016), QCANet (Tokuoka et al., 2020), Retina U-Net (Jaeger et al., 2020), NuSeT (Yang et al., 2020), StarDist (Weigert et al., 2020), nnU-Net (Isensee et al., 2021), DeepCell (Van Valen et al., 2016), and Cellpose (Stringer et al., 2021). ", "mentionContextAttributes": {"used": {"value": false, "score": 0.00855785608291626}, "created": {"value": false, "score": 1.4066696166992188e-05}, "shared": {"value": false, "score": 4.5299530029296875e-06}}, "documentContextAttributes": {"used": {"value": false, "score": 0.00855785608291626}, "created": {"value": false, "score": 0.00010633468627929688}, "shared": {"value": false, "score": 4.5299530029296875e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Fiji", "normalizedForm": "Fiji", "offsetStart": 137, "offsetEnd": 166}, "context": "Many platforms and libraries dedicated to the analysis of images from microscopy have been developed, of which the best known are ImageJ/Fiji (Schindelin et al., 2012), CellProfiler (Carpenter et al., 2006), Imaris (Oxford Instruments; https://imaris. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.00012099742889404297}, "created": {"value": false, "score": 0.01991826295852661}, "shared": {"value": false, "score": 5.328655242919922e-05}}, "documentContextAttributes": {"used": {"value": false, "score": 0.0004298090934753418}, "created": {"value": false, "score": 0.01991826295852661}, "shared": {"value": false, "score": 5.328655242919922e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "OpenMMLab", "normalizedForm": "OpenMMLab", "offsetStart": 147, "offsetEnd": 156}, "url": {"rawForm": "https://github.com/open-mmlab/ mmdetection", "normalizedForm": "https://github.com/open-mmlab/ mmdetection", "offsetStart": 158, "offsetEnd": 200}, "context": "For a programmer, another solution is to employ the implementation of the state-of-the-art methods for general object detection in 2D developed by OpenMMLab (https://github.com/open-mmlab/ mmdetection).", "mentionContextAttributes": {"used": {"value": false, "score": 4.9591064453125e-05}, "created": {"value": false, "score": 0.24756115674972534}, "shared": {"value": false, "score": 0.00036072731018066406}}, "documentContextAttributes": {"used": {"value": false, "score": 4.9591064453125e-05}, "created": {"value": false, "score": 0.24756115674972534}, "shared": {"value": false, "score": 0.00036072731018066406}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ZeroCostDL4Mic", "normalizedForm": "ZeroCostDL4Mic", "offsetStart": 153, "offsetEnd": 167}, "context": "Programmers might be interested in looking at these methods, whereas non-programmers could employ one of the easyto-use denoising models integrated into ZeroCostDL4Mic if they have access to a suitable dataset, which only needs to be composed of raw images and does not require manual labelling.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0007039308547973633}, "created": {"value": false, "score": 0.00013947486877441406}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.012839913368225098}, "created": {"value": false, "score": 0.0854610800743103}, "shared": {"value": true, "score": 0.9908242225646973}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "DeepImageJ                                  ImageJ", "normalizedForm": "DeepImageJ ImageJ", "offsetStart": 154, "offsetEnd": 204}, "context": "We advise non-programmers to use ZeroCostDL4Mic, which also contains DL models for segmentation, or alternatively either the U-Net (Falk et al., 2019) or DeepImageJ (G\u00f3mez-de-Mariscal et al., 2021) ImageJ/Fiji plugins, which both have a graphical interface. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0004298090934753418}, "created": {"value": false, "score": 0.0002925992012023926}, "shared": {"value": false, "score": 3.445148468017578e-05}}, "documentContextAttributes": {"used": {"value": false, "score": 0.0004298090934753418}, "created": {"value": false, "score": 0.0002925992012023926}, "shared": {"value": false, "score": 3.445148468017578e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "NucleiDetection", "normalizedForm": "NucleiDetection", "offsetStart": 157, "offsetEnd": 196}, "context": "Among these, only five provide a valid code with a trained model [StarDist (Schmidt et al., 2018), SP-CNN (Tofighi et al., 2018), KiNet (Xing et al., 2019), NucleiDetection (Valkonen et al., 2020) and QCANet (Tokuoka et al., 2020)], and only one works with 3D images (QCANet). ", "mentionContextAttributes": {"used": {"value": false, "score": 0.02047830820083618}, "created": {"value": false, "score": 4.410743713378906e-06}, "shared": {"value": false, "score": 1.430511474609375e-06}}, "documentContextAttributes": {"used": {"value": false, "score": 0.02047830820083618}, "created": {"value": false, "score": 4.410743713378906e-06}, "shared": {"value": false, "score": 1.430511474609375e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ZeroCostDL4Mic", "normalizedForm": "ZeroCostDL4Mic", "offsetStart": 166, "offsetEnd": 180}, "context": "A code-free solution is to first find a manually annotated dataset of nuclei before using an easy-to-use graphical interface generated for DL model training, such as ZeroCostDL4Mic (https://github.com/HenriquesLab/ ", "mentionContextAttributes": {"used": {"value": false, "score": 0.00017446279525756836}, "created": {"value": false, "score": 0.0013172030448913574}, "shared": {"value": false, "score": 0.00029724836349487305}}, "documentContextAttributes": {"used": {"value": false, "score": 0.012839913368225098}, "created": {"value": false, "score": 0.0854610800743103}, "shared": {"value": true, "score": 0.9908242225646973}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "DockerHub", "normalizedForm": "DockerHub", "offsetStart": 168, "offsetEnd": 177}, "context": "Aside from the datasets (see below), sharing this information can be done on code-sharing platforms, such as GitHub or GitLab, or environment-sharing platforms such as DockerHub.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0072803497314453125}, "created": {"value": false, "score": 9.691715240478516e-05}, "shared": {"value": false, "score": 0.02665609121322632}}, "documentContextAttributes": {"used": {"value": false, "score": 0.0072803497314453125}, "created": {"value": false, "score": 9.691715240478516e-05}, "shared": {"value": false, "score": 0.02665609121322632}}}, {"type": "software", "software-type": "software", "wikidataId": "Q5058134", "wikipediaExternalRef": 4366564, "lang": "en", "confidence": 0.9161, "software-name": {"rawForm": "CellProfiler", "normalizedForm": "CellProfiler", "wikidataId": "Q5058134", "wikipediaExternalRef": 4366564, "lang": "en", "confidence": 0.9161, "offsetStart": 169, "offsetEnd": 205}, "context": "Many platforms and libraries dedicated to the analysis of images from microscopy have been developed, of which the best known are ImageJ/Fiji (Schindelin et al., 2012), CellProfiler (Carpenter et al., 2006), Imaris (Oxford Instruments; https://imaris. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.00012099742889404297}, "created": {"value": false, "score": 0.01991826295852661}, "shared": {"value": false, "score": 5.328655242919922e-05}}, "documentContextAttributes": {"used": {"value": false, "score": 0.00012099742889404297}, "created": {"value": false, "score": 0.01991826295852661}, "shared": {"value": false, "score": 5.328655242919922e-05}}}, {"type": "software", "software-type": "software", "wikidataId": "Q17029215", "wikipediaExternalRef": 36480775, "lang": "en", "confidence": 0.5143, "software-name": {"rawForm": "Ilastik", "normalizedForm": "Ilastik", "wikidataId": "Q17029215", "wikipediaExternalRef": 36480775, "lang": "en", "confidence": 0.5143, "offsetStart": 175, "offsetEnd": 203}, "mentionContextAttributes": {"used": {"value": false, "score": 0.32873600721359253}, "created": {"value": false, "score": 0.003972530364990234}, "shared": {"value": false, "score": 2.1457672119140625e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9463687539100647}, "created": {"value": false, "score": 0.003972530364990234}, "shared": {"value": false, "score": 2.1457672119140625e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Google Colab", "normalizedForm": "Google Colab", "offsetStart": 179, "offsetEnd": 191}, "context": "A large set of DL models for object detection (for 2D images only), as well as for image segmentation, denoising and virtual staining, have been encapsulated and set up online on Google Colab servers. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.003955841064453125}, "created": {"value": false, "score": 0.002619922161102295}, "shared": {"value": false, "score": 1.6927719116210938e-05}}, "documentContextAttributes": {"used": {"value": false, "score": 0.003955841064453125}, "created": {"value": false, "score": 0.0854610800743103}, "shared": {"value": true, "score": 0.9410967230796814}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "QCANet", "normalizedForm": "QCANet", "offsetStart": 193, "offsetEnd": 199}, "context": "Among those, only 35 provide an open-source implementation, and of these, ten can handle 3D nuclei: CDeep3M (Haberl et al., 2018), DeepSynth (Dunn et al., 2019), 3D U-Net (Cicek et al., 2016), QCANet (Tokuoka et al., 2020), Retina U-Net (Jaeger et al., 2020), NuSeT (Yang et al., 2020), StarDist (Weigert et al., 2020), nnU-Net (Isensee et al., 2021), DeepCell (Van Valen et al., 2016), and Cellpose (Stringer et al., 2021).", "mentionContextAttributes": {"used": {"value": false, "score": 0.00855785608291626}, "created": {"value": false, "score": 1.4066696166992188e-05}, "shared": {"value": false, "score": 4.5299530029296875e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.8480234146118164}, "created": {"value": false, "score": 0.00010633468627929688}, "shared": {"value": false, "score": 4.5299530029296875e-06}}, "references": [{"label": "(Tokuoka et al., 2020)", "normalizedForm": "Tokuoka et al., 2020", "refKey": 71, "offsetStart": 29791, "offsetEnd": 29813}, {"label": "(Tokuoka et al., 2020)", "normalizedForm": "Tokuoka et al., 2020", "refKey": 71, "offsetStart": 29791, "offsetEnd": 29813}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "QCANet", "normalizedForm": "QCANet", "offsetStart": 201, "offsetEnd": 229}, "context": "Among these, only five provide a valid code with a trained model [StarDist (Schmidt et al., 2018), SP-CNN (Tofighi et al., 2018), KiNet (Xing et al., 2019), NucleiDetection (Valkonen et al., 2020) and QCANet (Tokuoka et al., 2020)], and only one works with 3D images (QCANet). ", "mentionContextAttributes": {"used": {"value": false, "score": 0.02047830820083618}, "created": {"value": false, "score": 4.410743713378906e-06}, "shared": {"value": false, "score": 1.430511474609375e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.8480234146118164}, "created": {"value": false, "score": 0.00010633468627929688}, "shared": {"value": false, "score": 4.5299530029296875e-06}}, "references": [{"label": "(Yang et al., 2020)", "normalizedForm": "Yang et al., 2020", "refKey": 82}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Fiji", "normalizedForm": "Fiji", "offsetStart": 205, "offsetEnd": 209}, "context": "We advise non-programmers to use ZeroCostDL4Mic, which also contains DL models for segmentation, or alternatively either the U-Net (Falk et al., 2019) or DeepImageJ (G\u00f3mez-de-Mariscal et al., 2021) ImageJ/Fiji plugins, which both have a graphical interface. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0004298090934753418}, "created": {"value": false, "score": 0.0002925992012023926}, "shared": {"value": false, "score": 3.445148468017578e-05}}, "documentContextAttributes": {"used": {"value": false, "score": 0.0004298090934753418}, "created": {"value": false, "score": 0.01991826295852661}, "shared": {"value": false, "score": 5.328655242919922e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LabelImg", "normalizedForm": "LabelImg", "offsetStart": 205, "offsetEnd": 213}, "context": "which is designed for annotation of 3D biomedical images, or more general-purpose software, such as VGG Image Annotator (VIA; https://www.robots. ox.ac.uk/~vgg/software/via/; Dutta and Zisserman, 2019) or LabelImg (https://github.com/tzutalin/labelImg) ", "mentionContextAttributes": {"used": {"value": false, "score": 8.797645568847656e-05}, "created": {"value": false, "score": 3.0040740966796875e-05}, "shared": {"value": false, "score": 8.368492126464844e-05}}, "documentContextAttributes": {"used": {"value": false, "score": 8.797645568847656e-05}, "created": {"value": false, "score": 3.0040740966796875e-05}, "shared": {"value": false, "score": 8.368492126464844e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "StarDist", "normalizedForm": "StarDist", "offsetStart": 214, "offsetEnd": 222}, "context": "In particular, the DenoiSeg method couples denoising and segmentation in the same model and has demonstrated a substantial improvement in 2D nuclear segmentation compared with other methods, such as U-Net alone or StarDist. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.000125885009765625}, "created": {"value": false, "score": 0.0001958012580871582}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.034613192081451416}, "created": {"value": false, "score": 0.0001958012580871582}, "shared": {"value": false, "score": 4.5299530029296875e-06}}, "references": [{"label": "(Tofighi et al., 2018)", "normalizedForm": "Tofighi et al., 2018", "refKey": 70}, {"label": "(Xing et al., 2019)", "normalizedForm": "Xing et al., 2019", "refKey": 81}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "DeepCell", "normalizedForm": "DeepCell", "offsetStart": 234, "offsetEnd": 266}, "context": "However, in case of 3D nucleus segmentation, if previous results are inaccurate, the model must be applied to a large dataset or the data cannot be uploaded to an online server, we suggest using and configuring the offline version of DeepCell (Van Valen et al., 2016), Cellpose (Stringer et al., 2021), QCANet (Tokuoka et al., 2020) or NuSeT (Yang et al., 2020). ", "mentionContextAttributes": {"used": {"value": true, "score": 0.848022997379303}, "created": {"value": false, "score": 3.910064697265625e-05}, "shared": {"value": false, "score": 4.5299530029296875e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.848022997379303}, "created": {"value": true, "score": 0.6521539092063904}, "shared": {"value": true, "score": 0.5825142860412598}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "NuSeT", "normalizedForm": "NuSeT", "offsetStart": 260, "offsetEnd": 265}, "context": "Among those, only 35 provide an open-source implementation, and of these, ten can handle 3D nuclei: CDeep3M (Haberl et al., 2018), DeepSynth (Dunn et al., 2019), 3D U-Net (Cicek et al., 2016), QCANet (Tokuoka et al., 2020), Retina U-Net (Jaeger et al., 2020), NuSeT (Yang et al., 2020), StarDist (Weigert et al., 2020), nnU-Net (Isensee et al., 2021), DeepCell (Van Valen et al., 2016), and Cellpose (Stringer et al., 2021).", "mentionContextAttributes": {"used": {"value": false, "score": 0.00855785608291626}, "created": {"value": false, "score": 1.4066696166992188e-05}, "shared": {"value": false, "score": 4.5299530029296875e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.8480234146118164}, "created": {"value": false, "score": 0.00012350082397460938}, "shared": {"value": false, "score": 0.00017660856246948242}}, "references": [{"label": "(Yang et al., 2020)", "normalizedForm": "Yang et al., 2020", "refKey": 82, "offsetStart": 29857, "offsetEnd": 29876}, {"label": "(Yang et al., 2020)", "normalizedForm": "Yang et al., 2020", "refKey": 82, "offsetStart": 29857, "offsetEnd": 29876}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "QCANet", "normalizedForm": "QCANet", "offsetStart": 268, "offsetEnd": 274}, "context": "Among these, only five provide a valid code with a trained model [StarDist (Schmidt et al., 2018), SP-CNN (Tofighi et al., 2018), KiNet (Xing et al., 2019), NucleiDetection (Valkonen et al., 2020) and QCANet (Tokuoka et al., 2020)], and only one works with 3D images (QCANet). ", "mentionContextAttributes": {"used": {"value": false, "score": 0.020477890968322754}, "created": {"value": false, "score": 4.410743713378906e-06}, "shared": {"value": false, "score": 1.430511474609375e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.8480234146118164}, "created": {"value": false, "score": 0.00010633468627929688}, "shared": {"value": false, "score": 4.5299530029296875e-06}}, "references": [{"label": "(Yang et al., 2020)", "normalizedForm": "Yang et al., 2020", "refKey": 82}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Cellpose", "normalizedForm": "Cellpose", "offsetStart": 269, "offsetEnd": 300}, "context": "However, in case of 3D nucleus segmentation, if previous results are inaccurate, the model must be applied to a large dataset or the data cannot be uploaded to an online server, we suggest using and configuring the offline version of DeepCell (Van Valen et al., 2016), Cellpose (Stringer et al., 2021), QCANet (Tokuoka et al., 2020) or NuSeT (Yang et al., 2020). ", "mentionContextAttributes": {"used": {"value": true, "score": 0.8480234146118164}, "created": {"value": false, "score": 3.910064697265625e-05}, "shared": {"value": false, "score": 4.5299530029296875e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.8480234146118164}, "created": {"value": false, "score": 0.005615711212158203}, "shared": {"value": true, "score": 0.9903010129928589}}, "references": [{"label": "(Tokuoka et al., 2020)", "normalizedForm": "Tokuoka et al., 2020", "refKey": 71, "offsetStart": 39143, "offsetEnd": 39165}, {"label": "(Yang et al., 2020)", "normalizedForm": "Yang et al., 2020", "refKey": 82, "offsetStart": 39175, "offsetEnd": 39194}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "StarDist", "normalizedForm": "StarDist", "offsetStart": 287, "offsetEnd": 295}, "context": "Among those, only 35 provide an open-source implementation, and of these, ten can handle 3D nuclei: CDeep3M (Haberl et al., 2018), DeepSynth (Dunn et al., 2019), 3D U-Net (Cicek et al., 2016), QCANet (Tokuoka et al., 2020), Retina U-Net (Jaeger et al., 2020), NuSeT (Yang et al., 2020), StarDist (Weigert et al., 2020), nnU-Net (Isensee et al., 2021), DeepCell (Van Valen et al., 2016), and Cellpose (Stringer et al., 2021).", "mentionContextAttributes": {"used": {"value": false, "score": 0.00855785608291626}, "created": {"value": false, "score": 1.4066696166992188e-05}, "shared": {"value": false, "score": 4.5299530029296875e-06}}, "documentContextAttributes": {"used": {"value": false, "score": 0.034613192081451416}, "created": {"value": false, "score": 0.0001958012580871582}, "shared": {"value": false, "score": 4.5299530029296875e-06}}, "references": [{"label": "(Weigert et al., 2020)", "normalizedForm": "Weigert et al., 2020", "refKey": 77, "offsetStart": 29887, "offsetEnd": 29909}, {"label": "(Isensee et al., 2021", "normalizedForm": "(Isensee et al., 2021", "refKey": 36, "offsetStart": 29919, "offsetEnd": 29940}, {"label": "(Weigert et al., 2020)", "normalizedForm": "Weigert et al., 2020", "refKey": 77, "offsetStart": 29887, "offsetEnd": 29909}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "QCANet", "normalizedForm": "QCANet", "offsetStart": 303, "offsetEnd": 332}, "context": "However, in case of 3D nucleus segmentation, if previous results are inaccurate, the model must be applied to a large dataset or the data cannot be uploaded to an online server, we suggest using and configuring the offline version of DeepCell (Van Valen et al., 2016), Cellpose (Stringer et al., 2021), QCANet (Tokuoka et al., 2020) or NuSeT (Yang et al., 2020). ", "mentionContextAttributes": {"used": {"value": true, "score": 0.8480234146118164}, "created": {"value": false, "score": 3.910064697265625e-05}, "shared": {"value": false, "score": 4.5299530029296875e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.8480234146118164}, "created": {"value": false, "score": 0.00010633468627929688}, "shared": {"value": false, "score": 4.5299530029296875e-06}}, "references": [{"label": "(Yang et al., 2020)", "normalizedForm": "Yang et al., 2020", "refKey": 82, "offsetStart": 39175, "offsetEnd": 39194}]}, {"type": "software", "software-type": "software", "wikidataId": "Q364", "wikipediaExternalRef": 18545292, "lang": "en", "confidence": 0.912, "software-name": {"rawForm": "GitHub", "normalizedForm": "GitHub", "wikidataId": "Q364", "wikipediaExternalRef": 18545292, "lang": "en", "confidence": 0.912, "offsetStart": 330, "offsetEnd": 336}, "context": "For users more familiar with programming, nnU-Net (Isensee et al., 2021; https://github.com/MIC-DKFZ/ nnUNet) is recommended for 3D instance segmentation because it automatically handles the full model configuration and training, and for 2D images, implementation of most state-of-the-art methods for segmentation can be found on GitHub (https://github.com/qubvel/ ", "mentionContextAttributes": {"used": {"value": false, "score": 0.009253263473510742}, "created": {"value": false, "score": 1.239776611328125e-05}, "shared": {"value": false, "score": 0.012427449226379395}}, "documentContextAttributes": {"used": {"value": false, "score": 0.009253263473510742}, "created": {"value": false, "score": 9.691715240478516e-05}, "shared": {"value": false, "score": 0.02665609121322632}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "NuSeT", "normalizedForm": "NuSeT", "offsetStart": 336, "offsetEnd": 360}, "context": "However, in case of 3D nucleus segmentation, if previous results are inaccurate, the model must be applied to a large dataset or the data cannot be uploaded to an online server, we suggest using and configuring the offline version of DeepCell (Van Valen et al., 2016), Cellpose (Stringer et al., 2021), QCANet (Tokuoka et al., 2020) or NuSeT (Yang et al., 2020). ", "mentionContextAttributes": {"used": {"value": true, "score": 0.8480234146118164}, "created": {"value": false, "score": 3.910064697265625e-05}, "shared": {"value": false, "score": 4.5299530029296875e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.8480234146118164}, "created": {"value": false, "score": 0.00012350082397460938}, "shared": {"value": false, "score": 0.00017660856246948242}}, "references": [{"label": "(Yang et al., 2020)", "normalizedForm": "Yang et al., 2020", "refKey": 82}, {"label": "(Yang et al., 2020)", "normalizedForm": "Yang et al., 2020", "refKey": 82}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "DeepCell", "normalizedForm": "DeepCell", "offsetStart": 352, "offsetEnd": 360}, "context": "Among those, only 35 provide an open-source implementation, and of these, ten can handle 3D nuclei: CDeep3M (Haberl et al., 2018), DeepSynth (Dunn et al., 2019), 3D U-Net (Cicek et al., 2016), QCANet (Tokuoka et al., 2020), Retina U-Net (Jaeger et al., 2020), NuSeT (Yang et al., 2020), StarDist (Weigert et al., 2020), nnU-Net (Isensee et al., 2021), DeepCell (Van Valen et al., 2016), and Cellpose (Stringer et al., 2021).", "mentionContextAttributes": {"used": {"value": false, "score": 0.00855785608291626}, "created": {"value": false, "score": 1.4066696166992188e-05}, "shared": {"value": false, "score": 4.5299530029296875e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.848022997379303}, "created": {"value": true, "score": 0.6521539092063904}, "shared": {"value": true, "score": 0.5825142860412598}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Cellpose", "normalizedForm": "Cellpose", "offsetStart": 391, "offsetEnd": 422}, "context": "Among those, only 35 provide an open-source implementation, and of these, ten can handle 3D nuclei: CDeep3M (Haberl et al., 2018), DeepSynth (Dunn et al., 2019), 3D U-Net (Cicek et al., 2016), QCANet (Tokuoka et al., 2020), Retina U-Net (Jaeger et al., 2020), NuSeT (Yang et al., 2020), StarDist (Weigert et al., 2020), nnU-Net (Isensee et al., 2021), DeepCell (Van Valen et al., 2016), and Cellpose (Stringer et al., 2021). ", "mentionContextAttributes": {"used": {"value": false, "score": 0.00855785608291626}, "created": {"value": false, "score": 1.4066696166992188e-05}, "shared": {"value": false, "score": 4.5299530029296875e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.8480234146118164}, "created": {"value": false, "score": 0.005615711212158203}, "shared": {"value": true, "score": 0.9903010129928589}}, "references": [{"label": "(Tokuoka et al., 2020)", "normalizedForm": "Tokuoka et al., 2020", "refKey": 71}, {"label": "(Yang et al., 2020)", "normalizedForm": "Yang et al., 2020", "refKey": 82}]}, {"type": "software", "software-type": "software", "wikidataId": "Q15206305", "wikipediaExternalRef": 40149201, "lang": "en", "confidence": 0.6895, "software-name": {"rawForm": "Docker", "normalizedForm": "Docker", "wikidataId": "Q15206305", "wikipediaExternalRef": 40149201, "lang": "en", "confidence": 0.6895, "offsetStart": 420, "offsetEnd": 426}, "context": "To be shared, a DL model should be delivered together with: (1) a detailed explanation in the associated publication; (2) commented code comprising the complete model and its pre-and post-processing steps; (3) documentation containing at least the installation steps and the prediction procedure; (4) a DL environment, including the software and hardware requirements, with the former ideally packaged using Anaconda or Docker (Fig. 3B; Box 1); and, finally, (5) a trained model in the form of a file containing all of the model parameters after training.", "mentionContextAttributes": {"used": {"value": true, "score": 0.8394791483879089}, "created": {"value": false, "score": 3.147125244140625e-05}, "shared": {"value": false, "score": 2.384185791015625e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.8394791483879089}, "created": {"value": false, "score": 0.0004107356071472168}, "shared": {"value": false, "score": 2.384185791015625e-06}}}], "references": [{"refKey": 82, "tei": "<biblStruct xml:id=\"b82\">\n\t<analytic>\n\t\t<title level=\"a\" type=\"main\">NuSeT: A deep learning tool for reliably separating and analyzing crowded cells</title>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Linfeng</forename><surname>Yang</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Rajarshi</forename><forename type=\"middle\">P</forename><surname>Ghosh</surname></persName>\n\t\t\t<idno type=\"ORCID\">0000-0002-0020-6194</idno>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">J</forename><forename type=\"middle\">Matthew</forename><surname>Franklin</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Simon</forename><surname>Chen</surname></persName>\n\t\t\t<idno type=\"ORCID\">0000-0003-0409-5978</idno>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Chenyu</forename><surname>You</surname></persName>\n\t\t\t<idno type=\"ORCID\">0000-0001-8365-7822</idno>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Raja</forename><forename type=\"middle\">R</forename><surname>Narayan</surname></persName>\n\t\t\t<idno type=\"ORCID\">0000-0001-7938-4702</idno>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Marc</forename><forename type=\"middle\">L</forename><surname>Melcher</surname></persName>\n\t\t\t<idno type=\"ORCID\">0000-0002-7185-4383</idno>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Jan</forename><forename type=\"middle\">T</forename><surname>Liphardt</surname></persName>\n\t\t\t<idno type=\"ORCID\">0000-0003-2835-5025</idno>\n\t\t</author>\n\t\t<idno type=\"DOI\">10.1371/journal.pcbi.1008193</idno>\n\t</analytic>\n\t<monogr>\n\t\t<title level=\"j\">PLOS Computational Biology</title>\n\t\t<title level=\"j\" type=\"abbrev\">PLoS Comput Biol</title>\n\t\t<idno type=\"ISSNe\">1553-7358</idno>\n\t\t<imprint>\n\t\t\t<biblScope unit=\"volume\">16</biblScope>\n\t\t\t<biblScope unit=\"issue\">9</biblScope>\n\t\t\t<biblScope unit=\"page\">e1008193</biblScope>\n\t\t\t<date type=\"published\" when=\"2020-09-14\">2020</date>\n\t\t\t<publisher>Public Library of Science (PLoS)</publisher>\n\t\t</imprint>\n\t</monogr>\n</biblStruct>\n"}, {"refKey": 71, "tei": "<biblStruct xml:id=\"b71\">\n\t<analytic>\n\t\t<title level=\"a\" type=\"main\">3D convolutional neural networks-based segmentation to acquire quantitative criteria of the nucleus during mouse embryogenesis</title>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Yuta</forename><surname>Tokuoka</surname></persName>\n\t\t\t<idno type=\"ORCID\">0000-0001-7035-6588</idno>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Takahiro</forename><forename type=\"middle\">G</forename><surname>Yamada</surname></persName>\n\t\t\t<idno type=\"ORCID\">0000-0002-1665-1778</idno>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Daisuke</forename><surname>Mashiko</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Zenki</forename><surname>Ikeda</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Noriko</forename><forename type=\"middle\">F</forename><surname>Hiroi</surname></persName>\n\t\t\t<idno type=\"ORCID\">0000-0002-0214-373X</idno>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Tetsuya</forename><forename type=\"middle\">J</forename><surname>Kobayashi</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Kazuo</forename><surname>Yamagata</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Akira</forename><surname>Funahashi</surname></persName>\n\t\t\t<idno type=\"ORCID\">0000-0003-0605-239X</idno>\n\t\t</author>\n\t\t<idno type=\"DOI\">10.1038/s41540-020-00152-8</idno>\n\t</analytic>\n\t<monogr>\n\t\t<title level=\"j\">npj Systems Biology and Applications</title>\n\t\t<title level=\"j\" type=\"abbrev\">npj Syst Biol Appl</title>\n\t\t<idno type=\"ISSNe\">2056-7189</idno>\n\t\t<imprint>\n\t\t\t<biblScope unit=\"volume\">6</biblScope>\n\t\t\t<biblScope unit=\"issue\">1</biblScope>\n\t\t\t<biblScope unit=\"page\">12</biblScope>\n\t\t\t<date type=\"published\" when=\"2020-10-20\">2020</date>\n\t\t\t<publisher>Springer Science and Business Media LLC</publisher>\n\t\t</imprint>\n\t</monogr>\n</biblStruct>\n"}, {"refKey": 60, "tei": "<biblStruct xml:id=\"b60\">\n\t<analytic>\n\t\t<title level=\"a\" type=\"main\">Fiji: an open-source platform for biological-image analysis</title>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Johannes</forename><surname>Schindelin</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Ignacio</forename><surname>Arganda-Carreras</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Erwin</forename><surname>Frise</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Verena</forename><surname>Kaynig</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Mark</forename><surname>Longair</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Tobias</forename><surname>Pietzsch</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Stephan</forename><surname>Preibisch</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Curtis</forename><surname>Rueden</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Stephan</forename><surname>Saalfeld</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Benjamin</forename><surname>Schmid</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Jean-Yves</forename><surname>Tinevez</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Daniel</forename><forename type=\"middle\">James</forename><surname>White</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Volker</forename><surname>Hartenstein</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Kevin</forename><surname>Eliceiri</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Pavel</forename><surname>Tomancak</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Albert</forename><surname>Cardona</surname></persName>\n\t\t</author>\n\t\t<idno type=\"DOI\">10.1038/nmeth.2019</idno>\n\t</analytic>\n\t<monogr>\n\t\t<title level=\"j\">Nature Methods</title>\n\t\t<title level=\"j\" type=\"abbrev\">Nat Methods</title>\n\t\t<idno type=\"ISSN\">1548-7091</idno>\n\t\t<idno type=\"ISSNe\">1548-7105</idno>\n\t\t<imprint>\n\t\t\t<biblScope unit=\"volume\">9</biblScope>\n\t\t\t<biblScope unit=\"issue\">7</biblScope>\n\t\t\t<biblScope unit=\"page\" from=\"676\" to=\"682\" />\n\t\t\t<date type=\"published\" when=\"2012-06-28\">2012</date>\n\t\t\t<publisher>Springer Science and Business Media LLC</publisher>\n\t\t</imprint>\n\t</monogr>\n</biblStruct>\n"}, {"refKey": 70, "tei": "<biblStruct xml:id=\"b70\">\n\t<analytic>\n\t\t<title level=\"a\" type=\"main\">Deep Networks with Shape Priors for Nucleus Detection</title>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Mohammad</forename><surname>Tofighi</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Tiantong</forename><surname>Guo</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Jairam</forename><forename type=\"middle\">K P</forename><surname>Vanamala</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Vishal</forename><surname>Monga</surname></persName>\n\t\t</author>\n\t\t<idno type=\"DOI\">10.1109/icip.2018.8451797</idno>\n\t</analytic>\n\t<monogr>\n\t\t<title level=\"m\">2018 25th IEEE International Conference on Image Processing (ICIP)</title>\n\t\t<imprint>\n\t\t\t<publisher>IEEE</publisher>\n\t\t\t<date type=\"published\" when=\"2018-10\">2018</date>\n\t\t\t<biblScope unit=\"page\">723</biblScope>\n\t\t</imprint>\n\t</monogr>\n</biblStruct>\n"}, {"refKey": 81, "tei": "<biblStruct xml:id=\"b81\">\n\t<analytic>\n\t\t<title level=\"a\" type=\"main\">Pixel-to-Pixel Learning With Weak Supervision for Single-Stage Nucleus Recognition in Ki67 Images</title>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Fuyong</forename><surname>Xing</surname></persName>\n\t\t\t<idno type=\"ORCID\">0000-0003-0982-8675</idno>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Toby</forename><forename type=\"middle\">C</forename><surname>Cornish</surname></persName>\n\t\t\t<idno type=\"ORCID\">0000-0002-1902-2109</idno>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Tell</forename><surname>Bennett</surname></persName>\n\t\t\t<idno type=\"ORCID\">0000-0003-1483-4236</idno>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Debashis</forename><surname>Ghosh</surname></persName>\n\t\t\t<idno type=\"ORCID\">0000-0001-6618-1316</idno>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Lin</forename><surname>Yang</surname></persName>\n\t\t</author>\n\t\t<idno type=\"DOI\">10.1109/tbme.2019.2900378</idno>\n\t</analytic>\n\t<monogr>\n\t\t<title level=\"j\">IEEE Transactions on Biomedical Engineering</title>\n\t\t<title level=\"j\" type=\"abbrev\">IEEE Trans. Biomed. Eng.</title>\n\t\t<idno type=\"ISSN\">0018-9294</idno>\n\t\t<idno type=\"ISSNe\">1558-2531</idno>\n\t\t<imprint>\n\t\t\t<biblScope unit=\"volume\">66</biblScope>\n\t\t\t<biblScope unit=\"issue\">11</biblScope>\n\t\t\t<biblScope unit=\"page\" from=\"3088\" to=\"3097\" />\n\t\t\t<date type=\"published\" when=\"2019-11\">2019</date>\n\t\t\t<publisher>Institute of Electrical and Electronics Engineers (IEEE)</publisher>\n\t\t</imprint>\n\t</monogr>\n</biblStruct>\n"}, {"refKey": 75, "tei": "<biblStruct xml:id=\"b75\">\n\t<analytic>\n\t\t<title level=\"a\" type=\"main\">Democratising deep learning for microscopy with ZeroCostDL4Mic</title>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Lucas</forename><surname>Von Chamier</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Romain</forename><forename type=\"middle\">F</forename><surname>Laine</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Johanna</forename><surname>Jukkala</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Christoph</forename><surname>Spahn</surname></persName>\n\t\t\t<idno type=\"ORCID\">0000-0001-9886-2263</idno>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Daniel</forename><surname>Krentzel</surname></persName>\n\t\t\t<idno type=\"ORCID\">0000-0002-6234-7259</idno>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Elias</forename><surname>Nehme</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Martina</forename><surname>Lerche</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Sara</forename><surname>Hern\u00e1ndez-P\u00e9rez</surname></persName>\n\t\t\t<idno type=\"ORCID\">0000-0002-0227-1045</idno>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Pieta</forename><forename type=\"middle\">K</forename><surname>Mattila</surname></persName>\n\t\t\t<idno type=\"ORCID\">0000-0003-2805-0686</idno>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Eleni</forename><surname>Karinou</surname></persName>\n\t\t\t<idno type=\"ORCID\">0000-0002-1099-4964</idno>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">S\u00e9amus</forename><surname>Holden</surname></persName>\n\t\t\t<idno type=\"ORCID\">0000-0002-7169-907X</idno>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Ahmet</forename><forename type=\"middle\">Can</forename><surname>Solak</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Alexander</forename><surname>Krull</surname></persName>\n\t\t\t<idno type=\"ORCID\">0000-0002-7778-7169</idno>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Tim-Oliver</forename><surname>Buchholz</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Martin</forename><forename type=\"middle\">L</forename><surname>Jones</surname></persName>\n\t\t\t<idno type=\"ORCID\">0000-0003-0994-5652</idno>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Lo\u00efc</forename><forename type=\"middle\">A</forename><surname>Royer</surname></persName>\n\t\t\t<idno type=\"ORCID\">0000-0002-9991-9724</idno>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Christophe</forename><surname>Leterrier</surname></persName>\n\t\t\t<idno type=\"ORCID\">0000-0002-2957-2032</idno>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Yoav</forename><surname>Shechtman</surname></persName>\n\t\t\t<idno type=\"ORCID\">0000-0001-8498-5203</idno>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Florian</forename><surname>Jug</surname></persName>\n\t\t\t<idno type=\"ORCID\">0000-0002-8499-5812</idno>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Mike</forename><surname>Heilemann</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Guillaume</forename><surname>Jacquemet</surname></persName>\n\t\t\t<idno type=\"ORCID\">0000-0002-9286-920X</idno>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Ricardo</forename><surname>Henriques</surname></persName>\n\t\t\t<idno type=\"ORCID\">0000-0002-2043-5234</idno>\n\t\t</author>\n\t\t<idno type=\"DOI\">10.1038/s41467-021-22518-0</idno>\n\t</analytic>\n\t<monogr>\n\t\t<title level=\"j\">Nature Communications</title>\n\t\t<title level=\"j\" type=\"abbrev\">Nat Commun</title>\n\t\t<idno type=\"ISSNe\">2041-1723</idno>\n\t\t<imprint>\n\t\t\t<biblScope unit=\"volume\">12</biblScope>\n\t\t\t<biblScope unit=\"issue\">1</biblScope>\n\t\t\t<biblScope unit=\"page\">2276</biblScope>\n\t\t\t<date type=\"published\" when=\"2021-04-15\">2021</date>\n\t\t\t<publisher>Springer Science and Business Media LLC</publisher>\n\t\t</imprint>\n\t</monogr>\n</biblStruct>\n"}, {"refKey": 80, "tei": "<biblStruct xml:id=\"b80\">\n\t<analytic>\n\t\t<title level=\"a\" type=\"main\">The medical imaging interaction toolkit (MITK): a toolkit facilitating the creation of interactive software by extending VTK and ITK</title>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Ivo</forename><surname>Wolf</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Marcus</forename><surname>Vetter</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Ingmar</forename><surname>Wegner</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Marco</forename><surname>Nolden</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Thomas</forename><surname>Bottger</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Mark</forename><surname>Hastenteufel</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Max</forename><surname>Schobinger</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Tobias</forename><surname>Kunert</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Hans-Peter</forename><surname>Meinzer</surname></persName>\n\t\t</author>\n\t\t<idno type=\"DOI\">10.1117/12.535112</idno>\n\t</analytic>\n\t<monogr>\n\t\t<title level=\"m\">SPIE Proceedings</title>\n\t\t<imprint>\n\t\t\t<publisher>SPIE</publisher>\n\t\t\t<date type=\"published\" when=\"2004-05-05\">2004. 2004</date>\n\t\t\t<biblScope unit=\"volume\">5367</biblScope>\n\t\t\t<biblScope unit=\"page\">16</biblScope>\n\t\t</imprint>\n\t</monogr>\n</biblStruct>\n"}, {"refKey": 0, "tei": "<biblStruct xml:id=\"b0\">\n\t<analytic>\n\t\t<title level=\"a\" type=\"main\">Deep learning \u00ad\u2013 promises for 3D nuclear imaging: a guide for biologists</title>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Guillaume</forename><surname>Mougeot</surname></persName>\n\t\t\t<idno type=\"ORCID\">0000-0003-3576-7300</idno>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Tristan</forename><surname>Dubos</surname></persName>\n\t\t\t<idno type=\"ORCID\">0000-0002-4265-2379</idno>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Fr\u00e9d\u00e9ric</forename><surname>Chausse</surname></persName>\n\t\t\t<idno type=\"ORCID\">0000-0001-7794-1587</idno>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Emilie</forename><surname>P\u00e9ry</surname></persName>\n\t\t\t<idno type=\"ORCID\">0000-0001-6198-9973</idno>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Katja</forename><surname>Graumann</surname></persName>\n\t\t\t<idno type=\"ORCID\">0000-0002-1529-8255</idno>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Christophe</forename><surname>Tatout</surname></persName>\n\t\t\t<idno type=\"ORCID\">0000-0001-5215-2338</idno>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">David</forename><forename type=\"middle\">E</forename><surname>Evans</surname></persName>\n\t\t\t<idno type=\"ORCID\">0000-0001-6248-1899</idno>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Sophie</forename><surname>Desset</surname></persName>\n\t\t\t<idno type=\"ORCID\">0000-0002-4897-4977</idno>\n\t\t</author>\n\t\t<idno type=\"DOI\">10.1242/jcs.258986</idno>\n\t\t<idno>57E98B44174D3B3AB43989BE54DA8406</idno>\n\t</analytic>\n\t<monogr>\n\t\t<title level=\"j\">Journal of Cell Science</title>\n\t\t<idno type=\"ISSN\">0021-9533</idno>\n\t\t<idno type=\"ISSNe\">1477-9137</idno>\n\t\t<imprint>\n\t\t\t<biblScope unit=\"volume\">135</biblScope>\n\t\t\t<biblScope unit=\"issue\">7</biblScope>\n\t\t\t<date type=\"published\" when=\"2022-04-01\" />\n\t\t\t<publisher>The Company of Biologists</publisher>\n\t\t</imprint>\n\t</monogr>\n</biblStruct>\n"}, {"refKey": 20, "tei": "<biblStruct xml:id=\"b20\">\n\t<analytic>\n\t\t<title level=\"a\" type=\"main\">The VIA Annotation Software for Images, Audio and Video</title>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Abhishek</forename><surname>Dutta</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Andrew</forename><surname>Zisserman</surname></persName>\n\t\t</author>\n\t\t<idno type=\"DOI\">10.1145/3343031.3350535</idno>\n\t</analytic>\n\t<monogr>\n\t\t<title level=\"m\">Proceedings of the 27th ACM International Conference on Multimedia</title>\n\t\t<meeting>the 27th ACM International Conference on Multimedia</meeting>\n\t\t<imprint>\n\t\t\t<publisher>ACM</publisher>\n\t\t\t<date type=\"published\" when=\"2019-10-15\">2019</date>\n\t\t\t<biblScope unit=\"page\">2279</biblScope>\n\t\t</imprint>\n\t</monogr>\n</biblStruct>\n"}, {"refKey": 77, "tei": "<biblStruct xml:id=\"b77\">\n\t<analytic>\n\t\t<title level=\"a\" type=\"main\">Star-convex Polyhedra for 3D Object Detection and Segmentation in Microscopy</title>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Martin</forename><surname>Weigert</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Uwe</forename><surname>Schmidt</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Robert</forename><surname>Haase</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Ko</forename><surname>Sugawara</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Gene</forename><surname>Myers</surname></persName>\n\t\t</author>\n\t\t<idno type=\"DOI\">10.1109/wacv45572.2020.9093435</idno>\n\t</analytic>\n\t<monogr>\n\t\t<title level=\"m\">2020 IEEE Winter Conference on Applications of Computer Vision (WACV)</title>\n\t\t<imprint>\n\t\t\t<publisher>IEEE</publisher>\n\t\t\t<date type=\"published\" when=\"2020-03\">2020</date>\n\t\t\t<biblScope unit=\"volume\">2020</biblScope>\n\t\t\t<biblScope unit=\"page\">3662</biblScope>\n\t\t</imprint>\n\t</monogr>\n</biblStruct>\n"}, {"refKey": 36, "tei": "<biblStruct xml:id=\"b36\">\n\t<analytic>\n\t\t<title level=\"a\" type=\"main\">nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation</title>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Fabian</forename><surname>Isensee</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Paul</forename><forename type=\"middle\">F</forename><surname>Jaeger</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Simon</forename><forename type=\"middle\">A A</forename><surname>Kohl</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Jens</forename><surname>Petersen</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Klaus</forename><forename type=\"middle\">H</forename><surname>Maier-Hein</surname></persName>\n\t\t\t<idno type=\"ORCID\">0000-0002-6626-2463</idno>\n\t\t</author>\n\t\t<idno type=\"DOI\">10.1038/s41592-020-01008-z</idno>\n\t</analytic>\n\t<monogr>\n\t\t<title level=\"j\">Nature Methods</title>\n\t\t<title level=\"j\" type=\"abbrev\">Nat Methods</title>\n\t\t<idno type=\"ISSN\">1548-7091</idno>\n\t\t<idno type=\"ISSNe\">1548-7105</idno>\n\t\t<imprint>\n\t\t\t<biblScope unit=\"volume\">18</biblScope>\n\t\t\t<biblScope unit=\"issue\">2</biblScope>\n\t\t\t<biblScope unit=\"page\" from=\"203\" to=\"211\" />\n\t\t\t<date type=\"published\" when=\"2020-12-07\">2021</date>\n\t\t\t<publisher>Springer Science and Business Media LLC</publisher>\n\t\t</imprint>\n\t</monogr>\n</biblStruct>\n"}], "runtime": 51535, "id": "64761bca781a30f6de5d194791682d70ddf4aad7", "metadata": {"id": "64761bca781a30f6de5d194791682d70ddf4aad7"}, "original_file_path": "../../datalake/Samuel/SV22/SV22_xml/hal-03977343.grobid.tei.xml", "file_name": "hal-03977343.grobid.tei.xml"}