{"application": "software-mentions", "version": "0.8.0", "date": "2024-03-21T09:57+0000", "md5": "C548EF4A1E995DD1D46BA91C62EB00A7", "mentions": [{"type": "software", "software-type": "software", "software-name": {"rawForm": "Umap", "normalizedForm": "Umap", "offsetStart": 4, "offsetEnd": 8}, "context": "The Umap algorithm was applied to our case. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999549388885498}, "created": {"value": false, "score": 0.3184605836868286}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999549388885498}, "created": {"value": false, "score": 0.3184605836868286}, "shared": {"value": false, "score": 3.5762786865234375e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "t-SNE", "normalizedForm": "t-SNE", "offsetStart": 15, "offsetEnd": 20}, "context": "Algorithm like t-SNE and Umap [22] are used to project neural networks activations(or feature maps) into 2-D or 3-D data that can be visualized. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.008169114589691162}, "created": {"value": false, "score": 9.5367431640625e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.008169114589691162}, "created": {"value": false, "score": 9.5367431640625e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "references": [{"label": "[22]", "normalizedForm": "[22]", "refKey": 22, "offsetStart": 18451, "offsetEnd": 18455}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Umap", "normalizedForm": "Umap", "offsetStart": 25, "offsetEnd": 34}, "context": "Algorithm like t-SNE and Umap [22] are used to project neural networks activations(or feature maps) into 2-D or 3-D data that can be visualized. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.008169114589691162}, "created": {"value": false, "score": 9.5367431640625e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999549388885498}, "created": {"value": false, "score": 0.3184605836868286}, "shared": {"value": false, "score": 3.5762786865234375e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "GPGPU", "normalizedForm": "GPGPU", "offsetStart": 42, "offsetEnd": 47}, "context": "Classical methods can be executed without GPGPU (they still need careful optimization) but might need more development time. ", "mentionContextAttributes": {"used": {"value": false, "score": 6.949901580810547e-05}, "created": {"value": false, "score": 0.00026410818099975586}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.0001647472381591797}, "created": {"value": false, "score": 0.0004690885543823242}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "GPGPU", "normalizedForm": "GPGPU", "offsetStart": 65, "offsetEnd": 70}, "context": "Deep learning for images needs at least one powerful, expensive, GPGPU. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0001647472381591797}, "created": {"value": false, "score": 0.0004690885543823242}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.0001647472381591797}, "created": {"value": false, "score": 0.0004690885543823242}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Keras Applications API", "normalizedForm": "Keras Applications API", "offsetStart": 65, "offsetEnd": 87}, "context": "The pre-trained MobileNet-V2 was automatically downloaded by the Keras Applications API. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9893423318862915}, "created": {"value": false, "score": 0.0001984238624572754}, "shared": {"value": false, "score": 0.12094348669052124}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9893423318862915}, "created": {"value": false, "score": 0.0001984238624572754}, "shared": {"value": false, "score": 0.12094348669052124}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LabelMe", "normalizedForm": "LabelMe", "offsetStart": 82, "offsetEnd": 89}, "context": "Each visible crate of the weighted pallet is labeled for binary segmentation with LabelMe polygonal mask [15]. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9362749457359314}, "created": {"value": false, "score": 1.0967254638671875e-05}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9362749457359314}, "created": {"value": false, "score": 1.0967254638671875e-05}, "shared": {"value": false, "score": 3.5762786865234375e-07}}}], "references": [{"refKey": 22, "tei": "<biblStruct xml:id=\"b22\">\n\t<monogr>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">L</forename><surname>Mcinnes</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">J</forename><surname>Healy</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">J</forename><surname>Melville</surname></persName>\n\t\t</author>\n\t\t<title level=\"m\">UMAP: Uniform Manifold Approximation and Projection for Dimension Reduction</title>\n\t\t<imprint>\n\t\t\t<date>2018</date>\n\t\t</imprint>\n\t</monogr>\n</biblStruct>\n"}], "runtime": 2694, "id": "042e196eae49b4da5687d6c0a2f7841baabdc4fe", "metadata": {"id": "042e196eae49b4da5687d6c0a2f7841baabdc4fe"}, "original_file_path": "../../datalake/Samuel/SV22/SV22_xml/hal-03647740.grobid.tei.xml", "file_name": "hal-03647740.grobid.tei.xml"}