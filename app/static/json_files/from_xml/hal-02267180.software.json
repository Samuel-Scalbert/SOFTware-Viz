{"application": "software-mentions", "version": "0.8.0", "date": "2024-04-12T16:19+0000", "md5": "5DA3D60B96A50EF0251AD7DB585185B9", "mentions": [{"type": "software", "software-type": "software", "software-name": {"rawForm": "BatchInterval", "normalizedForm": "BatchInterval", "offsetStart": 15, "offsetEnd": 28}, "context": "(b) shows that BatchInterval can exhibit opposite trends: a larger value reduces latency when the input rate is low, but increases latency when the input rate is high.", "mentionContextAttributes": {"used": {"value": false, "score": 0.006045699119567871}, "created": {"value": false, "score": 2.5212764739990234e-05}, "shared": {"value": false, "score": 7.748603820800781e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.1667565107345581}, "created": {"value": false, "score": 2.5212764739990234e-05}, "shared": {"value": false, "score": 1.2516975402832031e-06}}}, {"type": "software", "software-type": "software", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.5539, "software-name": {"rawForm": "Spark", "normalizedForm": "Spark", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.5539, "offsetStart": 23, "offsetEnd": 28}, "context": "In case of the popular Spark platform, these runtime parameters include parallelism (for reduce-style transformations), Rdd compression (boolean), Memory per executor, Memory fraction (of heap space), Batch interval (the size of each minibatch) and Block interval (the size of data handled by a map task) in the streaming setting, to name a few.", "mentionContextAttributes": {"used": {"value": false, "score": 0.011781454086303711}, "created": {"value": false, "score": 2.0325183868408203e-05}, "shared": {"value": false, "score": 8.940696716308594e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.024839818477630615}, "created": {"value": true, "score": 0.9998239874839783}, "shared": {"value": false, "score": 8.940696716308594e-07}}}, {"type": "software", "software-type": "software", "wikidataId": "Q4778914", "wikipediaExternalRef": 30248516, "lang": "en", "confidence": 0.3167, "software-name": {"rawForm": "HiveQL", "normalizedForm": "HiveQL", "wikidataId": "Q4778914", "wikipediaExternalRef": 30248516, "lang": "en", "confidence": 0.3167, "offsetStart": 39, "offsetEnd": 45}, "context": "A recent study [6] shows that even for HiveQL queries, expert engineers were often unable to make the correct choice between two cluster options, and their estimated runtime ranged from 20x underestimation to 5x over-estimation. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.991497814655304}, "created": {"value": false, "score": 1.1861324310302734e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.991497814655304}, "created": {"value": false, "score": 1.1861324310302734e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "BatchInterval", "normalizedForm": "BatchInterval", "offsetStart": 43, "offsetEnd": 56}, "context": "For example, Fig. 2(a) shows the effect of BatchInterval in relation to InputRate, where a smaller value of BatchInterval is always preferred, while Fig. 2(b) shows that BatchInterval can exhibit opposite trends: a larger value reduces latency when the input rate is low, but increases latency when the input rate is high.", "mentionContextAttributes": {"used": {"value": false, "score": 0.1667565107345581}, "created": {"value": false, "score": 8.285045623779297e-06}, "shared": {"value": false, "score": 1.2516975402832031e-06}}, "documentContextAttributes": {"used": {"value": false, "score": 0.1667565107345581}, "created": {"value": false, "score": 2.5212764739990234e-05}, "shared": {"value": false, "score": 1.2516975402832031e-06}}}, {"type": "software", "software-type": "software", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.7879, "software-name": {"rawForm": "Apache Spark", "normalizedForm": "Apache Spark", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.7879, "offsetStart": 44, "offsetEnd": 56}, "context": "Our demo showcases UDAO developed on top of Apache Spark, such that the user can understand i) the difficulty of manual parameter tuning, and the effect of these parameters on user objectives as indicated by the automatically learned models; ii) the tradeoffs between user objectives, and how a system recommended configuration explores these tradeoffs; iii) end-to-end benefits that UDAO can provide over manual performance tuning; iv) comparative analysis between our techniques and alternative techniques. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.007953166961669922}, "created": {"value": false, "score": 0.10683482885360718}, "shared": {"value": false, "score": 1.8477439880371094e-06}}, "documentContextAttributes": {"used": {"value": false, "score": 0.007953166961669922}, "created": {"value": false, "score": 0.10683482885360718}, "shared": {"value": false, "score": 1.8477439880371094e-06}}}, {"type": "software", "software-type": "software", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.5539, "software-name": {"rawForm": "Spark", "normalizedForm": "Spark", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.5539, "offsetStart": 84, "offsetEnd": 89}, "context": "We model an analytic task as a dataflow program as commonly used in systems such as Spark and Flink. ", "mentionContextAttributes": {"used": {"value": false, "score": 5.2034854888916016e-05}, "created": {"value": true, "score": 0.993679404258728}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.024839818477630615}, "created": {"value": true, "score": 0.9998239874839783}, "shared": {"value": false, "score": 8.940696716308594e-07}}}, {"type": "software", "software-type": "software", "wikidataId": "Q3073740", "wikipediaExternalRef": 5999274, "lang": "en", "confidence": 0.4462, "software-name": {"rawForm": "Flink", "normalizedForm": "Flink", "wikidataId": "Q3073740", "wikipediaExternalRef": 5999274, "lang": "en", "confidence": 0.4462, "offsetStart": 94, "offsetEnd": 99}, "context": "We model an analytic task as a dataflow program as commonly used in systems such as Spark and Flink. ", "mentionContextAttributes": {"used": {"value": false, "score": 5.2034854888916016e-05}, "created": {"value": true, "score": 0.993679404258728}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 5.2034854888916016e-05}, "created": {"value": true, "score": 0.993679404258728}, "shared": {"value": false, "score": 2.980232238769531e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "BatchInterval", "normalizedForm": "BatchInterval", "offsetStart": 108, "offsetEnd": 121}, "context": "For example, Fig. 2(a) shows the effect of BatchInterval in relation to InputRate, where a smaller value of BatchInterval is always preferred, while Fig. 2(b) shows that BatchInterval can exhibit opposite trends: a larger value reduces latency when the input rate is low, but increases latency when the input rate is high.", "mentionContextAttributes": {"used": {"value": false, "score": 0.1667565107345581}, "created": {"value": false, "score": 8.285045623779297e-06}, "shared": {"value": false, "score": 1.2516975402832031e-06}}, "documentContextAttributes": {"used": {"value": false, "score": 0.1667565107345581}, "created": {"value": false, "score": 2.5212764739990234e-05}, "shared": {"value": false, "score": 1.2516975402832031e-06}}}, {"type": "software", "software-type": "software", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.5539, "software-name": {"rawForm": "Spark", "normalizedForm": "Spark", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.5539, "offsetStart": 114, "offsetEnd": 119}, "context": "In this module, our system provides the original program, the execution plan, and all statistics available on the Spark UI for the user to consider.", "mentionContextAttributes": {"used": {"value": false, "score": 0.001202225685119629}, "created": {"value": true, "score": 0.9781227707862854}, "shared": {"value": false, "score": 7.152557373046875e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.024839818477630615}, "created": {"value": true, "score": 0.9998239874839783}, "shared": {"value": false, "score": 8.940696716308594e-07}}}, {"type": "software", "software-type": "software", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.5539, "software-name": {"rawForm": "Spark", "normalizedForm": "Spark", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.5539, "offsetStart": 203, "offsetEnd": 208}, "context": "Our work uses a mix of Bayesian Optimization, a sequential optimization technique for exploring an unknown space, and heuristics based sampling, leveraging domain knowledge of configurations (e.g., from Spark best practices) to overcome the cold start problem.", "mentionContextAttributes": {"used": {"value": false, "score": 6.031990051269531e-05}, "created": {"value": true, "score": 0.9998239874839783}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.024839818477630615}, "created": {"value": true, "score": 0.9998239874839783}, "shared": {"value": false, "score": 8.940696716308594e-07}}}, {"type": "software", "software-type": "software", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.5539, "software-name": {"rawForm": "Spark", "normalizedForm": "Spark", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.5539, "offsetStart": 262, "offsetEnd": 267}, "context": "A. Trace collection: This phase collects traces, collectively called observations, during job execution (step 4), which include: (i) user objectives such as throughput, latency, resource utilization, and computing cost; (ii) applicationlevel metrics, e.g., from Spark in our prototype, collecting the records read and written, bytes read and written, bytes spilled to disk, fetch wait time, etc.; (iii) OS-level metrics such as CPU, IO, and network usage.", "mentionContextAttributes": {"used": {"value": false, "score": 0.024839818477630615}, "created": {"value": false, "score": 5.4836273193359375e-06}, "shared": {"value": false, "score": 5.960464477539062e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.024839818477630615}, "created": {"value": true, "score": 0.9998239874839783}, "shared": {"value": false, "score": 8.940696716308594e-07}}}], "references": [], "runtime": 54173, "id": "712972ff643f0d7131aa02b1efcf8a3d39208ff7", "metadata": {"id": "712972ff643f0d7131aa02b1efcf8a3d39208ff7"}, "original_file_path": "../../datalake/Samuel/SOFTware-Sync/data/xml_files/hal-02267180.grobid.tei.xml", "file_name": "hal-02267180.grobid.tei.xml"}