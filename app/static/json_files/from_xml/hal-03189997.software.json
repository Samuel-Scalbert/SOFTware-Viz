{"application": "software-mentions", "version": "0.8.0", "date": "2024-04-15T07:31+0000", "md5": "8BAC1DC4B2CC02F58AC0186EA43521FA", "mentions": [{"type": "software", "software-type": "software", "software-name": {"rawForm": "samkNN", "normalizedForm": "samkNN", "offsetStart": 12, "offsetEnd": 18}, "context": "In fact, CS-samkNN maintains models for current and past concepts which makes it memory inefficient.", "mentionContextAttributes": {"used": {"value": false, "score": 6.335973739624023e-05}, "created": {"value": false, "score": 0.0034468770027160645}, "shared": {"value": false, "score": 5.364418029785156e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.27074134349823}, "created": {"value": false, "score": 0.0034468770027160645}, "shared": {"value": false, "score": 8.940696716308594e-07}}, "references": [{"label": "[28]", "normalizedForm": "[28]", "refKey": 28}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "samkNN", "normalizedForm": "samkNN", "offsetStart": 22, "offsetEnd": 28}, "context": "On the other hand, CS-samkNN, HT-kNN and PCA-kNN have different behaviors, clearly illustrated in Figure 3a; this results deduce that, in practice, it may be hard to fix a proper space size.", "mentionContextAttributes": {"used": {"value": false, "score": 0.005002200603485107}, "created": {"value": false, "score": 1.722574234008789e-05}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.27074134349823}, "created": {"value": false, "score": 0.0034468770027160645}, "shared": {"value": false, "score": 8.940696716308594e-07}}, "references": [{"label": "[28]", "normalizedForm": "[28]", "refKey": 28}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "samkNN", "normalizedForm": "samkNN", "offsetStart": 43, "offsetEnd": 49}, "context": "CS-kNN is moderately less accurate than CS-samkNN for some datasets containing drifts, because the latter deals with different types of concept drift which makes it stronger facing changes in data distributions.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00012189149856567383}, "created": {"value": false, "score": 1.5795230865478516e-05}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.27074134349823}, "created": {"value": false, "score": 0.0034468770027160645}, "shared": {"value": false, "score": 8.940696716308594e-07}}, "references": [{"label": "[28]", "normalizedForm": "[28]", "refKey": 28}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "samkNN", "normalizedForm": "samkNN", "offsetStart": 123, "offsetEnd": 129}, "context": "Therefore, some of them have been extended to handle evolving data streams [6,3], among others, Self-Adjusting Memory kNN (samkNN) [28] which uses a dual-memory model to capture the drift in data streams. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0002110004425048828}, "created": {"value": false, "score": 0.002940654754638672}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.27074134349823}, "created": {"value": false, "score": 0.0034468770027160645}, "shared": {"value": false, "score": 8.940696716308594e-07}}, "references": [{"label": "[28]", "normalizedForm": "[28]", "refKey": 28, "offsetStart": 8247, "offsetEnd": 8251}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "samkNN", "normalizedForm": "samkNN", "offsetStart": 123, "offsetEnd": 129}, "context": "Our proposed CS-kNN has more accurate results (Table 4) than HT-kNN for all datasets and it is slightly outperformed by CS-samkNN, the standard kNN (without projection) and PCA-kNN; this quite a   natural result since kNN processes the whole data stream and PCA-kNN formally tries to find a lower-dimensional space under which the sum of square distances -representing the error, between the original data and its projection -is minimized.", "mentionContextAttributes": {"used": {"value": false, "score": 0.015827298164367676}, "created": {"value": false, "score": 1.4722347259521484e-05}, "shared": {"value": false, "score": 8.940696716308594e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.27074134349823}, "created": {"value": false, "score": 0.0034468770027160645}, "shared": {"value": false, "score": 8.940696716308594e-07}}, "references": [{"label": "[28]", "normalizedForm": "[28]", "refKey": 28}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "samkNN", "normalizedForm": "samkNN", "offsetStart": 126, "offsetEnd": 132}, "context": "For instance, with Tweet2 and Enron in Figures 3c and3f respectively, we observe large gains compared to kNN, PCA-kNN, and CS-samkNN, albeit our proposal has the same memory usage as HT-kNN because both do not rely on data.", "mentionContextAttributes": {"used": {"value": false, "score": 0.017754077911376953}, "created": {"value": false, "score": 9.232759475708008e-05}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.27074134349823}, "created": {"value": false, "score": 0.0034468770027160645}, "shared": {"value": false, "score": 8.940696716308594e-07}}, "references": [{"label": "[28]", "normalizedForm": "[28]", "refKey": 28}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "samkNN", "normalizedForm": "samkNN", "offsetStart": 140, "offsetEnd": 146}, "context": "We compare the performance of our proposed classifier, CS-kNN, to commonly-used techniques in the literature; self-adjusting memory kNN (CS-samkNN) with CS, kNN using hashing trick (HT-kNN), principal component analysis (PCA-kNN), and the standard kNN without projection as well (using the entire data).", "mentionContextAttributes": {"used": {"value": false, "score": 0.27074134349823}, "created": {"value": false, "score": 2.6166439056396484e-05}, "shared": {"value": false, "score": 4.172325134277344e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.27074134349823}, "created": {"value": false, "score": 0.0034468770027160645}, "shared": {"value": false, "score": 8.940696716308594e-07}}, "references": [{"label": "[28]", "normalizedForm": "[28]", "refKey": 28}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "samkNN", "normalizedForm": "samkNN", "offsetStart": 184, "offsetEnd": 190}, "context": "To assess the benefits in terms of computational resources -where small values are desirable -Tables 5 and6 point out the improvements of CS-kNN in terms of memory and time against CS-samkNN, PCA-kNN, and kNN which are significant enough to justify relatively minor losses in accuracy.", "mentionContextAttributes": {"used": {"value": false, "score": 0.170943021774292}, "created": {"value": false, "score": 2.3245811462402344e-06}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.27074134349823}, "created": {"value": false, "score": 0.0034468770027160645}, "shared": {"value": false, "score": 8.940696716308594e-07}}, "references": [{"label": "[28]", "normalizedForm": "[28]", "refKey": 28}]}], "references": [{"refKey": 28, "tei": "<biblStruct xml:id=\"b28\">\n\t<analytic>\n\t\t<title level=\"a\" type=\"main\">KNN Classifier with Self Adjusting Memory for Heterogeneous Concept Drift</title>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Viktor</forename><surname>Losing</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Barbara</forename><surname>Hammer</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Heiko</forename><surname>Wersing</surname></persName>\n\t\t</author>\n\t\t<idno type=\"DOI\">10.1109/icdm.2016.0040</idno>\n\t</analytic>\n\t<monogr>\n\t\t<title level=\"m\">2016 IEEE 16th International Conference on Data Mining (ICDM)</title>\n\t\t<imprint>\n\t\t\t<publisher>IEEE</publisher>\n\t\t\t<date type=\"published\" when=\"2016-12\">2016</date>\n\t\t\t<biblScope unit=\"page\">300</biblScope>\n\t\t</imprint>\n\t</monogr>\n</biblStruct>\n"}], "runtime": 81745, "id": "54aed955fc0077d20e369676ca451ea345c4615b", "metadata": {"id": "54aed955fc0077d20e369676ca451ea345c4615b"}, "original_file_path": "../../datalake/Samuel/SOFTware-Sync/data/xml_not_sofctied/log_xml/hal-03189997.grobid.tei.xml", "file_name": "hal-03189997.grobid.tei.xml"}