{"application": "software-mentions", "version": "0.8.0", "date": "2024-04-15T07:14+0000", "md5": "07F992F87E5853A83ED18C6887E49333", "mentions": [{"type": "software", "software-type": "software", "wikidataId": "Q47607", "wikipediaExternalRef": 29004, "lang": "en", "confidence": 0.4606, "software-name": {"rawForm": "SQL", "normalizedForm": "SQL", "wikidataId": "Q47607", "wikipediaExternalRef": 29004, "lang": "en", "confidence": 0.4606, "offsetStart": 0, "offsetEnd": 3}, "context": "SQL-like query or vertex-centric graphic abstraction; then, the specification is transformed into an internal representation in the form of a data-flow DAG; and finally, code is generated to execute the workflow against the target platform.", "mentionContextAttributes": {"used": {"value": false, "score": 0.03070169687271118}, "created": {"value": false, "score": 0.00016021728515625}, "shared": {"value": false, "score": 1.4901161193847656e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9934203028678894}, "shared": {"value": false, "score": 0.010259866714477539}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Hive", "normalizedForm": "Hive", "offsetStart": 0, "offsetEnd": 4}, "context": "Hive gives a relational view of HDFS stored unstructured data. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.000133514404296875}, "created": {"value": false, "score": 9.834766387939453e-06}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999398589134216}, "created": {"value": false, "score": 0.0001316070556640625}, "shared": {"value": false, "score": 5.662441253662109e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "HiveQL", "normalizedForm": "HiveQL", "offsetStart": 0, "offsetEnd": 6}, "context": "HiveQL is the query language of the data warehousing solution Hive, built on top of Hadoop MapReduce [35]. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0028700828552246094}, "created": {"value": false, "score": 7.50422477722168e-05}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9755048155784607}, "created": {"value": false, "score": 0.0003439188003540039}, "shared": {"value": false, "score": 2.980232238769531e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "HiveQL", "normalizedForm": "HiveQL", "offsetStart": 0, "offsetEnd": 6}, "context": "HiveQL queries are decomposed to relational operators, which are then compiled to MapReduce jobs to be executed on Hadoop. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9755048155784607}, "created": {"value": false, "score": 4.45246696472168e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9755048155784607}, "created": {"value": false, "score": 0.0003439188003540039}, "shared": {"value": false, "score": 2.980232238769531e-07}}}, {"type": "software", "software-type": "software", "wikidataId": "Q29120", "wikipediaExternalRef": 5919308, "lang": "en", "confidence": 0.9056, "software-name": {"rawForm": "Hadoop", "normalizedForm": "Hadoop", "wikidataId": "Q29120", "wikipediaExternalRef": 5919308, "lang": "en", "confidence": 0.9056, "offsetStart": 0, "offsetEnd": 6}, "context": "Hadoop, Spark, Giraph, etc.). ", "mentionContextAttributes": {"used": {"value": false, "score": 0.11209166049957275}, "created": {"value": false, "score": 6.377696990966797e-06}, "shared": {"value": false, "score": 8.940696716308594e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9755048155784607}, "created": {"value": false, "score": 0.10342800617218018}, "shared": {"value": false, "score": 0.010259866714477539}}}, {"type": "software", "software-type": "software", "wikidataId": "Q29120", "wikipediaExternalRef": 5919308, "lang": "en", "confidence": 0.9056, "software-name": {"rawForm": "Hadoop", "normalizedForm": "Hadoop", "wikidataId": "Q29120", "wikipediaExternalRef": 5919308, "lang": "en", "confidence": 0.9056, "offsetStart": 0, "offsetEnd": 6}, "context": "Hadoop HDFS), and big data processing frameworks (e.g.", "mentionContextAttributes": {"used": {"value": false, "score": 0.004041433334350586}, "created": {"value": false, "score": 3.653764724731445e-05}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9755048155784607}, "created": {"value": false, "score": 0.10342800617218018}, "shared": {"value": false, "score": 0.010259866714477539}}}, {"type": "software", "software-type": "software", "wikidataId": "Q1165204", "wikipediaExternalRef": 21855450, "lang": "en", "confidence": 0.7457, "software-name": {"rawForm": "MongoDB", "normalizedForm": "MongoDB", "wikidataId": "Q1165204", "wikipediaExternalRef": 21855450, "lang": "en", "confidence": 0.7457, "offsetStart": 0, "offsetEnd": 7}, "context": "MongoDB subqueries show lowest performance as data retrieval passes through the embedded JavaScript interpreter at each worker.", "mentionContextAttributes": {"used": {"value": true, "score": 0.5013434290885925}, "created": {"value": false, "score": 1.8477439880371094e-06}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9999129176139832}, "shared": {"value": false, "score": 9.065866470336914e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "QoX", "normalizedForm": "QoX", "offsetStart": 0, "offsetEnd": 8}, "context": "QoX [33] integrates data from RDBMS and HDFS data stores through an XML common data model. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0005320310592651367}, "created": {"value": false, "score": 5.781650543212891e-06}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.0005320310592651367}, "created": {"value": false, "score": 1.6868114471435547e-05}, "shared": {"value": false, "score": 2.980232238769531e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Teradata", "normalizedForm": "Teradata", "offsetStart": 0, "offsetEnd": 8}, "context": "Teradata IntelliSphere [7] addresses the problem of accessing multiple data stores (called \"remote systems\") that may be heterogeneous, but must have an SQL-like interface. ", "mentionContextAttributes": {"used": {"value": false, "score": 6.669759750366211e-05}, "created": {"value": false, "score": 6.717443466186523e-05}, "shared": {"value": false, "score": 4.172325134277344e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.4376014471054077}, "created": {"value": false, "score": 0.013220012187957764}, "shared": {"value": false, "score": 4.172325134277344e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Teradata", "normalizedForm": "Teradata", "offsetStart": 0, "offsetEnd": 8}, "context": "Teradata is responsible for building an SQL query plan and deciding where each SQL operator (e.g. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.003480851650238037}, "created": {"value": false, "score": 0.013220012187957764}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.4376014471054077}, "created": {"value": false, "score": 0.013220012187957764}, "shared": {"value": false, "score": 4.172325134277344e-07}}}, {"type": "software", "software-type": "software", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.6951, "software-name": {"rawForm": "Spark SQL", "normalizedForm": "Spark SQL", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.6951, "offsetStart": 0, "offsetEnd": 9}, "context": "Spark SQL provides a DataFrame API that can map to relations arbitrary object collections and thus enables relational operations across Spark's RDDs and external data sources. ", "mentionContextAttributes": {"used": {"value": false, "score": 8.469820022583008e-05}, "created": {"value": false, "score": 0.0007729530334472656}, "shared": {"value": false, "score": 1.4901161193847656e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997720718383789}, "created": {"value": true, "score": 0.5916945338249207}, "shared": {"value": false, "score": 3.2782554626464844e-06}}}, {"type": "software", "software-type": "software", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.6951, "software-name": {"rawForm": "Spark SQL", "normalizedForm": "Spark SQL", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.6951, "offsetStart": 0, "offsetEnd": 9}, "context": "Spark SQL can access a MongoDB cluster through its MongoDB connector that maps a sharded document collection to a Data-Frame, partitioned as per the collection's sharding setup. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0013504624366760254}, "created": {"value": false, "score": 2.5093555450439453e-05}, "shared": {"value": false, "score": 7.748603820800781e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997720718383789}, "created": {"value": true, "score": 0.5916945338249207}, "shared": {"value": false, "score": 3.2782554626464844e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LeanXcale", "normalizedForm": "LeanXcale", "offsetStart": 0, "offsetEnd": 9}, "context": "LeanXcale is a scalable distributed SQL database management system with OLTP and OLAP support and full ACID capabilities. ", "mentionContextAttributes": {"used": {"value": false, "score": 9.137392044067383e-05}, "created": {"value": false, "score": 0.0007436275482177734}, "shared": {"value": false, "score": 1.4901161193847656e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999398589134216}, "created": {"value": true, "score": 0.9999358057975769}, "shared": {"value": false, "score": 8.52346420288086e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LeanXcale", "normalizedForm": "LeanXcale", "offsetStart": 0, "offsetEnd": 9}, "context": "LeanXcale solves this problem through its patented technology for scalable transaction processing [21]. ", "mentionContextAttributes": {"used": {"value": false, "score": 4.857778549194336e-05}, "created": {"value": false, "score": 0.004270076751708984}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999398589134216}, "created": {"value": true, "score": 0.9999358057975769}, "shared": {"value": false, "score": 8.52346420288086e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LeanXcale", "normalizedForm": "LeanXcale", "offsetStart": 0, "offsetEnd": 9}, "context": "LeanXcale's distributed query engine (DQE) is designed to process OLAP workloads over the operational data, so that analytical queries are answered over real-time data.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00013208389282226562}, "created": {"value": false, "score": 0.014199435710906982}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999398589134216}, "created": {"value": true, "score": 0.9999358057975769}, "shared": {"value": false, "score": 8.52346420288086e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SQL++", "normalizedForm": "SQL++", "offsetStart": 0, "offsetEnd": 10}, "context": "SQL++ [30] mediates SQL and NoSQL data sources through a semi-structured common data model. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0027878880500793457}, "created": {"value": false, "score": 4.708766937255859e-06}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.0027878880500793457}, "created": {"value": false, "score": 4.708766937255859e-06}, "shared": {"value": false, "score": 2.980232238769531e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "PostgreSQL", "normalizedForm": "PostgreSQL", "offsetStart": 0, "offsetEnd": 10}, "context": "PostgreSQL or MySQL) deployed across a cluster, as in a sharednothing parallel DBMS. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9520640969276428}, "created": {"value": false, "score": 9.834766387939453e-06}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9520640969276428}, "created": {"value": false, "score": 9.834766387939453e-06}, "shared": {"value": false, "score": 2.980232238769531e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CloudMdsQL", "normalizedForm": "CloudMdsQL", "offsetStart": 0, "offsetEnd": 10}, "context": "CloudMdsQL also provides a CREATE NAMED EXPRESSION command that allows an expression to be defined and stored in a global catalog in order to be referenced in several queries, similarly to SQL views and stored procedures/functions. ", "mentionContextAttributes": {"used": {"value": false, "score": 4.6193599700927734e-05}, "created": {"value": false, "score": 0.00011748075485229492}, "shared": {"value": false, "score": 1.2516975402832031e-06}}, "documentContextAttributes": {"used": {"value": false, "score": 0.10021162033081055}, "created": {"value": true, "score": 0.9999358057975769}, "shared": {"value": false, "score": 2.3245811462402344e-06}}, "references": [{"label": "[26]", "normalizedForm": "[26]", "refKey": 26}, {"label": "[26]", "normalizedForm": "[26]", "refKey": 26}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SparkAgent", "normalizedForm": "SparkAgent", "offsetStart": 0, "offsetEnd": 10}, "context": "SparkAgent is the component, which accepts TCP connections from Spark executors to push RDD partition data. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.045781731605529785}, "created": {"value": false, "score": 7.873773574829102e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.4153452515602112}, "created": {"value": false, "score": 0.00011998414993286133}, "shared": {"value": false, "score": 1.9669532775878906e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "HadoopDB", "normalizedForm": "HadoopDB", "offsetStart": 0, "offsetEnd": 12}, "context": "HadoopDB [1] provides Hadoop MapReduce/HDFS access to multiple single-node RDBMS servers (e.g. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.00031435489654541016}, "created": {"value": false, "score": 1.0907649993896484e-05}, "shared": {"value": false, "score": 9.834766387939453e-06}}, "documentContextAttributes": {"used": {"value": false, "score": 0.00031435489654541016}, "created": {"value": false, "score": 1.0907649993896484e-05}, "shared": {"value": false, "score": 9.834766387939453e-06}}}, {"type": "software", "software-type": "software", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.6951, "software-name": {"rawForm": "Spark SQL", "normalizedForm": "Spark SQL", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.6951, "offsetStart": 0, "offsetEnd": 13}, "context": "Spark SQL [6] is a parallel SQL engine built on top of Apache Spark and designed to provide tight integration between relational and procedural processing through a declarative API that integrates relational operators with procedural Spark code, taking advantage of massive parallelism. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.00022149085998535156}, "created": {"value": false, "score": 0.013364613056182861}, "shared": {"value": false, "score": 2.562999725341797e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997720718383789}, "created": {"value": true, "score": 0.5916945338249207}, "shared": {"value": false, "score": 3.2782554626464844e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LeanXcale DQE", "normalizedForm": "LeanXcale DQE", "offsetStart": 0, "offsetEnd": 13}, "context": "LeanXcale DQE is designed to integrate with arbitrary data management clusters, where data resides in its natural format and can be retrieved (in parallel) by running specific scripts or declarative queries. ", "mentionContextAttributes": {"used": {"value": false, "score": 5.227327346801758e-05}, "created": {"value": false, "score": 0.26259398460388184}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 5.227327346801758e-05}, "created": {"value": false, "score": 0.26259398460388184}, "shared": {"value": false, "score": 2.980232238769531e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Musketeer", "normalizedForm": "Musketeer", "offsetStart": 0, "offsetEnd": 14}, "context": "Musketeer [18] achieves this through a model that breaks the execution of a data processing workflow in three layers: first, the workflow is specified using a front-end framework of user's choice, e.g. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.00026547908782958984}, "created": {"value": false, "score": 1.9609928131103516e-05}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.0010941624641418457}, "created": {"value": false, "score": 2.7477741241455078e-05}, "shared": {"value": false, "score": 4.172325134277344e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Hadoop MapReduce", "normalizedForm": "Hadoop MapReduce", "offsetStart": 0, "offsetEnd": 16}, "context": "Hadoop MapReduce, Apache Spark, or Apache Flink), specialized for different kinds of data and tasks and able to scale and perform orders of magnitude better than traditional relational DBMS. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.00022077560424804688}, "created": {"value": false, "score": 0.000835716724395752}, "shared": {"value": false, "score": 4.172325134277344e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.0028700828552246094}, "created": {"value": false, "score": 0.0012637972831726074}, "shared": {"value": false, "score": 9.065866470336914e-05}}}, {"type": "software", "software-type": "software", "wikidataId": "Q4778908", "wikipediaExternalRef": 36943785, "lang": "en", "confidence": 0.5819, "software-name": {"rawForm": "Apache Drill", "normalizedForm": "Apache Drill", "wikidataId": "Q4778908", "wikipediaExternalRef": 36943785, "lang": "en", "confidence": 0.5819, "offsetStart": 0, "offsetEnd": 16}, "context": "Apache Drill [4] is a distributed query engine for large-scale datasets, designed to scale to thousands of nodes and query at low latency petabytes of data from various data sources through storage plugins. ", "mentionContextAttributes": {"used": {"value": false, "score": 4.774332046508789e-05}, "created": {"value": false, "score": 0.014595568180084229}, "shared": {"value": false, "score": 5.364418029785156e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 4.774332046508789e-05}, "created": {"value": false, "score": 0.014595568180084229}, "shared": {"value": false, "score": 5.364418029785156e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CloudMdsQL", "normalizedForm": "CloudMdsQL", "offsetStart": 0, "offsetEnd": 18}, "context": "CloudMdsQL [23,26] with its MFR (map/filter/reduce) extensions [9] even allows data store native queries to be expressed as inline scripts and combined with regular SQL statements in ad-hoc integration queries. ", "mentionContextAttributes": {"used": {"value": false, "score": 6.93202018737793e-05}, "created": {"value": false, "score": 1.5437602996826172e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.10021162033081055}, "created": {"value": true, "score": 0.9999358057975769}, "shared": {"value": false, "score": 2.3245811462402344e-06}}, "references": [{"label": "[26]", "normalizedForm": "[26]", "refKey": 26}, {"label": "[26]", "normalizedForm": "[26]", "refKey": 26}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "BigIntegrator", "normalizedForm": "BigIntegrator", "offsetStart": 0, "offsetEnd": 18}, "context": "BigIntegrator [29] integrates data from cloud-based NoSQL big data stores, such as Google's Bigtable, and relational databases. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.00016045570373535156}, "created": {"value": false, "score": 8.046627044677734e-06}, "shared": {"value": false, "score": 5.364418029785156e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.00016045570373535156}, "created": {"value": false, "score": 8.046627044677734e-06}, "shared": {"value": false, "score": 5.364418029785156e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "QoX", "normalizedForm": "QoX", "offsetStart": 4, "offsetEnd": 7}, "context": "The QoX optimizer uses a dataflow approach for optimizing queries over data stores, with a black box approach for cost modeling.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0004521012306213379}, "created": {"value": false, "score": 1.6868114471435547e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.0005320310592651367}, "created": {"value": false, "score": 1.6868114471435547e-05}, "shared": {"value": false, "score": 2.980232238769531e-07}}}, {"type": "software", "software-type": "software", "wikidataId": "Q47607", "wikipediaExternalRef": 29004, "lang": "en", "confidence": 0.4606, "software-name": {"rawForm": "SQL", "normalizedForm": "SQL", "wikidataId": "Q47607", "wikipediaExternalRef": 29004, "lang": "en", "confidence": 0.4606, "offsetStart": 4, "offsetEnd": 7}, "context": "The SQL table expression T1 is defined by an SQL subquery, while T2 is a native expression (identified by the special bracket symbols {* *}) expressed as a native MongoDB API call or JavaScript code.", "mentionContextAttributes": {"used": {"value": false, "score": 0.05572474002838135}, "created": {"value": false, "score": 4.178285598754883e-05}, "shared": {"value": false, "score": 1.1324882507324219e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9934203028678894}, "shared": {"value": false, "score": 0.010259866714477539}}}, {"type": "software", "software-type": "software", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.3825, "software-name": {"rawForm": "Spark", "normalizedForm": "Spark", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.3825, "offsetStart": 4, "offsetEnd": 9}, "context": "For Spark result sets, this overhead is a bit higher, because of the additional serialization/deserialization that takes place between Spark executors and SparkAgent instances.", "mentionContextAttributes": {"used": {"value": false, "score": 0.034141480922698975}, "created": {"value": false, "score": 2.0802021026611328e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9997756481170654}, "shared": {"value": false, "score": 1.4841556549072266e-05}}}, {"type": "software", "software-type": "software", "wikidataId": "Q1165204", "wikipediaExternalRef": 21855450, "lang": "en", "confidence": 0.7457, "software-name": {"rawForm": "MongoDB", "normalizedForm": "MongoDB", "wikidataId": "Q1165204", "wikipediaExternalRef": 21855450, "lang": "en", "confidence": 0.7457, "offsetStart": 4, "offsetEnd": 11}, "context": "The MongoDB storage allows running Drill and MongoDB together in distributed mode, by assigning shards to different drillbits to exploit parallelism.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0003085136413574219}, "created": {"value": false, "score": 5.8710575103759766e-05}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9999129176139832}, "shared": {"value": false, "score": 9.065866470336914e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LeanXcale", "normalizedForm": "LeanXcale", "offsetStart": 4, "offsetEnd": 13}, "context": "The LeanXcale database has derived its OLAP query engine from Apache Calcite [8], a Java-based open-source framework for SQL query processing and optimization.", "mentionContextAttributes": {"used": {"value": true, "score": 0.6484043598175049}, "created": {"value": false, "score": 0.00020933151245117188}, "shared": {"value": false, "score": 8.52346420288086e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999398589134216}, "created": {"value": true, "score": 0.9999358057975769}, "shared": {"value": false, "score": 8.52346420288086e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CloudMdsQL", "normalizedForm": "CloudMdsQL", "offsetStart": 4, "offsetEnd": 14}, "context": "The CloudMdsQL language [26] is SQL-based with the extended capabilities for embedding subqueries expressed in terms of each data store's native query interface. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0027697086334228516}, "created": {"value": false, "score": 0.000152587890625}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.10021162033081055}, "created": {"value": true, "score": 0.9999358057975769}, "shared": {"value": false, "score": 2.3245811462402344e-06}}, "references": [{"label": "[26]", "normalizedForm": "[26]", "refKey": 26, "offsetStart": 29904, "offsetEnd": 29908}, {"label": "[26]", "normalizedForm": "[26]", "refKey": 26, "offsetStart": 29904, "offsetEnd": 29908}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "findSharded", "normalizedForm": "findSharded", "offsetStart": 4, "offsetEnd": 15}, "language": {"rawForm": "JavaScript", "normalizedForm": "JavaScript"}, "context": "The findSharded() method accepts the same arguments as the native MongoDB find() operator, in order to provide the native flexible querying functionality, complemented with the ability to handle parallel iteration on the sharded result set.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00013494491577148438}, "created": {"value": false, "score": 4.082918167114258e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.7317376136779785}, "created": {"value": false, "score": 4.082918167114258e-05}, "shared": {"value": false, "score": 1.0132789611816406e-06}}}, {"type": "software", "software-type": "software", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.3825, "software-name": {"rawForm": "Spark", "normalizedForm": "Spark", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.3825, "offsetStart": 5, "offsetEnd": 10}, "context": "What Spark SQL is not capable of is bind join through SQL queries; to perform a bind join, one has to write a Spark program, which limits the use cases.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00010186433792114258}, "created": {"value": false, "score": 0.00010186433792114258}, "shared": {"value": false, "score": 4.172325134277344e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9997756481170654}, "shared": {"value": false, "score": 1.4841556549072266e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LeanXcale", "normalizedForm": "LeanXcale", "offsetStart": 5, "offsetEnd": 14}, "context": "With LeanXcale, once the named tables (subqueries to data stores) are defined by the system developer or administrator, they can be easily used and involved in joins (including bind joins) through the SQL interface. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.000822603702545166}, "created": {"value": false, "score": 5.227327346801758e-05}, "shared": {"value": false, "score": 8.940696716308594e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999398589134216}, "created": {"value": true, "score": 0.9999358057975769}, "shared": {"value": false, "score": 8.52346420288086e-06}}}, {"type": "software", "software-type": "software", "wikidataId": "Q1165204", "wikipediaExternalRef": 21855450, "lang": "en", "confidence": 0.7457, "software-name": {"rawForm": "MongoDB", "normalizedForm": "MongoDB", "wikidataId": "Q1165204", "wikipediaExternalRef": 21855450, "lang": "en", "confidence": 0.7457, "offsetStart": 6, "offsetEnd": 13}, "context": "Since MongoDB collections are used directly in the FROM clause as tables, the storage plugin translates relational operators to native MongoDB queries.", "mentionContextAttributes": {"used": {"value": false, "score": 0.09908026456832886}, "created": {"value": false, "score": 1.1861324310302734e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9999129176139832}, "shared": {"value": false, "score": 9.065866470336914e-05}}}, {"type": "software", "software-type": "software", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.3825, "software-name": {"rawForm": "Spark", "normalizedForm": "Spark", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.3825, "offsetStart": 8, "offsetEnd": 13}, "context": "Hadoop, Spark, Giraph, etc.).", "mentionContextAttributes": {"used": {"value": false, "score": 0.11209166049957275}, "created": {"value": false, "score": 6.377696990966797e-06}, "shared": {"value": false, "score": 8.940696716308594e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9997756481170654}, "shared": {"value": false, "score": 1.4841556549072266e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LeanXcale", "normalizedForm": "LeanXcale", "offsetStart": 8, "offsetEnd": 17}, "context": "JEN and LeanXcale are applying semi-joins as an optimization technique -JEN with its efficient zigzag join that exchanges bloom filters between the HDFS and RDBMS datasets and LeanXcale through bind joins. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.008451342582702637}, "created": {"value": false, "score": 4.827976226806641e-06}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999398589134216}, "created": {"value": true, "score": 0.9999358057975769}, "shared": {"value": false, "score": 8.52346420288086e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "REDUCE", "normalizedForm": "REDUCE", "offsetStart": 9, "offsetEnd": 15}, "context": "Rule #2: REDUCE(<transformation>).FILTER(<predicate>) is equivalent to FILTER(<predicate>).REDUCE(<transformation>), if predicate condition is a function only of the KEY, because thus, applying the FILTER before the REDUCE will preserve the values associated to those keys that satisfy the filter condition as they would be if the FILTER was applied after the REDUCE.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9831934571266174}, "created": {"value": false, "score": 3.039836883544922e-06}, "shared": {"value": false, "score": 2.4437904357910156e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9995518326759338}, "created": {"value": false, "score": 0.00020503997802734375}, "shared": {"value": false, "score": 2.4437904357910156e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ShardedCursor", "normalizedForm": "ShardedCursor", "offsetStart": 9, "offsetEnd": 22}, "context": "In fact, ShardedCursor implements all DataLake API methods and hence serves as a proxy of the API into the JavaScript MongoDB client library. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0036196112632751465}, "created": {"value": false, "score": 0.0005892515182495117}, "shared": {"value": false, "score": 1.5914440155029297e-05}}, "documentContextAttributes": {"used": {"value": false, "score": 0.011867344379425049}, "created": {"value": false, "score": 0.0005892515182495117}, "shared": {"value": false, "score": 1.5914440155029297e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Hive", "normalizedForm": "Hive", "offsetStart": 10, "offsetEnd": 14}, "context": "Note that Hive is interfaced only for getting metadata, while the data rows are read directly from HDFS.", "mentionContextAttributes": {"used": {"value": false, "score": 0.12791919708251953}, "created": {"value": false, "score": 9.59634780883789e-06}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999398589134216}, "created": {"value": false, "score": 0.0001316070556640625}, "shared": {"value": false, "score": 5.662441253662109e-06}}}, {"type": "software", "software-type": "software", "wikidataId": "Q47607", "wikipediaExternalRef": 29004, "lang": "en", "confidence": 0.4606, "software-name": {"rawForm": "SQL", "normalizedForm": "SQL", "wikidataId": "Q47607", "wikipediaExternalRef": 29004, "lang": "en", "confidence": 0.4606, "offsetStart": 11, "offsetEnd": 14}, "context": "What Spark SQL is not capable of is bind join through SQL queries; to perform a bind join, one has to write a Spark program, which limits the use cases.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00010186433792114258}, "created": {"value": false, "score": 0.00010186433792114258}, "shared": {"value": false, "score": 4.172325134277344e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9934203028678894}, "shared": {"value": false, "score": 0.010259866714477539}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LeanXcale", "normalizedForm": "LeanXcale", "offsetStart": 11, "offsetEnd": 20}, "context": "This turns LeanXcale DQE into a powerful \"big data lake\" polyglot query engine that can process data from its original format, taking full advantage of both expressive scripting and massive parallelism. ", "mentionContextAttributes": {"used": {"value": false, "score": 4.0590763092041016e-05}, "created": {"value": false, "score": 0.006999373435974121}, "shared": {"value": false, "score": 5.364418029785156e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999398589134216}, "created": {"value": true, "score": 0.9999358057975769}, "shared": {"value": false, "score": 8.52346420288086e-06}}}, {"type": "software", "software-type": "software", "wikidataId": "Q47607", "wikipediaExternalRef": 29004, "lang": "en", "confidence": 0.4606, "software-name": {"rawForm": "SQL", "normalizedForm": "SQL", "wikidataId": "Q47607", "wikipediaExternalRef": 29004, "lang": "en", "confidence": 0.4606, "offsetStart": 12, "offsetEnd": 15}, "context": "It produces SQL statements for relational data stores, and Pig/Hive code for interfacing Hadoop to access HDFS data.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00014781951904296875}, "created": {"value": false, "score": 0.0006139874458312988}, "shared": {"value": false, "score": 1.4901161193847656e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9934203028678894}, "shared": {"value": false, "score": 0.010259866714477539}}}, {"type": "software", "software-type": "software", "wikidataId": "Q1165204", "wikipediaExternalRef": 21855450, "lang": "en", "confidence": 0.7457, "software-name": {"rawForm": "MongoDB", "normalizedForm": "MongoDB", "wikidataId": "Q1165204", "wikipediaExternalRef": 21855450, "lang": "en", "confidence": 0.7457, "offsetStart": 12, "offsetEnd": 19}, "context": "To access a MongoDB cluster, Presto uses a connector that allows the parallel retrieval of sharded collections, which is typically configured with a list of MongoDB servers.", "mentionContextAttributes": {"used": {"value": false, "score": 0.004172682762145996}, "created": {"value": false, "score": 6.335973739624023e-05}, "shared": {"value": false, "score": 1.0132789611816406e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9999129176139832}, "shared": {"value": false, "score": 9.065866470336914e-05}}}, {"type": "software", "software-type": "software", "wikidataId": "Q1165204", "wikipediaExternalRef": 21855450, "lang": "en", "confidence": 0.7457, "software-name": {"rawForm": "MongoDB", "normalizedForm": "MongoDB", "wikidataId": "Q1165204", "wikipediaExternalRef": 21855450, "lang": "en", "confidence": 0.7457, "offsetStart": 12, "offsetEnd": 19}, "context": "Even if the MongoDB data has to undergo transformations, expressed through user-defined JavaScript functions, this can still be handled in parallel by making each worker initiate the execution of the custom JavaScript code against the MongoDB shard assigned to it and collect its partition of the intermediate data.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00835806131362915}, "created": {"value": false, "score": 0.00038951635360717773}, "shared": {"value": false, "score": 1.2516975402832031e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9999129176139832}, "shared": {"value": false, "score": 9.065866470336914e-05}}}, {"type": "software", "software-type": "software", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.7879, "software-name": {"rawForm": "Apache Spark", "normalizedForm": "Apache Spark", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.7879, "offsetStart": 12, "offsetEnd": 24}, "context": "In terms of Apache Spark, a dataset corresponds to an RDD (Resilient Distributed Dataset -the basic programming unit of Spark). ", "mentionContextAttributes": {"used": {"value": false, "score": 0.01917022466659546}, "created": {"value": false, "score": 2.664327621459961e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.01917022466659546}, "created": {"value": true, "score": 0.7794421911239624}, "shared": {"value": false, "score": 4.470348358154297e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "HiveQL", "normalizedForm": "HiveQL", "offsetStart": 13, "offsetEnd": 19}, "context": "In addition, HiveQL allows custom scripts, defining MapReduce jobs, to be referred in queries and used in combination with relational operators. ", "mentionContextAttributes": {"used": {"value": false, "score": 2.9981136322021484e-05}, "created": {"value": false, "score": 0.0003439188003540039}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9755048155784607}, "created": {"value": false, "score": 0.0003439188003540039}, "shared": {"value": false, "score": 2.980232238769531e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MySQL", "normalizedForm": "MySQL", "offsetStart": 14, "offsetEnd": 19}, "context": "PostgreSQL or MySQL) deployed across a cluster, as in a sharednothing parallel DBMS. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9520640969276428}, "created": {"value": false, "score": 9.834766387939453e-06}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9520640969276428}, "created": {"value": false, "score": 9.834766387939453e-06}, "shared": {"value": false, "score": 2.980232238769531e-07}}}, {"type": "software", "software-type": "software", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.3825, "software-name": {"rawForm": "Spark", "normalizedForm": "Spark", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.3825, "offsetStart": 14, "offsetEnd": 19}, "context": "The choice of Spark SQL for a state-of-the-art representative to compare our work with is justified by the fact that it supports most of the features our approach targets and hereby evaluates, namely: (a) parallel MongoDB subqueries through the use of the MongoDB connector that also supports native Mon-goDB operators (e.g.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0012915730476379395}, "created": {"value": false, "score": 0.04539138078689575}, "shared": {"value": false, "score": 8.940696716308594e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9997756481170654}, "shared": {"value": false, "score": 1.4841556549072266e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "REDUCE", "normalizedForm": "REDUCE", "offsetStart": 14, "offsetEnd": 20}, "context": ".MAP(KEY, 1) .REDUCE(SUM) .FILTER( KEY LIKE '%cloud%' ) *}", "mentionContextAttributes": {"used": {"value": true, "score": 0.9995518326759338}, "created": {"value": false, "score": 6.854534149169922e-06}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9995518326759338}, "created": {"value": false, "score": 0.00020503997802734375}, "shared": {"value": false, "score": 2.4437904357910156e-06}}}, {"type": "software", "software-type": "software", "wikidataId": "Q1165204", "wikipediaExternalRef": 21855450, "lang": "en", "confidence": 0.7457, "software-name": {"rawForm": "MongoDB", "normalizedForm": "MongoDB", "wikidataId": "Q1165204", "wikipediaExternalRef": 21855450, "lang": "en", "confidence": 0.7457, "offsetStart": 14, "offsetEnd": 21}, "context": "Subqueries to MongoDB are expressed natively in JavaScript.", "mentionContextAttributes": {"used": {"value": true, "score": 0.5642330646514893}, "created": {"value": false, "score": 1.6868114471435547e-05}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9999129176139832}, "shared": {"value": false, "score": 9.065866470336914e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MapReduce", "normalizedForm": "MapReduce", "offsetStart": 14, "offsetEnd": 23}, "context": "It interfaces MapReduce with RDBMS through database connectors that execute SQL queries to return key-value pairs.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00026595592498779297}, "created": {"value": false, "score": 8.70823860168457e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9755048155784607}, "created": {"value": false, "score": 0.22964704036712646}, "shared": {"value": false, "score": 2.980232238769531e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "BigDAWG", "normalizedForm": "BigDAWG", "offsetStart": 14, "offsetEnd": 29}, "context": "The polystore BigDAWG [16,17] goes one step further by defining \"islands of information\", where each island corresponds to a specific data model and its language and provides transparent access to a subset of the underlying data stores through the island's data model. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.00021457672119140625}, "created": {"value": false, "score": 2.104043960571289e-05}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.00021457672119140625}, "created": {"value": false, "score": 2.104043960571289e-05}, "shared": {"value": false, "score": 2.980232238769531e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Giraph", "normalizedForm": "Giraph", "offsetStart": 15, "offsetEnd": 21}, "context": "Hadoop, Spark, Giraph, etc.). ", "mentionContextAttributes": {"used": {"value": false, "score": 0.11209166049957275}, "created": {"value": false, "score": 6.377696990966797e-06}, "shared": {"value": false, "score": 8.940696716308594e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.11209166049957275}, "created": {"value": false, "score": 6.377696990966797e-06}, "shared": {"value": false, "score": 8.940696716308594e-07}}}, {"type": "software", "software-type": "software", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.6951, "software-name": {"rawForm": "Spark SQL", "normalizedForm": "Spark SQL", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.6951, "offsetStart": 16, "offsetEnd": 25}, "context": "Comparison with Spark SQL. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0011861920356750488}, "created": {"value": false, "score": 1.901388168334961e-05}, "shared": {"value": false, "score": 4.172325134277344e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997720718383789}, "created": {"value": true, "score": 0.5916945338249207}, "shared": {"value": false, "score": 3.2782554626464844e-06}}}, {"type": "software", "software-type": "software", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.3825, "software-name": {"rawForm": "Spark", "normalizedForm": "Spark", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.3825, "offsetStart": 18, "offsetEnd": 23}, "context": "For example, with Spark SQL it is possible to do a bind join, but this must be defined programmatically by a developer.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00011676549911499023}, "created": {"value": false, "score": 0.00022792816162109375}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9997756481170654}, "shared": {"value": false, "score": 1.4841556549072266e-05}}}, {"type": "software", "software-type": "software", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.3825, "software-name": {"rawForm": "Spark", "normalizedForm": "Spark", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.3825, "offsetStart": 18, "offsetEnd": 23}, "context": "MFR subqueries to Spark are defined as single SCAN operators, translated to Scala commands.", "mentionContextAttributes": {"used": {"value": false, "score": 0.011382699012756348}, "created": {"value": false, "score": 6.377696990966797e-06}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9997756481170654}, "shared": {"value": false, "score": 1.4841556549072266e-05}}}, {"type": "software", "software-type": "software", "wikidataId": "Q1165204", "wikipediaExternalRef": 21855450, "lang": "en", "confidence": 0.7457, "software-name": {"rawForm": "MongoDB", "normalizedForm": "MongoDB", "wikidataId": "Q1165204", "wikipediaExternalRef": 21855450, "lang": "en", "confidence": 0.7457, "offsetStart": 18, "offsetEnd": 25}, "context": "Impala can access MongoDB collections through a MongoDB connector for Hadoop, designed to provide the ability to read MongoDB data into Hadoop MapReduce jobs.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0019541382789611816}, "created": {"value": false, "score": 0.0012637972831726074}, "shared": {"value": false, "score": 9.065866470336914e-05}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9999129176139832}, "shared": {"value": false, "score": 9.065866470336914e-05}}}, {"type": "software", "software-type": "software", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.7879, "software-name": {"rawForm": "Apache Spark", "normalizedForm": "Apache Spark", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.7879, "offsetStart": 18, "offsetEnd": 30}, "context": "Hadoop MapReduce, Apache Spark, or Apache Flink), specialized for different kinds of data and tasks and able to scale and perform orders of magnitude better than traditional relational DBMS. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.00022077560424804688}, "created": {"value": false, "score": 0.000835716724395752}, "shared": {"value": false, "score": 4.172325134277344e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.01917022466659546}, "created": {"value": true, "score": 0.7794421911239624}, "shared": {"value": false, "score": 4.470348358154297e-06}}}, {"type": "software", "software-type": "software", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.5539, "software-name": {"rawForm": "Spark", "normalizedForm": "Spark", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.5539, "offsetStart": 19, "offsetEnd": 24}, "context": "Without bind join, Spark SQL shows a slight advantage compared to LeanXcale DQE, which is explainable by the overhead of the JavaScript interpreting that takes place at DQE wrappers for MongoDB. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.00408935546875}, "created": {"value": false, "score": 6.735324859619141e-06}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9997756481170654}, "shared": {"value": false, "score": 1.4841556549072266e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ShardedCursor", "normalizedForm": "ShardedCursor", "offsetStart": 19, "offsetEnd": 32}, "context": "At this point, the ShardedCursor object does not yet initiate the query execution, but only memorizes the query filter object.", "mentionContextAttributes": {"used": {"value": false, "score": 0.011867344379425049}, "created": {"value": false, "score": 2.294778823852539e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.011867344379425049}, "created": {"value": false, "score": 0.0005892515182495117}, "shared": {"value": false, "score": 1.5914440155029297e-05}}}, {"type": "software", "software-type": "software", "wikidataId": "Q47607", "wikipediaExternalRef": 29004, "lang": "en", "confidence": 0.4606, "software-name": {"rawForm": "SQL", "normalizedForm": "SQL", "wikidataId": "Q47607", "wikipediaExternalRef": 29004, "lang": "en", "confidence": 0.4606, "offsetStart": 20, "offsetEnd": 23}, "context": "SQL++ [30] mediates SQL and NoSQL data sources through a semi-structured common data model.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0027878880500793457}, "created": {"value": false, "score": 4.708766937255859e-06}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9934203028678894}, "shared": {"value": false, "score": 0.010259866714477539}}}, {"type": "software", "software-type": "software", "wikidataId": "Q47607", "wikipediaExternalRef": 29004, "lang": "en", "confidence": 0.4606, "software-name": {"rawForm": "SQL", "normalizedForm": "SQL", "wikidataId": "Q47607", "wikipediaExternalRef": 29004, "lang": "en", "confidence": 0.4606, "offsetStart": 20, "offsetEnd": 23}, "context": "The choice of Spark SQL for a state-of-the-art representative to compare our work with is justified by the fact that it supports most of the features our approach targets and hereby evaluates, namely: (a) parallel MongoDB subqueries through the use of the MongoDB connector that also supports native Mon-goDB operators (e.g.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0012915730476379395}, "created": {"value": false, "score": 0.04539138078689575}, "shared": {"value": false, "score": 8.940696716308594e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9934203028678894}, "shared": {"value": false, "score": 0.010259866714477539}}}, {"type": "software", "software-type": "software", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.6951, "software-name": {"rawForm": "Spark SQL", "normalizedForm": "Spark SQL", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.6951, "offsetStart": 21, "offsetEnd": 30}, "context": "Therefore, we target Spark SQL as the only relevant system to evaluate our contributions against.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9132308959960938}, "created": {"value": true, "score": 0.5916945338249207}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997720718383789}, "created": {"value": true, "score": 0.5916945338249207}, "shared": {"value": false, "score": 3.2782554626464844e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "REDUCE", "normalizedForm": "REDUCE", "offsetStart": 22, "offsetEnd": 28}, "context": "The following MAP and REDUCE count the frequencies of each such pair. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.928074836730957}, "created": {"value": false, "score": 5.424022674560547e-06}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9995518326759338}, "created": {"value": false, "score": 0.00020503997802734375}, "shared": {"value": false, "score": 2.4437904357910156e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Hadoop MapReduce", "normalizedForm": "Hadoop MapReduce", "offsetStart": 22, "offsetEnd": 38}, "context": "HadoopDB [1] provides Hadoop MapReduce/HDFS access to multiple single-node RDBMS servers (e.g. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.00031435489654541016}, "created": {"value": false, "score": 1.0907649993896484e-05}, "shared": {"value": false, "score": 9.834766387939453e-06}}, "documentContextAttributes": {"used": {"value": false, "score": 0.0028700828552246094}, "created": {"value": false, "score": 0.0012637972831726074}, "shared": {"value": false, "score": 9.065866470336914e-05}}}, {"type": "software", "software-type": "software", "wikidataId": "Q1165204", "wikipediaExternalRef": 21855450, "lang": "en", "confidence": 0.7457, "software-name": {"rawForm": "MongoDB", "normalizedForm": "MongoDB", "wikidataId": "Q1165204", "wikipediaExternalRef": 21855450, "lang": "en", "confidence": 0.7457, "offsetStart": 23, "offsetEnd": 30}, "context": "Spark SQL can access a MongoDB cluster through its MongoDB connector that maps a sharded document collection to a Data-Frame, partitioned as per the collection's sharding setup.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0013504624366760254}, "created": {"value": false, "score": 2.5093555450439453e-05}, "shared": {"value": false, "score": 7.748603820800781e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9999129176139832}, "shared": {"value": false, "score": 9.065866470336914e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "findSharded", "normalizedForm": "findSharded", "offsetStart": 23, "offsetEnd": 34}, "language": {"rawForm": "JavaScript", "normalizedForm": "JavaScript", "wikidataId": "Q2005", "offsetStart": 214, "offsetEnd": 224}, "context": "Thus, a composition of findSharded and map/flatMap (such as in the BookOrders example above) makes a user script expressive enough, so as to request a specific MongoDB dataset, retrieve the result set in parallel, and transform it in order to fit the named table signature and further be consumed by relational operators at the DQE level. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0015254616737365723}, "created": {"value": false, "score": 2.2590160369873047e-05}, "shared": {"value": false, "score": 1.0132789611816406e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.7317376136779785}, "created": {"value": false, "score": 4.082918167114258e-05}, "shared": {"value": false, "score": 1.0132789611816406e-06}}}, {"type": "software", "software-type": "software", "wikidataId": "Q47607", "wikipediaExternalRef": 29004, "lang": "en", "confidence": 0.4606, "software-name": {"rawForm": "SQL", "normalizedForm": "SQL", "wikidataId": "Q47607", "wikipediaExternalRef": 29004, "lang": "en", "confidence": 0.4606, "offsetStart": 24, "offsetEnd": 27}, "context": "For example, with Spark SQL it is possible to do a bind join, but this must be defined programmatically by a developer.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00011676549911499023}, "created": {"value": false, "score": 0.00022792816162109375}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9934203028678894}, "shared": {"value": false, "score": 0.010259866714477539}}}, {"type": "software", "software-type": "software", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.3825, "software-name": {"rawForm": "Spark", "normalizedForm": "Spark", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.3825, "offsetStart": 24, "offsetEnd": 29}, "context": "However, in the case of Spark, there is no way to directly access the data of an RDD partition.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00023794174194335938}, "created": {"value": false, "score": 0.00023317337036132812}, "shared": {"value": false, "score": 5.364418029785156e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9997756481170654}, "shared": {"value": false, "score": 1.4841556549072266e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LeanXcale", "normalizedForm": "LeanXcale", "offsetStart": 24, "offsetEnd": 33}, "context": "Hybrid systems (besides LeanXcale) usually access document data stores through extended relational mappings, with the added support of flattening operators (UNNEST) to express queries over nested documents. ", "mentionContextAttributes": {"used": {"value": false, "score": 5.882978439331055e-05}, "created": {"value": false, "score": 0.0006375908851623535}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999398589134216}, "created": {"value": true, "score": 0.9999358057975769}, "shared": {"value": false, "score": 8.52346420288086e-06}}}, {"type": "software", "software-type": "software", "wikidataId": "Q47607", "wikipediaExternalRef": 29004, "lang": "en", "confidence": 0.4606, "software-name": {"rawForm": "SQL", "normalizedForm": "SQL", "wikidataId": "Q47607", "wikipediaExternalRef": 29004, "lang": "en", "confidence": 0.4606, "offsetStart": 25, "offsetEnd": 28}, "context": "Without bind join, Spark SQL shows a slight advantage compared to LeanXcale DQE, which is explainable by the overhead of the JavaScript interpreting that takes place at DQE wrappers for MongoDB.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00408935546875}, "created": {"value": false, "score": 6.735324859619141e-06}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9934203028678894}, "shared": {"value": false, "score": 0.010259866714477539}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "API", "normalizedForm": "API", "offsetStart": 25, "offsetEnd": 28}, "context": "The concept relies on an API that allows its generalization to multiple script engines and data stores.", "mentionContextAttributes": {"used": {"value": false, "score": 4.0590763092041016e-05}, "created": {"value": false, "score": 0.035233914852142334}, "shared": {"value": false, "score": 1.0132789611816406e-06}}, "documentContextAttributes": {"used": {"value": false, "score": 0.05950498580932617}, "created": {"value": false, "score": 0.05537760257720947}, "shared": {"value": false, "score": 4.655122756958008e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LeanXcale", "normalizedForm": "LeanXcale", "offsetStart": 25, "offsetEnd": 34}, "context": "When LINEITEM resides at LeanXcale, the performance is highest, as the query engine processes it natively.", "mentionContextAttributes": {"used": {"value": false, "score": 0.018893778324127197}, "created": {"value": false, "score": 9.357929229736328e-06}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999398589134216}, "created": {"value": true, "score": 0.9999358057975769}, "shared": {"value": false, "score": 8.52346420288086e-06}}}, {"type": "software", "software-type": "software", "wikidataId": "Q47607", "wikipediaExternalRef": 29004, "lang": "en", "confidence": 0.4606, "software-name": {"rawForm": "SQL", "normalizedForm": "SQL", "wikidataId": "Q47607", "wikipediaExternalRef": 29004, "lang": "en", "confidence": 0.4606, "offsetStart": 26, "offsetEnd": 29}, "context": "With respect to combining SQL and map/reduce operators, a number of SQL-like query languages have been introduced.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0001055598258972168}, "created": {"value": false, "score": 0.012389957904815674}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9934203028678894}, "shared": {"value": false, "score": 0.010259866714477539}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Bigtable", "normalizedForm": "Bigtable", "offsetStart": 27, "offsetEnd": 35}, "publisher": {"rawForm": "Google", "normalizedForm": "Google"}, "context": "However, it only works for Bigtable-like systems and cannot integrate data from HDFS.", "mentionContextAttributes": {"used": {"value": false, "score": 6.777048110961914e-05}, "created": {"value": false, "score": 0.00018334388732910156}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.0007174015045166016}, "created": {"value": false, "score": 0.0002396106719970703}, "shared": {"value": false, "score": 5.364418029785156e-07}}}, {"type": "software", "software-type": "software", "wikidataId": "Q47607", "wikipediaExternalRef": 29004, "lang": "en", "confidence": 0.4606, "software-name": {"rawForm": "SQL", "normalizedForm": "SQL", "wikidataId": "Q47607", "wikipediaExternalRef": 29004, "lang": "en", "confidence": 0.4606, "offsetStart": 28, "offsetEnd": 31}, "context": "Spark SQL [6] is a parallel SQL engine built on top of Apache Spark and designed to provide tight integration between relational and procedural processing through a declarative API that integrates relational operators with procedural Spark code, taking advantage of massive parallelism.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00022149085998535156}, "created": {"value": false, "score": 0.013364613056182861}, "shared": {"value": false, "score": 2.562999725341797e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9934203028678894}, "shared": {"value": false, "score": 0.010259866714477539}}}, {"type": "software", "software-type": "software", "wikidataId": "Q1165204", "wikipediaExternalRef": 21855450, "lang": "en", "confidence": 0.7457, "software-name": {"rawForm": "MongoDB", "normalizedForm": "MongoDB", "wikidataId": "Q1165204", "wikipediaExternalRef": 21855450, "lang": "en", "confidence": 0.7457, "offsetStart": 28, "offsetEnd": 35}, "context": "The distributed wrapper for MongoDB comprises a number of instances of a Java class that implements the DataLake API, each of which embeds a JavaScript scripting engine that uses MongoDB's JavaScript client library. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.05950498580932617}, "created": {"value": false, "score": 0.0017822980880737305}, "shared": {"value": false, "score": 4.655122756958008e-05}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9999129176139832}, "shared": {"value": false, "score": 9.065866470336914e-05}}}, {"type": "software", "software-type": "software", "wikidataId": "Q47607", "wikipediaExternalRef": 29004, "lang": "en", "confidence": 0.4606, "software-name": {"rawForm": "SQL", "normalizedForm": "SQL", "wikidataId": "Q47607", "wikipediaExternalRef": 29004, "lang": "en", "confidence": 0.4606, "offsetStart": 29, "offsetEnd": 32}, "context": "Presto [32] is a distributed SQL query engine, running on a shared-nothing cluster of machines, and designed to process interactive analytic queries against data sources of any size.", "mentionContextAttributes": {"used": {"value": false, "score": 4.8220157623291016e-05}, "created": {"value": false, "score": 0.11347544193267822}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9934203028678894}, "shared": {"value": false, "score": 0.010259866714477539}}}, {"type": "software", "software-type": "software", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.3825, "software-name": {"rawForm": "Spark", "normalizedForm": "Spark", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.3825, "offsetStart": 29, "offsetEnd": 34}, "context": "Since this necessitates that Spark workers find and connect to DataLake wrapper instances, it results in a different, more complex architecture of the distributed Spark wrapper.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0006530880928039551}, "created": {"value": false, "score": 6.145238876342773e-05}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9997756481170654}, "shared": {"value": false, "score": 1.4841556549072266e-05}}}, {"type": "software", "software-type": "software", "wikidataId": "Q1165204", "wikipediaExternalRef": 21855450, "lang": "en", "confidence": 0.7457, "software-name": {"rawForm": "MongoDB", "normalizedForm": "MongoDB", "wikidataId": "Q1165204", "wikipediaExternalRef": 21855450, "lang": "en", "confidence": 0.7457, "offsetStart": 30, "offsetEnd": 37}, "context": "Intermediate result sets from MongoDB, HDFS, and Spark are retrieved in parallel, as described in Section 5. Fig. 8 shows the performance measurements on queries of the first test case, executing joins between LINEITEM and ORDERS tables in any configuration of pairs between the three data stores.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9919283390045166}, "created": {"value": false, "score": 7.927417755126953e-06}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9999129176139832}, "shared": {"value": false, "score": 9.065866470336914e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "API", "normalizedForm": "API", "offsetStart": 31, "offsetEnd": 34}, "context": "Spark SQL provides a DataFrame API that can map to relations arbitrary object collections and thus enables relational operations across Spark's RDDs and external data sources.", "mentionContextAttributes": {"used": {"value": false, "score": 8.469820022583008e-05}, "created": {"value": false, "score": 0.0007729530334472656}, "shared": {"value": false, "score": 1.4901161193847656e-06}}, "documentContextAttributes": {"used": {"value": false, "score": 0.05950498580932617}, "created": {"value": false, "score": 0.05537760257720947}, "shared": {"value": false, "score": 4.655122756958008e-05}}}, {"type": "software", "software-type": "software", "wikidataId": "Q47607", "wikipediaExternalRef": 29004, "lang": "en", "confidence": 0.4606, "software-name": {"rawForm": "SQL", "normalizedForm": "SQL", "wikidataId": "Q47607", "wikipediaExternalRef": 29004, "lang": "en", "confidence": 0.4606, "offsetStart": 32, "offsetEnd": 35}, "context": "The CloudMdsQL language [26] is SQL-based with the extended capabilities for embedding subqueries expressed in terms of each data store's native query interface.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0027697086334228516}, "created": {"value": false, "score": 0.000152587890625}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9934203028678894}, "shared": {"value": false, "score": 0.010259866714477539}}}, {"type": "software", "software-type": "software", "wikidataId": "Q1165204", "wikipediaExternalRef": 21855450, "lang": "en", "confidence": 0.7457, "software-name": {"rawForm": "MongoDB", "normalizedForm": "MongoDB", "wikidataId": "Q1165204", "wikipediaExternalRef": 21855450, "lang": "en", "confidence": 0.7457, "offsetStart": 32, "offsetEnd": 39}, "context": "Non-relational systems, such as MongoDB, are supported by defining relational semantics for their operations and adding rules to translate them properly into the relational algebra, used by Myria's relational algebra compiler RACO.", "mentionContextAttributes": {"used": {"value": false, "score": 6.109476089477539e-05}, "created": {"value": false, "score": 0.0007066726684570312}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9999129176139832}, "shared": {"value": false, "score": 9.065866470336914e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CloudMdsQL", "normalizedForm": "CloudMdsQL", "offsetStart": 33, "offsetEnd": 43}, "context": "We start with an overview of the CloudMdsQL query language focusing on the polyglot capabilities and optimization techniques. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.009201526641845703}, "created": {"value": true, "score": 0.9829027652740479}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.10021162033081055}, "created": {"value": true, "score": 0.9999358057975769}, "shared": {"value": false, "score": 2.3245811462402344e-06}}, "references": [{"label": "[26]", "normalizedForm": "[26]", "refKey": 26}, {"label": "[26]", "normalizedForm": "[26]", "refKey": 26}]}, {"type": "software", "software-type": "software", "wikidataId": "Q187432", "wikipediaExternalRef": 21490336, "lang": "en", "confidence": 0.5074, "software-name": {"rawForm": "scripts", "normalizedForm": "scripts", "wikidataId": "Q187432", "wikipediaExternalRef": 21490336, "lang": "en", "confidence": 0.5074, "offsetStart": 34, "offsetEnd": 41}, "context": "In addition, HiveQL allows custom scripts, defining MapReduce jobs, to be referred in queries and used in combination with relational operators.", "mentionContextAttributes": {"used": {"value": false, "score": 2.9981136322021484e-05}, "created": {"value": false, "score": 0.0003439188003540039}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.0027613043785095215}, "created": {"value": true, "score": 0.9998281002044678}, "shared": {"value": false, "score": 2.3245811462402344e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CloudMdsQL", "normalizedForm": "CloudMdsQL", "offsetStart": 34, "offsetEnd": 44}, "context": "For example, the following simple CloudMdsQL query contains two subqueries, defined by the named table expressions T1 and T2, and addressed respectively against the data stores rdb (an SQL database) and mongo (a MongoDB database):", "mentionContextAttributes": {"used": {"value": false, "score": 0.0022200942039489746}, "created": {"value": false, "score": 3.7610530853271484e-05}, "shared": {"value": false, "score": 4.172325134277344e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.10021162033081055}, "created": {"value": true, "score": 0.9999358057975769}, "shared": {"value": false, "score": 2.3245811462402344e-06}}, "references": [{"label": "[26]", "normalizedForm": "[26]", "refKey": 26}, {"label": "[26]", "normalizedForm": "[26]", "refKey": 26}]}, {"type": "software", "software-type": "software", "wikidataId": "Q47607", "wikipediaExternalRef": 29004, "lang": "en", "confidence": 0.4606, "software-name": {"rawForm": "SQL", "normalizedForm": "SQL", "wikidataId": "Q47607", "wikipediaExternalRef": 29004, "lang": "en", "confidence": 0.4606, "offsetStart": 35, "offsetEnd": 38}, "context": "SCOPE has been extended to combine SQL and MapReduce operators in a single language [40].", "mentionContextAttributes": {"used": {"value": false, "score": 0.00015783309936523438}, "created": {"value": false, "score": 0.0009505152702331543}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9934203028678894}, "shared": {"value": false, "score": 0.010259866714477539}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Apache Flink", "normalizedForm": "Apache Flink", "offsetStart": 35, "offsetEnd": 47}, "context": "Hadoop MapReduce, Apache Spark, or Apache Flink), specialized for different kinds of data and tasks and able to scale and perform orders of magnitude better than traditional relational DBMS. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.00022077560424804688}, "created": {"value": false, "score": 0.000835716724395752}, "shared": {"value": false, "score": 4.172325134277344e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.00022077560424804688}, "created": {"value": false, "score": 0.000835716724395752}, "shared": {"value": false, "score": 4.172325134277344e-07}}}, {"type": "software", "software-type": "software", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.3825, "software-name": {"rawForm": "Spark", "normalizedForm": "Spark", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.3825, "offsetStart": 36, "offsetEnd": 41}, "context": "The coordinating components for the Spark subsystem, Livy and AgentRegistry, are running on one of the nodes.", "mentionContextAttributes": {"used": {"value": true, "score": 0.8473861813545227}, "created": {"value": false, "score": 0.010139226913452148}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9997756481170654}, "shared": {"value": false, "score": 1.4841556549072266e-05}}}, {"type": "software", "software-type": "software", "wikidataId": "Q1165204", "wikipediaExternalRef": 21855450, "lang": "en", "confidence": 0.7457, "software-name": {"rawForm": "MongoDB", "normalizedForm": "MongoDB", "wikidataId": "Q1165204", "wikipediaExternalRef": 21855450, "lang": "en", "confidence": 0.7457, "offsetStart": 36, "offsetEnd": 43}, "context": "The full scripting functionality of MongoDB JavaScript library is still provided, but in case parallel execution constraints fail, the execution falls back to a sequential one. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.002060830593109131}, "created": {"value": false, "score": 0.0003560781478881836}, "shared": {"value": false, "score": 7.748603820800781e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9999129176139832}, "shared": {"value": false, "score": 9.065866470336914e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "DataLake API", "normalizedForm": "DataLake API", "offsetStart": 36, "offsetEnd": 48}, "context": "By interfacing wrappers through the DataLake API, the DQE has the possibility to retrieve in parallel disjoint subsets of the result set, much like it does with LeanXcale tables.", "mentionContextAttributes": {"used": {"value": false, "score": 0.009502410888671875}, "created": {"value": false, "score": 6.717443466186523e-05}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.0319443941116333}, "created": {"value": false, "score": 0.00882875919342041}, "shared": {"value": false, "score": 1.5914440155029297e-05}}}, {"type": "software", "software-type": "software", "wikidataId": "Q47607", "wikipediaExternalRef": 29004, "lang": "en", "confidence": 0.4606, "software-name": {"rawForm": "SQL", "normalizedForm": "SQL", "wikidataId": "Q47607", "wikipediaExternalRef": 29004, "lang": "en", "confidence": 0.4606, "offsetStart": 37, "offsetEnd": 40}, "context": "Existing polystore solutions provide SQL mappings to underlying data objects (document collections, raw files, etc.).", "mentionContextAttributes": {"used": {"value": false, "score": 3.427267074584961e-05}, "created": {"value": false, "score": 0.0028144121170043945}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9934203028678894}, "shared": {"value": false, "score": 0.010259866714477539}}}, {"type": "software", "software-type": "software", "wikidataId": "Q1165204", "wikipediaExternalRef": 21855450, "lang": "en", "confidence": 0.7457, "software-name": {"rawForm": "MongoDB", "normalizedForm": "MongoDB", "wikidataId": "Q1165204", "wikipediaExternalRef": 21855450, "lang": "en", "confidence": 0.7457, "offsetStart": 37, "offsetEnd": 44}, "context": "First, the wrapper verifies that the MongoDB balancer is not running in background, because otherwise it may be moving chunks of data across MongoDB shards at the same time the query is being executed, which may result in inconsistent reads. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.10765993595123291}, "created": {"value": false, "score": 1.3887882232666016e-05}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9999129176139832}, "shared": {"value": false, "score": 9.065866470336914e-05}}}, {"type": "software", "software-type": "software", "wikidataId": "Q1165204", "wikipediaExternalRef": 21855450, "lang": "en", "confidence": 0.7457, "software-name": {"rawForm": "MongoDB", "normalizedForm": "MongoDB", "wikidataId": "Q1165204", "wikipediaExternalRef": 21855450, "lang": "en", "confidence": 0.7457, "offsetStart": 37, "offsetEnd": 44}, "context": "To evaluate BookOrders, we created a MongoDB nested document collection named Orders_Items, where we combined the ORDERS and LINEITEM datasets as follows.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9208793044090271}, "created": {"value": true, "score": 0.9981259703636169}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9999129176139832}, "shared": {"value": false, "score": 9.065866470336914e-05}}}, {"type": "software", "software-type": "implicit", "wikidataId": "Q187432", "wikipediaExternalRef": 21490336, "lang": "en", "confidence": 0.5074, "software-name": {"rawForm": "scripts", "normalizedForm": "scripts", "wikidataId": "Q187432", "wikipediaExternalRef": 21490336, "lang": "en", "confidence": 0.5074, "offsetStart": 38, "offsetEnd": 45}, "context": "Moreover, enabling native queries and scripts allows to fully exploit the power of the underlying data stores, as opposed to using static mappings to a common data model.", "mentionContextAttributes": {"used": {"value": false, "score": 4.9054622650146484e-05}, "created": {"value": false, "score": 0.008386194705963135}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.0027613043785095215}, "created": {"value": true, "score": 0.9998281002044678}, "shared": {"value": false, "score": 2.3245811462402344e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LeanXcale", "normalizedForm": "LeanXcale", "offsetStart": 38, "offsetEnd": 47}, "context": "In particular, even in the context of LeanXcale DQE with 2 bind joins sophisticated subqueries expressed as JavaScript or Scala code, parallel join processing shows good speedup with increase of the parallelism level.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00011390447616577148}, "created": {"value": false, "score": 7.927417755126953e-06}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999398589134216}, "created": {"value": true, "score": 0.9999358057975769}, "shared": {"value": false, "score": 8.52346420288086e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "DataLake API", "normalizedForm": "DataLake API", "offsetStart": 38, "offsetEnd": 50}, "context": "In fact, ShardedCursor implements all DataLake API methods and hence serves as a proxy of the API into the JavaScript MongoDB client library.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0036196112632751465}, "created": {"value": false, "score": 0.0005892515182495117}, "shared": {"value": false, "score": 1.5914440155029297e-05}}, "documentContextAttributes": {"used": {"value": false, "score": 0.0319443941116333}, "created": {"value": false, "score": 0.00882875919342041}, "shared": {"value": false, "score": 1.5914440155029297e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "API", "normalizedForm": "API", "offsetStart": 39, "offsetEnd": 42}, "context": "Each wrapper typically uses the client API of the corresponding data management cluster and implements the following DataLake API methods to be invoked by the query engine in order to provide parallel retrieval of shards (Fig. 3).", "mentionContextAttributes": {"used": {"value": false, "score": 0.0319443941116333}, "created": {"value": false, "score": 8.994340896606445e-05}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.05950498580932617}, "created": {"value": false, "score": 0.05537760257720947}, "shared": {"value": false, "score": 4.655122756958008e-05}}}, {"type": "software", "software-type": "software", "wikidataId": "Q1165204", "wikipediaExternalRef": 21855450, "lang": "en", "confidence": 0.7457, "software-name": {"rawForm": "MongoDB", "normalizedForm": "MongoDB", "wikidataId": "Q1165204", "wikipediaExternalRef": 21855450, "lang": "en", "confidence": 0.7457, "offsetStart": 39, "offsetEnd": 46}, "context": "For example, Q1 ML joins LINEITEM from MongoDB with ORDERS from LeanXcale.", "mentionContextAttributes": {"used": {"value": false, "score": 0.005032062530517578}, "created": {"value": false, "score": 4.231929779052734e-06}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9999129176139832}, "shared": {"value": false, "score": 9.065866470336914e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LeanXcale", "normalizedForm": "LeanXcale", "offsetStart": 39, "offsetEnd": 48}, "context": "Fig. 1 illustrates the architecture of LeanXcale's Distributed Query Engine (DQE).", "mentionContextAttributes": {"used": {"value": false, "score": 0.059674859046936035}, "created": {"value": false, "score": 0.0003097057342529297}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999398589134216}, "created": {"value": true, "score": 0.9999358057975769}, "shared": {"value": false, "score": 8.52346420288086e-06}}}, {"type": "software", "software-type": "software", "wikidataId": "Q47607", "wikipediaExternalRef": 29004, "lang": "en", "confidence": 0.4606, "software-name": {"rawForm": "SQL", "normalizedForm": "SQL", "wikidataId": "Q47607", "wikipediaExternalRef": 29004, "lang": "en", "confidence": 0.4606, "offsetStart": 40, "offsetEnd": 43}, "context": "Teradata is responsible for building an SQL query plan and deciding where each SQL operator (e.g.", "mentionContextAttributes": {"used": {"value": false, "score": 0.003480851650238037}, "created": {"value": false, "score": 0.013220012187957764}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9934203028678894}, "shared": {"value": false, "score": 0.010259866714477539}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SQL Server Parallel", "normalizedForm": "SQL Server Parallel", "offsetStart": 40, "offsetEnd": 59}, "publisher": {"rawForm": "Microsoft", "normalizedForm": "Microsoft", "offsetStart": 30, "offsetEnd": 39}, "context": "Polybase [15] is a feature of Microsoft SQL Server Parallel Data Warehouse to access HDFS data using SQL. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.00020503997802734375}, "created": {"value": false, "score": 2.2590160369873047e-05}, "shared": {"value": false, "score": 5.900859832763672e-06}}, "documentContextAttributes": {"used": {"value": false, "score": 0.00020503997802734375}, "created": {"value": false, "score": 2.2590160369873047e-05}, "shared": {"value": false, "score": 5.900859832763672e-06}}}, {"type": "software", "software-type": "software", "wikidataId": "Q47607", "wikipediaExternalRef": 29004, "lang": "en", "confidence": 0.4606, "software-name": {"rawForm": "SQL", "normalizedForm": "SQL", "wikidataId": "Q47607", "wikipediaExternalRef": 29004, "lang": "en", "confidence": 0.4606, "offsetStart": 41, "offsetEnd": 44}, "context": "Impala [5] is an open-source distributed SQL engine operating over Hadoop data processing environment.", "mentionContextAttributes": {"used": {"value": false, "score": 0.001991748809814453}, "created": {"value": false, "score": 1.615285873413086e-05}, "shared": {"value": false, "score": 0.010259866714477539}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9934203028678894}, "shared": {"value": false, "score": 0.010259866714477539}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LeanXcale", "normalizedForm": "LeanXcale", "offsetStart": 41, "offsetEnd": 50}, "context": "All the queries were run on a cluster of LeanXcale DQE instances, running the distributed wrappers for MongoDB, Hive, and Spark.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999398589134216}, "created": {"value": false, "score": 2.7835369110107422e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999398589134216}, "created": {"value": true, "score": 0.9999358057975769}, "shared": {"value": false, "score": 8.52346420288086e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Hive", "normalizedForm": "Hive", "offsetStart": 42, "offsetEnd": 46}, "context": "Therefore, a wrapper instance can use the Hive metastore API to get schema and partitioning information for the subqueried HDFS table and hence to enable iteration on a particular split (shard) of the table.", "mentionContextAttributes": {"used": {"value": false, "score": 0.013434112071990967}, "created": {"value": false, "score": 1.6748905181884766e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999398589134216}, "created": {"value": false, "score": 0.0001316070556640625}, "shared": {"value": false, "score": 5.662441253662109e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "REDUCE", "normalizedForm": "REDUCE", "offsetStart": 42, "offsetEnd": 48}, "context": "Then, after grouping by keyword, the last REDUCE selects, for each keyword, the (user, frequency) pair that has the greatest value of frequency.", "mentionContextAttributes": {"used": {"value": false, "score": 0.04892730712890625}, "created": {"value": false, "score": 6.496906280517578e-06}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9995518326759338}, "created": {"value": false, "score": 0.00020503997802734375}, "shared": {"value": false, "score": 2.4437904357910156e-06}}}, {"type": "software", "software-type": "software", "wikidataId": "Q47607", "wikipediaExternalRef": 29004, "lang": "en", "confidence": 0.4606, "software-name": {"rawForm": "SQL", "normalizedForm": "SQL", "wikidataId": "Q47607", "wikipediaExternalRef": 29004, "lang": "en", "confidence": 0.4606, "offsetStart": 43, "offsetEnd": 46}, "context": "aggregation pipelines), beyond the trivial SQL mappings; (b) parallel map/filter/reduce subqueries, done natively through Spark RDD transformations; (c) parallel joins and scalability.", "mentionContextAttributes": {"used": {"value": false, "score": 0.048490285873413086}, "created": {"value": false, "score": 5.781650543212891e-06}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9934203028678894}, "shared": {"value": false, "score": 0.010259866714477539}}}, {"type": "software", "software-type": "software", "wikidataId": "Q1165204", "wikipediaExternalRef": 21855450, "lang": "en", "confidence": 0.7457, "software-name": {"rawForm": "MongoDB", "normalizedForm": "MongoDB", "wikidataId": "Q1165204", "wikipediaExternalRef": 21855450, "lang": "en", "confidence": 0.7457, "offsetStart": 43, "offsetEnd": 50}, "context": "The concept of parallel querying against a MongoDB cluster is built on the assumption that each DQE worker can access directly a MongoDB shard, bypassing the MongoDB router in order to sustain parallelism.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00023818016052246094}, "created": {"value": false, "score": 0.0005997419357299805}, "shared": {"value": false, "score": 4.172325134277344e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9999129176139832}, "shared": {"value": false, "score": 9.065866470336914e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MapReduce", "normalizedForm": "MapReduce", "offsetStart": 43, "offsetEnd": 52}, "context": "SCOPE has been extended to combine SQL and MapReduce operators in a single language [40]. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.00015783309936523438}, "created": {"value": false, "score": 0.0009505152702331543}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9755048155784607}, "created": {"value": false, "score": 0.22964704036712646}, "shared": {"value": false, "score": 2.980232238769531e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LeanXcale", "normalizedForm": "LeanXcale", "offsetStart": 43, "offsetEnd": 52}, "context": "All the generated datasets were: loaded in LeanXcale as relational tables; loaded in MongoDB as document collections; copied to the HDFS cluster as raw CSV files, to be accessed through Hive as tables and through Spark by means of scans expressed as simple MFR/Scala statements.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9994305372238159}, "created": {"value": false, "score": 2.9206275939941406e-06}, "shared": {"value": false, "score": 5.364418029785156e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999398589134216}, "created": {"value": true, "score": 0.9999358057975769}, "shared": {"value": false, "score": 8.52346420288086e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SparkAgent", "normalizedForm": "SparkAgent", "offsetStart": 43, "offsetEnd": 53}, "context": "When tuples are received and deserialized, SparkAgent buffers them to a queue, from where they are pulled by the query engine through calls of the next() method of the wrapper instance.", "mentionContextAttributes": {"used": {"value": false, "score": 0.04876136779785156}, "created": {"value": false, "score": 9.47713851928711e-06}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.4153452515602112}, "created": {"value": false, "score": 0.00011998414993286133}, "shared": {"value": false, "score": 1.9669532775878906e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "AgentRegistry", "normalizedForm": "AgentRegistry", "offsetStart": 43, "offsetEnd": 56}, "context": "It requests from a common component, named AgentRegistry, the address of an available SparkAgent (waiting for such availability, if necessary) and makes a socket connection to it.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0005658864974975586}, "created": {"value": false, "score": 0.00011998414993286133}, "shared": {"value": false, "score": 1.9669532775878906e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.8473858833312988}, "created": {"value": false, "score": 0.010139226913452148}, "shared": {"value": false, "score": 1.9669532775878906e-06}}}, {"type": "software", "software-type": "software", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.3825, "software-name": {"rawForm": "Spark", "normalizedForm": "Spark", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.3825, "offsetStart": 44, "offsetEnd": 49}, "context": "Doing this in parallel and uniformly across Spark and query engine workers is the major challenge of the current extension of our work.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0001723766326904297}, "created": {"value": false, "score": 0.35488754510879517}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9997756481170654}, "shared": {"value": false, "score": 1.4841556549072266e-05}}}, {"type": "software", "software-type": "software", "wikidataId": "Q47607", "wikipediaExternalRef": 29004, "lang": "en", "confidence": 0.4606, "software-name": {"rawForm": "SQL", "normalizedForm": "SQL", "wikidataId": "Q47607", "wikipediaExternalRef": 29004, "lang": "en", "confidence": 0.4606, "offsetStart": 45, "offsetEnd": 48}, "context": "The SQL table expression T1 is defined by an SQL subquery, while T2 is a native expression (identified by the special bracket symbols {* *}) expressed as a native MongoDB API call or JavaScript code.", "mentionContextAttributes": {"used": {"value": false, "score": 0.05572474002838135}, "created": {"value": false, "score": 4.178285598754883e-05}, "shared": {"value": false, "score": 1.1324882507324219e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9934203028678894}, "shared": {"value": false, "score": 0.010259866714477539}}}, {"type": "software", "software-type": "software", "wikidataId": "Q460584", "wikipediaExternalRef": 3254510, "lang": "en", "confidence": 0.2001, "software-name": {"rawForm": "Scala", "normalizedForm": "Scala", "wikidataId": "Q460584", "wikipediaExternalRef": 3254510, "lang": "en", "confidence": 0.2001, "offsetStart": 45, "offsetEnd": 50}, "context": "To enable remote submission of the generated Scala script for Spark by the master wrapper, our setup relies on Apache Livy2 , which provides a REST service for easy submission of Spark jobs and Spark context management.", "mentionContextAttributes": {"used": {"value": false, "score": 0.13044798374176025}, "created": {"value": false, "score": 0.08340615034103394}, "shared": {"value": false, "score": 1.4841556549072266e-05}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999205470085144}, "created": {"value": true, "score": 0.9993940591812134}, "shared": {"value": false, "score": 1.4841556549072266e-05}}}, {"type": "software", "software-type": "software", "wikidataId": "Q1165204", "wikipediaExternalRef": 21855450, "lang": "en", "confidence": 0.7457, "software-name": {"rawForm": "MongoDB", "normalizedForm": "MongoDB", "wikidataId": "Q1165204", "wikipediaExternalRef": 21855450, "lang": "en", "confidence": 0.7457, "offsetStart": 45, "offsetEnd": 52}, "context": "The MongoDB storage allows running Drill and MongoDB together in distributed mode, by assigning shards to different drillbits to exploit parallelism.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0003085136413574219}, "created": {"value": false, "score": 5.8710575103759766e-05}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9999129176139832}, "shared": {"value": false, "score": 9.065866470336914e-05}}}, {"type": "software", "software-type": "software", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.3825, "software-name": {"rawForm": "Spark", "normalizedForm": "Spark", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.3825, "offsetStart": 46, "offsetEnd": 51}, "context": "To make the CLICKS dataset accessible by both Spark and LeanXcale, it is generated as an HDFS file. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.04405391216278076}, "created": {"value": false, "score": 7.146596908569336e-05}, "shared": {"value": false, "score": 6.556510925292969e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9997756481170654}, "shared": {"value": false, "score": 1.4841556549072266e-05}}}, {"type": "software", "software-type": "software", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.3825, "software-name": {"rawForm": "Spark", "normalizedForm": "Spark", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.3825, "offsetStart": 46, "offsetEnd": 51}, "context": "At this moment, the execution of the prepared Spark job gets initiated by calling through the same Livy session the following foreachPartition action function that makes each partition connect to an available wrapper instance and send its data: In this code, connectSparkAgent is a function that the master wrapper preliminarily generates and defines in the Livy session.", "mentionContextAttributes": {"used": {"value": false, "score": 0.02586996555328369}, "created": {"value": false, "score": 1.4126300811767578e-05}, "shared": {"value": false, "score": 1.0132789611816406e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9997756481170654}, "shared": {"value": false, "score": 1.4841556549072266e-05}}}, {"type": "software", "software-type": "software", "wikidataId": "Q460584", "wikipediaExternalRef": 3254510, "lang": "en", "confidence": 0.2001, "software-name": {"rawForm": "Scala", "normalizedForm": "Scala", "wikidataId": "Q460584", "wikipediaExternalRef": 3254510, "lang": "en", "confidence": 0.2001, "offsetStart": 47, "offsetEnd": 52}, "context": "PrepareScript is responsible for preparing the Scala script to be submitted as a Spark job and is active only at the master wrapper for a particular query.", "mentionContextAttributes": {"used": {"value": false, "score": 0.004101216793060303}, "created": {"value": false, "score": 0.00535207986831665}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999205470085144}, "created": {"value": true, "score": 0.9993940591812134}, "shared": {"value": false, "score": 1.4841556549072266e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LeanXcale", "normalizedForm": "LeanXcale", "offsetStart": 47, "offsetEnd": 56}, "context": "Performance benefits are noticeable when using LeanXcale with bind join, where smaller values of the selectivity factor SF result in shorter lists of outer keys for the bind join condition and hence faster execution of the BookOrders subquery.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0020302534103393555}, "created": {"value": false, "score": 1.5795230865478516e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999398589134216}, "created": {"value": true, "score": 0.9999358057975769}, "shared": {"value": false, "score": 8.52346420288086e-06}}}, {"type": "software", "software-type": "software", "wikidataId": "Q47607", "wikipediaExternalRef": 29004, "lang": "en", "confidence": 0.4606, "software-name": {"rawForm": "SQL", "normalizedForm": "SQL", "wikidataId": "Q47607", "wikipediaExternalRef": 29004, "lang": "en", "confidence": 0.4606, "offsetStart": 48, "offsetEnd": 51}, "context": "Normally, a transformation is expressed with an SQL-like expression that involves special variables; however, more specific transformations may be defined through the use of lambda functions.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0008026957511901855}, "created": {"value": false, "score": 6.514787673950195e-05}, "shared": {"value": false, "score": 5.364418029785156e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9934203028678894}, "shared": {"value": false, "score": 0.010259866714477539}}}, {"type": "software", "software-type": "software", "wikidataId": "Q1165204", "wikipediaExternalRef": 21855450, "lang": "en", "confidence": 0.7457, "software-name": {"rawForm": "MongoDB", "normalizedForm": "MongoDB", "wikidataId": "Q1165204", "wikipediaExternalRef": 21855450, "lang": "en", "confidence": 0.7457, "offsetStart": 48, "offsetEnd": 55}, "context": "Impala can access MongoDB collections through a MongoDB connector for Hadoop, designed to provide the ability to read MongoDB data into Hadoop MapReduce jobs.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0019541382789611816}, "created": {"value": false, "score": 0.0012637972831726074}, "shared": {"value": false, "score": 9.065866470336914e-05}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9999129176139832}, "shared": {"value": false, "score": 9.065866470336914e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CloudMdsQL", "normalizedForm": "CloudMdsQL", "offsetStart": 48, "offsetEnd": 58}, "context": "To illustrate it, let us consider the following CloudMdsQL query:", "mentionContextAttributes": {"used": {"value": false, "score": 0.06672519445419312}, "created": {"value": false, "score": 0.0001842975616455078}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.10021162033081055}, "created": {"value": true, "score": 0.9999358057975769}, "shared": {"value": false, "score": 2.3245811462402344e-06}}, "references": [{"label": "[26]", "normalizedForm": "[26]", "refKey": 26}, {"label": "[26]", "normalizedForm": "[26]", "refKey": 26}]}, {"type": "software", "software-type": "software", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.3825, "software-name": {"rawForm": "Spark", "normalizedForm": "Spark", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.3825, "offsetStart": 49, "offsetEnd": 54}, "context": "Intermediate result sets from MongoDB, HDFS, and Spark are retrieved in parallel, as described in Section 5. Fig. 8 shows the performance measurements on queries of the first test case, executing joins between LINEITEM and ORDERS tables in any configuration of pairs between the three data stores.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9919283390045166}, "created": {"value": false, "score": 7.927417755126953e-06}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9997756481170654}, "shared": {"value": false, "score": 1.4841556549072266e-05}}}, {"type": "software", "software-type": "software", "wikidataId": "Q1165204", "wikipediaExternalRef": 21855450, "lang": "en", "confidence": 0.7457, "software-name": {"rawForm": "MongoDB", "normalizedForm": "MongoDB", "wikidataId": "Q1165204", "wikipediaExternalRef": 21855450, "lang": "en", "confidence": 0.7457, "offsetStart": 50, "offsetEnd": 57}, "context": "The level of parallelism was set to 512, i.e. 512 MongoDB shards, 512 LeanXcale DQE instances, and 512 Spark executors.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9998719692230225}, "created": {"value": false, "score": 9.357929229736328e-06}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9999129176139832}, "shared": {"value": false, "score": 9.065866470336914e-05}}}, {"type": "software", "software-type": "implicit", "software-name": {"rawForm": "script", "normalizedForm": "script", "offsetStart": 51, "offsetEnd": 57}, "language": {"rawForm": "Scala", "normalizedForm": "Scala", "wikidataId": "Q460584", "offsetStart": 45, "offsetEnd": 50}, "context": "To enable remote submission of the generated Scala script for Spark by the master wrapper, our setup relies on Apache Livy2 , which provides a REST service for easy submission of Spark jobs and Spark context management. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.13044798374176025}, "created": {"value": false, "score": 0.08340615034103394}, "shared": {"value": false, "score": 1.4841556549072266e-05}}, "documentContextAttributes": {"used": {"value": true, "score": 0.919108510017395}, "created": {"value": true, "score": 0.9993940591812134}, "shared": {"value": false, "score": 1.4841556549072266e-05}}}, {"type": "software", "software-type": "software", "wikidataId": "Q1165204", "wikipediaExternalRef": 21855450, "lang": "en", "confidence": 0.7457, "software-name": {"rawForm": "MongoDB", "normalizedForm": "MongoDB", "wikidataId": "Q1165204", "wikipediaExternalRef": 21855450, "lang": "en", "confidence": 0.7457, "offsetStart": 51, "offsetEnd": 58}, "context": "Spark SQL can access a MongoDB cluster through its MongoDB connector that maps a sharded document collection to a Data-Frame, partitioned as per the collection's sharding setup.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0013504624366760254}, "created": {"value": false, "score": 2.5093555450439453e-05}, "shared": {"value": false, "score": 7.748603820800781e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9999129176139832}, "shared": {"value": false, "score": 9.065866470336914e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MapReduce", "normalizedForm": "MapReduce", "offsetStart": 52, "offsetEnd": 61}, "context": "In addition, HiveQL allows custom scripts, defining MapReduce jobs, to be referred in queries and used in combination with relational operators. ", "mentionContextAttributes": {"used": {"value": false, "score": 2.9981136322021484e-05}, "created": {"value": false, "score": 0.0003439188003540039}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9755048155784607}, "created": {"value": false, "score": 0.22964704036712646}, "shared": {"value": false, "score": 2.980232238769531e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LeanXcale", "normalizedForm": "LeanXcale", "offsetStart": 52, "offsetEnd": 61}, "context": "Then we discuss the distributed architecture of the LeanXcale query engine, which we use to enable the parallel capabilities of our polystore.", "mentionContextAttributes": {"used": {"value": false, "score": 0.007561743259429932}, "created": {"value": true, "score": 0.9993625283241272}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999398589134216}, "created": {"value": true, "score": 0.9999358057975769}, "shared": {"value": false, "score": 8.52346420288086e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "script", "normalizedForm": "script", "offsetStart": 53, "offsetEnd": 59}, "language": {"rawForm": "Scala", "normalizedForm": "Scala"}, "context": "PrepareScript is responsible for preparing the Scala script to be submitted as a Spark job and is active only at the master wrapper for a particular query.", "mentionContextAttributes": {"used": {"value": false, "score": 0.004101216793060303}, "created": {"value": false, "score": 0.00535207986831665}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.919108510017395}, "created": {"value": true, "score": 0.9993940591812134}, "shared": {"value": false, "score": 1.4841556549072266e-05}}}, {"type": "software", "software-type": "software", "wikidataId": "Q47607", "wikipediaExternalRef": 29004, "lang": "en", "confidence": 0.4606, "software-name": {"rawForm": "SQL", "normalizedForm": "SQL", "wikidataId": "Q47607", "wikipediaExternalRef": 29004, "lang": "en", "confidence": 0.4606, "offsetStart": 54, "offsetEnd": 57}, "context": "What Spark SQL is not capable of is bind join through SQL queries; to perform a bind join, one has to write a Spark program, which limits the use cases.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00010186433792114258}, "created": {"value": false, "score": 0.00010186433792114258}, "shared": {"value": false, "score": 4.172325134277344e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9934203028678894}, "shared": {"value": false, "score": 0.010259866714477539}}}, {"type": "software", "software-type": "software", "wikidataId": "Q29120", "wikipediaExternalRef": 5919308, "lang": "en", "confidence": 0.9056, "software-name": {"rawForm": "Hadoop", "normalizedForm": "Hadoop", "wikidataId": "Q29120", "wikipediaExternalRef": 5919308, "lang": "en", "confidence": 0.9056, "offsetStart": 54, "offsetEnd": 60}, "context": "As opposed to typical batch processing frameworks for Hadoop, Impala provides low latency and high concurrency for analytical queries. ", "mentionContextAttributes": {"used": {"value": false, "score": 3.0100345611572266e-05}, "created": {"value": false, "score": 0.0002315044403076172}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9755048155784607}, "created": {"value": false, "score": 0.10342800617218018}, "shared": {"value": false, "score": 0.010259866714477539}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "script", "normalizedForm": "script", "offsetStart": 54, "offsetEnd": 60}, "language": {"rawForm": "Scala", "normalizedForm": "Scala"}, "context": "The DQE initiates the subquery request by passing the script code to each wrapper instance through a call to its init() method.", "mentionContextAttributes": {"used": {"value": false, "score": 0.2090783715248108}, "created": {"value": false, "score": 7.349252700805664e-05}, "shared": {"value": false, "score": 4.172325134277344e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.919108510017395}, "created": {"value": true, "score": 0.9993940591812134}, "shared": {"value": false, "score": 1.4841556549072266e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LeanXcale", "normalizedForm": "LeanXcale", "offsetStart": 54, "offsetEnd": 63}, "context": "Moreover, joins across any native datasets, including LeanXcale tables, can be applied, exploiting efficient parallel join algorithms. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.00013780593872070312}, "created": {"value": false, "score": 0.006434738636016846}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999398589134216}, "created": {"value": true, "score": 0.9999358057975769}, "shared": {"value": false, "score": 8.52346420288086e-06}}}, {"type": "software", "software-type": "software", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.7879, "software-name": {"rawForm": "Apache Spark", "normalizedForm": "Apache Spark", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.7879, "offsetStart": 54, "offsetEnd": 66}, "context": "To address distributed processing frameworks (such as Apache Spark) as data stores, CloudMdsQL introduces a formal notation that enables the adhoc usage of user-defined map/filter/reduce (MFR) operators as subqueries to request data processing in an underlying big data processing framework [9]. ", "mentionContextAttributes": {"used": {"value": false, "score": 6.16908073425293e-05}, "created": {"value": false, "score": 0.0030756592750549316}, "shared": {"value": false, "score": 2.3245811462402344e-06}}, "documentContextAttributes": {"used": {"value": false, "score": 0.01917022466659546}, "created": {"value": true, "score": 0.7794421911239624}, "shared": {"value": false, "score": 4.470348358154297e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SparkAgent", "normalizedForm": "SparkAgent", "offsetStart": 55, "offsetEnd": 65}, "context": "Each wrapper instance is composed of PrepareScript and SparkAgent components. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.4153452515602112}, "created": {"value": false, "score": 4.786252975463867e-05}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.4153452515602112}, "created": {"value": false, "score": 0.00011998414993286133}, "shared": {"value": false, "score": 1.9669532775878906e-06}}}, {"type": "software", "software-type": "software", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.7879, "software-name": {"rawForm": "Apache Spark", "normalizedForm": "Apache Spark", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.7879, "offsetStart": 55, "offsetEnd": 67}, "context": "Spark SQL [6] is a parallel SQL engine built on top of Apache Spark and designed to provide tight integration between relational and procedural processing through a declarative API that integrates relational operators with procedural Spark code, taking advantage of massive parallelism. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.00022149085998535156}, "created": {"value": false, "score": 0.013364613056182861}, "shared": {"value": false, "score": 2.562999725341797e-06}}, "documentContextAttributes": {"used": {"value": false, "score": 0.01917022466659546}, "created": {"value": true, "score": 0.7794421911239624}, "shared": {"value": false, "score": 4.470348358154297e-06}}}, {"type": "software", "software-type": "software", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.5539, "software-name": {"rawForm": "Spark", "normalizedForm": "Spark", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.5539, "offsetStart": 56, "offsetEnd": 61}, "context": "Fig. 11 shows the times for processing Q3 queries: with Spark SQL, with LeanXcale without using bind join, and with LeanXcale using bind join. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9697527289390564}, "created": {"value": false, "score": 4.708766937255859e-06}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9997756481170654}, "shared": {"value": false, "score": 1.4841556549072266e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "REDUCE", "normalizedForm": "REDUCE", "offsetStart": 56, "offsetEnd": 62}, "context": "Each of the three major MFR operations (MAP, FILTER and REDUCE) takes as input a dataset and produces another dataset by performing the corresponding transformation. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.014665365219116211}, "created": {"value": false, "score": 2.5570392608642578e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9995518326759338}, "created": {"value": false, "score": 0.00020503997802734375}, "shared": {"value": false, "score": 2.4437904357910156e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LeanXcale", "normalizedForm": "LeanXcale", "offsetStart": 56, "offsetEnd": 65}, "context": "To make the CLICKS dataset accessible by both Spark and LeanXcale, it is generated as an HDFS file. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.04405391216278076}, "created": {"value": false, "score": 7.146596908569336e-05}, "shared": {"value": false, "score": 6.556510925292969e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999398589134216}, "created": {"value": true, "score": 0.9999358057975769}, "shared": {"value": false, "score": 8.52346420288086e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "API", "normalizedForm": "API", "offsetStart": 57, "offsetEnd": 60}, "context": "Therefore, a wrapper instance can use the Hive metastore API to get schema and partitioning information for the subqueried HDFS table and hence to enable iteration on a particular split (shard) of the table.", "mentionContextAttributes": {"used": {"value": false, "score": 0.013434112071990967}, "created": {"value": false, "score": 1.6748905181884766e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.05950498580932617}, "created": {"value": false, "score": 0.05537760257720947}, "shared": {"value": false, "score": 4.655122756958008e-05}}}, {"type": "software", "software-type": "software", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.3825, "software-name": {"rawForm": "Spark", "normalizedForm": "Spark", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.3825, "offsetStart": 57, "offsetEnd": 62}, "context": "We also apply our approach for parallel integration with Spark, together with its architectural and implementation details (Section 5.5). ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0016289949417114258}, "created": {"value": false, "score": 0.4057740569114685}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9997756481170654}, "shared": {"value": false, "score": 1.4841556549072266e-05}}}, {"type": "software", "software-type": "software", "wikidataId": "Q460584", "wikipediaExternalRef": 3254510, "lang": "en", "confidence": 0.2001, "software-name": {"rawForm": "Scala", "normalizedForm": "Scala", "wikidataId": "Q460584", "wikipediaExternalRef": 3254510, "lang": "en", "confidence": 0.2001, "offsetStart": 58, "offsetEnd": 63}, "context": "Execution times (in seconds) of Q2 queries on complex MFR/Scala queries to Spark with scales of data from 60 to 240 GB and levels of parallelism from 32 to 512.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9998712539672852}, "created": {"value": false, "score": 4.589557647705078e-06}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999205470085144}, "created": {"value": true, "score": 0.9993940591812134}, "shared": {"value": false, "score": 1.4841556549072266e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Apache", "normalizedForm": "Apache", "offsetStart": 58, "offsetEnd": 64}, "context": "As stated in Section 3, the major challenge of supporting Apache Spark as an underlying data management cluster is to enable parallel data movement from Spark workers to DataLake wrappers. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.00023484230041503906}, "created": {"value": false, "score": 0.021330654621124268}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.00023484230041503906}, "created": {"value": false, "score": 0.021330654621124268}, "shared": {"value": false, "score": 2.980232238769531e-07}}}, {"type": "software", "software-type": "software", "wikidataId": "Q1165204", "wikipediaExternalRef": 21855450, "lang": "en", "confidence": 0.7457, "software-name": {"rawForm": "MongoDB", "normalizedForm": "MongoDB", "wikidataId": "Q1165204", "wikipediaExternalRef": 21855450, "lang": "en", "confidence": 0.7457, "offsetStart": 58, "offsetEnd": 65}, "context": "To run an analogue of the BookOrders subquery through the MongoDB connector for Spark SQL, we used the MongoDB aggregation framework against the same sharded collection in our MongoDB cluster as follows:", "mentionContextAttributes": {"used": {"value": true, "score": 0.9997720718383789}, "created": {"value": false, "score": 9.375810623168945e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9999129176139832}, "shared": {"value": false, "score": 9.065866470336914e-05}}}, {"type": "software", "software-type": "software", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.3825, "software-name": {"rawForm": "Spark", "normalizedForm": "Spark", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.3825, "offsetStart": 59, "offsetEnd": 64}, "context": "To achieve this, the query engine creates a session at the Spark driver, then translates the MFR subquery to code (in Scala or Python for Spark), delegates this code to Spark for execution, and collects the intermediate data through the same Spark driver session.", "mentionContextAttributes": {"used": {"value": false, "score": 0.20863837003707886}, "created": {"value": false, "score": 9.888410568237305e-05}, "shared": {"value": false, "score": 5.364418029785156e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9997756481170654}, "shared": {"value": false, "score": 1.4841556549072266e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "script", "normalizedForm": "script", "offsetStart": 59, "offsetEnd": 65}, "language": {"rawForm": "Scala", "normalizedForm": "Scala"}, "context": "The method init(ScriptContext) requests the execution of a script to retrieve data from the data store.", "mentionContextAttributes": {"used": {"value": false, "score": 0.10563725233078003}, "created": {"value": false, "score": 6.0617923736572266e-05}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.919108510017395}, "created": {"value": true, "score": 0.9993940591812134}, "shared": {"value": false, "score": 1.4841556549072266e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Pig/Hive code", "normalizedForm": "Pig/Hive code", "offsetStart": 59, "offsetEnd": 72}, "context": "It produces SQL statements for relational data stores, and Pig/Hive code for interfacing Hadoop to access HDFS data. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.00014781951904296875}, "created": {"value": false, "score": 0.0006139874458312988}, "shared": {"value": false, "score": 1.4901161193847656e-06}}, "documentContextAttributes": {"used": {"value": false, "score": 0.00014781951904296875}, "created": {"value": false, "score": 0.0006139874458312988}, "shared": {"value": false, "score": 1.4901161193847656e-06}}}, {"type": "software", "software-type": "software", "wikidataId": "Q1165204", "wikipediaExternalRef": 21855450, "lang": "en", "confidence": 0.7457, "software-name": {"rawForm": "MongoDB", "normalizedForm": "MongoDB", "wikidataId": "Q1165204", "wikipediaExternalRef": 21855450, "lang": "en", "confidence": 0.7457, "offsetStart": 60, "offsetEnd": 67}, "context": "In this section, we introduce the design of the distributed MongoDB wrapper. ", "mentionContextAttributes": {"used": {"value": false, "score": 4.416704177856445e-05}, "created": {"value": true, "score": 0.9999129176139832}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9999129176139832}, "shared": {"value": false, "score": 9.065866470336914e-05}}}, {"type": "software", "software-type": "software", "wikidataId": "Q187432", "wikipediaExternalRef": 21490336, "lang": "en", "confidence": 0.5074, "software-name": {"rawForm": "scripts", "normalizedForm": "scripts", "wikidataId": "Q187432", "wikipediaExternalRef": 21490336, "lang": "en", "confidence": 0.5074, "offsetStart": 60, "offsetEnd": 67}, "context": "To better illustrate the necessity of enabling user-defined scripts to MongoDB as subqueries, rather than defining SQL mappings to document collections, let us consider the following MongoDB collection orders that has a highly non-relational structure:", "mentionContextAttributes": {"used": {"value": false, "score": 0.00022840499877929688}, "created": {"value": false, "score": 0.0009966492652893066}, "shared": {"value": false, "score": 5.364418029785156e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.0027613043785095215}, "created": {"value": true, "score": 0.9998281002044678}, "shared": {"value": false, "score": 2.3245811462402344e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "code", "normalizedForm": "code", "offsetStart": 61, "offsetEnd": 65}, "context": "The DQE initiates the subquery request by passing the script code to each wrapper instance through a call to its init() method.", "mentionContextAttributes": {"used": {"value": false, "score": 0.2090783715248108}, "created": {"value": false, "score": 7.349252700805664e-05}, "shared": {"value": false, "score": 4.172325134277344e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.919108510017395}, "created": {"value": true, "score": 0.9997756481170654}, "shared": {"value": false, "score": 2.562999725341797e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "script", "normalizedForm": "script", "offsetStart": 61, "offsetEnd": 67}, "language": {"rawForm": "Scala", "normalizedForm": "Scala"}, "context": "Normally, the wrapper does not initiate the execution of the script before a shard is assigned by the setShard method (see below).", "mentionContextAttributes": {"used": {"value": false, "score": 0.002154111862182617}, "created": {"value": false, "score": 8.660554885864258e-05}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.919108510017395}, "created": {"value": true, "score": 0.9993940591812134}, "shared": {"value": false, "score": 1.4841556549072266e-05}}}, {"type": "software", "software-type": "software", "wikidataId": "Q47607", "wikipediaExternalRef": 29004, "lang": "en", "confidence": 0.4606, "software-name": {"rawForm": "SQL", "normalizedForm": "SQL", "wikidataId": "Q47607", "wikipediaExternalRef": 29004, "lang": "en", "confidence": 0.4606, "offsetStart": 62, "offsetEnd": 65}, "context": "A named table expression can be defined by means of either an SQL SELECT statement (that the query compiler is able to analyze and possibly rewrite) or a native expression (that the query engine considers as a black box and delegates its processing directly to the data store).", "mentionContextAttributes": {"used": {"value": false, "score": 0.0008913278579711914}, "created": {"value": false, "score": 0.00023436546325683594}, "shared": {"value": false, "score": 1.6093254089355469e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9934203028678894}, "shared": {"value": false, "score": 0.010259866714477539}}}, {"type": "software", "software-type": "software", "wikidataId": "Q47607", "wikipediaExternalRef": 29004, "lang": "en", "confidence": 0.4606, "software-name": {"rawForm": "SQL", "normalizedForm": "SQL", "wikidataId": "Q47607", "wikipediaExternalRef": 29004, "lang": "en", "confidence": 0.4606, "offsetStart": 62, "offsetEnd": 65}, "context": "Fig. 11 shows the times for processing Q3 queries: with Spark SQL, with LeanXcale without using bind join, and with LeanXcale using bind join.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9697527289390564}, "created": {"value": false, "score": 4.708766937255859e-06}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9934203028678894}, "shared": {"value": false, "score": 0.010259866714477539}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Hive", "normalizedForm": "Hive", "offsetStart": 62, "offsetEnd": 66}, "context": "HiveQL is the query language of the data warehousing solution Hive, built on top of Hadoop MapReduce [35]. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0028700828552246094}, "created": {"value": false, "score": 7.50422477722168e-05}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999398589134216}, "created": {"value": false, "score": 0.0001316070556640625}, "shared": {"value": false, "score": 5.662441253662109e-06}}}, {"type": "software", "software-type": "software", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.3825, "software-name": {"rawForm": "Spark", "normalizedForm": "Spark", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.3825, "offsetStart": 62, "offsetEnd": 67}, "context": "To enable remote submission of the generated Scala script for Spark by the master wrapper, our setup relies on Apache Livy2 , which provides a REST service for easy submission of Spark jobs and Spark context management.", "mentionContextAttributes": {"used": {"value": false, "score": 0.13044798374176025}, "created": {"value": false, "score": 0.08340615034103394}, "shared": {"value": false, "score": 1.4841556549072266e-05}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9997756481170654}, "shared": {"value": false, "score": 1.4841556549072266e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "AgentRegistry", "normalizedForm": "AgentRegistry", "offsetStart": 62, "offsetEnd": 75}, "context": "The coordinating components for the Spark subsystem, Livy and AgentRegistry, are running on one of the nodes. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.8473858833312988}, "created": {"value": false, "score": 0.010139226913452148}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.8473858833312988}, "created": {"value": false, "score": 0.010139226913452148}, "shared": {"value": false, "score": 1.9669532775878906e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Apache Calcite", "normalizedForm": "Apache Calcite", "offsetStart": 62, "offsetEnd": 79}, "context": "The LeanXcale database has derived its OLAP query engine from Apache Calcite [8], a Java-based open-source framework for SQL query processing and optimization. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.6484044790267944}, "created": {"value": false, "score": 0.00020933151245117188}, "shared": {"value": false, "score": 8.52346420288086e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.6484044790267944}, "created": {"value": false, "score": 0.00020933151245117188}, "shared": {"value": false, "score": 8.52346420288086e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CloudMdsQL", "normalizedForm": "CloudMdsQL", "offsetStart": 63, "offsetEnd": 73}, "context": "\u2022 Highly expressive queries: adopt he polyglot approach of the CloudMdsQL query language to allow data store native queries or scripts to be expressed as inline subqueries.", "mentionContextAttributes": {"used": {"value": false, "score": 2.7477741241455078e-05}, "created": {"value": false, "score": 0.0054280757904052734}, "shared": {"value": false, "score": 4.172325134277344e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.10021162033081055}, "created": {"value": true, "score": 0.9999358057975769}, "shared": {"value": false, "score": 2.3245811462402344e-06}}, "references": [{"label": "[26]", "normalizedForm": "[26]", "refKey": 26}, {"label": "[26]", "normalizedForm": "[26]", "refKey": 26}]}, {"type": "software", "software-type": "software", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.3825, "software-name": {"rawForm": "Spark", "normalizedForm": "Spark", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.3825, "offsetStart": 64, "offsetEnd": 69}, "context": "This allows for distributed data processing frameworks, such as Spark, to be supported by the DQE.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00013184547424316406}, "created": {"value": false, "score": 0.09245723485946655}, "shared": {"value": false, "score": 1.0132789611816406e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9997756481170654}, "shared": {"value": false, "score": 1.4841556549072266e-05}}}, {"type": "software", "software-type": "software", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.3825, "software-name": {"rawForm": "Spark", "normalizedForm": "Spark", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.3825, "offsetStart": 64, "offsetEnd": 69}, "context": "A discovery service is introduced through the special component Spark Agent Registry that keeps information about available Spark wrapper instances and dispatches them to the requesting Spark workers so that parallelism is fully exploited in moving data from a Spark RDD to the DQE.", "mentionContextAttributes": {"used": {"value": false, "score": 0.005214571952819824}, "created": {"value": false, "score": 0.003361940383911133}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9997756481170654}, "shared": {"value": false, "score": 1.4841556549072266e-05}}}, {"type": "software", "software-type": "software", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.3825, "software-name": {"rawForm": "Spark", "normalizedForm": "Spark", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.3825, "offsetStart": 64, "offsetEnd": 69}, "context": "SparkAgent is the component, which accepts TCP connections from Spark executors to push RDD partition data.", "mentionContextAttributes": {"used": {"value": false, "score": 0.045781731605529785}, "created": {"value": false, "score": 7.873773574829102e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9997756481170654}, "shared": {"value": false, "score": 1.4841556549072266e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LeanXcale", "normalizedForm": "LeanXcale", "offsetStart": 64, "offsetEnd": 73}, "context": "For example, Q1 ML joins LINEITEM from MongoDB with ORDERS from LeanXcale.", "mentionContextAttributes": {"used": {"value": false, "score": 0.005032062530517578}, "created": {"value": false, "score": 4.231929779052734e-06}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999398589134216}, "created": {"value": true, "score": 0.9999358057975769}, "shared": {"value": false, "score": 8.52346420288086e-06}}}, {"type": "software", "software-type": "software", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.3825, "software-name": {"rawForm": "Spark", "normalizedForm": "Spark", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.3825, "offsetStart": 65, "offsetEnd": 70}, "context": "As stated in Section 3, the major challenge of supporting Apache Spark as an underlying data management cluster is to enable parallel data movement from Spark workers to DataLake wrappers.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00023484230041503906}, "created": {"value": false, "score": 0.021330654621124268}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9997756481170654}, "shared": {"value": false, "score": 1.4841556549072266e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "script", "normalizedForm": "script", "offsetStart": 65, "offsetEnd": 71}, "language": {"rawForm": "Scala", "normalizedForm": "Scala"}, "context": "It provides connection details to address the data store and the script as text.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00011593103408813477}, "created": {"value": false, "score": 0.009908497333526611}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.919108510017395}, "created": {"value": true, "score": 0.9993940591812134}, "shared": {"value": false, "score": 1.4841556549072266e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Warehouse", "normalizedForm": "Warehouse", "offsetStart": 65, "offsetEnd": 74}, "context": "Polybase [15] is a feature of Microsoft SQL Server Parallel Data Warehouse to access HDFS data using SQL. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.00020503997802734375}, "created": {"value": false, "score": 2.2590160369873047e-05}, "shared": {"value": false, "score": 5.900859832763672e-06}}, "documentContextAttributes": {"used": {"value": false, "score": 0.00020503997802734375}, "created": {"value": false, "score": 2.2590160369873047e-05}, "shared": {"value": false, "score": 5.900859832763672e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "script", "normalizedForm": "script", "offsetStart": 66, "offsetEnd": 72}, "language": {"rawForm": "Scala", "normalizedForm": "Scala"}, "context": "\u2022 A wrapper instance must be able to execute a native subquery or script against a particular shard of the underlying data store cluster.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00017142295837402344}, "created": {"value": false, "score": 6.22868537902832e-05}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.919108510017395}, "created": {"value": true, "score": 0.9993940591812134}, "shared": {"value": false, "score": 1.4841556549072266e-05}}}, {"type": "software", "software-type": "software", "wikidataId": "Q1165204", "wikipediaExternalRef": 21855450, "lang": "en", "confidence": 0.7457, "software-name": {"rawForm": "MongoDB", "normalizedForm": "MongoDB", "wikidataId": "Q1165204", "wikipediaExternalRef": 21855450, "lang": "en", "confidence": 0.7457, "offsetStart": 66, "offsetEnd": 73}, "context": "The findSharded() method accepts the same arguments as the native MongoDB find() operator, in order to provide the native flexible querying functionality, complemented with the ability to handle parallel iteration on the sharded result set.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00013494491577148438}, "created": {"value": false, "score": 4.082918167114258e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9999129176139832}, "shared": {"value": false, "score": 9.065866470336914e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LeanXcale", "normalizedForm": "LeanXcale", "offsetStart": 66, "offsetEnd": 75}, "context": "Without bind join, Spark SQL shows a slight advantage compared to LeanXcale DQE, which is explainable by the overhead of the JavaScript interpreting that takes place at DQE wrappers for MongoDB. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.00408935546875}, "created": {"value": false, "score": 6.735324859619141e-06}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999398589134216}, "created": {"value": true, "score": 0.9999358057975769}, "shared": {"value": false, "score": 8.52346420288086e-06}}}, {"type": "software", "software-type": "software", "wikidataId": "Q47607", "wikipediaExternalRef": 29004, "lang": "en", "confidence": 0.4606, "software-name": {"rawForm": "SQL", "normalizedForm": "SQL", "wikidataId": "Q47607", "wikipediaExternalRef": 29004, "lang": "en", "confidence": 0.4606, "offsetStart": 67, "offsetEnd": 70}, "context": "With GQL, the task is achievable because it represents a subset of SQL.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0007592439651489258}, "created": {"value": false, "score": 0.00015854835510253906}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9934203028678894}, "shared": {"value": false, "score": 0.010259866714477539}}}, {"type": "software", "software-type": "software", "wikidataId": "Q47607", "wikipediaExternalRef": 29004, "lang": "en", "confidence": 0.4606, "software-name": {"rawForm": "SQL", "normalizedForm": "SQL", "wikidataId": "Q47607", "wikipediaExternalRef": 29004, "lang": "en", "confidence": 0.4606, "offsetStart": 67, "offsetEnd": 70}, "context": "This can facilitate the work of data analysts who just need to run SQL queries on predefined views over the underlying data stores, without the need to deeply understand the specifics of the data technologies and data organization.", "mentionContextAttributes": {"used": {"value": false, "score": 3.451108932495117e-05}, "created": {"value": false, "score": 0.01360863447189331}, "shared": {"value": false, "score": 4.172325134277344e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9934203028678894}, "shared": {"value": false, "score": 0.010259866714477539}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Hive", "normalizedForm": "Hive", "offsetStart": 67, "offsetEnd": 71}, "context": "We assume that each accessed HDFS file is registered as table in a Hive metastore.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9806445837020874}, "created": {"value": false, "score": 0.00011485815048217773}, "shared": {"value": false, "score": 5.662441253662109e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999398589134216}, "created": {"value": false, "score": 0.0001316070556640625}, "shared": {"value": false, "score": 5.662441253662109e-06}}}, {"type": "software", "software-type": "software", "wikidataId": "Q29120", "wikipediaExternalRef": 5919308, "lang": "en", "confidence": 0.9056, "software-name": {"rawForm": "Hadoop", "normalizedForm": "Hadoop", "wikidataId": "Q29120", "wikipediaExternalRef": 5919308, "lang": "en", "confidence": 0.9056, "offsetStart": 67, "offsetEnd": 73}, "context": "Impala [5] is an open-source distributed SQL engine operating over Hadoop data processing environment. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.001991748809814453}, "created": {"value": false, "score": 1.615285873413086e-05}, "shared": {"value": false, "score": 0.010259866714477539}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9755048155784607}, "created": {"value": false, "score": 0.10342800617218018}, "shared": {"value": false, "score": 0.010259866714477539}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "script", "normalizedForm": "script", "offsetStart": 67, "offsetEnd": 73}, "language": {"rawForm": "Scala", "normalizedForm": "Scala"}, "context": "Query Q2 M evaluates just the parallel execution of the BookOrders script in MongoDB, while Q2 ML involves a join between MongoDB and the CUSTOMER table from the LeanXcale data store: Fig. 9 shows the performance measurements of Q2 queries that stress on the evaluation of the parallel processing of highly expressive JavaScript queries, with and without join with a LeanXcale table.", "mentionContextAttributes": {"used": {"value": true, "score": 0.7139508724212646}, "created": {"value": false, "score": 3.159046173095703e-06}, "shared": {"value": false, "score": 1.0132789611816406e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.919108510017395}, "created": {"value": true, "score": 0.9993940591812134}, "shared": {"value": false, "score": 1.4841556549072266e-05}}}, {"type": "software", "software-type": "implicit", "wikidataId": "Q187432", "wikipediaExternalRef": 21490336, "lang": "en", "confidence": 0.5074, "software-name": {"rawForm": "scripts", "normalizedForm": "scripts", "wikidataId": "Q187432", "wikipediaExternalRef": 21490336, "lang": "en", "confidence": 0.5074, "offsetStart": 67, "offsetEnd": 74}, "context": "This allows data store native subqueries to be expressed as inline scripts and combined with regular SQL statements in ad-hoc integration statements. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.00016188621520996094}, "created": {"value": false, "score": 0.0001990795135498047}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.0027613043785095215}, "created": {"value": true, "score": 0.9998281002044678}, "shared": {"value": false, "score": 2.3245811462402344e-06}}}, {"type": "software", "software-type": "software", "wikidataId": "Q187432", "wikipediaExternalRef": 21490336, "lang": "en", "confidence": 0.5074, "software-name": {"rawForm": "scripts", "normalizedForm": "scripts", "wikidataId": "Q187432", "wikipediaExternalRef": 21490336, "lang": "en", "confidence": 0.5074, "offsetStart": 67, "offsetEnd": 74}, "context": "We introduced architectural extensions that enable specific native scripts to be handled in parallel at data store shards, so that efficient and scalable parallel joins take place at query engine level.", "mentionContextAttributes": {"used": {"value": false, "score": 6.920099258422852e-05}, "created": {"value": true, "score": 0.9998281002044678}, "shared": {"value": false, "score": 4.172325134277344e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.0027613043785095215}, "created": {"value": true, "score": 0.9998281002044678}, "shared": {"value": false, "score": 2.3245811462402344e-06}}}, {"type": "software", "software-type": "software", "wikidataId": "Q47607", "wikipediaExternalRef": 29004, "lang": "en", "confidence": 0.4606, "software-name": {"rawForm": "SQL", "normalizedForm": "SQL", "wikidataId": "Q47607", "wikipediaExternalRef": 29004, "lang": "en", "confidence": 0.4606, "offsetStart": 68, "offsetEnd": 71}, "context": "With respect to combining SQL and map/reduce operators, a number of SQL-like query languages have been introduced.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0001055598258972168}, "created": {"value": false, "score": 0.012389957904815674}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9934203028678894}, "shared": {"value": false, "score": 0.010259866714477539}}}, {"type": "software", "software-type": "software", "wikidataId": "Q47607", "wikipediaExternalRef": 29004, "lang": "en", "confidence": 0.4606, "software-name": {"rawForm": "SQL", "normalizedForm": "SQL", "wikidataId": "Q47607", "wikipediaExternalRef": 29004, "lang": "en", "confidence": 0.4606, "offsetStart": 69, "offsetEnd": 72}, "context": "An important problem the system focuses on is the cost estimation of SQL operators over remote systems.", "mentionContextAttributes": {"used": {"value": false, "score": 6.0617923736572266e-05}, "created": {"value": false, "score": 0.0021062493324279785}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9934203028678894}, "shared": {"value": false, "score": 0.010259866714477539}}}, {"type": "software", "software-type": "software", "wikidataId": "Q47607", "wikipediaExternalRef": 29004, "lang": "en", "confidence": 0.4606, "software-name": {"rawForm": "SQL", "normalizedForm": "SQL", "wikidataId": "Q47607", "wikipediaExternalRef": 29004, "lang": "en", "confidence": 0.4606, "offsetStart": 69, "offsetEnd": 72}, "context": "In particular, the parallel query processing with bind joins through SQL queries is not supported by any of the hybrid systems.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0038103461265563965}, "created": {"value": false, "score": 6.622076034545898e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9934203028678894}, "shared": {"value": false, "score": 0.010259866714477539}}}, {"type": "software", "software-type": "software", "wikidataId": "Q460584", "wikipediaExternalRef": 3254510, "lang": "en", "confidence": 0.2001, "software-name": {"rawForm": "Scala", "normalizedForm": "Scala", "wikidataId": "Q460584", "wikipediaExternalRef": 3254510, "lang": "en", "confidence": 0.2001, "offsetStart": 69, "offsetEnd": 74}, "context": "This can be expressed with the following MFR subquery, with embedded Scala lambda functions to define custom transformation logic: In this sequence of operations, the first MAP takes a tuple (corresponding to a row from the input file) as an array of string values (tup) and maps the username (tup(2)) to the keywords subarray (tup.slice(\u2026)).", "mentionContextAttributes": {"used": {"value": true, "score": 0.5007940530776978}, "created": {"value": false, "score": 6.139278411865234e-06}, "shared": {"value": false, "score": 1.2516975402832031e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999205470085144}, "created": {"value": true, "score": 0.9993940591812134}, "shared": {"value": false, "score": 1.4841556549072266e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MapReduce", "normalizedForm": "MapReduce", "offsetStart": 69, "offsetEnd": 78}, "context": "Let us consider the following simple example inspired by the popular MapReduce tutorial application \"word count\". ", "mentionContextAttributes": {"used": {"value": false, "score": 0.00023603439331054688}, "created": {"value": false, "score": 0.22964704036712646}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9755048155784607}, "created": {"value": false, "score": 0.22964704036712646}, "shared": {"value": false, "score": 2.980232238769531e-07}}}, {"type": "software", "software-type": "software", "wikidataId": "Q460584", "wikipediaExternalRef": 3254510, "lang": "en", "confidence": 0.2001, "software-name": {"rawForm": "Scala", "normalizedForm": "Scala", "wikidataId": "Q460584", "wikipediaExternalRef": 3254510, "lang": "en", "confidence": 0.2001, "offsetStart": 70, "offsetEnd": 75}, "context": "Then, the PrepareScript component of the master wrapper generates the Scala code that corresponds to the MFR query, to initialize a variable named rdd: val rdd = sc.textFile( ", "mentionContextAttributes": {"used": {"value": false, "score": 0.19873660802841187}, "created": {"value": false, "score": 2.008676528930664e-05}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999205470085144}, "created": {"value": true, "score": 0.9993940591812134}, "shared": {"value": false, "score": 1.4841556549072266e-05}}}, {"type": "software", "software-type": "software", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.3825, "software-name": {"rawForm": "Spark", "normalizedForm": "Spark", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.3825, "offsetStart": 70, "offsetEnd": 75}, "context": "In general, the execution of these queries is much slower, as, at the Spark level, it involves shuffles of significant amounts of intermediate data.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0011292695999145508}, "created": {"value": false, "score": 5.9664249420166016e-05}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9997756481170654}, "shared": {"value": false, "score": 1.4841556549072266e-05}}}, {"type": "software", "software-type": "software", "wikidataId": "Q29120", "wikipediaExternalRef": 5919308, "lang": "en", "confidence": 0.9056, "software-name": {"rawForm": "Hadoop", "normalizedForm": "Hadoop", "wikidataId": "Q29120", "wikipediaExternalRef": 5919308, "lang": "en", "confidence": 0.9056, "offsetStart": 70, "offsetEnd": 76}, "context": "Impala can access MongoDB collections through a MongoDB connector for Hadoop, designed to provide the ability to read MongoDB data into Hadoop MapReduce jobs.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0019541382789611816}, "created": {"value": false, "score": 0.0012637972831726074}, "shared": {"value": false, "score": 9.065866470336914e-05}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9755048155784607}, "created": {"value": false, "score": 0.10342800617218018}, "shared": {"value": false, "score": 0.010259866714477539}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LeanXcale", "normalizedForm": "LeanXcale", "offsetStart": 70, "offsetEnd": 79}, "context": "The level of parallelism was set to 512, i.e. 512 MongoDB shards, 512 LeanXcale DQE instances, and 512 Spark executors.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9998719692230225}, "created": {"value": false, "score": 9.357929229736328e-06}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999398589134216}, "created": {"value": true, "score": 0.9999358057975769}, "shared": {"value": false, "score": 8.52346420288086e-06}}}, {"type": "software", "software-type": "software", "wikidataId": "Q1165204", "wikipediaExternalRef": 21855450, "lang": "en", "confidence": 0.7457, "software-name": {"rawForm": "MongoDB", "normalizedForm": "MongoDB", "wikidataId": "Q1165204", "wikipediaExternalRef": 21855450, "lang": "en", "confidence": 0.7457, "offsetStart": 71, "offsetEnd": 78}, "context": "To better illustrate the necessity of enabling user-defined scripts to MongoDB as subqueries, rather than defining SQL mappings to document collections, let us consider the following MongoDB collection orders that has a highly non-relational structure:", "mentionContextAttributes": {"used": {"value": false, "score": 0.00022840499877929688}, "created": {"value": false, "score": 0.0009966492652893066}, "shared": {"value": false, "score": 5.364418029785156e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9999129176139832}, "shared": {"value": false, "score": 9.065866470336914e-05}}}, {"type": "software", "software-type": "software", "wikidataId": "Q47607", "wikipediaExternalRef": 29004, "lang": "en", "confidence": 0.4606, "software-name": {"rawForm": "SQL", "normalizedForm": "SQL", "wikidataId": "Q47607", "wikipediaExternalRef": 29004, "lang": "en", "confidence": 0.4606, "offsetStart": 72, "offsetEnd": 75}, "context": "And third, the query needs to be expressive enough, so as to combine an SQL subquery (to the relational database) with an arbitrary code in a scripting language (e.g. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.055995404720306396}, "created": {"value": false, "score": 5.322694778442383e-05}, "shared": {"value": false, "score": 4.172325134277344e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9934203028678894}, "shared": {"value": false, "score": 0.010259866714477539}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LeanXcale", "normalizedForm": "LeanXcale", "offsetStart": 72, "offsetEnd": 81}, "context": "Fig. 11 shows the times for processing Q3 queries: with Spark SQL, with LeanXcale without using bind join, and with LeanXcale using bind join. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9697527289390564}, "created": {"value": false, "score": 4.708766937255859e-06}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999398589134216}, "created": {"value": true, "score": 0.9999358057975769}, "shared": {"value": false, "score": 8.52346420288086e-06}}}, {"type": "software", "software-type": "implicit", "software-name": {"rawForm": "script engines", "normalizedForm": "script engines", "offsetStart": 72, "offsetEnd": 86}, "context": "The concept relies on an API that allows its generalization to multiple script engines and data stores. ", "mentionContextAttributes": {"used": {"value": false, "score": 4.0590763092041016e-05}, "created": {"value": false, "score": 0.03523397445678711}, "shared": {"value": false, "score": 1.0132789611816406e-06}}, "documentContextAttributes": {"used": {"value": false, "score": 0.0018170475959777832}, "created": {"value": false, "score": 0.05537760257720947}, "shared": {"value": false, "score": 1.1324882507324219e-06}}}, {"type": "software", "software-type": "software", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.3825, "software-name": {"rawForm": "Spark", "normalizedForm": "Spark", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.3825, "offsetStart": 73, "offsetEnd": 78}, "context": "On the other hand, as described above, when processing a partition, each Spark executor finds and sends to an available Spark agent all tuples of the partition.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0023292899131774902}, "created": {"value": false, "score": 4.678964614868164e-05}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9997756481170654}, "shared": {"value": false, "score": 1.4841556549072266e-05}}}, {"type": "software", "software-type": "software", "wikidataId": "Q47607", "wikipediaExternalRef": 29004, "lang": "en", "confidence": 0.4606, "software-name": {"rawForm": "SQL", "normalizedForm": "SQL", "wikidataId": "Q47607", "wikipediaExternalRef": 29004, "lang": "en", "confidence": 0.4606, "offsetStart": 74, "offsetEnd": 77}, "context": "But they are limited to accessing only specific data stores, usually with SQL mappings of the data stores' query interfaces.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00019073486328125}, "created": {"value": false, "score": 0.0002970695495605469}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9934203028678894}, "shared": {"value": false, "score": 0.010259866714477539}}}, {"type": "software", "software-type": "software", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.3825, "software-name": {"rawForm": "Spark", "normalizedForm": "Spark", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.3825, "offsetStart": 75, "offsetEnd": 80}, "context": "Fig. 12 shows the times for processing Q4 queries, involving 2 joins: with Spark SQL, with LeanXcale without using bind join, and with LeanXcale using bind join. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.986201822757721}, "created": {"value": false, "score": 1.1026859283447266e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9997756481170654}, "shared": {"value": false, "score": 1.4841556549072266e-05}}}, {"type": "software", "software-type": "software", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.3825, "software-name": {"rawForm": "Spark", "normalizedForm": "Spark", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.3825, "offsetStart": 75, "offsetEnd": 80}, "context": "Execution times (in seconds) of Q2 queries on complex MFR/Scala queries to Spark with scales of data from 60 to 240 GB and levels of parallelism from 32 to 512.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9998712539672852}, "created": {"value": false, "score": 4.589557647705078e-06}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9997756481170654}, "shared": {"value": false, "score": 1.4841556549072266e-05}}}, {"type": "software", "software-type": "software", "wikidataId": "Q47607", "wikipediaExternalRef": 29004, "lang": "en", "confidence": 0.4606, "software-name": {"rawForm": "SQL", "normalizedForm": "SQL", "wikidataId": "Q47607", "wikipediaExternalRef": 29004, "lang": "en", "confidence": 0.4606, "offsetStart": 76, "offsetEnd": 79}, "context": "It interfaces MapReduce with RDBMS through database connectors that execute SQL queries to return key-value pairs.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00026595592498779297}, "created": {"value": false, "score": 8.70823860168457e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9934203028678894}, "shared": {"value": false, "score": 0.010259866714477539}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "code", "normalizedForm": "code", "offsetStart": 76, "offsetEnd": 80}, "context": "Then, the PrepareScript component of the master wrapper generates the Scala code that corresponds to the MFR query, to initialize a variable named rdd: val rdd = sc.textFile( ", "mentionContextAttributes": {"used": {"value": false, "score": 0.19873660802841187}, "created": {"value": false, "score": 2.008676528930664e-05}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.919108510017395}, "created": {"value": true, "score": 0.9997756481170654}, "shared": {"value": false, "score": 2.562999725341797e-06}}}, {"type": "software", "software-type": "software", "wikidataId": "Q460584", "wikipediaExternalRef": 3254510, "lang": "en", "confidence": 0.591, "software-name": {"rawForm": "Scala", "normalizedForm": "Scala", "wikidataId": "Q460584", "wikipediaExternalRef": 3254510, "lang": "en", "confidence": 0.591, "offsetStart": 76, "offsetEnd": 81}, "context": "MFR subqueries to Spark are defined as single SCAN operators, translated to Scala commands. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.011382699012756348}, "created": {"value": false, "score": 6.377696990966797e-06}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999205470085144}, "created": {"value": true, "score": 0.9993940591812134}, "shared": {"value": false, "score": 1.4841556549072266e-05}}}, {"type": "software", "software-type": "software", "wikidataId": "Q1165204", "wikipediaExternalRef": 21855450, "lang": "en", "confidence": 0.7457, "software-name": {"rawForm": "MongoDB", "normalizedForm": "MongoDB", "wikidataId": "Q1165204", "wikipediaExternalRef": 21855450, "lang": "en", "confidence": 0.7457, "offsetStart": 76, "offsetEnd": 83}, "context": "Although these systems enable parallel integration with data clusters (like MongoDB), none of them supports the combination of massive parallelism with native queries and the optimization of bind joins, which is addressed by the LeanXcale distributed query engine.", "mentionContextAttributes": {"used": {"value": false, "score": 4.6193599700927734e-05}, "created": {"value": false, "score": 0.0024118423461914062}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9999129176139832}, "shared": {"value": false, "score": 9.065866470336914e-05}}}, {"type": "software", "software-type": "software", "wikidataId": "Q1165204", "wikipediaExternalRef": 21855450, "lang": "en", "confidence": 0.7457, "software-name": {"rawForm": "MongoDB", "normalizedForm": "MongoDB", "wikidataId": "Q1165204", "wikipediaExternalRef": 21855450, "lang": "en", "confidence": 0.7457, "offsetStart": 76, "offsetEnd": 83}, "context": "The list of shards is then reported to the DQE scheduler, which assigns one MongoDB shard to each of the workers by calling the setShard() method.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9479727149009705}, "created": {"value": false, "score": 4.51207160949707e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9999129176139832}, "shared": {"value": false, "score": 9.065866470336914e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Hive", "normalizedForm": "Hive", "offsetStart": 77, "offsetEnd": 81}, "context": "MISO [28] is a method for tuning the physical design of a multistore system (Hive/HDFS and RDBMS), i.e. deciding in which data store the data should reside, in order to improve the performance of big data query processing.", "mentionContextAttributes": {"used": {"value": false, "score": 4.89354133605957e-05}, "created": {"value": false, "score": 0.0001316070556640625}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999398589134216}, "created": {"value": false, "score": 0.0001316070556640625}, "shared": {"value": false, "score": 5.662441253662109e-06}}}, {"type": "software", "software-type": "software", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.3825, "software-name": {"rawForm": "Spark", "normalizedForm": "Spark", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.3825, "offsetStart": 77, "offsetEnd": 82}, "context": "Query Q2 S evaluates just the parallel execution of the Experts MFR query on Spark, while Q2 SL involves a join with the CUSTOMER table from the LeanXcale data store: Fig. 10 shows the performance measurements of Q2 queries that stress on the evaluation of the parallel processing of MFR/Scala queries against Spark, with and without join with a LeanXcale table.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9895274043083191}, "created": {"value": false, "score": 2.3245811462402344e-06}, "shared": {"value": false, "score": 5.364418029785156e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9997756481170654}, "shared": {"value": false, "score": 1.4841556549072266e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "script", "normalizedForm": "script", "offsetStart": 77, "offsetEnd": 83}, "language": {"rawForm": "Scala", "normalizedForm": "Scala"}, "context": "JavaScript), that requests a dataset from the document database, and another script (e.g. in Python or Scala for Spark), that requests a chain of transformations on the unstructured data from the HDFS log before involving it into relational joins. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.005140244960784912}, "created": {"value": false, "score": 3.916025161743164e-05}, "shared": {"value": false, "score": 8.940696716308594e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.919108510017395}, "created": {"value": true, "score": 0.9993940591812134}, "shared": {"value": false, "score": 1.4841556549072266e-05}}}, {"type": "software", "software-type": "software", "wikidataId": "Q29120", "wikipediaExternalRef": 5919308, "lang": "en", "confidence": 0.9056, "software-name": {"rawForm": "Hadoop", "normalizedForm": "Hadoop", "wikidataId": "Q29120", "wikipediaExternalRef": 5919308, "lang": "en", "confidence": 0.9056, "offsetStart": 77, "offsetEnd": 83}, "context": "Tightly-coupled polystores have been introduced with the goal of integrating Hadoop or Spark for big data analysis with traditional (parallel) RDBMSs. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0003224611282348633}, "created": {"value": false, "score": 0.10342800617218018}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9755048155784607}, "created": {"value": false, "score": 0.10342800617218018}, "shared": {"value": false, "score": 0.010259866714477539}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MyriaL", "normalizedForm": "MyriaL", "offsetStart": 77, "offsetEnd": 83}, "context": "Its extended relational model and the imperative-declarative hybrid language MyriaL span well all the underlying data models, where rewrite rules apply to transform expressions into specific API calls, queries, etc. for each of the data stores. ", "mentionContextAttributes": {"used": {"value": false, "score": 8.600950241088867e-05}, "created": {"value": false, "score": 0.002353072166442871}, "shared": {"value": false, "score": 5.364418029785156e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 8.600950241088867e-05}, "created": {"value": false, "score": 0.002353072166442871}, "shared": {"value": false, "score": 5.364418029785156e-07}}}, {"type": "software", "software-type": "software", "wikidataId": "Q1165204", "wikipediaExternalRef": 21855450, "lang": "en", "confidence": 0.7457, "software-name": {"rawForm": "MongoDB", "normalizedForm": "MongoDB", "wikidataId": "Q1165204", "wikipediaExternalRef": 21855450, "lang": "en", "confidence": 0.7457, "offsetStart": 77, "offsetEnd": 84}, "context": "Query Q2 M evaluates just the parallel execution of the BookOrders script in MongoDB, while Q2 ML involves a join between MongoDB and the CUSTOMER table from the LeanXcale data store: Fig. 9 shows the performance measurements of Q2 queries that stress on the evaluation of the parallel processing of highly expressive JavaScript queries, with and without join with a LeanXcale table. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.7139508724212646}, "created": {"value": false, "score": 3.159046173095703e-06}, "shared": {"value": false, "score": 1.0132789611816406e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9999129176139832}, "shared": {"value": false, "score": 9.065866470336914e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SparkAgent", "normalizedForm": "SparkAgent", "offsetStart": 78, "offsetEnd": 88}, "context": "Upon a subsequent call of setShard() to a wrapper instance, the corresponding SparkAgent reports to the AgentRegistry its availability to receive partition data for this particular query.", "mentionContextAttributes": {"used": {"value": false, "score": 0.04014432430267334}, "created": {"value": false, "score": 6.735324859619141e-06}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.4153452515602112}, "created": {"value": false, "score": 0.00011998414993286133}, "shared": {"value": false, "score": 1.9669532775878906e-06}}}, {"type": "software", "software-type": "software", "wikidataId": "Q47607", "wikipediaExternalRef": 29004, "lang": "en", "confidence": 0.4606, "software-name": {"rawForm": "SQL", "normalizedForm": "SQL", "wikidataId": "Q47607", "wikipediaExternalRef": 29004, "lang": "en", "confidence": 0.4606, "offsetStart": 79, "offsetEnd": 82}, "context": "Teradata is responsible for building an SQL query plan and deciding where each SQL operator (e.g.", "mentionContextAttributes": {"used": {"value": false, "score": 0.003480851650238037}, "created": {"value": false, "score": 0.013220012187957764}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9934203028678894}, "shared": {"value": false, "score": 0.010259866714477539}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LeanXcale", "normalizedForm": "LeanXcale", "offsetStart": 79, "offsetEnd": 88}, "context": "In this paper, we introduced a parallel polystore system that builds on top of LeanXcale's distributed query engine and processes queries in the CloudMdsQL query language. ", "mentionContextAttributes": {"used": {"value": false, "score": 3.629922866821289e-05}, "created": {"value": true, "score": 0.9999358057975769}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999398589134216}, "created": {"value": true, "score": 0.9999358057975769}, "shared": {"value": false, "score": 8.52346420288086e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Teradata", "normalizedForm": "Teradata", "offsetStart": 80, "offsetEnd": 88}, "context": "join or aggregation) will execute on one of the IntelliSphere's systems (either Teradata or a remote system).", "mentionContextAttributes": {"used": {"value": false, "score": 0.4376014471054077}, "created": {"value": false, "score": 0.0005382299423217773}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.4376014471054077}, "created": {"value": false, "score": 0.013220012187957764}, "shared": {"value": false, "score": 4.172325134277344e-07}}}, {"type": "software", "software-type": "software", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.6951, "software-name": {"rawForm": "Spark SQL", "normalizedForm": "Spark SQL", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.6951, "offsetStart": 80, "offsetEnd": 89}, "context": "To run an analogue of the BookOrders subquery through the MongoDB connector for Spark SQL, we used the MongoDB aggregation framework against the same sharded collection in our MongoDB cluster as follows:", "mentionContextAttributes": {"used": {"value": true, "score": 0.9997720718383789}, "created": {"value": false, "score": 9.375810623168945e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997720718383789}, "created": {"value": true, "score": 0.5916945338249207}, "shared": {"value": false, "score": 3.2782554626464844e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LeanXcale", "normalizedForm": "LeanXcale", "offsetStart": 80, "offsetEnd": 89}, "context": "Presto follows the classical distributed DBMS architecture, which, similarly to LeanXcale, consists of a coordinator, multiple workers and connectors (storage plugins that interface external data stores and provide metadata to the coordinator and data to workers).", "mentionContextAttributes": {"used": {"value": false, "score": 0.0008666515350341797}, "created": {"value": false, "score": 0.0003376007080078125}, "shared": {"value": false, "score": 1.0132789611816406e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999398589134216}, "created": {"value": true, "score": 0.9999358057975769}, "shared": {"value": false, "score": 8.52346420288086e-06}}}, {"type": "software", "software-type": "software", "wikidataId": "Q47607", "wikipediaExternalRef": 29004, "lang": "en", "confidence": 0.4606, "software-name": {"rawForm": "SQL", "normalizedForm": "SQL", "wikidataId": "Q47607", "wikipediaExternalRef": 29004, "lang": "en", "confidence": 0.4606, "offsetStart": 81, "offsetEnd": 84}, "context": "Fig. 12 shows the times for processing Q4 queries, involving 2 joins: with Spark SQL, with LeanXcale without using bind join, and with LeanXcale using bind join.", "mentionContextAttributes": {"used": {"value": true, "score": 0.986201822757721}, "created": {"value": false, "score": 1.1026859283447266e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9934203028678894}, "shared": {"value": false, "score": 0.010259866714477539}}}, {"type": "software", "software-type": "software", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.3825, "software-name": {"rawForm": "Spark", "normalizedForm": "Spark", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.3825, "offsetStart": 81, "offsetEnd": 86}, "context": "Thus, even a distributed query engine cannot exploit parallelism in retrieving a Spark RDD, since only one worker will collect the entire RDD through the Spark driver, which is the limitation we want to overcome in this paper as an extended version of [24].", "mentionContextAttributes": {"used": {"value": false, "score": 0.00014734268188476562}, "created": {"value": false, "score": 0.02785634994506836}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9997756481170654}, "shared": {"value": false, "score": 1.4841556549072266e-05}}}, {"type": "software", "software-type": "software", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.3825, "software-name": {"rawForm": "Spark", "normalizedForm": "Spark", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.3825, "offsetStart": 81, "offsetEnd": 86}, "context": "PrepareScript is responsible for preparing the Scala script to be submitted as a Spark job and is active only at the master wrapper for a particular query.", "mentionContextAttributes": {"used": {"value": false, "score": 0.004101216793060303}, "created": {"value": false, "score": 0.00535207986831665}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9997756481170654}, "shared": {"value": false, "score": 1.4841556549072266e-05}}}, {"type": "software", "software-type": "software", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.3825, "software-name": {"rawForm": "Spark", "normalizedForm": "Spark", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.3825, "offsetStart": 82, "offsetEnd": 87}, "context": "However, the collection of this intermediate result set is centralized, since the Spark driver simply merges the data from all the partitions of the final RDD into a single non-partitioned result set.", "mentionContextAttributes": {"used": {"value": false, "score": 0.26542991399765015}, "created": {"value": false, "score": 2.294778823852539e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9997756481170654}, "shared": {"value": false, "score": 1.4841556549072266e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MapReduce", "normalizedForm": "MapReduce", "offsetStart": 82, "offsetEnd": 91}, "context": "HiveQL queries are decomposed to relational operators, which are then compiled to MapReduce jobs to be executed on Hadoop. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9755048155784607}, "created": {"value": false, "score": 4.45246696472168e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9755048155784607}, "created": {"value": false, "score": 0.22964704036712646}, "shared": {"value": false, "score": 2.980232238769531e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CloudMdsQL", "normalizedForm": "CloudMdsQL", "offsetStart": 82, "offsetEnd": 92}, "context": "In this paper, we address these points by: (i) using the polyglot approach of the CloudMdsQL query language that allows native queries to be expressed as inline scripts and combined with SQL statements for ad-hoc integration and (ii) incorporating the approach within the LeanXcale distributed query engine, thus allowing for native scripts to be processed in parallel at data store shards. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0006181597709655762}, "created": {"value": false, "score": 0.4770117402076721}, "shared": {"value": false, "score": 2.3245811462402344e-06}}, "documentContextAttributes": {"used": {"value": false, "score": 0.10021162033081055}, "created": {"value": true, "score": 0.9999358057975769}, "shared": {"value": false, "score": 2.3245811462402344e-06}}, "references": [{"label": "[26]", "normalizedForm": "[26]", "refKey": 26}, {"label": "[26]", "normalizedForm": "[26]", "refKey": 26}]}, {"type": "software", "software-type": "software", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.7879, "software-name": {"rawForm": "Apache Spark", "normalizedForm": "Apache Spark", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.7879, "offsetStart": 83, "offsetEnd": 95}, "context": "The new material addresses the support of distributed processing platforms such as Apache Spark by enabling the ad-hoc usage of user defined map/filter/reduce (MFR) operators as subqueries, yet allowing for pushing down predicates (e.g. for bind join conditions) and parallel retrieval of intermediate results. ", "mentionContextAttributes": {"used": {"value": false, "score": 5.5849552154541016e-05}, "created": {"value": false, "score": 0.3127649426460266}, "shared": {"value": false, "score": 2.086162567138672e-06}}, "documentContextAttributes": {"used": {"value": false, "score": 0.01917022466659546}, "created": {"value": true, "score": 0.7794421911239624}, "shared": {"value": false, "score": 4.470348358154297e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CloudMdsQL", "normalizedForm": "CloudMdsQL", "offsetStart": 84, "offsetEnd": 94}, "context": "To address distributed processing frameworks (such as Apache Spark) as data stores, CloudMdsQL introduces a formal notation that enables the adhoc usage of user-defined map/filter/reduce (MFR) operators as subqueries to request data processing in an underlying big data processing framework [9]. ", "mentionContextAttributes": {"used": {"value": false, "score": 6.16908073425293e-05}, "created": {"value": false, "score": 0.0030756592750549316}, "shared": {"value": false, "score": 2.3245811462402344e-06}}, "documentContextAttributes": {"used": {"value": false, "score": 0.10021162033081055}, "created": {"value": true, "score": 0.9999358057975769}, "shared": {"value": false, "score": 2.3245811462402344e-06}}, "references": [{"label": "[26]", "normalizedForm": "[26]", "refKey": 26}, {"label": "[26]", "normalizedForm": "[26]", "refKey": 26}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Hadoop MapReduce", "normalizedForm": "Hadoop MapReduce", "offsetStart": 84, "offsetEnd": 104}, "context": "HiveQL is the query language of the data warehousing solution Hive, built on top of Hadoop MapReduce [35]. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0028700828552246094}, "created": {"value": false, "score": 7.50422477722168e-05}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.0028700828552246094}, "created": {"value": false, "score": 0.0012637972831726074}, "shared": {"value": false, "score": 9.065866470336914e-05}}}, {"type": "software", "software-type": "software", "wikidataId": "Q1165204", "wikipediaExternalRef": 21855450, "lang": "en", "confidence": 0.7457, "software-name": {"rawForm": "MongoDB", "normalizedForm": "MongoDB", "wikidataId": "Q1165204", "wikipediaExternalRef": 21855450, "lang": "en", "confidence": 0.7457, "offsetStart": 85, "offsetEnd": 92}, "context": "Thus, each DQE worker gets exactly one partition of both tables by connecting to one MongoDB shard (through a wrapper instance) and one KVDS (Fig. 4).", "mentionContextAttributes": {"used": {"value": false, "score": 0.10965782403945923}, "created": {"value": false, "score": 8.52346420288086e-06}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9999129176139832}, "shared": {"value": false, "score": 9.065866470336914e-05}}}, {"type": "software", "software-type": "software", "wikidataId": "Q1165204", "wikipediaExternalRef": 21855450, "lang": "en", "confidence": 0.7457, "software-name": {"rawForm": "MongoDB", "normalizedForm": "MongoDB", "wikidataId": "Q1165204", "wikipediaExternalRef": 21855450, "lang": "en", "confidence": 0.7457, "offsetStart": 85, "offsetEnd": 92}, "context": "All the generated datasets were: loaded in LeanXcale as relational tables; loaded in MongoDB as document collections; copied to the HDFS cluster as raw CSV files, to be accessed through Hive as tables and through Spark by means of scans expressed as simple MFR/Scala statements.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9994305372238159}, "created": {"value": false, "score": 2.9206275939941406e-06}, "shared": {"value": false, "score": 5.364418029785156e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9999129176139832}, "shared": {"value": false, "score": 9.065866470336914e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SparkAgent", "normalizedForm": "SparkAgent", "offsetStart": 86, "offsetEnd": 96}, "context": "It requests from a common component, named AgentRegistry, the address of an available SparkAgent (waiting for such availability, if necessary) and makes a socket connection to it.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0005658864974975586}, "created": {"value": false, "score": 0.00011998414993286133}, "shared": {"value": false, "score": 1.9669532775878906e-06}}, "documentContextAttributes": {"used": {"value": false, "score": 0.4153452515602112}, "created": {"value": false, "score": 0.00011998414993286133}, "shared": {"value": false, "score": 1.9669532775878906e-06}}}, {"type": "software", "software-type": "software", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.3825, "software-name": {"rawForm": "Spark", "normalizedForm": "Spark", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.3825, "offsetStart": 87, "offsetEnd": 92}, "context": "Tightly-coupled polystores have been introduced with the goal of integrating Hadoop or Spark for big data analysis with traditional (parallel) RDBMSs. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0003224611282348633}, "created": {"value": false, "score": 0.10342800617218018}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9997756481170654}, "shared": {"value": false, "score": 1.4841556549072266e-05}}}, {"type": "software", "software-type": "software", "wikidataId": "Q47607", "wikipediaExternalRef": 29004, "lang": "en", "confidence": 0.4606, "software-name": {"rawForm": "SQL", "normalizedForm": "SQL", "wikidataId": "Q47607", "wikipediaExternalRef": 29004, "lang": "en", "confidence": 0.4606, "offsetStart": 88, "offsetEnd": 91}, "context": "For example, let us consider a banking institution that keeps its operational data in a SQL database, but stores data about bank transactions in a document database, because each record typically contains data in just a few fields, so this makes use of the semistructured nature of documents.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00017976760864257812}, "created": {"value": false, "score": 0.0014140605926513672}, "shared": {"value": false, "score": 1.0132789611816406e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9934203028678894}, "shared": {"value": false, "score": 0.010259866714477539}}}, {"type": "software", "software-type": "software", "wikidataId": "Q29120", "wikipediaExternalRef": 5919308, "lang": "en", "confidence": 0.9056, "software-name": {"rawForm": "Hadoop", "normalizedForm": "Hadoop", "wikidataId": "Q29120", "wikipediaExternalRef": 5919308, "lang": "en", "confidence": 0.9056, "offsetStart": 89, "offsetEnd": 95}, "context": "It produces SQL statements for relational data stores, and Pig/Hive code for interfacing Hadoop to access HDFS data. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.00014781951904296875}, "created": {"value": false, "score": 0.0006139874458312988}, "shared": {"value": false, "score": 1.4901161193847656e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9755048155784607}, "created": {"value": false, "score": 0.10342800617218018}, "shared": {"value": false, "score": 0.010259866714477539}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Hive metastore", "normalizedForm": "Hive metastore", "offsetStart": 89, "offsetEnd": 103}, "context": "For HDFS tables, some overhead is added, due to data conversions, communication with the Hive metastore, and possibly accessing HDFS splits through the network. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0026703476905822754}, "created": {"value": false, "score": 3.820657730102539e-05}, "shared": {"value": false, "score": 6.556510925292969e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.0026703476905822754}, "created": {"value": false, "score": 3.820657730102539e-05}, "shared": {"value": false, "score": 6.556510925292969e-07}}}, {"type": "software", "software-type": "software", "wikidataId": "Q47607", "wikipediaExternalRef": 29004, "lang": "en", "confidence": 0.4606, "software-name": {"rawForm": "SQL", "normalizedForm": "SQL", "wikidataId": "Q47607", "wikipediaExternalRef": 29004, "lang": "en", "confidence": 0.4606, "offsetStart": 90, "offsetEnd": 93}, "context": "The first group evaluates the scalability of the system in the context of straightforward SQL mappings with the underlying data stores.", "mentionContextAttributes": {"used": {"value": false, "score": 0.023896634578704834}, "created": {"value": false, "score": 0.008063733577728271}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9934203028678894}, "shared": {"value": false, "score": 0.010259866714477539}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LeanXcale", "normalizedForm": "LeanXcale", "offsetStart": 90, "offsetEnd": 99}, "context": "Each table is stored as a KiVi table, where the key corresponds to the primary key of the LeanXcale table and all the columns are stored as they are into KiVi columns.", "mentionContextAttributes": {"used": {"value": false, "score": 0.17349368333816528}, "created": {"value": false, "score": 5.906820297241211e-05}, "shared": {"value": false, "score": 4.172325134277344e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999398589134216}, "created": {"value": true, "score": 0.9999358057975769}, "shared": {"value": false, "score": 8.52346420288086e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LeanXcale", "normalizedForm": "LeanXcale", "offsetStart": 90, "offsetEnd": 99}, "context": "Fig. 12. Execution times (in seconds) of Q4 queries joining the result of Q3 queries (1TB LeanXcale table joining 600GB MongoDB collection) with an MFR/Scala/Spark subquery against 240GB HDFS file.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999205470085144}, "created": {"value": false, "score": 4.0471553802490234e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999398589134216}, "created": {"value": true, "score": 0.9999358057975769}, "shared": {"value": false, "score": 8.52346420288086e-06}}}, {"type": "software", "software-type": "software", "wikidataId": "Q47607", "wikipediaExternalRef": 29004, "lang": "en", "confidence": 0.4606, "software-name": {"rawForm": "SQL", "normalizedForm": "SQL", "wikidataId": "Q47607", "wikipediaExternalRef": 29004, "lang": "en", "confidence": 0.4606, "offsetStart": 91, "offsetEnd": 94}, "context": "These data management clusters can range from distributed raw data files, through parallel SQL databases, to sharded NoSQL databases (such as MongoDB, where queries can be expressed as JavaScript programs) and parallel data processing frameworks (such as Apache Spark, where data retrieval and/or transformation can be requested by means of Python or Scala scripting).", "mentionContextAttributes": {"used": {"value": false, "score": 0.0007843375205993652}, "created": {"value": false, "score": 0.0032500028610229492}, "shared": {"value": false, "score": 4.470348358154297e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9934203028678894}, "shared": {"value": false, "score": 0.010259866714477539}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "REDUCE", "normalizedForm": "REDUCE", "offsetStart": 91, "offsetEnd": 97}, "context": "Rule #2: REDUCE(<transformation>).FILTER(<predicate>) is equivalent to FILTER(<predicate>).REDUCE(<transformation>), if predicate condition is a function only of the KEY, because thus, applying the FILTER before the REDUCE will preserve the values associated to those keys that satisfy the filter condition as they would be if the FILTER was applied after the REDUCE.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9831934571266174}, "created": {"value": false, "score": 3.039836883544922e-06}, "shared": {"value": false, "score": 2.4437904357910156e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9995518326759338}, "created": {"value": false, "score": 0.00020503997802734375}, "shared": {"value": false, "score": 2.4437904357910156e-06}}}, {"type": "software", "software-type": "software", "wikidataId": "Q1165204", "wikipediaExternalRef": 21855450, "lang": "en", "confidence": 0.7457, "software-name": {"rawForm": "MongoDB", "normalizedForm": "MongoDB", "wikidataId": "Q1165204", "wikipediaExternalRef": 21855450, "lang": "en", "confidence": 0.7457, "offsetStart": 91, "offsetEnd": 98}, "context": "Document collections are exposed as tables to Presto, keeping schema mappings in a special MongoDB collection.", "mentionContextAttributes": {"used": {"value": true, "score": 0.629574179649353}, "created": {"value": false, "score": 0.000125885009765625}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9999129176139832}, "shared": {"value": false, "score": 9.065866470336914e-05}}}, {"type": "software", "software-type": "software", "wikidataId": "Q1165204", "wikipediaExternalRef": 21855450, "lang": "en", "confidence": 0.7457, "software-name": {"rawForm": "MongoDB", "normalizedForm": "MongoDB", "wikidataId": "Q1165204", "wikipediaExternalRef": 21855450, "lang": "en", "confidence": 0.7457, "offsetStart": 91, "offsetEnd": 98}, "context": "Let us assume for simplicity a cluster of equal numbers of: DQE workers, KVDS servers, and MongoDB shards.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9932975769042969}, "created": {"value": false, "score": 3.534555435180664e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9999129176139832}, "shared": {"value": false, "score": 9.065866470336914e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LeanXcale", "normalizedForm": "LeanXcale", "offsetStart": 91, "offsetEnd": 100}, "context": "Fig. 12 shows the times for processing Q4 queries, involving 2 joins: with Spark SQL, with LeanXcale without using bind join, and with LeanXcale using bind join. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.986201822757721}, "created": {"value": false, "score": 1.1026859283447266e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999398589134216}, "created": {"value": true, "score": 0.9999358057975769}, "shared": {"value": false, "score": 8.52346420288086e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Bigtable", "normalizedForm": "Bigtable", "offsetStart": 92, "offsetEnd": 100}, "publisher": {"rawForm": "Google", "normalizedForm": "Google", "offsetStart": 83, "offsetEnd": 89}, "context": "BigIntegrator [29] integrates data from cloud-based NoSQL big data stores, such as Google's Bigtable, and relational databases. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.00016045570373535156}, "created": {"value": false, "score": 8.046627044677734e-06}, "shared": {"value": false, "score": 5.364418029785156e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.0007174015045166016}, "created": {"value": false, "score": 0.0002396106719970703}, "shared": {"value": false, "score": 5.364418029785156e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Python", "normalizedForm": "Python", "offsetStart": 93, "offsetEnd": 99}, "context": "JavaScript), that requests a dataset from the document database, and another script (e.g. in Python or Scala for Spark), that requests a chain of transformations on the unstructured data from the HDFS log before involving it into relational joins.", "mentionContextAttributes": {"used": {"value": false, "score": 0.005140244960784912}, "created": {"value": false, "score": 3.916025161743164e-05}, "shared": {"value": false, "score": 8.940696716308594e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.20863837003707886}, "created": {"value": false, "score": 0.0032500028610229492}, "shared": {"value": false, "score": 4.470348358154297e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "script", "normalizedForm": "script", "offsetStart": 93, "offsetEnd": 99}, "language": {"rawForm": "Scala", "normalizedForm": "Scala"}, "context": "Normally, this is the point where the connection to the data store shard takes place and the script execution is initiated.", "mentionContextAttributes": {"used": {"value": false, "score": 0.008256196975708008}, "created": {"value": false, "score": 0.0003540515899658203}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.919108510017395}, "created": {"value": true, "score": 0.9993940591812134}, "shared": {"value": false, "score": 1.4841556549072266e-05}}}, {"type": "software", "software-type": "software", "wikidataId": "Q47607", "wikipediaExternalRef": 29004, "lang": "en", "confidence": 0.4606, "software-name": {"rawForm": "SQL", "normalizedForm": "SQL", "wikidataId": "Q47607", "wikipediaExternalRef": 29004, "lang": "en", "confidence": 0.4606, "offsetStart": 94, "offsetEnd": 97}, "context": "Among hybrid systems, although Presto and Drill support well parallel query processing across SQL and NoSQL stores, the only one that provides parallel support of distributed data platforms is Spark SQL, as it uses Spark natively.", "mentionContextAttributes": {"used": {"value": false, "score": 7.051229476928711e-05}, "created": {"value": false, "score": 0.00028395652770996094}, "shared": {"value": false, "score": 3.2782554626464844e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9934203028678894}, "shared": {"value": false, "score": 0.010259866714477539}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "API", "normalizedForm": "API", "offsetStart": 94, "offsetEnd": 97}, "context": "In fact, ShardedCursor implements all DataLake API methods and hence serves as a proxy of the API into the JavaScript MongoDB client library.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0036196112632751465}, "created": {"value": false, "score": 0.0005892515182495117}, "shared": {"value": false, "score": 1.5914440155029297e-05}}, "documentContextAttributes": {"used": {"value": false, "score": 0.05950498580932617}, "created": {"value": false, "score": 0.05537760257720947}, "shared": {"value": false, "score": 4.655122756958008e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LeanXcale  Distributed Query Engine (DQE)", "normalizedForm": "LeanXcale Distributed Query Engine (DQE)", "offsetStart": 94, "offsetEnd": 135}, "context": "And to enable the parallel query processing, we incorporated the polyglot approach within the LeanXcale1 Distributed Query Engine (DQE), which provides a query engine with intra-query and intra-operator parallelism that operates over a standard SQL interface. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0017653703689575195}, "created": {"value": true, "score": 0.9934203028678894}, "shared": {"value": false, "score": 5.364418029785156e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.0017653703689575195}, "created": {"value": true, "score": 0.9934203028678894}, "shared": {"value": false, "score": 5.364418029785156e-07}}}, {"type": "software", "software-type": "software", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.3825, "software-name": {"rawForm": "Spark", "normalizedForm": "Spark", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.3825, "offsetStart": 96, "offsetEnd": 101}, "context": "Fig. 7 shows in detail the flow of operations for processing an MFR subquery by the distributed Spark wrapper.", "mentionContextAttributes": {"used": {"value": true, "score": 0.7658788561820984}, "created": {"value": false, "score": 1.3887882232666016e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9997756481170654}, "shared": {"value": false, "score": 1.4841556549072266e-05}}}, {"type": "software", "software-type": "software", "wikidataId": "Q187432", "wikipediaExternalRef": 21490336, "lang": "en", "confidence": 0.5074, "software-name": {"rawForm": "scripts", "normalizedForm": "scripts", "wikidataId": "Q187432", "wikipediaExternalRef": 21490336, "lang": "en", "confidence": 0.5074, "offsetStart": 98, "offsetEnd": 105}, "context": "A typical wrapper implementation should use a scripting engine and/or a client library to execute scripts (client-or server-side) against the data store.", "mentionContextAttributes": {"used": {"value": false, "score": 7.56382942199707e-05}, "created": {"value": false, "score": 0.000460207462310791}, "shared": {"value": false, "score": 7.748603820800781e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.0027613043785095215}, "created": {"value": true, "score": 0.9998281002044678}, "shared": {"value": false, "score": 2.3245811462402344e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "REDUCE", "normalizedForm": "REDUCE", "offsetStart": 99, "offsetEnd": 105}, "context": "In the example above, since the FILTER predicate involves only the KEY, it can be swapped with the REDUCE, thus allowing the filter to be applied earlier in order to avoid unnecessary and expensive computation.", "mentionContextAttributes": {"used": {"value": false, "score": 0.024402856826782227}, "created": {"value": false, "score": 1.710653305053711e-05}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9995518326759338}, "created": {"value": false, "score": 0.00020503997802734375}, "shared": {"value": false, "score": 2.4437904357910156e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LeanXcale", "normalizedForm": "LeanXcale", "offsetStart": 99, "offsetEnd": 108}, "context": "Prof. Jose Pereira, Ricardo Vila\u00e7a, and Rui Gon\u00e7alves contributed to this work when they were with LeanXcale.", "mentionContextAttributes": {"used": {"value": false, "score": 0.16759687662124634}, "created": {"value": false, "score": 0.006302475929260254}, "shared": {"value": false, "score": 4.172325134277344e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999398589134216}, "created": {"value": true, "score": 0.9999358057975769}, "shared": {"value": false, "score": 8.52346420288086e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Hive API", "normalizedForm": "Hive API", "offsetStart": 100, "offsetEnd": 108}, "context": "This information is used by the master wrapper, which reports the list of file splits (instances of Hive API's InputSplit class) to the DQE scheduler upon a call to the listShards() method. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.4094656705856323}, "created": {"value": false, "score": 3.057718276977539e-05}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.4094656705856323}, "created": {"value": false, "score": 3.057718276977539e-05}, "shared": {"value": false, "score": 2.980232238769531e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ShardedCursor", "normalizedForm": "ShardedCursor", "offsetStart": 100, "offsetEnd": 113}, "context": "The client library is therefore extended with the following document collection methods that return ShardedCursor and provide the targeted operators (find, map, and flat map) in user scripts.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0025480985641479492}, "created": {"value": false, "score": 0.00027632713317871094}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.011867344379425049}, "created": {"value": false, "score": 0.0005892515182495117}, "shared": {"value": false, "score": 1.5914440155029297e-05}}}, {"type": "software", "software-type": "software", "wikidataId": "Q47607", "wikipediaExternalRef": 29004, "lang": "en", "confidence": 0.4606, "software-name": {"rawForm": "SQL", "normalizedForm": "SQL", "wikidataId": "Q47607", "wikipediaExternalRef": 29004, "lang": "en", "confidence": 0.4606, "offsetStart": 101, "offsetEnd": 104}, "context": "Polybase [15] is a feature of Microsoft SQL Server Parallel Data Warehouse to access HDFS data using SQL.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00020503997802734375}, "created": {"value": false, "score": 2.2590160369873047e-05}, "shared": {"value": false, "score": 5.900859832763672e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9934203028678894}, "shared": {"value": false, "score": 0.010259866714477539}}}, {"type": "software", "software-type": "software", "wikidataId": "Q47607", "wikipediaExternalRef": 29004, "lang": "en", "confidence": 0.4606, "software-name": {"rawForm": "SQL", "normalizedForm": "SQL", "wikidataId": "Q47607", "wikipediaExternalRef": 29004, "lang": "en", "confidence": 0.4606, "offsetStart": 101, "offsetEnd": 104}, "context": "This allows data store native subqueries to be expressed as inline scripts and combined with regular SQL statements in ad-hoc integration statements.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00016188621520996094}, "created": {"value": false, "score": 0.0001990795135498047}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9934203028678894}, "shared": {"value": false, "score": 0.010259866714477539}}}, {"type": "software", "software-type": "software", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.3825, "software-name": {"rawForm": "Spark", "normalizedForm": "Spark", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.3825, "offsetStart": 101, "offsetEnd": 106}, "context": "For comparison with the state of the art, the large-scale test case queries were also performed on a Spark SQL cluster, where we used the MongoDB Spark connector to access MongoDB shards in parallel.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": false, "score": 1.5795230865478516e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9997756481170654}, "shared": {"value": false, "score": 1.4841556549072266e-05}}}, {"type": "software", "software-type": "software", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.7879, "software-name": {"rawForm": "Apache Spark", "normalizedForm": "Apache Spark", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.7879, "offsetStart": 101, "offsetEnd": 113}, "context": "This problem was addressed in [9], by allowing distributed data processing frameworks (in particular Apache Spark) to be accessed as data stores and queried through the semideclarative MFR notation. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0013478398323059082}, "created": {"value": false, "score": 0.0001156926155090332}, "shared": {"value": false, "score": 5.364418029785156e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.01917022466659546}, "created": {"value": true, "score": 0.7794421911239624}, "shared": {"value": false, "score": 4.470348358154297e-06}}}, {"type": "software", "software-type": "software", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.3825, "software-name": {"rawForm": "Spark", "normalizedForm": "Spark", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.3825, "offsetStart": 102, "offsetEnd": 107}, "context": "We address this problem by introducing an architecture, where each RDD partition (more precisely, the Spark worker that processes the partition) is instructed through generated code to find and connect to a query engine worker and to push the partition data.", "mentionContextAttributes": {"used": {"value": false, "score": 8.434057235717773e-05}, "created": {"value": true, "score": 0.9997756481170654}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9997756481170654}, "shared": {"value": false, "score": 1.4841556549072266e-05}}}, {"type": "software", "software-type": "environment", "wikidataId": "Q460584", "wikipediaExternalRef": 3254510, "lang": "en", "confidence": 0.2001, "software-name": {"rawForm": "Scala", "normalizedForm": "Scala", "wikidataId": "Q460584", "wikipediaExternalRef": 3254510, "lang": "en", "confidence": 0.2001, "offsetStart": 103, "offsetEnd": 108}, "context": "JavaScript), that requests a dataset from the document database, and another script (e.g. in Python or Scala for Spark), that requests a chain of transformations on the unstructured data from the HDFS log before involving it into relational joins. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.005140244960784912}, "created": {"value": false, "score": 3.916025161743164e-05}, "shared": {"value": false, "score": 8.940696716308594e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999205470085144}, "created": {"value": true, "score": 0.9993940591812134}, "shared": {"value": false, "score": 1.4841556549072266e-05}}}, {"type": "software", "software-type": "software", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.3825, "software-name": {"rawForm": "Spark", "normalizedForm": "Spark", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.3825, "offsetStart": 103, "offsetEnd": 108}, "context": "The level of parallelism was set to 512, i.e. 512 MongoDB shards, 512 LeanXcale DQE instances, and 512 Spark executors.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9998719692230225}, "created": {"value": false, "score": 9.357929229736328e-06}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9997756481170654}, "shared": {"value": false, "score": 1.4841556549072266e-05}}}, {"type": "software", "software-type": "software", "wikidataId": "Q1165204", "wikipediaExternalRef": 21855450, "lang": "en", "confidence": 0.7457, "software-name": {"rawForm": "MongoDB", "normalizedForm": "MongoDB", "wikidataId": "Q1165204", "wikipediaExternalRef": 21855450, "lang": "en", "confidence": 0.7457, "offsetStart": 103, "offsetEnd": 110}, "context": "To run an analogue of the BookOrders subquery through the MongoDB connector for Spark SQL, we used the MongoDB aggregation framework against the same sharded collection in our MongoDB cluster as follows:", "mentionContextAttributes": {"used": {"value": true, "score": 0.9997720718383789}, "created": {"value": false, "score": 9.375810623168945e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9999129176139832}, "shared": {"value": false, "score": 9.065866470336914e-05}}}, {"type": "software", "software-type": "software", "wikidataId": "Q1165204", "wikipediaExternalRef": 21855450, "lang": "en", "confidence": 0.7457, "software-name": {"rawForm": "MongoDB", "normalizedForm": "MongoDB", "wikidataId": "Q1165204", "wikipediaExternalRef": 21855450, "lang": "en", "confidence": 0.7457, "offsetStart": 103, "offsetEnd": 110}, "context": "All the queries were run on a cluster of LeanXcale DQE instances, running the distributed wrappers for MongoDB, Hive, and Spark.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999398589134216}, "created": {"value": false, "score": 2.7835369110107422e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9999129176139832}, "shared": {"value": false, "score": 9.065866470336914e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CloudMdsQL", "normalizedForm": "CloudMdsQL", "offsetStart": 104, "offsetEnd": 114}, "context": "To provide bind join as an efficient method for performing semi-joins across heterogeneous data stores, CloudMdsQL uses subquery rewriting to push the join conditions. ", "mentionContextAttributes": {"used": {"value": false, "score": 6.753206253051758e-05}, "created": {"value": false, "score": 2.4497509002685547e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.10021162033081055}, "created": {"value": true, "score": 0.9999358057975769}, "shared": {"value": false, "score": 2.3245811462402344e-06}}, "references": [{"label": "[26]", "normalizedForm": "[26]", "refKey": 26}, {"label": "[26]", "normalizedForm": "[26]", "refKey": 26}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "AgentRegistry", "normalizedForm": "AgentRegistry", "offsetStart": 104, "offsetEnd": 117}, "context": "Upon a subsequent call of setShard() to a wrapper instance, the corresponding SparkAgent reports to the AgentRegistry its availability to receive partition data for this particular query.", "mentionContextAttributes": {"used": {"value": false, "score": 0.04014432430267334}, "created": {"value": false, "score": 6.735324859619141e-06}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.8473858833312988}, "created": {"value": false, "score": 0.010139226913452148}, "shared": {"value": false, "score": 1.9669532775878906e-06}}}, {"type": "software", "software-type": "software", "wikidataId": "Q47607", "wikipediaExternalRef": 29004, "lang": "en", "confidence": 0.4606, "software-name": {"rawForm": "SQL", "normalizedForm": "SQL", "wikidataId": "Q47607", "wikipediaExternalRef": 29004, "lang": "en", "confidence": 0.4606, "offsetStart": 105, "offsetEnd": 108}, "context": "It allows HDFS data to be referenced through external PDW tables and joined with native PDW tables using SQL queries.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0001621246337890625}, "created": {"value": false, "score": 9.161233901977539e-05}, "shared": {"value": false, "score": 4.172325134277344e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9934203028678894}, "shared": {"value": false, "score": 0.010259866714477539}}}, {"type": "software", "software-type": "software", "wikidataId": "Q1165204", "wikipediaExternalRef": 21855450, "lang": "en", "confidence": 0.7457, "software-name": {"rawForm": "MongoDB", "normalizedForm": "MongoDB", "wikidataId": "Q1165204", "wikipediaExternalRef": 21855450, "lang": "en", "confidence": 0.7457, "offsetStart": 105, "offsetEnd": 112}, "context": "ordered by a given customer, would be defined by means of a flatMap operator in Ja-vaScript, following a MongoDB find() operator.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9996516704559326}, "created": {"value": false, "score": 2.187490463256836e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9999129176139832}, "shared": {"value": false, "score": 9.065866470336914e-05}}}, {"type": "software", "software-type": "software", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.5539, "software-name": {"rawForm": "Spark", "normalizedForm": "Spark", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.5539, "offsetStart": 106, "offsetEnd": 111}, "context": "Therefore, the query engine would be forced to use a single worker to retrieve the entire RDD through the Spark driver, serially. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.998376727104187}, "created": {"value": false, "score": 0.00014138221740722656}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9997756481170654}, "shared": {"value": false, "score": 1.4841556549072266e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "script", "normalizedForm": "script", "offsetStart": 106, "offsetEnd": 112}, "language": {"rawForm": "Scala", "normalizedForm": "Scala"}, "context": "Thus, a composition of findSharded and map/flatMap (such as in the BookOrders example above) makes a user script expressive enough, so as to request a specific MongoDB dataset, retrieve the result set in parallel, and transform it in order to fit the named table signature and further be consumed by relational operators at the DQE level.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0015254616737365723}, "created": {"value": false, "score": 2.2590160369873047e-05}, "shared": {"value": false, "score": 1.0132789611816406e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.919108510017395}, "created": {"value": true, "score": 0.9993940591812134}, "shared": {"value": false, "score": 1.4841556549072266e-05}}}, {"type": "software", "software-type": "software", "wikidataId": "Q47607", "wikipediaExternalRef": 29004, "lang": "en", "confidence": 0.4606, "software-name": {"rawForm": "SQL", "normalizedForm": "SQL", "wikidataId": "Q47607", "wikipediaExternalRef": 29004, "lang": "en", "confidence": 0.4606, "offsetStart": 107, "offsetEnd": 110}, "context": "For comparison with the state of the art, the large-scale test case queries were also performed on a Spark SQL cluster, where we used the MongoDB Spark connector to access MongoDB shards in parallel.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": false, "score": 1.5795230865478516e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9934203028678894}, "shared": {"value": false, "score": 0.010259866714477539}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "script", "normalizedForm": "script", "offsetStart": 107, "offsetEnd": 113}, "language": {"rawForm": "Scala", "normalizedForm": "Scala"}, "context": "In order to make a document result set fit the relational schema required by a Cloud-MdsQL query, the user script can further take advantage of the map() and flatMap() operators.", "mentionContextAttributes": {"used": {"value": false, "score": 0.007219374179840088}, "created": {"value": false, "score": 0.00012230873107910156}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.919108510017395}, "created": {"value": true, "score": 0.9993940591812134}, "shared": {"value": false, "score": 1.4841556549072266e-05}}}, {"type": "software", "software-type": "software", "wikidataId": "Q1165204", "wikipediaExternalRef": 21855450, "lang": "en", "confidence": 0.7457, "software-name": {"rawForm": "MongoDB", "normalizedForm": "MongoDB", "wikidataId": "Q1165204", "wikipediaExternalRef": 21855450, "lang": "en", "confidence": 0.7457, "offsetStart": 107, "offsetEnd": 114}, "context": "We compare the systems with respect to the features that we hereby address, mainly the parallel support of MongoDB, data processing platforms, and optimizability of selective joins through semi joins across data stores.", "mentionContextAttributes": {"used": {"value": false, "score": 0.015683770179748535}, "created": {"value": false, "score": 0.04509401321411133}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9999129176139832}, "shared": {"value": false, "score": 9.065866470336914e-05}}}, {"type": "software", "software-type": "software", "wikidataId": "Q1165204", "wikipediaExternalRef": 21855450, "lang": "en", "confidence": 0.7457, "software-name": {"rawForm": "MongoDB", "normalizedForm": "MongoDB", "wikidataId": "Q1165204", "wikipediaExternalRef": 21855450, "lang": "en", "confidence": 0.7457, "offsetStart": 107, "offsetEnd": 114}, "context": "In particular, we want to stress on the full parallelism to access the underlying datasets, in our case, a MongoDB collection and a Spark RDD, in the context of expressive subqueries.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0002913475036621094}, "created": {"value": true, "score": 0.852451741695404}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9999129176139832}, "shared": {"value": false, "score": 9.065866470336914e-05}}}, {"type": "software", "software-type": "software", "wikidataId": "Q460584", "wikipediaExternalRef": 3254510, "lang": "en", "confidence": 0.2001, "software-name": {"rawForm": "Scala", "normalizedForm": "Scala", "wikidataId": "Q460584", "wikipediaExternalRef": 3254510, "lang": "en", "confidence": 0.2001, "offsetStart": 108, "offsetEnd": 113}, "context": "To figure out this number, PrepareScript opens a Livy session, initializes the rdd variable using the above Scala statement, and then calls rdd.getNumPartitions().", "mentionContextAttributes": {"used": {"value": true, "score": 0.9127834439277649}, "created": {"value": false, "score": 1.0788440704345703e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999205470085144}, "created": {"value": true, "score": 0.9993940591812134}, "shared": {"value": false, "score": 1.4841556549072266e-05}}}, {"type": "software", "software-type": "software", "wikidataId": "Q47607", "wikipediaExternalRef": 29004, "lang": "en", "confidence": 0.4606, "software-name": {"rawForm": "SQL", "normalizedForm": "SQL", "wikidataId": "Q47607", "wikipediaExternalRef": 29004, "lang": "en", "confidence": 0.4606, "offsetStart": 109, "offsetEnd": 112}, "context": "The second group adds higher expressivity to the subqueries, which cannot be easily achieved through trivial SQL mappings, while still assessing the scalability.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00016927719116210938}, "created": {"value": false, "score": 0.00011211633682250977}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9934203028678894}, "shared": {"value": false, "score": 0.010259866714477539}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "code", "normalizedForm": "code", "offsetStart": 109, "offsetEnd": 113}, "context": "To achieve this, the query engine creates a session at the Spark driver, then translates the MFR subquery to code (in Scala or Python for Spark), delegates this code to Spark for execution, and collects the intermediate data through the same Spark driver session.", "mentionContextAttributes": {"used": {"value": false, "score": 0.20863837003707886}, "created": {"value": false, "score": 9.888410568237305e-05}, "shared": {"value": false, "score": 5.364418029785156e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.919108510017395}, "created": {"value": true, "score": 0.9997756481170654}, "shared": {"value": false, "score": 2.562999725341797e-06}}}, {"type": "software", "software-type": "software", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.3825, "software-name": {"rawForm": "Spark", "normalizedForm": "Spark", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.3825, "offsetStart": 110, "offsetEnd": 115}, "context": "What Spark SQL is not capable of is bind join through SQL queries; to perform a bind join, one has to write a Spark program, which limits the use cases.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00010186433792114258}, "created": {"value": false, "score": 0.00010186433792114258}, "shared": {"value": false, "score": 4.172325134277344e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9997756481170654}, "shared": {"value": false, "score": 1.4841556549072266e-05}}}, {"type": "software", "software-type": "software", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.3825, "software-name": {"rawForm": "Spark", "normalizedForm": "Spark", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.3825, "offsetStart": 110, "offsetEnd": 115}, "context": "The last test case extends the Q3 query by adding another join with the result of the Experts MFR subquery to Spark against the 240GB version of the generated posts log file.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9965709447860718}, "created": {"value": false, "score": 1.055002212524414e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9997756481170654}, "shared": {"value": false, "score": 1.4841556549072266e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Bigtable", "normalizedForm": "Bigtable", "offsetStart": 110, "offsetEnd": 118}, "publisher": {"rawForm": "Google", "normalizedForm": "Google"}, "context": "The system relies on mapping a limited set of relational operators to native queries expressed in GQL (Google Bigtable query language). ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0007174015045166016}, "created": {"value": false, "score": 0.0002396106719970703}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.0007174015045166016}, "created": {"value": false, "score": 0.0002396106719970703}, "shared": {"value": false, "score": 5.364418029785156e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CUSTOMER", "normalizedForm": "CUSTOMER", "offsetStart": 110, "offsetEnd": 118}, "context": "The data used was based on the TPC-H benchmark schema [37], particularly for the tables LINEITEM, ORDERS, and CUSTOMER.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999273419380188}, "created": {"value": false, "score": 2.4437904357910156e-06}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999273419380188}, "created": {"value": false, "score": 3.159046173095703e-06}, "shared": {"value": false, "score": 1.0132789611816406e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "InputSplit", "normalizedForm": "InputSplit", "offsetStart": 111, "offsetEnd": 121}, "context": "This information is used by the master wrapper, which reports the list of file splits (instances of Hive API's InputSplit class) to the DQE scheduler upon a call to the listShards() method. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.4094656705856323}, "created": {"value": false, "score": 3.057718276977539e-05}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.4094656705856323}, "created": {"value": false, "score": 3.057718276977539e-05}, "shared": {"value": false, "score": 2.980232238769531e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SparkAgent", "normalizedForm": "SparkAgent", "offsetStart": 111, "offsetEnd": 121}, "context": "serialize is another function that serializes each entry of the RDD partition to a byte array in a format that SparkAgent can interpret, which is then sent to the SparkAgent through the socket. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0029844045639038086}, "created": {"value": false, "score": 3.272294998168945e-05}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.4153452515602112}, "created": {"value": false, "score": 0.00011998414993286133}, "shared": {"value": false, "score": 1.9669532775878906e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Apache Livy", "normalizedForm": "Apache Livy", "offsetStart": 111, "offsetEnd": 123}, "context": "To enable remote submission of the generated Scala script for Spark by the master wrapper, our setup relies on Apache Livy2 , which provides a REST service for easy submission of Spark jobs and Spark context management. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.13044798374176025}, "created": {"value": false, "score": 0.08340615034103394}, "shared": {"value": false, "score": 1.4841556549072266e-05}}, "documentContextAttributes": {"used": {"value": false, "score": 0.13044798374176025}, "created": {"value": false, "score": 0.08340615034103394}, "shared": {"value": false, "score": 1.4841556549072266e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Hive", "normalizedForm": "Hive", "offsetStart": 112, "offsetEnd": 116}, "context": "All the queries were run on a cluster of LeanXcale DQE instances, running the distributed wrappers for MongoDB, Hive, and Spark.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999398589134216}, "created": {"value": false, "score": 2.7835369110107422e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999398589134216}, "created": {"value": false, "score": 0.0001316070556640625}, "shared": {"value": false, "score": 5.662441253662109e-06}}}, {"type": "software", "software-type": "software", "wikidataId": "Q1165204", "wikipediaExternalRef": 21855450, "lang": "en", "confidence": 0.7457, "software-name": {"rawForm": "MongoDB", "normalizedForm": "MongoDB", "wikidataId": "Q1165204", "wikipediaExternalRef": 21855450, "lang": "en", "confidence": 0.7457, "offsetStart": 112, "offsetEnd": 119}, "context": "Here, we specifically focus on parallel joins across a relational table, the result of a JavaScript subquery to MongoDB, and the result of an MFR/Scala subquery to Apache Spark, but the concept relies on an API that allows its generalization to other script engines and data stores as well. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0018170475959777832}, "created": {"value": false, "score": 0.05537760257720947}, "shared": {"value": false, "score": 1.1324882507324219e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9999129176139832}, "shared": {"value": false, "score": 9.065866470336914e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "API", "normalizedForm": "API", "offsetStart": 113, "offsetEnd": 116}, "context": "The distributed wrapper for MongoDB comprises a number of instances of a Java class that implements the DataLake API, each of which embeds a JavaScript scripting engine that uses MongoDB's JavaScript client library. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.05950498580932617}, "created": {"value": false, "score": 0.0017822980880737305}, "shared": {"value": false, "score": 4.655122756958008e-05}}, "documentContextAttributes": {"used": {"value": false, "score": 0.05950498580932617}, "created": {"value": false, "score": 0.05537760257720947}, "shared": {"value": false, "score": 4.655122756958008e-05}}}, {"type": "software", "software-type": "software", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.3825, "software-name": {"rawForm": "Spark", "normalizedForm": "Spark", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.3825, "offsetStart": 113, "offsetEnd": 118}, "context": "JavaScript), that requests a dataset from the document database, and another script (e.g. in Python or Scala for Spark), that requests a chain of transformations on the unstructured data from the HDFS log before involving it into relational joins. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.005140244960784912}, "created": {"value": false, "score": 3.916025161743164e-05}, "shared": {"value": false, "score": 8.940696716308594e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9997756481170654}, "shared": {"value": false, "score": 1.4841556549072266e-05}}}, {"type": "software", "software-type": "software", "wikidataId": "Q1165204", "wikipediaExternalRef": 21855450, "lang": "en", "confidence": 0.7457, "software-name": {"rawForm": "MongoDB", "normalizedForm": "MongoDB", "wikidataId": "Q1165204", "wikipediaExternalRef": 21855450, "lang": "en", "confidence": 0.7457, "offsetStart": 113, "offsetEnd": 120}, "context": "Assuming that W1 is the master worker, it calls the listShards() method of its wrapper instance WR1 to query the MongoDB router for a list of MongoDB shards (database instances identified by host address and port), where partitions of the lineitem collection are stored.", "mentionContextAttributes": {"used": {"value": false, "score": 0.14902013540267944}, "created": {"value": false, "score": 1.6391277313232422e-05}, "shared": {"value": false, "score": 5.364418029785156e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9999129176139832}, "shared": {"value": false, "score": 9.065866470336914e-05}}}, {"type": "software", "software-type": "software", "wikidataId": "Q47607", "wikipediaExternalRef": 29004, "lang": "en", "confidence": 0.4606, "software-name": {"rawForm": "SQL", "normalizedForm": "SQL", "wikidataId": "Q47607", "wikipediaExternalRef": 29004, "lang": "en", "confidence": 0.4606, "offsetStart": 114, "offsetEnd": 117}, "context": "Section 6 presents the experimental evaluation of various parallel join queries across data stores using combined SQL, MFR, and native queries.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0011314153671264648}, "created": {"value": false, "score": 0.0008005499839782715}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9934203028678894}, "shared": {"value": false, "score": 0.010259866714477539}}}, {"type": "software", "software-type": "software", "wikidataId": "Q47607", "wikipediaExternalRef": 29004, "lang": "en", "confidence": 0.4606, "software-name": {"rawForm": "SQL", "normalizedForm": "SQL", "wikidataId": "Q47607", "wikipediaExternalRef": 29004, "lang": "en", "confidence": 0.4606, "offsetStart": 114, "offsetEnd": 117}, "context": "This, however, limits the use cases, since a data analyst cannot easily take advantage of this feature through an SQL query.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00020456314086914062}, "created": {"value": false, "score": 0.0001366138458251953}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9934203028678894}, "shared": {"value": false, "score": 0.010259866714477539}}}, {"type": "software", "software-type": "software", "wikidataId": "Q47607", "wikipediaExternalRef": 29004, "lang": "en", "confidence": 0.4606, "software-name": {"rawForm": "SQL", "normalizedForm": "SQL", "wikidataId": "Q47607", "wikipediaExternalRef": 29004, "lang": "en", "confidence": 0.4606, "offsetStart": 115, "offsetEnd": 118}, "context": "To better illustrate the necessity of enabling user-defined scripts to MongoDB as subqueries, rather than defining SQL mappings to document collections, let us consider the following MongoDB collection orders that has a highly non-relational structure:", "mentionContextAttributes": {"used": {"value": false, "score": 0.00022840499877929688}, "created": {"value": false, "score": 0.0009966492652893066}, "shared": {"value": false, "score": 5.364418029785156e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9934203028678894}, "shared": {"value": false, "score": 0.010259866714477539}}}, {"type": "software", "software-type": "software", "wikidataId": "Q29120", "wikipediaExternalRef": 5919308, "lang": "en", "confidence": 0.9056, "software-name": {"rawForm": "Hadoop", "normalizedForm": "Hadoop", "wikidataId": "Q29120", "wikipediaExternalRef": 5919308, "lang": "en", "confidence": 0.9056, "offsetStart": 115, "offsetEnd": 121}, "context": "HiveQL queries are decomposed to relational operators, which are then compiled to MapReduce jobs to be executed on Hadoop. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9755048155784607}, "created": {"value": false, "score": 4.45246696472168e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9755048155784607}, "created": {"value": false, "score": 0.10342800617218018}, "shared": {"value": false, "score": 0.010259866714477539}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LeanXcale", "normalizedForm": "LeanXcale", "offsetStart": 116, "offsetEnd": 125}, "context": "Fig. 11 shows the times for processing Q3 queries: with Spark SQL, with LeanXcale without using bind join, and with LeanXcale using bind join. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.969752848148346}, "created": {"value": false, "score": 4.708766937255859e-06}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999398589134216}, "created": {"value": true, "score": 0.9999358057975769}, "shared": {"value": false, "score": 8.52346420288086e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "DataLake API", "normalizedForm": "DataLake API", "offsetStart": 117, "offsetEnd": 129}, "context": "Each wrapper typically uses the client API of the corresponding data management cluster and implements the following DataLake API methods to be invoked by the query engine in order to provide parallel retrieval of shards (Fig. 3).", "mentionContextAttributes": {"used": {"value": false, "score": 0.0319443941116333}, "created": {"value": false, "score": 8.994340896606445e-05}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.0319443941116333}, "created": {"value": false, "score": 0.00882875919342041}, "shared": {"value": false, "score": 1.5914440155029297e-05}}}, {"type": "software", "software-type": "software", "wikidataId": "Q460584", "wikipediaExternalRef": 3254510, "lang": "en", "confidence": 0.2001, "software-name": {"rawForm": "Scala", "normalizedForm": "Scala", "wikidataId": "Q460584", "wikipediaExternalRef": 3254510, "lang": "en", "confidence": 0.2001, "offsetStart": 118, "offsetEnd": 123}, "context": "To achieve this, the query engine creates a session at the Spark driver, then translates the MFR subquery to code (in Scala or Python for Spark), delegates this code to Spark for execution, and collects the intermediate data through the same Spark driver session.", "mentionContextAttributes": {"used": {"value": false, "score": 0.20863837003707886}, "created": {"value": false, "score": 9.888410568237305e-05}, "shared": {"value": false, "score": 5.364418029785156e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999205470085144}, "created": {"value": true, "score": 0.9993940591812134}, "shared": {"value": false, "score": 1.4841556549072266e-05}}}, {"type": "software", "software-type": "software", "wikidataId": "Q1165204", "wikipediaExternalRef": 21855450, "lang": "en", "confidence": 0.7457, "software-name": {"rawForm": "MongoDB", "normalizedForm": "MongoDB", "wikidataId": "Q1165204", "wikipediaExternalRef": 21855450, "lang": "en", "confidence": 0.7457, "offsetStart": 118, "offsetEnd": 125}, "context": "Impala can access MongoDB collections through a MongoDB connector for Hadoop, designed to provide the ability to read MongoDB data into Hadoop MapReduce jobs.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0019541382789611816}, "created": {"value": false, "score": 0.0012637972831726074}, "shared": {"value": false, "score": 9.065866470336914e-05}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9999129176139832}, "shared": {"value": false, "score": 9.065866470336914e-05}}}, {"type": "software", "software-type": "software", "wikidataId": "Q1165204", "wikipediaExternalRef": 21855450, "lang": "en", "confidence": 0.7457, "software-name": {"rawForm": "MongoDB", "normalizedForm": "MongoDB", "wikidataId": "Q1165204", "wikipediaExternalRef": 21855450, "lang": "en", "confidence": 0.7457, "offsetStart": 118, "offsetEnd": 125}, "context": "In fact, ShardedCursor implements all DataLake API methods and hence serves as a proxy of the API into the JavaScript MongoDB client library.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0036196112632751465}, "created": {"value": false, "score": 0.0005892515182495117}, "shared": {"value": false, "score": 1.5914440155029297e-05}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9999129176139832}, "shared": {"value": false, "score": 9.065866470336914e-05}}}, {"type": "software", "software-type": "software", "wikidataId": "Q1165204", "wikipediaExternalRef": 21855450, "lang": "en", "confidence": 0.7457, "software-name": {"rawForm": "MongoDB", "normalizedForm": "MongoDB", "wikidataId": "Q1165204", "wikipediaExternalRef": 21855450, "lang": "en", "confidence": 0.7457, "offsetStart": 119, "offsetEnd": 126}, "context": "The intermediate data are then cached at the workers and a list of distinct values for the UID column is pushed to the MongoDB wrapper instances, to form the bind join condition.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999001622200012}, "created": {"value": false, "score": 7.092952728271484e-06}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9999129176139832}, "shared": {"value": false, "score": 9.065866470336914e-05}}}, {"type": "software", "software-type": "software", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.3825, "software-name": {"rawForm": "Spark", "normalizedForm": "Spark", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.3825, "offsetStart": 120, "offsetEnd": 125}, "context": "In terms of Apache Spark, a dataset corresponds to an RDD (Resilient Distributed Dataset -the basic programming unit of Spark). ", "mentionContextAttributes": {"used": {"value": false, "score": 0.01917022466659546}, "created": {"value": false, "score": 2.664327621459961e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9997756481170654}, "shared": {"value": false, "score": 1.4841556549072266e-05}}}, {"type": "software", "software-type": "software", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.3825, "software-name": {"rawForm": "Spark", "normalizedForm": "Spark", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.3825, "offsetStart": 120, "offsetEnd": 125}, "context": "On the other hand, as described above, when processing a partition, each Spark executor finds and sends to an available Spark agent all tuples of the partition.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0023292899131774902}, "created": {"value": false, "score": 4.678964614868164e-05}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9997756481170654}, "shared": {"value": false, "score": 1.4841556549072266e-05}}}, {"type": "software", "software-type": "software", "wikidataId": "Q1165204", "wikipediaExternalRef": 21855450, "lang": "en", "confidence": 0.7457, "software-name": {"rawForm": "MongoDB", "normalizedForm": "MongoDB", "wikidataId": "Q1165204", "wikipediaExternalRef": 21855450, "lang": "en", "confidence": 0.7457, "offsetStart": 120, "offsetEnd": 127}, "context": "Fig. 12. Execution times (in seconds) of Q4 queries joining the result of Q3 queries (1TB LeanXcale table joining 600GB MongoDB collection) with an MFR/Scala/Spark subquery against 240GB HDFS file.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999205470085144}, "created": {"value": false, "score": 4.0471553802490234e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9999129176139832}, "shared": {"value": false, "score": 9.065866470336914e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MongoCursor", "normalizedForm": "MongoCursor", "offsetStart": 120, "offsetEnd": 131}, "context": "To support parallel data retrieval, we further enhance the client library with JavaScript primitives that wrap standard MongoCursor objects (usually returned by a MongoDB JavaScript query) in Shard-edCursor objects, which are aware of the sharding of the underlying dataset. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0002295970916748047}, "created": {"value": false, "score": 0.0748090147972107}, "shared": {"value": false, "score": 2.682209014892578e-06}}, "documentContextAttributes": {"used": {"value": false, "score": 0.0002295970916748047}, "created": {"value": false, "score": 0.0748090147972107}, "shared": {"value": false, "score": 2.682209014892578e-06}}}, {"type": "software", "software-type": "software", "wikidataId": "Q47607", "wikipediaExternalRef": 29004, "lang": "en", "confidence": 0.4606, "software-name": {"rawForm": "SQL", "normalizedForm": "SQL", "wikidataId": "Q47607", "wikipediaExternalRef": 29004, "lang": "en", "confidence": 0.4606, "offsetStart": 121, "offsetEnd": 124}, "context": "The LeanXcale database has derived its OLAP query engine from Apache Calcite [8], a Java-based open-source framework for SQL query processing and optimization.", "mentionContextAttributes": {"used": {"value": true, "score": 0.6484044790267944}, "created": {"value": false, "score": 0.00020933151245117188}, "shared": {"value": false, "score": 8.52346420288086e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9934203028678894}, "shared": {"value": false, "score": 0.010259866714477539}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Apache", "normalizedForm": "Apache", "offsetStart": 121, "offsetEnd": 127}, "context": "In another example, a more sophisticated data transformation logic (such as a chain of user-defined transformations over Apache Spark RDDs) needs to be applied to unstructured data before processing by means of relational operators [9].", "mentionContextAttributes": {"used": {"value": false, "score": 5.370378494262695e-05}, "created": {"value": false, "score": 0.00018167495727539062}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.00023484230041503906}, "created": {"value": false, "score": 0.021330654621124268}, "shared": {"value": false, "score": 2.980232238769531e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CUSTOMER", "normalizedForm": "CUSTOMER", "offsetStart": 121, "offsetEnd": 129}, "context": "Query Q2 S evaluates just the parallel execution of the Experts MFR query on Spark, while Q2 SL involves a join with the CUSTOMER table from the LeanXcale data store: Fig. 10 shows the performance measurements of Q2 queries that stress on the evaluation of the parallel processing of MFR/Scala queries against Spark, with and without join with a LeanXcale table.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9895274043083191}, "created": {"value": false, "score": 2.3245811462402344e-06}, "shared": {"value": false, "score": 5.364418029785156e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999273419380188}, "created": {"value": false, "score": 3.159046173095703e-06}, "shared": {"value": false, "score": 1.0132789611816406e-06}}}, {"type": "software", "software-type": "software", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.3825, "software-name": {"rawForm": "Spark", "normalizedForm": "Spark", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.3825, "offsetStart": 122, "offsetEnd": 127}, "context": "All the queries were run on a cluster of LeanXcale DQE instances, running the distributed wrappers for MongoDB, Hive, and Spark.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999398589134216}, "created": {"value": false, "score": 2.7835369110107422e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9997756481170654}, "shared": {"value": false, "score": 1.4841556549072266e-05}}}, {"type": "software", "software-type": "software", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.3825, "software-name": {"rawForm": "Spark", "normalizedForm": "Spark", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.3825, "offsetStart": 122, "offsetEnd": 127}, "context": "aggregation pipelines), beyond the trivial SQL mappings; (b) parallel map/filter/reduce subqueries, done natively through Spark RDD transformations; (c) parallel joins and scalability.", "mentionContextAttributes": {"used": {"value": false, "score": 0.048490285873413086}, "created": {"value": false, "score": 5.781650543212891e-06}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9997756481170654}, "shared": {"value": false, "score": 1.4841556549072266e-05}}}, {"type": "software", "software-type": "software", "wikidataId": "Q460584", "wikipediaExternalRef": 3254510, "lang": "en", "confidence": 0.2001, "software-name": {"rawForm": "Scala", "normalizedForm": "Scala", "wikidataId": "Q460584", "wikipediaExternalRef": 3254510, "lang": "en", "confidence": 0.2001, "offsetStart": 122, "offsetEnd": 127}, "context": "In particular, even in the context of LeanXcale DQE with 2 bind joins sophisticated subqueries expressed as JavaScript or Scala code, parallel join processing shows good speedup with increase of the parallelism level.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00011390447616577148}, "created": {"value": false, "score": 7.927417755126953e-06}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999205470085144}, "created": {"value": true, "score": 0.9993940591812134}, "shared": {"value": false, "score": 1.4841556549072266e-05}}}, {"type": "software", "software-type": "software", "wikidataId": "Q1165204", "wikipediaExternalRef": 21855450, "lang": "en", "confidence": 0.7457, "software-name": {"rawForm": "MongoDB", "normalizedForm": "MongoDB", "wikidataId": "Q1165204", "wikipediaExternalRef": 21855450, "lang": "en", "confidence": 0.7457, "offsetStart": 122, "offsetEnd": 129}, "context": "Query Q2 M evaluates just the parallel execution of the BookOrders script in MongoDB, while Q2 ML involves a join between MongoDB and the CUSTOMER table from the LeanXcale data store: Fig. 9 shows the performance measurements of Q2 queries that stress on the evaluation of the parallel processing of highly expressive JavaScript queries, with and without join with a LeanXcale table.", "mentionContextAttributes": {"used": {"value": true, "score": 0.7139508724212646}, "created": {"value": false, "score": 3.159046173095703e-06}, "shared": {"value": false, "score": 1.0132789611816406e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9999129176139832}, "shared": {"value": false, "score": 9.065866470336914e-05}}}, {"type": "software", "software-type": "software", "wikidataId": "Q47607", "wikipediaExternalRef": 29004, "lang": "en", "confidence": 0.4606, "software-name": {"rawForm": "SQL", "normalizedForm": "SQL", "wikidataId": "Q47607", "wikipediaExternalRef": 29004, "lang": "en", "confidence": 0.4606, "offsetStart": 123, "offsetEnd": 126}, "context": "Thus, tightly-coupled systems take advantage of massive parallelism by bringing in parallel shards from HDFS tables to the SQL database nodes and doing parallel joins.", "mentionContextAttributes": {"used": {"value": false, "score": 4.559755325317383e-05}, "created": {"value": false, "score": 0.00011223554611206055}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9934203028678894}, "shared": {"value": false, "score": 0.010259866714477539}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Cosmos", "normalizedForm": "Cosmos", "offsetStart": 123, "offsetEnd": 129}, "context": "SCOPE [12] is a declarative language from Microsoft designed to specify the processing of large sequential files stored in Cosmos, a distributed computing platform. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.00011140108108520508}, "created": {"value": false, "score": 0.031117558479309082}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.00011140108108520508}, "created": {"value": false, "score": 0.031117558479309082}, "shared": {"value": false, "score": 2.980232238769531e-07}}}, {"type": "software", "software-type": "software", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.3825, "software-name": {"rawForm": "Spark", "normalizedForm": "Spark", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.3825, "offsetStart": 124, "offsetEnd": 129}, "context": "A discovery service is introduced through the special component Spark Agent Registry that keeps information about available Spark wrapper instances and dispatches them to the requesting Spark workers so that parallelism is fully exploited in moving data from a Spark RDD to the DQE.", "mentionContextAttributes": {"used": {"value": false, "score": 0.005214571952819824}, "created": {"value": false, "score": 0.003361940383911133}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9997756481170654}, "shared": {"value": false, "score": 1.4841556549072266e-05}}}, {"type": "software", "software-type": "software", "wikidataId": "Q1165204", "wikipediaExternalRef": 21855450, "lang": "en", "confidence": 0.7457, "software-name": {"rawForm": "MongoDB", "normalizedForm": "MongoDB", "wikidataId": "Q1165204", "wikipediaExternalRef": 21855450, "lang": "en", "confidence": 0.7457, "offsetStart": 124, "offsetEnd": 131}, "context": "Workflow managers dispatch the execution of a query/workflow plan to underlying data processing platforms, hence can access MongoDB through the platforms, e.g., Spark using the Spark MongoDB connector.", "mentionContextAttributes": {"used": {"value": false, "score": 0.005359172821044922}, "created": {"value": false, "score": 2.9027462005615234e-05}, "shared": {"value": false, "score": 3.635883331298828e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9999129176139832}, "shared": {"value": false, "score": 9.065866470336914e-05}}}, {"type": "software", "software-type": "software", "wikidataId": "Q1165204", "wikipediaExternalRef": 21855450, "lang": "en", "confidence": 0.7457, "software-name": {"rawForm": "MongoDB", "normalizedForm": "MongoDB", "wikidataId": "Q1165204", "wikipediaExternalRef": 21855450, "lang": "en", "confidence": 0.7457, "offsetStart": 126, "offsetEnd": 133}, "context": "Furthermore, we aim at processing this join in the most efficient way, i.e. in parallel, by allowing parallel handling of the MongoDB subquery and parallel retrieval of its result set.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00012254714965820312}, "created": {"value": true, "score": 0.9474247097969055}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9999129176139832}, "shared": {"value": false, "score": 9.065866470336914e-05}}}, {"type": "software", "software-type": "software", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.3825, "software-name": {"rawForm": "Spark", "normalizedForm": "Spark", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.3825, "offsetStart": 127, "offsetEnd": 132}, "context": "All the three data stores and the query engine are evenly distributed across all the nodes, i.e. shards of each data store and Spark workers are collocated at each node.", "mentionContextAttributes": {"used": {"value": false, "score": 0.2777785062789917}, "created": {"value": false, "score": 5.3822994232177734e-05}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9997756481170654}, "shared": {"value": false, "score": 1.4841556549072266e-05}}}, {"type": "software", "software-type": "software", "wikidataId": "Q29120", "wikipediaExternalRef": 5919308, "lang": "en", "confidence": 0.9056, "software-name": {"rawForm": "Hadoop", "normalizedForm": "Hadoop", "wikidataId": "Q29120", "wikipediaExternalRef": 5919308, "lang": "en", "confidence": 0.9056, "offsetStart": 127, "offsetEnd": 133}, "context": "Tightly-coupled systems can perform parallel joins, but since they are focused only on the tight integration between RDBMS and Hadoop stores, cannot be extended to support NoSQL stores.", "mentionContextAttributes": {"used": {"value": false, "score": 8.45789909362793e-05}, "created": {"value": false, "score": 4.3332576751708984e-05}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9755048155784607}, "created": {"value": false, "score": 0.10342800617218018}, "shared": {"value": false, "score": 0.010259866714477539}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Python", "normalizedForm": "Python", "offsetStart": 127, "offsetEnd": 133}, "context": "To achieve this, the query engine creates a session at the Spark driver, then translates the MFR subquery to code (in Scala or Python for Spark), delegates this code to Spark for execution, and collects the intermediate data through the same Spark driver session.", "mentionContextAttributes": {"used": {"value": false, "score": 0.20863837003707886}, "created": {"value": false, "score": 9.888410568237305e-05}, "shared": {"value": false, "score": 5.364418029785156e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.20863837003707886}, "created": {"value": false, "score": 0.0032500028610229492}, "shared": {"value": false, "score": 4.470348358154297e-06}}}, {"type": "software", "software-type": "software", "wikidataId": "Q187432", "wikipediaExternalRef": 21490336, "lang": "en", "confidence": 0.5074, "software-name": {"rawForm": "scripts", "normalizedForm": "scripts", "wikidataId": "Q187432", "wikipediaExternalRef": 21490336, "lang": "en", "confidence": 0.5074, "offsetStart": 127, "offsetEnd": 134}, "context": "\u2022 Highly expressive queries: adopt he polyglot approach of the CloudMdsQL query language to allow data store native queries or scripts to be expressed as inline subqueries.", "mentionContextAttributes": {"used": {"value": false, "score": 2.7477741241455078e-05}, "created": {"value": false, "score": 0.0054280757904052734}, "shared": {"value": false, "score": 4.172325134277344e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.0027613043785095215}, "created": {"value": true, "score": 0.9998281002044678}, "shared": {"value": false, "score": 2.3245811462402344e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "code", "normalizedForm": "code", "offsetStart": 128, "offsetEnd": 132}, "context": "In particular, even in the context of LeanXcale DQE with 2 bind joins sophisticated subqueries expressed as JavaScript or Scala code, parallel join processing shows good speedup with increase of the parallelism level.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00011390447616577148}, "created": {"value": false, "score": 7.927417755126953e-06}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.919108510017395}, "created": {"value": true, "score": 0.9997756481170654}, "shared": {"value": false, "score": 2.562999725341797e-06}}}, {"type": "software", "software-type": "software", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.3825, "software-name": {"rawForm": "Spark", "normalizedForm": "Spark", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.3825, "offsetStart": 128, "offsetEnd": 133}, "context": "In another example, a more sophisticated data transformation logic (such as a chain of user-defined transformations over Apache Spark RDDs) needs to be applied to unstructured data before processing by means of relational operators [9].", "mentionContextAttributes": {"used": {"value": false, "score": 5.370378494262695e-05}, "created": {"value": false, "score": 0.00018167495727539062}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9997756481170654}, "shared": {"value": false, "score": 1.4841556549072266e-05}}}, {"type": "software", "software-type": "software", "wikidataId": "Q1165204", "wikipediaExternalRef": 21855450, "lang": "en", "confidence": 0.7457, "software-name": {"rawForm": "MongoDB", "normalizedForm": "MongoDB", "wikidataId": "Q1165204", "wikipediaExternalRef": 21855450, "lang": "en", "confidence": 0.7457, "offsetStart": 128, "offsetEnd": 135}, "context": "Note that, as opposed to the behavior of the original find() method, a call to find-Sharded() does not immediately initiate the MongoDB subquery execution, but only memorizes the filter condition (the method argument), if any, in the returned Shard-edCursor object.", "mentionContextAttributes": {"used": {"value": false, "score": 0.048179447650909424}, "created": {"value": false, "score": 3.415346145629883e-05}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9999129176139832}, "shared": {"value": false, "score": 9.065866470336914e-05}}}, {"type": "software", "software-type": "software", "wikidataId": "Q1165204", "wikipediaExternalRef": 21855450, "lang": "en", "confidence": 0.7457, "software-name": {"rawForm": "MongoDB", "normalizedForm": "MongoDB", "wikidataId": "Q1165204", "wikipediaExternalRef": 21855450, "lang": "en", "confidence": 0.7457, "offsetStart": 129, "offsetEnd": 136}, "context": "The concept of parallel querying against a MongoDB cluster is built on the assumption that each DQE worker can access directly a MongoDB shard, bypassing the MongoDB router in order to sustain parallelism.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00023818016052246094}, "created": {"value": false, "score": 0.0005997419357299805}, "shared": {"value": false, "score": 4.172325134277344e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9999129176139832}, "shared": {"value": false, "score": 9.065866470336914e-05}}}, {"type": "software", "software-type": "software", "wikidataId": "Q1165204", "wikipediaExternalRef": 21855450, "lang": "en", "confidence": 0.7457, "software-name": {"rawForm": "MongoDB", "normalizedForm": "MongoDB", "wikidataId": "Q1165204", "wikipediaExternalRef": 21855450, "lang": "en", "confidence": 0.7457, "offsetStart": 130, "offsetEnd": 137}, "context": "To use the same mechanism for controlling the selectivity of the second join, the keywords for each book item in the Orders_Items MongoDB collection are generated in a way that a selectivity factor SF on the first join results in about the same SF on the second join.", "mentionContextAttributes": {"used": {"value": false, "score": 0.22697579860687256}, "created": {"value": false, "score": 4.89354133605957e-05}, "shared": {"value": false, "score": 4.172325134277344e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9999129176139832}, "shared": {"value": false, "score": 9.065866470336914e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "code", "normalizedForm": "code", "offsetStart": 131, "offsetEnd": 135}, "context": "In order to make the wrapper instances collect in parallel partitions of the resulting RDD, the master wrapper ships an additional code together with the user defined script, that makes each RDD partition push its data directly to the assigned by the registry wrapper instance.", "mentionContextAttributes": {"used": {"value": false, "score": 0.10720396041870117}, "created": {"value": false, "score": 3.1888484954833984e-05}, "shared": {"value": false, "score": 6.556510925292969e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.919108510017395}, "created": {"value": true, "score": 0.9997756481170654}, "shared": {"value": false, "score": 2.562999725341797e-06}}}, {"type": "software", "software-type": "implicit", "wikidataId": "Q187432", "wikipediaExternalRef": 21490336, "lang": "en", "confidence": 0.5074, "software-name": {"rawForm": "scripts", "normalizedForm": "scripts", "wikidataId": "Q187432", "wikipediaExternalRef": 21490336, "lang": "en", "confidence": 0.5074, "offsetStart": 131, "offsetEnd": 138}, "context": "CloudMdsQL [23,26] with its MFR (map/filter/reduce) extensions [9] even allows data store native queries to be expressed as inline scripts and combined with regular SQL statements in ad-hoc integration queries. ", "mentionContextAttributes": {"used": {"value": false, "score": 6.93202018737793e-05}, "created": {"value": false, "score": 1.5437602996826172e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.0027613043785095215}, "created": {"value": true, "score": 0.9998281002044678}, "shared": {"value": false, "score": 2.3245811462402344e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LeanXcale", "normalizedForm": "LeanXcale", "offsetStart": 131, "offsetEnd": 140}, "context": "Section 4 gives an overview of the query language with its polyglot capabilities and discusses the distributed architecture of the LeanXcale query engine. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0008640289306640625}, "created": {"value": false, "score": 0.0015274882316589355}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999398589134216}, "created": {"value": true, "score": 0.9999358057975769}, "shared": {"value": false, "score": 8.52346420288086e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "code", "normalizedForm": "code", "offsetStart": 132, "offsetEnd": 136}, "context": "And third, the query needs to be expressive enough, so as to combine an SQL subquery (to the relational database) with an arbitrary code in a scripting language (e.g.", "mentionContextAttributes": {"used": {"value": false, "score": 0.055995404720306396}, "created": {"value": false, "score": 5.322694778442383e-05}, "shared": {"value": false, "score": 4.172325134277344e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.919108510017395}, "created": {"value": true, "score": 0.9997756481170654}, "shared": {"value": false, "score": 2.562999725341797e-06}}}, {"type": "software", "software-type": "software", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.3825, "software-name": {"rawForm": "Spark", "normalizedForm": "Spark", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.3825, "offsetStart": 132, "offsetEnd": 137}, "context": "In particular, we want to stress on the full parallelism to access the underlying datasets, in our case, a MongoDB collection and a Spark RDD, in the context of expressive subqueries.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0002913475036621094}, "created": {"value": true, "score": 0.852451741695404}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9997756481170654}, "shared": {"value": false, "score": 1.4841556549072266e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LeanXcale", "normalizedForm": "LeanXcale", "offsetStart": 132, "offsetEnd": 141}, "context": "The data itself are stored on a proprietary relational key-value store, KiVi, which allows for efficient horizontal partitioning of LeanXcale tables and indexes, based on the primary key or index key.", "mentionContextAttributes": {"used": {"value": false, "score": 0.49036771059036255}, "created": {"value": false, "score": 0.00030303001403808594}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999398589134216}, "created": {"value": true, "score": 0.9999358057975769}, "shared": {"value": false, "score": 8.52346420288086e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CloudMdsQL", "normalizedForm": "CloudMdsQL", "offsetStart": 132, "offsetEnd": 142}, "context": "To preserve the expressivity of the underlying data stores' query/scripting languages, we use the polyglot approach provided by the CloudMdsQL query language, which also enables the use of bind joins [19] to optimize the execution of selective queries.", "mentionContextAttributes": {"used": {"value": false, "score": 0.10021162033081055}, "created": {"value": false, "score": 0.00014162063598632812}, "shared": {"value": false, "score": 5.364418029785156e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.10021162033081055}, "created": {"value": true, "score": 0.9999358057975769}, "shared": {"value": false, "score": 2.3245811462402344e-06}}, "references": [{"label": "[26]", "normalizedForm": "[26]", "refKey": 26}, {"label": "[26]", "normalizedForm": "[26]", "refKey": 26}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "DataLake API", "normalizedForm": "DataLake API", "offsetStart": 133, "offsetEnd": 145}, "context": "\u2022 Extensibility: allow for other parallel data stores to be added by implementing adapters through a flexible programming interface (DataLake API, see Section 5.2). ", "mentionContextAttributes": {"used": {"value": false, "score": 7.385015487670898e-05}, "created": {"value": false, "score": 0.0007221698760986328}, "shared": {"value": false, "score": 1.2516975402832031e-06}}, "documentContextAttributes": {"used": {"value": false, "score": 0.0319443941116333}, "created": {"value": false, "score": 0.00882875919342041}, "shared": {"value": false, "score": 1.5914440155029297e-05}}}, {"type": "software", "software-type": "software", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.3825, "software-name": {"rawForm": "Spark", "normalizedForm": "Spark", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.3825, "offsetStart": 135, "offsetEnd": 140}, "context": "For Spark result sets, this overhead is a bit higher, because of the additional serialization/deserialization that takes place between Spark executors and SparkAgent instances.", "mentionContextAttributes": {"used": {"value": false, "score": 0.034141480922698975}, "created": {"value": false, "score": 2.0802021026611328e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9997756481170654}, "shared": {"value": false, "score": 1.4841556549072266e-05}}}, {"type": "software", "software-type": "software", "wikidataId": "Q1165204", "wikipediaExternalRef": 21855450, "lang": "en", "confidence": 0.7457, "software-name": {"rawForm": "MongoDB", "normalizedForm": "MongoDB", "wikidataId": "Q1165204", "wikipediaExternalRef": 21855450, "lang": "en", "confidence": 0.7457, "offsetStart": 135, "offsetEnd": 142}, "context": "Since MongoDB collections are used directly in the FROM clause as tables, the storage plugin translates relational operators to native MongoDB queries.", "mentionContextAttributes": {"used": {"value": false, "score": 0.09908026456832886}, "created": {"value": false, "score": 1.1861324310302734e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9999129176139832}, "shared": {"value": false, "score": 9.065866470336914e-05}}}, {"type": "software", "software-type": "software", "wikidataId": "Q1165204", "wikipediaExternalRef": 21855450, "lang": "en", "confidence": 0.7457, "software-name": {"rawForm": "MongoDB", "normalizedForm": "MongoDB", "wikidataId": "Q1165204", "wikipediaExternalRef": 21855450, "lang": "en", "confidence": 0.7457, "offsetStart": 135, "offsetEnd": 142}, "context": "As an example, elaborated in our previous work [24], we addressed the scenario of joining a sharded document collection, residing in a MongoDB cluster, with a partitioned table from a distributed relational database or a distributed HDFS dataset.", "mentionContextAttributes": {"used": {"value": false, "score": 0.03199189901351929}, "created": {"value": true, "score": 0.7937895655632019}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9999129176139832}, "shared": {"value": false, "score": 9.065866470336914e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LeanXcale", "normalizedForm": "LeanXcale", "offsetStart": 135, "offsetEnd": 144}, "context": "Fig. 12 shows the times for processing Q4 queries, involving 2 joins: with Spark SQL, with LeanXcale without using bind join, and with LeanXcale using bind join. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.986201822757721}, "created": {"value": false, "score": 1.1026859283447266e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999398589134216}, "created": {"value": true, "score": 0.9999358057975769}, "shared": {"value": false, "score": 8.52346420288086e-06}}}, {"type": "software", "software-type": "software", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.3825, "software-name": {"rawForm": "Spark", "normalizedForm": "Spark", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.3825, "offsetStart": 136, "offsetEnd": 141}, "context": "Spark SQL provides a DataFrame API that can map to relations arbitrary object collections and thus enables relational operations across Spark's RDDs and external data sources.", "mentionContextAttributes": {"used": {"value": false, "score": 8.469820022583008e-05}, "created": {"value": false, "score": 0.0007729530334472656}, "shared": {"value": false, "score": 1.4901161193847656e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9997756481170654}, "shared": {"value": false, "score": 1.4841556549072266e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Hadoop MapReduce", "normalizedForm": "Hadoop MapReduce", "offsetStart": 136, "offsetEnd": 152}, "context": "Impala can access MongoDB collections through a MongoDB connector for Hadoop, designed to provide the ability to read MongoDB data into Hadoop MapReduce jobs.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0019541382789611816}, "created": {"value": false, "score": 0.0012637972831726074}, "shared": {"value": false, "score": 9.065866470336914e-05}}, "documentContextAttributes": {"used": {"value": false, "score": 0.0028700828552246094}, "created": {"value": false, "score": 0.0012637972831726074}, "shared": {"value": false, "score": 9.065866470336914e-05}}}, {"type": "software", "software-type": "software", "wikidataId": "Q1165204", "wikipediaExternalRef": 21855450, "lang": "en", "confidence": 0.7457, "software-name": {"rawForm": "MongoDB", "normalizedForm": "MongoDB", "wikidataId": "Q1165204", "wikipediaExternalRef": 21855450, "lang": "en", "confidence": 0.7457, "offsetStart": 137, "offsetEnd": 144}, "context": "Thus, Q4 is defined as follows: Using bind join, the query executes as follows: first, the join between CLICKS at HDFS and BookOrders at MongoDB takes place, as in Q3; then, after flattening O.keywords and identifying the list of distinct keywords, another bind join condition is pushed to the Experts subquery to Spark, as described in Section 5.1, to reduce the amount of data processed by Spark transformations.", "mentionContextAttributes": {"used": {"value": true, "score": 0.6309001445770264}, "created": {"value": false, "score": 1.7285346984863281e-06}, "shared": {"value": false, "score": 8.940696716308594e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9999129176139832}, "shared": {"value": false, "score": 9.065866470336914e-05}}}, {"type": "software", "software-type": "software", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.3825, "software-name": {"rawForm": "Spark", "normalizedForm": "Spark", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.3825, "offsetStart": 138, "offsetEnd": 143}, "context": "To achieve this, the query engine creates a session at the Spark driver, then translates the MFR subquery to code (in Scala or Python for Spark), delegates this code to Spark for execution, and collects the intermediate data through the same Spark driver session.", "mentionContextAttributes": {"used": {"value": false, "score": 0.20863837003707886}, "created": {"value": false, "score": 9.888410568237305e-05}, "shared": {"value": false, "score": 5.364418029785156e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9997756481170654}, "shared": {"value": false, "score": 1.4841556549072266e-05}}}, {"type": "software", "software-type": "software", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.3825, "software-name": {"rawForm": "Spark", "normalizedForm": "Spark", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.3825, "offsetStart": 138, "offsetEnd": 143}, "context": "Similarly to the previous test case, the performance evaluation shows that the ability for applying bind join that cannot be handled with Spark SQL gives our approach a significant advantage for selective queries.", "mentionContextAttributes": {"used": {"value": true, "score": 0.7948041558265686}, "created": {"value": false, "score": 0.00012230873107910156}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9997756481170654}, "shared": {"value": false, "score": 1.4841556549072266e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "REDUCE", "normalizedForm": "REDUCE", "offsetStart": 138, "offsetEnd": 144}, "context": "The greatest advantage of these rules can be observed when Rule #2 is applicable, as it enables early filtering of the input to expensive REDUCE operators.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0007332563400268555}, "created": {"value": false, "score": 0.00020503997802734375}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9995518326759338}, "created": {"value": false, "score": 0.00020503997802734375}, "shared": {"value": false, "score": 2.4437904357910156e-06}}}, {"type": "software", "software-type": "software", "wikidataId": "Q1165204", "wikipediaExternalRef": 21855450, "lang": "en", "confidence": 0.7457, "software-name": {"rawForm": "MongoDB", "normalizedForm": "MongoDB", "wikidataId": "Q1165204", "wikipediaExternalRef": 21855450, "lang": "en", "confidence": 0.7457, "offsetStart": 138, "offsetEnd": 145}, "context": "For comparison with the state of the art, the large-scale test case queries were also performed on a Spark SQL cluster, where we used the MongoDB Spark connector to access MongoDB shards in parallel.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": false, "score": 1.5795230865478516e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9999129176139832}, "shared": {"value": false, "score": 9.065866470336914e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CUSTOMER", "normalizedForm": "CUSTOMER", "offsetStart": 138, "offsetEnd": 146}, "context": "Query Q2 M evaluates just the parallel execution of the BookOrders script in MongoDB, while Q2 ML involves a join between MongoDB and the CUSTOMER table from the LeanXcale data store: Fig. 9 shows the performance measurements of Q2 queries that stress on the evaluation of the parallel processing of highly expressive JavaScript queries, with and without join with a LeanXcale table. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.7139508724212646}, "created": {"value": false, "score": 3.159046173095703e-06}, "shared": {"value": false, "score": 1.0132789611816406e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999273419380188}, "created": {"value": false, "score": 3.159046173095703e-06}, "shared": {"value": false, "score": 1.0132789611816406e-06}}}, {"type": "software", "software-type": "software", "wikidataId": "Q1165204", "wikipediaExternalRef": 21855450, "lang": "en", "confidence": 0.7457, "software-name": {"rawForm": "MongoDB", "normalizedForm": "MongoDB", "wikidataId": "Q1165204", "wikipediaExternalRef": 21855450, "lang": "en", "confidence": 0.7457, "offsetStart": 140, "offsetEnd": 147}, "context": "As our work fits in this category, we will briefly discuss some of the existing solutions, focusing on their capabilities to integrate with MongoDB as a representative example of a non-relational data store.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0001659393310546875}, "created": {"value": true, "score": 0.9992099404335022}, "shared": {"value": false, "score": 1.0132789611816406e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9999129176139832}, "shared": {"value": false, "score": 9.065866470336914e-05}}}, {"type": "software", "software-type": "software", "wikidataId": "Q1165204", "wikipediaExternalRef": 21855450, "lang": "en", "confidence": 0.7457, "software-name": {"rawForm": "MongoDB", "normalizedForm": "MongoDB", "wikidataId": "Q1165204", "wikipediaExternalRef": 21855450, "lang": "en", "confidence": 0.7457, "offsetStart": 141, "offsetEnd": 148}, "context": "First, the wrapper verifies that the MongoDB balancer is not running in background, because otherwise it may be moving chunks of data across MongoDB shards at the same time the query is being executed, which may result in inconsistent reads. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.10765993595123291}, "created": {"value": false, "score": 1.3887882232666016e-05}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9999129176139832}, "shared": {"value": false, "score": 9.065866470336914e-05}}}, {"type": "software", "software-type": "software", "wikidataId": "Q47607", "wikipediaExternalRef": 29004, "lang": "en", "confidence": 0.4606, "software-name": {"rawForm": "SQL", "normalizedForm": "SQL", "wikidataId": "Q47607", "wikipediaExternalRef": 29004, "lang": "en", "confidence": 0.4606, "offsetStart": 142, "offsetEnd": 145}, "context": "Assuming that the distinct values of B.id are b1 \u2026 bn, the query to retrieve the right-hand side relation of the bind join uses the following SQL approach (or its equivalent according to the data store's query language), thus retrieving from A only the rows that match the join criteria:", "mentionContextAttributes": {"used": {"value": true, "score": 0.9644235968589783}, "created": {"value": false, "score": 1.3709068298339844e-06}, "shared": {"value": false, "score": 5.364418029785156e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9934203028678894}, "shared": {"value": false, "score": 0.010259866714477539}}}, {"type": "software", "software-type": "software", "wikidataId": "Q1165204", "wikipediaExternalRef": 21855450, "lang": "en", "confidence": 0.7457, "software-name": {"rawForm": "MongoDB", "normalizedForm": "MongoDB", "wikidataId": "Q1165204", "wikipediaExternalRef": 21855450, "lang": "en", "confidence": 0.7457, "offsetStart": 142, "offsetEnd": 149}, "context": "These data management clusters can range from distributed raw data files, through parallel SQL databases, to sharded NoSQL databases (such as MongoDB, where queries can be expressed as JavaScript programs) and parallel data processing frameworks (such as Apache Spark, where data retrieval and/or transformation can be requested by means of Python or Scala scripting).", "mentionContextAttributes": {"used": {"value": false, "score": 0.0007843375205993652}, "created": {"value": false, "score": 0.0032500028610229492}, "shared": {"value": false, "score": 4.470348358154297e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9999129176139832}, "shared": {"value": false, "score": 9.065866470336914e-05}}}, {"type": "software", "software-type": "software", "wikidataId": "Q1165204", "wikipediaExternalRef": 21855450, "lang": "en", "confidence": 0.7457, "software-name": {"rawForm": "MongoDB", "normalizedForm": "MongoDB", "wikidataId": "Q1165204", "wikipediaExternalRef": 21855450, "lang": "en", "confidence": 0.7457, "offsetStart": 142, "offsetEnd": 149}, "context": "Assuming that W1 is the master worker, it calls the listShards() method of its wrapper instance WR1 to query the MongoDB router for a list of MongoDB shards (database instances identified by host address and port), where partitions of the lineitem collection are stored.", "mentionContextAttributes": {"used": {"value": false, "score": 0.14902013540267944}, "created": {"value": false, "score": 1.6391277313232422e-05}, "shared": {"value": false, "score": 5.364418029785156e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9999129176139832}, "shared": {"value": false, "score": 9.065866470336914e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LeanXcale", "normalizedForm": "LeanXcale", "offsetStart": 142, "offsetEnd": 151}, "context": "At this point, the DQE is ready to involve the partitioned intermediate relation LINEITEM in the execution of a parallel join with the native LeanXcale partitioned table ORDERS.", "mentionContextAttributes": {"used": {"value": false, "score": 0.002438962459564209}, "created": {"value": false, "score": 0.0007367134094238281}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999398589134216}, "created": {"value": true, "score": 0.9999358057975769}, "shared": {"value": false, "score": 8.52346420288086e-06}}}, {"type": "software", "software-type": "software", "wikidataId": "Q47607", "wikipediaExternalRef": 29004, "lang": "en", "confidence": 0.4606, "software-name": {"rawForm": "SQL", "normalizedForm": "SQL", "wikidataId": "Q47607", "wikipediaExternalRef": 29004, "lang": "en", "confidence": 0.4606, "offsetStart": 144, "offsetEnd": 147}, "context": "Applications connect to one of the multiple DQE instances running, which exposes a typical JDBC interface to the applications, with support for SQL and transactions.", "mentionContextAttributes": {"used": {"value": false, "score": 0.015118658542633057}, "created": {"value": false, "score": 0.0001728534698486328}, "shared": {"value": false, "score": 4.172325134277344e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9934203028678894}, "shared": {"value": false, "score": 0.010259866714477539}}}, {"type": "software", "software-type": "software", "wikidataId": "Q47607", "wikipediaExternalRef": 29004, "lang": "en", "confidence": 0.4606, "software-name": {"rawForm": "SQL", "normalizedForm": "SQL", "wikidataId": "Q47607", "wikipediaExternalRef": 29004, "lang": "en", "confidence": 0.4606, "offsetStart": 144, "offsetEnd": 147}, "context": "Similarly to the previous test case, the performance evaluation shows that the ability for applying bind join that cannot be handled with Spark SQL gives our approach a significant advantage for selective queries.", "mentionContextAttributes": {"used": {"value": true, "score": 0.7948041558265686}, "created": {"value": false, "score": 0.00012230873107910156}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9934203028678894}, "shared": {"value": false, "score": 0.010259866714477539}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LeanXcale", "normalizedForm": "LeanXcale", "offsetStart": 145, "offsetEnd": 154}, "context": "Query Q2 S evaluates just the parallel execution of the Experts MFR query on Spark, while Q2 SL involves a join with the CUSTOMER table from the LeanXcale data store: Fig. 10 shows the performance measurements of Q2 queries that stress on the evaluation of the parallel processing of MFR/Scala queries against Spark, with and without join with a LeanXcale table.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9895274043083191}, "created": {"value": false, "score": 2.3245811462402344e-06}, "shared": {"value": false, "score": 5.364418029785156e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999398589134216}, "created": {"value": true, "score": 0.9999358057975769}, "shared": {"value": false, "score": 8.52346420288086e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CloudMdsQL", "normalizedForm": "CloudMdsQL", "offsetStart": 145, "offsetEnd": 155}, "context": "In this paper, we introduced a parallel polystore system that builds on top of LeanXcale's distributed query engine and processes queries in the CloudMdsQL query language. ", "mentionContextAttributes": {"used": {"value": false, "score": 3.629922866821289e-05}, "created": {"value": true, "score": 0.9999358057975769}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.10021162033081055}, "created": {"value": true, "score": 0.9999358057975769}, "shared": {"value": false, "score": 2.3245811462402344e-06}}, "references": [{"label": "[26]", "normalizedForm": "[26]", "refKey": 26}, {"label": "[26]", "normalizedForm": "[26]", "refKey": 26}]}, {"type": "software", "software-type": "software", "wikidataId": "Q460584", "wikipediaExternalRef": 3254510, "lang": "en", "confidence": 0.2001, "software-name": {"rawForm": "Scala", "normalizedForm": "Scala", "wikidataId": "Q460584", "wikipediaExternalRef": 3254510, "lang": "en", "confidence": 0.2001, "offsetStart": 146, "offsetEnd": 151}, "context": "Here, we specifically focus on parallel joins across a relational table, the result of a JavaScript subquery to MongoDB, and the result of an MFR/Scala subquery to Apache Spark, but the concept relies on an API that allows its generalization to other script engines and data stores as well.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0018170475959777832}, "created": {"value": false, "score": 0.05537760257720947}, "shared": {"value": false, "score": 1.1324882507324219e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999205470085144}, "created": {"value": true, "score": 0.9993940591812134}, "shared": {"value": false, "score": 1.4841556549072266e-05}}}, {"type": "software", "software-type": "software", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.3825, "software-name": {"rawForm": "Spark", "normalizedForm": "Spark", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.3825, "offsetStart": 146, "offsetEnd": 151}, "context": "For comparison with the state of the art, the large-scale test case queries were also performed on a Spark SQL cluster, where we used the MongoDB Spark connector to access MongoDB shards in parallel.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": false, "score": 1.5795230865478516e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9997756481170654}, "shared": {"value": false, "score": 1.4841556549072266e-05}}}, {"type": "software", "software-type": "software", "wikidataId": "Q1165204", "wikipediaExternalRef": 21855450, "lang": "en", "confidence": 0.7457, "software-name": {"rawForm": "MongoDB", "normalizedForm": "MongoDB", "wikidataId": "Q1165204", "wikipediaExternalRef": 21855450, "lang": "en", "confidence": 0.7457, "offsetStart": 146, "offsetEnd": 153}, "context": "Let us consider the following modification Q1 ML of query Q1, which assumes that the LINEITEM table resides as a sharded document collection in a MongoDB cluster and the selection on it is expressed by means of the findSharded() JavaScript method, while ORDERS is still a LeanXcale table, the partitions of which are stored in the KV storage layer.", "mentionContextAttributes": {"used": {"value": true, "score": 0.7317375540733337}, "created": {"value": false, "score": 2.562999725341797e-06}, "shared": {"value": false, "score": 7.748603820800781e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9999129176139832}, "shared": {"value": false, "score": 9.065866470336914e-05}}}, {"type": "software", "software-type": "software", "wikidataId": "Q29120", "wikipediaExternalRef": 5919308, "lang": "en", "confidence": 0.9056, "software-name": {"rawForm": "Hadoop", "normalizedForm": "Hadoop", "wikidataId": "Q29120", "wikipediaExternalRef": 5919308, "lang": "en", "confidence": 0.9056, "offsetStart": 148, "offsetEnd": 154}, "context": "To better illustrate the flow, let us consider another modification Q1 HL of query Q1, which assumes that the LINEITEM table is stored as file in a Hadoop cluster.", "mentionContextAttributes": {"used": {"value": false, "score": 0.07103186845779419}, "created": {"value": false, "score": 1.150369644165039e-05}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9755048155784607}, "created": {"value": false, "score": 0.10342800617218018}, "shared": {"value": false, "score": 0.010259866714477539}}}, {"type": "software", "software-type": "software", "wikidataId": "Q460584", "wikipediaExternalRef": 3254510, "lang": "en", "confidence": 0.2001, "software-name": {"rawForm": "Scala", "normalizedForm": "Scala", "wikidataId": "Q460584", "wikipediaExternalRef": 3254510, "lang": "en", "confidence": 0.2001, "offsetStart": 152, "offsetEnd": 157}, "context": "Fig. 12. Execution times (in seconds) of Q4 queries joining the result of Q3 queries (1TB LeanXcale table joining 600GB MongoDB collection) with an MFR/Scala/Spark subquery against 240GB HDFS file.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999205470085144}, "created": {"value": false, "score": 4.0471553802490234e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999205470085144}, "created": {"value": true, "score": 0.9993940591812134}, "shared": {"value": false, "score": 1.4841556549072266e-05}}}, {"type": "software", "software-type": "implicit", "software-name": {"rawForm": "scripting", "normalizedForm": "scripting", "offsetStart": 152, "offsetEnd": 161}, "context": "The distributed wrapper for MongoDB comprises a number of instances of a Java class that implements the DataLake API, each of which embeds a JavaScript scripting engine that uses MongoDB's JavaScript client library. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.05950498580932617}, "created": {"value": false, "score": 0.0017822980880737305}, "shared": {"value": false, "score": 4.655122756958008e-05}}, "documentContextAttributes": {"used": {"value": false, "score": 0.05950498580932617}, "created": {"value": false, "score": 0.0017822980880737305}, "shared": {"value": false, "score": 4.655122756958008e-05}}}, {"type": "software", "software-type": "software", "wikidataId": "Q47607", "wikipediaExternalRef": 29004, "lang": "en", "confidence": 0.4606, "software-name": {"rawForm": "SQL", "normalizedForm": "SQL", "wikidataId": "Q47607", "wikipediaExternalRef": 29004, "lang": "en", "confidence": 0.4606, "offsetStart": 153, "offsetEnd": 156}, "context": "Teradata IntelliSphere [7] addresses the problem of accessing multiple data stores (called \"remote systems\") that may be heterogeneous, but must have an SQL-like interface.", "mentionContextAttributes": {"used": {"value": false, "score": 6.669759750366211e-05}, "created": {"value": false, "score": 6.717443466186523e-05}, "shared": {"value": false, "score": 4.172325134277344e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9934203028678894}, "shared": {"value": false, "score": 0.010259866714477539}}}, {"type": "software", "software-type": "software", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.3825, "software-name": {"rawForm": "Spark", "normalizedForm": "Spark", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.3825, "offsetStart": 153, "offsetEnd": 158}, "context": "As stated in Section 3, the major challenge of supporting Apache Spark as an underlying data management cluster is to enable parallel data movement from Spark workers to DataLake wrappers.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00023484230041503906}, "created": {"value": false, "score": 0.021330654621124268}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9997756481170654}, "shared": {"value": false, "score": 1.4841556549072266e-05}}}, {"type": "software", "software-type": "software", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.3825, "software-name": {"rawForm": "Spark", "normalizedForm": "Spark", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.3825, "offsetStart": 154, "offsetEnd": 159}, "context": "Thus, even a distributed query engine cannot exploit parallelism in retrieving a Spark RDD, since only one worker will collect the entire RDD through the Spark driver, which is the limitation we want to overcome in this paper as an extended version of [24].", "mentionContextAttributes": {"used": {"value": false, "score": 0.00014734268188476562}, "created": {"value": false, "score": 0.02785634994506836}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9997756481170654}, "shared": {"value": false, "score": 1.4841556549072266e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SparkAgent", "normalizedForm": "SparkAgent", "offsetStart": 155, "offsetEnd": 165}, "context": "For Spark result sets, this overhead is a bit higher, because of the additional serialization/deserialization that takes place between Spark executors and SparkAgent instances.", "mentionContextAttributes": {"used": {"value": false, "score": 0.034141480922698975}, "created": {"value": false, "score": 2.0802021026611328e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.4153452515602112}, "created": {"value": false, "score": 0.00011998414993286133}, "shared": {"value": false, "score": 1.9669532775878906e-06}}}, {"type": "software", "software-type": "software", "wikidataId": "Q1165204", "wikipediaExternalRef": 21855450, "lang": "en", "confidence": 0.7457, "software-name": {"rawForm": "MongoDB", "normalizedForm": "MongoDB", "wikidataId": "Q1165204", "wikipediaExternalRef": 21855450, "lang": "en", "confidence": 0.7457, "offsetStart": 157, "offsetEnd": 164}, "context": "To access a MongoDB cluster, Presto uses a connector that allows the parallel retrieval of sharded collections, which is typically configured with a list of MongoDB servers.", "mentionContextAttributes": {"used": {"value": false, "score": 0.004172682762145996}, "created": {"value": false, "score": 6.335973739624023e-05}, "shared": {"value": false, "score": 1.0132789611816406e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9999129176139832}, "shared": {"value": false, "score": 9.065866470336914e-05}}}, {"type": "software", "software-type": "software", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.3825, "software-name": {"rawForm": "Spark", "normalizedForm": "Spark", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.3825, "offsetStart": 158, "offsetEnd": 163}, "context": "Fig. 12. Execution times (in seconds) of Q4 queries joining the result of Q3 queries (1TB LeanXcale table joining 600GB MongoDB collection) with an MFR/Scala/Spark subquery against 240GB HDFS file.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999205470085144}, "created": {"value": false, "score": 4.0471553802490234e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9997756481170654}, "shared": {"value": false, "score": 1.4841556549072266e-05}}}, {"type": "software", "software-type": "software", "wikidataId": "Q1165204", "wikipediaExternalRef": 21855450, "lang": "en", "confidence": 0.7457, "software-name": {"rawForm": "MongoDB", "normalizedForm": "MongoDB", "wikidataId": "Q1165204", "wikipediaExternalRef": 21855450, "lang": "en", "confidence": 0.7457, "offsetStart": 158, "offsetEnd": 165}, "context": "The concept of parallel querying against a MongoDB cluster is built on the assumption that each DQE worker can access directly a MongoDB shard, bypassing the MongoDB router in order to sustain parallelism.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00023818016052246094}, "created": {"value": false, "score": 0.0005997419357299805}, "shared": {"value": false, "score": 4.172325134277344e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9999129176139832}, "shared": {"value": false, "score": 9.065866470336914e-05}}}, {"type": "software", "software-type": "software", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.3825, "software-name": {"rawForm": "Spark", "normalizedForm": "Spark", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.3825, "offsetStart": 159, "offsetEnd": 164}, "context": "In our work, we focused on parallel joins across a partitioned relational table, the result of a parallel JavaScript subquery to Mon-goDB, and the result of a Spark/Scala script against an HDFS file.", "mentionContextAttributes": {"used": {"value": false, "score": 0.3267185688018799}, "created": {"value": true, "score": 0.9993940591812134}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9997756481170654}, "shared": {"value": false, "score": 1.4841556549072266e-05}}}, {"type": "software", "software-type": "software", "wikidataId": "Q1165204", "wikipediaExternalRef": 21855450, "lang": "en", "confidence": 0.7457, "software-name": {"rawForm": "MongoDB", "normalizedForm": "MongoDB", "wikidataId": "Q1165204", "wikipediaExternalRef": 21855450, "lang": "en", "confidence": 0.7457, "offsetStart": 160, "offsetEnd": 167}, "context": "Thus, a composition of findSharded and map/flatMap (such as in the BookOrders example above) makes a user script expressive enough, so as to request a specific MongoDB dataset, retrieve the result set in parallel, and transform it in order to fit the named table signature and further be consumed by relational operators at the DQE level.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0015254616737365723}, "created": {"value": false, "score": 2.2590160369873047e-05}, "shared": {"value": false, "score": 1.0132789611816406e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9999129176139832}, "shared": {"value": false, "score": 9.065866470336914e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "DataLake API", "normalizedForm": "DataLake API", "offsetStart": 160, "offsetEnd": 172}, "context": "In the subsequent subsections, we give details on how the process of parallel retrieval from Mon-goDB and HDFS datasets is mapped to the methods of the generic DataLake API.", "mentionContextAttributes": {"used": {"value": false, "score": 0.011699080467224121}, "created": {"value": false, "score": 0.00882875919342041}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.0319443941116333}, "created": {"value": false, "score": 0.00882875919342041}, "shared": {"value": false, "score": 1.5914440155029297e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "code", "normalizedForm": "code", "offsetStart": 161, "offsetEnd": 165}, "context": "To achieve this, the query engine creates a session at the Spark driver, then translates the MFR subquery to code (in Scala or Python for Spark), delegates this code to Spark for execution, and collects the intermediate data through the same Spark driver session.", "mentionContextAttributes": {"used": {"value": false, "score": 0.20863837003707886}, "created": {"value": false, "score": 9.888410568237305e-05}, "shared": {"value": false, "score": 5.364418029785156e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.919108510017395}, "created": {"value": true, "score": 0.9997756481170654}, "shared": {"value": false, "score": 2.562999725341797e-06}}}, {"type": "software", "software-type": "software", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.3825, "software-name": {"rawForm": "Spark", "normalizedForm": "Spark", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.3825, "offsetStart": 161, "offsetEnd": 166}, "context": "Workflow managers dispatch the execution of a query/workflow plan to underlying data processing platforms, hence can access MongoDB through the platforms, e.g., Spark using the Spark MongoDB connector.", "mentionContextAttributes": {"used": {"value": false, "score": 0.005359172821044922}, "created": {"value": false, "score": 2.9027462005615234e-05}, "shared": {"value": false, "score": 3.635883331298828e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9997756481170654}, "shared": {"value": false, "score": 1.4841556549072266e-05}}}, {"type": "software", "software-type": "implicit", "wikidataId": "Q187432", "wikipediaExternalRef": 21490336, "lang": "en", "confidence": 0.5074, "software-name": {"rawForm": "scripts", "normalizedForm": "scripts", "wikidataId": "Q187432", "wikipediaExternalRef": 21490336, "lang": "en", "confidence": 0.5074, "offsetStart": 161, "offsetEnd": 168}, "context": "In this paper, we address these points by: (i) using the polyglot approach of the CloudMdsQL query language that allows native queries to be expressed as inline scripts and combined with SQL statements for ad-hoc integration and (ii) incorporating the approach within the LeanXcale distributed query engine, thus allowing for native scripts to be processed in parallel at data store shards. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0006181597709655762}, "created": {"value": false, "score": 0.4770117402076721}, "shared": {"value": false, "score": 2.3245811462402344e-06}}, "documentContextAttributes": {"used": {"value": false, "score": 0.0027613043785095215}, "created": {"value": true, "score": 0.9998281002044678}, "shared": {"value": false, "score": 2.3245811462402344e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LeanXcale", "normalizedForm": "LeanXcale", "offsetStart": 161, "offsetEnd": 170}, "context": "By interfacing wrappers through the DataLake API, the DQE has the possibility to retrieve in parallel disjoint subsets of the result set, much like it does with LeanXcale tables.", "mentionContextAttributes": {"used": {"value": false, "score": 0.009502410888671875}, "created": {"value": false, "score": 6.717443466186523e-05}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999398589134216}, "created": {"value": true, "score": 0.9999358057975769}, "shared": {"value": false, "score": 8.52346420288086e-06}}}, {"type": "software", "software-type": "software", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.7879, "software-name": {"rawForm": "Apache Spark", "normalizedForm": "Apache Spark", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.7879, "offsetStart": 161, "offsetEnd": 173}, "context": "We also show that the same methods abstract well enough even the more sophisticated parallel data push model, necessary to support the parallel integration with Apache Spark, as introduced in Section 3.", "mentionContextAttributes": {"used": {"value": false, "score": 0.006913185119628906}, "created": {"value": true, "score": 0.7794421911239624}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.01917022466659546}, "created": {"value": true, "score": 0.7794421911239624}, "shared": {"value": false, "score": 4.470348358154297e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LeanXcale", "normalizedForm": "LeanXcale", "offsetStart": 162, "offsetEnd": 171}, "context": "Query Q2 M evaluates just the parallel execution of the BookOrders script in MongoDB, while Q2 ML involves a join between MongoDB and the CUSTOMER table from the LeanXcale data store: Fig. 9 shows the performance measurements of Q2 queries that stress on the evaluation of the parallel processing of highly expressive JavaScript queries, with and without join with a LeanXcale table.", "mentionContextAttributes": {"used": {"value": true, "score": 0.7139508724212646}, "created": {"value": false, "score": 3.159046173095703e-06}, "shared": {"value": false, "score": 1.0132789611816406e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999398589134216}, "created": {"value": true, "score": 0.9999358057975769}, "shared": {"value": false, "score": 8.52346420288086e-06}}}, {"type": "software", "software-type": "software", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.3825, "software-name": {"rawForm": "Spark", "normalizedForm": "Spark", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.3825, "offsetStart": 163, "offsetEnd": 168}, "context": "Since this necessitates that Spark workers find and connect to DataLake wrapper instances, it results in a different, more complex architecture of the distributed Spark wrapper.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0006530880928039551}, "created": {"value": false, "score": 6.145238876342773e-05}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9997756481170654}, "shared": {"value": false, "score": 1.4841556549072266e-05}}}, {"type": "software", "software-type": "software", "wikidataId": "Q29120", "wikipediaExternalRef": 5919308, "lang": "en", "confidence": 0.9056, "software-name": {"rawForm": "Hadoop", "normalizedForm": "Hadoop", "wikidataId": "Q29120", "wikipediaExternalRef": 5919308, "lang": "en", "confidence": 0.9056, "offsetStart": 163, "offsetEnd": 169}, "context": "Fig. 6 gives a high-level illustration of the processing of the query Q1 SL , assuming a simple MFR subquery that reads the LINEITEM table as a text file from the Hadoop cluster, but this time through Spark.", "mentionContextAttributes": {"used": {"value": false, "score": 0.3648099899291992}, "created": {"value": false, "score": 1.996755599975586e-05}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9755048155784607}, "created": {"value": false, "score": 0.10342800617218018}, "shared": {"value": false, "score": 0.010259866714477539}}}, {"type": "software", "software-type": "software", "wikidataId": "Q1165204", "wikipediaExternalRef": 21855450, "lang": "en", "confidence": 0.7457, "software-name": {"rawForm": "MongoDB", "normalizedForm": "MongoDB", "wikidataId": "Q1165204", "wikipediaExternalRef": 21855450, "lang": "en", "confidence": 0.7457, "offsetStart": 163, "offsetEnd": 170}, "context": "The SQL table expression T1 is defined by an SQL subquery, while T2 is a native expression (identified by the special bracket symbols {* *}) expressed as a native MongoDB API call or JavaScript code. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.05572474002838135}, "created": {"value": false, "score": 4.178285598754883e-05}, "shared": {"value": false, "score": 1.1324882507324219e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9999129176139832}, "shared": {"value": false, "score": 9.065866470336914e-05}}}, {"type": "software", "software-type": "software", "wikidataId": "Q1165204", "wikipediaExternalRef": 21855450, "lang": "en", "confidence": 0.7457, "software-name": {"rawForm": "MongoDB", "normalizedForm": "MongoDB", "wikidataId": "Q1165204", "wikipediaExternalRef": 21855450, "lang": "en", "confidence": 0.7457, "offsetStart": 163, "offsetEnd": 170}, "context": "To support parallel data retrieval, we further enhance the client library with JavaScript primitives that wrap standard MongoCursor objects (usually returned by a MongoDB JavaScript query) in Shard-edCursor objects, which are aware of the sharding of the underlying dataset. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0002295970916748047}, "created": {"value": false, "score": 0.0748090147972107}, "shared": {"value": false, "score": 2.682209014892578e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9999129176139832}, "shared": {"value": false, "score": 9.065866470336914e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SparkAgent", "normalizedForm": "SparkAgent", "offsetStart": 163, "offsetEnd": 173}, "context": "serialize is another function that serializes each entry of the RDD partition to a byte array in a format that SparkAgent can interpret, which is then sent to the SparkAgent through the socket.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0029844045639038086}, "created": {"value": false, "score": 3.272294998168945e-05}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.4153452515602112}, "created": {"value": false, "score": 0.00011998414993286133}, "shared": {"value": false, "score": 1.9669532775878906e-06}}}, {"type": "software", "software-type": "software", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.7879, "software-name": {"rawForm": "Apache Spark", "normalizedForm": "Apache Spark", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.7879, "offsetStart": 164, "offsetEnd": 176}, "context": "Here, we specifically focus on parallel joins across a relational table, the result of a JavaScript subquery to MongoDB, and the result of an MFR/Scala subquery to Apache Spark, but the concept relies on an API that allows its generalization to other script engines and data stores as well. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0018170475959777832}, "created": {"value": false, "score": 0.05537760257720947}, "shared": {"value": false, "score": 1.1324882507324219e-06}}, "documentContextAttributes": {"used": {"value": false, "score": 0.01917022466659546}, "created": {"value": true, "score": 0.7794421911239624}, "shared": {"value": false, "score": 4.470348358154297e-06}}}, {"type": "software", "software-type": "software", "wikidataId": "Q47607", "wikipediaExternalRef": 29004, "lang": "en", "confidence": 0.4606, "software-name": {"rawForm": "SQL", "normalizedForm": "SQL", "wikidataId": "Q47607", "wikipediaExternalRef": 29004, "lang": "en", "confidence": 0.4606, "offsetStart": 165, "offsetEnd": 168}, "context": "CloudMdsQL [23,26] with its MFR (map/filter/reduce) extensions [9] even allows data store native queries to be expressed as inline scripts and combined with regular SQL statements in ad-hoc integration queries.", "mentionContextAttributes": {"used": {"value": false, "score": 6.93202018737793e-05}, "created": {"value": false, "score": 1.5437602996826172e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9934203028678894}, "shared": {"value": false, "score": 0.010259866714477539}}}, {"type": "software", "software-type": "software", "wikidataId": "Q460584", "wikipediaExternalRef": 3254510, "lang": "en", "confidence": 0.2001, "software-name": {"rawForm": "Scala", "normalizedForm": "Scala", "wikidataId": "Q460584", "wikipediaExternalRef": 3254510, "lang": "en", "confidence": 0.2001, "offsetStart": 165, "offsetEnd": 170}, "context": "In our work, we focused on parallel joins across a partitioned relational table, the result of a parallel JavaScript subquery to Mon-goDB, and the result of a Spark/Scala script against an HDFS file.", "mentionContextAttributes": {"used": {"value": false, "score": 0.3267185688018799}, "created": {"value": true, "score": 0.9993940591812134}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999205470085144}, "created": {"value": true, "score": 0.9993940591812134}, "shared": {"value": false, "score": 1.4841556549072266e-05}}}, {"type": "software", "software-type": "implicit", "software-name": {"rawForm": "script", "normalizedForm": "script", "offsetStart": 167, "offsetEnd": 173}, "language": {"rawForm": "Scala", "normalizedForm": "Scala"}, "context": "In order to make the wrapper instances collect in parallel partitions of the resulting RDD, the master wrapper ships an additional code together with the user defined script, that makes each RDD partition push its data directly to the assigned by the registry wrapper instance. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.10720396041870117}, "created": {"value": false, "score": 3.1888484954833984e-05}, "shared": {"value": false, "score": 6.556510925292969e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.919108510017395}, "created": {"value": true, "score": 0.9993940591812134}, "shared": {"value": false, "score": 1.4841556549072266e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CloudMdsQL", "normalizedForm": "CloudMdsQL", "offsetStart": 168, "offsetEnd": 178}, "context": "To enable ad-hoc querying of an arbitrary data set, using its scripting mechanism, and then joining the retrieved result set at DQE level, DQE processes queries in the CloudMdsQL query language, where scripts are wrapped as native subqueries.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0027613043785095215}, "created": {"value": false, "score": 8.660554885864258e-05}, "shared": {"value": false, "score": 4.172325134277344e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.10021162033081055}, "created": {"value": true, "score": 0.9999358057975769}, "shared": {"value": false, "score": 2.3245811462402344e-06}}, "references": [{"label": "[26]", "normalizedForm": "[26]", "refKey": 26}, {"label": "[26]", "normalizedForm": "[26]", "refKey": 26}]}, {"type": "software", "software-type": "software", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.3825, "software-name": {"rawForm": "Spark", "normalizedForm": "Spark", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.3825, "offsetStart": 169, "offsetEnd": 174}, "context": "To achieve this, the query engine creates a session at the Spark driver, then translates the MFR subquery to code (in Scala or Python for Spark), delegates this code to Spark for execution, and collects the intermediate data through the same Spark driver session.", "mentionContextAttributes": {"used": {"value": false, "score": 0.20863837003707886}, "created": {"value": false, "score": 9.888410568237305e-05}, "shared": {"value": false, "score": 5.364418029785156e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9997756481170654}, "shared": {"value": false, "score": 1.4841556549072266e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "code", "normalizedForm": "code", "offsetStart": 170, "offsetEnd": 174}, "context": "SQL-like query or vertex-centric graphic abstraction; then, the specification is transformed into an internal representation in the form of a data-flow DAG; and finally, code is generated to execute the workflow against the target platform.", "mentionContextAttributes": {"used": {"value": false, "score": 0.03070169687271118}, "created": {"value": false, "score": 0.00016021728515625}, "shared": {"value": false, "score": 1.4901161193847656e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.919108510017395}, "created": {"value": true, "score": 0.9997756481170654}, "shared": {"value": false, "score": 2.562999725341797e-06}}}, {"type": "software", "software-type": "software", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.3825, "software-name": {"rawForm": "Spark", "normalizedForm": "Spark", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.3825, "offsetStart": 170, "offsetEnd": 175}, "context": "Second, in order to do this, the query engine must be able to retrieve in parallel the partitions from the underlying data stores and data processing frameworks (such as Spark). ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0017824172973632812}, "created": {"value": false, "score": 0.00012803077697753906}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9997756481170654}, "shared": {"value": false, "score": 1.4841556549072266e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "API", "normalizedForm": "API", "offsetStart": 171, "offsetEnd": 174}, "context": "The SQL table expression T1 is defined by an SQL subquery, while T2 is a native expression (identified by the special bracket symbols {* *}) expressed as a native MongoDB API call or JavaScript code.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0557246208190918}, "created": {"value": false, "score": 4.178285598754883e-05}, "shared": {"value": false, "score": 1.1324882507324219e-06}}, "documentContextAttributes": {"used": {"value": false, "score": 0.05950498580932617}, "created": {"value": false, "score": 0.05537760257720947}, "shared": {"value": false, "score": 4.655122756958008e-05}}}, {"type": "software", "software-type": "implicit", "software-name": {"rawForm": "script", "normalizedForm": "script", "offsetStart": 171, "offsetEnd": 177}, "language": {"rawForm": "Scala", "normalizedForm": "Scala"}, "context": "In our work, we focused on parallel joins across a partitioned relational table, the result of a parallel JavaScript subquery to Mon-goDB, and the result of a Spark/Scala script against an HDFS file.", "mentionContextAttributes": {"used": {"value": false, "score": 0.3267185688018799}, "created": {"value": true, "score": 0.9993940591812134}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.919108510017395}, "created": {"value": true, "score": 0.9993940591812134}, "shared": {"value": false, "score": 1.4841556549072266e-05}}}, {"type": "software", "software-type": "software", "wikidataId": "Q1165204", "wikipediaExternalRef": 21855450, "lang": "en", "confidence": 0.7457, "software-name": {"rawForm": "MongoDB", "normalizedForm": "MongoDB", "wikidataId": "Q1165204", "wikipediaExternalRef": 21855450, "lang": "en", "confidence": 0.7457, "offsetStart": 172, "offsetEnd": 179}, "context": "For comparison with the state of the art, the large-scale test case queries were also performed on a Spark SQL cluster, where we used the MongoDB Spark connector to access MongoDB shards in parallel.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": false, "score": 1.5795230865478516e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9999129176139832}, "shared": {"value": false, "score": 9.065866470336914e-05}}}, {"type": "software", "software-type": "software", "wikidataId": "Q1165204", "wikipediaExternalRef": 21855450, "lang": "en", "confidence": 0.7457, "software-name": {"rawForm": "MongoDB", "normalizedForm": "MongoDB", "wikidataId": "Q1165204", "wikipediaExternalRef": 21855450, "lang": "en", "confidence": 0.7457, "offsetStart": 174, "offsetEnd": 181}, "context": "The definition of the named table is hence slightly modified, to allow for the bind join to apply early filtering to reduce significantly the amount of data processed by the MongoDB JavaScript subquery: The query executes by first applying the filter and retrieving intermediate data from the CLICKS table, where a full scan takes place. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.07281148433685303}, "created": {"value": false, "score": 2.0682811737060547e-05}, "shared": {"value": false, "score": 4.172325134277344e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9999129176139832}, "shared": {"value": false, "score": 9.065866470336914e-05}}}, {"type": "software", "software-type": "software", "wikidataId": "Q1165204", "wikipediaExternalRef": 21855450, "lang": "en", "confidence": 0.7457, "software-name": {"rawForm": "MongoDB", "normalizedForm": "MongoDB", "wikidataId": "Q1165204", "wikipediaExternalRef": 21855450, "lang": "en", "confidence": 0.7457, "offsetStart": 176, "offsetEnd": 183}, "context": "The way to do the bind join counterpart for native queries is through the use of a JOINED ON clause in the named table signature, like in the named table A below, defined as a MongoDB script.", "mentionContextAttributes": {"used": {"value": false, "score": 0.055190205574035645}, "created": {"value": false, "score": 3.141164779663086e-05}, "shared": {"value": false, "score": 4.172325134277344e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9999129176139832}, "shared": {"value": false, "score": 9.065866470336914e-05}}}, {"type": "software", "software-type": "software", "wikidataId": "Q187432", "wikipediaExternalRef": 21490336, "lang": "en", "confidence": 0.5074, "software-name": {"rawForm": "scripts", "normalizedForm": "scripts", "wikidataId": "Q187432", "wikipediaExternalRef": 21490336, "lang": "en", "confidence": 0.5074, "offsetStart": 176, "offsetEnd": 183}, "context": "LeanXcale DQE is designed to integrate with arbitrary data management clusters, where data resides in its natural format and can be retrieved (in parallel) by running specific scripts or declarative queries.", "mentionContextAttributes": {"used": {"value": false, "score": 5.227327346801758e-05}, "created": {"value": false, "score": 0.26259398460388184}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.0027613043785095215}, "created": {"value": true, "score": 0.9998281002044678}, "shared": {"value": false, "score": 2.3245811462402344e-06}}}, {"type": "software", "software-type": "software", "wikidataId": "Q1165204", "wikipediaExternalRef": 21855450, "lang": "en", "confidence": 0.7457, "software-name": {"rawForm": "MongoDB", "normalizedForm": "MongoDB", "wikidataId": "Q1165204", "wikipediaExternalRef": 21855450, "lang": "en", "confidence": 0.7457, "offsetStart": 176, "offsetEnd": 183}, "context": "To run an analogue of the BookOrders subquery through the MongoDB connector for Spark SQL, we used the MongoDB aggregation framework against the same sharded collection in our MongoDB cluster as follows:", "mentionContextAttributes": {"used": {"value": true, "score": 0.9997720718383789}, "created": {"value": false, "score": 9.375810623168945e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9999129176139832}, "shared": {"value": false, "score": 9.065866470336914e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LeanXcale", "normalizedForm": "LeanXcale", "offsetStart": 176, "offsetEnd": 185}, "context": "JEN and LeanXcale are applying semi-joins as an optimization technique -JEN with its efficient zigzag join that exchanges bloom filters between the HDFS and RDBMS datasets and LeanXcale through bind joins.", "mentionContextAttributes": {"used": {"value": false, "score": 0.008451342582702637}, "created": {"value": false, "score": 4.827976226806641e-06}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999398589134216}, "created": {"value": true, "score": 0.9999358057975769}, "shared": {"value": false, "score": 8.52346420288086e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "API", "normalizedForm": "API", "offsetStart": 177, "offsetEnd": 180}, "context": "Spark SQL [6] is a parallel SQL engine built on top of Apache Spark and designed to provide tight integration between relational and procedural processing through a declarative API that integrates relational operators with procedural Spark code, taking advantage of massive parallelism.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00022149085998535156}, "created": {"value": false, "score": 0.013364613056182861}, "shared": {"value": false, "score": 2.562999725341797e-06}}, "documentContextAttributes": {"used": {"value": false, "score": 0.05950498580932617}, "created": {"value": false, "score": 0.05537760257720947}, "shared": {"value": false, "score": 4.655122756958008e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "code", "normalizedForm": "code", "offsetStart": 177, "offsetEnd": 181}, "context": "We address this problem by introducing an architecture, where each RDD partition (more precisely, the Spark worker that processes the partition) is instructed through generated code to find and connect to a query engine worker and to push the partition data.", "mentionContextAttributes": {"used": {"value": false, "score": 8.434057235717773e-05}, "created": {"value": true, "score": 0.9997756481170654}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.919108510017395}, "created": {"value": true, "score": 0.9997756481170654}, "shared": {"value": false, "score": 2.562999725341797e-06}}}, {"type": "software", "software-type": "software", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.3825, "software-name": {"rawForm": "Spark", "normalizedForm": "Spark", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.3825, "offsetStart": 177, "offsetEnd": 182}, "context": "Workflow managers dispatch the execution of a query/workflow plan to underlying data processing platforms, hence can access MongoDB through the platforms, e.g., Spark using the Spark MongoDB connector.", "mentionContextAttributes": {"used": {"value": false, "score": 0.005359172821044922}, "created": {"value": false, "score": 2.9027462005615234e-05}, "shared": {"value": false, "score": 3.635883331298828e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9997756481170654}, "shared": {"value": false, "score": 1.4841556549072266e-05}}}, {"type": "software", "software-type": "software", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.3825, "software-name": {"rawForm": "Spark", "normalizedForm": "Spark", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.3825, "offsetStart": 179, "offsetEnd": 184}, "context": "To enable remote submission of the generated Scala script for Spark by the master wrapper, our setup relies on Apache Livy2 , which provides a REST service for easy submission of Spark jobs and Spark context management.", "mentionContextAttributes": {"used": {"value": false, "score": 0.13044798374176025}, "created": {"value": false, "score": 0.08340615034103394}, "shared": {"value": false, "score": 1.4841556549072266e-05}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9997756481170654}, "shared": {"value": false, "score": 1.4841556549072266e-05}}}, {"type": "software", "software-type": "software", "wikidataId": "Q1165204", "wikipediaExternalRef": 21855450, "lang": "en", "confidence": 0.7457, "software-name": {"rawForm": "MongoDB", "normalizedForm": "MongoDB", "wikidataId": "Q1165204", "wikipediaExternalRef": 21855450, "lang": "en", "confidence": 0.7457, "offsetStart": 179, "offsetEnd": 186}, "context": "The distributed wrapper for MongoDB comprises a number of instances of a Java class that implements the DataLake API, each of which embeds a JavaScript scripting engine that uses MongoDB's JavaScript client library. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.05950498580932617}, "created": {"value": false, "score": 0.0017822980880737305}, "shared": {"value": false, "score": 4.655122756958008e-05}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9999129176139832}, "shared": {"value": false, "score": 9.065866470336914e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Hive", "normalizedForm": "Hive", "offsetStart": 180, "offsetEnd": 184}, "context": "To schedule parallel retrieval of the LINEITEM table, the DQE redirects the subquery to the HDFS wrapper, preliminarily configured to associate the @hdfs alias with the URI of the Hive metastore, which specifies how the file is parsed and split.", "mentionContextAttributes": {"used": {"value": false, "score": 0.162664532661438}, "created": {"value": false, "score": 1.8477439880371094e-06}, "shared": {"value": false, "score": 4.172325134277344e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999398589134216}, "created": {"value": false, "score": 0.0001316070556640625}, "shared": {"value": false, "score": 5.662441253662109e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "REDUCE", "normalizedForm": "REDUCE", "offsetStart": 183, "offsetEnd": 189}, "context": "As per the MFR rewrite rules, this would take place immediately after the FLAT_MAP operator, significantly reducing at early stage the amount of data to be processed by the expensive REDUCE operators that follow. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9158028960227966}, "created": {"value": false, "score": 4.035234451293945e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9995518326759338}, "created": {"value": false, "score": 0.00020503997802734375}, "shared": {"value": false, "score": 2.4437904357910156e-06}}}, {"type": "software", "software-type": "software", "wikidataId": "Q187432", "wikipediaExternalRef": 21490336, "lang": "en", "confidence": 0.5074, "software-name": {"rawForm": "scripts", "normalizedForm": "scripts", "wikidataId": "Q187432", "wikipediaExternalRef": 21490336, "lang": "en", "confidence": 0.5074, "offsetStart": 183, "offsetEnd": 190}, "context": "The client library is therefore extended with the following document collection methods that return ShardedCursor and provide the targeted operators (find, map, and flat map) in user scripts.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0025480985641479492}, "created": {"value": false, "score": 0.00027632713317871094}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.0027613043785095215}, "created": {"value": true, "score": 0.9998281002044678}, "shared": {"value": false, "score": 2.3245811462402344e-06}}}, {"type": "software", "software-type": "software", "wikidataId": "Q1165204", "wikipediaExternalRef": 21855450, "lang": "en", "confidence": 0.7457, "software-name": {"rawForm": "MongoDB", "normalizedForm": "MongoDB", "wikidataId": "Q1165204", "wikipediaExternalRef": 21855450, "lang": "en", "confidence": 0.7457, "offsetStart": 183, "offsetEnd": 190}, "context": "Workflow managers dispatch the execution of a query/workflow plan to underlying data processing platforms, hence can access MongoDB through the platforms, e.g., Spark using the Spark MongoDB connector.", "mentionContextAttributes": {"used": {"value": false, "score": 0.005359172821044922}, "created": {"value": false, "score": 2.9027462005615234e-05}, "shared": {"value": false, "score": 3.635883331298828e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9999129176139832}, "shared": {"value": false, "score": 9.065866470336914e-05}}}, {"type": "software", "software-type": "software", "wikidataId": "Q1165204", "wikipediaExternalRef": 21855450, "lang": "en", "confidence": 0.7457, "software-name": {"rawForm": "MongoDB", "normalizedForm": "MongoDB", "wikidataId": "Q1165204", "wikipediaExternalRef": 21855450, "lang": "en", "confidence": 0.7457, "offsetStart": 183, "offsetEnd": 190}, "context": "To better illustrate the necessity of enabling user-defined scripts to MongoDB as subqueries, rather than defining SQL mappings to document collections, let us consider the following MongoDB collection orders that has a highly non-relational structure:", "mentionContextAttributes": {"used": {"value": false, "score": 0.00022840499877929688}, "created": {"value": false, "score": 0.0009966492652893066}, "shared": {"value": false, "score": 5.364418029785156e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9999129176139832}, "shared": {"value": false, "score": 9.065866470336914e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "script", "normalizedForm": "script", "offsetStart": 184, "offsetEnd": 190}, "language": {"rawForm": "Scala", "normalizedForm": "Scala"}, "context": "The way to do the bind join counterpart for native queries is through the use of a JOINED ON clause in the named table signature, like in the named table A below, defined as a MongoDB script.", "mentionContextAttributes": {"used": {"value": false, "score": 0.055190205574035645}, "created": {"value": false, "score": 3.141164779663086e-05}, "shared": {"value": false, "score": 4.172325134277344e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.919108510017395}, "created": {"value": true, "score": 0.9993940591812134}, "shared": {"value": false, "score": 1.4841556549072266e-05}}}, {"type": "software", "software-type": "software", "wikidataId": "Q47607", "wikipediaExternalRef": 29004, "lang": "en", "confidence": 0.4606, "software-name": {"rawForm": "SQL", "normalizedForm": "SQL", "wikidataId": "Q47607", "wikipediaExternalRef": 29004, "lang": "en", "confidence": 0.4606, "offsetStart": 185, "offsetEnd": 188}, "context": "For example, the following simple CloudMdsQL query contains two subqueries, defined by the named table expressions T1 and T2, and addressed respectively against the data stores rdb (an SQL database) and mongo (a MongoDB database):", "mentionContextAttributes": {"used": {"value": false, "score": 0.0022200942039489746}, "created": {"value": false, "score": 3.7610530853271484e-05}, "shared": {"value": false, "score": 4.172325134277344e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9934203028678894}, "shared": {"value": false, "score": 0.010259866714477539}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Hive", "normalizedForm": "Hive", "offsetStart": 186, "offsetEnd": 190}, "context": "All the generated datasets were: loaded in LeanXcale as relational tables; loaded in MongoDB as document collections; copied to the HDFS cluster as raw CSV files, to be accessed through Hive as tables and through Spark by means of scans expressed as simple MFR/Scala statements.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9994305372238159}, "created": {"value": false, "score": 2.9206275939941406e-06}, "shared": {"value": false, "score": 5.364418029785156e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999398589134216}, "created": {"value": false, "score": 0.0001316070556640625}, "shared": {"value": false, "score": 5.662441253662109e-06}}}, {"type": "software", "software-type": "software", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.3825, "software-name": {"rawForm": "Spark", "normalizedForm": "Spark", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.3825, "offsetStart": 186, "offsetEnd": 191}, "context": "A discovery service is introduced through the special component Spark Agent Registry that keeps information about available Spark wrapper instances and dispatches them to the requesting Spark workers so that parallelism is fully exploited in moving data from a Spark RDD to the DQE.", "mentionContextAttributes": {"used": {"value": false, "score": 0.005214571952819824}, "created": {"value": false, "score": 0.003361940383911133}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9997756481170654}, "shared": {"value": false, "score": 1.4841556549072266e-05}}}, {"type": "software", "software-type": "software", "wikidataId": "Q1165204", "wikipediaExternalRef": 21855450, "lang": "en", "confidence": 0.7457, "software-name": {"rawForm": "MongoDB", "normalizedForm": "MongoDB", "wikidataId": "Q1165204", "wikipediaExternalRef": 21855450, "lang": "en", "confidence": 0.7457, "offsetStart": 186, "offsetEnd": 193}, "context": "This delayed iteration approach allows the DQE to internally manipulate the cursor object before the actual iteration takes place, e.g., to redirect the subquery execution to a specific MongoDB shard.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0012316703796386719}, "created": {"value": false, "score": 0.0003085136413574219}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9999129176139832}, "shared": {"value": false, "score": 9.065866470336914e-05}}}, {"type": "software", "software-type": "software", "wikidataId": "Q1165204", "wikipediaExternalRef": 21855450, "lang": "en", "confidence": 0.7457, "software-name": {"rawForm": "MongoDB", "normalizedForm": "MongoDB", "wikidataId": "Q1165204", "wikipediaExternalRef": 21855450, "lang": "en", "confidence": 0.7457, "offsetStart": 186, "offsetEnd": 193}, "context": "Without bind join, Spark SQL shows a slight advantage compared to LeanXcale DQE, which is explainable by the overhead of the JavaScript interpreting that takes place at DQE wrappers for MongoDB.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00408935546875}, "created": {"value": false, "score": 6.735324859619141e-06}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9999129176139832}, "shared": {"value": false, "score": 9.065866470336914e-05}}}, {"type": "software", "software-type": "software", "wikidataId": "Q47607", "wikipediaExternalRef": 29004, "lang": "en", "confidence": 0.4606, "software-name": {"rawForm": "SQL", "normalizedForm": "SQL", "wikidataId": "Q47607", "wikipediaExternalRef": 29004, "lang": "en", "confidence": 0.4606, "offsetStart": 187, "offsetEnd": 190}, "context": "In this paper, we address these points by: (i) using the polyglot approach of the CloudMdsQL query language that allows native queries to be expressed as inline scripts and combined with SQL statements for ad-hoc integration and (ii) incorporating the approach within the LeanXcale distributed query engine, thus allowing for native scripts to be processed in parallel at data store shards.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0006181597709655762}, "created": {"value": false, "score": 0.4770117402076721}, "shared": {"value": false, "score": 2.3245811462402344e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9934203028678894}, "shared": {"value": false, "score": 0.010259866714477539}}}, {"type": "software", "software-type": "software", "wikidataId": "Q47607", "wikipediaExternalRef": 29004, "lang": "en", "confidence": 0.4606, "software-name": {"rawForm": "SQL", "normalizedForm": "SQL", "wikidataId": "Q47607", "wikipediaExternalRef": 29004, "lang": "en", "confidence": 0.4606, "offsetStart": 189, "offsetEnd": 192}, "context": "CloudMdsQL also provides a CREATE NAMED EXPRESSION command that allows an expression to be defined and stored in a global catalog in order to be referenced in several queries, similarly to SQL views and stored procedures/functions.", "mentionContextAttributes": {"used": {"value": false, "score": 4.6193599700927734e-05}, "created": {"value": false, "score": 0.00011748075485229492}, "shared": {"value": false, "score": 1.2516975402832031e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9934203028678894}, "shared": {"value": false, "score": 0.010259866714477539}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "API", "normalizedForm": "API", "offsetStart": 191, "offsetEnd": 194}, "context": "Its extended relational model and the imperative-declarative hybrid language MyriaL span well all the underlying data models, where rewrite rules apply to transform expressions into specific API calls, queries, etc. for each of the data stores.", "mentionContextAttributes": {"used": {"value": false, "score": 8.600950241088867e-05}, "created": {"value": false, "score": 0.002353072166442871}, "shared": {"value": false, "score": 5.364418029785156e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.05950498580932617}, "created": {"value": false, "score": 0.05537760257720947}, "shared": {"value": false, "score": 4.655122756958008e-05}}}, {"type": "software", "software-type": "software", "wikidataId": "Q1165204", "wikipediaExternalRef": 21855450, "lang": "en", "confidence": 0.7457, "software-name": {"rawForm": "MongoDB", "normalizedForm": "MongoDB", "wikidataId": "Q1165204", "wikipediaExternalRef": 21855450, "lang": "en", "confidence": 0.7457, "offsetStart": 192, "offsetEnd": 199}, "context": "As for workflow managers, although they can orchestrate efficiently relational operators across platforms, they do not provide query execution themselves; for example, a parallel join between MongoDB and Spark would be dispatched for execution at Spark by both Musketeer and RHEEM, so we would consider this comparison as equivalent to comparing with Spark.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0010941624641418457}, "created": {"value": false, "score": 2.7477741241455078e-05}, "shared": {"value": false, "score": 4.172325134277344e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9999129176139832}, "shared": {"value": false, "score": 9.065866470336914e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "DataLake API", "normalizedForm": "DataLake API", "offsetStart": 192, "offsetEnd": 204}, "context": "The distributed HDFS wrapper is designed to access in parallel tables stored as HDFS files, thus providing the typical functionality of a tightly-coupled polystore, but through the use of the DataLake API.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0012021064758300781}, "created": {"value": false, "score": 0.0014584660530090332}, "shared": {"value": false, "score": 1.0907649993896484e-05}}, "documentContextAttributes": {"used": {"value": false, "score": 0.0319443941116333}, "created": {"value": false, "score": 0.00882875919342041}, "shared": {"value": false, "score": 1.5914440155029297e-05}}}, {"type": "software", "software-type": "software", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.6951, "software-name": {"rawForm": "Spark SQL", "normalizedForm": "Spark SQL", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.6951, "offsetStart": 193, "offsetEnd": 202}, "context": "Among hybrid systems, although Presto and Drill support well parallel query processing across SQL and NoSQL stores, the only one that provides parallel support of distributed data platforms is Spark SQL, as it uses Spark natively. ", "mentionContextAttributes": {"used": {"value": false, "score": 7.051229476928711e-05}, "created": {"value": false, "score": 0.00028395652770996094}, "shared": {"value": false, "score": 3.2782554626464844e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997720718383789}, "created": {"value": true, "score": 0.5916945338249207}, "shared": {"value": false, "score": 3.2782554626464844e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "code", "normalizedForm": "code", "offsetStart": 194, "offsetEnd": 198}, "context": "The SQL table expression T1 is defined by an SQL subquery, while T2 is a native expression (identified by the special bracket symbols {* *}) expressed as a native MongoDB API call or JavaScript code.", "mentionContextAttributes": {"used": {"value": false, "score": 0.05572474002838135}, "created": {"value": false, "score": 4.178285598754883e-05}, "shared": {"value": false, "score": 1.1324882507324219e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.919108510017395}, "created": {"value": true, "score": 0.9997756481170654}, "shared": {"value": false, "score": 2.562999725341797e-06}}}, {"type": "software", "software-type": "software", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.3825, "software-name": {"rawForm": "Spark", "normalizedForm": "Spark", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.3825, "offsetStart": 194, "offsetEnd": 199}, "context": "To enable remote submission of the generated Scala script for Spark by the master wrapper, our setup relies on Apache Livy2 , which provides a REST service for easy submission of Spark jobs and Spark context management.", "mentionContextAttributes": {"used": {"value": false, "score": 0.13044798374176025}, "created": {"value": false, "score": 0.08340615034103394}, "shared": {"value": false, "score": 1.4841556549072266e-05}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9997756481170654}, "shared": {"value": false, "score": 1.4841556549072266e-05}}}, {"type": "software", "software-type": "implicit", "software-name": {"rawForm": "programs", "normalizedForm": "programs", "offsetStart": 196, "offsetEnd": 204}, "context": "These data management clusters can range from distributed raw data files, through parallel SQL databases, to sharded NoSQL databases (such as MongoDB, where queries can be expressed as JavaScript programs) and parallel data processing frameworks (such as Apache Spark, where data retrieval and/or transformation can be requested by means of Python or Scala scripting). ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0007843375205993652}, "created": {"value": false, "score": 0.0032498836517333984}, "shared": {"value": false, "score": 4.470348358154297e-06}}, "documentContextAttributes": {"used": {"value": false, "score": 0.0007843375205993652}, "created": {"value": false, "score": 0.0032498836517333984}, "shared": {"value": false, "score": 4.470348358154297e-06}}}, {"type": "software", "software-type": "software", "wikidataId": "Q1165204", "wikipediaExternalRef": 21855450, "lang": "en", "confidence": 0.7457, "software-name": {"rawForm": "MongoDB", "normalizedForm": "MongoDB", "wikidataId": "Q1165204", "wikipediaExternalRef": 21855450, "lang": "en", "confidence": 0.7457, "offsetStart": 197, "offsetEnd": 204}, "context": "This, however, forces the DQE to define certain constraints for parallel processing of document collection subqueries, in order to guarantee consistent results, which is normally guaranteed by the MongoDB router. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0017469525337219238}, "created": {"value": false, "score": 0.0002770423889160156}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9999129176139832}, "shared": {"value": false, "score": 9.065866470336914e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "script", "normalizedForm": "script", "offsetStart": 198, "offsetEnd": 204}, "language": {"rawForm": "Scala", "normalizedForm": "Scala"}, "context": "A(id int, x int JOINED ON id REFERENCING OUTER AS b_keys)@mongo = {* return db.A.find( {id: {$in: b_keys}} ); *} Thus, when A.id participates in an equi-join, the values b1,\u2026,bn are provided to the script code through the iterator/list object b_keys (in this context, we refer to the table B as the \"outer\" table, and b_keys as the outer keys).", "mentionContextAttributes": {"used": {"value": true, "score": 0.919108510017395}, "created": {"value": false, "score": 1.9669532775878906e-06}, "shared": {"value": false, "score": 2.086162567138672e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.919108510017395}, "created": {"value": true, "score": 0.9993940591812134}, "shared": {"value": false, "score": 1.4841556549072266e-05}}}, {"type": "software", "software-type": "software", "wikidataId": "Q47607", "wikipediaExternalRef": 29004, "lang": "en", "confidence": 0.4606, "software-name": {"rawForm": "SQL", "normalizedForm": "SQL", "wikidataId": "Q47607", "wikipediaExternalRef": 29004, "lang": "en", "confidence": 0.4606, "offsetStart": 201, "offsetEnd": 204}, "context": "With LeanXcale, once the named tables (subqueries to data stores) are defined by the system developer or administrator, they can be easily used and involved in joins (including bind joins) through the SQL interface.", "mentionContextAttributes": {"used": {"value": false, "score": 0.000822603702545166}, "created": {"value": false, "score": 5.227327346801758e-05}, "shared": {"value": false, "score": 8.940696716308594e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9934203028678894}, "shared": {"value": false, "score": 0.010259866714477539}}}, {"type": "software", "software-type": "software", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.3825, "software-name": {"rawForm": "Spark", "normalizedForm": "Spark", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.3825, "offsetStart": 201, "offsetEnd": 206}, "context": "Fig. 6 gives a high-level illustration of the processing of the query Q1 SL , assuming a simple MFR subquery that reads the LINEITEM table as a text file from the Hadoop cluster, but this time through Spark.", "mentionContextAttributes": {"used": {"value": false, "score": 0.3648099899291992}, "created": {"value": false, "score": 1.996755599975586e-05}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9997756481170654}, "shared": {"value": false, "score": 1.4841556549072266e-05}}}, {"type": "software", "software-type": "software", "wikidataId": "Q187432", "wikipediaExternalRef": 21490336, "lang": "en", "confidence": 0.5074, "software-name": {"rawForm": "scripts", "normalizedForm": "scripts", "wikidataId": "Q187432", "wikipediaExternalRef": 21490336, "lang": "en", "confidence": 0.5074, "offsetStart": 201, "offsetEnd": 208}, "context": "To enable ad-hoc querying of an arbitrary data set, using its scripting mechanism, and then joining the retrieved result set at DQE level, DQE processes queries in the CloudMdsQL query language, where scripts are wrapped as native subqueries.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0027613043785095215}, "created": {"value": false, "score": 8.660554885864258e-05}, "shared": {"value": false, "score": 4.172325134277344e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.0027613043785095215}, "created": {"value": true, "score": 0.9998281002044678}, "shared": {"value": false, "score": 2.3245811462402344e-06}}}, {"type": "software", "software-type": "software", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.3825, "software-name": {"rawForm": "Spark", "normalizedForm": "Spark", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.3825, "offsetStart": 204, "offsetEnd": 209}, "context": "As for workflow managers, although they can orchestrate efficiently relational operators across platforms, they do not provide query execution themselves; for example, a parallel join between MongoDB and Spark would be dispatched for execution at Spark by both Musketeer and RHEEM, so we would consider this comparison as equivalent to comparing with Spark.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0010941624641418457}, "created": {"value": false, "score": 2.7477741241455078e-05}, "shared": {"value": false, "score": 4.172325134277344e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9997756481170654}, "shared": {"value": false, "score": 1.4841556549072266e-05}}}, {"type": "software", "software-type": "software", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.3825, "software-name": {"rawForm": "Spark", "normalizedForm": "Spark", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.3825, "offsetStart": 204, "offsetEnd": 209}, "context": "It parses and interprets a subquery written in MFR notation; then, uses an MFR planner to find optimization opportunities; and finally translates the resulting sequence of MFR operations to a sequence of Spark methods to be executed, expressed as Scala (in our focus for this paper) or Python script.", "mentionContextAttributes": {"used": {"value": false, "score": 0.09219372272491455}, "created": {"value": false, "score": 0.0001442432403564453}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9997756481170654}, "shared": {"value": false, "score": 1.4841556549072266e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "code", "normalizedForm": "code", "offsetStart": 205, "offsetEnd": 209}, "context": "A(id int, x int JOINED ON id REFERENCING OUTER AS b_keys)@mongo = {* return db.A.find( {id: {$in: b_keys}} ); *} Thus, when A.id participates in an equi-join, the values b1,\u2026,bn are provided to the script code through the iterator/list object b_keys (in this context, we refer to the table B as the \"outer\" table, and b_keys as the outer keys).", "mentionContextAttributes": {"used": {"value": true, "score": 0.919108510017395}, "created": {"value": false, "score": 1.9669532775878906e-06}, "shared": {"value": false, "score": 2.086162567138672e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.919108510017395}, "created": {"value": true, "score": 0.9997756481170654}, "shared": {"value": false, "score": 2.562999725341797e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "API", "normalizedForm": "API", "offsetStart": 207, "offsetEnd": 210}, "context": "Here, we specifically focus on parallel joins across a relational table, the result of a JavaScript subquery to MongoDB, and the result of an MFR/Scala subquery to Apache Spark, but the concept relies on an API that allows its generalization to other script engines and data stores as well.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0018170475959777832}, "created": {"value": false, "score": 0.05537760257720947}, "shared": {"value": false, "score": 1.1324882507324219e-06}}, "documentContextAttributes": {"used": {"value": false, "score": 0.05950498580932617}, "created": {"value": false, "score": 0.05537760257720947}, "shared": {"value": false, "score": 4.655122756958008e-05}}}, {"type": "software", "software-type": "software", "wikidataId": "Q1165204", "wikipediaExternalRef": 21855450, "lang": "en", "confidence": 0.7457, "software-name": {"rawForm": "MongoDB", "normalizedForm": "MongoDB", "wikidataId": "Q1165204", "wikipediaExternalRef": 21855450, "lang": "en", "confidence": 0.7457, "offsetStart": 212, "offsetEnd": 219}, "context": "For example, the following simple CloudMdsQL query contains two subqueries, defined by the named table expressions T1 and T2, and addressed respectively against the data stores rdb (an SQL database) and mongo (a MongoDB database):", "mentionContextAttributes": {"used": {"value": false, "score": 0.0022200942039489746}, "created": {"value": false, "score": 3.7610530853271484e-05}, "shared": {"value": false, "score": 4.172325134277344e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9999129176139832}, "shared": {"value": false, "score": 9.065866470336914e-05}}}, {"type": "software", "software-type": "software", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.5539, "software-name": {"rawForm": "Spark", "normalizedForm": "Spark", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.5539, "offsetStart": 213, "offsetEnd": 218}, "context": "All the generated datasets were: loaded in LeanXcale as relational tables; loaded in MongoDB as document collections; copied to the HDFS cluster as raw CSV files, to be accessed through Hive as tables and through Spark by means of scans expressed as simple MFR/Scala statements. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9994305372238159}, "created": {"value": false, "score": 2.9206275939941406e-06}, "shared": {"value": false, "score": 5.364418029785156e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9997756481170654}, "shared": {"value": false, "score": 1.4841556549072266e-05}}}, {"type": "software", "software-type": "software", "wikidataId": "Q1165204", "wikipediaExternalRef": 21855450, "lang": "en", "confidence": 0.7457, "software-name": {"rawForm": "MongoDB", "normalizedForm": "MongoDB", "wikidataId": "Q1165204", "wikipediaExternalRef": 21855450, "lang": "en", "confidence": 0.7457, "offsetStart": 214, "offsetEnd": 221}, "context": "The choice of Spark SQL for a state-of-the-art representative to compare our work with is justified by the fact that it supports most of the features our approach targets and hereby evaluates, namely: (a) parallel MongoDB subqueries through the use of the MongoDB connector that also supports native Mon-goDB operators (e.g.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0012915730476379395}, "created": {"value": false, "score": 0.04539138078689575}, "shared": {"value": false, "score": 8.940696716308594e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9999129176139832}, "shared": {"value": false, "score": 9.065866470336914e-05}}}, {"type": "software", "software-type": "software", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.3825, "software-name": {"rawForm": "Spark", "normalizedForm": "Spark", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.3825, "offsetStart": 215, "offsetEnd": 220}, "context": "Among hybrid systems, although Presto and Drill support well parallel query processing across SQL and NoSQL stores, the only one that provides parallel support of distributed data platforms is Spark SQL, as it uses Spark natively. ", "mentionContextAttributes": {"used": {"value": false, "score": 7.051229476928711e-05}, "created": {"value": false, "score": 0.00028395652770996094}, "shared": {"value": false, "score": 3.2782554626464844e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9997756481170654}, "shared": {"value": false, "score": 1.4841556549072266e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "findSharded", "normalizedForm": "findSharded", "offsetStart": 215, "offsetEnd": 226}, "language": {"rawForm": "JavaScript", "normalizedForm": "JavaScript"}, "context": "Let us consider the following modification Q1 ML of query Q1, which assumes that the LINEITEM table resides as a sharded document collection in a MongoDB cluster and the selection on it is expressed by means of the findSharded() JavaScript method, while ORDERS is still a LeanXcale table, the partitions of which are stored in the KV storage layer.", "mentionContextAttributes": {"used": {"value": true, "score": 0.7317376136779785}, "created": {"value": false, "score": 2.562999725341797e-06}, "shared": {"value": false, "score": 7.748603820800781e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.7317376136779785}, "created": {"value": false, "score": 4.082918167114258e-05}, "shared": {"value": false, "score": 1.0132789611816406e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "REDUCE", "normalizedForm": "REDUCE", "offsetStart": 216, "offsetEnd": 222}, "context": "Rule #2: REDUCE(<transformation>).FILTER(<predicate>) is equivalent to FILTER(<predicate>).REDUCE(<transformation>), if predicate condition is a function only of the KEY, because thus, applying the FILTER before the REDUCE will preserve the values associated to those keys that satisfy the filter condition as they would be if the FILTER was applied after the REDUCE.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9831934571266174}, "created": {"value": false, "score": 3.039836883544922e-06}, "shared": {"value": false, "score": 2.4437904357910156e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9995518326759338}, "created": {"value": false, "score": 0.00020503997802734375}, "shared": {"value": false, "score": 2.4437904357910156e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "REDUCE", "normalizedForm": "REDUCE", "offsetStart": 217, "offsetEnd": 223}, "context": "MFR rewrites can be combined with bind join in the sense that when a bind join condition is pushed down the MFR subquery, it will be applied as early as possible, in many cases reducing significantly the work done by REDUCE operators on the way.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00013256072998046875}, "created": {"value": false, "score": 5.513429641723633e-05}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9995518326759338}, "created": {"value": false, "score": 0.00020503997802734375}, "shared": {"value": false, "score": 2.4437904357910156e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "code", "normalizedForm": "code", "offsetStart": 218, "offsetEnd": 222}, "context": "Even if the MongoDB data has to undergo transformations, expressed through user-defined JavaScript functions, this can still be handled in parallel by making each worker initiate the execution of the custom JavaScript code against the MongoDB shard assigned to it and collect its partition of the intermediate data.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00835806131362915}, "created": {"value": false, "score": 0.00038951635360717773}, "shared": {"value": false, "score": 1.2516975402832031e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.919108510017395}, "created": {"value": true, "score": 0.9997756481170654}, "shared": {"value": false, "score": 2.562999725341797e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "API", "normalizedForm": "API", "offsetStart": 227, "offsetEnd": 230}, "context": "Loosely-coupled polystores are reminiscent of multidatabase systems in that they can deal with autonomous data stores, which can then be accessed through the polystore common interface as well as separately through their local API.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0003126859664916992}, "created": {"value": false, "score": 0.0001023411750793457}, "shared": {"value": false, "score": 1.7285346984863281e-06}}, "documentContextAttributes": {"used": {"value": false, "score": 0.05950498580932617}, "created": {"value": false, "score": 0.05537760257720947}, "shared": {"value": false, "score": 4.655122756958008e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LeanXcale", "normalizedForm": "LeanXcale", "offsetStart": 229, "offsetEnd": 238}, "context": "Although these systems enable parallel integration with data clusters (like MongoDB), none of them supports the combination of massive parallelism with native queries and the optimization of bind joins, which is addressed by the LeanXcale distributed query engine. ", "mentionContextAttributes": {"used": {"value": false, "score": 4.6193599700927734e-05}, "created": {"value": false, "score": 0.0024118423461914062}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999398589134216}, "created": {"value": true, "score": 0.9999358057975769}, "shared": {"value": false, "score": 8.52346420288086e-06}}}, {"type": "software", "software-type": "software", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.3825, "software-name": {"rawForm": "Spark", "normalizedForm": "Spark", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.3825, "offsetStart": 234, "offsetEnd": 239}, "context": "Spark SQL [6] is a parallel SQL engine built on top of Apache Spark and designed to provide tight integration between relational and procedural processing through a declarative API that integrates relational operators with procedural Spark code, taking advantage of massive parallelism.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00022149085998535156}, "created": {"value": false, "score": 0.013364613056182861}, "shared": {"value": false, "score": 2.562999725341797e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9997756481170654}, "shared": {"value": false, "score": 1.4841556549072266e-05}}}, {"type": "software", "software-type": "software", "wikidataId": "Q1165204", "wikipediaExternalRef": 21855450, "lang": "en", "confidence": 0.7457, "software-name": {"rawForm": "MongoDB", "normalizedForm": "MongoDB", "wikidataId": "Q1165204", "wikipediaExternalRef": 21855450, "lang": "en", "confidence": 0.7457, "offsetStart": 235, "offsetEnd": 242}, "context": "Even if the MongoDB data has to undergo transformations, expressed through user-defined JavaScript functions, this can still be handled in parallel by making each worker initiate the execution of the custom JavaScript code against the MongoDB shard assigned to it and collect its partition of the intermediate data.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00835806131362915}, "created": {"value": false, "score": 0.00038951635360717773}, "shared": {"value": false, "score": 1.2516975402832031e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9999129176139832}, "shared": {"value": false, "score": 9.065866470336914e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "code", "normalizedForm": "code", "offsetStart": 240, "offsetEnd": 244}, "context": "Spark SQL [6] is a parallel SQL engine built on top of Apache Spark and designed to provide tight integration between relational and procedural processing through a declarative API that integrates relational operators with procedural Spark code, taking advantage of massive parallelism.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00022149085998535156}, "created": {"value": false, "score": 0.013364613056182861}, "shared": {"value": false, "score": 2.562999725341797e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.919108510017395}, "created": {"value": true, "score": 0.9997756481170654}, "shared": {"value": false, "score": 2.562999725341797e-06}}}, {"type": "software", "software-type": "software", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.3825, "software-name": {"rawForm": "Spark", "normalizedForm": "Spark", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.3825, "offsetStart": 242, "offsetEnd": 247}, "context": "To achieve this, the query engine creates a session at the Spark driver, then translates the MFR subquery to code (in Scala or Python for Spark), delegates this code to Spark for execution, and collects the intermediate data through the same Spark driver session.", "mentionContextAttributes": {"used": {"value": false, "score": 0.20863837003707886}, "created": {"value": false, "score": 9.888410568237305e-05}, "shared": {"value": false, "score": 5.364418029785156e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9997756481170654}, "shared": {"value": false, "score": 1.4841556549072266e-05}}}, {"type": "software", "software-type": "software", "wikidataId": "Q47607", "wikipediaExternalRef": 29004, "lang": "en", "confidence": 0.4606, "software-name": {"rawForm": "SQL", "normalizedForm": "SQL", "wikidataId": "Q47607", "wikipediaExternalRef": 29004, "lang": "en", "confidence": 0.4606, "offsetStart": 245, "offsetEnd": 248}, "context": "And to enable the parallel query processing, we incorporated the polyglot approach within the LeanXcale1 Distributed Query Engine (DQE), which provides a query engine with intra-query and intra-operator parallelism that operates over a standard SQL interface.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0017653703689575195}, "created": {"value": true, "score": 0.9934203028678894}, "shared": {"value": false, "score": 5.364418029785156e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9934203028678894}, "shared": {"value": false, "score": 0.010259866714477539}}}, {"type": "software", "software-type": "software", "wikidataId": "Q460584", "wikipediaExternalRef": 3254510, "lang": "en", "confidence": 0.591, "software-name": {"rawForm": "Scala", "normalizedForm": "Scala", "wikidataId": "Q460584", "wikipediaExternalRef": 3254510, "lang": "en", "confidence": 0.591, "offsetStart": 247, "offsetEnd": 252}, "context": "It parses and interprets a subquery written in MFR notation; then, uses an MFR planner to find optimization opportunities; and finally translates the resulting sequence of MFR operations to a sequence of Spark methods to be executed, expressed as Scala (in our focus for this paper) or Python script. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.09219372272491455}, "created": {"value": false, "score": 0.0001442432403564453}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999205470085144}, "created": {"value": true, "score": 0.9993940591812134}, "shared": {"value": false, "score": 1.4841556549072266e-05}}}, {"type": "software", "software-type": "software", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.3825, "software-name": {"rawForm": "Spark", "normalizedForm": "Spark", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.3825, "offsetStart": 247, "offsetEnd": 252}, "context": "As for workflow managers, although they can orchestrate efficiently relational operators across platforms, they do not provide query execution themselves; for example, a parallel join between MongoDB and Spark would be dispatched for execution at Spark by both Musketeer and RHEEM, so we would consider this comparison as equivalent to comparing with Spark.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0010941624641418457}, "created": {"value": false, "score": 2.7477741241455078e-05}, "shared": {"value": false, "score": 4.172325134277344e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9997756481170654}, "shared": {"value": false, "score": 1.4841556549072266e-05}}}, {"type": "software", "software-type": "implicit", "software-name": {"rawForm": "script engines", "normalizedForm": "script engines", "offsetStart": 251, "offsetEnd": 265}, "context": "Here, we specifically focus on parallel joins across a relational table, the result of a JavaScript subquery to MongoDB, and the result of an MFR/Scala subquery to Apache Spark, but the concept relies on an API that allows its generalization to other script engines and data stores as well. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0018170475959777832}, "created": {"value": false, "score": 0.05537760257720947}, "shared": {"value": false, "score": 1.1324882507324219e-06}}, "documentContextAttributes": {"used": {"value": false, "score": 0.0018170475959777832}, "created": {"value": false, "score": 0.05537760257720947}, "shared": {"value": false, "score": 1.1324882507324219e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "code", "normalizedForm": "code", "offsetStart": 253, "offsetEnd": 257}, "context": "At this moment, the execution of the prepared Spark job gets initiated by calling through the same Livy session the following foreachPartition action function that makes each partition connect to an available wrapper instance and send its data: In this code, connectSparkAgent is a function that the master wrapper preliminarily generates and defines in the Livy session.", "mentionContextAttributes": {"used": {"value": false, "score": 0.02586996555328369}, "created": {"value": false, "score": 1.4126300811767578e-05}, "shared": {"value": false, "score": 1.0132789611816406e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.919108510017395}, "created": {"value": true, "score": 0.9997756481170654}, "shared": {"value": false, "score": 2.562999725341797e-06}}}, {"type": "software", "software-type": "software", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.7879, "software-name": {"rawForm": "Apache Spark", "normalizedForm": "Apache Spark", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.7879, "offsetStart": 255, "offsetEnd": 267}, "context": "These data management clusters can range from distributed raw data files, through parallel SQL databases, to sharded NoSQL databases (such as MongoDB, where queries can be expressed as JavaScript programs) and parallel data processing frameworks (such as Apache Spark, where data retrieval and/or transformation can be requested by means of Python or Scala scripting). ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0007843375205993652}, "created": {"value": false, "score": 0.0032500028610229492}, "shared": {"value": false, "score": 4.470348358154297e-06}}, "documentContextAttributes": {"used": {"value": false, "score": 0.01917022466659546}, "created": {"value": true, "score": 0.7794421911239624}, "shared": {"value": false, "score": 4.470348358154297e-06}}}, {"type": "software", "software-type": "software", "wikidataId": "Q1165204", "wikipediaExternalRef": 21855450, "lang": "en", "confidence": 0.7457, "software-name": {"rawForm": "MongoDB", "normalizedForm": "MongoDB", "wikidataId": "Q1165204", "wikipediaExternalRef": 21855450, "lang": "en", "confidence": 0.7457, "offsetStart": 256, "offsetEnd": 263}, "context": "The choice of Spark SQL for a state-of-the-art representative to compare our work with is justified by the fact that it supports most of the features our approach targets and hereby evaluates, namely: (a) parallel MongoDB subqueries through the use of the MongoDB connector that also supports native Mon-goDB operators (e.g.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0012915730476379395}, "created": {"value": false, "score": 0.04539138078689575}, "shared": {"value": false, "score": 8.940696716308594e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9999129176139832}, "shared": {"value": false, "score": 9.065866470336914e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "connectSparkAgent", "normalizedForm": "connectSparkAgent", "offsetStart": 259, "offsetEnd": 276}, "context": "At this moment, the execution of the prepared Spark job gets initiated by calling through the same Livy session the following foreachPartition action function that makes each partition connect to an available wrapper instance and send its data: In this code, connectSparkAgent is a function that the master wrapper preliminarily generates and defines in the Livy session. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.02586996555328369}, "created": {"value": false, "score": 1.4126300811767578e-05}, "shared": {"value": false, "score": 1.0132789611816406e-06}}, "documentContextAttributes": {"used": {"value": false, "score": 0.02586996555328369}, "created": {"value": false, "score": 1.4126300811767578e-05}, "shared": {"value": false, "score": 1.0132789611816406e-06}}}, {"type": "software", "software-type": "software", "wikidataId": "Q47607", "wikipediaExternalRef": 29004, "lang": "en", "confidence": 0.4606, "software-name": {"rawForm": "SQL", "normalizedForm": "SQL", "wikidataId": "Q47607", "wikipediaExternalRef": 29004, "lang": "en", "confidence": 0.4606, "offsetStart": 261, "offsetEnd": 264}, "context": "The system applies the principles of Hybrid Transactional and Analytical Processing (HTAP) and addresses the hard problem of scaling out transactions in mixed operational and analytical workloads over big data, possibly coming from different data stores (HDFS, SQL, NoSQL, etc.).", "mentionContextAttributes": {"used": {"value": false, "score": 0.0003935694694519043}, "created": {"value": false, "score": 0.008056879043579102}, "shared": {"value": false, "score": 6.556510925292969e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9934203028678894}, "shared": {"value": false, "score": 0.010259866714477539}}}, {"type": "software", "software-type": "software", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.3825, "software-name": {"rawForm": "Spark", "normalizedForm": "Spark", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.3825, "offsetStart": 261, "offsetEnd": 266}, "context": "A discovery service is introduced through the special component Spark Agent Registry that keeps information about available Spark wrapper instances and dispatches them to the requesting Spark workers so that parallelism is fully exploited in moving data from a Spark RDD to the DQE.", "mentionContextAttributes": {"used": {"value": false, "score": 0.005214571952819824}, "created": {"value": false, "score": 0.003361940383911133}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9997756481170654}, "shared": {"value": false, "score": 1.4841556549072266e-05}}}, {"type": "software", "software-type": "software", "wikidataId": "Q460584", "wikipediaExternalRef": 3254510, "lang": "en", "confidence": 0.2001, "software-name": {"rawForm": "Scala", "normalizedForm": "Scala", "wikidataId": "Q460584", "wikipediaExternalRef": 3254510, "lang": "en", "confidence": 0.2001, "offsetStart": 261, "offsetEnd": 266}, "context": "All the generated datasets were: loaded in LeanXcale as relational tables; loaded in MongoDB as document collections; copied to the HDFS cluster as raw CSV files, to be accessed through Hive as tables and through Spark by means of scans expressed as simple MFR/Scala statements.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9994305372238159}, "created": {"value": false, "score": 2.9206275939941406e-06}, "shared": {"value": false, "score": 5.364418029785156e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999205470085144}, "created": {"value": true, "score": 0.9993940591812134}, "shared": {"value": false, "score": 1.4841556549072266e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Musketeer", "normalizedForm": "Musketeer", "offsetStart": 261, "offsetEnd": 270}, "context": "As for workflow managers, although they can orchestrate efficiently relational operators across platforms, they do not provide query execution themselves; for example, a parallel join between MongoDB and Spark would be dispatched for execution at Spark by both Musketeer and RHEEM, so we would consider this comparison as equivalent to comparing with Spark.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0010941624641418457}, "created": {"value": false, "score": 2.7477741241455078e-05}, "shared": {"value": false, "score": 4.172325134277344e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.0010941624641418457}, "created": {"value": false, "score": 2.7477741241455078e-05}, "shared": {"value": false, "score": 4.172325134277344e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LeanXcale", "normalizedForm": "LeanXcale", "offsetStart": 272, "offsetEnd": 281}, "context": "In this paper, we address these points by: (i) using the polyglot approach of the CloudMdsQL query language that allows native queries to be expressed as inline scripts and combined with SQL statements for ad-hoc integration and (ii) incorporating the approach within the LeanXcale distributed query engine, thus allowing for native scripts to be processed in parallel at data store shards. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0006181597709655762}, "created": {"value": false, "score": 0.4770117402076721}, "shared": {"value": false, "score": 2.3245811462402344e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999398589134216}, "created": {"value": true, "score": 0.9999358057975769}, "shared": {"value": false, "score": 8.52346420288086e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LeanXcale", "normalizedForm": "LeanXcale", "offsetStart": 272, "offsetEnd": 281}, "context": "Let us consider the following modification Q1 ML of query Q1, which assumes that the LINEITEM table resides as a sharded document collection in a MongoDB cluster and the selection on it is expressed by means of the findSharded() JavaScript method, while ORDERS is still a LeanXcale table, the partitions of which are stored in the KV storage layer.", "mentionContextAttributes": {"used": {"value": true, "score": 0.7317376136779785}, "created": {"value": false, "score": 2.562999725341797e-06}, "shared": {"value": false, "score": 7.748603820800781e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999398589134216}, "created": {"value": true, "score": 0.9999358057975769}, "shared": {"value": false, "score": 8.52346420288086e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Python", "normalizedForm": "Python", "offsetStart": 286, "offsetEnd": 292}, "context": "It parses and interprets a subquery written in MFR notation; then, uses an MFR planner to find optimization opportunities; and finally translates the resulting sequence of MFR operations to a sequence of Spark methods to be executed, expressed as Scala (in our focus for this paper) or Python script.", "mentionContextAttributes": {"used": {"value": false, "score": 0.09219372272491455}, "created": {"value": false, "score": 0.0001442432403564453}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.20863837003707886}, "created": {"value": false, "score": 0.0032500028610229492}, "shared": {"value": false, "score": 4.470348358154297e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "DataLake API", "normalizedForm": "DataLake API", "offsetStart": 287, "offsetEnd": 299}, "context": "The query engine architecture is therefore extended to access in parallel shards of the external data store through the use of DataLake distributed wrappers that hide the complexity of the underlying data stores' query/scripting languages and encapsulate their interfaces under a common DataLake API to be interfaced by the query engine.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0006234049797058105}, "created": {"value": false, "score": 0.0038558244705200195}, "shared": {"value": false, "score": 4.231929779052734e-06}}, "documentContextAttributes": {"used": {"value": false, "score": 0.0319443941116333}, "created": {"value": false, "score": 0.00882875919342041}, "shared": {"value": false, "score": 1.5914440155029297e-05}}}, {"type": "software", "software-type": "software", "wikidataId": "Q460584", "wikipediaExternalRef": 3254510, "lang": "en", "confidence": 0.2001, "software-name": {"rawForm": "Scala", "normalizedForm": "Scala", "wikidataId": "Q460584", "wikipediaExternalRef": 3254510, "lang": "en", "confidence": 0.2001, "offsetStart": 288, "offsetEnd": 293}, "context": "Query Q2 S evaluates just the parallel execution of the Experts MFR query on Spark, while Q2 SL involves a join with the CUSTOMER table from the LeanXcale data store: Fig. 10 shows the performance measurements of Q2 queries that stress on the evaluation of the parallel processing of MFR/Scala queries against Spark, with and without join with a LeanXcale table.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9895274043083191}, "created": {"value": false, "score": 2.3245811462402344e-06}, "shared": {"value": false, "score": 5.364418029785156e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999205470085144}, "created": {"value": true, "score": 0.9993940591812134}, "shared": {"value": false, "score": 1.4841556549072266e-05}}}, {"type": "software", "software-type": "implicit", "software-name": {"rawForm": "script", "normalizedForm": "script", "offsetStart": 293, "offsetEnd": 299}, "language": {"rawForm": "Scala", "normalizedForm": "Scala"}, "context": "It parses and interprets a subquery written in MFR notation; then, uses an MFR planner to find optimization opportunities; and finally translates the resulting sequence of MFR operations to a sequence of Spark methods to be executed, expressed as Scala (in our focus for this paper) or Python script. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.09219372272491455}, "created": {"value": false, "score": 0.0001442432403564453}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.919108510017395}, "created": {"value": true, "score": 0.9993940591812134}, "shared": {"value": false, "score": 1.4841556549072266e-05}}}, {"type": "software", "software-type": "software", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.3825, "software-name": {"rawForm": "Spark", "normalizedForm": "Spark", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.3825, "offsetStart": 309, "offsetEnd": 314}, "context": "Thus, RHEEM can integrate data from different data stores (hence act as a polystore) by assigning different operators from the query plan to different engines, e.g., perform selections on base tables and associated joins at the RDBMS to exploit indexes, then ship intermediate data and perform other joins at Spark to exploit parallelism.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00041991472244262695}, "created": {"value": false, "score": 2.7954578399658203e-05}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9997756481170654}, "shared": {"value": false, "score": 1.4841556549072266e-05}}}, {"type": "software", "software-type": "software", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.3825, "software-name": {"rawForm": "Spark", "normalizedForm": "Spark", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.3825, "offsetStart": 310, "offsetEnd": 315}, "context": "Query Q2 S evaluates just the parallel execution of the Experts MFR query on Spark, while Q2 SL involves a join with the CUSTOMER table from the LeanXcale data store: Fig. 10 shows the performance measurements of Q2 queries that stress on the evaluation of the parallel processing of MFR/Scala queries against Spark, with and without join with a LeanXcale table.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9895274043083191}, "created": {"value": false, "score": 2.3245811462402344e-06}, "shared": {"value": false, "score": 5.364418029785156e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9997756481170654}, "shared": {"value": false, "score": 1.4841556549072266e-05}}}, {"type": "software", "software-type": "software", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.3825, "software-name": {"rawForm": "Spark", "normalizedForm": "Spark", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.3825, "offsetStart": 314, "offsetEnd": 319}, "context": "Thus, Q4 is defined as follows: Using bind join, the query executes as follows: first, the join between CLICKS at HDFS and BookOrders at MongoDB takes place, as in Q3; then, after flattening O.keywords and identifying the list of distinct keywords, another bind join condition is pushed to the Experts subquery to Spark, as described in Section 5.1, to reduce the amount of data processed by Spark transformations.", "mentionContextAttributes": {"used": {"value": true, "score": 0.6309001445770264}, "created": {"value": false, "score": 1.7285346984863281e-06}, "shared": {"value": false, "score": 8.940696716308594e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9997756481170654}, "shared": {"value": false, "score": 1.4841556549072266e-05}}}, {"type": "software", "software-type": "implicit", "wikidataId": "Q187432", "wikipediaExternalRef": 21490336, "lang": "en", "confidence": 0.5074, "software-name": {"rawForm": "scripts", "normalizedForm": "scripts", "wikidataId": "Q187432", "wikipediaExternalRef": 21490336, "lang": "en", "confidence": 0.5074, "offsetStart": 333, "offsetEnd": 340}, "context": "In this paper, we address these points by: (i) using the polyglot approach of the CloudMdsQL query language that allows native queries to be expressed as inline scripts and combined with SQL statements for ad-hoc integration and (ii) incorporating the approach within the LeanXcale distributed query engine, thus allowing for native scripts to be processed in parallel at data store shards. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0006181597709655762}, "created": {"value": false, "score": 0.4770117402076721}, "shared": {"value": false, "score": 2.3245811462402344e-06}}, "documentContextAttributes": {"used": {"value": false, "score": 0.0027613043785095215}, "created": {"value": true, "score": 0.9998281002044678}, "shared": {"value": false, "score": 2.3245811462402344e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Python", "normalizedForm": "Python", "offsetStart": 341, "offsetEnd": 347}, "context": "These data management clusters can range from distributed raw data files, through parallel SQL databases, to sharded NoSQL databases (such as MongoDB, where queries can be expressed as JavaScript programs) and parallel data processing frameworks (such as Apache Spark, where data retrieval and/or transformation can be requested by means of Python or Scala scripting). ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0007843375205993652}, "created": {"value": false, "score": 0.0032500028610229492}, "shared": {"value": false, "score": 4.470348358154297e-06}}, "documentContextAttributes": {"used": {"value": false, "score": 0.20863837003707886}, "created": {"value": false, "score": 0.0032500028610229492}, "shared": {"value": false, "score": 4.470348358154297e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LeanXcale", "normalizedForm": "LeanXcale", "offsetStart": 346, "offsetEnd": 355}, "context": "Query Q2 S evaluates just the parallel execution of the Experts MFR query on Spark, while Q2 SL involves a join with the CUSTOMER table from the LeanXcale data store: Fig. 10 shows the performance measurements of Q2 queries that stress on the evaluation of the parallel processing of MFR/Scala queries against Spark, with and without join with a LeanXcale table.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9895274043083191}, "created": {"value": false, "score": 2.3245811462402344e-06}, "shared": {"value": false, "score": 5.364418029785156e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999398589134216}, "created": {"value": true, "score": 0.9999358057975769}, "shared": {"value": false, "score": 8.52346420288086e-06}}}, {"type": "software", "software-type": "software", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.3825, "software-name": {"rawForm": "Spark", "normalizedForm": "Spark", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.3825, "offsetStart": 351, "offsetEnd": 356}, "context": "As for workflow managers, although they can orchestrate efficiently relational operators across platforms, they do not provide query execution themselves; for example, a parallel join between MongoDB and Spark would be dispatched for execution at Spark by both Musketeer and RHEEM, so we would consider this comparison as equivalent to comparing with Spark. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0010941624641418457}, "created": {"value": false, "score": 2.7477741241455078e-05}, "shared": {"value": false, "score": 4.172325134277344e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9997756481170654}, "shared": {"value": false, "score": 1.4841556549072266e-05}}}, {"type": "software", "software-type": "software", "wikidataId": "Q460584", "wikipediaExternalRef": 3254510, "lang": "en", "confidence": 0.2001, "software-name": {"rawForm": "Scala", "normalizedForm": "Scala", "wikidataId": "Q460584", "wikipediaExternalRef": 3254510, "lang": "en", "confidence": 0.2001, "offsetStart": 351, "offsetEnd": 356}, "context": "These data management clusters can range from distributed raw data files, through parallel SQL databases, to sharded NoSQL databases (such as MongoDB, where queries can be expressed as JavaScript programs) and parallel data processing frameworks (such as Apache Spark, where data retrieval and/or transformation can be requested by means of Python or Scala scripting). ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0007843971252441406}, "created": {"value": false, "score": 0.0032500028610229492}, "shared": {"value": false, "score": 4.410743713378906e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999205470085144}, "created": {"value": true, "score": 0.9993940591812134}, "shared": {"value": false, "score": 1.4841556549072266e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "REDUCE", "normalizedForm": "REDUCE", "offsetStart": 360, "offsetEnd": 366}, "context": "Rule #2: REDUCE(<transformation>).FILTER(<predicate>) is equivalent to FILTER(<predicate>).REDUCE(<transformation>), if predicate condition is a function only of the KEY, because thus, applying the FILTER before the REDUCE will preserve the values associated to those keys that satisfy the filter condition as they would be if the FILTER was applied after the REDUCE.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9831936359405518}, "created": {"value": false, "score": 2.9802322387695312e-06}, "shared": {"value": false, "score": 2.384185791015625e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9995518326759338}, "created": {"value": false, "score": 0.00020503997802734375}, "shared": {"value": false, "score": 2.4437904357910156e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LeanXcale", "normalizedForm": "LeanXcale", "offsetStart": 367, "offsetEnd": 376}, "context": "Query Q2 M evaluates just the parallel execution of the BookOrders script in MongoDB, while Q2 ML involves a join between MongoDB and the CUSTOMER table from the LeanXcale data store: Fig. 9 shows the performance measurements of Q2 queries that stress on the evaluation of the parallel processing of highly expressive JavaScript queries, with and without join with a LeanXcale table.", "mentionContextAttributes": {"used": {"value": true, "score": 0.7139508724212646}, "created": {"value": false, "score": 3.0994415283203125e-06}, "shared": {"value": false, "score": 9.5367431640625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999398589134216}, "created": {"value": true, "score": 0.9999358057975769}, "shared": {"value": false, "score": 8.52346420288086e-06}}}, {"type": "software", "software-type": "software", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.3825, "software-name": {"rawForm": "Spark", "normalizedForm": "Spark", "wikidataId": "Q7573619", "wikipediaExternalRef": 42164234, "lang": "en", "confidence": 0.3825, "offsetStart": 392, "offsetEnd": 397}, "context": "Thus, Q4 is defined as follows: Using bind join, the query executes as follows: first, the join between CLICKS at HDFS and BookOrders at MongoDB takes place, as in Q3; then, after flattening O.keywords and identifying the list of distinct keywords, another bind join condition is pushed to the Experts subquery to Spark, as described in Section 5.1, to reduce the amount of data processed by Spark transformations.", "mentionContextAttributes": {"used": {"value": true, "score": 0.6309002637863159}, "created": {"value": false, "score": 1.6689300537109375e-06}, "shared": {"value": false, "score": 8.344650268554688e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999768137931824}, "created": {"value": true, "score": 0.9997756481170654}, "shared": {"value": false, "score": 1.4841556549072266e-05}}}], "references": [{"refKey": 26, "tei": "<biblStruct xml:id=\"b26\">\n\t<analytic>\n\t\t<title level=\"a\" type=\"main\">CloudMdsQL: querying heterogeneous cloud data stores with a common language</title>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Boyan</forename><surname>Kolev</surname></persName>\n\t\t\t<idno type=\"ORCID\">0000-0003-4871-0434</idno>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Patrick</forename><surname>Valduriez</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Carlyna</forename><surname>Bondiombouy</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Ricardo</forename><surname>Jim\u00e9nez-Peris</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Raquel</forename><surname>Pau</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Jos\u00e9</forename><surname>Pereira</surname></persName>\n\t\t</author>\n\t\t<idno type=\"DOI\">10.1007/s10619-015-7185-y</idno>\n\t</analytic>\n\t<monogr>\n\t\t<title level=\"j\">Distributed and Parallel Databases</title>\n\t\t<title level=\"j\" type=\"abbrev\">Distrib Parallel Databases</title>\n\t\t<idno type=\"ISSN\">0926-8782</idno>\n\t\t<idno type=\"ISSNe\">1573-7578</idno>\n\t\t<imprint>\n\t\t\t<biblScope unit=\"volume\">34</biblScope>\n\t\t\t<biblScope unit=\"issue\">4</biblScope>\n\t\t\t<biblScope unit=\"page\" from=\"463\" to=\"503\" />\n\t\t\t<date type=\"published\" when=\"2015-09-25\">2015</date>\n\t\t\t<publisher>Springer Science and Business Media LLC</publisher>\n\t\t</imprint>\n\t</monogr>\n</biblStruct>\n"}], "runtime": 202219, "id": "b5713d09a9b4da68b971530e593f441eb538132b", "metadata": {"id": "b5713d09a9b4da68b971530e593f441eb538132b"}, "original_file_path": "../../datalake/Samuel/SOFTware-Sync/data/xml_not_sofctied/lirmm-03148271.grobid.tei.xml", "file_name": "lirmm-03148271.grobid.tei.xml"}