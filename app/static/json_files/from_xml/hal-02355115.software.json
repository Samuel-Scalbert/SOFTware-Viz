{"application": "software-mentions", "version": "0.8.0", "date": "2024-04-15T07:30+0000", "md5": "695C7337CB7BBDD94247F7B51E97EF8C", "mentions": [{"type": "software", "software-type": "software", "software-name": {"rawForm": "VoiceMask", "normalizedForm": "VoiceMask", "offsetStart": 0, "offsetEnd": 9}, "context": "VoiceMask is described in [15] as the frequency warping method based on the composition of a log-bilinear function, expressed as f (\u03c9, \u03b1) = | -i ln z-\u03b1 1-\u03b1z |, and a quadratic function, given by g", "mentionContextAttributes": {"used": {"value": false, "score": 0.0002974271774291992}, "created": {"value": false, "score": 0.0004851222038269043}, "shared": {"value": false, "score": 4.172325134277344e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.29853516817092896}, "created": {"value": false, "score": 0.0004851222038269043}, "shared": {"value": false, "score": 1.8477439880371094e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "VoiceMask", "normalizedForm": "VoiceMask", "offsetStart": 0, "offsetEnd": 9}, "context": "VoiceMask.", "mentionContextAttributes": {"used": {"value": false, "score": 0.012755393981933594}, "created": {"value": false, "score": 0.0004292130470275879}, "shared": {"value": false, "score": 1.8477439880371094e-06}}, "documentContextAttributes": {"used": {"value": false, "score": 0.29853516817092896}, "created": {"value": false, "score": 0.0004851222038269043}, "shared": {"value": false, "score": 1.8477439880371094e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "VoiceMask", "normalizedForm": "VoiceMask", "offsetStart": 9, "offsetEnd": 18}, "context": "However, VoiceMask uses the same parameter values to warp the spectra at each time step of the utterance. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.000883936882019043}, "created": {"value": false, "score": 5.781650543212891e-06}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.29853516817092896}, "created": {"value": false, "score": 0.0004851222038269043}, "shared": {"value": false, "score": 1.8477439880371094e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "VoiceMask", "normalizedForm": "VoiceMask", "offsetStart": 12, "offsetEnd": 21}, "context": "Compared to VoiceMask, this approach warps the frequency axis in different directions over time. ", "mentionContextAttributes": {"used": {"value": false, "score": 5.9664249420166016e-05}, "created": {"value": false, "score": 4.89354133605957e-05}, "shared": {"value": false, "score": 4.172325134277344e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.29853516817092896}, "created": {"value": false, "score": 0.0004851222038269043}, "shared": {"value": false, "score": 1.8477439880371094e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "VoiceMask", "normalizedForm": "VoiceMask", "offsetStart": 19, "offsetEnd": 28}, "context": "Strictly speaking, VoiceMask is a voice transformation method rather than a VC method: pitch is converted from the source speaker to a target speaker, but the spectral envelope is not related to a particular target speaker.", "mentionContextAttributes": {"used": {"value": false, "score": 8.45789909362793e-05}, "created": {"value": false, "score": 0.0001766681671142578}, "shared": {"value": false, "score": 5.364418029785156e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.29853516817092896}, "created": {"value": false, "score": 0.0004851222038269043}, "shared": {"value": false, "score": 1.8477439880371094e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "VoiceMask", "normalizedForm": "VoiceMask", "offsetStart": 29, "offsetEnd": 38}, "context": "These ranges are provided by VoiceMask's authors in [15] since they produce most intelligible output.", "mentionContextAttributes": {"used": {"value": false, "score": 0.29853516817092896}, "created": {"value": false, "score": 4.392862319946289e-05}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.29853516817092896}, "created": {"value": false, "score": 0.0004851222038269043}, "shared": {"value": false, "score": 1.8477439880371094e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LibriSpeech", "normalizedForm": "LibriSpeech", "offsetStart": 37, "offsetEnd": 48}, "context": "All experiments are performed on the LibriSpeech corpus [24].", "mentionContextAttributes": {"used": {"value": true, "score": 0.986311674118042}, "created": {"value": false, "score": 9.351968765258789e-05}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9969823360443115}, "created": {"value": true, "score": 0.9908990263938904}, "shared": {"value": false, "score": 6.556510925292969e-07}}, "references": [{"label": "[24]", "normalizedForm": "[24]", "refKey": 24, "offsetStart": 12503, "offsetEnd": 12507}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LibriSpeech", "normalizedForm": "LibriSpeech", "offsetStart": 54, "offsetEnd": 65}, "context": "This reduced architecture performs slightly better on LibriSpeech than the architecture in the original recipe. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.00252455472946167}, "created": {"value": false, "score": 8.887052536010742e-05}, "shared": {"value": false, "score": 6.556510925292969e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9969823360443115}, "created": {"value": true, "score": 0.9908990263938904}, "shared": {"value": false, "score": 6.556510925292969e-07}}, "references": [{"label": "[24]", "normalizedForm": "[24]", "refKey": 24}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "VoiceMask", "normalizedForm": "VoiceMask", "offsetStart": 64, "offsetEnd": 73}, "context": "This means choosing a unique target speaker and, in the case of VoiceMask, fixed values for \u03b1 and \u03b2. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.00016021728515625}, "created": {"value": false, "score": 4.547834396362305e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.29853516817092896}, "created": {"value": false, "score": 0.0004851222038269043}, "shared": {"value": false, "score": 1.8477439880371094e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "pyworld", "normalizedForm": "pyworld", "offsetStart": 66, "offsetEnd": 73}, "context": "Pitch, aperiodicity and spectral envelope are extracted using the pyworld vocoder. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999348521232605}, "created": {"value": false, "score": 4.470348358154297e-06}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999696612358093}, "created": {"value": false, "score": 4.470348358154297e-06}, "shared": {"value": false, "score": 1.7881393432617188e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "pyworld", "normalizedForm": "pyworld", "offsetStart": 66, "offsetEnd": 73}, "context": "Pitch, aperiodicity and spectral envelope are extracted using the pyworld vocoder 5 .", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999696612358093}, "created": {"value": false, "score": 1.9669532775878906e-06}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999696612358093}, "created": {"value": false, "score": 4.470348358154297e-06}, "shared": {"value": false, "score": 1.7881393432617188e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LibriSpeech", "normalizedForm": "LibriSpeech", "offsetStart": 72, "offsetEnd": 84}, "context": "We adapt the sre16 Kaldi recipe for training x-vectors and i-vectors to LibriSpeech3 . ", "mentionContextAttributes": {"used": {"value": false, "score": 0.025171339511871338}, "created": {"value": true, "score": 0.9908990263938904}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9969823360443115}, "created": {"value": true, "score": 0.9908990263938904}, "shared": {"value": false, "score": 6.556510925292969e-07}}, "references": [{"label": "[24]", "normalizedForm": "[24]", "refKey": 24}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "VoiceMask", "normalizedForm": "VoiceMask", "offsetStart": 83, "offsetEnd": 92}, "context": "For instance, we consider a Semi-Informed attacker who knows the chosen VC method (VoiceMask, VTLN, or disentangled representation) and the target selection strategy (const, perm, or random), but not the actual target (i.e., the actual target speaker or the value of \u03b1 and \u03b2).", "mentionContextAttributes": {"used": {"value": false, "score": 0.001118779182434082}, "created": {"value": false, "score": 3.7550926208496094e-06}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.29853516817092896}, "created": {"value": false, "score": 0.0004851222038269043}, "shared": {"value": false, "score": 1.8477439880371094e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LibriSpeech", "normalizedForm": "LibriSpeech", "offsetStart": 175, "offsetEnd": 186}, "context": "We use a hybrid connectionist temporal classification (CTC) and attention based encoder-decoder [20] trained on the converted 460 h training set using the standard recipe for LibriSpeech provided in ESPnet4 .", "mentionContextAttributes": {"used": {"value": true, "score": 0.9969823360443115}, "created": {"value": false, "score": 3.993511199951172e-06}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9969823360443115}, "created": {"value": true, "score": 0.9908990263938904}, "shared": {"value": false, "score": 6.556510925292969e-07}}, "references": [{"label": "[24]", "normalizedForm": "[24]", "refKey": 24}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "VoiceMask", "normalizedForm": "VoiceMask", "offsetStart": 177, "offsetEnd": 186}, "context": "Finally, in the random strategy, each time a user applies VC to an utterance, a random set of parameters is drawn, i.e., a random target speaker is selected and, in the case of VoiceMask, random values are drawn for \u03b1 and \u03b2.", "mentionContextAttributes": {"used": {"value": false, "score": 0.002176344394683838}, "created": {"value": false, "score": 5.441904067993164e-05}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.29853516817092896}, "created": {"value": false, "score": 0.0004851222038269043}, "shared": {"value": false, "score": 1.8477439880371094e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LibriSpeech", "normalizedForm": "LibriSpeech", "offsetStart": 240, "offsetEnd": 251}, "context": "As per the authors' suggestion in the preprocessing script, we train the disentanglement models (speaker encoder, content encoder, decoder) over the trainclean-100 subset of the LibriTTS corpus (itself a subset of the 460 h training set of LibriSpeech), with a batch size of 128 and learning rate of 0.0005 for 500,000 iterations.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9520418047904968}, "created": {"value": false, "score": 5.066394805908203e-06}, "shared": {"value": false, "score": 4.172325134277344e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9969823360443115}, "created": {"value": true, "score": 0.9908990263938904}, "shared": {"value": false, "score": 6.556510925292969e-07}}, "references": [{"label": "[24]", "normalizedForm": "[24]", "refKey": 24}]}], "references": [{"refKey": 24, "tei": "<biblStruct xml:id=\"b24\">\n\t<analytic>\n\t\t<title level=\"a\" type=\"main\">Librispeech: An ASR corpus based on public domain audio books</title>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Vassil</forename><surname>Panayotov</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Guoguo</forename><surname>Chen</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Daniel</forename><surname>Povey</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Sanjeev</forename><surname>Khudanpur</surname></persName>\n\t\t</author>\n\t\t<idno type=\"DOI\">10.1109/icassp.2015.7178964</idno>\n\t</analytic>\n\t<monogr>\n\t\t<title level=\"m\">2015 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</title>\n\t\t<imprint>\n\t\t\t<publisher>IEEE</publisher>\n\t\t\t<date type=\"published\" when=\"2015-04\">2015</date>\n\t\t\t<biblScope unit=\"page\">5210</biblScope>\n\t\t</imprint>\n\t</monogr>\n</biblStruct>\n"}], "runtime": 64822, "id": "e3b4b9dff176a5d342aabb187027c71ab36a58b0", "metadata": {"id": "e3b4b9dff176a5d342aabb187027c71ab36a58b0"}, "original_file_path": "../../datalake/Samuel/SOFTware-Sync/data/xml_not_sofctied/hal-02355115.grobid.tei.xml", "file_name": "hal-02355115.grobid.tei.xml"}