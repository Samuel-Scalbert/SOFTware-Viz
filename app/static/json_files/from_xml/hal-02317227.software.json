{"application": "software-mentions", "version": "0.8.0", "date": "2024-04-12T17:26+0000", "md5": "BA48C1D2CEB20983FEB63E3A19C08FB5", "mentions": [{"type": "software", "software-type": "software", "software-name": {"rawForm": "Word", "normalizedForm": "Word", "offsetStart": 4, "offsetEnd": 8}, "context": "The Word2vec algorithm is coded also in Python and is a part of the gensim package.", "mentionContextAttributes": {"used": {"value": false, "score": 0.008877336978912354}, "created": {"value": false, "score": 0.003138303756713867}, "shared": {"value": false, "score": 5.364418029785156e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999906420707703}, "created": {"value": false, "score": 0.25546520948410034}, "shared": {"value": false, "score": 5.304813385009766e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Word", "normalizedForm": "Word", "offsetStart": 4, "offsetEnd": 8}, "context": "The Word2vec algorithm [28] can be described as follows: The first phase of Word2vec is to associate each word w of the prepared data with a randomly initialised vector denoted by v w \u2208 R n .", "mentionContextAttributes": {"used": {"value": false, "score": 0.014530062675476074}, "created": {"value": false, "score": 2.3186206817626953e-05}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999906420707703}, "created": {"value": false, "score": 0.25546520948410034}, "shared": {"value": false, "score": 5.304813385009766e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Word", "normalizedForm": "Word", "offsetStart": 11, "offsetEnd": 15}, "context": "We use the Word2vec which is a popular algorithm to learn word embeddings using a shallow neural network.", "mentionContextAttributes": {"used": {"value": true, "score": 0.97393399477005}, "created": {"value": false, "score": 0.026214003562927246}, "shared": {"value": false, "score": 5.364418029785156e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999906420707703}, "created": {"value": false, "score": 0.25546520948410034}, "shared": {"value": false, "score": 5.304813385009766e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Word", "normalizedForm": "Word", "offsetStart": 13, "offsetEnd": 17}, "context": "Indeed, this Word2vec is able to model and provide the relationship between predictive variables (input words) and a target variable (the target ontological terms).", "mentionContextAttributes": {"used": {"value": false, "score": 7.361173629760742e-05}, "created": {"value": false, "score": 0.03353220224380493}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999906420707703}, "created": {"value": false, "score": 0.25546520948410034}, "shared": {"value": false, "score": 5.304813385009766e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Owlready", "normalizedForm": "Owlready", "offsetStart": 16, "offsetEnd": 24}, "context": "These packages, Owlready and Pythonskos, provide a large variety of methods for treating ontologies, in particular for the insertion of instances in the ontology.", "mentionContextAttributes": {"used": {"value": false, "score": 3.0338764190673828e-05}, "created": {"value": false, "score": 0.07774108648300171}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 3.0338764190673828e-05}, "created": {"value": false, "score": 0.07774108648300171}, "shared": {"value": false, "score": 2.980232238769531e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Python", "normalizedForm": "Python", "offsetStart": 24, "offsetEnd": 30}, "context": "To do this, we used the Python open source Gensim5 library for the implementation of the Word2vec algorithm.", "mentionContextAttributes": {"used": {"value": true, "score": 0.996141791343689}, "created": {"value": false, "score": 0.25546520948410034}, "shared": {"value": false, "score": 5.304813385009766e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.996141791343689}, "created": {"value": false, "score": 0.25546520948410034}, "shared": {"value": false, "score": 5.304813385009766e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "gensim", "normalizedForm": "gensim", "offsetStart": 25, "offsetEnd": 31}, "context": "https://radimrehurek.com/gensim/about.html", "mentionContextAttributes": {"used": {"value": false, "score": 0.00019478797912597656}, "created": {"value": false, "score": 1.5914440155029297e-05}, "shared": {"value": true, "score": 0.9718983769416809}}, "documentContextAttributes": {"used": {"value": false, "score": 0.008877336978912354}, "created": {"value": false, "score": 0.003138303756713867}, "shared": {"value": true, "score": 0.9718983769416809}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Pythonskos", "normalizedForm": "Pythonskos", "offsetStart": 29, "offsetEnd": 39}, "context": "These packages, Owlready and Pythonskos, provide a large variety of methods for treating ontologies, in particular for the insertion of instances in the ontology.", "mentionContextAttributes": {"used": {"value": false, "score": 3.0338764190673828e-05}, "created": {"value": false, "score": 0.07774108648300171}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 3.0338764190673828e-05}, "created": {"value": false, "score": 0.07774108648300171}, "shared": {"value": false, "score": 2.980232238769531e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Python", "normalizedForm": "Python", "offsetStart": 40, "offsetEnd": 46}, "context": "The Word2vec algorithm is coded also in Python and is a part of the gensim package.", "mentionContextAttributes": {"used": {"value": false, "score": 0.008877336978912354}, "created": {"value": false, "score": 0.003138303756713867}, "shared": {"value": false, "score": 5.364418029785156e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.996141791343689}, "created": {"value": false, "score": 0.25546520948410034}, "shared": {"value": false, "score": 5.304813385009766e-06}}}, {"type": "software", "software-type": "environment", "software-name": {"rawForm": "Python", "normalizedForm": "Python", "offsetStart": 41, "offsetEnd": 47}, "context": "The proposed approach was implemented in Python using the Natural Language Toolkit 7 (NLTK), and the Pandas, Mat plotlib, Seaborn and Numpy packages for performing the preprocessing and NLP tasks. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.028182506561279297}, "created": {"value": false, "score": 0.2090715765953064}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.996141791343689}, "created": {"value": false, "score": 0.25546520948410034}, "shared": {"value": false, "score": 5.304813385009766e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Gensim", "normalizedForm": "Gensim", "offsetStart": 43, "offsetEnd": 50}, "context": "To do this, we used the Python open source Gensim5 library for the implementation of the Word2vec algorithm. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.996141791343689}, "created": {"value": false, "score": 0.25546520948410034}, "shared": {"value": false, "score": 5.304813385009766e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.996141791343689}, "created": {"value": false, "score": 0.25546520948410034}, "shared": {"value": false, "score": 5.304813385009766e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Natural Language Toolkit", "normalizedForm": "Natural Language Toolkit", "offsetStart": 58, "offsetEnd": 82}, "version": {"rawForm": "7", "normalizedForm": "7", "offsetStart": 83, "offsetEnd": 84}, "publisher": {"rawForm": "NLTK", "normalizedForm": "NLTK", "offsetStart": 86, "offsetEnd": 90}, "context": "The proposed approach was implemented in Python using the Natural Language Toolkit 7 (NLTK), and the Pandas, Mat plotlib, Seaborn and Numpy packages for performing the preprocessing and NLP tasks. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.028182506561279297}, "created": {"value": false, "score": 0.2090715765953064}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.028182506561279297}, "created": {"value": false, "score": 0.2090715765953064}, "shared": {"value": false, "score": 1.7881393432617188e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Word", "normalizedForm": "Word", "offsetStart": 60, "offsetEnd": 64}, "context": "The candidate words embedding are obtained with the trained Word2vec algorithm are compared with the concept classes and properties of the BNO ontology.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999906420707703}, "created": {"value": false, "score": 8.165836334228516e-06}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999906420707703}, "created": {"value": false, "score": 0.25546520948410034}, "shared": {"value": false, "score": 5.304813385009766e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "gensim", "normalizedForm": "gensim", "offsetStart": 68, "offsetEnd": 74}, "context": "The Word2vec algorithm is coded also in Python and is a part of the gensim package.", "mentionContextAttributes": {"used": {"value": false, "score": 0.008877336978912354}, "created": {"value": false, "score": 0.003138303756713867}, "shared": {"value": false, "score": 5.364418029785156e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.008877336978912354}, "created": {"value": false, "score": 0.003138303756713867}, "shared": {"value": true, "score": 0.9718983769416809}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Word", "normalizedForm": "Word", "offsetStart": 76, "offsetEnd": 80}, "context": "The Word2vec algorithm [28] can be described as follows: The first phase of Word2vec is to associate each word w of the prepared data with a randomly initialised vector denoted by v w \u2208 R n .", "mentionContextAttributes": {"used": {"value": false, "score": 0.014530062675476074}, "created": {"value": false, "score": 2.3186206817626953e-05}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999906420707703}, "created": {"value": false, "score": 0.25546520948410034}, "shared": {"value": false, "score": 5.304813385009766e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Word", "normalizedForm": "Word", "offsetStart": 89, "offsetEnd": 93}, "context": "To do this, we used the Python open source Gensim5 library for the implementation of the Word2vec algorithm.", "mentionContextAttributes": {"used": {"value": true, "score": 0.996141791343689}, "created": {"value": false, "score": 0.25546520948410034}, "shared": {"value": false, "score": 5.304813385009766e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999906420707703}, "created": {"value": false, "score": 0.25546520948410034}, "shared": {"value": false, "score": 5.304813385009766e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Word", "normalizedForm": "Word", "offsetStart": 94, "offsetEnd": 98}, "context": "In other words, the seed concepts of the BNO ontology are used to organise the results of the Word2vec algorithm.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9032542705535889}, "created": {"value": false, "score": 0.0016344189643859863}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999906420707703}, "created": {"value": false, "score": 0.25546520948410034}, "shared": {"value": false, "score": 5.304813385009766e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Pandas", "normalizedForm": "Pandas", "offsetStart": 101, "offsetEnd": 107}, "context": "The proposed approach was implemented in Python using the Natural Language Toolkit 7 (NLTK), and the Pandas, Mat plotlib, Seaborn and Numpy packages for performing the preprocessing and NLP tasks. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.028182506561279297}, "created": {"value": false, "score": 0.20907151699066162}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.028182506561279297}, "created": {"value": false, "score": 0.20907151699066162}, "shared": {"value": false, "score": 1.1920928955078125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Mat plotlib", "normalizedForm": "Mat plotlib", "offsetStart": 109, "offsetEnd": 120}, "context": "The proposed approach was implemented in Python using the Natural Language Toolkit 7 (NLTK), and the Pandas, Mat plotlib, Seaborn and Numpy packages for performing the preprocessing and NLP tasks. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.028182506561279297}, "created": {"value": false, "score": 0.20907151699066162}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.028182506561279297}, "created": {"value": false, "score": 0.20907151699066162}, "shared": {"value": false, "score": 1.1920928955078125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "NLTK", "normalizedForm": "NLTK", "offsetStart": 115, "offsetEnd": 121}, "context": "This task relies on two pre-trained algorithms, the Punkt sentence tokenizer and Penn Treebank word tokenizer from NLTK 2 . ", "mentionContextAttributes": {"used": {"value": false, "score": 0.4141533374786377}, "created": {"value": false, "score": 0.0007661581039428711}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.4141533374786377}, "created": {"value": false, "score": 0.0007661581039428711}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Seaborn", "normalizedForm": "Seaborn", "offsetStart": 122, "offsetEnd": 129}, "context": "The proposed approach was implemented in Python using the Natural Language Toolkit 7 (NLTK), and the Pandas, Mat plotlib, Seaborn and Numpy packages for performing the preprocessing and NLP tasks. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.028182506561279297}, "created": {"value": false, "score": 0.20907151699066162}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.028182506561279297}, "created": {"value": false, "score": 0.20907151699066162}, "shared": {"value": false, "score": 1.1920928955078125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Numpy", "normalizedForm": "Numpy", "offsetStart": 134, "offsetEnd": 139}, "context": "The proposed approach was implemented in Python using the Natural Language Toolkit 7 (NLTK), and the Pandas, Mat plotlib, Seaborn and Numpy packages for performing the preprocessing and NLP tasks. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.028182506561279297}, "created": {"value": false, "score": 0.20907151699066162}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.028182506561279297}, "created": {"value": false, "score": 0.20907151699066162}, "shared": {"value": false, "score": 1.1920928955078125e-07}}}], "references": [], "runtime": 69487, "id": "05419c309b50e99b4ef2ed9bd2030359c5a2baaa", "metadata": {"id": "05419c309b50e99b4ef2ed9bd2030359c5a2baaa"}, "original_file_path": "../../datalake/Samuel/SOFTware-Sync/data/xml_not_sofctied/hal-02317227.grobid.tei.xml", "file_name": "hal-02317227.grobid.tei.xml"}