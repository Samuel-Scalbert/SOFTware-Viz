{"application": "software-mentions", "version": "0.8.0", "date": "2024-04-12T15:53+0000", "md5": "BDF953279E3E728D4A71715B862BB66D", "mentions": [{"type": "software", "software-type": "software", "software-name": {"rawForm": "Phenotrack", "normalizedForm": "Phenotrack", "offsetStart": 0, "offsetEnd": 10}, "version": {"rawForm": "D", "normalizedForm": "D", "offsetStart": 11, "offsetEnd": 12}, "context": "Phenotrack3D requires as input a time-series of 3D reconstructed plants with stem and leaves individually segmented. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.00028145313262939453}, "created": {"value": false, "score": 4.231929779052734e-06}, "shared": {"value": false, "score": 4.172325134277344e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999037384986877}, "created": {"value": true, "score": 0.9999191164970398}, "shared": {"value": false, "score": 4.172325134277344e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Phenomenal", "normalizedForm": "Phenomenal", "offsetStart": 9, "offsetEnd": 19}, "context": "Briefly, Phenomenal estimates a 3D plant volume by applying a space carving algorithm [37] on a regular grid of voxels, so that the projection of the plant volume matches all plant silhouettes of the multi-view image stack. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0015230774879455566}, "created": {"value": false, "score": 1.043081283569336e-05}, "shared": {"value": false, "score": 4.172325134277344e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999945759773254}, "created": {"value": false, "score": 0.027262568473815918}, "shared": {"value": false, "score": 4.172325134277344e-07}}, "references": [{"label": "[16]", "normalizedForm": "[16]", "refKey": 16}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Phenotrack", "normalizedForm": "Phenotrack", "offsetStart": 11, "offsetEnd": 21}, "version": {"rawForm": "3D", "normalizedForm": "3D", "offsetStart": 21, "offsetEnd": 23}, "context": "We propose Phenotrack3D, a pipeline that allows reconstructing, from time-inconsistent segmentations, the 3D architectural development of a maize plant at organ level, from emergence to flowering. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.00016498565673828125}, "created": {"value": true, "score": 0.9999191164970398}, "shared": {"value": false, "score": 4.172325134277344e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999037384986877}, "created": {"value": true, "score": 0.9999191164970398}, "shared": {"value": false, "score": 4.172325134277344e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Phenotrack", "normalizedForm": "Phenotrack", "offsetStart": 15, "offsetEnd": 25}, "version": {"rawForm": "D", "normalizedForm": "D"}, "context": "In this study, Phenotrack3D was tested on dense (average frequency of 24 h), high quality 3D acquisition (isolated plants to avoid occlusions), which is typical of image phenotyping in controlled conditions.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999037384986877}, "created": {"value": false, "score": 1.4483928680419922e-05}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999037384986877}, "created": {"value": true, "score": 0.9999191164970398}, "shared": {"value": false, "score": 4.172325134277344e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Phenomenal", "normalizedForm": "Phenomenal", "offsetStart": 23, "offsetEnd": 38}, "context": "In our study, we apply Phenomenal [16] on single time-point data to reconstruct 3D volumes of the plants (Fig. 1C), extract 3D skeletons (Fig. 1D) and 3D segmentations of plant volumes into individual plant organs (stem, leaves) (Fig. 1E). ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9991909861564636}, "created": {"value": false, "score": 0.00011116266250610352}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999945759773254}, "created": {"value": false, "score": 0.027262568473815918}, "shared": {"value": false, "score": 4.172325134277344e-07}}, "references": [{"label": "[16]", "normalizedForm": "[16]", "refKey": 16}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Phenomenal", "normalizedForm": "Phenomenal", "offsetStart": 32, "offsetEnd": 42}, "context": "Among the existing methods, the Phenomenal pipeline [16] proved relevant to process large datasets of multiple species of agronomic interest, providing an endto-end solution to extract a 3D plant reconstruction from a set of 2D images taken at regular viewpoints around the plant.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00027489662170410156}, "created": {"value": false, "score": 0.027262568473815918}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999945759773254}, "created": {"value": false, "score": 0.027262568473815918}, "shared": {"value": false, "score": 4.172325134277344e-07}}, "references": [{"label": "[16]", "normalizedForm": "[16]", "refKey": 16, "offsetStart": 3932, "offsetEnd": 3936}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Phenotrack", "normalizedForm": "Phenotrack", "offsetStart": 44, "offsetEnd": 54}, "version": {"rawForm": "D", "normalizedForm": "D"}, "context": "This type of data is the primary target for Phenotrack3D and only minor adaptations in data preparation are expected to allow re-using our method in such conditions.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00015091896057128906}, "created": {"value": false, "score": 0.001035451889038086}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999037384986877}, "created": {"value": true, "score": 0.9999191164970398}, "shared": {"value": false, "score": 4.172325134277344e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Phenomenal", "normalizedForm": "Phenomenal", "offsetStart": 45, "offsetEnd": 55}, "context": "To that end, 2D binary images extracted with Phenomenal were also skeletonized, and the segments of both skeletons were matched to find an extension path for each segment of the original 3D skeleton.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999478459358215}, "created": {"value": false, "score": 1.245737075805664e-05}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999945759773254}, "created": {"value": false, "score": 0.027262568473815918}, "shared": {"value": false, "score": 4.172325134277344e-07}}, "references": [{"label": "[16]", "normalizedForm": "[16]", "refKey": 16}]}, {"type": "software", "software-type": "software", "wikidataId": "Q364", "wikipediaExternalRef": 18545292, "lang": "en", "confidence": 0.5963, "software-name": {"rawForm": "Github", "normalizedForm": "Github", "wikidataId": "Q364", "wikipediaExternalRef": 18545292, "lang": "en", "confidence": 0.5963, "offsetStart": 46, "offsetEnd": 52}, "url": {"rawForm": "https:// github. com/ opena lea/ pheno track 3d", "normalizedForm": "https:// github. com/ opena lea/ pheno track 3d", "offsetStart": 54, "offsetEnd": 101}, "context": "The source code and examples are available on Github (https:// github. com/ opena lea/ pheno track 3d) under an Open Source licence (Cecill-C).", "mentionContextAttributes": {"used": {"value": false, "score": 0.11906623840332031}, "created": {"value": false, "score": 5.59687614440918e-05}, "shared": {"value": true, "score": 0.9784151315689087}}, "documentContextAttributes": {"used": {"value": false, "score": 0.11906623840332031}, "created": {"value": false, "score": 5.59687614440918e-05}, "shared": {"value": true, "score": 0.9784151315689087}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "PhenoArch", "normalizedForm": "PhenoArch", "offsetStart": 68, "offsetEnd": 77}, "context": "We apply this method on a challenging image dataset acquired at the PhenoArch platform consisting of a diverse panel of maize genotypes developing from plant emergence to late flowering stage, under various levels of water stress. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9907224774360657}, "created": {"value": false, "score": 0.08646565675735474}, "shared": {"value": false, "score": 4.172325134277344e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9989383816719055}, "created": {"value": false, "score": 0.08646565675735474}, "shared": {"value": false, "score": 4.172325134277344e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Phenotrack", "normalizedForm": "Phenotrack", "offsetStart": 72, "offsetEnd": 82}, "version": {"rawForm": "D", "normalizedForm": "D"}, "context": "To precisely locate the stem tip, which is of particular importance for Phenotrack3D, we trained an object detection model to detect collars on the 2D images, like in [38].", "mentionContextAttributes": {"used": {"value": true, "score": 0.9998233318328857}, "created": {"value": false, "score": 0.0002675056457519531}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999037384986877}, "created": {"value": true, "score": 0.9999191164970398}, "shared": {"value": false, "score": 4.172325134277344e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "PhenoArch", "normalizedForm": "PhenoArch", "offsetStart": 119, "offsetEnd": 128}, "context": "This pipeline is validated on a challenging dataset of 60 maize hybrids imaged daily from emergence to maturity in the PhenoArch platform (ca.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9989383816719055}, "created": {"value": false, "score": 0.02926170825958252}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9989383816719055}, "created": {"value": false, "score": 0.08646565675735474}, "shared": {"value": false, "score": 4.172325134277344e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Phenomenal", "normalizedForm": "Phenomenal", "offsetStart": 124, "offsetEnd": 138}, "context": "This pipeline is fully automatic and works smoothly with available automatic reconstruction-segmentation pipelines, such as Phenomenal [16]. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.00011259317398071289}, "created": {"value": false, "score": 0.0003693699836730957}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999945759773254}, "created": {"value": false, "score": 0.027262568473815918}, "shared": {"value": false, "score": 4.172325134277344e-07}}, "references": [{"label": "[16]", "normalizedForm": "[16]", "refKey": 16}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "GitHub", "normalizedForm": "GitHub", "offsetStart": 134, "offsetEnd": 140}, "url": {"rawForm": "Phenomenal:", "normalizedForm": "Phenomenal", "offsetStart": 142, "offsetEnd": 153}, "context": "First, organs are segmented on 3D reconstructed volumes at all time steps using a former described method [16], publicly available on GitHub (Phenomenal: https:// github. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.99061119556427}, "created": {"value": false, "score": 0.0003364086151123047}, "shared": {"value": false, "score": 0.14254891872406006}}, "documentContextAttributes": {"used": {"value": true, "score": 0.99061119556427}, "created": {"value": false, "score": 0.0003364086151123047}, "shared": {"value": false, "score": 0.14254891872406006}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Phenomenal", "normalizedForm": "Phenomenal", "offsetStart": 146, "offsetEnd": 156}, "context": "Predictions were twice as accurate as when simply counting the leaves present on the reconstructed plant (Fig. 6B: RMSE = 1.29 vs RMSE = 2.62 for Phenomenal).", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999945759773254}, "created": {"value": false, "score": 7.68899917602539e-06}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999945759773254}, "created": {"value": false, "score": 0.027262568473815918}, "shared": {"value": false, "score": 4.172325134277344e-07}}, "references": [{"label": "[16]", "normalizedForm": "[16]", "refKey": 16}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Phenomenal", "normalizedForm": "Phenomenal", "offsetStart": 155, "offsetEnd": 165}, "context": "Ligulated leaves can be ordered topologically (numbers) by increasing insertion height, unlike growing leaves which all emerge from the same point stages, Phenomenal was complemented with a new stem tip detection method based on deep-learning.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00018286705017089844}, "created": {"value": false, "score": 0.0017600655555725098}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999945759773254}, "created": {"value": false, "score": 0.027262568473815918}, "shared": {"value": false, "score": 4.172325134277344e-07}}, "references": [{"label": "[16]", "normalizedForm": "[16]", "refKey": 16}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Phenomenal", "normalizedForm": "Phenomenal", "offsetStart": 156, "offsetEnd": 166}, "context": "The method tracks the development of each organ from a time-series of plants whose organs have already been segmented in 3D using existing methods, such as Phenomenal [Artzet et al. in BioRxiv 1:805739, 2019]  which was chosen in this study.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0019549131393432617}, "created": {"value": false, "score": 0.0025041699409484863}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999945759773254}, "created": {"value": false, "score": 0.027262568473815918}, "shared": {"value": false, "score": 4.172325134277344e-07}}, "references": [{"label": "[16]", "normalizedForm": "[16]", "refKey": 16}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Phenotrack", "normalizedForm": "Phenotrack", "offsetStart": 192, "offsetEnd": 202}, "version": {"rawForm": "D", "normalizedForm": "D"}, "context": "Some methods using Terrestrial LiDAR Point Cloud were also successful at segmenting organs in field conditions (maize grown at  [54,55], hence producing data that could fit the requirement of Phenotrack3D, despite the lower quality of the segmentation of individual plants.", "mentionContextAttributes": {"used": {"value": false, "score": 0.3862292170524597}, "created": {"value": false, "score": 1.895427703857422e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999037384986877}, "created": {"value": true, "score": 0.9999191164970398}, "shared": {"value": false, "score": 4.172325134277344e-07}}}], "references": [{"refKey": 16, "tei": "<biblStruct xml:id=\"b16\">\n\t<analytic>\n\t\t<title level=\"a\" type=\"main\">&lt;i&gt;Phenomenal&lt;/i&gt;: An automatic open source library for 3D shoot architecture reconstruction and analysis for image-based plant phenotyping</title>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Simon</forename><surname>Artzet</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Tsu-Wei</forename><surname>Chen</surname></persName>\n\t\t\t<idno type=\"ORCID\">0000-0001-6698-563X</idno>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">J\u00e9r\u00f4me</forename><surname>Chopard</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Nicolas</forename><surname>Brichet</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Michael</forename><surname>Mielewczik</surname></persName>\n\t\t\t<idno type=\"ORCID\">0000-0002-3796-4183</idno>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Sarah</forename><surname>Cohen-Boulakia</surname></persName>\n\t\t\t<idno type=\"ORCID\">0000-0002-7439-1441</idno>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Lloren\u00e7</forename><surname>Cabrera-Bosquet</surname></persName>\n\t\t\t<idno type=\"ORCID\">0000-0002-2147-2846</idno>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Fran\u00e7ois</forename><surname>Tardieu</surname></persName>\n\t\t\t<idno type=\"ORCID\">0000-0002-7287-0094</idno>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Christian</forename><surname>Fournier</surname></persName>\n\t\t\t<idno type=\"ORCID\">0000-0001-7098-8278</idno>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Christophe</forename><surname>Pradal</surname></persName>\n\t\t\t<idno type=\"ORCID\">0000-0002-2555-761X</idno>\n\t\t</author>\n\t\t<idno type=\"DOI\">10.1101/805739</idno>\n\t</analytic>\n\t<monogr>\n\t\t<title level=\"j\">BioRxiv</title>\n\t\t<imprint>\n\t\t\t<biblScope unit=\"volume\">1</biblScope>\n\t\t\t<biblScope unit=\"page\">805739</biblScope>\n\t\t\t<date type=\"published\" when=\"2019-10-21\">2019</date>\n\t\t\t<publisher>Cold Spring Harbor Laboratory</publisher>\n\t\t</imprint>\n\t</monogr>\n</biblStruct>\n"}], "runtime": 63724, "id": "ceefe0a98479259a5c11e7fb1db058695b2f25d9", "metadata": {"id": "ceefe0a98479259a5c11e7fb1db058695b2f25d9"}, "original_file_path": "../../datalake/Samuel/SOFTware-Sync/data/xml_files/hal-03890913.grobid.tei.xml", "file_name": "hal-03890913.grobid.tei.xml"}