<?xml version='1.0' encoding='utf-8'?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" version="1.1" xsi:schemaLocation="http://www.tei-c.org/ns/1.0 http://api.archives-ouvertes.fr/documents/aofr-sword.xsd">
  <teiHeader>
    <fileDesc>
      <titleStmt>
        <title>HAL TEI export of hal-03084606</title>
      </titleStmt>
      <publicationStmt>
        <distributor>CCSD</distributor>
        <availability status="restricted">
          <licence target="http://creativecommons.org/licenses/by/4.0/">Distributed under a Creative Commons Attribution 4.0 International License</licence>
        </availability>
        <date when="2024-04-23T23:26:19+02:00" />
      </publicationStmt>
      <sourceDesc>
        <p part="N">HAL API platform</p>
      </sourceDesc>
    </fileDesc>
  </teiHeader>
  <text>
    <body>
      <listBibl>
        <biblFull>
          <titleStmt>
            <title xml:lang="en">Fast and Exact Rule Mining with AMIE 3</title>
            <author role="aut">
              <persName>
                <forename type="first">Jonathan</forename>
                <surname>Lajus</surname>
              </persName>
              <idno type="halauthorid">1307605-0</idno>
              <affiliation ref="#struct-554328" />
              <affiliation ref="#struct-121818" />
              <affiliation ref="#struct-563936" />
            </author>
            <author role="aut">
              <persName>
                <forename type="first">Luis</forename>
                <surname>Galárraga</surname>
              </persName>
              <email type="md5">47b10c913ed0e98db109342faebe61db</email>
              <email type="domain">telecom-paristech.fr</email>
              <idno type="idhal" notation="numeric">1086583</idno>
              <idno type="halauthorid" notation="string">935990-1086583</idno>
              <affiliation ref="#struct-491653" />
            </author>
            <author role="aut">
              <persName>
                <forename type="first">Fabian</forename>
                <surname>Suchanek</surname>
              </persName>
              <email type="md5">ea5bf13de9841dd0a0a6f9e33eb04e13</email>
              <email type="domain">suchanek.name</email>
              <idno type="idhal" notation="string">fabian-suchanek</idno>
              <idno type="idhal" notation="numeric">12540</idno>
              <idno type="halauthorid" notation="string">17276-12540</idno>
              <idno type="IDREF">https://www.idref.fr/203477707</idno>
              <idno type="ORCID">https://orcid.org/0000-0001-7189-2796</idno>
              <idno type="GOOGLE SCHOLAR">djtZhi8AAAAJ</idno>
              <affiliation ref="#struct-554328" />
              <affiliation ref="#struct-121818" />
              <affiliation ref="#struct-563936" />
            </author>
            <editor role="depositor">
              <persName>
                <forename>Luis</forename>
                <surname>Galárraga</surname>
              </persName>
              <email type="md5">2ab89542c7290c9a3428e0e968ba9bcd</email>
              <email type="domain">inria.fr</email>
            </editor>
            <funder ref="#projanr-44439" />
          </titleStmt>
          <editionStmt>
            <edition n="v1" type="current">
              <date type="whenSubmitted">2020-12-21 11:31:48</date>
              <date type="whenModified">2023-10-09 12:49:40</date>
              <date type="whenReleased">2020-12-21 12:17:52</date>
              <date type="whenProduced">2020-05-31</date>
              <date type="whenEndEmbargoed">2020-12-21</date>
              <ref type="file" target="https://inria.hal.science/hal-03084606/document">
                <date notBefore="2020-12-21" />
              </ref>
              <ref type="file" subtype="author" n="1" target="https://inria.hal.science/hal-03084606/file/amie3.pdf">
                <date notBefore="2020-12-21" />
              </ref>
              <ref type="externalLink" target="https://link.springer.com/content/pdf/10.1007%2F978-3-030-49461-2_3.pdf" />
            </edition>
            <respStmt>
              <resp>contributor</resp>
              <name key="329432">
                <persName>
                  <forename>Luis</forename>
                  <surname>Galárraga</surname>
                </persName>
                <email type="md5">2ab89542c7290c9a3428e0e968ba9bcd</email>
                <email type="domain">inria.fr</email>
              </name>
            </respStmt>
          </editionStmt>
          <publicationStmt>
            <distributor>CCSD</distributor>
            <idno type="halId">hal-03084606</idno>
            <idno type="halUri">https://inria.hal.science/hal-03084606</idno>
            <idno type="halBibtex">lajus:hal-03084606</idno>
            <idno type="halRefHtml">&lt;i&gt;ESWC 2020 - 17th International Semantic Web Conference&lt;/i&gt;, May 2020, Virtual Event, Greece. pp.36-52, &lt;a target="_blank" href="https://dx.doi.org/10.1007/978-3-030-49461-2_3"&gt;&amp;#x27E8;10.1007/978-3-030-49461-2_3&amp;#x27E9;&lt;/a&gt;</idno>
            <idno type="halRef">ESWC 2020 - 17th International Semantic Web Conference, May 2020, Virtual Event, Greece. pp.36-52, &amp;#x27E8;10.1007/978-3-030-49461-2_3&amp;#x27E9;</idno>
          </publicationStmt>
          <seriesStmt>
            <idno type="stamp" n="INSTITUT-TELECOM">Institut Mines Télécom</idno>
            <idno type="stamp" n="UNIV-RENNES1">Université de Rennes 1</idno>
            <idno type="stamp" n="CNRS">CNRS - Centre national de la recherche scientifique</idno>
            <idno type="stamp" n="INRIA">INRIA - Institut National de Recherche en Informatique et en Automatique</idno>
            <idno type="stamp" n="UNIV-UBS">Université de Bretagne Sud</idno>
            <idno type="stamp" n="INSA-RENNES">Institut National des Sciences Appliquées de Rennes</idno>
            <idno type="stamp" n="ENST">Ecole Nationale Supérieure des Télécommunications</idno>
            <idno type="stamp" n="INRIA-RENNES">INRIA Rennes - Bretagne Atlantique</idno>
            <idno type="stamp" n="IRISA">Irisa</idno>
            <idno type="stamp" n="TELECOM-PARISTECH" corresp="INSTITUT-TELECOM">Télécom Paris</idno>
            <idno type="stamp" n="IRISA_SET">IRISA_SET</idno>
            <idno type="stamp" n="INRIA_TEST">INRIA - Institut National de Recherche en Informatique et en Automatique</idno>
            <idno type="stamp" n="TESTALAIN1">TESTALAIN1</idno>
            <idno type="stamp" n="CENTRALESUPELEC">Ecole CentraleSupélec</idno>
            <idno type="stamp" n="INRIA2">INRIA 2</idno>
            <idno type="stamp" n="UR1-HAL">Publications labos UR1 dans HAL-Rennes 1</idno>
            <idno type="stamp" n="UR1-MATH-STIC">UR1 - publications Maths-STIC</idno>
            <idno type="stamp" n="UR1-UFR-ISTIC">UFR ISTIC Informatique et électronique</idno>
            <idno type="stamp" n="TEST-UR-CSS">TEST Université de Rennes CSS</idno>
            <idno type="stamp" n="UNIV-RENNES">Université de Rennes</idno>
            <idno type="stamp" n="INRIA-RENGRE">INRIA-RENGRE</idno>
            <idno type="stamp" n="LTCI" corresp="TELECOM-PARISTECH">Laboratoire Traitement et Communication de l'Information</idno>
            <idno type="stamp" n="INFRES" corresp="TELECOM-PARISTECH">Département Informatique et Réseaux</idno>
            <idno type="stamp" n="DIG" corresp="TELECOM-PARISTECH">Equipe Data, Intelligence and Graphs</idno>
            <idno type="stamp" n="DSAIDIS" corresp="TELECOM-PARISTECH">Chaire Data Science and Artificial Intelligence for Digitalized Industry and Services</idno>
            <idno type="stamp" n="IP_PARIS">Institut Polytechnique de Paris</idno>
            <idno type="stamp" n="INSTITUTS-TELECOM" corresp="INSTITUT-TELECOM">composantes instituts telecom </idno>
            <idno type="stamp" n="ANR">ANR</idno>
            <idno type="stamp" n="UR1-MATH-NUM">Pôle UnivRennes - Mathématiques - Numérique </idno>
            <idno type="stamp" n="NORDF" corresp="TELECOM-PARISTECH">NoRDF Project</idno>
            <idno type="stamp" n="INRIA_WEB">Inria &amp; web</idno>
          </seriesStmt>
          <notesStmt>
            <note type="audience" n="2">International</note>
            <note type="invited" n="0">No</note>
            <note type="popular" n="0">No</note>
            <note type="peer" n="1">Yes</note>
            <note type="proceedings" n="1">Yes</note>
          </notesStmt>
          <sourceDesc>
            <biblStruct>
              <analytic>
                <title xml:lang="en">Fast and Exact Rule Mining with AMIE 3</title>
                <author role="aut">
                  <persName>
                    <forename type="first">Jonathan</forename>
                    <surname>Lajus</surname>
                  </persName>
                  <idno type="halauthorid">1307605-0</idno>
                  <affiliation ref="#struct-554328" />
                  <affiliation ref="#struct-121818" />
                  <affiliation ref="#struct-563936" />
                </author>
                <author role="aut">
                  <persName>
                    <forename type="first">Luis</forename>
                    <surname>Galárraga</surname>
                  </persName>
                  <email type="md5">47b10c913ed0e98db109342faebe61db</email>
                  <email type="domain">telecom-paristech.fr</email>
                  <idno type="idhal" notation="numeric">1086583</idno>
                  <idno type="halauthorid" notation="string">935990-1086583</idno>
                  <affiliation ref="#struct-491653" />
                </author>
                <author role="aut">
                  <persName>
                    <forename type="first">Fabian</forename>
                    <surname>Suchanek</surname>
                  </persName>
                  <email type="md5">ea5bf13de9841dd0a0a6f9e33eb04e13</email>
                  <email type="domain">suchanek.name</email>
                  <idno type="idhal" notation="string">fabian-suchanek</idno>
                  <idno type="idhal" notation="numeric">12540</idno>
                  <idno type="halauthorid" notation="string">17276-12540</idno>
                  <idno type="IDREF">https://www.idref.fr/203477707</idno>
                  <idno type="ORCID">https://orcid.org/0000-0001-7189-2796</idno>
                  <idno type="GOOGLE SCHOLAR">djtZhi8AAAAJ</idno>
                  <affiliation ref="#struct-554328" />
                  <affiliation ref="#struct-121818" />
                  <affiliation ref="#struct-563936" />
                </author>
              </analytic>
              <monogr>
                <meeting>
                  <title>ESWC 2020 - 17th International Semantic Web Conference</title>
                  <date type="start">2020-05-31</date>
                  <date type="end">2020-06-04</date>
                  <settlement>Virtual Event</settlement>
                  <country key="GR">Greece</country>
                </meeting>
                <imprint>
                  <biblScope unit="pp">36-52</biblScope>
                  <date type="datePub">2020-05-27</date>
                </imprint>
              </monogr>
              <idno type="doi">10.1007/978-3-030-49461-2_3</idno>
            </biblStruct>
          </sourceDesc>
          <profileDesc>
            <langUsage>
              <language ident="en">English</language>
            </langUsage>
            <textClass>
              <classCode scheme="acm" n="I.2">I.: Computing Methodologies/I.2: ARTIFICIAL INTELLIGENCE</classCode>
              <classCode scheme="acm" n="I.2.6.4">I.: Computing Methodologies/I.2: ARTIFICIAL INTELLIGENCE/I.2.6: Learning/I.2.6.4: Knowledge acquisition</classCode>
              <classCode scheme="halDomain" n="info.info-wb">Computer Science [cs]/Web</classCode>
              <classCode scheme="halDomain" n="info.info-ai">Computer Science [cs]/Artificial Intelligence [cs.AI]</classCode>
              <classCode scheme="halTypology" n="COMM">Conference papers</classCode>
              <classCode scheme="halOldTypology" n="COMM">Conference papers</classCode>
              <classCode scheme="halTreeTypology" n="COMM">Conference papers</classCode>
            </textClass>
            <abstract xml:lang="en">
              <p>Given a knowledge base (KB), rule mining finds rules such as "If two people are married, then they live (most likely) in the same place". Due to the exponential search space, rule mining approaches still have difficulties to scale to today's large KBs. In this paper, we present AMIE 3, a system that employs a number of sophisticated pruning strategies and optimizations. This allows the system to mine rules on large KBs in a matter of minutes. Most importantly, we do not have to resort to approximations or sampling, but are able to compute the exact confidence and support of each rule. Our experiments on DBpedia, YAGO, and Wikidata show that AMIE 3 beats the state of the art by a factor of more than 15 in terms of runtime.</p>
            </abstract>
            <particDesc>
              <org type="consortium">NoRDF DSAIDIS</org>
            </particDesc>
          </profileDesc>
        </biblFull>
      </listBibl>
    </body>
    <back>
      <listOrg type="structures">
        <org type="researchteam" xml:id="struct-554328" status="VALID">
          <orgName>Data, Intelligence and Graphs</orgName>
          <orgName type="acronym">DIG</orgName>
          <date type="start">2019-02-21</date>
          <desc>
            <address>
              <addrLine>Télécom Paris 19 Place Marguerite Perey 91120 Palaiseau</addrLine>
              <country key="FR" />
            </address>
            <ref type="url">https://www.telecom-paris.fr/fr/recherche/laboratoires/laboratoire-traitement-et-communication-de-linformation-ltci/les-equipes-de-recherche/data-intelligence-and-graphs-dig</ref>
          </desc>
          <listRelation>
            <relation active="#struct-484335" type="direct" />
            <relation active="#struct-302102" type="indirect" />
            <relation active="#struct-1048346" type="indirect" />
          </listRelation>
        </org>
        <org type="department" xml:id="struct-121818" status="VALID">
          <orgName>Département Informatique et Réseaux</orgName>
          <orgName type="acronym">INFRES</orgName>
          <desc>
            <address>
              <addrLine>46, rue Barrault 75013 Paris</addrLine>
              <country key="FR" />
            </address>
            <ref type="url">https://www.telecom-paris.fr/fr/recherche/laboratoires/laboratoire-traitement-et-communication-de-linformation-ltci/les-departements-denseignement-et-recherche</ref>
          </desc>
          <listRelation>
            <relation active="#struct-300362" type="direct" />
          </listRelation>
        </org>
        <org type="regroupinstitution" xml:id="struct-563936" status="VALID">
          <orgName>Institut Polytechnique de Paris</orgName>
          <orgName type="acronym">IP Paris</orgName>
          <date type="start">2019-06-02</date>
          <desc>
            <address>
              <country key="FR" />
            </address>
            <ref type="url">https://www.ip-paris.fr</ref>
          </desc>
        </org>
        <org type="researchteam" xml:id="struct-491653" status="VALID">
          <idno type="RNSR">201622044W</idno>
          <orgName>Large Scale Collaborative Data Mining</orgName>
          <orgName type="acronym">LACODAM</orgName>
          <desc>
            <address>
              <addrLine>Campus de Beaulieu 35042 Rennes cedex</addrLine>
              <country key="FR" />
            </address>
            <ref type="url">https://www.inria.fr/equipes/lacodam</ref>
          </desc>
          <listRelation>
            <relation active="#struct-419153" type="direct" />
            <relation active="#struct-300009" type="indirect" />
            <relation active="#struct-491231" type="direct" />
            <relation active="#struct-490899" type="indirect" />
            <relation active="#struct-105160" type="indirect" />
            <relation active="#struct-117606" type="indirect" />
            <relation active="#struct-301232" type="indirect" />
            <relation active="#struct-172265" type="indirect" />
            <relation active="#struct-247362" type="indirect" />
            <relation active="#struct-411575" type="indirect" />
            <relation name="UMR6074" active="#struct-441569" type="indirect" />
            <relation active="#struct-481355" type="indirect" />
            <relation active="#struct-302102" type="indirect" />
          </listRelation>
        </org>
        <org type="laboratory" xml:id="struct-484335" status="VALID">
          <idno type="IdRef">162384270</idno>
          <idno type="ISNI">0000 0000 9194 9502</idno>
          <idno type="RNSR">200319327Z</idno>
          <idno type="ROR">https://ror.org/057er4c39</idno>
          <orgName>Laboratoire Traitement et Communication de l'Information</orgName>
          <orgName type="acronym">LTCI</orgName>
          <date type="start">2017-01-01</date>
          <desc>
            <address>
              <addrLine>Télécom Paris 19 Place Marguerite Perey 91120 PALAISEAU</addrLine>
              <country key="FR" />
            </address>
            <ref type="url">https://www.telecom-paris.fr/fr/recherche/laboratoires/laboratoire-traitement-et-communication-de-linformation-ltci</ref>
          </desc>
          <listRelation>
            <relation active="#struct-302102" type="direct" />
            <relation active="#struct-1048346" type="direct" />
          </listRelation>
        </org>
        <org type="regroupinstitution" xml:id="struct-302102" status="VALID">
          <idno type="ROR">https://ror.org/025vp2923</idno>
          <orgName>Institut Mines-Télécom [Paris]</orgName>
          <orgName type="acronym">IMT</orgName>
          <date type="start">2012-03-01</date>
          <desc>
            <address>
              <addrLine>37-39 Rue Dareau, 75014 Paris</addrLine>
              <country key="FR" />
            </address>
            <ref type="url">http://www.mines-telecom.fr/</ref>
          </desc>
        </org>
        <org type="institution" xml:id="struct-1048346" status="VALID">
          <idno type="IdRef">026375273</idno>
          <idno type="ISNI">0000 0001 2108 2779</idno>
          <idno type="ROR">https://ror.org/01naq7912</idno>
          <orgName>Télécom Paris</orgName>
          <date type="start">2019-06-12</date>
          <desc>
            <address>
              <addrLine>19 Place Marguerite Perey 91120 Palaiseau </addrLine>
              <country key="FR" />
            </address>
            <ref type="url">https://www.telecom-paris.fr</ref>
          </desc>
        </org>
        <org type="institution" xml:id="struct-300362" status="VALID">
          <idno type="ROR">https://ror.org/01naq7912</idno>
          <orgName>Télécom ParisTech</orgName>
          <date type="start">2008-01-01</date>
          <date type="end">2019-06-11</date>
          <desc>
            <address>
              <addrLine>46 rue Barrault 75634 Paris Cedex 13</addrLine>
              <country key="FR" />
            </address>
            <ref type="url">https://www.telecom-paris.fr</ref>
          </desc>
        </org>
        <org type="laboratory" xml:id="struct-419153" status="VALID">
          <idno type="RNSR">198018249C</idno>
          <idno type="ROR">https://ror.org/04040yw90</idno>
          <orgName>Inria Rennes – Bretagne Atlantique</orgName>
          <desc>
            <address>
              <addrLine>Campus de beaulieu35042 Rennes cedex</addrLine>
              <country key="FR" />
            </address>
            <ref type="url">http://www.inria.fr/centre/rennes</ref>
          </desc>
          <listRelation>
            <relation active="#struct-300009" type="direct" />
          </listRelation>
        </org>
        <org type="institution" xml:id="struct-300009" status="VALID">
          <idno type="ROR">https://ror.org/02kvxyf05</idno>
          <orgName>Institut National de Recherche en Informatique et en Automatique</orgName>
          <orgName type="acronym">Inria</orgName>
          <desc>
            <address>
              <addrLine>Domaine de VoluceauRocquencourt - BP 10578153 Le Chesnay Cedex</addrLine>
              <country key="FR" />
            </address>
            <ref type="url">http://www.inria.fr/en/</ref>
          </desc>
        </org>
        <org type="department" xml:id="struct-491231" status="VALID">
          <orgName>GESTION DES DONNÉES ET DE LA CONNAISSANCE</orgName>
          <orgName type="acronym">IRISA-D7</orgName>
          <desc>
            <address>
              <country key="FR" />
            </address>
            <ref type="url">https://www.irisa.fr/fr/departements/d7-gestion-donnees-connaissance</ref>
          </desc>
          <listRelation>
            <relation active="#struct-490899" type="direct" />
            <relation active="#struct-105160" type="indirect" />
            <relation active="#struct-117606" type="indirect" />
            <relation active="#struct-301232" type="indirect" />
            <relation active="#struct-172265" type="indirect" />
            <relation active="#struct-247362" type="indirect" />
            <relation active="#struct-300009" type="indirect" />
            <relation active="#struct-411575" type="indirect" />
            <relation name="UMR6074" active="#struct-441569" type="indirect" />
            <relation active="#struct-481355" type="indirect" />
            <relation active="#struct-302102" type="indirect" />
          </listRelation>
        </org>
        <org type="laboratory" xml:id="struct-490899" status="VALID">
          <idno type="IdRef">026386909</idno>
          <idno type="ISNI">0000 0001 2298 7270</idno>
          <idno type="RNSR">200012163A</idno>
          <idno type="ROR">https://ror.org/00myn0z94</idno>
          <orgName>Institut de Recherche en Informatique et Systèmes Aléatoires</orgName>
          <orgName type="acronym">IRISA</orgName>
          <date type="start">2017-01-01</date>
          <desc>
            <address>
              <addrLine>Avenue du général LeclercCampus de Beaulieu 35042 RENNES CEDEX</addrLine>
              <country key="FR" />
            </address>
            <ref type="url">http://www.irisa.fr</ref>
          </desc>
          <listRelation>
            <relation active="#struct-105160" type="direct" />
            <relation active="#struct-117606" type="direct" />
            <relation active="#struct-301232" type="indirect" />
            <relation active="#struct-172265" type="direct" />
            <relation active="#struct-247362" type="direct" />
            <relation active="#struct-300009" type="direct" />
            <relation active="#struct-411575" type="direct" />
            <relation name="UMR6074" active="#struct-441569" type="direct" />
            <relation active="#struct-481355" type="direct" />
            <relation active="#struct-302102" type="indirect" />
          </listRelation>
        </org>
        <org type="institution" xml:id="struct-105160" status="VALID">
          <idno type="ROR">https://ror.org/015m7wh34</idno>
          <orgName>Université de Rennes</orgName>
          <orgName type="acronym">UR</orgName>
          <desc>
            <address>
              <addrLine>Campus de Beaulieu, 263 avenue Général Leclerc, CS 74205, 35042 RENNES CEDEX</addrLine>
              <country key="FR" />
            </address>
            <ref type="url">https://www.univ-rennes.fr/</ref>
          </desc>
        </org>
        <org type="institution" xml:id="struct-117606" status="VALID">
          <idno type="ROR">https://ror.org/04xaa4j22</idno>
          <orgName>Institut National des Sciences Appliquées - Rennes</orgName>
          <orgName type="acronym">INSA Rennes</orgName>
          <desc>
            <address>
              <addrLine>20, avenue des Buttes de Coësmes - CS 70839 - 35708 Rennes cedex 7</addrLine>
              <country key="FR" />
            </address>
            <ref type="url">http://www.insa-rennes.fr/</ref>
          </desc>
          <listRelation>
            <relation active="#struct-301232" type="direct" />
          </listRelation>
        </org>
        <org type="regroupinstitution" xml:id="struct-301232" status="VALID">
          <idno type="IdRef">162105150</idno>
          <orgName>Institut National des Sciences Appliquées</orgName>
          <orgName type="acronym">INSA</orgName>
          <desc>
            <address>
              <country key="FR" />
            </address>
          </desc>
        </org>
        <org type="institution" xml:id="struct-172265" status="VALID">
          <idno type="ROR">https://ror.org/04ed7fw48</idno>
          <orgName>Université de Bretagne Sud</orgName>
          <orgName type="acronym">UBS</orgName>
          <desc>
            <address>
              <addrLine>BP 92116 - 56321 Lorient cedex</addrLine>
              <country key="FR" />
            </address>
            <ref type="url">http://www.univ-ubs.fr/</ref>
          </desc>
        </org>
        <org type="institution" xml:id="struct-247362" status="VALID">
          <idno type="ROR">https://ror.org/03rxtdc22</idno>
          <orgName>École normale supérieure - Rennes</orgName>
          <orgName type="acronym">ENS Rennes</orgName>
          <desc>
            <address>
              <addrLine>Campus de Ker Lann - avenue Robert Schuman - 35170 Bruz</addrLine>
              <country key="FR" />
            </address>
            <ref type="url">http://www.ens-rennes.fr</ref>
          </desc>
        </org>
        <org type="institution" xml:id="struct-411575" status="VALID">
          <idno type="IdRef">184443237</idno>
          <idno type="ROR">https://ror.org/019tcpt25</idno>
          <orgName>CentraleSupélec</orgName>
          <desc>
            <address>
              <addrLine>3, rue Joliot Curie,Plateau de Moulon,91192 GIF-SUR-YVETTE Cedex</addrLine>
              <country key="FR" />
            </address>
            <ref type="url">http://www.centralesupelec.fr</ref>
          </desc>
        </org>
        <org type="regroupinstitution" xml:id="struct-441569" status="VALID">
          <idno type="IdRef">02636817X</idno>
          <idno type="ISNI">0000000122597504</idno>
          <idno type="ROR">https://ror.org/02feahw73</idno>
          <orgName>Centre National de la Recherche Scientifique</orgName>
          <orgName type="acronym">CNRS</orgName>
          <date type="start">1939-10-19</date>
          <desc>
            <address>
              <country key="FR" />
            </address>
            <ref type="url">https://www.cnrs.fr/</ref>
          </desc>
        </org>
        <org type="institution" xml:id="struct-481355" status="VALID">
          <idno type="IdRef">202743233</idno>
          <idno type="ROR">https://ror.org/030hj3061</idno>
          <orgName>IMT Atlantique</orgName>
          <orgName type="acronym">IMT Atlantique</orgName>
          <date type="start">2017-01-01</date>
          <desc>
            <address>
              <addrLine>Campus Brest : Technopôle Brest-Iroise CS 8381829238 BREST Cedex 3 -Campus Nantes : 4, rue Alfred Kastler- La chantrerie 44300 NANTES -Campus Rennes :  2 Rue de la Châtaigneraie, 35510 CESSON SEVIGNE</addrLine>
              <country key="FR" />
            </address>
            <ref type="url">https://www.imt-atlantique.fr</ref>
          </desc>
          <listRelation>
            <relation active="#struct-302102" type="direct" />
          </listRelation>
        </org>
      </listOrg>
      <listOrg type="projects">
        <org type="anrProject" xml:id="projanr-44439" status="VALID">
          <idno type="anr">ANR-16-CE23-0007</idno>
          <orgName>DICOS</orgName>
          <desc>Découverte de schémas complexes dans les bases de connaissances</desc>
          <date type="start">2016</date>
        </org>
      </listOrg>
    </back>
  <teiCorpus>
	<teiHeader xml:lang="fr">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Fast and Exact Rule Mining with AMIE 3</title>
			</titleStmt>
			<publicationStmt>
				<publisher />
				<availability status="unknown"><licence /></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Jonathan</forename><surname>Lajus</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Télécom Paris</orgName>
								<orgName type="institution" key="instit2">Institut Polytechnique de Paris</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Luis</forename><surname>Galárraga</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">INRIA Rennes</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Fabian</forename><surname>Suchanek</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Télécom Paris</orgName>
								<orgName type="institution" key="instit2">Institut Polytechnique de Paris</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Fast and Exact Rule Mining with AMIE 3</title>
					</analytic>
					<monogr>
						<imprint>
							<date />
						</imprint>
					</monogr>
					<idno type="MD5">4D524C1826A18EBF4D307E6BED87139E</idno>
					<idno type="DOI">10.1007/978-3-030-49461-2_3</idno>
					<note type="submission">Submitted on 21 Dec 2020</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-04-12T14:44+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid" />
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div><p>come from teaching and research institutions in France or abroad, or from public or private research centers. L'archive ouverte pluridisciplinaire HAL, est destinée au dépôt et à la diffusion de documents scientifiques de niveau recherche, publiés ou non, émanant des établissements d'enseignement et de recherche français ou étrangers, des laboratoires publics ou privés.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="fr">
		<body>
<div><head n="1">Introduction</head><p>Recent years have seen the rise of large knowledge bases (KBs) such as Wikidata, YAGO, DBpedia, and many others. These are large collections of knowledge about the real world in the form of entities (such as organizations, movies, people, and locations) and relations between them (such as wasBornIn, actesIn, etc.). Today's KBs contain millions of entities and facts about them. They find applications in Web search, text analysis, and chat bots.</p><p>Rule mining is the task of automatically finding logical rules in a given KB. For example, a rule mining approach can find that "If X and Y are married, and X lives in Z, then Y also lives in Z". Such rules usually come with confidence scores that express to what degree a rule holds. The rules can serve several purposes: First, they serve to complete the KB. If we do not know the place of residence of a person, we can propose that the person lives where their spouse lives. Second, they can serve to debug the KB. If the spouse of someone lives in a different city, then this can indicate a problem. Finally, rules are useful in downstream applications such as fact prediction <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b17">18]</ref>, data and ontology alignment <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b9">10]</ref>, fact checking <ref type="bibr" target="#b1">[2]</ref>, and error detection <ref type="bibr" target="#b0">[1]</ref>.</p><p>The difficulty in finding such rules lies in the exponential size of the search space: every relation can potentially be combined with every other relation in a rule. This is why early approaches (such as <software ContextAttributes="used">AMIE</software> <ref type="bibr" target="#b7">[8]</ref>) were unable to run on large KBs such as Wikidata in less than a day. Since then, several approaches have resorted to sampling or approximate confidence calculations <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b3">4]</ref>. The more the approach samples, the faster it becomes, but the less accurate the results will be. Another common technique <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b15">16]</ref> (from standard inductive logic programming) is to mine not all rules, but only enough rules to cover the positive examples. This, likewise, speeds up the computation, but does not mine all rules that hold in the KB.</p><p>In this paper, we present <software ContextAttributes="used">AMIE 3</software>, a successor of <software ContextAttributes="used">AMIE</software> <ref type="bibr" target="#b7">[8]</ref> and <software ContextAttributes="used">AMIE+</software> <ref type="bibr" target="#b8">[9]</ref>. Our system employs a number of sophisticated strategies to speed up rule mining: pruning strategies, parallelization, and a lazy computation of confidence scores. This allows our system to scale effortlessly to large KBs. At the same time, the system still computes the exact confidence and support values for each rule, without resorting to approximations. Furthermore, unlike her predecessor <ref type="bibr" target="#b8">[9]</ref> and other systems, <software ContextAttributes="used">AMIE 3</software> exhaustively computes all rules that hold in the KB for a given confidence and support threshold.</p><p>Our experiments show that <software>AMIE 3</software> beats the state of the art by a factor of 15 in terms of runtime. We believe that the techniques that we have discovered can be of use for other systems as well -no matter whether they compute the exhaustive set of rules or not.</p></div>
<div><head n="2">Related Work</head><p>First Generation Rule Mining. Inductive Logic Programming (ILP) is the task of learning rules from positive and negative examples. The first of these systems <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b15">16]</ref> appeared before the rise of large KBs. Hence, they are generally unsuitable for today's KBs for two reasons: (i) they were not designed to scale to millions of facts, and (ii) they do not account for the Open World Assumption (OWA) made by current KBs. For example, FOIL <ref type="bibr" target="#b15">[16]</ref> (as well as its optimized successor <ref type="bibr" target="#b18">[19]</ref>) cannot be applied directly to KBs because it assumes the user can provide explicit counter-examples for the rules. Alas, KBs do not store negative statements. In contrast, WARMR <ref type="bibr" target="#b10">[11]</ref> generates negative evidence by assuming the KB is complete, i.e., by making a closed world assumption (CWA), whereas <ref type="bibr" target="#b12">[13]</ref> uses a positives-only learning function that generates negative evidence from random facts (a similar, but more systematic mechanism is proposed in <ref type="bibr" target="#b14">[15]</ref>). It was shown <ref type="bibr" target="#b7">[8]</ref> that these strategies work less well on KBs than the partial completeness assumption (PCA), which was explicitly designed for KBs. Second Generation Rule Mining. <software ContextAttributes="used">AMIE</software> (and its successor <software ContextAttributes="used">AMIE+</software>) <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b8">9]</ref> was the first approach to explicitly target large KBs. While <software ContextAttributes="used">AMIE</software>+ is at least 3 orders of magnitude faster than the first-generation systems, it can still take hours, even days, to find rules in very large KBs such as Wikidata. On these grounds, more recent approaches <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b14">15]</ref> have proposed new strategies (parallelism, approximations, etc.) to speed up rule mining on the largest KBs. The Ontological Pathfinding method (OP) <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b3">4]</ref> resorts to a highly concurrent architecture based on <software ContextAttributes="used">Spark</software> 3 to calculate the support and the confidence of a set of candidate rules. The candidates are computed by enumerating all conjunctions of atoms that are allowed by the schema. Like <software ContextAttributes="used">AMIE</software>, OP calculates the exact scores of the rules and supports both the CWA and the PCA for the generation of counter-evidence. At the same time, the system supports only path rules of up to 3 atoms. Other types of rules require the user to implement a new mining procedure. We will see in our experiments that <software ContextAttributes="used">AMIE 3</software> is both more general and faster than OP.</p><p>RudiK <ref type="bibr" target="#b14">[15]</ref> is a recent rule mining method that applies the PCA to generate explicit counter-examples that are semantically related. For example, when generating counter-facts for the relation hasChild and a given person x, RudiK will sample among the non-children of x who are children of someone else (x = x). Rudik's strategy is to find all rules that are necessary to predict the positive examples, based on a greedy heuristic that at each step adds the most promising rule (in terms of coverage of the examples) to the output set. Thus, differently from exhaustive rule mining approaches <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b10">11]</ref>, Rudik aims to find rules that make good predictions, not all rules above a given confidence threshold. This non-exhaustivity endows RudiK with comparable performance to <software ContextAttributes="used">AMIE</software>+ and OP. Nevertheless, we show that <software ContextAttributes="used">AMIE</software> 3 outperforms RudiK in terms of runtime while still being exhaustive.</p></div>
<div><head n="3">Preliminaries</head><p>Knowledge Bases. We assume a set I of entities (such as Paris), a set P of binary relations (such as locatedIn), and a set L of literal values (strings or numbers) <ref type="foot" target="#foot_1">4</ref> . We model a knowledge base (KB) K as a set of assertions r(s, o), also called facts, with a subject s ∈ I, a relation r ∈ P and an object o ∈ I ∪ L. An example of a fact is locatedIn(Paris, France). Whenever K is clear from the context, we write r(s, o) to mean r(s, o) ∈ K.</p><p>Relations &amp; Functions. The inverse of a relation r, denoted r -, is the relation consisting of all the facts of the form r -(o, s) such that r(s, o) ∈ K. A relation r is a function in K, if r has at most one object for each subject. Some relations (e.g., isCitizenOf ) are quasi-functions, i.e. they rarely associate multiple objects to a given subject. Hence, the notion of functions has been generalized to the functionality score <ref type="bibr" target="#b16">[17]</ref> of a relation r:</p><formula xml:id="formula_0">fun(r) = |{s : ∃o : r(s, o) ∈ K}| |{(s, o) : r(s, o) ∈ K}|<label>(1)</label></formula><p>The functionality score is always between 0 and 1 (incl.). It is exactly 1 for strict functions such as hasBirthPlace, it is close to 1 for quasi-functions, and it is smaller for relations that have many objects (such as actedInMovie).</p><p>Atoms and Rules. An atom is an expression of the form r(X, Y ), where r is a relation and X, Y are either constants or variables. From now on, we denote variables by lowercase letters, whereas constants (entities) are always capitalized. An atom is instantiated if at least one of its arguments is a constant, as in livesIn(x, Berlin). If both arguments are constants, the atom is grounded and it is tantamount to a fact. We define the operator var (A) so that it returns the set of variables of an atom A. A (conjunctive) query is a conjunction of atoms: B 1 ∧ ... ∧ B n . A substitution σ is a partial mapping from variables to constants. Substitutions can be straightforwardly extended to atoms and conjunctions. A result of a query B 1 ∧ ... ∧ B n on a KB K is a substitution σ that (i) maps all variables and (ii) that entails σ(B i ) ∈ K ∀i ∈ {1, ..., n}. A (Horn) rule is a formula of the form B ⇒ H, where the B is a query of body atoms B 1 , ..., B n , and H is the head atom. Two atoms A, A are connected if var (A)∩var (A ) = ∅, i.e., they have common variables. It is common <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b14">15]</ref> to impose that all atoms in a rule are transitively connected and that rules are closed. A rule is closed if all variables appear in at least two atoms. A closed rule is always safe, i.e. all head variables appear also in at least one body atom. Predictions. Given a rule R = B 1 ∧ ... ∧ B n ⇒ H and a substitution σ, we call σ(R) an instantiation of R. If σ(B i ) ∈ K ∀i ∈ {1, ..., n}, we call σ(H) a prediction of R from K, and we write K ∧ R |= σ(H). If σ(H) ∈ K, we call σ(H) a true prediction.</p><p>A false prediction of a rule is a prediction of a counter-example of the rule. There are different approaches to define these counter-examples: Under the Closed World Assumption (CWA), any assertion that is not in the KB is considered a counter-example. However, KBs are usually incomplete, and thus the CWA penalizes rules that predict new facts. Under the Open World Assumption (OWA), facts that are not in the KB are not necessarily wrong, and hence there are no counter-examples. This entails that a rule mining algorithm will report arbitrary rules as long as these rules make enough true predictions (such as "All people play the violin"). Therefore, <software ContextAttributes="used">AMIE</software> <ref type="bibr" target="#b7">[8]</ref> has proposed the Partial Completeness Assumption (PCA): If we have r(s, o) in the KB K, and if fun(r) ≥ fun(r -), then we assume that all r(s, o') ∈ K do not hold in the real world. If fun(r) &lt; fun(r -), then the PCA says that all r(s', o) ∈ K do not hold in the real world. These assertions can thus serve as counter-examples. There are a number of other approaches to generate counter-examples in the literature <ref type="bibr" target="#b17">[18]</ref>. Support and Confidence. The support of a rule R in a KB K is the number of true predictions p (of the form r(X, Y )) that the rule makes in the KB:</p><formula xml:id="formula_1">support(R) = |{p : (K ∧ R |= p) ∧ p ∈ K}|<label>(2)</label></formula><p>The head-coverage is the proportional variant of the support: It is the ratio of instantiations of the head atom that are predicted by the rule:</p><formula xml:id="formula_2">hc(B ⇒ r(x, y)) = support(B ⇒ r(x, y)) |{(x, y) : r(x, y) ∈ K}|</formula><p>The confidence of a rule R in a KB K is the proportion of true predictions out of the true predictions and false predictions:</p><formula xml:id="formula_3">confidence(R) = support(R) support(R) + |{p : (K ∧ R |= p) ∧ p ∈ cex(R)}|<label>(3)</label></formula><p>Here, cex(R) denotes the set of counter-examples of R. If the counter-examples are chosen by the PCA, we refer to the confidence as the PCA confidence and denote it by pca-conf (analogously for the CWA).</p><p>In general, the support of the rule quantifies its relevance, whereas the confidence quantifies its accuracy. Rule mining is the task of finding all rules in a KB that fulfill certain confidence and support thresholds. It is a relaxation of inductive logic programming (ILP), in the sense that it finds also rules that predict some limited number of counter-examples (see <ref type="bibr" target="#b17">[18]</ref> for a discussion).</p></div>
<div><head n="4">AMIE 3</head><p>In this section, we first recap the original <software ContextAttributes="used">AMIE</software> algorithm <ref type="bibr" target="#b7">[8]</ref> (Section 4.1). Then we present a series of optimizations that give rise to <software ContextAttributes="used">AMIE</software> 3 (Section 4.2). Finally, we show different quality metrics that <software ContextAttributes="used">AMIE</software> 3 can compute (Section 4.3).</p></div>
<div><head n="4.1">The AMIE Approach</head><p>The <software ContextAttributes="used">AMIE</software> algorithm <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b8">9]</ref> is a method to mine closed Horn rules on large KBs. AMIE (Algorithm 1) takes as input a knowledge base K, and thresholds l for the maximal number of atoms per rule, minHC for the minimum head coverage, and minC for the minimum PCA confidence. <software ContextAttributes="used">AMIE</software> uses a classical breadth-first search: Line 1 initializes a queue with all possible rules of size 1, i.e., rules with an empty body. The search strategy then dequeues a rule R at a time and adds it to the output list (Line 6) if it meets certain criteria (Line 5), namely, (i) the rule is closed, (ii) its PCA confidence is higher than minC, and (iii) its PCA confidence is higher than the confidence of all previously mined rules with the same head atom as R and a subset of its body atoms. If the rule R has less than l atoms and its confidence can still be improved (Line 7), <software ContextAttributes="used">AMIE</software> refines it. The refinement operator refine (Line 8) derives new rules from R by considering all possible atoms that can be added to the body of the rule, and creating one new rule for each of them.</p><p><software ContextAttributes="used">AMIE</software> iterates over all the non-duplicate refinements of rule R and adds those with enough head coverage (Lines 10-11). The routine finishes when the queue runs out of rules. The <software ContextAttributes="used">AMIE</software> algorithm has been implemented in Java with multi-threading. By default, <software ContextAttributes="used">AMIE</software> sets minHC=0.01, minC=0.1, and l = 3. <software ContextAttributes="used">AMIE</software>+ <ref type="bibr" target="#b8">[9]</ref> optimized this algorithm by a number of pruning strategies, but did not change the main procedure.</p></div>
<div><head n="4.2">AMIE 3</head><p>We now present the optimizations of Algorithm 1 that constitute AMIE 3, the successor of <software>AMIE</software>+.</p><p>Existential Variable Detection. In order to decide whether to output a rule, <software>AMIE</software> has to compute its confidence (Lines 5 and 7 of Algorithm 1), i.e., it has to evaluate Equation 3. If the PCA confidence is used, this equation becomes:</p><formula xml:id="formula_4">pca-conf(B ⇒ r(x, y)) = support(B ⇒ r(x, y)) |{(x, y) : ∃y : B ∧ r(x, y )}| . (<label>4</label></formula><formula xml:id="formula_5">)</formula><p>Algorithm 1: <software>AMIE</software> Input: a KB: K, maximum rule length: l, head coverage threshold: minHC , confidence threshold: minC Output: set of Horn rules: rules</p><formula xml:id="formula_6">1 q = [ ⇒ r1(x, y), ⇒ r2(x, y) . . . ⇒ rm(x, y)] 2 rules = 3 while |q| &gt; 0 do 4 R = q.dequeue() 5 if closed (R) ∧ pca-conf(R) ≥ minC ∧ betterThanParents(R, rules) then 6 rules.add (r) 7 if length(R) &lt; l ∧ pca-conf(Rc) &lt; 1.0 then 8 for each rule Rc ∈ refine(R) do 9 if hc(Rc) ≥ minHC ∧ Rc / ∈ q then 10 q.enqueue(rc)</formula><p>11 return rules This is for the case where fun(r) ≥ fun(r -). If fun(r) &lt; fun(r -), the denominator becomes |{(x, y) : ∃x : B ∧ r(x , y)}|. To evaluate this denominator, <software ContextAttributes="used">AMIE</software> first finds every possible value of x. This is the purpose of Algorithm 2: We find the most restrictive atom in the query, i.e., the atom A * with the relation with the least number of facts. If x appears in this atom, we select the possible instantiation of x in the atom for which the rest of the query is satisfiable (Lines 3 and 4). Otherwise, we recursively find the values of x for each instantiation of this most restrictive atom and add them to the result set X . Once <software ContextAttributes="used">AMIE</software> has found the set of possible values for x with Algorithm 2, it determines, for each value of x, the possible values of y -again by Algorithm 2. This is necessary because we cannot keep in memory all values of y encountered when we computed the values of x, because this would lead to a quadratic memory consumption. This method can be improved as follows: Assume that our rule is simply r 1 (x, z) ∧ r 2 (z, y) ⇒ r h (x, y). Then <software ContextAttributes="used">AMIE</software> will compute the number of distinct pairs (x, y) for the following query (the denominator of Equation <ref type="formula" target="#formula_4">4</ref>):</p><formula xml:id="formula_7">r 1 (x, z) ∧ r 2 (z, y) ∧ r h (x, y )</formula><p><software>AMIE</software> will use Algorithm 2 to select the possible values of x. Assume that the most restrictive atom is r 2 (z, y). Then <software ContextAttributes="used">AMIE</software> will use all possible instantiations σ : {z ← Z, y ← Y } of this atom, and find the possible values of x for the following query (Lines 5 and 6 of Algorithm 2):</p><formula xml:id="formula_8">r 1 (x, Z) ∧ r 2 (Z, Y ) ∧ r h (x, y )<label>(5)</label></formula><p>However, we do not have to try out all possible values of y, because for a fixed instantiation z ← Z all assignments y ← Y lead to the same value for x. Rather, y can be treated as an existential variable: once there is a single Y with r 2 (Z, Y ), we do not need to try out the others. Thus, we can improve Algorithm 2 as Algorithm 2: DistinctValues</p><formula xml:id="formula_9">Input: variable x, query q = A1 ∧ ... ∧ An, KB K, Output: set of values X 1 X := ∅ 2 A * := argmin A (|{(x, y) : A = r(x, y), A ∈ q}|) 3 if x appears in A * then 4 return {x : x ∈ σ(A * ) ∧ σ(q \ A * ) is satisfiable} 5 for each σ : σ(A * ) ∈ K do 6 X := X ∪ DistinctValues(x, σ(q \ A * ), K) 7 return X</formula><p>follows: If a variable y of A * = r(x, y) does not appear elsewhere in q, then Line 5 iterates only over the possible values of x in A * . Lazy Evaluation. The calculation of the denominator of Equation 4 can be computationally expensive, most notably for "bad" rules such as:</p><formula xml:id="formula_10">R : directed (x, z) ∧ hasActor (z, y) ⇒ marriedTo(x, y).<label>(6)</label></formula><p>In such cases, AMIE spends a lot of time computing the exact confidence, only to find that the rule will be pruned away by the confidence threshold. This can be improved as follows: Instead of computing first the set of values for x, and then for each value of x the possible values of y, we compute for each value of x directly the possible values of y -and only then consider the next value of x. Following the principle "If you know something is bad, do not spend time to figure out how bad exactly it is", we stop this computation as soon as the set size reaches the value support(R) × minC -1 . If this occurs, we know that pca-conf(R) &lt; minC , and hence the rule will be pruned in Line 5 of Algorithm 1.</p><p>Variable Order. To compute the PCA confidence (Equation <ref type="formula" target="#formula_4">4</ref>), we have to count the instantiations of pairs of variables x, y. <software ContextAttributes="used">AMIE</software> counts these asymmetrically: It finds the values of x and then, for each value of x, the values of y. We could as well choose to start with y instead. The number of pairs is the same, but we found that the choice impacts the runtime: Once one variable is fixed, the computation of the other variable happens on a rule that has fewer degrees of freedom than the original rule, i.e., it has fewer instantiations. Thus, one has an interest in fixing first the variable that appears in as many selective atoms as possible. Alas, it is very intricate to determine which variable restricts more efficiently the set of instantations, because the variables appear in several atoms, and each instantiation of the first variable may entail a different number of instantiations of the second variable. Therefore, estimating the exact complexity is unpractical. We use the following heuristic: Between x and y, we choose to start with the variable that appears in the head atom of the rule in the denominator of Equation 4. The reason is that this variable appears in at least two atoms already, whereas the other variable appears only in at least one atom. We show in our experiments that this method improves the runtime by several orders of magnitude for some rules.</p><p>Parallel Computation for Overlap Tables. <software ContextAttributes="used">AMIE</software> implements an approximation of Equation <ref type="formula" target="#formula_4">4</ref>. This approximation misses only a small percentage of rules (maximally 5% according to <ref type="bibr" target="#b8">[9]</ref>), but speeds up the calculation drastically. In <software ContextAttributes="used">AMIE</software> 3, this feature can be switched off (to have exact results) or on (to have faster results). Here, we show how to further speed up this heuristic. The method finds an efficient approximation of the denominator of Equation 4 for a rule R, denoted by d(R). <software ContextAttributes="used">AMIE</software> will compute first d(R), and then discard the rule altogether if the approximated PCA confidence, support(R) × d(R) -1 , is smaller than the user threshold minC. For a rule R = r 1 (x, z) ∧ r 2 (z, y) ⇒ r h (x, y), the approximation d(R) is computed as:</p><formula xml:id="formula_11">d(R) := ov (r h , r 1 ) • ov (r - 1 , r 2 ) • fun(r - 2 ) fun(r 1 ) • |dom(r - 1 )| • fun(r 2 )</formula><p>.</p><p>Here, fun(r) is the functionality score of r; dom(r) = {s : r(s, o)} is the domain of r, i.e., the set of distinct subject values of r; and ov (r, r ) = dom(r) ∩ dom(r ) is the overlap between the domains of r and r . The approximation d(R) uses the join structure of the query in combination with the functionality scores and the overlaps to estimate the total number of examples (both positive and negative) of a rule. The expressions fun(r), dom(r), and ov (r, r ) are pre-computed for all relations. This pre-calculation can be significant for large KBs with many predicates. In our experiments with DBpedia, e.g., precomputing ov takes twice as much time as the mining. In <software>AMIE</software> 3, we exploit the fact that this task is easy parallelizable, and start as many threads as possible in parallel, each treating one pair of relations. This reduces the precomputation time linearly with the number of threads (by a factor of 40 in our experiments).</p><p>Integer-based in-memory database. <software ContextAttributes="used">AMIE</software> uses an in-memory database to store the entire KB. Each fact is indexed by subject, by object, by relation, and by pairs of relation/subject and relation/object. In order to be able to load also large KBs into memory, <software ContextAttributes="used">AMIE</software> compresses strings into custom-made ByteStrings, where each character takes only 8 bits. <software ContextAttributes="used">AMIE</software> makes sure that ByteString variables holding equivalent ByteStrings point to the same physical object (i.e., the ByteString exists only once). This not just saves space, but also makes hashing and equality tests trivial. Still, we incur high costs of managing these objects and the indexes: ByteStrings have to be first created, and then checked for duplicity; unused ByteStrings have to be garbage-collected; equality checks still require casting checks; and <software ContextAttributes="used">HashMaps</software> create a large memory overhead. Built-in strings suffer from the same problems. Therefore, we migrated the in-memory database to an integer-based system, where entities and relations are mapped to an integer space and represented by the primitive datatype int. This is in compliance with most RDF engines and popular serialization formats such as <ref type="bibr" target="#b5">[6]</ref>. We use the fastutil library<ref type="foot" target="#foot_2">5</ref> to store the indexes. This avoids the overhead of standard <software ContextAttributes="used">HashMaps</software>. It also reduces the number of objects that the garbage collector has to treat, leading to a significant speedup.</p></div>
<div><head n="4.3">Quality Metrics</head><p><software ContextAttributes="used">AMIE</software> is a generic exhaustive rule miner, and thus its output consists of rules. These rules can serve as input to other applications, for example, to approaches that predict facts <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b14">15]</ref>. Such downstream applications may require different quality metrics. These can be implemented on top of <software ContextAttributes="used">AMIE</software>, as shown here:</p><p>Support &amp; head coverage. Support is a standard quality metric that indicates the significance of a rule. Due to the anti-monotonicity property, most approaches use support to prune the search space of rules. <software ContextAttributes="used">AMIE</software> <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b8">9]</ref> uses by default the head coverage (the relative variant of support) for pruning. PCA Confidence. By default, <software ContextAttributes="used">AMIE</software> uses the PCA confidence to assess the quality of a rule, because it has been shown to rank rules closer to the quality of their predictions than classical metrics such as the CWA confidence <ref type="bibr" target="#b7">[8]</ref>. CWA confidence. This confidence is used in OP <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b3">4]</ref>. Many link prediction methods are evaluated under the closed world assumption as well <ref type="bibr" target="#b17">[18]</ref>. GPRO confidence. The work of <ref type="bibr" target="#b4">[5]</ref> noted that the PCA confidence can underestimate the likelihood of a prediction in the presence of non-injective mappings. Therefore, the authors propose a refinement of the PCA confidence, the GPRO confidence, which excludes instances coming from non-injective mappings in the confidence computation. To judge the quality of a predicted fact, the approach needs the GPRO confidence both on the first and second variable of the head atom. <software ContextAttributes="used">AMIE</software> is not designed to judge the quality of a predicted fact, but can compute the GPRO confidence on both variables. GRANK confidence. This refinement of the GPRO metric is proposed by <ref type="bibr" target="#b4">[5]</ref> in order to take into account the number of instances of the variables of the rule that are not in the head atom.</p><p>These metrics are implemented in <software>AMIE</software> 3 and can be enabled by command line switches.</p></div>
<div><head n="5">Experiments</head><p>We conducted two series of experiments to evaluate <software ContextAttributes="used">AMIE 3</software>: In the first series we study the impact of our optimizations on the system's runtime. In the second series, we compare <software ContextAttributes="used">AMIE 3</software> with two scalable state-of-the-art approaches, namely RudiK <ref type="bibr" target="#b14">[15]</ref> and Ontological Pathfinding (OP) <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b3">4]</ref> (also known as ScaleKB) on 6 different datasets.</p></div>
<div><head n="5.1">Experimental Setup</head><p>Data. We evaluated <software ContextAttributes="used">AMIE 3</software> and its competitors on YAGO (2 and 2s), DBpedia (2.0 and 3.8) and a dump of Wikipedia from December 2014. These datasets were used in evaluations of <software ContextAttributes="used">AMIE+</software> <ref type="bibr" target="#b8">[9]</ref>, OP <ref type="bibr" target="#b2">[3]</ref> and Rudik <ref type="bibr" target="#b14">[15]</ref>. In addition, we used a recent dump of Wikidata from July 1st, 2019 <ref type="foot" target="#foot_3">6</ref> . Table <ref type="table" target="#tab_0">1</ref> shows the numbers of facts, relations, and entities of our experimental datasets.  Unless otherwise noted, the experiments were run using the default settings of <software ContextAttributes="used">AMIE</software>: We used the PCA confidence, computed lazily with a threshold of 0.1, with all the lossless optimizations (no approximations). The threshold on the head coverage is 0.01 and the maximal rule length is 3 <ref type="bibr" target="#b7">[8]</ref>.</p></div>
<div><head n="5.2">Effect of our optimizations</head><p>In-memory database. Table <ref type="table" target="#tab_1">2</ref> shows the performance with the new integerbased in-memory database and the old ByteString database. The change reduces the memory footprint by around 3 GB in most cases, and by 50% in Wikidata. Moreover, the new database is consistently faster, up to 8-fold for the larger KBs such as DBpedia 3.8. Laziness. As explained in Section 4.2, <software ContextAttributes="used">AMIE</software> can invest a lot of time in calculating the PCA confidence of low-confident rules. The lazy evaluation targets exactly this problem. Table <ref type="table" target="#tab_2">3</ref> shows that this strategy can reduce the runtime by a factor of 4. We also show the impact of laziness when the PCA confidence approximation is switched on. We observe that the parallel calculation of the overlap tables reduces drastically the contribution of this phase to the total runtime when compared to <software ContextAttributes="used">AMIE</software>+ -where it could take longer than the mining itself. We also note that the residual impact of the confidence approximation is small, so that this feature is now dispensable: We can mine rules exhaustively.</p><p>Count variable order. To measure the impact of the count variable order, we ran <software ContextAttributes="used">AMIE 3</software> (with the lazy evaluation activated) on Yago2s and looked at the runtimes when counting with the variable that appears in the head atom versus the runtime when counting with the other variable. For every rule with three atoms and a support superior to 100, we timed the computation of the PCA confidence denominator (Equation <ref type="formula" target="#formula_4">4</ref>) in each case. The y-axis of Figure <ref type="figure">1</ref> shows the runtime when we first instantiate the variable that occurs in the head atom, whereas the x-axis shows the runtime when using the other variable.</p><p>We see that every query can be run in under 10 seconds and that most of the queries would run equally fast independently of the order of the variables. However, for some rules, instantiating first the variable that does not appear in the head atom can be worse than the contrary by several orders of magnitude. Some queries would take hours (days in one case) to compute, even with lazy evaluation. In Yago2s, these rules happen to be pruned away by the <software>AMIE</software>+ confidence upper bound (a lossless optimization), but this may not be the case for all KBs. The problematic rules all have bodies of the following shape:</p><formula xml:id="formula_12">hasGender (x, g) ∧ hasGender (y, g) isLocatedIn(x, l) ∧ isLocatedIn(y, l)</formula><p>Both hasGender and <software ContextAttributes="used">isLocatedIn</software> are very large relations as they apply to any person and location, respectively. While early pruning of those "hard rules" is the purpose of the confidence approximations and upper bounds of <software ContextAttributes="used">AMIE</software>+, these strategies may fail in a few cases, leading to the execution of expensive queries. Finally, we show the overall impact of the count variable order heuristic in Table <ref type="table" target="#tab_3">4</ref>. The results suggest that our heuristic generally yields lower runtimes. Impact of existential variable detection. Last but not least, the on-the-fly detection of existential variables reduces the number of recursive calls made to Algorithm 2. Table <ref type="table" target="#tab_4">5a</ref> shows the performances of <software ContextAttributes="used">AMIE 3</software> with and without this Other variable</p></div>
<div><head>Head variable</head><p>Fig. <ref type="figure">1</ref>: Impact of the variable order on Yago2s. Each point is a rule. Cross points: pruned by the confidence approximation. Red line: same performance. Dashed lines: relative speedup of 10×. optimization. This optimization is critical for <software ContextAttributes="used">AMIE</software> 3 on most datasets. This is less important for DBpedia 2.0 as it contains mostly small relations.</p><p>Metrics. Table <ref type="table" target="#tab_4">5b</ref> shows the impact of different quality metrics on the runtime, with iPCA being the PCA with injective mappings. The metrics run slower than the PCA confidence, because we cannot use the PCA upper bound optimization. The GRank metric, in particular, is very sensitive to the number of facts per relation, which explains its performance on Yago2s and DBpedia 3.8. For all other metrics, however, the numbers are very reasonable.</p></div>
<div><head n="5.3">Comparative Experiments</head><p>In this section, we compare the performance of <software>AMIE</software> 3 with two main state-ofthe-art algorithms for rule mining in large KBs, <software ContextAttributes="used">RuDiK</software> and OP. <software ContextAttributes="used">AMIE</software> 3. We ran <software ContextAttributes="used">AMIE 3</software> in its default settings. In order to compare the improvements to previous benchmarks of <software ContextAttributes="used">AMIE</software>, we had <software ContextAttributes="used">AMIE</software> compute the standard CWA confidence for each rule, in addition to the PCA confidence (except for Wikidata 2019, where no such previous benchmark exists).</p><p><software ContextAttributes="used">RuDiK</software>. We set the number of positive and negative examples to 500, as advised on the project's github page <ref type="foot" target="#foot_4">7</ref> . We tried to run the system in parallel for different head relations. However, the graph generation phase of the algorithm already runs in parallel and executes a lot of very selective SPARQL queries in parallel. Hence, the additional parallelization flooded the SPARQL endpoint, which rejected any new connection at some point. For this reason, we mined the rules for every possible relation sequentially, using only the original parallelization mechanism. <software ContextAttributes="used">RuDiK</software> also benefits from information on the taxonomic types of the variables. While the built-in method to detect the types of the relations works out-of-the-box for DBpedia (which has a flat taxonomy), it overgeneralizes on the other datasets, inverting the expected benefits. Therefore, we ran <software ContextAttributes="used">RuDiK</software> without the type information on the other datasets.</p><p>Ontological Pathfinding. This system first builds a list of candidate rules (Part 5.1 of <ref type="bibr" target="#b3">[4]</ref>). Unfortunately, the implementation of this phase of the algorithm is not publicly available. Hence, we had to generate candidate rules ourselves. The goal is to create all rules that are "reasonable", i.e., to avoid rules with empty joins such as birthPlace(x, y) ∧ hasCapital(x, z). The original algorithm discards all rules where the domain and range of joining relations do not match. However, it does not take into account the fact that an entity can be an instance of multiple classes. Thus, if the domain of actedIn is Actor, and the domain of directed is Director, the original algorithm would discard any rule that contains actedIn(x, y) ∧ directed(x, z) -even though it may have a non-empty support. Hence, we generated all candidate rules where the join between two connected atoms is not empty in the KB. This produces more candidate rules than the original algorithm (around 10 times more for Yago2s, i.e., 29762), but in return OP can potentially mine all rules that the other systems mine.</p></div>
<div><head>Results</head><p>It is not easy to compare the performance of OP, <software ContextAttributes="used">AMIE</software> 3, and Rudik, because the systems serve different purposes, have different prerequisites, and mine different rules. Therefore, we ran all systems in their default configurations, and discuss the results (Table <ref type="table" target="#tab_5">6</ref>) qualitatively in detail. Ontological Pathfinding. We ran OP both with a domain-based candidate generation (which finds fewer rules) and with our candidate generation. In general, OP has the longest running times, but the largest number of rules. This is inherent to the approach: OP will prune candidate rules using a heuristic <ref type="bibr" target="#b2">[3]</ref> that is similar to the confidence approximation of <software ContextAttributes="used">AMIE+</software>. After this step, it will compute the support and the exact CWA confidence of any remaining candidate. However, it offers no way of pruning rules upfront by support and confidence. This has two effects: First, the vast majority (&gt; 90%) of rules found by OP have very low confidence (&lt; 10%) or very low support (&lt; 100). Second, most of the time will be spent computing the confidence of these low-confidence rules, because the exact confidence is harder to compute for a rule with low confidence.</p><p>To reproduce the result of OP with <software ContextAttributes="used">AMIE</software>, we ran <software ContextAttributes="used">AMIE 3</software> with a support threshold of 100 and a CWA confidence threshold of 10%. This reproduces the rules of OP (and 8 more because <software ContextAttributes="used">AMIE</software> does not use the OP functionality heuristics) in less than two minutes. If we set our support threshold to 1, and our minimal CWA confidence to 10 -5 , then we mine more rules than OP on Yago2s (as shown in Table <ref type="table" target="#tab_5">6</ref>) in less time (factor 25×). If we mine rules with <software ContextAttributes="used">AMIE</software>'s default parameters, we mine rules in less than two minutes (factor 90×).</p><p>The large search space is even more critical for OP on DBpedia 3.8 and Wikidata 2019, as the number of candidate rules grows cubically with the number of relations. We generated around 9 million candidate rules for DBpedia and around 114 million candidates for Wikidata. In both cases, OP mined all rules of size 2 in 1h 20min (≈ 21k candidates) and 14 hours (≈ 100k candidates) respectively. However, it failed to mine any rule of size 3 in the remaining time. If we set the minimal support again to 1 and the CWA confidence threshold to 10 -5 , <software>AMIE</software> can mine twice as many rules as OP on DBpedia 3.8 in 33 minutes. RuDiK. For <software ContextAttributes="used">RuDiK</software>, we found that the original parallelization mechanism does not scale well to 40 cores. The load average of our system, <software ContextAttributes="used">Virtuoso</software> included, never exceeded 5 cores used. This explains the similar results between our benchmark and <software ContextAttributes="used">RuDiK</software>'s original experiments on Yago2s with fewer cores. On DBpedia, we could run the system also with type information -although this did not impact the runtime significantly. The loss of performance during the execution of the SPARQL queries is more noticeable due to the multitude of small relations in DBpedia compared to Yago. In comparison, <software ContextAttributes="used">AMIE</software> was more than 20× faster on both datasets. This means that, even if <software ContextAttributes="used">RuDiK</software> were to make full use of the 40 cores, and speed up 4-fold, it would still be 5 times slower. <software ContextAttributes="used">AMIE</software> also found more rules than <software ContextAttributes="used">RuDiK</software>. Among these are all rules that <software ContextAttributes="used">RuDiK</software> found, except two (which were clearly wrong rules; one had a confidence of 0.001).</p><p>In our experiment, <software>RuDiK</software> mined rules in Wikidata in 23 hours. However, <software ContextAttributes="used">RuDiK</software> was not able to mine rules for 22 of the relations as <software ContextAttributes="used">Virtuoso</software> was not able to compute any of the positive or the negative examples <software ContextAttributes="used">RuDiK</software> requires to operate. This is because <software ContextAttributes="used">RuDiK</software> would timeout any SPARQL query after 20 seconds of execution 8 . <software ContextAttributes="used">Virtuoso</software> failed to compute the examples during this time frame on the 22 relations, which are the largest ones in our Wikidata dataset: They cover 84% of the facts. Interestingly, <software ContextAttributes="used">RuDiK</software> did also not find rules that contain these relations in the body (except one, which covered 0.5% of the KB).</p><p>In comparison, <software>AMIE</software> mined 1703 rules with at least one of these relations, computing the support, confidence and PCA confidence exactly on these huge relations -in less time. For example, it found the rule inRegion(x, y) ∧ inCountry(y, z) ⇒ inCountry(x, z), which is not considered by <software ContextAttributes="used">RuDiK</software>, but has a support of over 7 million and a PCA confidence of over 99%. <software ContextAttributes="used">AMIE 3</software> outperformed both OP and <software ContextAttributes="used">RuDiK</software> in terms of runtime and the number of rules. Moreover, it has the advantage of being exact and complete. Then again, the comparisons have to be seen in context: <software ContextAttributes="used">RuDiK</software>, e.g., is designed to run on a small machine. For this, it uses a disk-based database and sampling. <software ContextAttributes="used">AMIE</software>, in contrast, loads all data into memory, and thus has a large memory footprint (the 500GB were nearly used up for the Wikidata experiment). In return, it computes all rules exactly and is fast. 8 Increasing the timeout parameter is not necessarily a good solution for two reasons:</p><p>First, we cannot predict the optimal value so that all queries finish. Second, it would increase the runtime of queries succeeding with partial results thanks to <software>Virtuoso</software>'s Anytime Query capability. This would largely increase <software ContextAttributes="used">RuDiK</software>'s runtime with no guarantee to solve the issue.</p></div>
<div><head n="6">Conclusion</head><p>We have presented <software>AMIE</software> 3, the newest version of the rule mining system <software ContextAttributes="created">AMIE</software>.</p><p>The new system uses a range of optimization and pruning strategies, which allow scaling to large KBs that were previously beyond reach. In particular, <software>AMIE 3</software> can exhaustively mine all rules above given thresholds on support and confidence, without resorting to sampling or approximations. We hope that the optimizations and subtleties exposed in this paper can carry over to other types of databases, and potentially other systems. <software ContextAttributes="used">AMIE</software> is openly available at https://github.com/lajus/amie/.</p><p>Acknowledgements. Partially supported by the grant ANR-16-CE23-0007-01.</p></div><figure type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Experimental datasets</figDesc><table><row><cell>Dataset</cell><cell cols="2">Facts Relations</cell><cell>Entities</cell></row><row><cell>Yago2</cell><cell>948 358</cell><cell>36</cell><cell>834 750</cell></row><row><cell>Yago2s</cell><cell>4 484 914</cell><cell>37</cell><cell>2 137 469</cell></row><row><cell>DBpedia 2.0</cell><cell>6 601 014</cell><cell>1 595</cell><cell>2 275 327</cell></row><row><cell>DBpedia 3.8</cell><cell>11 024 066</cell><cell>650</cell><cell>3 102 999</cell></row><row><cell>Wikidata 12-2014</cell><cell>8 397 936</cell><cell>430</cell><cell>3 085 248</cell></row><row><cell cols="2">Wikidata 07-2019 386 156 557</cell><cell cols="2">1 188 57 963 264</cell></row></table></figure>
<figure type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Old ByteString database vs. the new integer-based database.</figDesc><table><row><cell>Dataset</cell><cell>Loading time</cell><cell cols="4">Wall time Integer ByteString Integer ByteString Memory used</cell></row><row><cell>Yago2</cell><cell>7s</cell><cell>26.40s</cell><cell>29.69s</cell><cell>6Go</cell><cell>9Go</cell></row><row><cell>Yago2s</cell><cell cols="2">45s 1min 55s</cell><cell>4min 10s</cell><cell>16Go</cell><cell>19Go</cell></row><row><cell>DBpedia 2.0</cell><cell cols="2">55s 7min 32s</cell><cell>34min 06s</cell><cell>29Go</cell><cell>32Go</cell></row><row><cell>DBpedia 3.8</cell><cell cols="2">1min 20s 7min 49s</cell><cell>52min 10s</cell><cell>40Go</cell><cell>42Go</cell></row><row><cell>Wikidata 2014</cell><cell cols="2">59s 5min 44s</cell><cell>6min 01s</cell><cell>27Go</cell><cell>54Go</cell></row><row><cell cols="6">Configurations. All experiments were run on a Ubuntu 18.04.3 LTS with 40</cell></row><row><cell cols="6">processing cores (Intel Xeon CPU E5-2660 v3 at 2.60GHz) and 500Go of RAM.</cell></row><row><cell cols="6">AMIE 3 and RudiK are implemented in Java 1.8. AMIE 3 uses its own in-</cell></row><row><cell cols="6">memory database to store the KB, whereas RudiK relies on Virtuoso Open</cell></row><row><cell cols="6">Source 06.01.3127, accessed via a local endpoint. OP was implemented in Scala</cell></row><row><cell cols="2">2.11.12 and Spark 2.3.4.</cell><cell /><cell /><cell /><cell /></row></table></figure>
<figure type="table" xml:id="tab_2"><head>Table 3 :</head><label>3</label><figDesc>Impact of laziness and of switching on the confidence approximation. Ov. tables is the time needed to compute the overlap tables.</figDesc><table><row><cell>Dataset</cell><cell cols="2">Conf. Approx. off Non-lazy Lazy</cell><cell cols="3">Confidence Approximation on Non-lazy Lazy Ov. tables</cell></row><row><cell>Yago2</cell><cell>24.12s</cell><cell>26.40s</cell><cell>24.39s</cell><cell>21.41s</cell><cell>0.2s</cell></row><row><cell>Yago2s</cell><cell>4min 28s</cell><cell>1min 55s</cell><cell>1min 42s</cell><cell>2min 03s</cell><cell>2.4s</cell></row><row><cell>DBpedia 2.0</cell><cell>10min 14s</cell><cell>7min 32s</cell><cell>7min 42s</cell><cell>8min 13s</cell><cell>23.5s</cell></row><row><cell>DBpedia 3.8</cell><cell>14min 50s</cell><cell cols="3">7min 49s 11min 07s 10min 18s</cell><cell>15.2s</cell></row><row><cell>Wikidata 2014</cell><cell>19min 27s</cell><cell>5min 44s</cell><cell>5min 45s</cell><cell>4min 36s</cell><cell>12s</cell></row><row><cell>Wikidata 2019</cell><cell cols="4">&gt; 48h 16h 43min 17h 06min 16h 31min</cell><cell>41.4s</cell></row></table></figure>
<figure type="table" xml:id="tab_3"><head>Table 4 :</head><label>4</label><figDesc>Impact of the variable order: variable that appears in the head atom (new AMIE 3 heuristic); variable that does not appear in the head atom; variable that appears first in the head atom of the original rule (old AMIE method).</figDesc><table><row><cell>Dataset</cell><cell>Head</cell><cell cols="2">Non-head Always first</cell></row><row><cell>Yago2</cell><cell>26.40s</cell><cell>25.64s</cell><cell>23.59s</cell></row><row><cell>Yago2s</cell><cell>1min 55s</cell><cell>4min 32s</cell><cell>4min 30s</cell></row><row><cell>DBpedia 2.0</cell><cell>7min 32s</cell><cell>12min 46s</cell><cell>6min 36s</cell></row><row><cell>DBpedia 3.8</cell><cell>7min 49s</cell><cell>21min 12s</cell><cell>8min 53s</cell></row><row><cell>Wikidata 2014</cell><cell>5min 44s</cell><cell>36min 09s</cell><cell>9min 50s</cell></row></table></figure>
<figure type="table" xml:id="tab_4"><head>Table 5 :</head><label>5</label><figDesc>Performance with different features.</figDesc><table><row><cell cols="3">(a) Existential variable detection (ED)</cell><cell cols="4">(b) Different metrics (Section 4.3)</cell></row><row><cell>Dataset</cell><cell>AMIE 3</cell><cell>No ED</cell><cell>CWA</cell><cell>iPCA</cell><cell cols="2">GPro GRank</cell></row><row><cell>Yago2</cell><cell>26.40s</cell><cell>24.84s</cell><cell>22.54s</cell><cell>38.42s</cell><cell>37.47s</cell><cell>33.36s</cell></row><row><cell>Yago2s</cell><cell>1min 55s</cell><cell>&gt; 2h</cell><cell cols="3">1min 56s 3min 30s 2min 45s</cell><cell>&gt; 2h</cell></row><row><cell>DBpedia 2.0</cell><cell>7min 32s</cell><cell>9min 10s</cell><cell cols="4">7min 26s 12min 31s 11min 53s 1h 16min</cell></row><row><cell>DBpedia 3.8</cell><cell>7min 49s</cell><cell>&gt; 2h</cell><cell cols="3">6min 49s 15min 22s 23min 31s</cell><cell>&gt; 2h</cell></row><row><cell>Wikidata 2014</cell><cell>5min 44s</cell><cell>&gt; 2h</cell><cell cols="3">5min 48s 7min 04s 11min 50s</cell><cell>&gt; 2h</cell></row></table></figure>
<figure type="table" xml:id="tab_5"><head>Table 6 :</head><label>6</label><figDesc>Performances and output of Ontological Pathfinding (OP), RuDiK and AMIE 3. *: rules with support ≥ 100 and CWA confidence ≥ 0.1.</figDesc><table><row><cell>Dataset</cell><cell>System</cell><cell>Rules</cell><cell>Runtime</cell></row><row><cell /><cell>OP (their candidates)</cell><cell>429 (52*)</cell><cell>18min 50s</cell></row><row><cell /><cell>OP (our candidates)</cell><cell>1 348 (96*)</cell><cell>3h 20min</cell></row><row><cell>Yago2s</cell><cell>RuDiK</cell><cell>17</cell><cell>37min 30s</cell></row><row><cell /><cell>AMIE 3</cell><cell>97</cell><cell>1min 50s</cell></row><row><cell /><cell>AMIE 3 (support=1)</cell><cell>1 596</cell><cell>7min 6s</cell></row><row><cell /><cell>OP (our candidates)</cell><cell>7 714 (220*)</cell><cell>&gt; 45h</cell></row><row><cell>DBpedia 3.8</cell><cell>RuDiK RuDiK + types</cell><cell>650 650</cell><cell>12h 10min 11h 52min</cell></row><row><cell /><cell>AMIE 3</cell><cell>5 084</cell><cell>7min 52s</cell></row><row><cell /><cell>AMIE 3 (support=1)</cell><cell>132 958</cell><cell>32min 57s</cell></row><row><cell /><cell cols="2">OP (our candidates) 15 999 (326*)</cell><cell>&gt; 48h</cell></row><row><cell>Wikidata 2019</cell><cell>RuDiK</cell><cell>1 145</cell><cell>23h</cell></row><row><cell /><cell>AMIE 3</cell><cell>8 662</cell><cell>16h 43min</cell></row></table></figure>
			<note place="foot" n="3" xml:id="foot_0"><p>https://spark.apache.org</p></note>
			<note place="foot" n="4" xml:id="foot_1"><p>In line with the other works<ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b14">15]</ref>, we do not consider blank nodes.</p></note>
			<note place="foot" n="5" xml:id="foot_2"><p>http://fastutil.di.unimi.it/</p></note>
			<note place="foot" n="6" xml:id="foot_3"><p>Selecting only facts between two Wikidata entities, and excluding literals.</p></note>
			<note place="foot" n="7" xml:id="foot_4"><p>https://github.com/stefano-ortona/rudik</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Mining Expressive Rules in Knowledge Graphs</title>
		<author>
			<persName><forename type="first">N</forename><surname>Ahmadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">P</forename><surname>Huynh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Meduri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ortona</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Papotti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JDIQ</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Explainable Fact Checking with Probabilistic Answer Set Programming</title>
		<author>
			<persName><forename type="first">N</forename><surname>Ahmadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Papotti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Saeed</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference for Truth and Trust online</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Ontological Pathfinding</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Goldberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Johri</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016">2016</date>
			<publisher>SIG-MOD</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">ScaLeKB: Scalable Learning and Inference over Large Knowledge Bases</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Goldberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">VLDB Journal</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">6</biblScope>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Graph Pattern Entity Ranking Model for Knowledge Graph Completion</title>
		<author>
			<persName><forename type="first">T</forename><surname>Ebisu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ichise</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL-HLT</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Binary RDF Representation (HDT)</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Fernández</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Martínez-Prieto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Gutiérrez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Polleres</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Arias</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Web Semantics</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Canonicalizing Open Knowledge Bases</title>
		<author>
			<persName><forename type="first">L</forename><surname>Galárraga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Heitz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Suchanek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIKM</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">AMIE: Association Rule Mining Under Incomplete Evidence in Ontological Knowledge Bases</title>
		<author>
			<persName><forename type="first">L</forename><surname>Galárraga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Teflioudi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Hose</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Suchanek</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013">2013</date>
			<publisher>WWW</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Fast Rule Mining in Ontological Knowledge Bases with AMIE+</title>
		<author>
			<persName><forename type="first">L</forename><surname>Galárraga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Teflioudi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Hose</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">M</forename><surname>Suchanek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">VLDB Journal</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">6</biblScope>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Mining rules to align knowledge bases</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">A</forename><surname>Galárraga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Preda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">M</forename><surname>Suchanek</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013">2013</date>
			<publisher>AKBC</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Relational Association Rules: Getting WARMER</title>
		<author>
			<persName><forename type="first">B</forename><surname>Goethals</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Van Den Bussche</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Detection and Discovery</title>
		<imprint>
			<biblScope unit="volume">2447</biblScope>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Discovering meta-paths in large heterogeneous information networks</title>
		<author>
			<persName><forename type="first">C</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Maniu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Senellart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zhang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015">2015</date>
			<publisher>WWW</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Learning from Positive Data</title>
		<author>
			<persName><forename type="first">S</forename><surname>Muggleton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ILP</title>
		<imprint>
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Tuffy: Scaling up Statistical Inference in Markov Logic Networks using an RDBMS</title>
		<author>
			<persName><forename type="first">F</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Ré</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Doan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Shavlik</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1104.3216</idno>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Robust Discovery of Positive and Negative Rules in Knowledge Bases</title>
		<author>
			<persName><forename type="first">S</forename><surname>Ortona</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">V</forename><surname>Meduri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Papotti</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
			<publisher>ICDE</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Learning Logical Definitions from Relations</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Quinlan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine Learning</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="1990-08">Aug 1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">PARIS: Probabilistic Alignment of Relations, Instances, and Schema</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">M</forename><surname>Suchanek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Abiteboul</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Senellart</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PVLDB</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Knowledge Representation and Rule Mining in Entity-Centric KBs</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">M</forename><surname>Suchanek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lajus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Boschin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Weikum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Reasoning Web Summer School</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">QuickFOIL: Scalable Inductive Logic Programming</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Patel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Page</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">VLDB</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2014-11">Nov 2014</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</teiCorpus></text>
</TEI>