<?xml version='1.0' encoding='utf-8'?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" version="1.1" xsi:schemaLocation="http://www.tei-c.org/ns/1.0 http://api.archives-ouvertes.fr/documents/aofr-sword.xsd">
  <teiHeader>
    <fileDesc>
      <titleStmt>
        <title>HAL TEI export of hal-03793389</title>
      </titleStmt>
      <publicationStmt>
        <distributor>CCSD</distributor>
        <availability status="restricted">
          <licence target="http://creativecommons.org/licenses/by/4.0/">Distributed under a Creative Commons Attribution 4.0 International License</licence>
        </availability>
        <date when="2024-04-29T11:49:21+02:00" />
      </publicationStmt>
      <sourceDesc>
        <p part="N">HAL API platform</p>
      </sourceDesc>
    </fileDesc>
  </teiHeader>
  <text>
    <body>
      <listBibl>
        <biblFull>
          <titleStmt>
            <title xml:lang="en">Reasoning about manipulation in multi-agent systems</title>
            <author role="aut">
              <persName>
                <forename type="first">Christopher</forename>
                <surname>Leturc</surname>
              </persName>
              <email type="md5">b884a869c8055085cf4d7594866db43d</email>
              <email type="domain">inria.fr</email>
              <idno type="idhal" notation="numeric">1173502</idno>
              <idno type="halauthorid" notation="string">1314929-1173502</idno>
              <affiliation ref="#struct-178918" />
            </author>
            <author role="aut">
              <persName>
                <forename type="first">Grégory</forename>
                <surname>Bonnet</surname>
              </persName>
              <email type="md5">7b14f4ccd1d08e184e3eb2dbe9c9c0a4</email>
              <email type="domain">unicaen.fr</email>
              <idno type="idhal" notation="string">bonnet-gregory</idno>
              <idno type="idhal" notation="numeric">1295794</idno>
              <idno type="halauthorid" notation="string">805860-1295794</idno>
              <idno type="ORCID">https://orcid.org/0000-0001-5096-8093</idno>
              <idno type="GOOGLE SCHOLAR">sPzk8z8AAAAJ</idno>
              <affiliation ref="#struct-406663" />
            </author>
            <editor role="depositor">
              <persName>
                <forename>Grégory</forename>
                <surname>Bonnet</surname>
              </persName>
              <email type="md5">7b14f4ccd1d08e184e3eb2dbe9c9c0a4</email>
              <email type="domain">unicaen.fr</email>
            </editor>
          </titleStmt>
          <editionStmt>
            <edition n="v1" type="current">
              <date type="whenSubmitted">2022-10-21 17:08:41</date>
              <date type="whenModified">2024-04-16 13:49:54</date>
              <date type="whenReleased">2022-10-24 15:10:55</date>
              <date type="whenProduced">2022-09-30</date>
              <date type="whenEndEmbargoed">2022-10-21</date>
              <ref type="file" target="https://hal.science/hal-03793389/document">
                <date notBefore="2022-10-21" />
              </ref>
              <ref type="file" subtype="author" n="1" target="https://hal.science/hal-03793389/file/Reasoning_about_Manipulation_in_Multi_Agent_Systems_Author_Version.pdf">
                <date notBefore="2022-10-21" />
              </ref>
            </edition>
            <respStmt>
              <resp>contributor</resp>
              <name key="533621">
                <persName>
                  <forename>Grégory</forename>
                  <surname>Bonnet</surname>
                </persName>
                <email type="md5">7b14f4ccd1d08e184e3eb2dbe9c9c0a4</email>
                <email type="domain">unicaen.fr</email>
              </name>
            </respStmt>
          </editionStmt>
          <publicationStmt>
            <distributor>CCSD</distributor>
            <idno type="halId">hal-03793389</idno>
            <idno type="halUri">https://hal.science/hal-03793389</idno>
            <idno type="halBibtex">leturc:hal-03793389</idno>
            <idno type="halRefHtml">&lt;i&gt;Journal of Applied Non-Classical Logics&lt;/i&gt;, 2022, 32 (2-3), pp.89-155. &lt;a target="_blank" href="https://dx.doi.org/10.1080/11663081.2022.2124067"&gt;&amp;#x27E8;10.1080/11663081.2022.2124067&amp;#x27E9;&lt;/a&gt;</idno>
            <idno type="halRef">Journal of Applied Non-Classical Logics, 2022, 32 (2-3), pp.89-155. &amp;#x27E8;10.1080/11663081.2022.2124067&amp;#x27E9;</idno>
          </publicationStmt>
          <seriesStmt>
            <idno type="stamp" n="UNICE">Université Nice Sophia Antipolis</idno>
            <idno type="stamp" n="CNRS">CNRS - Centre national de la recherche scientifique</idno>
            <idno type="stamp" n="INRIA">INRIA - Institut National de Recherche en Informatique et en Automatique</idno>
            <idno type="stamp" n="INRIA-SOPHIA">INRIA Sophia Antipolis - Méditerranée</idno>
            <idno type="stamp" n="I3S">Laboratoire d'Informatique, Signaux et Systèmes de Sophia-Antipolis</idno>
            <idno type="stamp" n="INRIASO">INRIA-SOPHIA</idno>
            <idno type="stamp" n="INRIA_TEST">INRIA - Institut National de Recherche en Informatique et en Automatique</idno>
            <idno type="stamp" n="TESTALAIN1">TESTALAIN1</idno>
            <idno type="stamp" n="GREYC">Groupe de Recherche en Informatique, Image, Automatique et Instrumentation de Caen (GREYC)</idno>
            <idno type="stamp" n="GREYC-MAD" corresp="GREYC">GREYC mad</idno>
            <idno type="stamp" n="WIMMICS">WIMMICS: Web-Instrumented Man-Machine Interactions, Communities, and Semantics</idno>
            <idno type="stamp" n="COMUE-NORMANDIE">Normandie Université</idno>
            <idno type="stamp" n="INRIA2">INRIA 2</idno>
            <idno type="stamp" n="UNIV-COTEDAZUR">Université Côte d'Azur</idno>
            <idno type="stamp" n="ENSICAEN">École Nationale Supérieure d’Ingénieurs de Caen</idno>
            <idno type="stamp" n="UNICAEN">Université de Caen Normandie</idno>
          </seriesStmt>
          <notesStmt>
            <note type="audience" n="2">International</note>
            <note type="popular" n="0">No</note>
            <note type="peer" n="1">Yes</note>
          </notesStmt>
          <sourceDesc>
            <biblStruct>
              <analytic>
                <title xml:lang="en">Reasoning about manipulation in multi-agent systems</title>
                <author role="aut">
                  <persName>
                    <forename type="first">Christopher</forename>
                    <surname>Leturc</surname>
                  </persName>
                  <email type="md5">b884a869c8055085cf4d7594866db43d</email>
                  <email type="domain">inria.fr</email>
                  <idno type="idhal" notation="numeric">1173502</idno>
                  <idno type="halauthorid" notation="string">1314929-1173502</idno>
                  <affiliation ref="#struct-178918" />
                </author>
                <author role="aut">
                  <persName>
                    <forename type="first">Grégory</forename>
                    <surname>Bonnet</surname>
                  </persName>
                  <email type="md5">7b14f4ccd1d08e184e3eb2dbe9c9c0a4</email>
                  <email type="domain">unicaen.fr</email>
                  <idno type="idhal" notation="string">bonnet-gregory</idno>
                  <idno type="idhal" notation="numeric">1295794</idno>
                  <idno type="halauthorid" notation="string">805860-1295794</idno>
                  <idno type="ORCID">https://orcid.org/0000-0001-5096-8093</idno>
                  <idno type="GOOGLE SCHOLAR">sPzk8z8AAAAJ</idno>
                  <affiliation ref="#struct-406663" />
                </author>
              </analytic>
              <monogr>
                <idno type="halJournalId" status="VALID">39557</idno>
                <idno type="issn">1958-5780</idno>
                <idno type="eissn">1166-3081</idno>
                <title level="j">Journal of Applied Non-Classical Logics</title>
                <imprint>
                  <publisher>Taylor &amp; Francis</publisher>
                  <biblScope unit="volume">32</biblScope>
                  <biblScope unit="issue">2-3</biblScope>
                  <biblScope unit="pp">89-155</biblScope>
                  <date type="datePub">2022-09-30</date>
                </imprint>
              </monogr>
              <idno type="doi">10.1080/11663081.2022.2124067</idno>
            </biblStruct>
          </sourceDesc>
          <profileDesc>
            <langUsage>
              <language ident="en">English</language>
            </langUsage>
            <textClass>
              <keywords scheme="author">
                <term xml:lang="en">Deception</term>
                <term xml:lang="en">Manipulation</term>
                <term xml:lang="en">Modal logics</term>
                <term xml:lang="en">Neighborhood semantics</term>
              </keywords>
              <classCode scheme="acm" n="I.2.4.1">I.: Computing Methodologies/I.2: ARTIFICIAL INTELLIGENCE/I.2.4: Knowledge Representation Formalisms and Methods/I.2.4.1: Modal logic</classCode>
              <classCode scheme="acm" n="I.2.11.1">I.: Computing Methodologies/I.2: ARTIFICIAL INTELLIGENCE/I.2.11: Distributed Artificial Intelligence/I.2.11.1: Intelligent agents</classCode>
              <classCode scheme="halDomain" n="info.info-ai">Computer Science [cs]/Artificial Intelligence [cs.AI]</classCode>
              <classCode scheme="halTypology" n="ART">Journal articles</classCode>
              <classCode scheme="halOldTypology" n="ART">Journal articles</classCode>
              <classCode scheme="halTreeTypology" n="ART">Journal articles</classCode>
            </textClass>
            <abstract xml:lang="en">
              <p>In many applications, selfish, dishonest or malicious agents may find an interest in manipulating others. While many works deal with designing robust systems or designing manipulative strategies, few works are interested in defining in a broad sense what is a manipulation and how we can reason with such a notion. In this article, based on a social science literature, we give at first a general definition of manipulation that can be applied in multi-agent systems. A manipulation is a deliberate effect of an agent (called a manipulator ) to instrumentalize another agent (called a victim), while making sure to conceal that effect. Secondly, we show how this definition is related with different fields in computer science where the conceptof manipulation is studied. Finally, we present a logical framework, called KBE, to express and reason about manipulations. Since manipulation relies on deliberate effects, KBE introduces a deliberate BIAT operator which abstracts deliberate consequences of actions. We prove that this logic is sound and complete and, we formally define manipulation. Furthermore, based on KBE, we express related notions such as coercion, persuasion, or deception and we show that these notions are different from manipulation.</p>
            </abstract>
          </profileDesc>
        </biblFull>
      </listBibl>
    </body>
    <back>
      <listOrg type="structures">
        <org type="researchteam" xml:id="struct-178918" status="VALID">
          <idno type="RNSR">201221031M</idno>
          <orgName>Web-Instrumented Man-Machine Interactions, Communities and Semantics</orgName>
          <orgName type="acronym">WIMMICS</orgName>
          <desc>
            <address>
              <country key="FR" />
            </address>
            <ref type="url">http://wimmics.inria.fr/</ref>
          </desc>
          <listRelation>
            <relation active="#struct-34586" type="direct" />
            <relation active="#struct-300009" type="indirect" />
            <relation active="#struct-452156" type="direct" />
            <relation active="#struct-13009" type="indirect" />
            <relation active="#struct-117617" type="indirect" />
            <relation name="UMR7271" active="#struct-441569" type="indirect" />
            <relation active="#struct-1039632" type="indirect" />
          </listRelation>
        </org>
        <org type="researchteam" xml:id="struct-406663" status="VALID">
          <orgName>Equipe MAD - Laboratoire GREYC - UMR6072</orgName>
          <desc>
            <address>
              <country key="FR" />
            </address>
          </desc>
          <listRelation>
            <relation active="#struct-150" type="direct" />
            <relation active="#struct-7127" type="indirect" />
            <relation active="#struct-455934" type="indirect" />
            <relation active="#struct-246955" type="indirect" />
            <relation name="UMR6072" active="#struct-441569" type="indirect" />
          </listRelation>
        </org>
        <org type="laboratory" xml:id="struct-34586" status="VALID">
          <idno type="RNSR">198318250R</idno>
          <idno type="ROR">https://ror.org/01nzkaw91</idno>
          <orgName>Inria Sophia Antipolis - Méditerranée</orgName>
          <orgName type="acronym">CRISAM</orgName>
          <desc>
            <address>
              <addrLine>2004 route des Lucioles BP 93 06902 Sophia Antipolis</addrLine>
              <country key="FR" />
            </address>
            <ref type="url">http://www.inria.fr/centre/sophia/</ref>
          </desc>
          <listRelation>
            <relation active="#struct-300009" type="direct" />
          </listRelation>
        </org>
        <org type="institution" xml:id="struct-300009" status="VALID">
          <idno type="ROR">https://ror.org/02kvxyf05</idno>
          <orgName>Institut National de Recherche en Informatique et en Automatique</orgName>
          <orgName type="acronym">Inria</orgName>
          <desc>
            <address>
              <addrLine>Domaine de VoluceauRocquencourt - BP 10578153 Le Chesnay Cedex</addrLine>
              <country key="FR" />
            </address>
            <ref type="url">http://www.inria.fr/en/</ref>
          </desc>
        </org>
        <org type="department" xml:id="struct-452156" status="VALID">
          <orgName>Scalable and Pervasive softwARe and Knowledge Systems</orgName>
          <orgName type="acronym">Laboratoire I3S - SPARKS</orgName>
          <date type="start">2016-03-03</date>
          <desc>
            <address>
              <addrLine>Laboratoire I3SCS 4012106903 Sophia Antipolis Cedex</addrLine>
              <country key="FR" />
            </address>
            <ref type="url">http://www.i3s.unice.fr/sparks</ref>
          </desc>
          <listRelation>
            <relation active="#struct-13009" type="direct" />
            <relation active="#struct-117617" type="indirect" />
            <relation name="UMR7271" active="#struct-441569" type="indirect" />
            <relation active="#struct-1039632" type="indirect" />
          </listRelation>
        </org>
        <org type="laboratory" xml:id="struct-13009" status="VALID">
          <orgName>Laboratoire d'Informatique, Signaux, et Systèmes de Sophia Antipolis</orgName>
          <orgName type="acronym">I3S</orgName>
          <desc>
            <address>
              <addrLine>2000, route des Lucioles - Les Algorithmes - bât. Euclide B 06900 Sophia Antipolis</addrLine>
              <country key="FR" />
            </address>
            <ref type="url">http://www.i3s.unice.fr/</ref>
          </desc>
          <listRelation>
            <relation active="#struct-117617" type="direct" />
            <relation name="UMR7271" active="#struct-441569" type="direct" />
            <relation active="#struct-1039632" type="direct" />
          </listRelation>
        </org>
        <org type="institution" xml:id="struct-117617" status="VALID">
          <idno type="IdRef">026403498</idno>
          <idno type="ISNI">0000000123372892</idno>
          <idno type="ROR">https://ror.org/02k9vew78</idno>
          <orgName>Université Nice Sophia Antipolis (1965 - 2019)</orgName>
          <orgName type="acronym">UNS</orgName>
          <date type="start">1965-10-23</date>
          <date type="end">2019-12-31</date>
          <desc>
            <address>
              <addrLine>Parc Valrose, 06100 Nice</addrLine>
              <country key="FR" />
            </address>
            <ref type="url">http://unice.fr/</ref>
          </desc>
        </org>
        <org type="regroupinstitution" xml:id="struct-441569" status="VALID">
          <idno type="IdRef">02636817X</idno>
          <idno type="ISNI">0000000122597504</idno>
          <idno type="ROR">https://ror.org/02feahw73</idno>
          <orgName>Centre National de la Recherche Scientifique</orgName>
          <orgName type="acronym">CNRS</orgName>
          <date type="start">1939-10-19</date>
          <desc>
            <address>
              <country key="FR" />
            </address>
            <ref type="url">https://www.cnrs.fr/</ref>
          </desc>
        </org>
        <org type="regroupinstitution" xml:id="struct-1039632" status="VALID">
          <idno type="IdRef">241035694</idno>
          <idno type="ROR">https://ror.org/019tgvf94</idno>
          <orgName>Université Côte d'Azur</orgName>
          <orgName type="acronym">UniCA</orgName>
          <date type="start">2020-01-01</date>
          <desc>
            <address>
              <addrLine>Parc Valrose, 28, avenue Valrose 06108 Nice Cedex 2</addrLine>
              <country key="FR" />
            </address>
            <ref type="url">https://univ-cotedazur.fr</ref>
          </desc>
        </org>
        <org type="laboratory" xml:id="struct-150" status="VALID">
          <idno type="IdRef">035827335</idno>
          <idno type="ISNI">0000 0000 9466 2590</idno>
          <idno type="RNSR">201722568L</idno>
          <idno type="ROR">https://ror.org/043749971</idno>
          <idno type="Wikidata">Q3117752</idno>
          <orgName>Groupe de Recherche en Informatique, Image et Instrumentation de Caen</orgName>
          <orgName type="acronym">GREYC</orgName>
          <date type="start">1995-01-01</date>
          <desc>
            <address>
              <addrLine>Boulevard du Maréchal Juin - 14050 CAEN Cedex</addrLine>
              <country key="FR" />
            </address>
            <ref type="url">http://www.greyc.fr</ref>
          </desc>
          <listRelation>
            <relation active="#struct-7127" type="direct" />
            <relation active="#struct-455934" type="indirect" />
            <relation active="#struct-246955" type="direct" />
            <relation name="UMR6072" active="#struct-441569" type="direct" />
          </listRelation>
        </org>
        <org type="institution" xml:id="struct-7127" status="VALID">
          <idno type="IdRef">026403064</idno>
          <idno type="ISNI">0000000121864076</idno>
          <idno type="ROR">https://ror.org/051kpcy16</idno>
          <orgName>Université de Caen Normandie</orgName>
          <orgName type="acronym">UNICAEN</orgName>
          <date type="start">1432-01-01</date>
          <desc>
            <address>
              <addrLine>Esplanade de la Paix - CS 14032 - 14032 CAEN Cedex 5</addrLine>
              <country key="FR" />
            </address>
            <ref type="url">http://www.unicaen.fr/</ref>
          </desc>
          <listRelation>
            <relation active="#struct-455934" type="direct" />
          </listRelation>
        </org>
        <org type="regroupinstitution" xml:id="struct-455934" status="VALID">
          <idno type="IdRef">190906332</idno>
          <idno type="ISNI">0000000417859671 </idno>
          <idno type="ROR">https://ror.org/01k40cz91</idno>
          <orgName>Normandie Université</orgName>
          <orgName type="acronym">NU</orgName>
          <date type="start">2015-01-01</date>
          <desc>
            <address>
              <addrLine>Esplanade de la Paix - CS 14032 - 14032 Caen Cedex 5</addrLine>
              <country key="FR" />
            </address>
            <ref type="url">http://www.normandie-univ.fr/</ref>
          </desc>
        </org>
        <org type="institution" xml:id="struct-246955" status="VALID">
          <idno type="IdRef">190907991</idno>
          <idno type="ROR">https://ror.org/01fpqqe90</idno>
          <orgName>École Nationale Supérieure d'Ingénieurs de Caen</orgName>
          <orgName type="acronym">ENSICAEN</orgName>
          <desc>
            <address>
              <addrLine>6, Boulevard du Maréchal Juin CS 45053 14050 CAEN cedex 04</addrLine>
              <country key="FR" />
            </address>
            <ref type="url">http://www.ensicaen.fr/</ref>
          </desc>
          <listRelation>
            <relation active="#struct-455934" type="direct" />
          </listRelation>
        </org>
      </listOrg>
    </back>
  <teiCorpus>
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Reasoning about manipulation in multi-agent systems</title>
			</titleStmt>
			<publicationStmt>
				<publisher />
				<availability status="unknown"><licence /></availability>
				<date type="published" when="2022-10-21">October 21, 2022</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Christopher</forename><surname>Leturc</surname></persName>
							<email>christopher.leturc@inria.fr</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Inria</orgName>
								<orgName type="institution" key="instit2">Université Côte d'Azur</orgName>
								<orgName type="institution" key="instit3">CNRS</orgName>
								<address>
									<region>I3S</region>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Grégory</forename><surname>Bonnet</surname></persName>
							<affiliation key="aff1">
								<orgName type="laboratory">ENSICAEN</orgName>
								<orgName type="institution" key="instit1">Normandie Univ</orgName>
								<orgName type="institution" key="instit2">UNICAEN</orgName>
								<orgName type="institution" key="instit3">CNRS</orgName>
								<orgName type="institution" key="instit4">GREYC</orgName>
								<address>
									<postCode>14000</postCode>
									<settlement>Caen</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Reasoning about manipulation in multi-agent systems</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2022-10-21">October 21, 2022</date>
						</imprint>
					</monogr>
					<idno type="MD5">B4C808CC4D2F1E7BB7690BF74AE535DD</idno>
					<idno type="DOI">10.1080/11663081.2022.2124067</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-04-12T14:48+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid" />
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Deception</term>
					<term>Manipulation</term>
					<term>Modal logics</term>
					<term>Neighborhood semantics</term>
				</keywords>
			</textClass>
			<abstract>
<div><p>In many applications, selfish, dishonest or malicious agents may find an interest in manipulating others. While many works deal with designing robust systems or designing manipulative strategies, few works are interested in defining in a broad sense what is a manipulation and how we can reason with such a notion. In this article, based on a social science literature, we give at first a general definition of manipulation that can be applied in multi-agent systems. A manipulation is a deliberate effect of an agent (called a manipulator ) to instrumentalize another agent (called a victim), while making sure to conceal that effect. Secondly, we show how this definition is related with different fields in computer science where the concept of manipulation is studied. Finally, we present a logical framework, called KBE, to express and reason about manipulations. Since manipulation relies on deliberate effects, KBE introduces a deliberate BIAT operator which abstracts deliberate consequences of actions. We prove that this logic is sound and complete and, we formally define manipulation. Furthermore, based on KBE, we express related notions such as coercion, persuasion, or deception and we show that these notions are different from manipulation.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div><head n="1.">Introduction</head><p>In many applications, selfish, dishonest or malicious agents may find an interest in manipulating others. In computer science and social science, manipulation is viewed as controlling or influencing somebody or something, often in a dishonest way so that they do not realize it. For example, reputation systems evaluate the trust that one agent should place in another depending on other agent's testimonies <ref type="bibr">(Hoffman, Zage, &amp; Nita-Rotaru, 2009;</ref><ref type="bibr" target="#b35">Josang &amp; Golbeck, 2009;</ref><ref type="bibr" target="#b66">Ruan &amp; Durresi, 2016)</ref>. However, agents may have interest in those systems in lying so as to mislead others, and push them to interact with some specific agents. Such behaviour is a manipulation in the sense that, to be effective, the liar must ensure that the other agents are unaware he intended to mislead them.</p><p>In the field of artificial intelligence, many works dealt with manipulation as in computational social choice <ref type="bibr" target="#b26">(Gibbard, 1973;</ref><ref type="bibr" target="#b58">Parkes &amp; Ungar, 2000;</ref><ref type="bibr" target="#b64">Robinson, 1985;</ref><ref type="bibr" target="#b71">Sanghvi &amp; Parkes, 2004)</ref>, game theory <ref type="bibr" target="#b21">(Ettinger &amp; Jehiel, 2010;</ref><ref type="bibr" target="#b89">Wagner &amp; Arkin, 2009)</ref>, or recommendation systems <ref type="bibr" target="#b53">(Mobasher, Burke, Bhaumik, &amp; Sandvig, 2007;</ref><ref type="bibr" target="#b62">Resnick &amp; Sami, 2008)</ref>. From a general perspective, there are many works on concepts closely related to manipulation <ref type="bibr" target="#b48">(Masters, Smith, Sonenberg, &amp; Kirley, 2021)</ref>. For instance, in modal logic literature, some works have modeled social influence <ref type="bibr" target="#b43">(Lorini &amp; Sartor, 2016)</ref> and deception <ref type="bibr" target="#b70">(Sakama, Caminada, &amp; Herzig, 2015;</ref><ref type="bibr" target="#b88">Van Ditmarsch, Van Eijck, Sietsma, &amp; Wang, 2012)</ref>. Interestingly, social science deals with manipulation as a combination of many concepts, e.g. strategies, deception, obfuscation, intentionality <ref type="bibr" target="#b4">(Akopova, 2013;</ref><ref type="bibr" target="#b19">Cohen, 2017;</ref><ref type="bibr" target="#b30">Handelman, 2009;</ref><ref type="bibr" target="#b80">Todd, 2013)</ref>. A review of social science literature allows us to consider a general definition of manipulation, i.e. acting in such a way to produce a deliberate effect of influencing another agent while concealing this influence.</p><p>This article is an extended version of our previous work <ref type="bibr" target="#b41">(Leturc &amp; Bonnet, 2020)</ref>. In this work, we defined a modal logic that allows one to reason about this concept of manipulation. To this end and to express deliberate effects, we have proposed a deliberate BIAT modality and combined it with a STIT-like modality to catch all consequences of actions and side-effects of actions. Concealment was expressed through epistemic and doxastic modalities. In the present article, we extend this previous work with two new contributions: (1) we provide a broad state-of-the-art about manipulation in social science, and about logical systems to express such notion; (2) we provide the complete proofs of all theorems given in <ref type="bibr" target="#b41">Leturc and Bonnet (2020)</ref>.</p><p>The remainder of this article is structured as follows. In Section 2, we present a review of the notion of manipulation drawn from social science literature, and we propose a general definition of manipulation. In Section 3, in view of the previous definition of manipulation, we survey available logical tools that are able to express it. In Section 4, we propose a logical framework and show that it is sound and complete. In Section 5, we formally define manipulation, and show our formal framework can also be used to model coercion, persuasion and deception. Finally, in Section 6 we instantiate an example.</p></div>
<div><head n="2.">Defining manipulation</head><p>The notion of manipulation is present in several fields of computer science such as in social choice theory <ref type="bibr" target="#b26">(Gibbard, 1973)</ref>, or in reputation systems <ref type="bibr" target="#b83">(Vallée &amp; Bonnet, 2015)</ref> where it is defined as a strategy allowing an agent to influence and control the individual (or collective) decision-making process of a group of agents using false information in order to push the latter to make a decision in favour of the manipulating agent. However, this is a restrictive notion of manipulation, as shown by works on social psychology, manipulative agent does not necessarily use the transmission of false information to manipulate. For example, the "foot in the door" consists in getting the victim to engage in a preparatory behavior to facilitate a decision in favor of the manipulator <ref type="bibr" target="#b36">(Joule, Beauvois, &amp; Deschamps, 2002)</ref>. As another example, social proof consists in showing a victimized agent a set of behaviours that other agents exhibit in order to influence him or her to imitate those agents <ref type="bibr" target="#b18">(Cialdini, 2012)</ref>. All those manners -using false informations, behaviors or social proof -are different concrete strategies to manipulate. In order to model manipulation in a broader way, we need a sufficiently broad definition of manipulation and we propose to extract it through social science literature. For this reason, Section 2.1 presents a survey on manipulation from the point of view of these fields. This state-of-the-art then allows us to give a definition of the term in Section 2.2.</p></div>
<div><head n="2.1.">Manipulation in social science</head><p>Social scientists often disagree on the definition of manipulation. For some of them, manipulation is considered to be the act of altering the judgment of individuals by depriving them of some of their deliberate choices <ref type="bibr" target="#b39">(Kligman &amp; Culver, 1992;</ref><ref type="bibr" target="#b68">Saint Clair, 1966;</ref><ref type="bibr" target="#b79">Sunstein, 2015)</ref>. However as stated by <ref type="bibr" target="#b30">(Handelman, 2009;</ref><ref type="bibr" target="#b67">Rudinow, 1978;</ref><ref type="bibr" target="#b76">Sorlin, 2017)</ref>, such a definition would lead to consider rational persuasion, deception or coercion as manipulation whereas most people would distinguish them. Consequently, there are four ways to consider manipulation in social science literature: considering it as a "vague concept", as strategies to alter the others' judgment, as an exercise of power over others, and finally as the invisible exercise of power. We review each of these points-of-view and extract their main features to propose a definition of manipulation for modeling.</p></div>
<div><head n="2.1.1.">Manipulation seen as a vague concept</head><p>By reviewing several situations in which the term "manipulation" is frequently used but giving counterexamples to each of them, the philosopher Felicia Nimue Ackerman claims that it is impossible to characterize manipulation because it is a "combinatorially vague concept" <ref type="bibr" target="#b1">(Ackerman, 1995)</ref>. By "combinatorially vague concept", she means that there are a variety of conditions under which the term is frequently used but none of them are sufficient to discriminate with certainty between manipulative and non-manipulative situations. To support her claim, Ackerman made a broad review of those conditions, including for instance use of indirect, cunning and subtle means, falsification or omission of information, deception, pressure and unethical behaviors, presence of hidden motives, and so on. While Ackerman claims that we cannot know what combinations of these conditions actually constitute manipulation. We reject this point-of-view for at least two reasons: (1) considering manipulation as a vague concept makes impossible to give an explicit formal definition of manipulation and reasoning with it as proposed in this paper and, (2) it would mean that efforts to model manipulation are doomed to failure unless to consider machine learning techniques to classify the data space into categories such as "manipulation" or "not manipulation", which is currently not the aim of this paper.</p></div>
<div><head n="2.1.2.">Manipulation seen as strategies to tamper the others' judgment</head><p>For many social scientists, manipulation is characterized by the use of psychological methods that can alter the victim's judgement, making him vulnerable to the manipulator's influence and unable to perceive the manipulation. For this reason, manipulation can be defined as strategies to exploit the others' weaknesses: manipulation is any successful and intentional act of influencing an agent's beliefs or behavior, directly or indirectly, by causing changes in mental processes <ref type="bibr" target="#b8">(Baron, 2003;</ref><ref type="bibr" target="#b22">Faden &amp; Beauchamp, 1986;</ref><ref type="bibr" target="#b38">Kahneman, 2011;</ref><ref type="bibr" target="#b51">Mills, 1995;</ref><ref type="bibr" target="#b67">Rudinow, 1978;</ref><ref type="bibr" target="#b92">Wilkinson, 2013)</ref>. Those changes can be:</p><p>(1) increasing or decreasing the available options to the victim;</p><p>(2) offering a reward or threatening punishment to the victim;</p><p>(3) directly influencing the victim's mental states. This point-of-view focuses on the strategies behind a manipulation. Obviously, in the literature there exists many definitions of strategy and the reader may refer to Mintzberg's review <ref type="bibr" target="#b52">(Mintzberg, 1987)</ref>. A manipulation can be based on exploiting</p></div>
<div><head>Basis of the strategy Examples</head></div>
<div><head>Exploiting agents' weaknesses</head><p>Cognitive dissonance <ref type="bibr" target="#b24">(Festinger, 1962)</ref>, discursive deception <ref type="bibr" target="#b84">(Van Dijk, 2006)</ref>, free will compliance <ref type="bibr" target="#b36">(Joule et al., 2002)</ref> Deflecting norms Reciprocity, social proof or social commitment <ref type="bibr" target="#b17">(Cialdini, 2001)</ref> Abusing trust Aggressive marketing <ref type="bibr" target="#b15">(Calo, 2013)</ref>, authority abuse <ref type="bibr" target="#b44">(Luhmann, 1979)</ref>, self-disclosure <ref type="bibr" target="#b3">(Aïmeur &amp; Sahnoune, 2020)</ref> Using rationality Authority arguments <ref type="bibr" target="#b30">Handelman (2009)</ref>, nudges and discreet rewards <ref type="bibr" target="#b92">(Wilkinson, 2013)</ref> Relying on emotions Coercion <ref type="bibr" target="#b93">(Wood, 2014)</ref>, emotional blackmail <ref type="bibr" target="#b29">(Gunderson, 1984)</ref>, seduction <ref type="bibr" target="#b78">(Strauss, 2006</ref>) Playing on knowledge / beliefs Deception <ref type="bibr" target="#b91">(Whiten &amp; Byrne, 1988)</ref>, hidding truth <ref type="bibr" target="#b46">(Maillat &amp; Oswald, 2009)</ref> or bullshitting <ref type="bibr" target="#b50">(McGinn, 2014)</ref>.</p><p>Table <ref type="table">1</ref>. A taxonomy of manipulation strategies in social science an agent weakness as a cognitive dissonance, deflecting norms as social commitment, abusing trust as betrayal, playing on the rational behavior of the victim, relying on emotions such as playing on fear with coercion, or a manipulation strategy can be based on knowledge or beliefs as lying, or bullshitting. Table <ref type="table">1</ref> sums up and gives examples of those kind of manipulation strategies.</p></div>
<div><head>Exploiting agent weaknesses</head><p>The theory of free will compliance, introduced in social psychology by <ref type="bibr" target="#b36">Joule et al. (2002)</ref>, describes a set of behavioral manipulation techniques. Among them, baiting involves asking a victim for a simple service, such as asking the time. It turns out that after obtaining this first service, it is easier to ask for a more compelling service. Thus, a manipulator may have the deliberate intention to use one of these techniques to manipulate humans. Another kind of weakness are cognitive biases <ref type="bibr" target="#b38">(Kahneman, 2011)</ref>. An agent can exploit those cognitive bias in order to induce another agent to make commitments of which he is unable to see the importance.</p></div>
<div><head>Deflecting norms</head><p>A manipulator can deflect a social norm to his own benefit. In social psychology, presents a set of norms on which a manipulator can rely to push another agent to realize his desire. For example, the norm of reciprocity is an internalized norm that says to always reciprocate with agents who offer us a service. Thus, a manipulator may circumvent this norm by voluntarily offering a costless service or resource to a victim to push him to provide a costier service requested in return by the manipulator <ref type="bibr" target="#b17">(Cialdini, 2001)</ref>.</p></div>
<div><head>Abusing trust</head><p>According to <ref type="bibr" target="#b16">Castelfranchi and Falcone (2010)</ref>, trust is the backbone of society. It is also a tool of manipulation. Indeed, a manipulation strategy consists in building trust in order to better control the other agents of the system. In marketing, trust is a tool to get a customer to buy a product he does not need and without his awareness <ref type="bibr" target="#b15">(Calo, 2013)</ref>. For example, salespeople can announce a "scarcity" <ref type="bibr" target="#b17">(Cialdini, 2001)</ref> to give a customer the illusion that a product is of quality because there is not much left in stock.</p></div>
<div><head>Using rationality</head><p>Rationality is a behaviour of agents who always want to maximize what they can hope to gain from a given situation. It can be used to influence decisions without the agent even being aware of this influence. Governments can use rationality as an argument to undermine political opponents. For instance, the 2003 Iraq war was presented as "rational warfare" to gain support <ref type="bibr" target="#b30">(Handelman, 2009)</ref>. Other examples of manipulations that can circumvent or subvert the victim's rational abilities are the use of nudges, or small discreet rewards to push an agent in the "good" direction <ref type="bibr" target="#b92">(Wilkinson, 2013)</ref>.</p></div>
<div><head>Relying on emotions</head><p>Manipulations between humans can have an emotional basis. A manipulative agent simulates certain emotional states, for example when a child cries to get a new toy from his parents. The child deliberately puts himself in this state to affect the parents' emotional state in order to get what he wants. In psychiatry, this emotionally based manipulation strategy is found in many examples such as when a person threatens to commit suicide. In this case, the threat aims at getting something from the others: a listening ear, a service, hoping to get back together with a person <ref type="bibr" target="#b29">(Gunderson, 1984)</ref>.</p></div>
<div><head>Playing on knowledge and beliefs</head><p>The linguist Eddo Rigotti presents a typology of the main processes that allow a manipulating agent to mislead another agent by playing on his beliefs and knowledge <ref type="bibr" target="#b63">(Rigotti, 2005)</ref>. For example, sophistry is a technique that consists in pushing another agent to deduce something false in order to exploit this error. Another example consists in hiding the truth of a proposition which could weaken or contradict the manipulator's discourse <ref type="bibr" target="#b46">(Maillat &amp; Oswald, 2009)</ref>.</p></div>
<div><head n="2.1.3.">Manipulation seen as the exercise of power over others</head><p>Beyond the strategies an agent can use to manipulate, for many researchers, manipulation is primarily characterized as a form of power exercised over others <ref type="bibr" target="#b0">(Abell, 1977;</ref><ref type="bibr" target="#b28">Goodin, 1980;</ref><ref type="bibr" target="#b39">Kligman &amp; Culver, 1992;</ref><ref type="bibr" target="#b47">Maoz, 1990;</ref><ref type="bibr" target="#b80">Todd, 2013)</ref>.</p><p>Manipulation is not simply a loss of autonomy. While manipulation is sometimes characterized as a loss of autonomy <ref type="bibr" target="#b60">(Poulin, 2010;</ref><ref type="bibr" target="#b61">Raz, 1986</ref>) (e.g. when a parasite takes control of its host), the philospher Patrick Todd claims it is not enough to define manipulation because it is necessary to distinguish between manipulation as the manipulation of an object, and manipulation as a case in which agents act in a manipulative manner <ref type="bibr" target="#b80">(Todd, 2013)</ref>. However, loss of autonomy is necessary for the manipulation to take place.</p></div>
<div><head>Manipulation is a deliberate intention.</head><p>Many social scientists state that manipulation is primarily an intention to act on another agent with influence. This influence is said to be manipulative if it is deliberately and intentionally used by the manipulator while the influence is said to be not manipulative as long as it is sincere, i.e. in accordance with what the influencer takes to be true, relevant, and appropriate <ref type="bibr" target="#b39">(Kligman &amp; Culver, 1992;</ref><ref type="bibr" target="#b55">Noggle, 1996)</ref>. Indeed, when an agent manipulates another, the act is knowingly deliberate. As social science rejects the concept of unintentional manipulation, using a mechanism of influence without knowing it, and therefore without having intended it, cannot be considered as a manipulation.</p><p>Manipulation is the intention to change something. <ref type="bibr" target="#b39">Kligman and Culver (1992)</ref> define manipulation as the manpilator's intention to change something in his environment. For example, a manipulator may deliberately withhold or selectively present certain information and omit others, exploiting the ignorance or beliefs of his victim in order to maintain control over his perceived options and direct him in the direction desired by the manipulator. For <ref type="bibr" target="#b47">Maoz (1990)</ref>, political manipulation is an attempt by one or more individuals to structure a collective decision as to maximize (resp. minimize) the chances of a favourable (resp. unfavourable) outcome. For <ref type="bibr" target="#b0">Abell (1977)</ref>, manipulation is a process where a manipulative agent A control a manipulated agent B's preferences by reducing B's understanding of the situation or B's means of action. Interestingly, all those definitions are similar to those used in game theory and social choice theory. For example, manipulating a voting system consists in providing a false preference profile to ensure a result preferred to the one normally obtained with the true preference profile <ref type="bibr" target="#b25">(Gärdenfors, 1976;</ref><ref type="bibr" target="#b26">Gibbard, 1973)</ref>.</p><p>Manipulation does not always go against the interests of the others. When one agent manipulates the other, he is doing it for his own interest, and this often goes against the interests of the others. That is why <ref type="bibr" target="#b28">Goodin (1980)</ref> claims that manipulation is primarily a deceptive influence compelling one to act against one's will. In the same way, <ref type="bibr" target="#b7">Barnhill (2014)</ref> states manipulation is also the intention of influencing certain traits or psychological dispositions in order to bring the victim into ideals of beliefs, desires or emotions in a way that is generally not in the victim's self-interest in the current context. However, all manipulations do not go against the self-interest of the manipulated agent. For example, the placebo effect that is sometimes used in medicine to make a patient believe that he will be cured with an ineffective drug is a manipulation in the patient's interest <ref type="bibr" target="#b82">(Turner, Deyo, Loeser, Von Korff, &amp; Fordyce, 1994)</ref>. That is why some authors consider the existence of benevolent manipulations <ref type="bibr" target="#b65">(Rosenberg &amp; Pearlin, 1962)</ref> meaning somebody exhibits a manipulative behavior in order to push someone else to do something in the latter's interest. Obviously, it means that the manipulator has a representation (possibly impropered) of the "victim"'s interest.</p><p>Manipulation is an instrumentalization of the others. Being benevolant or not, manipulation can be viewed in all cases as a psychosocial maneuver that uses aggression, coercion, intelligence, deception and trickery to influence someone in order to achieve a manipulator's desire <ref type="bibr" target="#b13">(Bowers, 2003;</ref><ref type="bibr" target="#b63">Rigotti, 2005;</ref><ref type="bibr" target="#b68">Saint Clair, 1966)</ref>. <ref type="bibr" target="#b63">Rigotti (2005)</ref> said the victim of a manipulation pursues the aim of the manipulator in the illusion of pursuing his or her own goal. While Saint Clair <ref type="bibr">(1966)</ref> states that there must be an incompatibility between the manipulator's desires and the manipulated's ones, <ref type="bibr" target="#b13">Bowers (2003)</ref> claims that manipulation seeks to achieve a desired goal without regard to the interests or needs of the manipulated agent. In both cases, achieving the manipulator's desires is the fundamental point associated with manipulation. That is why social science considers the manipulation as a form of intrumentalization, namely using somebody as a mean to achieve a goal.</p></div>
<div><head n="2.1.4.">Manipulation seen as the invisible exercise of a power</head><p>Interestingly, many researchers states manipulation is primarily an hidden influence <ref type="bibr" target="#b20">(de Saussure &amp; Schulz, 2005;</ref><ref type="bibr" target="#b30">Handelman, 2009;</ref><ref type="bibr" target="#b84">Van Dijk, 2006;</ref><ref type="bibr" target="#b90">Ware, 1981)</ref>.</p><p>For instance in clinical settings, manipulation is then associated with a patient's efforts (e.g. somatic complaints, provocative actions or misleading messages, and selfdestructive acts) to use covert means to gain control or support from significant persons <ref type="bibr" target="#b29">(Gunderson, 1984)</ref>. In linguistics, manipulation is a malevolant intention of the speaker with a character of hidden influence <ref type="bibr" target="#b4">(Akopova, 2013;</ref><ref type="bibr" target="#b63">Rigotti, 2005)</ref>: a manipulation is carried out when the addressee can no longer see the speaker's intentions behind what he or she is asserting. More generally, <ref type="bibr" target="#b30">Handelman (2009)</ref> states the practical meaning of the manipulation is that the target is subject to a hidden influence and believes that his or her choices are made freely and independently. The manipulation is therefore intended to motivate the target to operate in a form that, under normal conditions, would likely cause him or her to resist or reject the interaction. That is why this influence must be above all indirect, invisible and secret in order to take place. While this secrecy can simply mean the victim cannot use his deliberative capabilities <ref type="bibr" target="#b79">(Sunstein, 2015)</ref> to know or understand what is happening <ref type="bibr" target="#b90">(Ware, 1981)</ref>, awareness is also considered: manipulation can be viewed as a form of control in which the manipulated is not aware of what is happening or of the manipulator's strategy <ref type="bibr" target="#b20">(de Saussure &amp; Schulz, 2005;</ref><ref type="bibr" target="#b84">Van Dijk, 2006)</ref>.</p></div>
<div><head n="2.2.">Towards a general definition of manipulation</head><p>However, although we have highlighted significant differences among researchers, it appears that there is agreement among them on certain points. Hence, we use these commonalities to consider a general definition of manipulation. One of the main characteristics of manipulation is that it is, on the one hand, the exercise of power over others, and on the other hand, the exercise of a concealed power from the manipulated agents.</p><p>Firstly, manipulation is a power which is distinct from the more general concept of influence. While influence may be exerted in an unintentional way, manipulation is first and foremost a voluntary effect of a manipulator to use the victim to accomplish something <ref type="bibr" target="#b4">(Akopova, 2013;</ref><ref type="bibr" target="#b19">Cohen, 2017;</ref><ref type="bibr" target="#b30">Handelman, 2009;</ref><ref type="bibr" target="#b80">Todd, 2013)</ref>. Manipulation is necessarily intentional, and the use of the concept of "unintentional manipulation" is strongly rejected <ref type="bibr" target="#b39">(Kligman &amp; Culver, 1992)</ref>. Indeed, we cannot call it manipulation if the so-called manipulator did not deliberate about manipulating a victim. Thus, an agent who unwittingly influences another agent without his knowledge cannot be manipulating. That is why we consider in the sequel manipulation as an instrumentalization of a victim. Unlike influence, which can relate to beliefs, knowledge or even intentions, instrumentalization is a deliberate influence on the effects produced by a victim whether those latters are deliberate or not.</p><p>Secondly, this instrumentalization is concealed from the victim. Manipulation cannot simply be reduced to coercion and persuasion <ref type="bibr" target="#b30">(Handelman, 2009;</ref><ref type="bibr" target="#b39">Kligman &amp; Culver, 1992;</ref><ref type="bibr" target="#b76">Sorlin, 2017)</ref> as it is something that happens completely invisibly, and by the time we start talking about manipulation, the act has already been committed. So, when we talk about manipulation, whether it is in the past tense or the second person, we are definitely stating something that the victim did not know. So the inevitable conclusion is that the target is necessarily unable to identify that he was subjected to a manipulative influence. The linguist Sandrine Sorlin claims that if one can say "he tried to manipulate me but failed", we cannot say "he manipulated me but failed" <ref type="bibr" target="#b76">(Sorlin, 2017)</ref>. He insists on the fact that success is embedded in manipulation. Manipulation implies the success of this enterprise. Finally, manipulation is not similar to deception <ref type="bibr" target="#b30">(Handelman, 2009;</ref><ref type="bibr" target="#b39">Kligman &amp; Culver, 1992;</ref><ref type="bibr" target="#b76">Sorlin, 2017)</ref>. Indeed, deception may be related to lying which can be one possible strategy to manipulate a victim. However not all manipulations are based on lies: e.g. telling the truth may be also a way to manipulate and induce somebody in the wrong way. That is why a manipulation should not be confused with its inner strategy. To summarize, manipulation has three fundamental characteristics:</p><p>(1) it is a deliberate effect of a manipulator (i.e. an applied strategy);</p><p>(2) it is an instrumentalization of a victim (i.e. an influence);</p><p>(3) it is always hidden from the victim (i.e. a concealment).</p><p>Consequently manipulation is an instrumentalization and it is concealed from the target. Hence, by considering a synthesis of the definitions given in <ref type="bibr" target="#b4">(Akopova, 2013;</ref><ref type="bibr" target="#b19">Cohen, 2017;</ref><ref type="bibr" target="#b30">Handelman, 2009;</ref><ref type="bibr" target="#b80">Todd, 2013)</ref>, we retain the following definition of manipulation.</p><p>Definition 2.1. A manipulation is a deliberate effect of an agent (called a manipulator ) to instrumentalize another agent (called a victim), while making sure to conceal that effect.</p><p>It is important to notice that this definition makes sense in Artificial Intelligence literature, even in specific domains where manipulation has its own definition. In order to support our claim let us consider three domains: game theory <ref type="bibr" target="#b21">(Ettinger &amp; Jehiel, 2010)</ref>, social choice theory <ref type="bibr" target="#b26">(Gibbard, 1973)</ref> and reputation systems <ref type="bibr">(Hoffman, Zage, &amp; Nita-Rotaru, 2009)</ref> where manipulation has been widely studied. Obvious manipulation is not limited to those domains. The interested reader may refer to <ref type="bibr" target="#b48">Masters et al. (2021)</ref> to have other examples.</p><p>(1) Game theory deals with the strategic interactions between agents and is based on the assumption they are rational, i.e. the agents always seek to maximize their personal or collective reward function according to the decisions they can make. In this setting, manipulation is just considered as a strategy: manipulators must decide if they have an interest to manipulate while victims must decide if they have an interest to not play an counter-manipulation strategy. A refinement of this notion has been proposed by <ref type="bibr" target="#b21">Ettinger and Jehiel (2010)</ref>: manipulation is expressed through a Bayesian game on which the victims are associated to cognitive types that describe how much they believe the other types of player have a manipulation strategy, and how much they are able to distinguish the strategies of the various types of their opponents. Here, manipulation is a deliberate strategy (a chosen action) with instrumentalization (the manipulator's utility depends on the victim's strategy) and concealment (as the less the victim is able to distinguish the manipulation strategy, the more interest there is to manipulate). (2) Social choice theory deals with collective decision making based on the agents' preferences. Here, manipulation consists in as lying on our own preferences so as to obtain an outcome in our favor <ref type="bibr" target="#b26">(Gibbard, 1973)</ref>. Thus, it reduces manipulation as a particular strategy in which an agent is deliberately not sincere about its real preference profile. However, it also implies instrumentalization and concealment. Social choice theory deals with agents seeking for collective decisions.</p><p>A manipulator lies (its deliberate strategy) and pushes other agents to make a given collective decision (it is an intrumentalization). Concealment results from the fact that, to be effective, other agents must not be aware (or knowledgeable) of that strategy because, if it was the case, rational agents may adapt their behaviors to make the manipulation fail if it is in their interest (for instance by removing the manipulator from the decision process). (3) Reputation systems are systems where agents interact, collect, share, and aggregate the results of their past interactions to decide where they should be agents they can trust for future interactions. In this setting, manipulation consists in either lying on his identity (to avoid to accumulate bad evaluations), producing wrong evaluation (to increase or reduce another agent's reputation), interacting in order to blur the other agents (so they produce wrong evaluations), or do not collecting or sharing some messages in order to isolate another agent <ref type="bibr">(Hoffman, Zage, &amp; Nita-Rotaru, 2009)</ref>. As for the social choice theory, manipulation is here a deliberate strategy. Instrumentalization comes from the fact the manipulation wants to push the other agents to interact with him, or to forbid some agents to interact with the others. Finally, concealment comes from the fact that, if the other agents were aware or knew the manipulation, they should be able to isolate the manipulator.</p><p>While manipulation has been studied in multi-agent systems as a particular strategy or action e.g. in game theory or social choice theory as we showed, in this article we adopt a general position in regard to what is a manipulation in a multi-agent system by considering the definition 2.1. This definition makes clear the distinction with other related concepts such as e.g. coercion which is the instrumentalization of somebody by making him seeing a threat (thus without concealment) <ref type="bibr" target="#b49">(McCloskey, 1980)</ref>, persuasion which is the deliberate effect of changing beliefs (O'Keefe, 2015), lying which is the intention to induce a contrary beliefs from ours <ref type="bibr" target="#b45">(Mahon, 2008)</ref>, and so on. These concepts have been studied and disambiguated in the field of logic in multi-agent systems. Thus, in the next section, we provide a survey about related works in logic that are interested in defining such notions and how these formalisms can help us in defining manipulation.</p></div>
<div><head n="3.">Formalizing manipulation</head><p>From a general point-of-view, modal logics allow us to explicitly describe notions of intention, belief and knowledge that are fundamental to manipulations. Several logical approaches have already studied similar notions such as social influence <ref type="bibr" target="#b12">(Bottazzi &amp; Troquard, 2015;</ref><ref type="bibr" target="#b43">Lorini &amp; Sartor, 2016;</ref><ref type="bibr" target="#b72">Santos &amp; Carmo, 1996)</ref>, lying and deception <ref type="bibr" target="#b70">(Sakama et al., 2015;</ref><ref type="bibr" target="#b88">Van Ditmarsch et al., 2012)</ref>. In this section, since manipulation is a deliberate instrumentalization with concealment, we survey related works in literature about how to represent concealment (van der Hoek, Iliev, &amp; Wooldridge, 2012) and deliberate effects <ref type="bibr" target="#b14">(Broersen, 2008)</ref>. First, we present works related on modeling of lies and dishonesty. In a second step, since manipulation is a deliberate effect to instrumentalize, we review logics that have been interested in representing influence and deliberate effects. Finally, we present works on modeling awareness.</p></div>
<div><head n="3.1.">Representing dishonesty, deception and lies</head><p>Those three related concepts has been modeled by <ref type="bibr" target="#b11">(Bonnet, Leturc, Lorini, &amp; Sartor, 2021;</ref><ref type="bibr" target="#b70">Sakama et al., 2015;</ref><ref type="bibr" target="#b88">Van Ditmarsch et al., 2012)</ref>. All those approaches are based of the fact that an agent i informs another agent j about something so that j believes it while the agent i believes the opposite. For instance, <ref type="bibr" target="#b70">Sakama et al. (2015)</ref> use modal logic and introduces a modality of communication between two agents, a modality of belief as well as a modality of intention to describe concepts such as lying, churning, concealment or deception. <ref type="bibr" target="#b11">Bonnet et al. (2021)</ref> define persuasion as a deliberate action through which a persuader changes the beliefs of a persuadee, and define deception as persuading the persuadee of something under the assumption that the persuader believes that it is false. finally, <ref type="bibr" target="#b88">Van Ditmarsch et al. (2012)</ref> uses dynamic doxastic logics with a modality to describe the action of private advertisements that is used to describe lying. <ref type="bibr" target="#b70">Sakama et al. (2015)</ref> define a logical theory of dishonesty in which they characterize notions of lying, bullshitting, concealment of information, deception, and half-truth. To formally describe these notions, they consider a formalism called BIC in which they considers for any agent i, j ∈ N , modalities of beliefs B i , intentions I i and communications, noted C i,j , from an agent i to another agent j. While <ref type="bibr" target="#b45">Mahon (2008)</ref> first defines lying as making another person believe a false statement with the intent that the statement to be believed to be true by the other person, <ref type="bibr" target="#b70">Sakama et al. (2015)</ref> take up this definition and define a simple lie with the predicate:</p></div>
<div><head n="3.1.1.">A theory of dishonesty</head><formula xml:id="formula_0">SimpleLie i,j (ϕ) = C i,j ϕ ∧ B i ¬ϕ ∧ I i B j ϕ</formula><p>However, <ref type="bibr" target="#b45">Mahon (2008)</ref> also considers that lying to another person can be defined as the intention to make the intention to make the addressee believe that the statement is believed to be true by the speaker. Thus, <ref type="bibr" target="#b70">Sakama et al. (2015)</ref> describe lying as:</p><formula xml:id="formula_1">Lie * i,j (ϕ) = SimpleLie i,j (ϕ) ∨ (C i,j ϕ ∧ B i ¬ϕ ∧ I i B j B i ϕ)</formula><p>To this notion of lying, <ref type="bibr" target="#b70">Sakama et al. (2015)</ref> add the notion of lying by objective when the agent i lying intends to make his addressee believe a proposition ϕ by deduction. Here, the liar then lies about a statement that he does not believe σ, but believes that the statement will lead the other person to believe ϕ. This notion is then described by the predicate:</p><formula xml:id="formula_2">O -Lie * i,j (σ, ϕ) = I i B j ϕ ∧ ¬B i B j ϕ ∧ B i B j (σ ⇒ ϕ) ∧ B i ¬σ ∧ C i,j σ</formula><p>Other notions are characterized as "bullshitting", which describes the action of communicating information that is not the case whether the agent communicating i believes ϕ and believes the opposite ¬ϕ, i.e. the predicate:</p><formula xml:id="formula_3">BS i,j (ϕ) = C i,j ϕ ∧ ¬B i ϕ ∧ ¬B i ¬ϕ</formula><p>They also characterize withholding information as the fact that an agent i intends not to reveal information ϕ that i believes to be true, that is:</p><formula xml:id="formula_4">W I i,j (ϕ) = ¬C i,j ϕ ∧ B i ϕ ∧ I i ¬B j ϕ</formula><p>Finally, the notion of half-truth consists in giving information that we believe to be true in order to mislead the other person by playing on an error of reasoning in the addressee. It is formally described by:</p><formula xml:id="formula_5">HT i,j (ϕ, ψ) = (C i,j ϕ ∧ B i ϕ ∧ I i B j ϕ) ∧ ¬B i B j ψ ∧ B i B j (ϕ ⇒ ψ) ∧ B i ¬ψ ∧ ¬C i,j ¬ψ ∧ I i B j ψ</formula><p>The part of this predicate (C i,j ϕ ∧ B i ϕ ∧ I i B j ϕ) is called the intentional sincerity. So, in their system, they show, for example, that lying about a proposition ϕ while intending to be sincere is impossible and deduce the theorem</p><formula xml:id="formula_6">(C i,j ϕ ∧ B i ϕ ∧ I i B j ϕ) ∧ Lie B i,j (ϕ) ⇒ ⊥.</formula></div>
<div><head n="3.1.2.">A theory of persuasion and deception</head><p>Bonnet et al. ( <ref type="formula">2021</ref>) model notions such as influence, persuasion, deception and their logical relations. To do that they extend a propositional dynamic logic to a STIT logic and express a ex post knowledge K post i which characterizes an agent's knowledge assuming that the agent has made his decision about which action to take, but might still be uncertain about the decisions of others. Here, a deliberate STIT [{i}:dstit] is defined as seeing to it that something is true, which is not necessary true in the other worlds in a current moment. There is also a temporal operator 'next' X defined as the applied joint action in the current world and a belief modality B j . In their approach, persuasion is defined as a deliberate action through which an agent (persuader) changes the beliefs of another agent's (persuadee):</p><formula xml:id="formula_7">Persuades(i, j, ϕ) = K post i [{i}:dstit]XB j ϕ</formula><p>Based on this notion, they define deception as a persuasion in a proposition ϕ under the assumption that the persuader believes that ϕ is false.</p><formula xml:id="formula_8">Deceives(i, j, ϕ) = Persuades(i, j, ϕ) ∧ B i X¬ϕ</formula><p>Here, truthfully telling is simply captured by persuasion, while deception always involves not telling the truth. This notion of deception is then refined to express more subtle notions, such as smooth-talking (persuading since the persuader is uncertain whether ϕ is true or false) which is equivalent to <ref type="bibr" target="#b70">Sakama et al. (2015)</ref>'s "bullshitting". <ref type="bibr" target="#b11">Bonnet et al. (2021)</ref> distinguish benevolent, malevolent and reckless deception, which differ in how persuading an agent j of something is good for j (or not). In the malevolent form, the deceiver believes that believing ϕ will have bad consequences for the deceived. On the contrary, in a benevolent deception the deceiver believes that believing ϕ is good for the deceived. Finally, reckless deception consists for the deceiver to not know whether that ϕ is good or bad for the deceived.</p><formula xml:id="formula_9">PersuadesBySmoothTalking(i, j, ϕ) = Persuades(i, j, ϕ) ∧ ¬K post i X¬ϕ ∧ ¬K post i ¬X¬ϕ Finally,</formula><formula xml:id="formula_10">MalevolentDeception(i, j, ϕ) = Deceives(i, j, ϕ) ∧ B i X(B j ϕ → bad j ) BenevolentDeception(i, j, ϕ) = Deceives(i, j, ϕ) ∧ B i X(B j ϕ → good j ) RecklessDeception(i, j, ϕ) = Deceives(i, j, ϕ) ∧ ¬K post i X(B j ϕ → good j ) ∧ ¬K post i X(B j ϕ → bad j )</formula></div>
<div><head n="3.1.3.">A dynamic logic of lying</head><p>While <ref type="bibr" target="#b11">Bonnet et al. (2021)</ref> and <ref type="bibr" target="#b70">Sakama et al. (2015)</ref> consider predicates to express lying, deception, or persuasion, another approach Van Ditmarsch et al. ( <ref type="formula">2012</ref>) gets rid of representing those notions through predicates. Instead, they consider lying as a public announcement which is false, and they use a dynamic doxastic logic to describe the effects of lying through the semantics of the logical system. In this work, they consider a language L ll generated by the following BNF:</p><formula xml:id="formula_11">ϕ ::= p|(ϕ 1 ∧ ϕ 2 )|¬ϕ| |⊥|B i ϕ|[ ‡ϕ 1 ]ϕ 2 |[!ϕ 1 ]ϕ 2 |[¡ϕ 1 ]ϕ 2</formula><p>In this language, they consider a set of modal operators and public announcement operators as:</p><formula xml:id="formula_12">• B i ϕ means the agent i believes that ϕ is true, • [!ϕ]</formula><p>ψ means that ψ is true after the public announcement of ϕ, • [¡ϕ]ψ means that ψ is true after the lie ϕ, • [ ‡ϕ]ψ means that ψ is true after the public announcement of ϕ but also true after the lie ϕ. To interpret these operators they first consider a doxastic model M = (W, {B i } i∈N , V ) with {B i } i∈N a set of serial, transitive and euclidean relations. Secondly they define an action model A p = (W α , {B α i } i∈N , I α , P α ) with I α : W α → L ll the precondition function and P α : W α → Sub Lll a function called postcondition function which assigns to each possible event a substitution which represents the effects of actions on variables. If A(L ll ) = {p 1 , . . . , p n } is the set of propositional variables of L ll , elements of Sub Lll are represented by:</p><formula xml:id="formula_13">{p 1 → σ 1 , . . . , p n → σ n |σ 1 , . . . , σ n ∈ L ll }</formula><p>The action model they use is described by Figure <ref type="figure" target="#fig_0">1</ref> which expresses the effects of actions, here public announcements. For instance the event 1 : p represents the public announcement of p where p is true while 0 : ¬p represents the possible event when it is a lie i.e. p is announced while p is false. Furthermore let us notice that p can be substituted for any formula ϕ which means that public announcement are not necessary related to atomic propositions. Then, to define the effect of public announcement on the beliefs of the agents, this is given by a standard product update defined as (M, U ) ⊗ (A, S) = ((W ⊗ , {B ⊗ i } i∈N , V ⊗ ), U ⊗ ) where U ⊆ W, S ⊆ W α and:</p><formula xml:id="formula_14">• W ⊗ = {(v, f ) ∈ W × W α : M, v |= I α (f )} • ∀(v, f ) ∈ W ⊗ , ∀i ∈ N , B ⊗ i (v, f ) = {(u, g) ∈ W ⊗ : u ∈ B i (v), g ∈ B α i (f )} • ∀(v, f ) ∈ W ⊗ : V ⊗ (v, f ) = {p ∈ A(L B )|M, w |= P (s)(p)} • U ⊗ := {(v, f )|v ∈ U, f ∈ S, (v, f ) ∈ W ⊗ }</formula><p>Finally, the semantics of the operators of L ll is given by:</p><formula xml:id="formula_15">• M, w |= B i ϕ iff ∀v ∈ W : wB i v, M, v |= ϕ • M, w |= [!ϕ]ψ iff (M, {w}) ⊗ (A ϕ , {1}), (w, 1) |= ψ • M, w |= [¡ϕ]ψ iff (M, {w}) ⊗ (A ϕ , {0}), (w, 0) |= ψ • M, w |= [ ‡ϕ]ψ iff (M, {w}) ⊗ (A ϕ , {0, 1}), (w, 0) |= ψ and (M, {w}) ⊗ (A ϕ , {0, 1}), (w, 1) |= ψ</formula><p>This semantics then gives the axiomatic system summarized in Figure <ref type="figure" target="#fig_1">2</ref>, the manipulative announcement is then described as [ ‡ϕ]ψ and by Ax0,</p><formula xml:id="formula_16">[ ‡ϕ]ψ ⇔ [!ϕ]ψ ∧ [¡ϕ]ψ.</formula><p>The rule A1 describes that if a public announcement ϕ brings the consequence p, then if ϕ is true, then necessarily p is true and vice versa. The formula [!ϕ]p ⇔ ϕ ⇒ p is then a tautology of the system. Let us notice that other works using dynamic logic to model lying or deceiving exist. For instance, <ref type="bibr" target="#b69">Sakama (2021)</ref> recently extends his previous work <ref type="bibr" target="#b70">(Sakama et al., 2015)</ref> and proposes to model deception with a doxastic dynamic semantics.</p><formula xml:id="formula_17">(CP) ϕ, for all PC theorems ϕ (Ax0) [ ‡ϕ]ψ ⇔ [!ϕ]ψ ∧ [¡ϕ]ψ (A1) [!ϕ]p ⇔ ϕ ⇒ p (A2) [!ϕ]¬ψ ⇔ ϕ ⇒ ¬[!ϕ]ψ (A3) [!ϕ](ψ 1 ∧ ψ 2 ) ⇔ [!ϕ]ψ 1 ∧ [!ϕ]ψ 2 (A4) [!ϕ]B i ψ ⇔ ϕ ⇒ B i [!ϕ]ψ (L1) [¡ϕ]p ⇔ ¬ϕ ⇒ p (L2) [¡ϕ]¬ψ ⇔ ¬ϕ ⇒ [¡ϕ]ψ (L3) [¡ϕ](ψ 1 ∧ ψ 2 ) ⇔ [¡ϕ]ψ 1 ∧ [¡ϕ]ψ 2 (L4) [¡ϕ]B i ψ ⇔ ¬ϕ ⇒ B i [¡ϕ]ψ</formula></div>
<div><head n="3.2.">Representing the effects of actions</head><p>As manipulation is a deliberate effect in order to instrumentalize an agent, it is of interest to reason on actions, their intended consequences, their side-effects, and how they can influence the other agents. Many formalisms exist. For instance, dynamic logics <ref type="bibr" target="#b31">(Harel, Kozen, &amp; Tiuryn, 2001)</ref> and temporal logics <ref type="bibr" target="#b5">(Alur, Henzinger, &amp; Kupferman, 2002)</ref> consider several action modalities where each action modality is associated with a program and its outputs. Dynamic epistemic logics express the logical consequences generated by public or private announcements of agents <ref type="bibr" target="#b85">(Van Ditmarsch, Van Der Hoek, &amp; Kooi, 2007)</ref>. Many other formalisms exist such as fluent calculus. For a detailed survey, the interested reader may refer to <ref type="bibr" target="#b74">(Segerberg, Meyer, &amp; Kracht, 2009)</ref>. Interestingly, <ref type="bibr" target="#b27">(Giordano, Martelli, &amp; Schwind, 2000)</ref> propose a formalism that catches all ramification effects of actions i.e. all direct consequences and side-effects of actions. However such formalism introduces a distinct modality for each possible action, while we saw in Table <ref type="table">1</ref> that manipulation does not depend on particular actions or strategies (e.g. lying, rumor propagating, emotional blackmailing) but rather on its results. Thus, it is of interest to consider action logics which only represent abstract strategies that lead to a state-of-affair. Two approaches seem relevant: the STIT logics <ref type="bibr" target="#b6">(Balbiani, Herzig, &amp; Troquard, 2008;</ref><ref type="bibr" target="#b9">Belnap &amp; Perloff, 1988;</ref><ref type="bibr" target="#b43">Lorini &amp; Sartor, 2016)</ref> and the BIAT logics <ref type="bibr" target="#b59">(Pörn, 1977;</ref><ref type="bibr" target="#b72">Santos &amp; Carmo, 1996;</ref><ref type="bibr" target="#b81">Troquard, 2014)</ref>, which both consider, in an abstract way, the fact of ensuring that something is done.</p><p>Both STIT and BIAT logics consider actions as the fruit of their consequences. This level of abstraction is well-adapted to define manipulation. BIAT considers a modality E i which means that the agent i brings it about. Let us notice it is side-effects free, i.e. indirect consequences of actions are not considered as intended effects. For its part, STIT considers a modality [ST IT ] i which means that the agent i sees to it that and catches all consequences of actions. Although these two approaches are often confused, the main difference between these two formalisms lies in the semantics of these modalities. STIT considers a S5 system<ref type="foot" target="#foot_0">1</ref> whereas BIAT is a non normal system based on neighborhood functions. Furthermore, STIT uses a notion of temporality while BIAT does not.</p></div>
<div><head n="3.2.1.">Representing influence</head><p>In the literature about STIT, some approaches already defined a notion of influence. Here, influence consists in seeing to it that another agent will see to it that something becomes true. For instance, <ref type="bibr" target="#b43">Lorini and Sartor (2016)</ref> define the fact that agent i influences agent j on ϕ if, and only if, agent i sees to it that in the future, agent j rationally sees to it that ϕ, i.e.:</p><formula xml:id="formula_18">[inf l] i,j ϕ = [stit] i X[rstit] j ϕ</formula><p>where [rstit] is a primitive modal operator which represents the current choice as a rational choice. For its part, BIAT logics define influence similarly as the effect of an agent i to bring it about that another agent j brings about something. For instance, <ref type="bibr" target="#b12">Bottazzi and Troquard (2015)</ref> considers the following predicate to define influence which is called interpersonal control :</p><formula xml:id="formula_19">[inf l] i,j ϕ = E i (E j ϕ ∧ ψ)</formula><p>The modality E i (resp. E j ) refers to a non-normal modality which means that agent i (resp. agent j) brings it about something. The formula ψ represents any formula of the language that does not contradict E j ϕ. This ψ is explicitly included in the definition of the predicate of influence because of the semantics which does not allow us to have the property of normal logics (ϕ ∧ ψ) ≡ ϕ ∧ ψ. If influence is defined only as E i E j ϕ and if a formula E i (E j ϕ ∧ ψ) is verified with ψ = , then since we do not have the property of normal logics, we could not be able to deduce the influence</p><formula xml:id="formula_20">E i E j ϕ from E i (E j ϕ ∧ ψ).</formula></div>
<div><head n="3.2.2.">Representing deliberate effects</head><p>While STIT approaches define influence, they also define a notion of deliberate effect. <ref type="bibr" target="#b43">Lorini and Sartor (2016)</ref> define deliberate effect by considering that something is done deliberately by another agent i if, and only if, i sees to it that something is true while it is not necessarily the case, that is to say:</p><formula xml:id="formula_21">[dstit] i ϕ = [stit] i ϕ ∧ ¬ ϕ</formula><p>However, this definition is not without problems. Let us imagine a situation in which one agent i deliberately causes a car crash to take advantage of car insurance. But during this car crash, a person died. By following the formal definition of Lorini and Sartor (2016)'s deliberate STIT, we would deduce that the agent i deliberately sees to it that "the car is crashed" but also, all indirect consequences as "a person is dead". Consequently by following STIT reasoning and since it was not necessarily the case (if the agent did not choose to cause this accident) that the person is dead, we would also deduce that i deliberately sees to it that "the person is dead". However we claim the opposite. Even if the agent i deliberately caused this car accident, he did not deliberately kill the victim. Furthermore a deliberate effect must be known by the agent. Indeed when we deliberately do or do not something, then we know what we are doing. Because they use standard STIT, <ref type="bibr" target="#b43">Lorini and Sartor (2016)</ref> do not and cannot consider positive and negative introspection on knowledge. Let us notice that <ref type="bibr" target="#b14">Broersen (2008)</ref> integrates a knowledge modality into the STIT language and defines a deliberate see to it such as:</p><formula xml:id="formula_22">[dxstit] i ϕ = K i [xstit] i ϕ ∧ K i ¬ Xϕ</formula><p>Here, <ref type="bibr">[xstit]</ref> i ϕ denotes that in the future, agent i sees to it that ϕ. Broersen (2008)'s deliberate STIT has the positive and negative introspection with knowledge. Furthermore it has also the side-effect free property since a consequence may not be known by the agent to consider it as a deliberate effect. A third important property that deliberate effects has to be verified which is the conjunction of all deliberate effects forms a deliberate effect. This property means that if agent i deliberately sees to it that ϕ and also deliberate sees to it that ψ, then he deliberately sees to it that ϕ ∧ ψ; and Broersen (2008)'s deliberate STIT has this property.</p><p>Concerning BIAT, as written previously, it explicitly defines a deliberate effect modality and it is side-effects free.</p></div>
<div><head n="3.3.">Representing revelation, concealment and awareness</head><p>Lastly, we have seen that manipulation needs to conceal its effects. In the literature, this notion of concealment can be expressed either in terms of an agent's knowledge, or in terms of his level of awareness. In this section, we highlight some logical approaches that have represented those notions.</p></div>
<div><head n="3.3.1.">A logic of revelation and concealment</head><p>To the best of our knowledge, only van der Hoek et al. ( <ref type="formula">2012</ref>) proposed a logic for representing revelation and concealment as a Propositional Dynamic Logic (PDL). They considered particular actions for revelation and concealment, denoted (resp) by r(p, i) and c(p, i). The formula [r(p, i)]ϕ means that after revealing the value of p to an agent i, the formula ϕ is true, while [c(p, i)]ϕ means that after concealing the value of p to an agent i, the formula ϕ is true. These modalities are described in a PDL logical frame. They combined to action a standard S5 epistemic operator K i with a Kripke relationship.</p><p>Their formalism makes possible to express and deduce interesting valid formulas as if a proposition p is true, then after revealing p to one agent i, then this agent will know that p is true i.e.:</p><formula xml:id="formula_23">p ⇒ [r(p, i)]K i p</formula><p>In the same way, this formalism provides other valid formulas which combine effects of actions on the knowledge of agents. For instance, they can express a validity as e.g. if after doing an action α, the variable p is true, then if we reveal p to one agent i and then do α, then i will know that p is true:</p><formula xml:id="formula_24">[α]p ⇒ [r(p, i); α]K i p</formula><p>In their logical framework, they are able to express interesting validities related to that action of concealment as e.g. after concealing to agent i the value of p it is possible that after some execution of one action α, ϕ is true, is equivalent to, after some execution of α and, after concealing to agent i the value of p, makes ϕ true, i.e.: c(p, i) α ϕ ⇔ α c(p, i) ϕ</p></div>
<div><head n="3.3.2.">Representing awareness</head><p>Contrary to concealment, many works have taken an interest in formally representing the semantics of being aware of <ref type="bibr" target="#b32">(Hill, 2010;</ref><ref type="bibr" target="#b54">Modica &amp; Rustichini, 1994;</ref><ref type="bibr" target="#b73">Schipper, 2014;</ref><ref type="bibr" target="#b87">Van Ditmarsch, French, Velázquez-Quesada, &amp; Wáng, 2018)</ref>. <ref type="bibr" target="#b23">Fagin and Halpern (1987)</ref> consider Levesque's logic on implicit and explicit knowledge to model a logic of non-omniscience <ref type="bibr" target="#b42">(Levesque, 1984)</ref>. <ref type="bibr" target="#b54">Modica and Rustichini (1994)</ref> consider that an agent i ∈ N is aware of something, denoted A i ϕ, if, and only if, that agent knows ϕ or it is not the case it knows ϕ and it knows that it is not the case it knows ϕ, i.e. checks the predicate</p><formula xml:id="formula_25">A i ϕ := K i ϕ ∨ (¬K i ϕ ∧ K i ¬K i ϕ) where K i is a knowledge modality. If K i is associated with a modal system S5, then the previous definition of consciousness becomes equivalent to A i ϕ := K i ϕ ∨ K i ¬K i ϕ.</formula><p>While previous mentioned approaches use knowledge or belief operators semantically defined by a Kripke relationship to define awareness, <ref type="bibr" target="#b73">Schipper (2014)</ref> proposes to model awareness semantically with a function A i : W → 2 L that maps from a possible world, the set of formulas that agent i is aware of. It defines a modal language L in which a modality L i refers to the implicit knowledge of an agent i, and a modality A i ϕ expresses the awareness of an agent i on a proposition ϕ. The semantics of this modality A i is defined with a function A i : W → 2 L . This function is called Awareness Correspondence. Thus, an agent i is aware of a proposition ϕ if, and only if, this formula ϕ belongs to a set of formulas given by this correspondence function.</p><p>A i : W → 2 L associates for a given world, all the formulas that a i agent is aware of. Knowledge is then defined by the predicate</p><formula xml:id="formula_26">K i ϕ = L i ϕ ∧ A i ϕ. In this formalism, a model is a tuple, M = (W, {R i } i∈N , {A i } i∈N , V ) such that (W, {R i } i∈N , V ) is a</formula><p>Kripke frame where {R i } i∈N is a set of equivalence relations associated to the semantics of L i for each agent i ∈ N . To define the correspondence function A i , it is then necessary to use a function that returns the set of atomic propositions of a formula, this function At is such that:</p><formula xml:id="formula_27">• At( ) = ∅ • At(p) = {p} if p is an atom of L • At(¬ϕ) = At(ϕ) • At(ϕ ∧ ψ) = At(ϕ) ∪ At(ψ) • At(K i ϕ) = At(ϕ) • At(A i ϕ) = At(ϕ)</formula><p>So, for each agent i ∈ N and all possible worlds w ∈ W, the correspondence function is such that:</p><formula xml:id="formula_28">(1) ϕ ∈ A i (w) if, and only if, At(ϕ) ⊆ A i (w) (2) ∀v ∈ W : wR i v ⇒ A i (w) = A i (v)</formula><p>Property 1 means that, for an agent i to be aware of a formula ϕ, it is necessary for that agent to be aware of all the propositional atoms contained in a formula. Property 2 corresponds to the fact that an agent knows what it is aware of. Finally, a pattern is defined in a standard way. We have, for every agent i ∈ N and for each world w ∈ W, the following semantics:</p><formula xml:id="formula_29">• M, w |= L i ϕ iff ∀v ∈ W, wR i v : M, v |= ϕ • M, w |= A i ϕ iff ϕ ∈ A i (w) • M, w |= K i ϕ iff M, w |= L i ϕ and M, w |= A i ϕ</formula><p>This semantics then gives us the axiomatic system of the figure 3. An immediate theorem of consciousness is that if an agent i knows that something is true then necessarily this agent i is aware of that something. Indeed:</p><formula xml:id="formula_30">• K i ϕ ⇔ L i ϕ ∧ A i ϕ • L i ϕ ∧ A i ϕ ⇒ A i ϕ • K i ϕ ⇒ A i ϕ</formula><p>Finally, all these works have been extended in <ref type="bibr" target="#b87">Van Ditmarsch et al. (2018)</ref> where they define a logic of speculative knowledge allowing to reason about the notion of non awareness, based on the logic of implicit and explicit knowledge of <ref type="bibr" target="#b23">Fagin and Halpern (1987)</ref> and the logic of consciousness of <ref type="bibr" target="#b73">Schipper (2014)</ref>. This notion of speculative knowledge is distinct from that of implicit knowledge and explicit knowledge. It translates that an agent has speculative knowledge of a proposition ϕ in a model M and a world w if this formula is verified in all accessible worlds in all pointed models of the framework that are A i (w)-bisimilar<ref type="foot" target="#foot_1">2</ref> to the world w.</p></div>
<div><head>(CP)</head><p>ϕ, for all PC theorems ϕ (KL)</p><formula xml:id="formula_31">K i ϕ ⇔ L i ϕ ∧ A i ϕ (S5(L i ))</formula><p>ϕ, for all theorems ϕ of S5 associated with L i (AS)</p><formula xml:id="formula_32">A i ϕ ⇔ A i ¬ϕ (AC) A i (ϕ ∧ ψ) ⇔ A i ϕ ∧ A i ψ (AKR) A i ϕ ⇔ A i K i ϕ (AR) A i ϕ ⇔ A i A i ϕ (ALR) A i ϕ ⇔ A i L i ϕ (UL) ¬A i ϕ ⇔ L i ¬A i ϕ (MP) If ϕ ⇒ ψ and ϕ then ψ (Nec) If ϕ then L i ϕ Figure 3</formula><p>. Axiomatic system of the logic of awareness <ref type="bibr" target="#b73">(Schipper, 2014)</ref> </p></div>
<div><head n="4.">A modal logic for manipulation</head><p>In this section, we propose a logic to represent the notion of manipulation as it has been defined in Section 2.1. Let us remark our goal is not to propose a definitive logic but rather to provide the basic elements to express such definition and disambiguate this concept.</p><p>To this end, we consider a logic with several modalities: deliberate effects, consequences of actions, belief and knowledge. One of the main element of this logic is the deliberate effect operator. Indeed, we require that this operator must have: (1) negative and positive introspection; (2) side-effect free; (3) the conjunction of all deliberate effects forms a deliberate effect. As written previously, STIT semantic catches all (direct and indirect) consequences of actions while BIAT semantics catches the deliberate effects. Moreover, since BIAT is side-effect free and makes it easy to express positive and negative introspection and also the conjunction of all deliberate effects forms a deliberate effect, we distinguish a modality of deliberate effects (expressed by a BIAT-like modality denoted E d i in the sequel) from a modality that catches all consequences of performed actions (expressed by a STIT-like modality denoted E i in the sequel). Thanks to these modalities, combined with knowledge and belief, we are able to express instrumentalization and concealment. Furthermore distinguishing an epistemic modal operator from a belief operator allows us to define different levels of concealment. Then, we chose to not introduce an awareness operator explicitly in the language and prefer to keep the logic simple. Finally, we also do not want the modality of future which increases the complexity of the model.</p></div>
<div><head n="4.1.">Language</head><p>Let P = {a, b, c, . . .} be a set of propositional letters, N be a finite set of agents with two agents i, j ∈ N , and p ∈ P be a propositional variable. We define L KBE the language with the following BNF grammar rule:</p><formula xml:id="formula_33">ϕ ::= p | ¬ϕ | (ϕ ∨ ϕ) | (ϕ ∧ ϕ) | (ϕ ⇒ ϕ) | K i ϕ | B i ϕ | E i ϕ | E d i ϕ</formula><p>The formula E i ϕ means that the actions of i lead to ϕ. So E i represents the effects of actions which may have been deliberated or not such as side-effects. The formula E d i ϕ means<ref type="foot" target="#foot_2">3</ref> that agent i deliberately brings it about that ϕ. This modality is semantically represented with a neighborhood function which associates a set of possible worlds for each deliberate effect. Finally the formulas K i ϕ and B i ϕ mean respectively that the agent knows that ϕ, and the agent believes that ϕ. We note the dual operators as following:</p><formula xml:id="formula_34">K i ϕ = ¬K i ¬ϕ, B i ϕ = ¬B i ¬ϕ, E i ϕ = ¬E i ¬ϕ and E d i ϕ = ¬E d i ¬ϕ.</formula></div>
<div><head n="4.2.">Associated semantics</head><p>We consider the following logical frame:</p><formula xml:id="formula_35">C = (W, {B i } i∈N , {K i } i∈N , {E i } i∈N , {E d i } i∈N )</formula><p>where W is a nonempty set of possible worlds, {B i } i∈N , {K i } i∈N , {E i } i∈N are sets of binary relationships, and</p><formula xml:id="formula_36">{E d i } i∈N is a set of neighborhood functions, i.e.: ∀i ∈ N , E d i : W → 2 2 W</formula><p>The reasons why we consider neighborhood functions for the deliberate brings it about semantics are twofold. Firstly, neighborhood semantics allow us to be free from the necessitation since we do not want to express that the agent deliberately brings it about a tautology. Secondly, the neighborhood functions translate semantically sets of possible worlds that results from strategies deliberated by the agent. In this case, each set of possible worlds corresponds to the deliberate effects of those strategies.</p><p>We define a model as</p><formula xml:id="formula_37">M = (W, {B i } i∈N , {K i } i∈N , {E i } i∈N , {E d i } i∈N , V</formula><p>) with V : P → 2 W an interpretation function. For all w ∈ W, ϕ, ψ ∈ L KBE , and p ∈ P, we inductively define M, w |= ϕ as:</p><formula xml:id="formula_38">(1) M, w |= (2) M, w |= ⊥ (3) M, w |= p iff w ∈ V (p) (4) M, w |= ¬ϕ iff M, w |= ϕ (5) M, w |= ϕ ∨ ψ iff M, w |= ϕ or M, w |= ψ (6) M, w |= ϕ ∧ ψ iff M, w |= ϕ and M, w |= ψ (7) M, w |= ϕ ⇒ ψ iff M, w |= ¬ϕ or M, w |= ψ (8) M, w |= B i ϕ iff ∀v ∈ W, wB i v : M, v |= ϕ (9) M, w |= K i ϕ iff ∀v ∈ W, wK i v : M, v |= ϕ (10) M, w |= E i ϕ iff ∀v ∈ W, wE i v : M, v |= ϕ (11) M, w |= E d i ϕ iff ||ϕ|| ∈ E d i (w) with ||ϕ|| := {v ∈ W : M, v |= ϕ}</formula><p>Let us detail the difference between rule (10) and rule (11). We do not want to express that an agent deliberately brings it about a tautology. Thus, since the rule ( <ref type="formula">11</ref>) is defined on a neighborhood function, it allows E d i to be freed from necessitation, while since the rule (10) characterizes a normal modality, the necessitation holds.</p><p>We also consider a dual notion of deliberate effects, denoted E d i , which translates "it is possible that one agent deliberately brings it about something as he does not deliberately brings it about the contrary". Formally, we write </p></div>
<div><head n="4.2.1.">Semantics for beliefs and knowledge</head><p>For the modalities of knowledge and belief, we conventionally constrain our frame C so that, for any agent i ∈ N , K i is reflexive, transitive and confluent<ref type="foot" target="#foot_3">4</ref> and B i is serial, transitive and Euclidean. The constraints and relations between these two modalities have already been well studied <ref type="bibr" target="#b77">(Stalnaker, 2006)</ref>. Thus, we first consider that an agent i believes what it knows, namely:</p><formula xml:id="formula_39">∀w ∈ W : B i (w) ⊆ K i (w) (KB1)</formula><p>If an agent believes something then it knows it believes it:</p><formula xml:id="formula_40">∀w, u, v ∈ W : wK i u ∧ uB i v ⇒ wB i v (KB2)</formula><p>In the same way, an agent knows what it does not believe:</p><formula xml:id="formula_41">∀w, u, v ∈ W : wK i u ∧ wB i v ⇒ uB i v (KB3)</formula></div>
<div><head n="4.2.2.">Semantics for the effects of actions</head><p>It is commonly accepted to consider the effects of action as an equivalence relationships, such as in STIT. Thus, for any agent i ∈ N , E i is a reflexive, transitive and Euclidean relationship<ref type="foot" target="#foot_4">5</ref> . Indeed, when an agent implements one or more actions, if he has carried them out, it means that this is the case and that the consequence ϕ is true. The reflexivity, denoted (E1), expresses the fact that once the actions leading to a certain ϕ consequence have been performed by an agent i, then that consequence ϕ is necessarily true in the current world. This constraint (E1) gives the axiom T. ∀w ∈ W : wE i w (E1)</p><p>From this constraint, we immediately deduce that this relation E i is also serial. This translates that if an agent i ensures that one or several actions lead to a certain consequence ϕ, it is not the case that this action or series of actions can lead to the opposite in the current world. So we deduce in such a system the property D. The relation E i is also transitive since when the actions of agent i lead to ϕ, these actions also lead to the fact that these actions are done properly, i.e.:</p><formula xml:id="formula_42">∀w, u, v ∈ W : wE i u ∧ uE i v ⇒ wE i v (E2)</formula><p>Finally, if an agent i does not perform actions that lead to some consequences ϕ, then agent i indirectly performs actions that lead to not realize the actions that lead to ϕ. Thus the relation E i is Euclidean, i.e.:</p><formula xml:id="formula_43">∀w, u, v ∈ W : wE i u ∧ wE i v ⇒ uE i v (E3)</formula><p>Let us notice that we do not consider positive and negative introspection with knowledge because since E i represents the effects of actions, some effects may not be known by the agent i as side-effects.</p></div>
<div><head n="4.2.3.">Semantic representation of deliberate effects</head><p>While the effects of actions are represented as an equivalence relationship, we represent deliberate effects as a neighborhood function. This semantic difference is justified by the fact that when an agent deliberately brings it about something, the latter considers as many sets of possible worlds as deliberate effects which has been carried out. Moreover, Kripke's relations do not allow us to express the fact that an agent cannot deliberately bring it about something that he always knows to be true, such as tautologies. It is due to the principle of necessity which is valid in any Kripke frame.</p><p>Thus, the first semantic difference with the E i modality is that an agent i cannot deliberately bring it about that a tautology to be true since he knows it is always true. This constraint, denoted E d N ec , is semantically translated by the fact that the set of all possible worlds cannot belong to any neighborhood, i.e.:</p><formula xml:id="formula_44">∀w ∈ W : W ∈ E d i (w) (E d N ec )</formula><p>Moreover, there is a logical link between the modality of deliberate effects and that of the effects of actions that may or may not be deliberate. Indeed, if an agent i deliberately brings it about some action, then this agent does these actions. It is represented by the constraint E d E which is semantically translated by the fact that all the possible worlds reachable by the relation E i are always included in all possible worlds sets of E d i , i.e.:</p><formula xml:id="formula_45">∀w ∈ W : S ∈ E d i (w) ⇒ E i (w) ⊆ S (E d E)</formula><p>When an agent i deliberately brings it about that a proposition ϕ to be true while deliberately bringing it about that another proposition ψ to be true, then that agent i deliberately brings it about that ϕ ∧ ψ to be true, i.e.:</p><formula xml:id="formula_46">∀w ∈ W : S ∈ E d i (w) ∧ T ∈ E d i (w) =⇒ S ∩ T ∈ E d i (w) (E ⇒,∧ )</formula><p>However, we cannot consider the reciprocal of (E ⇒,∧ ) because deliberate effects concern a whole and cannot be considered as the sum of its part. For example, when somebody decides to eat a hazelnut cake, he does not decide to deliberately eat the dough of the cake and eat the hazelnuts independently. Moreover, this reciprocal, defined by ∀w ∈ W :</p><formula xml:id="formula_47">S ∩ T ∈ E d i (w) =⇒ S ∈ E d i (w) ∧ T ∈ E d i (w) and associated with the theorem E d i (ϕ ∧ ψ) ⇒ E d i ϕ ∧ E d i ψ, cannot be considered for technical reasons. Indeed, an immediate result is that such constraint is equivalent to ∀w ∈ W : S ∈ E d i (w) ∧ S ⊆ T =⇒ T ∈ E d i (w)</formula><p>. Hence, if this reciprocal is considered, we would get an inconsistent logical system due to the constraint (E d N ec ).</p><p>Finally, an essential characteristic of deliberate effects is that it is introspective to the knowledge of agents. An agent always knows what it is doing and what it is not doing deliberately. Thus, the deliberate effect modality has positive (E d KP ) and negative introspection (E d KN ) with respect to the knowledge of the agent, i.e.:</p><formula xml:id="formula_48">∀w ∈ W : E d i (w) ⊆ v∈W:wKiv E d i (v) (E d KP ) ∀w, v ∈ W, ∀S ∈ 2 W : S ∈ E d i (w) =⇒ (wK i v ⇒ S ∈ E d i (v)) (E d KN )</formula><p>These constraints mean that when an agent i deliberately brings it about a consequence, she knows what she is doing deliberately. The same is true when an agent i does not deliberately bring it about that a consequence, then the agent i knows that she did not do it deliberately. Furthermore, let us notice that (E d KN ) is equivalent to:</p><formula xml:id="formula_49">∀w ∈ W, ∀S ∈ 2 W : S ∈ E d i (w) =⇒ S ∈ v∈W:wKiv E d i (v) (E d KN )</formula><p>Or simply by contraposition, (E d KN ) can be rewritten as:</p><formula xml:id="formula_50">∀w ∈ W, ∀S ∈ 2 W : v∈W:wKiv E d i (v) ⊆ E d i (w) (E d KN )</formula><p>Thus, we can deduce the following theorems, whose proofs are given in Appendix A.1:</p><formula xml:id="formula_51">Proposition 4.1. If (E d KN )</formula><p>and (E d KP ) hold at the same time, then it implies on the Kripke structure that the following property holds:</p><formula xml:id="formula_52">∀w ∈ W : E d i (w) = v∈W:wKiv E d i (v) = v∈W:wKiv E d i (v) (E d KN ) + (E d KP )</formula><p>Proposition 4.2.</p><p>(1) If (E d KP ) holds and K i is reflexive, then:</p><formula xml:id="formula_53">∀w ∈ W, E d i (w) = v∈W:wKiv E d i (v) (2) If (E d KN )</formula><p>holds and K i is reflexive, then:</p><formula xml:id="formula_54">∀w ∈ W, E d i (w) = v∈W:wKiv E d i (v)</formula><p>However considering for instance only the property (1) is not enough to verify that (E d KN ) and (E d KP ) hold at the same time. Thus, we can say that (E d KN ) is stronger than considering an equivalence between intersections. Indeed, (E d KN ) translates exactly that if an agent does not deliberate something, then it cannot be the case for all indistinguishable worlds by the epistemic relationship.</p></div>
<div><head n="4.2.4.">Illustration of semantic relations</head><p>Example 4.3 illustrates the fundamental differences between deliberate and nondeliberate effects. A deliberate effect is characterized as a calculated choice of an agent to achieve something, making the agent fully aware of the consequences, whereas a non-deliberate effect represents the set of all consequences of the actions of the agent which may be deliberate or not. Thus, the agent does not necessarily have knowledge of all these consequences.</p><p>Example 4.3. Suppose a situation in which there is a murderer i that deliberately brings it about to kill a victim j. In order to represent this situation we consider three propositional variables: p denotes that "the agent kills the victim by stabbing her", q denotes that "the agent gets arrested by the police", and r denotes that "there is no witness". For this situation, there are several possible worlds, for example, agent i kills the victim and does not get stopped by the police, the victim was already dead before the agent stabs her, agent i is remorseful and does not kill the victim, or the victim j wakes up and makes agent i run away, etc. Let us assume that a model M describes all of these possible worlds. Obviously we could consider a large number of possible worlds to describe this example, but for the sake of clarity, we consider only a small number of possible worlds. Let us assume M is such that:</p><formula xml:id="formula_55">• W = {w, u, v, x, y, z, a} • V (p) = {w, u, v}, V (q) = {v, y, z}, V (r) = {w, x, y, z, a}</formula><p>The possible worlds are:</p><p>• w: "there is no witness, agent i kills the victim j and does not get arrested" • u: "there is a witness and agent i kills the victim j but does not get arrested" • v: "there is a witness and agent i kills the victim j and agent i gets arrested" • x: "the victim was already dead, no witness, and i does not get arrested" • y: "the victim was already dead, no witness, and agent i gets arrested" • z: "the killer is remorseful, no witness, and does not kill the victim, but agent i still gets arrested for attempted murder" • a: "no murder"</p><p>In the possible world w, the agent i therefore has a deliberate effect to kill the victim. In addition, he also takes care that there is no witness. So the neighborhood function is such that E d i (w) = {{w, u, v}, {w, x, y, z, a}}. It represents each independent strategy that agent i intended to implement in w:</p><p>• {w, u, v} represents the deliberate effect by agent i to kill the victim; • {w, x, y, z, a} represents the deliberate effect by agent i to ensure that there is no witness at the crime scene.</p><p>In the world w, agent i successfully manages to kill the victim without getting caught, so E i (w) = {w}. Furthermore in w, since agent i deliberately brings it about that there were no witness, we infer that the agent knows that p and r are true. So we have K i (w) = {w}, the only possible world where p and r are true simultaneously. The agent i cannot discern in w any other world than this one. Moreover in w, the agent knows that the police does not arrest him.</p><p>Let us remark that in this model semantics constraints, e.g. ∀w ∈ W : S ∈ E d i (w) ⇒ E i (w) ⊆ S, are naturally satisfied and illustrate the fact that since agent i deliberately brings it about in w to kill the victim, then this agent i deliberately brings it about that the victim is killed. Furthermore, since ||p|| ∈ E d i (w) we have M, w |= E d i p, i.e. agent i deliberately brings it about to kill the victim. Since the agent's strategic choice was to succeed in killing the victim, he set up a strategy to make p true.</p></div>
<div><head n="4.3.">Associated axiomatic system</head><p>Given the constraints on our frame, the associated axiomatic system is given in Fig- <ref type="figure">ure 4</ref>. Here, ϕ means that ϕ is a theorem. For all modalities ∈ {K i , B i , E i , E d i }, we have the modus ponens (M P ), the substitution (SU B) and the rule of inference (RE), i.e. from ϕ ⇔ ψ, we infer ϕ ⇔ ψ. However, the rule of necessitation (N EC) is only verified for normal modalities, i.e. for all ∈ {K i , B i , E i }, from ϕ, we infer ϕ. Finally, we have duality (DU AL), i.e. for all ( ,</p><formula xml:id="formula_56">♦) ∈ {(B i , B i ), (K i , K i ), (E i , E i ), (E d i , E d i )}, ϕ ⇔ ¬♦¬ϕ. (PC) All tautologies of Propositional Calculus (S4 Ki ) All S4-axioms for K i (4.2 Ki ) K i K i ϕ ⇒ K i K i ϕ (KD45 Bi ) All KD45-axioms 6 for B i (S5 Ei ) All S5-axioms for E i (K i B i ) K i ϕ ⇒ B i ϕ (4 Ki,Bi ) B i ϕ ⇒ K i B i ϕ (5 Ki,Bi ) ¬B i ϕ ⇒ K i ¬B i ϕ (E d i E i ) E d i ϕ ⇒ E i ϕ (C E d i ) E d i ϕ ∧ E d i ψ ⇒ E d i (ϕ ∧ ψ) (¬N E d i ) ¬E d i (4 Ki,E d i ) E d i ϕ ⇒ K i E d i ϕ (5 Ki,E d i ) ¬E d i ϕ ⇒ K i ¬E d i ϕ Figure 4. Axiomatic system KBE</formula><p>From Figure <ref type="figure">4</ref>, one may wonder if deliberate effect modality E d i may be expressed with the non-deliberate modality E i and a combination of modalities K i , B i or another modality expressing intention? It is not the case because, (1) as we consider a S4.2 system for knowledge, we do not have the negative introspection on K i E i ϕ while we want it; (2) B i E i ϕ does not satisfy the axiom T while E d i satisfies it, which will be shown in Section 4.6; (3) an intention modality I i such has the one proposed by <ref type="bibr" target="#b70">Sakama et al. (2015)</ref> will satisfy the necessitation on I i E i ϕ which is a problem.</p></div>
<div><head n="4.4.">Soundness</head><p>It is well known that the semantics of a normal modality of a S5 system that preserves validity is an equivalence relation <ref type="bibr" target="#b10">(Blackburn et al., 2002)</ref>. Since the relation E i is an equivalence relation, the rules of S5 preserve the validity. Then a relation K i which is reflexive, transitive and confluent is sound as it is a S4.2 system. Concerning the inference rules between the modality K i and B i , <ref type="bibr" target="#b77">Stalnaker (2006)</ref> showed they are valid in our logical frame. Moreover, it is well known that a serial, transitive and Euclidean relation preserves the validity of a KD45 system for the modality B i . Thus, in this section, we only focus on the non-normal properties associated with the neighborhood semantics E d i . The following properties are in Pacuit ( <ref type="formula">2017</ref>):</p><formula xml:id="formula_57">(1) C |= ¬E d i iff ∀w ∈ W : W ∈ E d i (w) (2) C |= E d i p ∧ E d i q ⇒ E d i (p ∧ q) iff: ∀w ∈ W : S ∈ E d i (w) ∧ T ∈ E d i (w) =⇒ S ∩ T ∈ E d i (w)</formula><p>Other properties are standard to prove by using contraposition. Consequently it is straightforward to prove that our KBE system is sound. The complete proof is detailed in Appendix A.2.</p><p>Theorem 4.4. The KBE system is sound.</p></div>
<div><head n="4.5.">KBE Completeness</head><p>In order to prove that our system is complete, we apply a Henkin-like proof method by building a canonical model which relies on Maximal Consistent Sets (MCS) and a notion of minimal canonical model for neighborhood semantics <ref type="bibr" target="#b57">(Pacuit, 2017)</ref>.</p><p>Theorem 4.5. The KBE system is complete.</p><p>The complete proof can be found in Appendix A.3. Moreover the KBE system has the deduction theorem, is strongly complete and strongly sound <ref type="bibr" target="#b10">(Blackburn et al., 2002;</ref><ref type="bibr" target="#b57">Pacuit, 2017)</ref>. For the interested reader, the proofs are given in Appendix A.4.</p></div>
<div><head n="4.6.">Deductible theorems</head><p>Let us remark that (D) and (T ) can be derived for E d i . It means that one agent i cannot deliberately bring about something and its opposite, and that when an agent i deliberately brings about ϕ, he makes ϕ to be true. In particular, it makes beliefs equivalent to knowledge for the special case of the deliberate effect modality. It means that an agent cannot have false beliefs concerning the formulas he deliberately brings about. It is given by the following theorem; the complete proofs are given in Appendix A.5.</p><p>Theorem 4.6.</p><p>(1)</p><formula xml:id="formula_58">¬E d i ⊥ (D E d i ) (2) E d i ϕ ⇒ ϕ (T E d i ) (3) K i E d i ϕ ⇔ E d i ϕ (4) K i ¬E d i ϕ ⇔ ¬E d i ϕ (5) ¬K i E d i ϕ ⇔ ¬E d i ϕ (6) ¬K i ¬E d i ϕ ⇔ E d i ϕ (7) B i E d i ϕ ⇔ E d i ϕ (8) B i ¬E d i ϕ ⇔ ¬E d i ϕ (9) ¬B i E d i ϕ ⇔ ¬E d i ϕ (10) ¬B i ¬E d i ϕ ⇔ E d i ϕ</formula><p>We can also show that any agent i, when it deliberately brings it about that another agent j believes something, this agent i also brings it about that the agent j cannot believe that this agent i can know the opposite. Such a theorem translates that when an agent seeks to convey new beliefs, whether they are true or false in the case of lies, that agent always brings it about that he is credible to the other agent.</p><p>Theorem 4.7.</p><p>(1) concealing contrary beliefs:</p><formula xml:id="formula_59">E d i B j ϕ ⇒ E i ¬B j K k ¬ϕ (2) concealing knowledge: E d i ¬B j ϕ ⇒ E i ¬B j K k ϕ</formula><p>The complete proofs are given in Appendix A.5. Other interesting theorems can also be deduced. Moreover, when an agent deliberately brings it about that another agent believes something, then it cannot be the case that the agent deliberately brings it about the other to believe that a third-party agent can know the opposite.</p><p>Theorem 4.8.</p><p>(1) An agent who deliberately influences the beliefs of an agent cannot have deliberated to show that other agents, including himself, may hold the opposite, i.e.:</p><formula xml:id="formula_60">E d i B j ϕ ⇒ ¬E d i B j K k ¬ϕ</formula><p>(2) An agent who deliberately brings it about that another agent does not believe a piece of information, cannot also deliberately bring it about that the agent knows that a third-party agent holds the opposite, i.e.:</p><formula xml:id="formula_61">E d i ¬B j ϕ ⇒ ¬E d i B j K k ϕ</formula><p>As previously, the complete proofs are given in Appendix A.5. These theorems tell us that when an agent i brings it about new beliefs in another agent j, they also maintained consistency (i.e. by preventing j to know that a third party agent may know the opposite as it is the case for i). Let us notice that E d i ¬K j ϕ ⇒ E i ¬K j K k ϕ is also a theorem by following the same method as in 4.2. Moreover, as the contraposition of</p><formula xml:id="formula_62">K k ϕ ⇒ B k ϕ is ¬B k ϕ ⇒ ¬K k ϕ and E d i ϕ ⇒ E i ϕ is ¬E i ϕ ⇒ ¬E d i ϕ,</formula><p>we deduce two immediate corollaries to these theorems:</p><p>(1)</p><formula xml:id="formula_63">E d i B j ϕ ⇒ ¬E d i K j K k ¬ϕ (2) E d i ¬B j ϕ ⇒ ¬E d i K j K k ϕ</formula><p>In the KBE system, we can also deduce the qui facit per alium facit per se principle, i.e. "he who acts through another does the act himself". Theorem 4.9 (Qui facit per alium facit per se).</p><formula xml:id="formula_64">(E d i E j ϕ ∨ E d i E d j ϕ) ⇒ E i ϕ</formula><p>This theorem means that an agent influencing another agent to act illegally also acts illegally itself. Thus in a legal context, an influencer is also responsible for illegal acts perpetrated by the influenced agent. Therefore, the influencer has some responsibility in these acts committed by this principle.</p></div>
<div><head n="5.">Modeling manipulations</head><p>In this section we first define formally what a manipulation is. Secondly we show our logical framework can also model coercion, persuasion and some forms of deception, and thus is consistent with "manipulation is not exactly coercion, not precisely persuasion, and not entirely similar to deception" <ref type="bibr" target="#b30">(Handelman, 2009)</ref>.</p></div>
<div><head n="5.1.">Different kinds of manipulation</head><p>In terms of manipulation, a manipulator always intends to influence the intentions: by pushing his victim to do something, or by preventing his victim from doing something. It is the instrumentalization involved in Definition 2.1. Moreover, the manipulator always deliberately brings it about to conceal this instrumentalization. Thus, we can characterize manipulation depending on (1) what the manipulator wanted the victim to realize; (2) whether the victim deliberately brings it about to realize the manipulator's will; (3) how the manipulator intended to conceal. Hence, we consider constructive manipulations to be those where the manipulator brings about his victim to do something, and destructive manipulations when the manipulator aims at preventing an agent from doing something. Since manipulation is a deliberate effect of the manipulator, we also need to distinguish between bringing about another agent to do something in a deliberate way from doing it in an unintentional way. Thus, when the manipulator deliberately brings about the manipulated agent to deliberately bringing it about something, it relies on a strong instrumentalization. When the manipulator deliberately brings about the manipulated agent to do something in general, it relies on a soft instrumentalization. Finally we distinguish different forms of manipulation depending on whether the dissimulation is based on knowledge or beliefs: we call an epistemic concealment when the manipulator aims at preventing the victim to know his effects, and a doxastic concealment when the manipulator aims at preventing the victim from believing his intentions.</p><p>Tables <ref type="table">2</ref> and<ref type="table" target="#tab_1">3</ref> present different ways of expressing instrumentalization and concealment in the case of constructive manipulations and the case of destructive manipulations.</p></div>
<div><head>Instrumentalization Concealment</head><formula xml:id="formula_65">Strong (E d i E d j ϕ) Epistemic (E d i ¬K j E d i E d j ϕ) Soft (E d i E j ϕ) Epistemic (E d i ¬K j E d i E j ϕ) Strong (E d i E d j ϕ) Doxastic (E d i ¬B j E d i E d j ϕ) Soft (E d i E j ϕ) Doxastic (E d i ¬B j E d i E j ϕ) Table 2</formula></div>
<div><head>. Constructive forms of manipulation</head><p>Table <ref type="table">2</ref> shows the different components of a constructive manipulation. For example, a strong instrumentalization is represented by the formula E d i E d j ϕ. Literally, this formula describes that the agent i employed a strategy leading the agent j deliberately bringing it about the consequence ϕ. A soft instrumentalization can be represented by the formula E d i E j ϕ. Finally, in the case of constructive manipulations, an epistemic concealment can be represented by the formula E d i ¬K j E d i E j ϕ and a doxastic concealment by the formula E d i ¬B j E d i E j ϕ. Table <ref type="table" target="#tab_1">3</ref> describes the different components when a manipulation is destructive. For example, in this case of destructive manipulations, soft instrumentalization is Let us that notice that, for both constructive and destructive manipulations, an agent i cannot manipulate another agent j to deliberately brings about ϕ while concealing i deliberately brings j about bringing about ϕ as a side-effect (and inversely). This is due to the definition of manipulation we consider (see Definition 2.1): there is a manipulation when the effect of intrumentalization is the effect which is concealed. Thus, combining both a strong instrumentalization with the corresponding "soft" epistemic (or doxastic) and the soft instrumentalization with the corresponding "strong" epistemic (or doxastic) does not make sense.</p><formula xml:id="formula_66">Instrumentalization Concealment Strong (E d i ¬E d j ϕ) Epistemic (E d i ¬K j E d i ¬E d j ϕ) Soft (E d i ¬E j ϕ) Epistemic (E d i ¬K j E d i ¬E j ϕ) Strong (E d i ¬E d j ϕ) Doxastic (E d i ¬B j E d i ¬E d j ϕ) Soft (E d i ¬E j ϕ) Doxastic (E d i ¬B j E d i ¬E j ϕ)</formula></div>
<div><head n="5.1.1.">The set of formulas Σ</head><p>In the sequel, we combine these different forms of instrumentalization and concealment to define all the forms of manipulation that can be expressed in KBE. Since we use a non-normal modality for E d i which does not have the theorem (ϕ ∧ ψ) ≡ ϕ ∧ ψ, we have to consider all other possible formulas that this agent may deliberately bring about at the same time. Indeed, an agent can manipulate another one while deliberately bringing about something else. However, without this theorem, we cannot deduce manipulation alone in this situation. One way to deal with this problem is to consider an explicit set of formulas on which we (as designers) allow the logic to reason, and to use this set to define predicates for manipulation. However, this set must be finite, otherwise the formulas that will characterize manipulation cannot be well-formed.</p><p>Thus, we introduce a set of formulas Σ which is finite, closed, and which contains P ∪ { , ⊥}. We consider the closure as <ref type="bibr" target="#b10">Blackburn et al. (2002)</ref>: a set of formulas Σ is said to be closed if, and only if, (1) if σ ∈ Σ and θ is a subformula of σ, then θ ∈ Σ and (2) if σ ∈ Σ and σ is not of the form ¬θ, then ¬σ ∈ Σ. While Σ may be arbitrarily instantiated, it makes sense to ground it on a action-effect knowledge base: Σ shall be the closed set of all subformulas of this knowledge base. In order to manipulate the predicates that will use in the next sections a Σ-set, we introduce a new operator to define a conjunctive Cartesian product between two sets of formulas, i.e. Σ Γ := {σ ∧ γ : σ ∈ Σ, γ ∈ Γ}. This operator will allow us to rewrite these predicates in order to highlight logical relations between related concepts, as for instance between strong instrumentalization and the persuasion predicate.</p></div>
<div><head n="5.1.2.">Soft constructive manipulations</head><p>A soft constructive manipulation with epistemic concealment, denoted M CEK Σ i,j (ϕ), is when a manipulator deliberately brings the victim about doing something while making sure that the victim does not know the deliberate effects of the manipulator. Here, ϕ ∈ Σ and must be consistent. A soft constructive manipulation with doxastic concealment -denoted M CEB Σ i,j (ϕ) below -is defined similarly but, in this case, the manipulator deliberately brings it about that the victim does not believe his deliberate effects. Formally, we define these manipulation forms such as:</p><formula xml:id="formula_67">M CEK Σ i,j (ϕ) = ψ∈Σ E d i (E j ϕ ∧ ¬K j E d i E j ϕ ∧ ψ) M CEB Σ i,j (ϕ) = ψ∈Σ E d i (E j ϕ ∧ ¬B j E d i E j ϕ ∧ ψ)</formula><p>Let us notice that ψ represents all formulas from Σ which do not contradict</p><formula xml:id="formula_68">E j ϕ ∧ ¬K j E d i E j ϕ. Indeed, if ψ contradicts E j ϕ ∧ ¬K j E d i E j ϕ, then we immediately deduce that E d i ⊥.</formula><p>However it is necessarily false due to the theorem ¬E d i ⊥.</p></div>
<div><head n="5.1.3.">Strong constructive manipulations</head><p>A strong constructive manipulation with epistemic concealment is denoted with M CE d K Σ i,j (ϕ), and is when the manipulator brings the other agent about doing something in a deliberate way while making sure that the victim does not know the deliberate effects of the manipulator. A strong constructive manipulation with doxastic concealment -denoted M CE d B Σ i,j (ϕ) below -is similar but, in this case, the manipulator makes sure that the victim does not believe his effects. Formally,</p><formula xml:id="formula_69">M CE d K Σ i,j (ϕ) = ψ∈Σ E d i (E d j ϕ ∧ ¬K j E d i E d j ϕ ∧ ψ) M CE d B Σ i,j (ϕ) = ψ∈Σ E d i (E d j ϕ ∧ ¬B j E d i E d j ϕ ∧ ψ)</formula><p>Example 5.1. Let us illustrate this predicate with an example related to advertising. An advertiser always intends to bring new customers about buying a product. These intentions are not concealed and therefore we cannot speak of manipulation. On the other hand, it becomes manipulation when the advertiser uses concealed sales techniques such as, for example, the use of subliminal images. Thus, the advertiser does not seek to conceal his intention to bring the customer about buying the product, but to deliberately conceal the technique he uses to bring the customer about buying. If the agent i is the advertiser, E d i represents his strategy of using subliminal images to get the customer j to buy a product. The customer does not know that the advertiser has used these images. Thus, if ϕ := "the product is bought", then this situation of manipulation is fully described by the formula</p><formula xml:id="formula_70">E d i (E j ϕ ∧ ¬K j E d i E j ϕ).</formula></div>
<div><head n="5.1.4.">Strong and soft destructive manipulations</head><p>As said in the introduction, another way to see manipulation is to consider that a manipulator may deliberately prevent the victim from doing something. We call this kind of manipulation a destructive manipulation. As previous, destructive manipulation can be declined in soft and strong destructive manipulations with either epistemic, or doxastic concealment. Formally,</p><formula xml:id="formula_71">M DEK Σ i,j (ϕ) = ψ∈Σ E d i (¬E j ϕ ∧ ¬K j E d i ¬E j ϕ ∧ ψ) M DE d K Σ i,j (ϕ) = ψ∈Σ E d i (¬E d j ϕ ∧ ¬K j E d i ¬E d j ϕ ∧ ψ) M DEB Σ i,j (ϕ) = ψ∈Σ E d i (¬E j ϕ ∧ ¬B j E d i ¬E j ϕ ∧ ψ) M DE d B Σ i,j (ϕ) = ψ∈Σ E d i (¬E d j ϕ ∧ ¬B j E d i ¬E d j ϕ ∧ ψ)</formula><p>Example 5.2. An example of destructive manipulation is illustrated by the case of eclipse attacks <ref type="bibr" target="#b75">(Singh, Ngan, Druschel, &amp; Wallach, 2006)</ref>. These attacks consist in isolating an agent in order to exclude it from a network. This type of manipulation is captured by destructive manipulation. Indeed, the hacker makes sure at the moment of the attack that the target node can no longer communicate with other nodes in the network (i.e. E d i ¬E j ϕ with ϕ any communicable information) while making sure that he does not know that he is at that moment under the instance of an attack (i.e. E d i ¬K j E d i ¬E j ϕ).</p></div>
<div><head n="5.1.5.">A general definition of manipulation</head><p>Finally, all these definitions can be merged in a general definition of manipulation:</p><formula xml:id="formula_72">M Σ i,j (ϕ) = ∈{B,K} M CE Σ i,j (ϕ) ∨ M CE d Σ i,j (ϕ) ∨ M DE Σ i,j (ϕ) ∨ M DE d Σ i,j (ϕ)</formula></div>
<div><head n="5.2.">Some properties of manipulation</head><p>In this section, we exhibit some properties of the above definitions.</p></div>
<div><head n="5.2.1.">Believing being influenced</head><p>Obvioulsy, if an agent is a victim of an epistemic (resp. doxastic) manipulation, he cannot know (resp. believe) he is instrumentalized. However, an agent can believe he is instrumentalized while being a victim of an epistemic manipulation. It means that the victim may believe to be instrumentalized while being unable to prove it, i.e. it is not the case the agent knows he is instrumentalized. Indeed, when a child cries to get a new toy from his parents, the parents may believe the child deliberately puts himself in this state but cannot be sure it is the case. It is given by the following theorem for the soft epistemic constructive manipulation.</p><formula xml:id="formula_73">Theorem 5.3. |= M CEK Σ i,j (ϕ) ∧ B j E d i E j ϕ ⇒ ⊥</formula><p>This property is obvious because there is no contradiction between ¬K j E d i E j ϕ and B j E d i E j ϕ. The same property holds for the other forms of manipulation with epistemic concealment, i.e. strong epistemic and destructive manipulation.</p></div>
<div><head n="5.2.2.">Knowing being influenced</head><p>Interestingly, an agent can be victim of a manipulation while knowing he is influenced. In this case, the agent does not know (resp. believe) he is instrumentalized, i.e. the manipulator deliberately brings the victim about bringing about something, but he can know the manipulator influenced him. Indeed, the manipulation conceals the deliberate intention of the the manipulator, but not the influence in itself. It is given by the following theorem.</p><formula xml:id="formula_74">Theorem 5.4. |= M CEK Σ i,j (ϕ) ∧ K j E i E j ϕ ⇒ ⊥</formula><p>This property is obvious as there is no contradiction between ¬K j E d i E j ϕ and K j E i E j ϕ. The same property holds for the other forms of manipulation. Let us consider the previous example: when the child cries to get a new toy from his parents, the parents can know the cries influence them while not knowing the child deliberately puts himself in this state to affect them.</p></div>
<div><head n="5.2.3.">Knowing or believing the effects of a manipulation</head><p>If an agent is strongly manipulated in a constructive way to bring himself about a formula ϕ, he knows that ϕ, and cannot know or believe ¬ϕ. Indeed, while a manipulation conceals the instrumentalization, it does not conceal its effect, i.e. the fact that the victim brings about ϕ.</p><p>Theorem 5.5.</p><formula xml:id="formula_75">(1) (M CE d K Σ i,j (ϕ) ∨ M CE d B Σ i,j (ϕ)) ∧ K j ¬ϕ ⇒ ⊥ (2) (M CE d K Σ i,j (ϕ) ∨ M CE d B Σ i,j (ϕ)) ∧ B j ¬ϕ ⇒ ⊥ (3) (M CE d K Σ i,j (ϕ) ∨ M CE d B Σ i,j (ϕ)) ⇒ K j ϕ</formula><p>The proofs are given in Appendix A.6. Let us notice that those properties do not hold for the soft or destructive manipulations.</p></div>
<div><head n="5.2.4.">Interactions between deliberate and non-deliberate effects</head><p>When the goal ϕ of a manipulation consists in bringing the victim about another formula ϕ , some form of manipulation may be reduced while some others allow us to express particular situations depending if it is a soft or strong manipulation.</p><p>In the case of soft manipulation:</p><p>Theorem 5.6.</p><p>(</p><formula xml:id="formula_76">) M CEK Σ i,j (E j ϕ) ⇔ M CEK Σ i,j (ϕ) (2) M CEK Σ i,j (¬E j ϕ) ⇔ M DEK Σ i,j (ϕ) (3) M CEB Σ i,j (E j ϕ) ⇔ M CEB Σ i,j (ϕ) (4) M CEB Σ i,j (¬E j ϕ) ⇔ M DEB Σ i,j (ϕ) (5) M DEK Σ i,j (E j ϕ) ⇔ M DEK Σ i,j (ϕ) (6) M DEK Σ i,j (¬E j ϕ) ⇔ M CEK Σ i,j (ϕ) (7) M DEB Σ i,j (E j ϕ) ⇔ M DEB Σ i,j (ϕ) (8) M DEB Σ i,j (¬E j ϕ) ⇔ M CEB Σ i,j (ϕ)<label>1</label></formula><p>The previous properties obviously hold because we have</p><formula xml:id="formula_77">|= E i E i ϕ ≡ E i ϕ, |= ¬E i E i ϕ ≡ ¬E i ϕ,</formula><p>and |= E j ¬E j ϕ ⇔ ¬E j ϕ i.e. |= ¬E j ¬E j ϕ ⇔ E j ϕ. Interestingly such properties do not hold for deliberate effects, i.e. when ϕ = E d j ϕ . However, it allows us to express manipulation where the goal is to let a victim obliges or forbids herself by side-effect to apply a given strategy, e.g. to make a mistake that obliges or forbids herself to deliberately bring her about something. For instance for constructive manipulation, such situations are expressed by:</p><formula xml:id="formula_78">• E d i (E j E d j ϕ ∧ ¬K j E d i E j E d j ϕ ) • E d i (E j E d j ϕ ∧ ¬B j E d i E j E d j ϕ ) • E d i (E j ¬E d j ϕ ∧ ¬K j E d i E j ¬E d j ϕ ) • E d i (E j ¬E d j ϕ ∧ ¬B j E d i E j ¬E d j ϕ )</formula><p>In the case of strong manipulation, if we consider ϕ = E j ϕ , we can express manipulation where the goal is to instrumentalize a victim to make her to insure producing (or not producing) something by side-effects, e.g. to jeopardize (or insuring not to jeopardize) another strategy. For instance for constructive manipulation, such situations are expressed by:</p><formula xml:id="formula_79">• E d i (E d j E j ϕ ∧ ¬K j E d i E d j E j ϕ ) • E d i (E d j E j ϕ ∧ ¬B j E d i E d j E j ϕ ) • E d i (E d j ¬E j ϕ ∧ ¬K j E d i E d j ¬E j ϕ ) • E d i (E d j ¬E j ϕ ∧ ¬B j E d i E d j ¬E j ϕ</formula><p>) Finally, we have the case where ϕ = E d j ϕ . In this case, it correspond to manipulation where the goal is to instrumentalize a victim in order she puts herself a situation where she deliberately brings about something or deliberately forbid herself to bring about something, e.g. pushing a drug-addict to attach himself in order to not be able to take drug. For instance for constructive manipulation, such situations are expressed by:</p><formula xml:id="formula_80">• E d i (E d j E d j ϕ ∧ ¬K j E d i E d j E d j ϕ ) • E d i (E d j E d j ϕ ∧ ¬K j E d i E d j E d j ϕ ) • E d i (E d j ¬E d j ϕ ∧ ¬K j E d i E d j ¬E d j ϕ ) • E d i (E d j ¬E d j ϕ ∧ ¬B j E d i E d j ¬E d j ϕ )</formula></div>
<div><head n="5.2.5.">Interactions between soft and strong manipulation</head><p>An agent can strongly manipulate another one while not softly manipulating the victim. Conversely, an agent can softly manipulate another one while not strongly manipulating the victim. Obviously, an agent can both softly and strongly manipulate another one.</p><p>Theorem 5.7.</p><p>(</p><formula xml:id="formula_81">) |= ¬M CEK Σ i,j (ϕ) ∧ M CE d K Σ i,j (ϕ) ⇒ ⊥ (2) |= M CEK Σ i,j (ϕ) ∧ ¬M CE d K Σ i,j (ϕ) ⇒ ⊥ (3) |= M CEK Σ i,j (ϕ) ∧ M CE d K Σ i,j (ϕ) ⇒ ⊥<label>1</label></formula><p>Those properties can be extended to the other forms of manipulation. While it may be seen as counterintuitive, it expressed some particular situations. For instance, if ¬M CEK Σ i,j (ϕ) ∧ M CE d K Σ i,j (ϕ) is true, then it means that the manipulator aims at concealing the way he instrumentalized the victim, i.e. he brings the victim to deliberately bring about something, while not concealing the fact that he brings the victim about something (e.g. by side-effects).</p></div>
<div><head n="5.2.6.">Manipulating oneself</head><p>As defined in Section 2.2, manipulation consists in instrumentalizing another agent. However, the KBE system only partially prevents an agent to manipulate himself as shown by the following properties.</p><p>Theorem 5.8.</p><formula xml:id="formula_82">(1) E d i E i ϕ ∧ E d i ¬K i E d i E i ϕ ⇒ ⊥ (2) |= M CEK Σ i,i (ϕ) ⇒ ⊥ and |= M CEB Σ i,i (ϕ) ⇒ ⊥</formula><p>Both properties can be extended to the other forms of manipulation. Property (1) holds because of</p><formula xml:id="formula_83">|= ¬K i E d i ϕ ⇔ ¬E d i ϕ while properties in (2) are due to |= E d i (ϕ ∧ ψ) =⇒ E d i ϕ ∧ E d i ψ.</formula><p>Property (1) means that manipulating oneself by independently deliberately bringing oneself about each part of the manipulation is inconsistent. However, properties in (2) mean that an agent can manipulate himself when the strategy of concealment is intrinsic to the strategy of instrumentalization. It makes particularly sense for artificial agents, e.g. in the case where a hacker changes the normal behavior of an artificial agent to delete or prevent log recording.</p></div>
<div><head n="5.3.">Other notions related to manipulation</head><p>We can also express related notions like coercion, persuasion and deception. We exhibit some links between those notions and manipulation. As previously, the proofs are given in Appendix A.6.</p></div>
<div><head n="5.3.1.">Coercion</head><p>The coercion is an influence of an agent over another agent by means of pressure without any dissimulation. For instance, a robber pointing a gun at somebody so as to get his wallet is not trying to manipulate the victim but he is influencing his behavior. The robber deliberately ensures that the victim knows or believes that he is under pressure (by pointing the gun). As manipulation, coercion can be expressed in a constructive or a destructive form. Thus, coercion can be defined formally with several predicates, i.e. constructive epistemic coercion, constructive doxastic coercion, destructive epistemic coercion and destructive doxastic coercion:</p><formula xml:id="formula_84">CKCoe Σ i,j (ϕ) = ψ∈Σ E d i (E d j ϕ ∧ K j E d i E d j ϕ ∧ ψ) CBCoe Σ i,j (ϕ) = ψ∈Σ E d i (E d j ϕ ∧ B j E d i E d j ϕ ∧ ψ) DKCoe Σ i,j (ϕ) = ψ∈Σ E d i (¬E d j ϕ ∧ K j E d i ¬E d j ϕ ∧ ψ) DBCoe Σ i,j (ϕ) = ψ∈Σ E d i (¬E d j ϕ ∧ B j E d i ¬E d j ϕ ∧ ψ)</formula><p>Obviously, coercion is a particular case of strong instrumentalization. Let us notice the following theorems use the operator defined in Section 5.1.1 in order to better highlight some interesting properties. We recall the reader this operator is a conjunctive Cartesian product between two sets of formulas.</p><p>Theorem 5.9.</p><p>(1)</p><formula xml:id="formula_85">CKCoe Σ i,j (ϕ) ⇔ ψ∈Σ {KjE d i E d j ϕ} E d i (E d j ϕ ∧ ψ) (2) CBCoe Σ i,j (ϕ) ⇔ ψ∈Σ {BjE d i E d j ϕ} E d i (E d j ϕ ∧ ψ)</formula></div>
<div><head n="5.3.2.">Persuasion</head><p>Persuasion consists in an agent making another one into believing something.</p><formula xml:id="formula_86">per Σ i,j (ϕ) = ψ∈Σ E d i (B j ϕ ∧ ψ)</formula><p>Persuasion is view as a particular case of influence, i.e. an influence on the belief state of the persuadee. Let us notice that, as the KBE system is not based on dynamic logic, this notion of persuasion does not capture the case of belief revision. However, if the persuadee is persuaded to deliberately bring about something, then the persuasion is equivalent to strong instrumentalization. It is expressed by the following theorem.</p><p>Theorem 5.10.</p><formula xml:id="formula_87">(1) per Σ i,j (¬E d j ϕ) ⇔ ψ∈Σ E d i (¬E d j ϕ ∧ ψ) (2) per Σ i,j (E d j ϕ) ⇔ ψ∈Σ E d i (E d j ϕ ∧ ψ)</formula><p>When an agent persuades another one to deliberately bring about something while ensuring that this agent knows or believes that he is persuaded, we can deduce a coercion.</p><p>Theorem 5.11.</p><p>(1) CKCoe Σ i,j (ϕ) ⇔ per</p><formula xml:id="formula_88">Σ {KjE d i E d j ϕ} i,j (E d j ϕ) (2) CBCoe Σ i,j (ϕ) ⇔ per Σ {BjE d i E d j ϕ} i,j (E d j ϕ) (3) DKCoe Σ i,j (ϕ) ⇔ per Σ {KjE d i ¬E d j ϕ} i,j (¬E d j ϕ) (4) DBCoe Σ i,j (ϕ) ⇔ per Σ {BjE d i ¬E d j ϕ} i,j (¬E d j ϕ)</formula><p>Interestingly, when an agent persuades another agent to bring about something while concealing the persuader deliberate intention, we can deduce a strong manipulation.</p><p>Theorem 5.12.</p><p>(1) per</p><formula xml:id="formula_89">Σ {¬KjE d i E d j ϕ} i,j (E d j ϕ) ⇔ M CE d K Σ i,j (ϕ) (2) per Σ {¬BjE d i E d j ϕ} i,j (E d j ϕ) ⇔ M CE d B Σ i,j (ϕ) (3) per Σ {¬KjE d i ¬E d j ϕ} i,j (¬E d j ϕ) ⇔ M DE d K Σ i,j (ϕ) (4) per Σ {¬BjE d i ¬E d j ϕ} i,j (¬E d j ϕ) ⇔ M DE d B Σ i,j (ϕ)</formula><p>Let us notice the previous properties does not hold for soft manipulation.</p></div>
<div><head n="5.3.3.">Deception</head><p>Deception consists in an agent making another believing something while hiding it some aspects linked to the newly believed statement. It may be half-truth, or deception by omission <ref type="bibr" target="#b70">(Sakama et al., 2015)</ref>. Let us focus on source concealment (namely hiding the deliberate effects to make another agent into believing something) and credible lies (namely hiding we believe the opposite of the statement we want the other agent to believe). Interestingly, both cases can be defined as a special case of persuasion. Source concealment can represent agents that spread rumors. For instance, in the case of stock exchange market, it happens that some agents spread rumors in order to influence the others to buy or sell a product without they know that it is a part of their strategy <ref type="bibr" target="#b2">(Aggarwal &amp; Wu, 2006)</ref>. Thus, it can be characterized by the fact that an agent makes sure to conceal -from an epistemic (resp. doxastic) point-of-view -his deliberate effects to make someone believes something. Thus, we can define epistemic (resp. doxastic) source concealment as follows:</p><formula xml:id="formula_90">KSoCo Σ i,j (ϕ) = ψ∈Σ E d i (B j ϕ ∧ ¬K j E d i B j ϕ ∧ ψ) BSoCo Σ i,j (ϕ) = ψ∈Σ E d i (B j ϕ ∧ ¬B j E d i B j ϕ ∧ ψ)</formula><p>Mahon defines lying as "to make a believed-false statement (to another person) with the intention that that statement be believed to be true (by the other person)" <ref type="bibr" target="#b45">(Mahon, 2008)</ref>. Thus, a statement is a lie if there is also a deliberate effect to conceal the intended effects to lie, from an epistemic or a doxastic point-of-view. We call such a lie an epistemic (reps. doxastic) credible lie:</p><formula xml:id="formula_91">KCrLie Σ i,j (ϕ) = B i ¬ϕ ∧ ( ψ∈Σ E d i (B j ϕ ∧ ¬K j B i ¬ϕ ∧ ψ)) BCrLie Σ i,j (ϕ) = B i ¬ϕ ∧ ( ψ∈Σ E d i (B j ϕ ∧ ¬B j B i ¬ϕ ∧ ψ))</formula><p>One property of credible lie is that an agent cannot lie to another one in order to make the victim believes he deliberately brings about something. Indeed, due to Theorem 5.10(1), believing to deliberately bring about ϕ implies deliberately bringing about ϕ, and the persuader would believe it while he should not. It is given by the next theorem.</p><p>Theorem 5.13.</p><formula xml:id="formula_92">(1) KCrLie Σ i,j (E d j ϕ) ⇒ ⊥ (2) BCrLie Σ i,j (E d j ϕ) ⇒ ⊥ (3) KSoCo Σ i,j (E d j ϕ) ⇔ M CE d K Σ i,j (ϕ) (4) BSoCo Σ i,j (E d j ϕ) ⇔ M CE d B Σ i,j (ϕ) (5) KCrLie Σ i,j (ϕ) ⇒ P er Σ {¬KjBi¬ϕ} i,j<label>(ϕ)</label></formula><formula xml:id="formula_93">(6) BCrLie Σ i,j (ϕ) ⇒ P er Σ {¬BjBi¬ϕ} i,j<label>(ϕ)</label></formula><p>We can compare the persuasion and deception definitions we propose here to the literature presented in Section 3.1. Firstly, we do not need to introduce explicit communication modality as <ref type="bibr" target="#b70">Sakama et al. (2015)</ref> did. Here, the communication is expressed (more precisely reduced) to a deliberate effect of having an influence on the mental state of another agent, e.g. making the agent believing something, or making him bringing about something. Obviously, communication in a whole cannot be reduced to just that, e.g. when an agent asks a question, or apologize, or publicly commit himself to do something, etc. Our notion of persuasion is syntactically close to the one proposed by <ref type="bibr" target="#b11">Bonnet et al. (2021)</ref> -deliberately seeing to it that the persuadee believes something -except we do not consider a temporal modality. Our notion of deception is however different as we explicitly consider concealment, which is not the case in <ref type="bibr" target="#b11">Bonnet et al. (2021)</ref>. The same remark holds for lie when compared to the one proposed by <ref type="bibr" target="#b70">Sakama et al. (2015)</ref>.</p></div>
<div><head n="6.">Application of KBE</head><p>The purpose of this section is to instantiate the KBE system in a situation where it is possible for one agent to manipulate another.</p></div>
<div><head n="6.1.">The story</head><p>We consider an e-commerce website in which two agents perform a commercial transaction. Let i be the seller and j be the customer, and i says to j: "You can trust me on the quality of the product. You will not find a better product anywhere else. You are</p><formula xml:id="formula_94">w v u a K i , K j , B i , B j , E i , E j K i , K j , B i , B j , E i , E j K j , B j , E j E j E j K i , K j , B i , B j , E i , E j K i , K j , B i , B j , E i , E j Figure 5</formula><p>. Mental states of the agents free to check information by yourself!". Let us notice in the conversation when you use terms such as you "are free to" may be related to a technique of manipulation in the theory of free will compliance. Indeed, it has been observed by sociopsychologists that the use of terms such as you are free to can strongly influence the choice of somebody to which desired by a manipulator <ref type="bibr" target="#b37">(Joule, Girandola, &amp; Bernard, 2007)</ref>.</p></div>
<div><head n="6.2.">Variables and possible worlds</head><p>To represent this situation, we consider two propositional variables p and q:</p><p>• p refers to "agent j trusts agent i on the product quality";</p><p>• q refers to "agent j buys the product".</p><p>For the sake of readability, we do not consider all possible scenarios such as agent j does not buy the product but trusts i on the product quality. We represent the possible scenarios we consider as a set of possible worlds W = {a, w, v, u} where:</p><p>• w: "i builds trust to get j to buy the product"; • v: "i does not deliberately instrumentalize j to buy the product but j buys the product and trusts i on the product quality"; • u: "j buys the product without trust in i on the product quality and knows that the agent i intended to make him buy the product"; • a: "j does not buy the product and does not trust i on the product quality".</p></div>
<div><head n="6.3.">Defining the set Σ</head><p>Let us define the set Σ (see Section 5.1.1). Here, Σ = Cl(Γ) be a finite and closed set of formulas where:</p><formula xml:id="formula_95">Γ = {E d i (E d i p ⇒ E d i E j q), E d i E j q ∧ E d i ¬K j E d i E j q ⇒ E d i (E j q ∧ ¬K j E d i E j q), E d i E d j q ∧ E d i K j E d i E d j q ⇒ E d i (E d j q ∧ K j E d i E d j q), , ⊥}</formula><p>Hence for example, the formula</p><formula xml:id="formula_96">E d i (E d i p ⇒ E d i E j q)</formula><p>allows us to reason about the situation described in the world w, i.e. the agent i deliberately builds trust in order to get agent j to buy the product. As another example, the formula</p><formula xml:id="formula_97">E d i E j q∧E d i ¬K j E d i E j q ⇒ E d i (E j q ∧ ¬K j E d i E j q)</formula><p>allows us to deduce a soft constructive manipulation if agent i manipulates agent j. Finally,</p><formula xml:id="formula_98">E d i E d j q ∧ E d i K j E d i E d j q ⇒ E d i (E d j q ∧ K j E d i E d j q</formula><p>) allows agents to infer coercion if there is coercion in a world. Furthermore, as we consider the closure of Γ, we also express all subformulas and their single negation<ref type="foot" target="#foot_6">7</ref> .</p></div>
<div><head n="6.4.">The KBE model</head><p>The valuation function V of the model describing this situation is given by V (p) = {w, v} and V (q) = {w, u, v}. The accessibility relations are given in Figure <ref type="figure">5</ref> and they are assumed to be: <ref type="bibr">v}, {w, u, v}, {w, u, a}, {w, v, a}, {w}, {w, a}, {w,</ref> u}},</p><formula xml:id="formula_99">(1) K i (w) = {w}, K i (v) = {v}, K i (u) = {u}, K i (a) = {a} (2) K j (w) = {w, v}, K j (v) = {w, v}, K j (u) = {u}, K j (a) = {a} (3) B i (w) = {w}, B i (v) = {v}, B i (u) = {u}, B i (a) = {a} (4) B j (w) = {w, v}, B j (v) = {w, v}, B j (u) = {u}, B j (a) = {a} (5) E i (w) = {w}, E i (v) = {v}, E i (u) = {u}, E i (a) = {a} (6) E j (w) = {w, u, v}, E j (v) = {w, u, v}, E j (u) = {w, u, v}, E j (a) = {a} (7) E d i (w) = {{w,</formula><formula xml:id="formula_100">E d i (v) = {{v}, {w, v}}, E d i (u) = {{u}, {w, u, v}}, E d i (a) = {{w, a}} (8) E d j (w) = {{w, u, v}}, E d j (v) = {{w, u, v}}, E d j (u) = {{w, u, v}}, E d j (a) = {{w, a}} Informally:</formula><p>(1) describes the fact that the agent i knows agent j trusts him about the product quality and knows that agent j knows he buys a product and trusts i about the product quality, if it is the case. (2) describes the agent j that buy the product while trusting the agent j does not distinguish the worlds where he is instrumentalized and where he is not. (3) and (4) describe that the agents believe what they know and vice versa, i.e.</p><p>K i = B i and K j = B j . (5) means that in the world w, agent i ensures that p and q. (6) says that agent j buys the product in {w, u, v} but does not necessarily trust i on the product quality. (7) means the agent i in w deliberately brings agent j about trusting him and he deliberately brings it about if agent j trusts him, then agent j buys the product while i makes sure to hide his strategy to get j to buy the product. (8) means the agent j in {w, u, v} only intended to buy the product.</p></div>
<div><head n="6.5.">Deductions</head><p>We give now some deductions. We show according to the given KBE model that there is a soft instrumentalization, a deliberate concealment in w, a possible manipulation in w and a coercion in the world u.</p></div>
<div><head n="6.5.1.">Soft instrumentalization in w</head><p>Let us notice that in w, this model expresses that agent i has deliberately brought j about buying the product by building trust. Indeed, we have</p><formula xml:id="formula_101">||E d i p ⇒ E d i E j q|| = {w, u, a} and {w, u, a} ∈ E d i (w). So M, w |= E d i (E d i p ⇒ E d i E j q)</formula><p>. Thus, by applying the theorem</p><formula xml:id="formula_102">E d i ϕ ⇒ ϕ, we deduce that in w, we have M, w |= E d i p ⇒ E d i E j q. But ||p|| = {w, v} and {w, v} ∈ E d i (w), M, w |= E d i p. Therefore, we have M, w |= E d i E j q.</formula></div>
<div><head n="6.5.2.">Deliberate concealment in w</head><p>In addition, we can notice that in w agent i also ensures to hide his strategy to get j to buy the product. Indeed, we have in v that M, v |= ¬E d i E j q, since ||E j q|| = {w, u, v} and {w, u, v} ∈ E d i (v). Thus, since agent j cannot discern between the worlds w and v, we also deduce that M, w, v |= ¬K j E d i E j q. Moreover, we can notice that</p><formula xml:id="formula_103">||¬K j E d i E j q|| = {w, v, a} 8 and {w, v, a} ∈ E d i (w). Therefore, since ||¬K j E d i E j q|| ∈ E d i (w), we have M, w |= E d i ¬K j E d i E j q.</formula><p>In conclusion, we have shown that M, w |=</p><formula xml:id="formula_104">E d i E j q ∧ E d i ¬K j E d i E j q.</formula></div>
<div><head n="6.5.3.">Possible manipulation in w</head><p>Now, by the tautology</p><formula xml:id="formula_105">|= E d i ϕ ∧ E d i ψ ⇒ E d i (ϕ ∧ ψ), we deduce that M, w |= E d i (E j q ∧ ¬K j E d i E j q) and it is equivalent to M, w |= E d i (E j q ∧ ¬K j E d i E j q ∧</formula><p>). So, we showed that, in this situation, there is a possible world in which agent i manipulates the agent j to make him buy the product by using a soft constructive manipulation with epistemic concealment.</p><p>Moreover, if we decompose the deliberate effects of the agent i, E d i (w) = {{w, v}, {w, u, v}, {w, u, a}, {w, v, a}, {w}, {w, a}, {w, u}}, we notice that agent i intended to ensure p by considering the set ||p|| = {w, v}, and on the other hand to ensure q by considering the set ||q|| = {w, u, v}. This agent also has the strategy to get the other agent to buy the product with the set ||E d i p ⇒ E d i E j q|| = {w, u, a}, and his dissimulation strategy is represented by the set ||¬K j E d i E j q|| = {w, v, a}. Finally, the sets {w}, {w, a}, {w, u} are given by the imposed constraint (CE) on the frame to allow the tautology</p><formula xml:id="formula_106">|= E d i ϕ ∧ E d i ψ ⇒ E d i (ϕ ∧ ψ).</formula><p>These sets of possible worlds reflect the fact that when an agent sets up different plans, this agent also considers all combinations of all the different plans as a possible plan. For example, since {w, a} = {w, u, a} ∩ {w, v, a}, {w, a} is the combination of the respective plans</p><formula xml:id="formula_107">||E d i p ⇒ E d i E j q|| and ||¬K j E d i E j q||.</formula></div>
<div><head n="6.5.4.">Coercion in the world u</head><p>Finally let us notice that in the world u, agent i coerced agent j to push him to buy the product. Indeed, since we have</p><formula xml:id="formula_108">||E d j q|| = {w, u, v} and ||K j E d i E d j q|| = {u} 9 and that ||E d j q|| ∩ ||K j E d i E d j q|| = {u} ∈ E d i (u), we deduce that M, u |= E d i (E d j q ∧ K j E d i E d j q) and so M, u |= E d i (E d j q ∧ K j E d i E d j q ∧ ). Consequently, we just have proved that M, u |= coe Σ i,j (q). 8 We explain why a ∈ ||¬K j E d i E j q|| and u ∈ ||¬K j E d i E j q||. Firstly, notice that ||E j q|| ∈ E d i (a)</formula><p>, and M, a |= ¬E d i E j q and ∀x ∈ W : aK j x, M, x |= ¬E d i E j q. Thus, M, a |= K j ¬E d i E j q, and so M, a |= ¬K j E d i E j q. Secondly, notice that ||E d i E j q|| = {w, u} and since ∀x ∈ W, uK j x, M, x |= E d i E j q, we have M, u |= K j E d i E j q and so u ∈ ||¬K j E d i E j q||. 9 To make sure, just compute the set ||E d i E d j q|| = {w, u} and so the only possible world x such that ∀z ∈ W, xK j z, M, z |= E d i E d j q is the world x = u.</p></div>
<div><head n="7.">Conclusion and future works</head><p>In this article, we provide a broad state-of-the-art about manipulation in social science. We used this state-of-the-art to define manipulation as the deliberate effect to instrumentalize a victim while making sure to conceal that effect. We proposed a logical framework to reason about this notion. To this end, we defined a new deliberate BIAT modality for deliberate effects. We then considered logical interactions between knowledge, belief, deliberate effects and consequences of actions and proved that our system is strongly sound and complete. Furthermore we deduced several theorems such as concealment of contrary beliefs and qui facit per alium facit per se principle. Finally we gave an explicit definition of what manipulation is, and we modeled coercion, persuasion and deception differently such as highlighted by the literature.</p><p>In terms of perspectives, future works are twofold. Firstly, it may be of interest to formalize deliberated intention in a deeper way. Indeed, KBE neither consider temporal nor dynamic operators while they are necessary to express actions and their consequences. Secondly, expressing more kind of manipulation is of interest. For instance, it should be interesting to extend the framework with awareness so as to define new manipulation forms with awareness concealment. As another example, extending KBE with other mental state can be of interest to model manipulation strategies such as presented in Table <ref type="table">1</ref>.</p></div>
<div><head n="7.1.">Extending KBE to awareness logics</head><p>When we defined manipulation such as the deliberate effect to instrumentalize an agent while making sure to conceal that effect, we defined concealment as a lack of knowledge or belief about the manipulator's effects. However, in many situations, a manipulated agent is unaware that he or she has been manipulated. In section 3.3, we have presented work on the representation of awareness. One perspective is to integrate awareness into manipulation.</p><p>We could for instance consider a modality A i to represent that agent i is aware of something, as proposed in <ref type="bibr" target="#b73">Schipper (2014)</ref>. Let Σ be a set of formulas that is closed and finite such as { , ⊥} ⊆ Σ, ϕ ∈ Σ and A i : W → 2 Σ be the awareness function associated with the modality A i . We could then define new forms of manipulations with absence of awareness. Thus, a soft constructive manipulation with absence of awareness would be defined as:</p><formula xml:id="formula_109">M CEA Σ i,j (ϕ) = ψ∈Σ E d i (E j ϕ ∧ ¬A j E d i E j ϕ ∧ ψ)</formula><p>A strong constructive manipulation with absence of awareness would be defined as:</p><formula xml:id="formula_110">M CE d A Σ i,j (ϕ) = ψ∈Σ E d i (E d j ϕ ∧ ¬A j E d i E d j ϕ ∧ ψ)</formula><p>A soft destructive manipulation with absence of awareness would be defined as:</p><formula xml:id="formula_111">M DEA Σ i,j (ϕ) = ψ∈Σ E d i (¬E j ϕ ∧ ¬A j E d i ¬E j ϕ ∧ ψ)</formula></div>
<div><head>40</head><p>A strong destructive manipulation with absence of awareness would be defined as:</p><formula xml:id="formula_112">M DE d A Σ i,j (ϕ) = ψ∈Σ E d i (¬E d j ϕ ∧ ¬A j E d i ¬E d j ϕ ∧ ψ)</formula><p>Furthermore, note that in this case the function A i is such that for any w ∈ W, A i (w) ⊆ Σ. That means that, in such a system, we assume agents are never aware of formulas that are not in Σ.</p></div>
<div><head n="7.2.">Extending KBE with other mental states</head><p>We also could consider mental states other than awareness, in particular mental states on which a manipulation strategy relies (see Table <ref type="table">1</ref>). Indeed, while our KBE system can express strategies based on an agent's beliefs and knowledge as with deception or lying, we cannot express other forms of strategies when they are based on the agents' desires, norms, or when they are based on trust in the sincerity that one agent gives to another agent.</p><p>In a previous work, we propose a logic -called TB system -in which a modality T s j,i expresses the fact that an agent i trusts the sincerity of an agent i about something <ref type="bibr" target="#b40">(Leturc &amp; Bonnet, 2018)</ref>. A perspective would consist in merging the KBE system and the TB system. By merging them we would be able to deduce new theorems such as if an agent j trusts the sincerity of another agent i about the fact that i does not instrumentalize him, then it cannot be the case that agent j believes that i can instrumentalize him. This theorem would be represented by the following formula:</p><formula xml:id="formula_113">T s j,i ¬E d i E j ϕ ⇒ ¬B j E d i E j ϕ</formula><p>We would then have new forms of manipulation whose concealment would be based on trust between two agents. In the same way, it could be interesting to extend the KBE system with notions of desires, norms or obligations so as to describe other kinds of manipulation strategies presented in Table <ref type="table">1</ref>.</p><formula xml:id="formula_114">A.1. Theorems on semantic constraints Proposition 4.1. If (E d KN )</formula><p>and (E d KP ) hold at the same time, then it implies on the Kripke structure that the following property holds:</p><formula xml:id="formula_115">∀w ∈ W : E d i (w) = v∈W:wKiv E d i (v) = v∈W:wKiv E d i (v) (E d KN ) + (E d KP )</formula><p>Proof. Let assume a frame C s. </p><formula xml:id="formula_116">E d i (v) ⊆ v∈W:wKiv E d i (v) (E d KP )</formula><p>Then, since for all sets E, F , (E ⊆ F ∧ ∀e, e ∈ E ⇒ e ∈ F ) ⇐⇒ E = F<ref type="foot" target="#foot_7">10</ref> , and since (E d KN ) holds, we thus deduce:</p><formula xml:id="formula_117">∀w ∈ W : E d i (w) = v∈W:wKiv E d i (v)</formula><p>Then, with (E d KP ) we prove the complete theorem :</p><p>∀w ∈ W : v∈W:wKiv</p><formula xml:id="formula_118">E d i (v) = E d i (w) ⊆ v∈W:wKiv E d i (v)</formula><p>Consequently:</p><formula xml:id="formula_119">∀w ∈ W : E d i (w) = v∈W:wKiv E d i (v) = v∈W:wKiv E d i (v) (E d KN ) + (E d KP )</formula><p>Proposition 4.2.</p><p>(1) If (E d KP ) holds and K i is reflexive, then:</p><formula xml:id="formula_120">∀w ∈ W, E d i (w) = v∈W:wKiv E d i (v)</formula><p>(2) If (E d KN ) holds and K i is reflexive, then:</p><formula xml:id="formula_121">∀w ∈ W, E d i (w) = v∈W:wKiv E d i (v)</formula><p>Proof.</p><p>(1) Let assume a frame C s.t. (E d KP ) holds and K i is reflexive, then:</p><formula xml:id="formula_122">∀w ∈ W, E d i (w) ⊆ v∈W:wKiv E d i (v) ⊆ E d i (w)</formula><p>Consequently, ∀w ∈ W, E d i (w) = v∈W:wKiv</p><formula xml:id="formula_123">E d i (v).</formula><p>(2) Let assume a frame C s.t. (E d KN ) holds and K i is reflexive, then:</p><p>∀w ∈ W, v∈W:wKiv</p><formula xml:id="formula_124">E d i (v) ⊆ E d i (w) ⊆ v∈W:wKiv E d i (v)</formula><p>Consequently, ∀w ∈ W, E d i (w) = v∈W:wKiv</p><formula xml:id="formula_125">E d i (v).</formula></div>
<div><head>A.2. Soundness</head><p>This section aims to demonstrate the correctness of our KBE system. Thus, in the sequel we consider any frame C = (W,</p><formula xml:id="formula_126">{B i } i∈N , {K i } i∈N , {E i } i∈N , {E d i } i∈N ).</formula></div>
<div><head>A.2.1. Normal modalities</head><p>It is well known that the semantics of a normal modality of a S5 system that preserves validity is an equivalence relation <ref type="bibr" target="#b10">Blackburn et al. (2002)</ref>. Since the relation E i is an equivalence relation, the rules of S5 preserve the validity. Then a relation K i which is reflexive, transitive and confluent is sound with a S4.2 system. Let us recall a proof method to show that confluence corresponds to the axiom 4.2.</p><p>Proposition A.1. K i is confluent if, and only if, </p><formula xml:id="formula_127">C |= K i K i p ⇒ K i K i ϕ Proof. (⇒) Let us suppose a frame C |= K i K i p ⇒ K i K i p, i.e.</formula><formula xml:id="formula_128">i K i p ∧ ¬K i K i p i.e. C |= K i K i p ⇒ K i K i ϕ</formula><p>Concerning the inference rules between the modality K i and B i , <ref type="bibr" target="#b77">Stalnaker (2006)</ref> showed they are valid in our logical frame. Moreover, it is well known that a serial, transitive and Euclidean relation preserves the validity of a KD45 system for the modality B i .</p></div>
<div><head>A.2.2. Non standard properties</head><p>In this section, we focus on the non-standard properties associated with our neighborhood semantics for the relation E d i . Some of these properties may be found in <ref type="bibr" target="#b57">Pacuit (2017)</ref> but not all. Thus, in the interest of rigor, we demonstrate all non standard properties in this section.</p><p>Firstly the axiom (C) is valid in KBE.</p><p>Proposition A.2.</p><formula xml:id="formula_129">C |= E d i ϕ ∧ E d i ψ ⇒ E d i (ϕ ∧ ψ)</formula><p>if, and only if,</p><formula xml:id="formula_130">∀w ∈ W : S ∈ E d i (w) ∧ T ∈ E d i (w) =⇒ S ∩ T ∈ E d i (w)</formula><p>Proof. (⇒) By contraposition, let be a frame C such that : ∃w ∈ W : </p><formula xml:id="formula_131">S ∈ E d i (w)∧T ∈ E d i (w) ∧ S ∩ T ∈ E d i (w). Let us assume M, w s.t. M, w |= E d i p ∧ E d i q, V (p) = S and V (q) = T .</formula><formula xml:id="formula_132">E d i (v)</formula><p>Consequently, we have proved that:</p><formula xml:id="formula_133">∃w ∈ W : E d i (w) ⊆ v∈W:wKiv E d i (v)</formula><p>The deliberate effects has negative introspection with knowledge.</p><p>Proposition A.5.</p><formula xml:id="formula_134">C |= ¬E d i p ⇒ K i ¬E d i p</formula><p>if, and only if,</p><formula xml:id="formula_135">∀w, v ∈ W, ∀S ∈ 2 W : S ∈ E d i (w) =⇒ (wK i v ⇒ S ∈ E d i (v))</formula><p>Proof. (⇒) By contraposition, let us assume a frame C such that :</p><formula xml:id="formula_136">∃w, v ∈ W, ∃S ∈ 2 W : S ∈ E d i (w) ∧ wK i v ∧ S ∈ E d i (v)</formula><p>Let us define a model M on C s. </p><formula xml:id="formula_137">∃w, v ∈ W, ∃S ∈ 2 W : S ∈ E d i (w) ∧ wK i v ∧ S ∈ E d i (v)</formula><p>There is logical link between deliberate effects and effects of actions.</p><p>Proposition A.6.</p><p>C </p><formula xml:id="formula_138">(w, S) ∈ W × 2 W : S ∈ E d i (w) ∧ E i (w) ⊆ S.</formula></div>
<div><head>A.2.3. Soundness properties</head><p>In this section, we give the complete proof of soundness.</p><p>Theorem 4.4. The KBE system is sound.</p><p>Proof. In order to show soundness, we have to show that substitution, modus ponens, necessitation, (RE) and (DUAL) preserve the validity for all modalities.</p><p>(1) Let us prove that substitution preserves validity. Let ϕ ∈ L KBE be a formula and p a1 , . . . , p an ∈ P be propositional atoms that are contained in ϕ. We define θ = ϕ(ψ 1 /p a1 , . . ., ψ n /p an ) the obtained formula after an uniform substitution on ϕ and ψ 1 , . . . , ψ n ∈ L KBE formulas. We want to prove that if ϕ is valid in C, then θ is also valid in C. By contraposition let us assume that C |= θ. So there exists a model M = (C, h) and a world w ∈ W such that: M, w |= θ. Let us build a model for ϕ, M = (C, h ) such that:</p><formula xml:id="formula_139">• ∀j ∈ N : 1 ≥ j ≥ n, M, w |= ψ j =⇒ w ∈ h (p aj ) • ∀j ∈ N : 1 ≥ j ≥ n, M, w |= ψ j =⇒ w / ∈ h (p aj ) • ∀p ∈ P : ∀j ∈ N : p = p aj , w / ∈ h (p) 12</formula><p>Since M, w |= θ, we have that the combination of ψ j invalidate formula θ in M, w. Since for all ψ j we associate an atom p aj language with the same truth value as the formula as ψ j . The combination of p aj invalidate the formula ϕ in M , w. Thus, we have M , w |= ϕ. It has therefore been well proven by contraposition that substitution preserves validity, i.e. if ϕ is valid in C then its substitution ψ is also valid in C. (3) Let us prove that necessitation preserves validity for all ( , R) ∈ </p><formula xml:id="formula_140">{(B i , B i ), (K i , K i ), (E i , E i )}.</formula><formula xml:id="formula_141">= W \ (W \ ||ϕ|| M ) and ||¬ϕ|| M = W \ ||ϕ|| M . Then, we have M, w |= E d i ϕ iff ||ϕ|| M ∈ E d i (w) iff W \ (W \ ||ϕ|| M ) ∈ E d i (w) iff M, w |= E d i ¬ϕ iff M, w |= ¬ E d i ¬ϕ.</formula><p>Consequently (DUAL) preserves validity.</p></div>
<div><head>A.3. Completeness</head><p>In this section we prove the completeness of the logic KBE by using maximal consistent sets. Firstly, we define maximal consistent sets for KBE. Secondly, we give the proof of the completeness.</p></div>
<div><head>A.3.1. Definition of a deductible system</head><p>We recall in this section the notion of deductible system which is used in this article to prove later the strongly completeness.</p><p>Now that the link between validity and KBE-consistent maximum sets has been demonstrated, we can prove the link between our canonical model and the proven formulas in our axiomatic system. Lemma A.17 </p><formula xml:id="formula_142">M c = (W c , {B c i } i∈N , {K c i } i∈N , {E c i } i∈N , {E d c i } i∈N , V c</formula><p>) be the canonical model.</p><p>Lemma A.18. The canonical model M c is a KBE model i.e. the following properties for the canonical model hold:</p><p>(</p><formula xml:id="formula_143">1) ∀w ∈ W c : X ∈ E d c i (w) ∧ Y ∈ E d c i (w) =⇒ X ∩ Y ∈ E d c i (w) (2) ∀w ∈ W c : E d c i (w) ⊆ v∈W:wK c i v E d c i (v) (3) ∀w, v ∈ W c , ∀X ∈ 2 W : X ∈ E d c i (w) =⇒ (wK c i v ⇒ X ∈ E d c i (v)) (4) ∀w ∈ W c : W c ∈ E d c i (w) (5) ∀w ∈ W : X ∈ E d c i (w) =⇒ (E i (w) ⊆ X) (6) M c respects the constraints for K i , B i and E i Proof.</formula><p>(1) Let us first show that:  </p><formula xml:id="formula_144">∀w ∈ W c : X ∈ E d c i (w) ∧ Y ∈ E d c i (w) =⇒ X ∩ Y ∈ E d c i (w) Let w ∈ W c , X ∈ E c i (</formula><formula xml:id="formula_145">d i ϕ ∧ E d i ψ ∈ w. However E d i ϕ ∧ E d i ψ ⇒ E d i (ϕ ∧ ψ). Thus, by MCS5 E d i ϕ ∧ E d i ψ ⇒ E d i (ϕ ∧ ψ) ∈ w and by MCS4, we deduce that E d i (ϕ ∧ ψ) ∈ w. So |ϕ ∧ ψ| ∈ E d c i (w). However |ϕ ∧ ψ| = |ϕ| ∩ |ψ| = X ∩ Y . Consequently, we prove that X ∩ Y ∈ E d c i (w). (2) Let us show that: ∀w ∈ W c : E d c i (w) ⊆ v∈W:wK c i v E d c i (v) Let w ∈ W c and X ∈ E d c i (w). By definition of E d c i , there exists ϕ ∈ L KBE , X = |ϕ|. So E d i ϕ ∈ w. However, E d i ϕ ⇒ K i E d i ϕ</formula><formula xml:id="formula_146">v ∈ W c , wK c i v : M c , v |= E d i ϕ. So E d i ϕ ∈ v, which means that |ϕ| ∈ E d c i (v), i.e. X ∈ E d c i (v). Consequently, we prove that ∀v ∈ W c , wK c i v : X ∈ E d c i (v), i.e. X ∈ v∈W:wK c i v E d c i (v).</formula><p>(3) Let us show that:</p><formula xml:id="formula_147">∀w, v ∈ W c , ∀X ∈ 2 W : X ∈ E d c i (w) =⇒ (wK c i v ⇒ X ∈ E d c i (v)) Let w, v ∈ W c s.t. wK c i v and X ∈ E d c i (w). By definition of E d c i (w) = {|ϕ| : E d i ϕ ∈ w}, since X ∈ E d c i (w)</formula><p>, there is no ϕ ∈ L KBE such that X = |ϕ| and E d i ϕ ∈ w. So, this means that for all ϕ ∈ L KBE , X = |ϕ| ⇒ E d i ϕ ∈ w, and by MCS2, we have for all ϕ ∈ L KBE , X = |ϕ| ⇒ ¬E d i ϕ ∈ w. Thus, there are two possible cases:</p><formula xml:id="formula_148">• If X is of the form X = |ϕ|, then ¬E d i ϕ ∈ w. However, ¬E d i ϕ ⇒ K i ¬E d i ϕ and, by MCS5, ¬E d i ϕ ⇒ K i ¬E d i ϕ ∈ w then, by MCS4, K i ¬E d i ϕ ∈ w. Thus, ∀u ∈ W c s.t. wK c i u, ¬E d i ϕ ∈ u. Finally, ∀u ∈ W c s.t. wK c i u, |ϕ| ∈ E d c i (u), and thus X ∈ E d c i (v).</formula><p>• If X cannot be written as X = |ϕ|, then by using the definition of the minimal canonical model, i.e.</p><formula xml:id="formula_149">E d c i (w) = {|ϕ| : E d i ϕ ∈ w}, we deduce that ∀u ∈ W c : X ∈ E d c i (u). So X ∈ E d c i (v).</formula><p>Consequently, we prove that:</p><formula xml:id="formula_150">∀w, v ∈ W c , ∀X ∈ 2 W : X ∈ E d c i (w) =⇒ (wK c i v ⇒ X ∈ E d c i (v)) (4) Let us show that: ∀w ∈ W c : W c ∈ E d c i (w) Let w ∈ W c . We have ¬E d i and, by MCS5, we have ¬E i ∈ w, i.e. | | ∈ E d c i (w). However, since | | = W c , we deduce that W c ∈ E d c i (w). (5) Let us show that: ∀w ∈ W : X ∈ E d c i (w) =⇒ (E i (w) ⊆ X) Let w ∈ W c and X ∈ E d c i (w). By definition of E d c i (w) = {|ϕ| : E i ϕ ∈ w}, there exists ϕ ∈ L KBE s.t. X = |ϕ|. So, E d i ϕ ∈ w. However, E d i ϕ ⇒ E i ϕ and, by MCS5, E d i ϕ ⇒ E i ϕ ∈ w, then, by MCS4, we have E i ϕ ∈ w, i.e. M c , w |= E i ϕ and so ∀u ∈ W c : u ∈ E c i (w), M c , u |= ϕ. But since X = |ϕ|, then we have ∀u ∈ E c i (w), u ∈ |ϕ|. Thus, if v ∈ E c i (w), then v ∈ |ϕ| i.e. v ∈ X. So we prove that ∀w ∈ W : X ∈ E d c i (w) =⇒ (E i (w) ⊆ X).</formula><p>(6) The other canonical properties are easy to show and standard for K i , B i and E i (see <ref type="bibr" target="#b10">Blackburn et al. (2002)</ref>).</p></div>
<div><head>A.3.7. Completeness proof</head><p>In this section, we give the complete proof of completeness.</p><p>Theorem 4.5. The KBE system is complete.</p><p>Proof. (Completeness) By definition, we have that for all valid formulas ϕ in the frame C, ϕ is valid in all models M on C. Thus, since the canonical model is a KBE model from Lemma A.18, ϕ is also valid in the canonical model M c . So, from the all KBE-consistent sets Γ, there exists a world w ∈ W c satisfying all formulas of Γ in the canonical model M c . Finally we give the proof of the strong completeness of KBE.</p><p>Theorem A.21 (Strong completeness of KBE). Let ϕ ∈ L KBE be a formula and for all sets Γ ⊆ L KBE of formulas, we have that the system KBE is strongly complete i.e. if Γ |= ϕ, then Γ ϕ.</p><p>Proof. By contraposition, let Γ ⊆ L KBE be a set of formulas such that Γ ϕ, we have that Γ ∪ {¬ϕ} is a KBE-consistent set. Indeed, by absurdity, if we have Γ ∪ {¬ϕ} is KBE-inconsistent, then we would have that there exists ψ 1 , . . . , ψ n ∈ Γ such that ¬(ψ 1 ∧ . . . ∧ ψ n ∧ ¬ϕ), and so we would also have (ψ 1 ∧ . . . ∧ ψ n ) ⇒ ϕ. However by deduction theorem, we would deduce that Γ ∪ {ψ 1 , . . . , ψ n } ϕ, i.e. Γ ϕ, which contradicts the hypothesis Γ ϕ. Thus, by lemma A.20, there exists a model M (the canonical model) and a world w such that M, w |= Γ ∪ {¬ϕ}, i.e. M, w |= Γ and M, w |= ¬ϕ. Consequently we have proved that there exists a model M such that M, Γ |= ϕ.</p></div>
<div><head>A.5. Theorems of KBE</head><p>In Section 4.6, we gave theorems that can be deduced with KBE such as the property D, T, concealing contrary beliefs or knowledge and the qui facit per alium facit per se principle. In this section we give complete Hilbert-style proof of these theorems.  </p><formula xml:id="formula_151">1) ¬E d i ⊥ (D E d i ) (2) E d i ϕ ⇒ ϕ (T E d i ) Proof. (1) (a) E d i ⊥ ⇒ E i ⊥ [Ax. (E d i E i )] (b) (E d i ⊥ ⇒ E i ⊥) ⇒ (¬E i ⊥ ⇒ ¬E d i ⊥) [Contra. on (a)] (c) ¬E i ⊥ ⇒ ¬E d i ⊥ [MP (a), (b)] (d) ¬E i ⊥ [Ax. (D Ei )] (e) ¬E d i ⊥ [MP (d), (c)] (2) (a) E d i ϕ ⇒ E i ϕ [Ax. (E d i E i )] (b) E i ϕ ⇒ ϕ [Ax. (T Ei )] (c) E d i ϕ ⇒ E i ϕ ⇒ ϕ [Aug. (b)] (d) (E d i ϕ ⇒ E i ϕ ⇒ ϕ) ⇒ ((E d i ϕ ⇒ E i ϕ) ⇒ (E d i ϕ ⇒ ϕ)) [Syll. (c)] (e) E d i ϕ ⇒ ϕ [MP (c) (a) (d)]</formula><p>Theorem 4.6 (Statements 3 to 10).</p><p>(</p><formula xml:id="formula_152">) K i E d i ϕ ⇔ E d i ϕ (4) K i ¬E d i ϕ ⇔ ¬E d i ϕ (5) ¬K i E d i ϕ ⇔ ¬E d i ϕ (6) ¬K i ¬E d i ϕ ⇔ E d i ϕ (7) ¬B i ¬E d i ϕ ⇔ E d i ϕ (8) B i ¬E d i ϕ ⇔ ¬E d i ϕ 60 (9) B i E d i ϕ ⇔ E d i ϕ (10) ¬B i E d i ϕ ⇔ ¬E d i ϕ<label>3</label></formula><p>Proof.</p><p>(3) (a) (⇒)</p><formula xml:id="formula_153">K i E d i ϕ ⇒ E d i ϕ [Ax. (T Ki )] (b) (⇐) E d i ϕ ⇒ K i E d i ϕ [Ax. (4 Ki,E d i )] (c) K i E d i ϕ ⇔ E d i ϕ [Def. (⇔)] (4) (a) (⇒) K i ¬E d i ϕ ⇒ ¬E d i ϕ [Ax. (T Ki )] (b) (⇐) ¬E d i ϕ ⇒ K i ¬E d i ϕ [Ax. (5 Ki,E d i )] (c) K i ¬E d i ϕ ⇔ ¬E d i ϕ [Def. (⇔)] (5) (a) ¬K i E d i ϕ ⇔ ¬E d i ϕ [Contrap. (1.c)] (6) (a) ¬K i ¬E d i ϕ ⇔ E d i ϕ [Contrap. (2.c)] (7) (a) (⇒) ¬B i ¬E d i ϕ ⇒ ¬K i ¬E d i ϕ [Contrap. (K i B i )] (b) (⇒) ¬B i ¬E d i ϕ ⇒ E d i ϕ [RE (3.a) in (a)] (c) (⇒) ¬B i ¬E d i ϕ ⇒ ¬B i ¬E d i ϕ ⇒ E d i ϕ [Aug. (b)] (d) (⇒) (¬B i ¬E d i ϕ ⇒ ¬B i ¬E d i ϕ ⇒ E d i ϕ) ⇒ ((¬B i ¬E d i ϕ ⇒ ¬B i ¬E d i ϕ) ⇒ (¬B i ¬E d i ϕ ⇒ E d i ϕ)) [Syll. (c)] (e) (⇒) ¬B i ¬E d i ϕ ⇒ E d i ϕ [MP (c) (a) (b)] (f) (⇐) E d i ϕ ⇒ K i E d i ϕ [Ax. (4 Ki,E d i )] (g) (⇐) K i E d i ϕ ⇒ B i E d i ϕ [Ax. (K i B j )] (h) (⇐) E d i ϕ ⇒ K i E d i ϕ ⇒ B i E d i ϕ [Aug. (g)] (i) (⇐) (E d i ϕ ⇒ K i E d i ϕ ⇒ B i E d i ϕ) ⇒ (E d i ϕ ⇒ K i E d i ϕ) ⇒ (E d i ϕ ⇒ B i E d i ϕ) [Syll. (h)] (j) (⇐) E d i ϕ ⇒ B i E d i ϕ [MP (h) (i) (g)] (k) (⇐) B i E d i ϕ ⇒ ¬B i ¬E d i ϕ [Ax. (D Bi )] (l) (⇐) E d i ϕ ⇒ K i E d i ϕ ⇒ B i E d i ϕ ⇒ ¬B i ¬E d i ϕ [Aug. (k)] (m) (⇐) (E d i ϕ ⇒ K i E d i ϕ ⇒ B i E d i ϕ ⇒ ¬B i ¬E d i ϕ) ⇒ (E d i ϕ ⇒ K i E d i ϕ) ⇒ (E d i ϕ ⇒ B i E d i ϕ) ⇒ (E d i ϕ ⇒ ¬B i ¬E d i ϕ) [Syll. (l)] (n) (⇐) E d i ϕ ⇒ ¬B i ¬E d i ϕ [MP (l) (f) (j) (m)] (o) E d i ϕ ⇔ ¬B i ¬E d i ϕ [Def. (⇔)] (8) (a) ¬E d i ϕ ⇔ B i ¬E d i ϕ [Contrap. (5.o)] (9) (a) (⇒) B i E d i ϕ ⇒ ¬B i ¬E d i ϕ [Ax. (D Bi )] (b) (⇒) B i E d i ϕ ⇒ E d i ϕ [RE (5.o)] (c) (⇐) E d i ϕ ⇒ B i E d i ϕ [Th. (5.j)] (d) E d i ϕ ⇔ B i E d i ϕ [Def. (⇔)] (10) (a) ¬E d i ϕ ⇔ ¬B i E d i ϕ [Contrap. (7.d)]</formula><p>Theorem 4.7.</p><p>(1)</p><formula xml:id="formula_154">E d i B j ϕ ⇒ E i ¬B j K k ¬ϕ (2) E d i ¬B j ϕ ⇒ E i ¬B j K k ϕ Proof.</formula><p>Here is the proof of (1).</p><p>(</p><formula xml:id="formula_155">) B j ϕ ∧ B j K k ¬ϕ ⇒ B j ϕ [Left Elim. ∧] (2) B j (K k ¬ϕ ⇒ ¬ϕ) [Nec. B j on (T Kk )] (3) B j (K k ¬ϕ ⇒ ¬ϕ) ⇒ (B j K k ¬ϕ ⇒ B j ¬ϕ) [Ax. (K)] (4) B j K k ¬ϕ ⇒ B j ¬ϕ [MP (2), (3)] (5) B j ¬ϕ ⇒ ¬B j ϕ [Ax. (D)] 61 (6) B j K k ¬ϕ ⇒ B j ¬ϕ ⇒ ¬B j ϕ [Aug. (5)] (7) (B j K k ¬ϕ ⇒ B j ¬ϕ ⇒ ¬B j ϕ) ⇒ ((B j K k ¬ϕ ⇒ B j ¬ϕ) ⇒ (B j K k ¬ϕ ⇒ ¬B j ϕ)) [Syll. (6)] (8) B j K k ¬ϕ ⇒ ¬B j ϕ<label>1</label></formula><p>[MP ( <ref type="formula">6</ref>),( <ref type="formula">4</ref>),( <ref type="formula">7</ref></p><formula xml:id="formula_156">)] (9) B j ϕ ∧ B j K k ¬ϕ ⇒ (B j K k ¬ϕ ⇒ ¬B j ϕ) [Aug. (8)] (10) B j ϕ ∧ B j K k ¬ϕ ⇒ B j K k ¬ϕ [Right Elim. (∧) ] (11) (B j ϕ ∧ B j K k ¬ϕ ⇒ (B j K k ¬ϕ ⇒ ¬B j ϕ)) ⇒ ((B j ϕ ∧ B j K k ¬ϕ ⇒ B j K k ¬ϕ) ⇒ (B j ϕ ∧ B j K k ¬ϕ ⇒ ¬B j ϕ))) [Syll. (9)] (12) B j ϕ ∧ B j K k ¬ϕ ⇒ ¬B j ϕ</formula><p>[MP ( <ref type="formula">9</ref>),( <ref type="formula">10</ref>),( <ref type="formula">11</ref>)] ( <ref type="formula">13</ref>)</p><formula xml:id="formula_157">((B j ϕ ∧ B j K k ¬ϕ ⇒ B j ϕ)) ⇒ ((B j ϕ ∧ B j K k ¬ϕ ⇒ ¬B j ϕ) ⇒ ¬(B j ϕ ∧ B j K k ¬ϕ)) [Reductio ad absurdum] (14) ¬(B j ϕ ∧ B j K k ¬ϕ)</formula><p>[MP (1), ( <ref type="formula">12</ref>), ( <ref type="formula">13</ref>)] ( <ref type="formula">15</ref></p><formula xml:id="formula_158">) ¬(B j ϕ ∧ B j K k ¬ϕ) ≡ (B j ϕ ⇒ ¬B j K k ¬ϕ)</formula><p>[De Morgan Th. ( <ref type="formula">14</ref>)] (16) B j ϕ ⇒ ¬B j K k ¬ϕ</p><p>[MP ( <ref type="formula">14</ref>), ( <ref type="formula">15</ref>)] (17</p><formula xml:id="formula_159">) E i (B j ϕ ⇒ ¬B j K k ¬ϕ) [Nec. (16)] (18) E i (B j ϕ ⇒ ¬B j K k ¬ϕ) ⇒ (E i B j ϕ ⇒ E i ¬B j K k ¬ϕ) [Ax. (K)] (19) E i B j ϕ ⇒ E i ¬B j K k ¬ϕ [MP (17), (18)] (20) E d i B j ϕ ⇒ E i B j ϕ [Ax. (E d i E i )] (21) E d i B j ϕ ⇒ E i B j ϕ ⇒ E i ¬B j K k ¬ϕ [Aug. (20)] (22) (E d i B j ϕ ⇒ E i B j ϕ ⇒ E i ¬B j K k ¬ϕ) ⇒ ((E d i B j ϕ ⇒ E i B j ϕ) ⇒ (E d i B j ϕ ⇒ E i ¬B j K k ¬ϕ)) [Syll. (21)] (23) E d i B j ϕ ⇒ E i ¬B j K k ¬ϕ [Ax. (E d i E i )]</formula><p>Here is the proof of (2).</p><p>(</p><formula xml:id="formula_160">) K k ϕ ⇒ ϕ [Ax. (T)] (2) B j (K k ϕ ⇒ ϕ) [Nec (1)] (3) B j (K k ϕ ⇒ ϕ) ⇒ B j K k ϕ ⇒ B j ϕ [Ax. (K Bj )] (4) B j K k ϕ ⇒ B j ϕ [MP (2) (3)] (5) (B j K k ϕ ⇒ B j ϕ) ⇒ ¬B j ϕ ⇒ ¬B j K k ϕ [Contrap. (4)] (6) ¬B j ϕ ⇒ ¬B j K k ϕ [MP (4) (5)] (7) E i (¬B j ϕ ⇒ ¬B j K k ϕ) [Nec (6)] (8) E i (¬B j ϕ ⇒ ¬B j K k ϕ) ⇒ E i ¬B j ϕ ⇒ E i ¬B j K k ϕ [Ax. (K Ei )] (9) E i ¬B j ϕ ⇒ E i ¬B j K k ϕ [MP (7) (8)] (10) E d i ¬B j ϕ ⇒ E i ¬B j ϕ [Ax. (E d i E i )] (11) E d i ¬B j ϕ ⇒ E i ¬B j ϕ ⇒ E i ¬B j K k ϕ [Aug. (9)] (12) (E d i ¬B j ϕ ⇒ E i ¬B j ϕ ⇒ E i ¬B j K k ϕ) ⇒ (E d i ¬B j ϕ ⇒ E i ¬B j ϕ) ⇒ E d i ¬B j ϕ ⇒ E i ¬B j K k ϕ [Syll. (11)] (13) E d i ¬B j ϕ ⇒ E i ¬B j K k ϕ [MP (11) (10) (12)]<label>1</label></formula><p>Theorem 4.8.</p><p>(1)</p><formula xml:id="formula_161">E d i B j ϕ ⇒ ¬E d i B j K k ¬ϕ (2) E d i ¬B j ϕ ⇒ ¬E d i B j K k ϕ Proof.</formula><p>Here is the proof of (1).</p><p>(</p><formula xml:id="formula_162">) E i ¬B j K k ¬ϕ ⇒ ¬E i B j K k ¬ϕ [Ax. (D)] (2) ¬E i B j K k ¬ϕ ⇒ ¬E d i B j K k ¬ϕ [Contrap. Ax. (E i E d i )] (3) E d i B j ϕ ⇒ ¬E i B j K k ¬ϕ ⇒ ¬E d i B j K k ¬ϕ [Aug. (2)] (4) (E d i B j ϕ ⇒ ¬E i B j K k ¬ϕ ⇒ ¬E d i B j K k ¬ϕ) ⇒ (E d i B j ϕ ⇒ ¬E i B j K k ¬ϕ) ⇒ E d i B j ϕ ⇒ ¬E d i B j K k ¬ϕ [Syll. (3)] (5) E d i B j ϕ ⇒ ¬E d i B j K k ¬ϕ [MP (3) (Syll. ((Thm 4.7.1)-(1)))) (4)]<label>1</label></formula><p>Here is the proof of ( <ref type="formula">2</ref>).</p><p>(</p><formula xml:id="formula_163">) E i ¬B j K k ϕ ⇒ ¬E i B j K k ϕ [Ax. (D Ei )] (2) ¬E i B j K k ϕ ⇒ ¬E d i B j K k ϕ [Contrap. (E d i E i )] (3) E d i ¬B j ϕ ⇒ E i ¬B j K k ϕ ⇒ ¬E d i B j K k ϕ [Aug. (2)] (4) (E d i ¬B j ϕ ⇒ E i ¬B j K k ϕ ⇒ ¬E d i B j K k ϕ) ⇒ (E d i ¬B j ϕ ⇒ E i ¬B j K k ϕ) ⇒ E d i ¬B j ϕ ⇒ ¬E d i B j K k ϕ [Syll. (3)] (5) E d i ¬B j ϕ ⇒ ¬E d i B j K k ϕ [MP (3) (Thm 4.7.2) (4)]<label>1</label></formula><p>The next theorem is the qui facit per alium facit per se principle.</p><p>Theorem 4.9 (Qui facit per alium facit per se).</p><p>(</p><formula xml:id="formula_164">E d i E j ϕ ∨ E d i E d j ϕ) ⇒ E i ϕ</formula><p>Proof.</p><p>Left part:</p><p>(1)</p><formula xml:id="formula_165">E d i E j ϕ ⇒ E i E j ϕ [Ax. (E d i E i )] (2) E j ϕ ⇒ ϕ [Ax. (T)] (3) E i (E j ϕ ⇒ ϕ) [Nec (E i )] (4) E i (E j ϕ ⇒ ϕ) ⇒ E i E j ϕ ⇒ E i ϕ [Ax. (K)] (5) E i E j ϕ ⇒ E i ϕ [MP (3) (4)] (6) (E d i E j ϕ ⇒ E i E j ϕ ⇒ E i ϕ) ⇒ (E d i E j ϕ ⇒ E i E j ϕ) ⇒ E d i E j ϕ ⇒ E i ϕ [Syll. (5)] (7) E d i E j ϕ ⇒ E i ϕ [MP (4) (1) (6)]</formula><p>Right part:</p><p>(1)</p><formula xml:id="formula_166">E d i E d j ϕ ⇒ E i E d j ϕ [Ax. (E d i E i )] (2) E i (E d j ϕ ⇒ E j ϕ) [Nec (Ax. (E d i E i ))] (3) E i (E d j ϕ ⇒ E j ϕ) ⇒ E i E d j ϕ ⇒ E i E j ϕ [Ax. (K)] (4) E i E d j ϕ ⇒ E i E j ϕ [MP (2) (3)] (5) E d i E d j ϕ ⇒ E i E d j ϕ ⇒ E i E j ϕ [Aug. (4)] (6) (E d i E d j ϕ ⇒ E i E d j ϕ ⇒ E i E j ϕ) ⇒ (E d i E d j ϕ ⇒ E i E d j ϕ) ⇒ E d i E d j ϕ ⇒ E i E j ϕ [Syll. (5)] (7) E d i E d j ϕ ⇒ E i E j ϕ [MP (5) (1) (6)] (8) E d i E d j ϕ ⇒ E i E j ϕ ⇒ E i ϕ [Aug. (Ax. (4 Ei ))] (9) (E d i E d j ϕ ⇒ E i E j ϕ ⇒ E i ϕ) ⇒ (E d i E d j ϕ ⇒ E i E j ϕ) ⇒ E d i E d j ϕ ⇒ E i ϕ [Syll. (8)] (10) E d i E d j ϕ ⇒ E i ϕ [MP (8) (7) (9)] Conclusion: (1) (E d i E j ϕ ∨ E d i E d j ϕ) ⇒ ((E d i E j ϕ ⇒ E i ϕ) ⇒ (E d i E d j ϕ ⇒ E i ϕ) ⇒ E i ϕ)) [Elim. (∨)] (2) ((E d i E j ϕ ∨ E d i E d j ϕ) ⇒ ((E d i E j ϕ ⇒ E i ϕ) ⇒ (E d i E d j ϕ ⇒ E i ϕ) ⇒ E i ϕ)) ⇒ ((E d i E j ϕ ∨ E d i E d j ϕ) ⇒ (E d i E j ϕ ⇒ E i ϕ)) ⇒ (E d i E j ϕ ∨ E d i E d j ϕ) ⇒ (E d i E d j ϕ ⇒ 63 E i ϕ) ⇒ E i ϕ [Syll. (1)] (3) (E d i E j ϕ ∨ E d i E d j ϕ) ⇒ (E d i E d j ϕ ⇒ E i ϕ) ⇒ E i ϕ [MP (1) (Aug. (T E d i )) (2)] (4) ((E d i E j ϕ ∨ E d i E d j ϕ) ⇒ (E d i E d j ϕ ⇒ E i ϕ) ⇒ E i ϕ) ⇒ ((E d i E j ϕ ∨ E d i E d j ϕ) ⇒ (E d i E d j ϕ ⇒ E i ϕ)) ⇒ (E d i E j ϕ ∨ E d i E d j ϕ) ⇒ E i ϕ [Syll. (3)] (5) (E d i E j ϕ ∨ E d i E d j ϕ) ⇒ E i ϕ [MP (3) (Aug. ( E d i E d j ϕ ⇒ E i ϕ)) (4)]</formula><p>A.6. Properties of manipulation, coercion, persuasion and deception</p><p>In Sections 5.2 and 5.3, we provide theorems for manipulation and the related notions, i.e. coercion, perusasion and deception. In this section we give the proofs of these theorems. In some cases, the Hilbert proofs need several steps of obvious syllogisms and rewritings that make the proofs difficult to read. In those cases and for ease of reading, we allow ourselves to denote those steps by ". . .".</p><p>Theorem 5.5.</p><p>(</p><formula xml:id="formula_167">) (M CE d K Σ i,j (ϕ) ∨ M CE d B Σ i,j (ϕ)) ∧ K j ¬ϕ ⇒ ⊥ (2) (M CE d K Σ i,j (ϕ) ∨ M CE d B Σ i,j (ϕ)) ∧ B j ¬ϕ ⇒ ⊥ (3) (M CE d K Σ i,j (ϕ) ∨ M CE d B Σ i,j (ϕ)) ⇒ K j ϕ<label>1</label></formula><p>Proof.</p><p>(   Theorem 5.6.</p><formula xml:id="formula_169">Σ i,j (ϕ) ∨ M CE d B Σ i,j (ϕ))) ⇒ ((E d j ϕ ∧ ¬K j E d i E d j ϕ) ∨ (E d j ϕ ∧ ¬B j E d i E d j ϕ)) [CBR 13 Th. (T)] (i) . . . (j) ((E d j ϕ ∧ ¬K j E d i E d j ϕ) ∨ (E d j ϕ ∧ ¬B j E d i E d j ϕ)) ⇒ E d j ϕ [Elim. (∧) (∨) ] (k) E d j ϕ ⇒ ϕ [Ax. (T)] (l) ((M CE d K Σ i,j (ϕ) ∨ M CE d B Σ i,j (ϕ)) ∧ K j ¬ϕ) ⇒ ((E d j ϕ ∧ ¬K j E d i E d j ϕ) ∨ (E d j ϕ ∧ ¬B j E d i E d j ϕ)) ⇒ E d j ϕ ⇒ ϕ [Aug. (k)(×2)] (m) (((M CE d K Σ i,j (ϕ) ∨ M CE d B Σ i,j (ϕ)) ∧ K j ¬ϕ) ⇒ ((E d j ϕ ∧ ¬K j E d i E d j ϕ) ∨ (E d j ϕ ∧ ¬B j E d i E d j ϕ)) ⇒ E d j ϕ ⇒ ϕ) ⇒ (((M CE d K Σ i,j (ϕ) ∨ M CE d B Σ i,j (ϕ)) ∧ K j ¬ϕ) ⇒ ((E d j ϕ ∧ ¬K j E d i E d j ϕ) ∨ (E d j ϕ ∧ ¬B j E d i E d j ϕ))) ⇒ (((M CE d K Σ i,j (ϕ) ∨ M CE d B Σ i,j (ϕ)) ∧ K j ¬ϕ) ⇒ (E d j ϕ ⇒ ϕ)) [Syll. (l)] (n) ((M CE d K Σ i,j (ϕ) ∨ M CE d B Σ i,j (ϕ)) ∧ K j ¬ϕ) ⇒ (E d j ϕ ⇒ ϕ) [MP<label>(</label></formula><formula xml:id="formula_170">(r) (M CE d K Σ i,j (ϕ) ∨ M CE d B Σ i,j (ϕ)) ∧ B j ¬ϕ ⇒ (B j ϕ ∧ B j ¬ϕ) [MP (n) (a) (Syll. (q)) ] (s) (M CE d K Σ i,j (ϕ) ∨ M CE d B Σ i,j (ϕ)) ∧ B j ¬ϕ ⇒ ⊥ [RE (r) ( B j ϕ ∧ B j ¬ϕ ⇔ ⊥)] (3) (a) (E d i (E d j ϕ∧¬K j E d i E d j ϕ)∨E d i (E d j ϕ∧¬B j E d i E d j ϕ)) ⇒ ((E d j ϕ∧¬K j E d i E d j ϕ)∨ (E d j ϕ ∧ ¬B j E d i E d j ϕ)) [Th. (T E d i )] (b) (E d j ϕ ∧ ¬K j E d i E d j ϕ) ∨ (E d j ϕ ∧ ¬B j E d i E d j ϕ)) ⇒ E d</formula><p>(1) M CEK Σ i,j (E j ϕ) ⇔ M CEK Σ i,j (ϕ) (2) M CEK Σ i,j (¬E j ϕ) ⇔ M DEK Σ i,j (ϕ) (3) M CEB Σ i,j (E j ϕ) ⇔ M CEB Σ i,j (ϕ) (4) M CEB Σ i,j (¬E j ϕ) ⇔ M DEB Σ i,j (ϕ) (5) M DEK Σ i,j (E j ϕ) ⇔ M DEK Σ i,j (ϕ) (6) M DEK Σ i,j (¬E j ϕ) ⇔ M CEK Σ i,j (ϕ) (7) M DEB Σ i,j (E j ϕ) ⇔ M DEB Σ i,j (ϕ) (8) M DEB Σ i,j (¬E j ϕ) ⇔ M CEB Σ i,j (ϕ)</p><p>Proof. All those theorems are obvious to show by using (RE) and considering the following theorems E i E i ϕ ⇔ E i ϕ for (1) and ( <ref type="formula" target="#formula_152">3</ref>), E j ¬E j ϕ ⇔ ¬E j ϕ for ( <ref type="formula">2</ref>) and (4), ¬E i E i ϕ ⇔ ¬E i ϕ for ( <ref type="formula" target="#formula_183">5</ref>) and ( <ref type="formula">7</ref>), ¬E j ¬E j ϕ ⇔ E j ϕ for ( <ref type="formula">6</ref>) and (8).</p><p>Theorem 5.7.</p><p>(</p><formula xml:id="formula_171">) |= ¬M CEK Σ i,j (ϕ) ∧ M CE d K Σ i,j (ϕ) ⇒ ⊥ (2) |= M CEK Σ i,j (ϕ) ∧ ¬M CE d K Σ i,j (ϕ) ⇒ ⊥ (3) |= M CEK Σ i,j (ϕ) ∧ M CE d K Σ i,j (ϕ) ⇒ ⊥<label>1</label></formula><p>Proof. For both theorems, we will use the same model base, modulo a set of sets of possible worlds X ⊆ 2 W . Let M = W, {B i }, {K i }, {E i }, {E d i }, V be a KBE model, and Σ be any finite and closed set of formulas that contains { , ⊥} ∪ {p} and such that:</p><p>• W = {w, x, y, • K i = {(w, w), (x, x), (y, y), (z, z)} = B i = E i = K j = B j = E j • E d i = {(w, X), (x, {{x}}), (y, {{w, y}}), (z, {{z}})} • E d j = {(w, {{w, y, z}}), (x, {{x}}), (y, {{w, y, z}}), (z, {{z}})} • V (p) = {w, y, z} (0) if X = {{w}}, X = {{w, z}} or X = {{w}, {w, z}}, then we have:</p><p>• Theorem 5.8.</p><p>(1) (1) (a)</p><formula xml:id="formula_172">E d i E i ϕ ∧ E d i ¬K i E d i E i ϕ ⇒ ⊥ (2) |= M CEK Σ i,i<label>(</label></formula><formula xml:id="formula_173">E d i E i ϕ ∧ E d i ¬K i E d i E i ϕ ⇒ K i E d i E i ϕ [Left Elim. (∧) + Ax. (5 Ki,E d i )] (b) E d i E i ϕ ∧ E d i ¬K i E d i E i ϕ ⇒ ¬K i E d i E i ϕ [Right Elim. (∧) + Th. (T E d i )] (c) . . . (d) E d i E i ϕ ∧ E d i ¬K i E d i E i ϕ ⇒ (K i E d i E i ϕ ∧ ¬K i E d i E i ϕ ⇔ ⊥) [Conclusion]</formula><p>(2) Let M = W, {B i }, {K i }, {E i }, {E d i }, V be a KBE model, and Σ be any finite and closed set of formulas that contains { , ⊥} ∪ {p} and such that:</p><p>• W = {w, x, y} • K i = {(w, w), (x, x), (y, y)} = B i = E i • E d i = {(w, {{w}}), (x, {{x}}), (y, {{w, y}})} • V (p) = {w, y} We have: i,i (ϕ). We notice that with this KBE model, we prove also |= M CEB Σ i,i (ϕ) ⇒ ⊥.</p><formula xml:id="formula_174">• ||E i p|| = {w, y} • ||¬K i E d i E i p|| = ||¬E d i E i p|| = {z ∈ W : ||E i p|| ∈ E d i (z)} = {w, x} • ||E i p ∧ ¬K i E d i E i p|| = ||E i p|| ∩ ||¬K i E d i E i p|| =</formula><p>Theorem 5.9.</p><p>(1) CKCoe Σ i,j (ϕ) ⇔</p><formula xml:id="formula_175">ψ∈Σ {KjE d i E d j ϕ} E d i (E d j ϕ ∧ ψ) (2) CBCoe Σ i,j (ϕ) ⇔ ψ∈Σ {BjE d i E d j ϕ} E d i (E d j ϕ ∧ ψ)</formula><p>Proof. By rewriting CKCoe Σ i,j (ϕ) and Σ, we have for (1):</p><formula xml:id="formula_176">CKCoe Σ i,j (ϕ) ⇔ ψ∈Σ E d i (E d j ϕ ∧ K j E d i E d j ϕ ∧ ψ) ⇔ ψ∈Σ {KjE d i E d j ϕ} E d i (E d j ϕ ∧ ψ)</formula><p>The same methodology holds for (2).</p><p>Theorem 5.10.</p><p>(1) per Σ i,j (¬E Proof. By rewriting CKCoe Σ i,j (ϕ) and Σ, we have for (1):</p><formula xml:id="formula_177">CKCoe Σ i,j (ϕ) ⇔ ψ∈Σ E d i (E d j ϕ ∧ K j E d i E d j ϕ ∧ ψ) ⇔ ψ∈Σ {KjE d i E d j ϕ} E d i (E d j ϕ ∧ ψ) ⇔ per Σ {KjE d i E d j ϕ} i,j (E d j ϕ)</formula><p>The same methodology holds for (2), (3) and (4).</p><p>Theorem 5.12.</p><p>(1) per </p><formula xml:id="formula_178">E d i (B j E d j ϕ ∧ ψ) ⇔ ψ∈Σ {¬KjE d i E d j ϕ} E d i (E d j ϕ ∧ ψ) ⇔ ψ∈Σ E d i (E d j ϕ ∧ ¬K j E d i E d j ϕ ∧ ψ) ⇔ M CE d K Σ i,j<label>(ϕ)</label></formula><p>The same methodology holds for (2), (3) and (4).</p><p>Theorem 5.13.</p><p>(1) KCrLie Σ i,j (E d j ϕ) ⇒ ⊥ (2) BCrLie Σ i,j (E d j ϕ) ⇒ ⊥ (3) KSoCo Σ i,j (E d j ϕ) ⇔ M CE d K Σ i,j (ϕ) (4) BSoCo Σ i,j (E d j ϕ) ⇔ M CE d B Σ i,j (ϕ) (5) KCrLie Σ i,j (ϕ) ⇒ P er</p><formula xml:id="formula_179">Σ {¬KjBi¬ϕ} i,j<label>(ϕ)</label></formula><p>(6) BCrLie Σ i,j (ϕ) ⇒ P er</p><formula xml:id="formula_180">Σ {¬BjBi¬ϕ} i,j<label>(ϕ)</label></formula><p>Proof.</p><p>(1) (a)</p><formula xml:id="formula_181">B i ¬E d j ϕ ∧ E d i (B j E d j ϕ ∧ ¬K j B i ¬ϕ) ⇒ B i ¬E d j ϕ ∧ E d i (E d j ϕ ∧ ¬K j B i ¬ϕ) [RE on Th. ( B j E d j ϕ ⇔ E d j ϕ)] (b) B i ¬E d j ϕ ∧ E d i (E d j ϕ ∧ ¬K j B i ¬ϕ) ⇔ B i ¬E d j ϕ ∧ B i E d i (E d j ϕ ∧ ¬K j B i ¬ϕ) [RE on Th. ( B i E d i ϕ ⇔ E d i ϕ)] (c) B i ¬E d j ϕ ∧ B i E d i (E d j ϕ ∧ ¬K j B i ¬ϕ) ⇒ B i ¬E d j ϕ ∧ B i E d j ϕ [Right elim. (∧) + Th. (T E d i ) + Nec. B i + MP on (K)] (d) B i ¬E d j ϕ ∧ B i E d j ϕ ⇔ B i ⊥ (e) B i ¬E d j ϕ ∧ E d i (B j E d j ϕ ∧ ¬K j B i ¬ϕ) ⇒ ⊥ (2)</formula><p>The same methodology as (1) holds for this property.</p><p>(3) By rewriting M CE d K Σ i,j (ϕ) and Σ, we have:</p><formula xml:id="formula_182">KSoCo Σ i,j (E d j ϕ) ⇔ ψ∈Σ E d i (B j E d j ϕ ∧ ¬K j E d i B j E d j ϕ ∧ ψ) ⇔ ψ∈Σ E d i (E d j ϕ ∧ ¬K j E d i E d j ϕ ∧ ψ) ⇔ M CE d K Σ i,j<label>(ϕ)</label></formula><p>(4) The same methodology as (3) holds for this property.</p><p>( (6) The same methodology as (5) holds for (6).</p></div><figure xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Figure1. Event-driven model of the logic of lying<ref type="bibr" target="#b88">(Van Ditmarsch et al., 2012)</ref> </figDesc></figure>
<figure xml:id="fig_1"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2. Simplified axiomatic system of Van Ditmarsch et al. (2012)</figDesc></figure>
<figure xml:id="fig_2"><head>( 2 )</head><label>2</label><figDesc>Let us prove that modus ponens preserves validity. Let us suppose C |= ϕ and C |= (ϕ ⇒ ψ). So for all models M and for all worlds w, we have M, w |= ϕ and M, w |= ϕ ⇒ ψ, i.e. M, w |= ϕ ∧ (¬ϕ ∨ ψ), i.e M, w |= (ϕ ∧ ¬ϕ) ∨ (ϕ ∧ ψ), so M, w |= (ϕ ∧ ψ), i.e. M, w |= ϕ and M, w |= ψ. So M, w |= ψ. Therefore it has been proven that for all models M and for all worlds w, ψ is valid, i.e. C |= ψ.</figDesc></figure>
<figure xml:id="fig_3"><head /><label /><figDesc>(Truth lemma). Let ϕ ∈ L KBE be a formula and w ∈ W c , M c , w |= ϕ if, and only if, ϕProof. Let ϕ ∈ L KBE be a formula and w ∈ W c . We have M c , w |= ϕ iff (by lemma A.16) ϕ ∈ w iff (by MCS5) ϕ.A.3.6. Canonical model propertiesLet us prove that the canonical model preserves the semantic constraints of KBE. Let</figDesc></figure>
<figure xml:id="fig_5"><head>(</head><label /><figDesc /></figure>
<figure xml:id="fig_6"><head /><label /><figDesc>) (a) (M CE d K Σ i,j (ϕ) ∨ M CE d B Σ i,j (ϕ)) ∧ K j ¬ϕ ⇒ K j ¬ϕ [Right elim. (∧)] (b) K j ¬ϕ ⇒ ¬ϕ [Ax. (T)] (c) (M CE d K Σ i,j (ϕ) ∨ M CE d B Σ i,j (ϕ)) ∧ K j ¬ϕ ⇒ (K j ¬ϕ ⇒ ¬ϕ) [Aug. (b)] (d) (M CE d K Σ i,j (ϕ) ∨ M CE d B Σ i,j (ϕ)) ∧ K j ¬ϕ ⇒ (K j ¬ϕ ⇒ ¬ϕ)) ⇒ ((M CE d K Σ i,j (ϕ) ∨ M CE d B Σ i,j (ϕ)) ∧ K j ¬ϕ ⇒ K j ¬ϕ) ⇒ (((M CE d K Σ i,j (ϕ) ∨ M CE d B Σ i,j (ϕ)) ∧ K j ¬ϕ ⇒ ¬ϕ) [Syll. (c)] (e) ((M CE d K Σ i,j (ϕ) ∨ M CE d B Σ i,j (ϕ)) ∧ K j ¬ϕ) ⇒ ¬ϕ [MP (c),(a),(d)] (f) ((M CE d K Σ i,j (ϕ) ∨ M CE d B Σ i,j (ϕ)) ∧ K j ¬ϕ) ⇒ (M CE d K Σ i,j (ϕ) ∨ M CE d B Σ i,j(ϕ)) [Left elim. (∧)] (g) . . . (h) ((M CE d K</figDesc></figure>
<figure xml:id="fig_7"><head /><label /><figDesc>CE d K Σ i,j (ϕ) ∨ M CE d B Σ i,j (ϕ)) ∧ K j ¬ϕ) ⇒ (E d j ϕ ⇒ ϕ)) ⇒ ((((M CE d K Σ i,j (ϕ)∨M CE d B Σ i,j (ϕ))∧K j ¬ϕ) ⇒ E d j ϕ) ⇒ (((M CE d K Σ i,j (ϕ)∨ M CE d B Σ i,j (ϕ)) ∧ K j ¬ϕ) ⇒ ϕ)) [Syll. (n)] (p) (((M CE d K Σ i,j (ϕ) ∨ M CE d B Σ i,j (ϕ)) ∧ K j ¬ϕ) ⇒ ϕ) [MP (l),(e),(m)] (q) (((M CE d K Σ i,j (ϕ)∨M CE d B Σ i,j (ϕ))∧K j ¬ϕ) ⇒ ¬ϕ) ⇒ ((((M CE d K Σ i,j (ϕ)∨ M CE d B Σ i,j (ϕ)) ∧ K j ¬ϕ) ⇒ ϕ)) ⇒ (¬(M CE d K Σ i,j (ϕ) ∨ M CE d B Σ i,j (ϕ)) ∨ ¬K j ¬ϕ)) [Reductio ad absurdum] (r) (¬(M CE d K Σ i,j (ϕ) ∨ M CE d B Σ i,j (ϕ)) ∨ ¬K j ¬ϕ) [MP (e),(p),(q)] (s) (¬(M CE d K Σ i,j (ϕ) ∨ M CE d B Σ i,j (ϕ)) ∨ ¬K j ¬ϕ) ⇔ ((M CE d K Σ i,j (ϕ) ∨ M CE d B Σ i,j (ϕ)) ∧ K j ¬ϕ ⇒ ⊥) [Th. ( ϕ ⇔ (¬ϕ ⇒ ⊥))] (t) (M CE d K Σ i,j (ϕ) ∨ M CE d B Σ i,j (ϕ)) ∧ K j ¬ϕ ⇒ ⊥ [MP (r),(s)] (2) (a) (M CE d K Σ i,j (ϕ) ∨ M CE d B Σ i,j (ϕ)) ∧ B j ¬ϕ ⇒ B j ¬ϕ [Right elim. (∧)] (b) . . . (c) ((E d j ϕ ∧ ¬K j E d i E d j ϕ) ∨ (E d j ϕ ∧ ¬B j E d i E d j ϕ)) ∧ B j ¬ϕ ⇒ E d j ϕ [Left elim. (∧) ] (d) . . . (e) (E d j ϕ ⇒ K j E d j ϕ) [Ax. (5 Kj,E d j )] (f) ((E d j ϕ ∧ ¬K j E d i E d j ϕ) ∨ (E d j ϕ ∧ ¬B j E d i E d j ϕ)) ⇒ (E d j ϕ ⇒ K j E d j ϕ) [Aug. (e)] (g) K j E d j ϕ ⇒ B j E d j ϕ [Ax. (K j B j )] (h) . . . (i) B j (E d j ϕ ⇒ ϕ) [Nec (B j ) on (T E d j )] (j) B j (E d j ϕ ⇒ ϕ) ⇒ (B j E d j ϕ ⇒ B j ϕ) [Ax. (K)] (k) B j E d j ϕ ⇒ B j ϕ [MP (i), (j)] (l) . . . (m) ((E d j ϕ ∧ ¬K j E d i E d j ϕ) ∨ (E d j ϕ ∧ ¬B j E d i E d j ϕ)) ⇒ E d j ϕ ⇒ K j E d j ϕ ⇒ B j E d j ϕ ⇒ B j ϕ [Aug. (k)] (n) (M CE d K Σ i,j (ϕ) ∨ M CE d B Σ i,j (ϕ)) ∧ B j ¬ϕ ⇒ B j ϕ [MP (c) . . . (m) (Syll. (m))] (o) . . . (p) B j ϕ ⇒ (B j ¬ϕ ⇒ (B j ϕ ∧ B j ¬ϕ))[Intro. (∧)] (q) (M CE d K Σ i,j (ϕ) ∨ M CE d B Σ i,j (ϕ)) ∧ B j ¬ϕ ⇒ (B j ϕ ⇒ (B j ¬ϕ ⇒ (B j ϕ ∧ B j ¬ϕ)))[Aug. (p)]</figDesc></figure>
<figure xml:id="fig_8"><head /><label /><figDesc>E d j ϕ ⇒ K j E d j ϕ ⇒ K j ϕ [Aug. (MP (Th. (T E d i ))(Nec K i + Ax. (K Ki )))] (d) . . . (e) (M CE d K Σ i,j (ϕ) ∨ M CE d B Σ i,j (ϕ)) ⇒ K j ϕ [MP (...) Syll. (c)]</figDesc></figure>
<figure xml:id="fig_9"><head /><label /><figDesc>ϕ) ⇒ ⊥ and |= M CEB Σ i,i (ϕ) ⇒ ⊥ Proof.</figDesc></figure>
<figure xml:id="fig_10"><head /><label /><figDesc>) (a) KCrLie Σ i,j (ϕ) ⇒ ( ψ∈Σ E d i (B j ϕ ∧ ¬K j B i ¬ϕ ∧ ψ)) [Right Elim. (∧)] (b) ( ψ∈Σ E d i (B j ϕ ∧ ¬K j B i ¬ϕ ∧ ψ)) ⇔ P er</figDesc></figure>
<figure type="table" xml:id="tab_0"><head /><label /><figDesc>M, w |= E d i ϕ if, and only if, W \ ||ϕ|| ∈ E d i (w), with ||ϕ|| := {v ∈ W : M, v |= ϕ}. Finally, let us remind that ϕ is valid in M (written M |= ϕ) if, and only if, for all worlds w ∈ W, ϕ is satisfiable in w, i.e. M, w |= ϕ is true. A formula ϕ is valid in a frame C (written |= C ϕ or C |= ϕ) if, and only if, for all models M built on C, M |= ϕ. In this case ϕ is a tautology of C, written |= C ϕ.</figDesc><table /></figure>
<figure type="table" xml:id="tab_1"><head>Table 3 .</head><label>3</label><figDesc>Destructive forms of manipulation</figDesc><table><row><cell>represented by the formula E d i ¬E j ϕ, a strong manipulation is represented by the formula E d i ¬E d j ϕ, then an epistemic concealment by the formula E d i ¬K j E d i ¬E d j ϕ and</cell></row><row><cell>finally, a doxastic concealment is represented by the formula E d i ¬B j E d i ¬E d j ϕ.</cell></row></table></figure>
<figure type="table" xml:id="tab_3"><head /><label /><figDesc>there exists a model M on C and a world w∈ W s.t. M, w |= K i K i p ∧ ¬K i K i p. Thus, there exists u ∈ W, wK i u and v ∈ W, wK i v such that M, u |= K i p and M, v |= ¬ K i p. So for all z 1 ∈ W, uK i z 1 , M, z 1 |= p and for all z 2 ∈ W, vK i z 2 , M, z 2 |= ¬p. Therefore z 1 = z 2 and K i is not confluent. (⇐) By contraposition, let us suppose a frame C s.t. K i is not confluent i.e. ∃w, u, v ∈ W : wK i u ∧ wK i v∧ ∃z ∈ W : uK i z ∧ vK i z Let us assume M on C s.t. M, w |= K i K i p, V (p) = W \ K i (u). Thus, M, u |= K i ¬p i.e. M, u |= ¬ K i p. Since wK i u, we have M, w |= K i ¬ K i p i.e. M, w |= ¬K i K i p.Consequently, we have proved, there exists M on C s.t. M, w |= K</figDesc><table /></figure>
<figure type="table" xml:id="tab_4"><head /><label /><figDesc>Thus, we prove that there exists a world w ∈ W, S ∈ E i (w) ∧ T ∈ E i (w) ∧ S ∩ T ∈ E i (w).The necessitation does not hold for the modality of deliberate effects. Furthermore sinceX ∈ v∈W:wKiv E d i (v), we have there exists v ∈ K i (w), X ∈ E d i (v) 11 i.e. M, v |= ¬E d i p. Thus, M, w |= K i ¬E d i p. Consequently, M, w |= ¬K i E d i p and so, C |= E d i p ⇒ K i E d i p. (⇐) Let us assume C |= E d i p ⇒ K i E d i p, i.e.there exists a model M and a world w ∈ W such that M, w |= E d i p ∧ ¬K i E d i p. So, we have that ||p|| ∈ E d i (w). Moreover, there exists v ∈ W such that: wK i v and M, v |= ¬E d i p, i.e. ||p|| ∈ E d i (v). So, we deduce that :</figDesc><table><row><cell cols="2">Proposition A.4.</cell></row><row><cell /><cell>C |= E d i p ⇒ K i E d i p</cell></row><row><cell /><cell>if, and only if,</cell></row><row><cell /><cell>∀w ∈ W : E d i (w) ⊆</cell><cell>E d i (v)</cell></row><row><cell /><cell>v∈W:wKiv</cell></row><row><cell cols="3">Proof. (⇒) By contraposition, let us assume a frame C such that ∃w ∈ W :</cell></row><row><cell>E d i (w) ⊆</cell><cell cols="2">v∈W:wKiv E d i (v). First, let us notice that necessary E d i (w) = ∅ since</cell></row><row><cell cols="3">∅ ⊆ v∈W:wKiv E d i (v). Thus there exists X ∈ E d i (w) \ v∈W:wKiv E d i (v) i.e. X ∈ E d i (w)</cell></row><row><cell cols="3">and X ∈ v∈W:wKiv E d i (v). Second, let M be a model on C such that X = V (p) ∈</cell></row><row><cell cols="3">E d i (w) \ v∈W:wKiv E d i (v). As ||p|| ∈ E d i (w), we have M, w |= E d i p. ||p|| ∈</cell></row><row><cell /><cell>v∈W:wKiv</cell></row><row><cell cols="3">Thus, M, w |= E d i p i.e. ||p|| ∈ E d i (w) and M, w |= E d i q i.e. ||p|| ∈ E d i (w). However since S ∩ T ∈ E d i (w), we have ||p|| ∩ ||q|| ∈ E d i (w) and so ||p ∧ q|| ∈ E d i (w) i.e. M, w |= E d i (p ∧ q). (⇐) Let us assume that C |= E d i p ∧ E d i q ⇒ E d i (p ∧ q), i.e. there exists a model M and a world w ∈ W such that M, w |= E d i p ∧ E d i q ∧ ¬E d i (p ∧ q). So ||p|| ∈ E i (w) and ||q|| ∈ E i (w). Moreover, as M, w |= ¬E d i (p ∧ q), we have ||p ∧ q|| ∈ E d i (w) i.e ||p|| ∩ ||q|| ∈ E d i (w). Proposition A.3.</cell></row><row><cell /><cell>C |= ¬E d i</cell></row><row><cell /><cell>if, and only if,</cell></row><row><cell /><cell>∀w ∈ W : W ∈ E d i (w)</cell></row><row><cell cols="3">Proof. Let us suppose a frame C |= ¬E d i . As || || = W, it follows ∀M, ∀w ∈ W : M, w |= ¬E d i if, and only if, ∀w ∈ W, || || ∈ E i (w) i.e. ∀w ∈ W, W ∈ E i (w).</cell></row><row><cell cols="3">The deliberate effects has positive introspection with knowledge.</cell></row></table></figure>
<figure type="table" xml:id="tab_5"><head /><label /><figDesc>Furthermore, since wK i v, we deduce that M, w |= K i E d i p i.e. M, w |= ¬K i ¬E d i p. Consequently, M, w |= ¬E d i p ∧ ¬K i ¬E d i p. We have proved that there exists a model M |= ¬E d i p ⇒ K i ¬E d i p and so C |= ¬E d i p ⇒ K i ¬E d i p. (⇐) Let us suppose by contraposition C |= ¬E d i p ⇒ K i ¬E d i p, i.e. there exists a model M and a world w ∈ W such that M, w |= ¬E d i p ∧ ¬K i ¬E d i p. So ||p|| ∈ E d i (w). Moreover, there exists v ∈ W such that wK i v and M, v |= E d i p, i.e ||p|| ∈ E d i (v). Consequently, for S = ||p||, we can conclude that:</figDesc><table><row><cell>t. V (p) = S. As ||p|| ∈ E d i (w), we directly have i (v), we have M, v |= E d i p. As ||p|| ∈ E d M, w |= ¬E d i p.</cell></row></table></figure>
<figure type="table" xml:id="tab_6"><head /><label /><figDesc>Proof. (⇒) By contraposition, let us suppose a frame C such that :∃w ∈ W, ∃S ∈ 2 W : S ∈ E d i (w) ∧ E i (w) ⊆ S.Let us consider a model M on C s.t. V (p) = S. So, we have, ||p|| ∈ E d i (w) and so M, w |= E d i p. Furthermore, as E i (w) ⊆ S, there exists v ∈ E i (w) \ S, and so M, v |= ¬p (since S = ||p||). We deduce that since wE i v we have M, w |= E i ¬p i.e. M, w |= ¬E i p. We have M, w |= E d i p ∧ ¬E i p. Consequently, we can conclude that there exists M satisfying the constraint of the frame C such that M |= E d i p ⇒ E i p, and so C |= E d i p ⇒ E i p. (⇐) Let us suppose C |= E d i p ⇒ K i E d i p, i.e. there exists a model M and a world w ∈ W such that M, w |= E d i p ∧ ¬E i p. So ||p|| ∈ E d i (w) and there exists v ∈ W s.t. wE i v and M, v |= ¬p. By definition, we have v ∈ ||p||. Consequently, for S = ||p||, we prove that ∃</figDesc><table><row><cell>|= E d i p ⇒ E i p</cell></row><row><cell>if, and only if,</cell></row><row><cell>∀w ∈ W, ∀S ∈ 2 W : S ∈ E d i (w) =⇒ E i (w) ⊆ S</cell></row></table></figure>
<figure type="table" xml:id="tab_7"><head /><label /><figDesc>Let ϕ be a tautology, so for all models M and ∀v ∈ W, M, v |= ϕ. So ∀w, v ∈ W, wRv : M, v |= ϕ, i.e. ∀w ∈ W, M, w |= ϕ. We prove that if C |= ϕ, then C |= ϕ. Consequently, necessitation preserves validity. Let us assume |= ϕ ⇔ ψ. We have |= E d i ϕ if, and only if, for all (M, w), M, w |= E d i ϕ i.e. for all (M, w), ||ϕ|| M ∈ E d i (w) if, and only if, for all (M, w), ||ψ|| M∈ E d i (w) (since |= ϕ ⇔ ψ, we have for all (M , w ), ||ϕ|| M = ||ψ|| M ) iff |= E d i ψ. Consequently, we prove that if |= ϕ ⇔ ψ then |= E d i ϕ ⇔ E d i ψ i.e. (RE) preserves validity. (5) Let us prove that the rule (DUAL) preserves validity for E d i i.e.:For all models M and for all worlds w ∈ W such that M, w |= E d i ϕ. We just have to notice that ||ϕ|| M</figDesc><table><row><cell>(4) Let us prove that the rule (RE) preserves validity for E d i i.e.:</cell></row><row><cell>If |= ϕ ⇔ ψ then |= E d i ϕ ⇔ E d i ψ</cell></row><row><cell>|= E d i ϕ ⇔ ¬ E d i ¬ϕ</cell></row></table></figure>
<figure type="table" xml:id="tab_8"><head /><label /><figDesc>w) and Y ∈ E d c i (w). By definition of the minimal canonical model, there exists ϕ, ψ ∈ L KBE such that X = |ϕ| and Y = |ψ|. Thus, |ϕ| ∈ E d c i (w) and |ψ| ∈ E d c</figDesc><table /><note><p>i (w). Then, by definition, we have E d i ϕ ∈ w and E d i ψ ∈ w. Furthermore by MCS3' we have E</p></note></figure>
<figure type="table" xml:id="tab_10"><head /><label /><figDesc>||E j p|| = {w, y, z} and ||E d j p|| = {w, y} • ||E d i E j p|| = {y} and ||¬Ed i E j p|| = {w, x, z} • ||E d i E d j p|| = {y} and ||¬E d i E d j p|| = {w, x, z} • ||K j ¬E d i E j p|| = {w, x, z} ⊆ ||¬K j E d i E j p|| = {w, x, z} • ||K j ¬E d i E d j p|| = {w, x, z} ⊆ ||¬K j E d i E d j p|| = {w, x, z} • ||E d j p ∧ ¬K j E d i E d j p|| = ||E d j p|| ∩ ||¬K j E d i E d j p|| = {w}, • ||E j p ∧ ¬K j E d i E j p|| = ||E j p|| ∩ ||¬K j E d i E j p|| = {w, z}, (1) if X = {{w}}, then M, w |= ¬M CEK Σ i,j (ϕ) ∧ M CE d K Σ i,j (ϕ) since M, w |= ¬E d i (E j p ∧ ¬K j E d i E j p) ∧ E d i (E d j p ∧ ¬K j E d i E d j p) (2) if X = {{w, z}}, then M, w |= M CEK Σ i,j (ϕ) ∧ ¬M CE d K Σ i,j (ϕ) since M, w |= E d i (E j p ∧ ¬K j E d i E j p) ∧ ¬E d i (E d j p ∧ ¬K j E d i E d j p) (3) if X = {{w}, {w, z}}, then M, w |= M CEK Σ i,j (ϕ) ∧ M CE d K Σ i,j (ϕ) since M, w |= E d i (E j p ∧ ¬K j E d i E j p) ∧ E d i (E d j p ∧ ¬K j E d i E d j p)Let us notice that it is possible to describe with this model the fact that the agent i 66 does not softly or strongly manipulate the agent j if X = {{w, x}}. We would have M, w |= ¬M CEK Σ i,j (ϕ) ∧ ¬M CE d K Σ i,j (ϕ) since M, w |= ¬E d i (E j p ∧ ¬K j E d i E j p) ∧ ¬E d i (E d j p ∧ ¬K j E d i E d j p).</figDesc><table /></figure>
<figure type="table" xml:id="tab_11"><head /><label /><figDesc>{w} Thus, since ||E i p ∧ ¬K i E d i E i p|| ∈ E d i (w), we have proved that there exists a KBE-model M and w ∈ W s.t. M, w |= E d i (E i p ∧ ¬K i E d i E i p). Furthermore, since |= E d i (E i p ∧ ¬K i E d i E i p) ⇔ E d i (E i p ∧ ¬K i E d i E i p ∧) and by introduction of ∨ i.e. |= ϕ ⇒ (ϕ ∨ ψ), we prove the manipulation, i.e. M, w |= M CEK Σ</figDesc><table /></figure>
<figure type="table" xml:id="tab_12"><head /><label /><figDesc>Proof. Let us recall Theorem 4.6 says B j ¬E d j ϕ ⇔ ¬E d j ϕ and B j E d j ϕ ⇔ E d j ϕ. Thus, we have:(1) per Σ i,j (¬E d j ϕ) ⇔ ψ∈Σ E d i (B j ¬E d j ϕ ∧ ψ) ⇔</figDesc><table><row><cell>(2) per Σ i,j (E d j ϕ) ⇔</cell><cell cols="3">E d i (E d j ϕ ∧ ψ)</cell></row><row><cell>ψ∈Σ</cell><cell /><cell /></row><row><cell /><cell /><cell /><cell>E d i (¬E d j ϕ ∧ ψ)</cell></row><row><cell /><cell /><cell /><cell>ψ∈Σ</cell></row><row><cell cols="4">(2) per Σ i,j (E d j ϕ) ⇔ ψ∈Σ E d i (B j E d j ϕ ∧ ψ) ⇔</cell><cell>ψ∈Σ</cell><cell>E d i (E d j ϕ ∧ ψ)</cell></row><row><cell>Theorem 5.11.</cell><cell /><cell /></row><row><cell cols="4">(1) CKCoe Σ i,j (ϕ) ⇔ per</cell><cell>Σ {KjE d i E d j ϕ} i,j</cell><cell>(E d j ϕ)</cell></row><row><cell cols="2">(2) CBCoe Σ i,j (ϕ) ⇔ per</cell><cell cols="2">Σ {BjE d i E d j ϕ} i,j</cell><cell>(E d j ϕ)</cell></row><row><cell cols="4">(3) DKCoe Σ i,j (ϕ) ⇔ per</cell><cell>Σ {KjE d i ¬E d j ϕ} i,j</cell><cell>(¬E d j ϕ)</cell></row><row><cell cols="3">(4) DBCoe Σ i,j (ϕ) ⇔ per</cell><cell>Σ {BjE d i ¬E d j ϕ} i,j</cell><cell>(¬E d j ϕ)</cell></row><row><cell /><cell /><cell /><cell>E d i (¬E d j ϕ ∧ ψ)</cell></row><row><cell cols="4">ψ∈Σ</cell></row><row><cell /><cell /><cell /><cell>67</cell></row></table><note><p>d j ϕ) ⇔</p></note></figure>
<figure type="table" xml:id="tab_13"><head /><label /><figDesc>Proof. By rewriting M CE d K Σ i,j (ϕ) and Σ, we have for (1):</figDesc><table><row><cell /><cell cols="3">Σ {¬KjE d i E d j ϕ} i,j</cell><cell>(E d j ϕ) ⇔ M CE d K Σ i,j (ϕ)</cell></row><row><cell>(2) per</cell><cell cols="2">Σ {¬BjE d i E d j ϕ} i,j</cell><cell>(E d j ϕ) ⇔ M CE d B Σ i,j (ϕ)</cell></row><row><cell>(3) per</cell><cell cols="3">Σ {¬KjE d i ¬E d j ϕ} i,j</cell><cell>(¬E d j ϕ) ⇔ M DE d K Σ i,j (ϕ)</cell></row><row><cell>(4) per</cell><cell cols="3">Σ {¬BjE d i ¬E d j ϕ} i,j</cell><cell>(¬E d j ϕ) ⇔ M DE d B Σ i,j (ϕ)</cell></row><row><cell /><cell>per</cell><cell cols="2">Σ {¬KjE d i E d j ϕ} i,j</cell><cell>(E d j ϕ) ⇔</cell></row><row><cell /><cell /><cell /><cell>ψ∈Σ {¬KjE d i E d j ϕ}</cell></row></table></figure>
			<note place="foot" n="1" xml:id="foot_0"><p>A S5 system for a modality is a system where the axioms: (K) (ϕ ⇒ ψ) ⇒ ( ϕ ⇒ ψ), (T ) ϕ ⇒ ϕ, (4) ¬ ϕ ⇒ ¬ ϕ and (5) ϕ ⇒ ϕ are considered.</p></note>
			<note place="foot" n="2" xml:id="foot_1"><p>A bisimulation is a relation between two models in which related states have identical atomic information and matching transition possibilities<ref type="bibr" target="#b10">(Blackburn, De Rijke, &amp; Venema, 2002)</ref>.</p></note>
			<note place="foot" n="3" xml:id="foot_2"><p>We also accept the expressions "ϕ is a deliberate effect of agent i" or "agent i deliberately sees to it that ϕ".</p></note>
			<note place="foot" n="4" xml:id="foot_3"><p>A binary relation R on W is confluent if, and only if, the following property is satisfied ∀w, u, v ∈ W, wRu ∧ wRv → ∃z ∈ W : uRz ∧ vRz. Here we do not consider a S5 system with negative introspection but a S4.2 system. A S4.2 system is a S4 system -a system with the axioms for a modality (K) (ϕ ⇒ ψ) ⇒ ϕ ⇒ ψ, (T ) ϕ ⇒ ϕ, and (4) ¬ ϕ ⇒ ¬ ϕ -with a 4.2 axiom, ie. ♦ ϕ ⇒ ♦ϕ. The main reason is that since we would like to model also human agents' reasoning, we cannot accept that humans know everything they do not know. For more details, the interested reader may refer to<ref type="bibr" target="#b77">Stalnaker (2006)</ref> who gave arguments to support S4.2 rather than S5 for modeling knowledge.</p></note>
			<note place="foot" n="5" xml:id="foot_4"><p>An equivalence relationship is by definition a reflexive, transitive and symmetrical relationship, but equivalently we can consider any reflexive, transitive and Euclidean relationship.</p></note>
			<note place="foot" n="6" xml:id="foot_5"><p>It corresponds to the axioms of the KD45-system for a modality, i.e. (K) (ϕ ⇒ ψ) ⇒ ( ϕ ⇒ ψ), (D) ϕ ⇒ ¬ ¬ϕ, (4) ¬ ϕ ⇒ ¬ ϕ, and (5) ϕ ⇒ ϕ are considered.</p></note>
			<note place="foot" n="7" xml:id="foot_6"><p>A set of formulas Σ is closed under single negation iff if σ ∈ Σ and σ is not of the form ¬θ, then ¬σ ∈ Σ.</p></note>
			<note place="foot" n="10" xml:id="foot_7"><p>It is an obvious theorem of the theory of set. Let E, F be two sets. (⇒) Let assume (E ⊆ F ∧ ∀e, e ∈ E ⇒ e ∈ F ). W have E ⊆ F and so, let us show that F ⊆ E. Let f ∈ F . Since ∀e, e ∈ E ⇒ e ∈ F is equivalent, by contraposition, to ∀e, e ∈ F ⇒ e ∈ E, we deduce that f ∈ E. So E = F . (⇐) Let us assume E = F , thus E ⊆ F and F ⊆ E. Thus ∀e, e ∈ F ⇒ e ∈ E and by contraposition, we deduce ∀e, e ∈ E ⇒ e ∈ F .</p></note>
			<note place="foot" n="11" xml:id="foot_8"><p>X ∈ v∈W:wK i v E d i (v) iff ∀v ∈ K i (w), X ∈ E d i (v). Thus, X ∈ v∈W:wK i v E d i (v) iff ∃v ∈ K i (w), X ∈ E d i (v)</p></note>
			<note place="foot" n="12" xml:id="foot_9"><p>Since p is not an atom involved in the substitution, regardless if w / ∈ h (p) or w ∈ h (p), it will not affect the demonstration. We are just making sure we have got the right model here.</p></note>
			<note place="foot" n="13" xml:id="foot_10"><p>We apply here the Case-Based Reasoning i.e. the elimination of the disjunction.</p></note>
		</body>
		<back>
			<div type="annex">
<div><head>Appendix A. Soundness, completeness and theorems of KBE</head><p>In this appendix, we firstly prove some theorems on the KBE semantics constraints. Then we demonstrate that the axiomatic system presented in Figure <ref type="figure">4</ref> is correct. Then, we demonstrate that this axiomatic system is complete. We show that it verifies the deduction theorems and that it is strongly correct and strongly complete. Finally, we give the proofs of the theorems with a Hilbert system.</p></div>
<div><head>A.3.2. Deduction theorems</head><p>We talk about KBE-deductibility when a formula ϕ can be deduced from a set Σ of formulas.</p><p>Definition A.7 (KBE-deductibility). Let Σ be a set formulas in KBE and ϕ be a formula. We say that ϕ is a KBE-deduction from Σ and we write Σ ϕ if, and only if:</p><p>(1) If Σ = ∅, then ϕ ;</p><p>(2) Otherwise ∃ψ 1 , . . . , ψ n ∈ Σ with n ∈ N * and ψ 1 ∧ . . . ∧ ψ n ⇒ ϕ.</p><p>If Σ ϕ is verified, then ϕ is KBE-deductible.</p><p>The KBE-deductibility has various fundamental properties such as reflexivity, transitivity, and left weakening.</p><p>Proposition A.8. Let Σ and Γ be two sets of formulas in KBE. It holds:</p><p>(1) Reflexivity holds i.e. if ϕ ∈ Σ, then Σ ϕ (2) Transitivity holds i.e. if Σ ϕ and {ϕ} ψ, then Σ ψ (3) Left weakening holds i.e. if Σ ϕ and Σ ⊆ Γ, then Γ ϕ Proof. Let Σ and Γ be two non-empty sets of formulas in KBE.</p><p>(1) If ϕ ∈ Σ, then since ϕ ⇒ ϕ, by definition of KBE-deductibility, we have Σ ϕ.</p><p>(2) If Σ ϕ and {ϕ} ψ, then there exists ψ 1 , . . . , ψ n ∈ Σ with n ∈ N * such that:</p><p>Furthermore since {ϕ} ψ, by definition we have ϕ ⇒ ψ. Thus, we deduce:</p><p>Consequently, we prove that Σ ψ.</p><p>(3) If Σ ϕ and Σ ⊆ Γ, then there exists ψ 1 , . . . , ψ n ∈ Σ with n ∈ N * such that:</p><p>Since ψ 1 , . . . , ψ n ∈ Σ and Σ ⊆ Γ, we have ψ 1 , . . . , ψ n ∈ Γ. Thus, we prove that Γ ϕ.</p><p>We prove now the deduction theorem of KBE. We first recall the definition of a model of a set of formula.</p><p>Definition A.9. Let Σ be a set of formulas and ϕ be a formula. Σ semantically entails ϕ, written Σ |= ϕ if, and only if, for all models M of Σ (i.e. ∀ψ ∈ Σ, M |= ψ), M |= ϕ.</p></div>
<div><head>Theorem A.10 (Deduction theorems).</head><p>If Γ is a set of formulas in KBE, ϕ and ψ be two formulas of KBE, then:</p><p>(1) Γ ∪ {ψ} ϕ if, and only if, Γ ψ ⇒ ϕ If Γ is a set of formulas in KBE, ϕ and ψ be two formulas of KBE, then:</p><p>(2) Γ ∪ {ψ} |= ϕ if, and only if, Γ |= ψ ⇒ ϕ Proof. Let Γ ⊆ L KBE be a set of formulas, ϕ and ψ be two formulas of L KBE .</p><p>(⇒) Let us assume that Γ ∪ {ψ} ϕ. By definition of the KBE-deductibility, we have that there exists Σ = {ψ 1 , . . . , ψ n }, Σ ⊆ Γ ∪ {ψ} such that: i∈{1,...,n}</p><p>We have two cases to consider ψ ∈ Σ and when ψ ∈ Σ.</p><p>(1) If ψ ∈ Σ, then there exists i ∈ {1, . . . , n} such that ψ = ψ i . So ( </p><p>Consequently, since for all k ∈ {1, . . . , n}, ψ k ∈ Σ and so ψ k ∈ Γ by inclusion. Thus, Γ ψ ⇒ ϕ.</p><p>The semantic version (2) of the deduction theorem immediately follows:</p></div>
<div><head>A.3.3. Maximal KBE-consistent sets</head><p>First of all let us recall some well-known results about maximal consistent sets. A set of formulas Σ is inconsistent if, and only if, ∃ψ 1 , . . . , ψ n ∈ Σ : ¬ n i=1 ψ i . A set of formulas Σ is consistent iff Σ is not inconsistent. A set of formulas Γ is a maximal consistent iff Γ : Γ Γ , Γ consistent. It leads us to the well-known Lindenbaum's lemma: for all consistent sets of formulas Γ , there exists a set of formulas Γ s.t Γ ⊆ Γ and Γ is a maximal consistent set (MCS). Let us consider a MCS Γ and ϕ, ψ ∈ L KBE two formulas:</p><p>In order to prove that our system is complete, we are doing a Henkin-like proof. Thus, we need to define the canonical model for our non normal system <ref type="bibr" target="#b57">Pacuit (2017)</ref>.</p><p>) is the canonical model for KBE if, and only if M c is such that:</p><p>• W c is a non-empty set of worlds where each world is a MCS,</p><p>The part E d c i of the canonical model for KBE corresponds to the notion of minimal canonical model for neighborhood semantics described in <ref type="bibr" target="#b57">Pacuit (2017)</ref>. In the sequel, we use the following notations, for all i ∈ N , w ∈ W c :</p><p>) be a minimal canonical model for KBE.</p><p>Lemma A.12. Let i, j ∈ N and ϕ ∈ L KBE be a formula,</p><p>There exists n ∈ N and ψ 1 , . . . , ψ n ∈ R * (w) such that:</p><p>and only if, ψ k ∈ w and w is a maximal KBE-consistent set. Thus, n k=1 ψ k ∈ w (MCS3') and so { ψ 1 , . . . , ψ n } is KBE-consistent. But { ψ 1 , . . . , ψ n } ∪ {¬ ϕ} is KBE-inconsistent. So ¬ ϕ cannot belong to the set of maximal KBE-consistent formulas w. Indeed by reductio ad absurdum, if we have ¬ ϕ ∈ w, we would also have that n k=1 ψ k ∧ ¬ ϕ ∈ w (by MCS3'), and { ψ 1 , . . . , ψ n , ¬ ϕ} would be KBE-consistent, which is a contradiction. Thus, ¬ ϕ / ∈ w. Consequently we prove that if ¬ ϕ ∈ w, then R * (w) ∪ {¬ϕ} is KBEconsistent.</p><p>Lemma A.13. Let i, j ∈ N and ϕ, ψ ∈ L KBE be a formula,</p><p>We need a second lemma to demonstrate the completeness of our system. This lemma shows that any valid formula of the canonical model is a formula of a maximal KBE-consistent set corresponding to a world in which it is verified and reciprocally.</p><p>The following proofs are based on the degree of formulas. We recall the basic notion of a degree of a formula. Definition A.15. We define deg : L KBE → N the degree function iff for all ϕ, ψ ∈ L KBE :</p><p>(1) ∀p ∈ P, deg(p</p><p>We say that the degree of a formula ϕ is n ∈ N * iff deg(ϕ) = n. </p><p>Let us consider (R, ) ∈ {(B i , B i ), (K i , K i ), (E i , E i )} and a world w ∈ W c . Let us show that the equivalence for normal modalities by double implication.</p><p>(⇒) Let us assume by contraposition that ψ / ∈ w and since w is a maximal KBEconsistent set, we have ¬ ψ ∈ w. By the previous lemma, we have R * (w) ∪ {¬ψ} is KBE-consistent and so, by the Lindenbaum's lemma, there exists v ∈ W c : R * (w) ∪ {¬ψ} ⊆ v and v is maximal KBE-consistent set. So we have ¬ψ ∈ v and, by definition of R c , we have wR c v. Furthermore, we have ψ / Lemma A.17, we have ϕ. Consequently, we have proved that the KBE system is complete.</p></div>
<div><head>A.4. Strong properties of KBE</head><p>We prove here the strong soundness and strong completeness of KBE.</p></div>
<div><head>A.4.1. Strong soundness</head><p>In the following, we demonstrate the strong correction of KBE. The strong correction is an almost immediate consequence of the correction and the semantic weakening that we demonstrate in the proof of the theorem.</p><p>Theorem A.19 (Strongly soundness of KBE). Let Γ be a set of formulas of KBE, ϕ be a theorem of KBE, we have that the system KBE is strongly sound, i.e. if Γ ϕ then Γ |= ϕ.</p><p>Proof. Let Γ be a set of formulas of KBE, ϕ be a formula of KBE. Let us assume that Γ ϕ, so there exists ψ 1 , . . . , ψ n ∈ Γ such that ψ 1 ∧ . . . ∧ ψ n ⇒ ϕ. Thus, by soundness we have |= ψ </p></div>
<div><head>A.4.2. Strong completeness</head><p>The KBE system is strongly complete. In order to demonstrate the strong completeness of the system, we need the following lemma A.20.</p><p>Lemma A.20. For all KBE-consistent sets Γ of formulas, there exists a world w ∈ W c in the canonical model M c such that M c , w |= Γ, i.e. ∀ϕ ∈ Γ : M c , w |= ϕ.</p><p>Proof. Let M c = (W c , (K c i ) i∈N , (B c i ) i∈N , (E c i ) i∈N , (E d c i ) i∈N , V c ) be the canonical model. Let Γ be a KBE-consistent set of formulas. By applying the lemma of Lindenbaum, there exists a maximal consistent set of formulas Γ such that Γ ⊆ Γ and Γ ∈ W c . Let w = Γ denotes the possible world in W c . We have ∀ϕ ∈ Γ : M c , Γ |= ϕ, and so ∀ϕ ∈ Γ : M c , Γ |= ϕ i.e. ∀ϕ ∈ Γ : M c , w |= ϕ. Thus, we have proved that for</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">The many faces of power and liberty: Revealed preference, autonomy, and teleological explanation</title>
		<author>
			<persName><forename type="first">P</forename><surname>Abell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sociology</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="3" to="24" />
			<date type="published" when="1977">1977</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">The concept of manipulativeness</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">N</forename><surname>Ackerman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Philosophical Perspectives</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="335" to="340" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Stock market manipulations</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">K</forename><surname>Aggarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Business</title>
		<imprint>
			<biblScope unit="volume">79</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1915" to="1953" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Privacy, trust, and manipulation in online relationships</title>
		<author>
			<persName><forename type="first">E</forename><surname>Aïmeur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Sahnoune</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Technology in Human Services</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="159" to="183" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Linguistic manipulation: Definition and types</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">S</forename><surname>Akopova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Cognitive Research in Science, Engineering and Education</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="78" to="82" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Alternating-time temporal logic</title>
		<author>
			<persName><forename type="first">R</forename><surname>Alur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">A</forename><surname>Henzinger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Kupferman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the ACM</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="672" to="713" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Alternative axiomatics and complexity of deliberative STIT theories</title>
		<author>
			<persName><forename type="first">P</forename><surname>Balbiani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Herzig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Troquard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Philosophical Logic</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="387" to="406" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">What is manipulation</title>
		<author>
			<persName><forename type="first">A</forename><surname>Barnhill</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Manipulation: Theory and practice</title>
		<editor>
			<persName><forename type="first">C</forename><surname>Coons</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Weber</surname></persName>
		</editor>
		<imprint>
			<publisher>Oxford University Press</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="51" to="72" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Manipulativeness</title>
		<author>
			<persName><forename type="first">M</forename><surname>Baron</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Addresses of the American Philosophical Association</title>
		<imprint>
			<biblScope unit="volume">77</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="37" to="54" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Seeing to it that: a canonical form for agentives</title>
		<author>
			<persName><forename type="first">N</forename><surname>Belnap</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Perloff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Theoria</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="175" to="199" />
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<author>
			<persName><forename type="first">P</forename><surname>Blackburn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>De Rijke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Venema</surname></persName>
		</author>
		<title level="m">Modal logic: Graph. darst</title>
		<imprint>
			<publisher>Cambridge University Press</publisher>
			<date type="published" when="2002">2002</date>
			<biblScope unit="volume">53</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Influencing choices by changing beliefs: A logical theory of influence, persuasion, and deception</title>
		<author>
			<persName><forename type="first">G</forename><surname>Bonnet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Leturc</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Lorini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Sartor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Deceptive AI. DeceptECAI 2020</title>
		<title level="s">Communications in Computer and Information Science</title>
		<editor>
			<persName><forename type="first">S</forename><surname>Sarkadi</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">B</forename><surname>Wright</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><surname>Masters</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><forename type="middle">P</forename></persName>
		</editor>
		<meeting><address><addrLine>DeceptAI</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2021">2021. 2021</date>
			<biblScope unit="volume">1296</biblScope>
			<biblScope unit="page" from="124" to="141" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">On help and interpersonal control</title>
		<author>
			<persName><forename type="first">E</forename><surname>Bottazzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Troquard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The cognitive foundations of group attitudes and social interaction</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Herzig</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">E</forename><surname>Lorini</surname></persName>
		</editor>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1" to="23" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Manipulation: description, identification and ambiguity</title>
		<author>
			<persName><forename type="first">L</forename><surname>Bowers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Psychiatric and Mental Health Nursing</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="323" to="328" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">A complete STIT logic for knowledge and action, and some of its applications</title>
		<author>
			<persName><forename type="first">J</forename><surname>Broersen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International workshop on declarative agent languages and technologies</title>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="47" to="59" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Digital market manipulation</title>
		<author>
			<persName><forename type="first">R</forename><surname>Calo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">George Washington Law Review</title>
		<imprint>
			<biblScope unit="volume">82</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="995" to="1051" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Trust theory: A socio-cognitive and computational model</title>
		<author>
			<persName><forename type="first">C</forename><surname>Castelfranchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Falcone</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010">2010</date>
			<publisher>John Wiley &amp; Sons</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Harnessing the science of persuasion</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">B</forename><surname>Cialdini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Harvard Business Review</title>
		<imprint>
			<biblScope unit="volume">79</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="72" to="81" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">B</forename><surname>Cialdini</surname></persName>
		</author>
		<title level="m">Influence and manipulation</title>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
	<note>First Editions</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Manipulation and deception</title>
		<author>
			<persName><forename type="first">S</forename><surname>Cohen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Australasian Journal of Philosophy</title>
		<imprint>
			<biblScope unit="volume">96</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1" to="15" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Manipulation and ideologies in the twentieth century: Discourse, language, mind</title>
		<author>
			<persName><forename type="first">L</forename><surname>De Saussure</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Schulz</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005">2005</date>
			<publisher>John Benjamins Publishing</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">A theory of deception</title>
		<author>
			<persName><forename type="first">D</forename><surname>Ettinger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Jehiel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Microeconomics</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="20" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">R</forename><surname>Faden</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">L</forename><surname>Beauchamp</surname></persName>
		</author>
		<title level="m">A history and theory of informed consent</title>
		<imprint>
			<publisher>Oxford University Press</publisher>
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Belief, awareness, and limited reasoning</title>
		<author>
			<persName><forename type="first">R</forename><surname>Fagin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">Y</forename><surname>Halpern</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="39" to="76" />
			<date type="published" when="1987">1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<author>
			<persName><forename type="first">L</forename><surname>Festinger</surname></persName>
		</author>
		<title level="m">A theory of cognitive dissonance</title>
		<imprint>
			<publisher>Stanford University Press</publisher>
			<date type="published" when="1962">1962</date>
			<biblScope unit="volume">2</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Manipulation of social choice functions</title>
		<author>
			<persName><forename type="first">P</forename><surname>Gärdenfors</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Economic Theory</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="217" to="228" />
			<date type="published" when="1976">1976</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Manipulation of voting schemes: a general result</title>
		<author>
			<persName><forename type="first">A</forename><surname>Gibbard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Econometrica</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="587" to="601" />
			<date type="published" when="1973">1973</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Ramification and causality in a modal action logic</title>
		<author>
			<persName><forename type="first">L</forename><surname>Giordano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Martelli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Schwind</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Logic and Computation</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="625" to="662" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Goodin</surname></persName>
		</author>
		<title level="m">Manipulatory politics</title>
		<imprint>
			<publisher>Yale University Press</publisher>
			<date type="published" when="1980">1980</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Borderline personality disorder</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">G</forename><surname>Gunderson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1984">1984</date>
			<publisher>SUNY Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Thought manipulation: the use and abuse of psychological trickery</title>
		<author>
			<persName><forename type="first">S</forename><surname>Handelman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
			<publisher>Praeger</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Dynamic logic</title>
		<author>
			<persName><forename type="first">D</forename><surname>Harel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Kozen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tiuryn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Handbook of philosophical logic</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="99" to="217" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Awareness dynamics</title>
		<author>
			<persName><forename type="first">B</forename><surname>Hill</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Philosophical Logic</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="113" to="137" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">A survey of attack and defense techniques for reputation systems</title>
		<author>
			<persName><forename type="first">K</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zage</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Nita-Rotaru</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Computing Surveys</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="17" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">A survey of attack and defense techniques for reputation systems</title>
		<author>
			<persName><forename type="first">K</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zage</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Nita-Rotaru</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Computing Surveys (CSUR)</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">1</biblScope>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Challenges for robust trust and reputation systems</title>
		<author>
			<persName><forename type="first">A</forename><surname>Josang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Golbeck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">5th International workshop on security and trust management</title>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<author>
			<persName><forename type="first">R.-V</forename><surname>Joule</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-L</forename><surname>Beauvois</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-C</forename><surname>Deschamps</surname></persName>
		</author>
		<title level="m">Concise handbook of manipulation in honest people's favour</title>
		<imprint>
			<publisher>Grenoble University Press</publisher>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
	<note>french edition</note>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">How can people be induced to willingly change their behavior? The path from persuasive communication to binding communication</title>
		<author>
			<persName><forename type="first">R.-V</forename><surname>Joule</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Girandola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Bernard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Social and Personality Psychology Compass</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="493" to="505" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Thinking, fast and slow</title>
		<author>
			<persName><forename type="first">D</forename><surname>Kahneman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011">2011</date>
			<publisher>Macmillan</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">An analysis of interpersonal manipulation</title>
		<author>
			<persName><forename type="first">M</forename><surname>Kligman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">M</forename><surname>Culver</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Medicine and Philosophy</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="173" to="197" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">A normal modal logic for trust in the sincerity</title>
		<author>
			<persName><forename type="first">C</forename><surname>Leturc</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Bonnet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">17th International conference on autonomous agents and multiagent systems</title>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="175" to="183" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">A deliberate BIAT logic for modeling manipulations</title>
		<author>
			<persName><forename type="first">C</forename><surname>Leturc</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Bonnet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">20th International conference on autonomous agents and multiagent systems</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="699" to="707" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">A logic of implicit and explicit belief</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">J</forename><surname>Levesque</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI Conference on artificial intelligence</title>
		<imprint>
			<date type="published" when="1984">1984</date>
			<biblScope unit="page" from="198" to="202" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">A STIT logic for reasoning about social influence</title>
		<author>
			<persName><forename type="first">E</forename><surname>Lorini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Sartor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Studia Logica</title>
		<imprint>
			<biblScope unit="volume">104</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="773" to="812" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">Trust and power</title>
		<author>
			<persName><forename type="first">N</forename><surname>Luhmann</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1979">1979</date>
			<publisher>Wiley</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Two definitions of lying</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Mahon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Applied Philosophy</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="211" to="230" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Defining manipulative discourse: The pragmatics of cognitive illusions</title>
		<author>
			<persName><forename type="first">D</forename><surname>Maillat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Oswald</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Review of Pragmatics</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="348" to="370" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Framing the national interest: The manipulation of foreign policy decisions in group settings</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Maoz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">World Politics</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="77" to="110" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Characterising deception in AI: A survey</title>
		<author>
			<persName><forename type="first">P</forename><surname>Masters</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Sonenberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kirley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Deceptive AI. DeceptECAI 2020</title>
		<title level="s">Communications in Computer and Information Science</title>
		<editor>
			<persName><forename type="first">S</forename><surname>Sarkadi</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">B</forename><surname>Wright</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><surname>Masters</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><forename type="middle">P</forename></persName>
		</editor>
		<meeting><address><addrLine>DeceptAI</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2021">2021. 2021</date>
			<biblScope unit="volume">1296</biblScope>
			<biblScope unit="page" from="3" to="16" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Coercion: its nature and significance</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">J</forename><surname>Mccloskey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Southern Journal of Philosophy</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="335" to="351" />
			<date type="published" when="1980">1980</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<title level="m" type="main">Mindfucking: A critique of mental manipulation</title>
		<author>
			<persName><forename type="first">C</forename><surname>Mcginn</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014">2014</date>
			<publisher>Routledge</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Politics and manipulation</title>
		<author>
			<persName><forename type="first">C</forename><surname>Mills</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Social Theory and Practice</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="97" to="112" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">The strategy concept I: Five Ps for strategy</title>
		<author>
			<persName><forename type="first">H</forename><surname>Mintzberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">California Management Review</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="11" to="24" />
			<date type="published" when="1987">1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Attacks and remedies in collaborative recommendation</title>
		<author>
			<persName><forename type="first">B</forename><surname>Mobasher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Burke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Bhaumik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Sandvig</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Intelligent Systems</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="56" to="63" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Awareness and partitional information structures</title>
		<author>
			<persName><forename type="first">S</forename><surname>Modica</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rustichini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Theory and Decision</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="107" to="124" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Manipulative actions: a conceptual and moral analysis</title>
		<author>
			<persName><forename type="first">R</forename><surname>Noggle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">American Philosophical Quarterly</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="43" to="55" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<monogr>
		<title level="m" type="main">Persuasion: Theory and research</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>O'keefe</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015">2015</date>
			<publisher>Sage Publications</publisher>
		</imprint>
	</monogr>
	<note>third edition</note>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
		<title level="m" type="main">Neighborhood semantics for modal logic</title>
		<author>
			<persName><forename type="first">E</forename><surname>Pacuit</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Preventing strategic manipulation in iterative auctions: Proxy agents and price-adjustment</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">C</forename><surname>Parkes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">H</forename><surname>Ungar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI Conference on artificial intelligence</title>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="82" to="89" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<monogr>
		<title level="m" type="main">Action theory and social science: Some formal models</title>
		<author>
			<persName><forename type="first">I</forename><surname>Pörn</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1977">1977</date>
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Parasite manipulation of host behavior: an update and frequently asked questions</title>
		<author>
			<persName><forename type="first">R</forename><surname>Poulin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in the Study of Behavior</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="page" from="151" to="186" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<monogr>
		<title level="m" type="main">The morality of freedom</title>
		<author>
			<persName><forename type="first">J</forename><surname>Raz</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1986">1986</date>
			<publisher>Clarendon Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Manipulation-resistant recommender systems through influence limits</title>
		<author>
			<persName><forename type="first">P</forename><surname>Resnick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Sami</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM SIGecom Exchanges</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">10</biblScope>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Towards a typology of manipulative processes</title>
		<author>
			<persName><forename type="first">E</forename><surname>Rigotti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Manipulation and ideologies in the twentieth century: discourse, language</title>
		<editor>
			<persName><forename type="first">L</forename><surname>De Saussure</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">&amp;</forename><forename type="middle">P</forename><surname>Schulz</surname></persName>
		</editor>
		<imprint>
			<publisher>John Benjamins Publishing Company</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="61" to="83" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Collusion and the choice of auction</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Robinson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">RAND Journal of Economics</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="141" to="145" />
			<date type="published" when="1985">1985</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Power-orientations in the mental hospital</title>
		<author>
			<persName><forename type="first">M</forename><surname>Rosenberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">I</forename><surname>Pearlin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Human Relations</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="335" to="349" />
			<date type="published" when="1962">1962</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">A survey of trust management systems for online social communities -trust modeling, trust inference and attacks</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Ruan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Durresi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Knowledge-Based Systems</title>
		<imprint>
			<biblScope unit="volume">106</biblScope>
			<biblScope unit="page" from="150" to="163" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title />
		<author>
			<persName><forename type="first">J</forename><surname>Rudinow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Manipulation. Ethics</title>
		<imprint>
			<biblScope unit="volume">88</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="338" to="347" />
			<date type="published" when="1978">1978</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Manipulation</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">R</forename><surname>Saint Clair</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comprehensive Psychiatry</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="248" to="258" />
			<date type="published" when="1966">1966</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Deception in epistemic causal logic</title>
		<author>
			<persName><forename type="first">C</forename><surname>Sakama</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Deceptive AI. DeceptECAI 2020</title>
		<title level="s">Communications in Computer and Information Science</title>
		<editor>
			<persName><forename type="first">S</forename><surname>Sarkadi</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">B</forename><surname>Wright</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><surname>Masters</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><forename type="middle">P</forename></persName>
		</editor>
		<meeting><address><addrLine>DeceptAI</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2021">2021. 2021</date>
			<biblScope unit="volume">1296</biblScope>
			<biblScope unit="page" from="105" to="123" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">A formal account of dishonesty</title>
		<author>
			<persName><forename type="first">C</forename><surname>Sakama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Caminada</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Herzig</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Logic Journal of the IGPL</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="259" to="294" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><surname>Sanghvi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Parkes</surname></persName>
		</author>
		<title level="m">Hard-to-manipulate VCG-based auctions</title>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
		<respStmt>
			<orgName>Division of Engineering and Applied Sciences: Harvard University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Tech. Rep.</note>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Indirect action, influence and responsibility</title>
		<author>
			<persName><forename type="first">F</forename><surname>Santos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Carmo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Deontic logic, agency and normative systems</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1996">1996</date>
			<biblScope unit="page" from="194" to="215" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Awareness</title>
		<author>
			<persName><forename type="first">B</forename><surname>Schipper</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Handbook of epistemic logic</title>
		<editor>
			<persName><forename type="first">H</forename><surname>Van Ditmarsch</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">Y</forename><surname>Halpern</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">W</forename><surname>Van Der Hoek</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">&amp;</forename><forename type="middle">B</forename><surname>Kooi</surname></persName>
		</editor>
		<imprint>
			<publisher>College Publications</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="77" to="146" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">The logic of action</title>
		<author>
			<persName><forename type="first">K</forename><surname>Segerberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-J</forename><surname>Meyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kracht</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">Stanford Library of Philosophy</title>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">Eclipse attacks on overlay networks: Threats and defenses</title>
		<author>
			<persName><forename type="first">A</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T.-W</forename><surname>Ngan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Druschel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wallach</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">25th International Conference on Computer Communications</title>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">The pragmatics of manipulation: Exploiting im/politeness theories</title>
		<author>
			<persName><forename type="first">S</forename><surname>Sorlin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Pragmatics</title>
		<imprint>
			<biblScope unit="volume">121</biblScope>
			<biblScope unit="page" from="132" to="146" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">On logics of knowledge and belief</title>
		<author>
			<persName><forename type="first">R</forename><surname>Stalnaker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Philosophical Studies</title>
		<imprint>
			<biblScope unit="volume">128</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="169" to="199" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<monogr>
		<title level="m" type="main">The game</title>
		<author>
			<persName><forename type="first">N</forename><surname>Strauss</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006">2006</date>
			<publisher>Canongate Books</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">Fifty shades of manipulation</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">R</forename><surname>Sunstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Marketing Behavior</title>
		<imprint>
			<biblScope unit="page">213</biblScope>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<monogr>
		<title level="m" type="main">Manipulation. International Encyclopedia of Ethics</title>
		<author>
			<persName><forename type="first">P</forename><surname>Todd</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<analytic>
		<title level="a" type="main">Reasoning about coalitional agency and ability in the logics of "bringingit-about</title>
		<author>
			<persName><forename type="first">N</forename><surname>Troquard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Autonomous Agents and Multiagent Systems</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="381" to="407" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<analytic>
		<title level="a" type="main">The importance of placebo effects in pain treatment and research</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Turner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Deyo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Loeser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Von Korff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">E</forename><surname>Fordyce</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Medical Association</title>
		<imprint>
			<biblScope unit="volume">271</biblScope>
			<biblScope unit="issue">20</biblScope>
			<biblScope unit="page" from="1609" to="1614" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<analytic>
		<title level="a" type="main">Using KL divergence for credibility assessment</title>
		<author>
			<persName><forename type="first">T</forename><surname>Vallée</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Bonnet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">14th International conference on autonomous agents and multiagent Systems</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1797" to="1798" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b84">
	<analytic>
		<title level="a" type="main">Discourse and manipulation</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">A</forename><surname>Van Dijk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Discourse &amp; Society</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="359" to="383" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b85">
	<monogr>
		<title level="m" type="main">Dynamic epistemic logic</title>
		<author>
			<persName><forename type="first">H</forename><surname>Van Ditmarsch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Van Der Hoek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Kooi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007">2007</date>
			<publisher>Springer Science &amp; Business Media</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b86">
	<analytic>
		<title level="a" type="main">A logic of revelation and concealment</title>
		<author>
			<persName><forename type="first">W</forename><surname>Van Der Hoek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Iliev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Wooldridge</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Aamas</title>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="1115" to="1122" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b87">
	<analytic>
		<title level="a" type="main">Implicit, explicit and speculative knowledge</title>
		<author>
			<persName><forename type="first">H</forename><surname>Van Ditmarsch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>French</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">R</forename><surname>Velázquez-Quesada</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">N</forename><surname>Wáng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">256</biblScope>
			<biblScope unit="page" from="35" to="67" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b88">
	<analytic>
		<title level="a" type="main">On the logic of lying</title>
		<author>
			<persName><forename type="first">H</forename><surname>Van Ditmarsch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Van Eijck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Sietsma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Games, actions and social software</title>
		<editor>
			<persName><forename type="first">J</forename><surname>Van Eijck</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">&amp;</forename><forename type="middle">R</forename><surname>Verbrugge</surname></persName>
		</editor>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="41" to="72" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b89">
	<analytic>
		<title level="a" type="main">Robot deception: recognizing when a robot should deceive</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">R</forename><surname>Wagner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">C</forename><surname>Arkin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International symposium on computational intelligence in robotics and automation</title>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="46" to="54" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b90">
	<analytic>
		<title level="a" type="main">The concept of manipulation: its relation to democracy and power</title>
		<author>
			<persName><forename type="first">A</forename><surname>Ware</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">British Journal of Political Science</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="163" to="181" />
			<date type="published" when="1981">1981</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b91">
	<analytic>
		<title level="a" type="main">Tactical deception in primates</title>
		<author>
			<persName><forename type="first">A</forename><surname>Whiten</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">W</forename><surname>Byrne</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Behavioral and Brain Sciences</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="233" to="244" />
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b92">
	<analytic>
		<title level="a" type="main">Nudging and manipulation</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">M</forename><surname>Wilkinson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Political Studies</title>
		<imprint>
			<biblScope unit="volume">61</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="341" to="355" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b93">
	<analytic>
		<title level="a" type="main">Coercion, manipulation</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">W</forename><surname>Wood</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Manipulation: Theory and practice</title>
		<editor>
			<persName><forename type="first">C</forename><surname>Coons</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Weber</surname></persName>
		</editor>
		<imprint>
			<publisher>Oxford University Press</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="17" to="50" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</teiCorpus></text>
</TEI>