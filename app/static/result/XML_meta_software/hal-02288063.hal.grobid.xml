<?xml version='1.0' encoding='utf-8'?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" version="1.1" xsi:schemaLocation="http://www.tei-c.org/ns/1.0 http://api.archives-ouvertes.fr/documents/aofr-sword.xsd">
  <teiHeader>
    <fileDesc>
      <titleStmt>
        <title>HAL TEI export of hal-02288063</title>
      </titleStmt>
      <publicationStmt>
        <distributor>CCSD</distributor>
        <availability status="restricted">
          <licence target="http://creativecommons.org/licenses/by/4.0/">Distributed under a Creative Commons Attribution 4.0 International License</licence>
        </availability>
        <date when="2024-04-29T03:17:52+02:00" />
      </publicationStmt>
      <sourceDesc>
        <p part="N">HAL API platform</p>
      </sourceDesc>
    </fileDesc>
  </teiHeader>
  <text>
    <body>
      <listBibl>
        <biblFull>
          <titleStmt>
            <title xml:lang="en">Cauchy Multichannel Speech Enhancement with a Deep Speech Prior</title>
            <author role="aut">
              <persName>
                <forename type="first">Mathieu</forename>
                <surname>Fontaine</surname>
              </persName>
              <email type="md5">89a2d201f3abde448209bbdfb6c03b44</email>
              <email type="domain">telecom-paris.fr</email>
              <idno type="idhal" notation="string">mathieu-fontaine</idno>
              <idno type="idhal" notation="numeric">13405</idno>
              <idno type="halauthorid" notation="string">34886-13405</idno>
              <idno type="ORCID">https://orcid.org/0000-0002-7657-6271</idno>
              <idno type="IDREF">https://www.idref.fr/236886681</idno>
              <affiliation ref="#struct-420403" />
              <affiliation ref="#struct-300362" />
            </author>
            <author role="aut">
              <persName>
                <forename type="first">Aditya Arie</forename>
                <surname>Nugraha</surname>
              </persName>
              <email type="md5">baec7ba689fcda4261289b932762b5ca</email>
              <email type="domain">riken.jp</email>
              <idno type="idhal" notation="string">aanugraha</idno>
              <idno type="idhal" notation="numeric">4303</idno>
              <idno type="halauthorid" notation="string">38615-4303</idno>
              <idno type="ORCID">https://orcid.org/0000-0001-5424-747X</idno>
              <idno type="IDREF">https://www.idref.fr/223438278</idno>
              <affiliation ref="#struct-569958" />
            </author>
            <author role="aut">
              <persName>
                <forename type="first">Roland</forename>
                <surname>Badeau</surname>
              </persName>
              <email type="md5">4f9855374b5f1933b5b849d0082a29a1</email>
              <email type="domain">enst.fr</email>
              <idno type="idhal" notation="string">rbadeau</idno>
              <idno type="idhal" notation="numeric">1121</idno>
              <idno type="halauthorid" notation="string">20667-1121</idno>
              <idno type="IDREF">https://www.idref.fr/106938134</idno>
              <idno type="ORCID">https://orcid.org/0000-0002-9630-6877</idno>
              <orgName ref="#struct-300362" />
              <affiliation ref="#struct-554452" />
              <affiliation ref="#struct-554512" />
            </author>
            <author role="aut">
              <persName>
                <forename type="first">Kazuyoshi</forename>
                <surname>Yoshii</surname>
              </persName>
              <idno type="halauthorid">1216004-0</idno>
              <affiliation ref="#struct-569958" />
              <affiliation ref="#struct-555649" />
            </author>
            <author role="aut">
              <persName>
                <forename type="first">Antoine</forename>
                <surname>Liutkus</surname>
              </persName>
              <email type="md5">7ab1134d5b439685d1e0412dcdc5142a</email>
              <email type="domain">telecom-paristech.fr</email>
              <idno type="idhal" notation="string">antoine-liutkus</idno>
              <idno type="idhal" notation="numeric">2740</idno>
              <idno type="halauthorid" notation="string">25455-2740</idno>
              <idno type="GOOGLE SCHOLAR">https://scholar.google.fr/citations?user=0s7V4FAAAAAJ&amp;hl=fr</idno>
              <idno type="IDREF">https://www.idref.fr/167600419</idno>
              <idno type="ORCID">https://orcid.org/0000-0002-3458-6498</idno>
              <orgName ref="#struct-300009" />
              <affiliation ref="#struct-141072" />
            </author>
            <editor role="depositor">
              <persName>
                <forename>TelecomParis</forename>
                <surname>HAL</surname>
              </persName>
              <email type="md5">f0a3d3bd944d31b06d22d97fd2a37eac</email>
              <email type="domain">telecom-paristech.fr</email>
            </editor>
            <funder ref="#projanr-45798" />
            <funder>This work was partly supported by the research programme KAMoulox (ANR- 15-CE38-0003-01) funded by ANR, the French State agency for research, and JSPS KAKENHI No. 19H04137.</funder>
          </titleStmt>
          <editionStmt>
            <edition n="v1" type="current">
              <date type="whenSubmitted">2019-10-16 15:54:18</date>
              <date type="whenModified">2024-02-01 10:04:34</date>
              <date type="whenReleased">2019-10-18 09:34:29</date>
              <date type="whenProduced">2019-09-02</date>
              <date type="whenEndEmbargoed">2019-10-16</date>
              <ref type="file" target="https://telecom-paris.hal.science/hal-02288063/document">
                <date notBefore="2019-10-16" />
              </ref>
              <ref type="file" subtype="author" n="1" target="https://telecom-paris.hal.science/hal-02288063/file/eusipco-2019-fontaine.pdf">
                <date notBefore="2019-10-16" />
              </ref>
              <ref type="externalLink" target="https://hal.telecom-paris.fr/hal-02288063/file/eusipco-2019-fontaine.pdf" />
            </edition>
            <respStmt>
              <resp>contributor</resp>
              <name key="750726">
                <persName>
                  <forename>TelecomParis</forename>
                  <surname>HAL</surname>
                </persName>
                <email type="md5">f0a3d3bd944d31b06d22d97fd2a37eac</email>
                <email type="domain">telecom-paristech.fr</email>
              </name>
            </respStmt>
          </editionStmt>
          <publicationStmt>
            <distributor>CCSD</distributor>
            <idno type="halId">hal-02288063</idno>
            <idno type="halUri">https://telecom-paris.hal.science/hal-02288063</idno>
            <idno type="halBibtex">fontaine:hal-02288063</idno>
            <idno type="halRefHtml">&lt;i&gt;EUSIPCO 2019 - 27th European Signal Processing Conference&lt;/i&gt;, Sep 2019, Coruña, Spain. &lt;a target="_blank" href="https://dx.doi.org/10.23919/EUSIPCO.2019.8903091"&gt;&amp;#x27E8;10.23919/EUSIPCO.2019.8903091&amp;#x27E9;&lt;/a&gt;</idno>
            <idno type="halRef">EUSIPCO 2019 - 27th European Signal Processing Conference, Sep 2019, Coruña, Spain. &amp;#x27E8;10.23919/EUSIPCO.2019.8903091&amp;#x27E9;</idno>
          </publicationStmt>
          <seriesStmt>
            <idno type="stamp" n="INSTITUT-TELECOM">Institut Mines Télécom</idno>
            <idno type="stamp" n="UNIV-RENNES1">Université de Rennes 1</idno>
            <idno type="stamp" n="CNRS">CNRS - Centre national de la recherche scientifique</idno>
            <idno type="stamp" n="INRIA">INRIA - Institut National de Recherche en Informatique et en Automatique</idno>
            <idno type="stamp" n="ENST">Ecole Nationale Supérieure des Télécommunications</idno>
            <idno type="stamp" n="INRIA-SOPHIA">INRIA Sophia Antipolis - Méditerranée</idno>
            <idno type="stamp" n="IRISA">Irisa</idno>
            <idno type="stamp" n="TELECOM-PARISTECH" corresp="INSTITUT-TELECOM">Télécom Paris</idno>
            <idno type="stamp" n="INRIASO">INRIA-SOPHIA</idno>
            <idno type="stamp" n="INRIA_TEST">INRIA - Institut National de Recherche en Informatique et en Automatique</idno>
            <idno type="stamp" n="INRIA-LORRAINE">INRIA Nancy - Grand Est</idno>
            <idno type="stamp" n="LORIA2">Publications du LORIA</idno>
            <idno type="stamp" n="INRIA34">Montpellier</idno>
            <idno type="stamp" n="INRIA-NANCY-GRAND-EST">INRIA Nancy - Grand Est</idno>
            <idno type="stamp" n="TESTALAIN1">TESTALAIN1</idno>
            <idno type="stamp" n="ZENITH" corresp="LIRMM">Scientific Data Management</idno>
            <idno type="stamp" n="LIRMM">Laboratoire d'Informatique de Robotique et de Microélectronique de Montpellier</idno>
            <idno type="stamp" n="UNIV-LORRAINE">Université de Lorraine</idno>
            <idno type="stamp" n="INRIA2">INRIA 2</idno>
            <idno type="stamp" n="UR1-HAL">Publications labos UR1 dans HAL-Rennes 1</idno>
            <idno type="stamp" n="LORIA">Laboratoire Lorrain de Recherche en Informatique et ses Applications</idno>
            <idno type="stamp" n="LORIA-NLPKD" corresp="LORIA">Department of Natural Language Processing &amp; Knowledge Discovery</idno>
            <idno type="stamp" n="UR1-MATH-STIC">UR1 - publications Maths-STIC</idno>
            <idno type="stamp" n="UR1-UFR-ISTIC">UFR ISTIC Informatique et électronique</idno>
            <idno type="stamp" n="MIPS">Mathématiques, Informatique, Physique et Systèmes</idno>
            <idno type="stamp" n="UNIV-MONTPELLIER">Université de Montpellier</idno>
            <idno type="stamp" n="TEST-UR-CSS">TEST Université de Rennes CSS</idno>
            <idno type="stamp" n="UNIV-RENNES">Université de Rennes</idno>
            <idno type="stamp" n="INRIA-300009">Inria 300009</idno>
            <idno type="stamp" n="LTCI" corresp="TELECOM-PARISTECH">Laboratoire Traitement et Communication de l'Information</idno>
            <idno type="stamp" n="IDS" corresp="TELECOM-PARISTECH">Département Image, Données, Signal</idno>
            <idno type="stamp" n="S2A" corresp="TELECOM-PARISTECH">Equipe Signal, Statistique et Apprentissage</idno>
            <idno type="stamp" n="IP_PARIS">Institut Polytechnique de Paris</idno>
            <idno type="stamp" n="INSTITUTS-TELECOM" corresp="INSTITUT-TELECOM">composantes instituts telecom </idno>
            <idno type="stamp" n="ANR">ANR</idno>
            <idno type="stamp" n="UR1-MATH-NUM">Pôle UnivRennes - Mathématiques - Numérique </idno>
            <idno type="stamp" n="INRIA-JAPON">Co-publications INRIA Japon</idno>
            <idno type="stamp" n="UM-2015-2021" corresp="UNIV-MONTPELLIER">Université de Montpellier (2015-2021)</idno>
          </seriesStmt>
          <notesStmt>
            <note type="audience" n="2">International</note>
            <note type="invited" n="0">No</note>
            <note type="popular" n="0">No</note>
            <note type="peer" n="1">Yes</note>
            <note type="proceedings" n="1">Yes</note>
          </notesStmt>
          <sourceDesc>
            <biblStruct>
              <analytic>
                <title xml:lang="en">Cauchy Multichannel Speech Enhancement with a Deep Speech Prior</title>
                <author role="aut">
                  <persName>
                    <forename type="first">Mathieu</forename>
                    <surname>Fontaine</surname>
                  </persName>
                  <email type="md5">89a2d201f3abde448209bbdfb6c03b44</email>
                  <email type="domain">telecom-paris.fr</email>
                  <idno type="idhal" notation="string">mathieu-fontaine</idno>
                  <idno type="idhal" notation="numeric">13405</idno>
                  <idno type="halauthorid" notation="string">34886-13405</idno>
                  <idno type="ORCID">https://orcid.org/0000-0002-7657-6271</idno>
                  <idno type="IDREF">https://www.idref.fr/236886681</idno>
                  <affiliation ref="#struct-420403" />
                  <affiliation ref="#struct-300362" />
                </author>
                <author role="aut">
                  <persName>
                    <forename type="first">Aditya Arie</forename>
                    <surname>Nugraha</surname>
                  </persName>
                  <email type="md5">baec7ba689fcda4261289b932762b5ca</email>
                  <email type="domain">riken.jp</email>
                  <idno type="idhal" notation="string">aanugraha</idno>
                  <idno type="idhal" notation="numeric">4303</idno>
                  <idno type="halauthorid" notation="string">38615-4303</idno>
                  <idno type="ORCID">https://orcid.org/0000-0001-5424-747X</idno>
                  <idno type="IDREF">https://www.idref.fr/223438278</idno>
                  <affiliation ref="#struct-569958" />
                </author>
                <author role="aut">
                  <persName>
                    <forename type="first">Roland</forename>
                    <surname>Badeau</surname>
                  </persName>
                  <email type="md5">4f9855374b5f1933b5b849d0082a29a1</email>
                  <email type="domain">enst.fr</email>
                  <idno type="idhal" notation="string">rbadeau</idno>
                  <idno type="idhal" notation="numeric">1121</idno>
                  <idno type="halauthorid" notation="string">20667-1121</idno>
                  <idno type="IDREF">https://www.idref.fr/106938134</idno>
                  <idno type="ORCID">https://orcid.org/0000-0002-9630-6877</idno>
                  <orgName ref="#struct-300362" />
                  <affiliation ref="#struct-554452" />
                  <affiliation ref="#struct-554512" />
                </author>
                <author role="aut">
                  <persName>
                    <forename type="first">Kazuyoshi</forename>
                    <surname>Yoshii</surname>
                  </persName>
                  <idno type="halauthorid">1216004-0</idno>
                  <affiliation ref="#struct-569958" />
                  <affiliation ref="#struct-555649" />
                </author>
                <author role="aut">
                  <persName>
                    <forename type="first">Antoine</forename>
                    <surname>Liutkus</surname>
                  </persName>
                  <email type="md5">7ab1134d5b439685d1e0412dcdc5142a</email>
                  <email type="domain">telecom-paristech.fr</email>
                  <idno type="idhal" notation="string">antoine-liutkus</idno>
                  <idno type="idhal" notation="numeric">2740</idno>
                  <idno type="halauthorid" notation="string">25455-2740</idno>
                  <idno type="GOOGLE SCHOLAR">https://scholar.google.fr/citations?user=0s7V4FAAAAAJ&amp;hl=fr</idno>
                  <idno type="IDREF">https://www.idref.fr/167600419</idno>
                  <idno type="ORCID">https://orcid.org/0000-0002-3458-6498</idno>
                  <orgName ref="#struct-300009" />
                  <affiliation ref="#struct-141072" />
                </author>
              </analytic>
              <monogr>
                <idno type="localRef">MF:EUSIPCO-19</idno>
                <meeting>
                  <title>EUSIPCO 2019 - 27th European Signal Processing Conference</title>
                  <date type="start">2019-09-02</date>
                  <date type="end">2019-09-06</date>
                  <settlement>Coruña</settlement>
                  <country key="ES">Spain</country>
                </meeting>
                <imprint>
                  <publisher>IEEE</publisher>
                  <date type="datePub">2019-09</date>
                </imprint>
              </monogr>
              <idno type="doi">10.23919/EUSIPCO.2019.8903091</idno>
            </biblStruct>
          </sourceDesc>
          <profileDesc>
            <langUsage>
              <language ident="en">English</language>
            </langUsage>
            <textClass>
              <keywords scheme="author">
                <term xml:lang="en">Nonnegative matrix factorization</term>
                <term xml:lang="en">multivariate complex Cauchy distribution</term>
                <term xml:lang="en">Multichannel speech enhancement</term>
                <term xml:lang="en">variational autoencoder</term>
              </keywords>
              <classCode scheme="halDomain" n="spi.signal">Engineering Sciences [physics]/Signal and Image processing</classCode>
              <classCode scheme="halTypology" n="COMM">Conference papers</classCode>
              <classCode scheme="halOldTypology" n="COMM">Conference papers</classCode>
              <classCode scheme="halTreeTypology" n="COMM">Conference papers</classCode>
            </textClass>
            <abstract xml:lang="en">
              <p>We propose a semi-supervised multichannel speech enhancement system based on a probabilistic model which assumes that both speech and noise follow the heavy-tailed multi-variate complex Cauchy distribution. As we advocate, this allows handling strong and adverse noisy conditions. Consequently, the model is parameterized by the source magnitude spectrograms and the source spatial scatter matrices. To deal with the non-additivity of scatter matrices, our first contribution is to perform the enhancement on a projected space. Then, our second contribution is to combine a latent variable model for speech, which is trained by following the variational autoencoder framework, with a low-rank model for the noise source. At test time, an iterative inference algorithm is applied, which produces estimated parameters to use for separation. The speech latent variables are estimated first from the noisy speech and then updated by a gradient descent method, while a majorization-equalization strategy is used to update both the noise and the spatial parameters of both sources. Our experimental results show that the Cauchy model outperforms the state-of-art methods. The standard deviation scores also reveal that the proposed method is more robust against non-stationary noise.</p>
            </abstract>
          </profileDesc>
        </biblFull>
      </listBibl>
    </body>
    <back>
      <listOrg type="structures">
        <org type="researchteam" xml:id="struct-420403" status="VALID">
          <idno type="RNSR">201421147E</idno>
          <orgName>Speech Modeling for Facilitating Oral-Based Communication</orgName>
          <orgName type="acronym">MULTISPEECH</orgName>
          <desc>
            <address>
              <country key="FR" />
            </address>
            <ref type="url">http://www.inria.fr/equipes/multispeech</ref>
          </desc>
          <listRelation>
            <relation active="#struct-129671" type="direct" />
            <relation active="#struct-300009" type="indirect" />
            <relation active="#struct-423086" type="direct" />
            <relation active="#struct-206040" type="indirect" />
            <relation active="#struct-413289" type="indirect" />
            <relation name="UMR7503" active="#struct-441569" type="indirect" />
          </listRelation>
        </org>
        <org type="institution" xml:id="struct-300362" status="VALID">
          <idno type="ROR">https://ror.org/01naq7912</idno>
          <orgName>Télécom ParisTech</orgName>
          <date type="start">2008-01-01</date>
          <date type="end">2019-06-11</date>
          <desc>
            <address>
              <addrLine>46 rue Barrault 75634 Paris Cedex 13</addrLine>
              <country key="FR" />
            </address>
            <ref type="url">https://www.telecom-paris.fr</ref>
          </desc>
        </org>
        <org type="institution" xml:id="struct-569958" status="VALID">
          <idno type="ROR">https://ror.org/03ckxwf91</idno>
          <orgName>RIKEN Center for Advanced Intelligence Project [Tokyo]</orgName>
          <orgName type="acronym">RIKEN AIP</orgName>
          <desc>
            <address>
              <addrLine>Nihonbashi 1-chome Mitsui Building, 15th floor, 1-4-1 Nihonbashi, Chuo-ku, Tokyo 103-0027, Japan</addrLine>
              <country key="JP" />
            </address>
            <ref type="url">https://www.riken.jp/en/research/labs/aip/</ref>
          </desc>
          <listRelation>
            <relation active="#struct-26075" type="direct" />
          </listRelation>
        </org>
        <org type="researchteam" xml:id="struct-554452" status="VALID">
          <orgName>Signal, Statistique et Apprentissage</orgName>
          <orgName type="acronym">S2A</orgName>
          <date type="start">2019-02-22</date>
          <desc>
            <address>
              <addrLine>Télécom Paris 19 Place Marguerite Perey 91120 Palaiseau</addrLine>
              <country key="FR" />
            </address>
            <ref type="url">https://www.telecom-paris.fr/fr/recherche/laboratoires/laboratoire-traitement-et-communication-de-linformation-ltci/les-equipes-de-recherche/signal-statistique-et-apprentissage-s2a</ref>
          </desc>
          <listRelation>
            <relation active="#struct-484335" type="direct" />
            <relation active="#struct-302102" type="indirect" />
            <relation active="#struct-1048346" type="indirect" />
          </listRelation>
        </org>
        <org type="department" xml:id="struct-554512" status="VALID">
          <orgName>Département Images, Données, Signal</orgName>
          <orgName type="acronym">IDS</orgName>
          <date type="start">2017-01-01</date>
          <desc>
            <address>
              <addrLine>46, rue Barrault 75013 Paris ; 15 Place Marguerite Perey 91120 Palaiseau (depuis oct 2019)</addrLine>
              <country key="FR" />
            </address>
            <ref type="url">https://www.telecom-paris.fr/fr/recherche/laboratoires/laboratoire-traitement-et-communication-de-linformation-ltci/les-departements-denseignement-et-recherche</ref>
          </desc>
          <listRelation>
            <relation active="#struct-300362" type="direct" />
          </listRelation>
        </org>
        <org type="institution" xml:id="struct-555649" status="VALID">
          <orgName>University of Tokyo [Kashiwa Campus]</orgName>
          <desc>
            <address>
              <addrLine>Kashiwa, Chiba 277-0882, Japan</addrLine>
              <country key="JP" />
            </address>
          </desc>
        </org>
        <org type="researchteam" xml:id="struct-141072" status="OLD">
          <idno type="RNSR">201121208J</idno>
          <orgName>Scientific Data Management</orgName>
          <orgName type="acronym">ZENITH</orgName>
          <date type="end">2021-12-31</date>
          <desc>
            <address>
              <addrLine>LIRMM, 161 rue Ada, 34000 Montpellier</addrLine>
              <country key="FR" />
            </address>
            <ref type="url">https://team.inria.fr/zenith/</ref>
          </desc>
          <listRelation>
            <relation active="#struct-181" type="direct" />
            <relation name="UMR5506" active="#struct-410122" type="indirect" />
            <relation name="UMR5506" active="#struct-441569" type="indirect" />
            <relation active="#struct-34586" type="direct" />
            <relation active="#struct-300009" type="indirect" />
          </listRelation>
        </org>
        <org type="laboratory" xml:id="struct-129671" status="VALID">
          <idno type="RNSR">198618246Y</idno>
          <idno type="ROR">https://ror.org/03fcjvn64</idno>
          <orgName>Inria Nancy - Grand Est</orgName>
          <desc>
            <address>
              <addrLine>615 rue du Jardin Botanique 54600 Villers-lès-Nancy</addrLine>
              <country key="FR" />
            </address>
            <ref type="url">http://www.inria.fr/nancy</ref>
          </desc>
          <listRelation>
            <relation active="#struct-300009" type="direct" />
          </listRelation>
        </org>
        <org type="institution" xml:id="struct-300009" status="VALID">
          <idno type="ROR">https://ror.org/02kvxyf05</idno>
          <orgName>Institut National de Recherche en Informatique et en Automatique</orgName>
          <orgName type="acronym">Inria</orgName>
          <desc>
            <address>
              <addrLine>Domaine de VoluceauRocquencourt - BP 10578153 Le Chesnay Cedex</addrLine>
              <country key="FR" />
            </address>
            <ref type="url">http://www.inria.fr/en/</ref>
          </desc>
        </org>
        <org type="department" xml:id="struct-423086" status="VALID">
          <orgName>Department of Natural Language Processing &amp; Knowledge Discovery</orgName>
          <orgName type="acronym">LORIA - NLPKD</orgName>
          <desc>
            <address>
              <country key="FR" />
            </address>
            <ref type="url">http://www.loria.fr/en/research/departments/natural-language-processing-and-knowledge-discovery/</ref>
          </desc>
          <listRelation>
            <relation active="#struct-206040" type="direct" />
            <relation active="#struct-300009" type="indirect" />
            <relation active="#struct-413289" type="indirect" />
            <relation name="UMR7503" active="#struct-441569" type="indirect" />
          </listRelation>
        </org>
        <org type="laboratory" xml:id="struct-206040" status="VALID">
          <idno type="IdRef">067077927</idno>
          <idno type="ISNI">0000000121795429</idno>
          <idno type="RNSR">198912571S</idno>
          <idno type="IdUnivLorraine">[UL]RSI--</idno>
          <idno type="ROR">https://ror.org/02vnf0c38</idno>
          <orgName>Laboratoire Lorrain de Recherche en Informatique et ses Applications</orgName>
          <orgName type="acronym">LORIA</orgName>
          <date type="start">2012-01-01</date>
          <desc>
            <address>
              <addrLine>Campus Scientifique BP 239 54506 Vandoeuvre-lès-Nancy Cedex</addrLine>
              <country key="FR" />
            </address>
            <ref type="url">http://www.loria.fr</ref>
          </desc>
          <listRelation>
            <relation active="#struct-300009" type="direct" />
            <relation active="#struct-413289" type="direct" />
            <relation name="UMR7503" active="#struct-441569" type="direct" />
          </listRelation>
        </org>
        <org type="institution" xml:id="struct-413289" status="VALID">
          <idno type="IdRef">157040569</idno>
          <idno type="IdUnivLorraine">[UL]100--</idno>
          <idno type="ROR">https://ror.org/04vfs2w97</idno>
          <orgName>Université de Lorraine</orgName>
          <orgName type="acronym">UL</orgName>
          <date type="start">2012-01-01</date>
          <desc>
            <address>
              <addrLine>34 cours Léopold - CS 25233 - 54052 Nancy cedex</addrLine>
              <country key="FR" />
            </address>
            <ref type="url">http://www.univ-lorraine.fr/</ref>
          </desc>
        </org>
        <org type="regroupinstitution" xml:id="struct-441569" status="VALID">
          <idno type="IdRef">02636817X</idno>
          <idno type="ISNI">0000000122597504</idno>
          <idno type="ROR">https://ror.org/02feahw73</idno>
          <orgName>Centre National de la Recherche Scientifique</orgName>
          <orgName type="acronym">CNRS</orgName>
          <date type="start">1939-10-19</date>
          <desc>
            <address>
              <country key="FR" />
            </address>
            <ref type="url">https://www.cnrs.fr/</ref>
          </desc>
        </org>
        <org type="regroupinstitution" xml:id="struct-26075" status="VALID">
          <orgName>RIKEN - Institute of Physical and Chemical Research [Japon]</orgName>
          <orgName type="acronym">RIKEN</orgName>
          <date type="start">1917-03-20</date>
          <desc>
            <address>
              <addrLine>Hirosawa 2-1, Wako, Saitama 351-0198</addrLine>
              <country key="JP" />
            </address>
            <ref type="url">https://www.riken.jp/en/</ref>
          </desc>
        </org>
        <org type="laboratory" xml:id="struct-484335" status="VALID">
          <idno type="IdRef">162384270</idno>
          <idno type="ISNI">0000 0000 9194 9502</idno>
          <idno type="RNSR">200319327Z</idno>
          <idno type="ROR">https://ror.org/057er4c39</idno>
          <orgName>Laboratoire Traitement et Communication de l'Information</orgName>
          <orgName type="acronym">LTCI</orgName>
          <date type="start">2017-01-01</date>
          <desc>
            <address>
              <addrLine>Télécom Paris 19 Place Marguerite Perey 91120 PALAISEAU</addrLine>
              <country key="FR" />
            </address>
            <ref type="url">https://www.telecom-paris.fr/fr/recherche/laboratoires/laboratoire-traitement-et-communication-de-linformation-ltci</ref>
          </desc>
          <listRelation>
            <relation active="#struct-302102" type="direct" />
            <relation active="#struct-1048346" type="direct" />
          </listRelation>
        </org>
        <org type="regroupinstitution" xml:id="struct-302102" status="VALID">
          <idno type="ROR">https://ror.org/025vp2923</idno>
          <orgName>Institut Mines-Télécom [Paris]</orgName>
          <orgName type="acronym">IMT</orgName>
          <date type="start">2012-03-01</date>
          <desc>
            <address>
              <addrLine>37-39 Rue Dareau, 75014 Paris</addrLine>
              <country key="FR" />
            </address>
            <ref type="url">http://www.mines-telecom.fr/</ref>
          </desc>
        </org>
        <org type="institution" xml:id="struct-1048346" status="VALID">
          <idno type="IdRef">026375273</idno>
          <idno type="ISNI">0000 0001 2108 2779</idno>
          <idno type="ROR">https://ror.org/01naq7912</idno>
          <orgName>Télécom Paris</orgName>
          <date type="start">2019-06-12</date>
          <desc>
            <address>
              <addrLine>19 Place Marguerite Perey 91120 Palaiseau </addrLine>
              <country key="FR" />
            </address>
            <ref type="url">https://www.telecom-paris.fr</ref>
          </desc>
        </org>
        <org type="laboratory" xml:id="struct-181" status="OLD">
          <idno type="IdRef">139590827</idno>
          <idno type="ISNI">0000000405990488</idno>
          <idno type="RNSR">199111950H</idno>
          <idno type="ROR">https://ror.org/013yean28</idno>
          <orgName>Laboratoire d'Informatique de Robotique et de Microélectronique de Montpellier</orgName>
          <orgName type="acronym">LIRMM</orgName>
          <date type="start">1995-01-01</date>
          <date type="end">2021-12-31</date>
          <desc>
            <address>
              <addrLine>161 rue Ada - 34095 Montpellier</addrLine>
              <country key="FR" />
            </address>
            <ref type="url">https://www.lirmm.fr</ref>
          </desc>
          <listRelation>
            <relation name="UMR5506" active="#struct-410122" type="direct" />
            <relation name="UMR5506" active="#struct-441569" type="direct" />
          </listRelation>
        </org>
        <org type="institution" xml:id="struct-410122" status="OLD">
          <idno type="ISNI">0000000120970141</idno>
          <idno type="ROR">https://ror.org/051escj72</idno>
          <orgName>Université de Montpellier</orgName>
          <orgName type="acronym">UM</orgName>
          <date type="end">2021-12-31</date>
          <desc>
            <address>
              <addrLine>163 rue Auguste Broussonnet - 34090 Montpellier</addrLine>
              <country key="FR" />
            </address>
            <ref type="url">http://www.umontpellier.fr/</ref>
          </desc>
        </org>
        <org type="laboratory" xml:id="struct-34586" status="VALID">
          <idno type="RNSR">198318250R</idno>
          <idno type="ROR">https://ror.org/01nzkaw91</idno>
          <orgName>Inria Sophia Antipolis - Méditerranée</orgName>
          <orgName type="acronym">CRISAM</orgName>
          <desc>
            <address>
              <addrLine>2004 route des Lucioles BP 93 06902 Sophia Antipolis</addrLine>
              <country key="FR" />
            </address>
            <ref type="url">http://www.inria.fr/centre/sophia/</ref>
          </desc>
          <listRelation>
            <relation active="#struct-300009" type="direct" />
          </listRelation>
        </org>
      </listOrg>
      <listOrg type="projects">
        <org type="anrProject" xml:id="projanr-45798" status="VALID">
          <idno type="anr">ANR-15-CE38-0003</idno>
          <orgName>KAMoulox</orgName>
          <desc>Démixage en ligne de larges archives sonores</desc>
          <date type="start">2015</date>
        </org>
      </listOrg>
    </back>
  <teiCorpus>
	<teiHeader xml:lang="fr">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Cauchy Multichannel Speech Enhancement with a Deep Speech Prior</title>
				<funder>
					<orgName type="full">French State agency</orgName>
				</funder>
				<funder ref="#_W7QQzSz">
					<orgName type="full">Agence Nationale de la Recherche</orgName>
					<orgName type="abbreviated">ANR</orgName>
				</funder>
				<funder ref="#_E2rTJMX">
					<orgName type="full">JSPS KAKENHI</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher />
				<availability status="unknown"><licence /></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Mathieu</forename><surname>Fontaine</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Université de Lorraine</orgName>
								<orgName type="institution" key="instit2">CNRS</orgName>
								<orgName type="institution" key="instit3">Inria</orgName>
								<orgName type="institution" key="instit4">LORIA</orgName>
								<address>
									<settlement>Nancy</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Aditya</forename><forename type="middle">Arie</forename><surname>Nugraha</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">AIP</orgName>
								<orgName type="institution">RIKEN</orgName>
								<address>
									<settlement>Tokyo</settlement>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Roland</forename><surname>Badeau</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Télécom ParisTech</orgName>
								<orgName type="laboratory">LTCI</orgName>
								<orgName type="institution">Université Paris-Saclay</orgName>
								<address>
									<settlement>Paris</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Kazuyoshi</forename><surname>Yoshii</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">AIP</orgName>
								<orgName type="institution">RIKEN</orgName>
								<address>
									<settlement>Tokyo</settlement>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
							<affiliation key="aff4">
								<orgName type="department">Graduate School of Informatics</orgName>
								<orgName type="institution">Kyoto University</orgName>
								<address>
									<settlement>Kyoto</settlement>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Antoine</forename><surname>Liutkus</surname></persName>
							<affiliation key="aff3">
								<orgName type="institution" key="instit1">Inria</orgName>
								<orgName type="institution" key="instit2">LIRMM</orgName>
								<address>
									<settlement>Montpellier</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Cauchy Multichannel Speech Enhancement with a Deep Speech Prior</title>
					</analytic>
					<monogr>
						<imprint>
							<date />
						</imprint>
					</monogr>
					<idno type="MD5">C8B6AA69CC7BA081F4529B84781A1459</idno>
					<idno type="DOI">10.23919/EUSIPCO.2019.8903091</idno>
					<note type="submission">Submitted on 16 Oct 2019</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-04-12T14:43+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid" />
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Multichannel speech enhancement</term>
					<term>multivariate complex Cauchy distribution</term>
					<term>variational autoencoder</term>
					<term>nonnegative matrix factorization</term>
				</keywords>
			</textClass>
			<abstract>
<div><p>de niveau recherche, publiés ou non, émanant des établissements d'enseignement et de recherche français ou étrangers, des laboratoires publics ou privés.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="fr">
		<body>
<div><head>I. INTRODUCTION</head><p>Multichannel speech enhancement aims to extract speech from an observed multichannel noisy signal <ref type="bibr" target="#b0">[1]</ref>. Usually, parametric models are used for the speech (target) signal, the additive noise, and the way both are captured by the microphones. The core feature of such models is to allow the reconstruction of the target signal from the noisy mixture, provided that the parameters are well estimated. The standard example is having sources parameterized by their spectrograms, and reconstructed through soft-masking (Wiener-like) strategies.</p><p>Deep neural networks (DNNs) have been increasingly used in this context <ref type="bibr" target="#b0">[1]</ref>- <ref type="bibr" target="#b3">[4]</ref>. Most approaches train denoising DNNs to estimate the model parameters, e.g., source spectrograms or the time-frequency mask of one or all of the sources. In this case, the training employs paired data consisting of noisy speech and clean speech. Although it has been shown that denoising DNNs could be robust to unseen environments <ref type="bibr" target="#b4">[5]</ref>, there is still a concern that they are not adaptive enough to unseen noises. This issue has recently been addressed by several studies on semi-supervised speech enhancement <ref type="bibr" target="#b5">[6]</ref>- <ref type="bibr" target="#b9">[10]</ref>. The core idea of these studies is to formulate a probabilistic generative model in which both speech spectrogram and noise spectrogram are modeled by latent variable models. The speech spectrogram model is trained as the decoder in the variational autoencoder (VAE) framework <ref type="bibr" target="#b10">[11]</ref>, while the noise spectrogram is modeled by a nonnegative matrix factorization (NMF) <ref type="bibr" target="#b11">[12]</ref> approach. The speech model is trained with clean speech only, thus independent from the actual noise that will be found in the observations at test time. Indeed, the core feature of this strategy is to let the noise parameters be estimated and adapted at test time, so that it is flexible and may achieve good denoising performance even in adversarial conditions not met at training time. In the case of multichannel enhancement <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b8">[9]</ref>, the spatial parameters are also estimated at test time.</p><p>Most of these methods <ref type="bibr" target="#b5">[6]</ref>- <ref type="bibr" target="#b8">[9]</ref> tackle such a whole estimation problem under a Gaussian probabilistic setting. Although it is convenient because it leads to straightforward inference methods, it has the drawback of being sensitive to initialization and prone to be trapped in a local minimum <ref type="bibr" target="#b12">[13]</ref>.</p><p>As opposed to their Gaussian counterpart, heavy-tailed probabilistic models allow for outcomes that are far away from the expected values <ref type="bibr" target="#b13">[14]</ref>, <ref type="bibr" target="#b14">[15]</ref>. From an inference perspective, this means that unlikely observations will not have a detrimental impact on the parameters, yielding robust estimation. Among them, non-Gaussian α-stable models are remarkable because they also satisfy the central limit theorem <ref type="bibr" target="#b15">[16]</ref>, which means that a sum of α-stable random vectors remains α-stable. This is an interesting feature in a context of speech enhancement where additive sources are combined to yield the observed mixture. Notwithstanding their attractive features, the main weakness of these distributions is the absence of a closed-form probability density function (PDF), except for α = 0.5 (the Lévy distribution), α = 1 (the Cauchy distribution), and α = 2 (the Gaussian distribution).</p><p>An option is to express an α-stable random variable as conditionally Gaussian <ref type="bibr" target="#b15">[16]</ref>. This may always be done in the scalar (single-channel) case and only in some cases for multichannel data. Put it simply, the trick is to write an α-stable random variable as a Gaussian variable with a covariance that is multiplied by a random impulse variable, distributed as a positive α 2 -stable random variable. This makes it possible to use the classical Gaussian methodology, provided that some specific method is found to estimate the impulse variables, notably some Markov chain Monte Carlo (MCMC) strategy <ref type="bibr" target="#b16">[17]</ref>- <ref type="bibr" target="#b18">[19]</ref>. However, the MCMC algorithm is often computationally demanding at test time, and <ref type="bibr" target="#b19">[20]</ref> proposes an approximation to construct filters without requiring the estimation of impulse variables. Still, this strategy does not provide any convenient cost function to use for parameter estimation, which is inconvenient in our case.</p><p>In line with the present study, combining a VAE and general α-stable distributions has recently been proposed in <ref type="bibr" target="#b9">[10]</ref>. It suffers from expensive MCMC schemes. A simplified approach undertaken in <ref type="bibr" target="#b20">[21]</ref> is to focus on the Cauchy α = 1 case, for which closed-form expressions of the likelihood are available. However, this study is limited to single-channel source separation based on low-rank source models.</p><p>In this paper, we go beyond related work in this respect and introduce a semi-supervised multichannel speech enhancement method that uses a VAE-based speech model and a low-rank noise model, that both parameterize Cauchy models for the sources. To the best of our knowledge, this is the first study that uses a computationally-tractable heavy-tailed model for multichannel sources unlike previous studies that use a heavytailed model for multichannel mixtures <ref type="bibr" target="#b21">[22]</ref>, <ref type="bibr" target="#b22">[23]</ref>. Additionally, we show how deep latent variable models may be combined with more classical low-rank models in this setting.</p></div>
<div><head>II. PROBABILISTIC FORMULATION</head><p>This section formulates a probabilistic model for the proposed Cauchy multichannel speech enhancement method.</p></div>
<div><head>A. Multivariate Complex Cauchy Distribution</head><p>Let y be a complex random vector of dimension K. Then, y ∼ C C (y|µ, V) follows a circularly-symmetric multivariate complex Cauchy distribution iff. its probability density is</p><formula xml:id="formula_0">p µ,V (y) = A K,V 1 + (y -µ) H V -1 (y -µ) -K-1 2 ,<label>(1)</label></formula><p>where</p><formula xml:id="formula_1">A K,V = K k=1 K -k + 1 2 π -K det (V) -1<label>(2)</label></formula><p>and . H , V and µ in (1) respectively stand for the Hermitian transposition, the positive definite scatter matrix and the location parameter <ref type="bibr" target="#b23">[24]</ref>, <ref type="bibr" target="#b24">[25]</ref>. Similarly to the Gaussian distribution, a linear combination of Cauchy vectors remains a Cauchy vector. However, the tails of a Gaussian distribution are lighter than those of a Cauchy one (see Fig. <ref type="figure" target="#fig_0">1</ref>).</p></div>
<div><head>B. Spatial Model</head><p>We work in the short time Fourier transform (STFT) domain. Let f ∈ [1, F ] and t ∈ [1, T ] be the frequency bin and time frame indexes, respectively. Following the literature, we assume that the observed mixture signal is a linear combination of the sources. Considering speech and noise as the sources, the STFT of a K-channel noisy speech x ∈ C F ×T ×K is expressed for each time-frequency (TF) bin f t as where the speech x s f t ∈ C K and the noise x n f t ∈ C K are assumed to follow a Cauchy distribution:</p><formula xml:id="formula_2">x f t = x s f t + x n f t ,<label>(3)</label></formula><formula xml:id="formula_3">x s f t ∼ C C x s f t 0, a s f t R s f , x n f t ∼ C C x n f t 0, a n f t R n f ,<label>(4)</label></formula><p>with a s f t ∈ R + and a n f t ∈ R + are the sources' magnitudes, while R s f and R n f are the K × K positive definite spatial scatter matrices of the sources.</p></div>
<div><head>C. Source Models</head><p>While the scatter matrices R s f and R n f are left unconstrained, specific models are picked for the speech and noise magnitudes.</p><p>First, the F -dimensional vector a s t gathering the speech magnitudes a s f t for frame t is assumed to depend on lowdimensional latent variables written z t ∈ R D with D &lt; F . This mapping is given by a function called the decoder and written a s t = µ θ (z t ), parameterized by θ. Second, the noise magnitudes a n f t are modeled with a nonnegative matrix factorization (NMF) <ref type="bibr" target="#b25">[26]</ref> as follows:</p><formula xml:id="formula_4">a n f t = L l=1 w f l h lt for ∀f, t,<label>(5)</label></formula><p>where L is the number of basis vectors. At test time, the key idea becomes to use the observed mixture x to estimate the most likely latent vectors z t and NMF parameters w and h as well as the scatter matrices. They are then used in conjunction to âs t = µ θ (z t ) to separate the signals with the technique presented in section II-D.</p></div>
<div><head>D. Projection-Based Wiener Filter</head><p>The Cauchy model above resembles its Gaussian counterpart <ref type="bibr" target="#b26">[27]</ref>. Instead of scatter matrices, the Gaussian model has covariance matrices. The mixture covariance matrix is simply a linear combination of the source covariance matrices. In this case, given the model parameters, the multichannel Wiener filter can be used to extract the sources. Unfortunately, this linear combination between scatter matrices is usually not satisfied for the Cauchy model with K &gt; 1.</p><p>We therefore propose to project the observation vectors</p><formula xml:id="formula_5">x f t ∈ C K to the complex plane C. Let us consider M vectors u 1 , • • • , u M ∈ C K and let x mf t = u H m x f t for ∀m, f, t<label>(6)</label></formula><p>be the m th -projection of the observed signal x f t . As demonstrated in <ref type="bibr" target="#b27">[28]</ref>, the random variable x mf t is Cauchy distributed and the following posterior mean of the projected speech</p><formula xml:id="formula_6">xs mf t</formula><p>is tractable for all m, f, t:</p><formula xml:id="formula_7">xs mf t E u H m x s f t |x mf t , Ψ = v s mf t v mf t x mf t ,<label>(7)</label></formula><p>where</p><formula xml:id="formula_8">       v s mf t = a s f t u H m R s f u m , v n mf t = a n f t u H m R n f u m , v mf t = v s mf t + v n mf t 2 ,<label>(8)</label></formula><p>and Ψ a s f t , a n f t , R s f , R n f . We then deduce an estimator xs f t of x s f t by using U † , which is the pseudo-inverse of U [u 1 , . . . , u M ]</p><p>H ∈ C M ×K :</p><formula xml:id="formula_9">xs f t = U † xs 1f t , • • • , xs mf t T .<label>(9)</label></formula><p>An estimator xn f t of x n f t can be computed in a similar way. In this paper, in order to simplify the computation of ( <ref type="formula" target="#formula_9">9</ref>), the projector U is chosen to be unitary so that U † = U.</p></div>
<div><head>III. PARAMETER ESTIMATION</head><p>This section explains how to estimate the parameters of the probabilistic model proposed in Section II.</p></div>
<div><head>A. Training Phase</head><p>To train the speech decoder model µ θ (z), we adopt the VAE framework <ref type="bibr" target="#b10">[11]</ref>. For training, two DNNs are considered:</p><p>• An encoder that inputs a s t and outputs two D-dimensional vectors written µ q φ (a s t ) and σ q φ (a s t ). Together, they define the distribution of the latent vectors: q φ (z t |a t ), defined as N (z t |µ q φ (a t ), Diag[σ q φ (a t )]) • A decoder that outputs two F -dimensional vectors written µ θ (z t ) and γ θ (z t ), that together describe the distribution of the speech magnitudes a s t given z, written p θ (a s t |z t ). We detail that distribution later. In any case, the model parameters θ and φ are jointly optimized by minimizing the negative log-likelihood (NLL):</p><formula xml:id="formula_10">-ln p θ (a s t ) = -ln zt q φ (z t |a s t ) q φ (z t |a s t ) p θ (a s t , z t )dz t ≤ -E q φ (zt|a s t ) ln p θ (a s t |z t )p θ (z t ) q φ (z t |a s t ) = -E q φ (zt|a s t ) [ln p θ (a s t |z t )]+KL[q φ (z t |a s t ) p θ (z t )] def = L mag + L reg ,<label>(10)</label></formula><p>where KL[q p] is the Kullback-Leibler (KL) divergence from p to q <ref type="bibr" target="#b28">[29]</ref>. The reparameterization trick <ref type="bibr" target="#b10">[11]</ref> is used to obtain z t given the encoder outputs µ q φ (a s t ) and σ q φ (a s t ). For training, the observed magnitudes from a clean speech dataset, a s f t , are assumed to follow a real Cauchy distribution</p><formula xml:id="formula_11">C R with location [µ θ (z t )] f ∈ R + and scale [γ θ (z t )] f ∈ R + : p θ (a s f t |z t ) = C R a s f t [µ θ (z t )] f , [γ θ (z t )] f . (<label>11</label></formula><formula xml:id="formula_12">)</formula><p>This complies with the α-spectrogram assumption for α = 1 <ref type="bibr" target="#b29">[30]</ref>. Thus, the magnitude reconstruction loss L mag , serving as a cost function for training the parameters θ, may be picked as the negative log-likelihood (NLL):</p><formula xml:id="formula_13">L mag c = 1 T F,T f,t=1 ln[γ θ (z t )] f + ln 1 + a s f t -[µ θ (z t )] f 2 γ 2 f t . (<label>12</label></formula><formula xml:id="formula_14">)</formula><p>Then, assuming a simple prior p θ (z t ) ∼ N (z t |0, I), the regularization term L reg <ref type="bibr" target="#b10">[11]</ref> is computed as</p><formula xml:id="formula_15">L reg = 1 2T D,T d,t=1 [µ q φ (a s t )] 2 d + [σ q φ (a s t )] 2 d -ln[σ q φ (a s t )] 2 d -1 .<label>(13)</label></formula></div>
<div><head>B. Test Phase</head><p>As advocated above, the projected mixtures x mf t are considered as isotropic complex random variables. They are thus parameterized through a scale parameter √ v mf t and the negative log-likelihood is given by</p><formula xml:id="formula_16">D (v) c = M,F,T m,f,t=1 3 2 ln v mf t + |x mf t | 2 - 1 2 ln (v mf t ) ,<label>(14) where c</label></formula><p>= denotes equality up to a constant. At test time, the latent variables z t are initialized by sampling from q φ (z t | |x t |), i.e., by applying the encoder to the average of the mixture magnitude spectrogram over channels. This in turn provides an initial estimate µ θ (z t ) for the speech magnitude a s t . Then, the latent variables z t are updated by backpropagation with a gradient descent method to minimize the cost function <ref type="bibr" target="#b13">(14)</ref>. In this case, all parameters other than z t , including the decoder parameters, are kept fixed.</p><p>For estimating the noise parameters, we adopt a majorizationequalization (ME) strategy <ref type="bibr" target="#b25">[26]</ref> as in <ref type="bibr" target="#b20">[21]</ref>. Due to space constraints, we only provide here the multiplicative updates used for the parameters w and h as follows:</p><formula xml:id="formula_17">w f l ← 1 3 w f l mt h lt ψ n mf mt h lt ψ n mf ξ mf t ,<label>(15)</label></formula><formula xml:id="formula_18">h lt ← 1 3 h lt mf h f l ψ n mf mf w f l ψ n mf ξ mf t ,<label>(16)</label></formula><p>Fig. <ref type="figure">3</ref>: Performance comparison in terms of PESQ (left), STOI (middle), and SDR (right). Higher is better. The mean and the standard deviation are respectively shown in white and black fonts.</p><formula xml:id="formula_19">ψ n mf u H m R n f u m v n mf t v mf t ,<label>(17)</label></formula><formula xml:id="formula_20">ξ mf t 1 + |x mf t | 2 v mf t .<label>(18)</label></formula><p>Similarly for noise parameter estimation, we define the estimator vj f t = a j f t Rj f for j ∈ {s, n}, where a j f t is provided by the source models and Rj</p><formula xml:id="formula_21">f = m r j m ,f u m u H m . It leads to r j m f ← 1 3 r j f mt a j f t η j mm f t mt η j mm f t ξ mf t ,<label>(19)</label></formula><formula xml:id="formula_22">η j mm f t |u H m u m | 2 v j mf t v mf t .<label>(20)</label></formula><p>IV. EVALUATION</p><p>In this section, we compare the performance of three different systems on a 5-channel speech enhancement task. Each of them includes at least one multichannel nonnegative matrix factorization (MNMF) spectrogram model <ref type="bibr" target="#b30">[31]</ref>. The systems include: (1) Cauchy VAE-MNMF, that we propose above; (2) Gaussian VAE-MNMF, that is a system similar to ours, but based on a Gaussian model <ref type="bibr" target="#b8">[9]</ref>; and (3) Cauchy MNMF, that is a semi-supervised multichannel Cauchy NMF, where the speech magnitude is also modeled with an NMF with basis vectors trained on clean speech beforehand. The Gaussian VAE-MNMF system is provided by the authors <ref type="bibr" target="#b8">[9]</ref>.</p><p>The performance is measured by the signal-to-distortion ratio (SDR) provided by the BSS-Eval toolbox <ref type="bibr" target="#b31">[32]</ref>, the Perceptual Evaluation of Speech Quality (PESQ) score <ref type="bibr" target="#b32">[33]</ref>, and the Short-Time Objective Intelligibility (STOI) score <ref type="bibr" target="#b33">[34]</ref>. The SDR is computed on the enhanced 5-channel speech, while the PESQ and the STOI are computed on one of the channels.</p></div>
<div><head>A. Experimental Conditions</head><p>We consider the simulated training, development, and test sets of the CHiME-4 corpus <ref type="bibr" target="#b4">[5]</ref> The evaluation is then done on 10% of the full test set, i.e., 132 randomly selected 5-channel noisy utterances (K = 5).</p><p>The STFT coefficients are extracted using a Hann window with a length of 1024 samples and an overlap of 75% (F = 513).</p><p>The encoder and the decoder of the speech VAE for the Cauchy VAE-MNMF is depicted in Fig. <ref type="figure" target="#fig_1">2</ref>. These DNNs are trained by backpropagation with the Adam update rule whose learning rate is fixed to 10 -3 <ref type="bibr" target="#b34">[35]</ref>. The update is done for every minibatch of 8192 frames from 32 randomly selected utterances. The gradient is normalized with threshold fixed to 1 <ref type="bibr" target="#b35">[36]</ref>. The weight normalization <ref type="bibr" target="#b36">[37]</ref> is also employed. The training is started with a warm-up technique <ref type="bibr" target="#b37">[38]</ref> for 100 epochs and stopped after 50 consecutive epochs that failed to obtain a better validation score. The latest model yielding the lowest error is kept. These DNNs are comparable in size to the ones used in the Gaussian VAE-MNMF.</p><p>For both VAE-MNMF methods, the latent variable dimension of the speech model is fixed to D = 32 and the number of bases of the noise model is fixed to L = 32. Similarly, for the Cauchy MNMF, the number of bases of both source models is fixed to L = 32. For the Cauchy MNMF and the Cauchy VAE-MNMF, the dimension of the projector U is fixed to M = 8. The NMF parameters are initialized randomly and the coefficients r j mf are initialized as 1. We consider 64 optimization iterations for the Cauchy MNMF and 50 for both VAE-MNMF methods.</p></div>
<div><head>B. Experimental Results</head><p>Fig. <ref type="figure">3</ref> shows that the Cauchy VAE-MNMF globally outperforms the Cauchy MNMF and the Gaussian VAE-MNMF. It provides an SDR improvement of 4.2 dB w.r.t. the Gaussian VAE-MNMF. We also observe that the standard deviation of the metrics is generally smaller for the Cauchy VAE-MNMF, suggesting that it has stronger robustness to noise.</p><p>As an illustration, we also displayed in Fig. <ref type="figure" target="#fig_4">4</ref> the logmagnitude spectrograms of estimated speech obtained with the Cauchy and the Gaussian VAE-MNMFs. We see that the one seems less robust against non-stationary noise.</p></div>
<div><head>V. CONCLUSION</head><p>We proposed a speech enhancement system combining a nonnegative matrix factorization (NMF) model for the noise and a variational autoencoder (VAE) for speech, that is trained and used under heavy-tailed probabilistic models. We derived the whole training and inference strategy and gave the details of the corresponding algorithms.  In an evaluation on 5-channel mixtures from the CHiME-4 corpus, we found out that our proposed system achieves a significantly better performance than its Gaussian counterpart, yielding a 4 dB SDR improvement.</p></div><figure xml:id="fig_0"><head>Fig. 1 :</head><label>1</label><figDesc>Fig. 1: Tails of unidimensional Cauchy and Gaussian PDF</figDesc></figure>
<figure xml:id="fig_1"><head>Fig. 2 :</head><label>2</label><figDesc>Fig.2:The encoder and decoder of the speech VAE. 'FC' represents a fully-connected layer whose size is shown inside the parentheses. The speech magnitude estimate is computed from the decoder output âs t = exp (ln µ t ).</figDesc></figure>
<figure xml:id="fig_2"><head /><label /><figDesc>. All data are sampled at 16 kHz. We use 7138 single-channel clean speech signals of the training set for training the DNNs of the Cauchy VAE-MNMF and the speech basis vectors of the Cauchy MNMF. Moreover, we use 1640 single-channel clean speech signals from the development set as the validation set for the DNN training.</figDesc></figure>
<figure xml:id="fig_4"><head>Fig. 4 :</head><label>4</label><figDesc>Fig. 4: Log-magnitude spectrograms of clean speech (topleft), corrupted speech (top-right), speech estimated with the Gaussian VAE-MNMF (bottom-left) and speech estimated with the Cauchy VAE-MNMF (bottom-right). The utterance is M05_447C020F_PED from the test set et05_ped_simu.</figDesc><graphic coords="6,73.79,127.31,103.75,61.87" type="bitmap" /></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>ACKNOWLEDGEMENT</head><p>We thank <rs type="person">S. Leglaive</rs> for providing the code of [9].</p></div>
			</div>
			<div type="funding">
<div><p>This work was partly supported by the research programme <rs type="projectName">KAMoulox</rs> (<rs type="grantNumber">ANR-15-CE38-0003-01</rs>) funded by <rs type="funder">ANR</rs>, the <rs type="funder">French State agency</rs> for research, and <rs type="funder">JSPS KAKENHI</rs> No. <rs type="grantNumber">19H04137</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funded-project" xml:id="_W7QQzSz">
					<idno type="grant-number">ANR-15-CE38-0003-01</idno>
					<orgName type="project" subtype="full">KAMoulox</orgName>
				</org>
				<org type="funding" xml:id="_E2rTJMX">
					<idno type="grant-number">19H04137</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m">Audio Source Separation and Speech Enhancement</title>
		<editor>
			<persName><forename type="first">E</forename><surname>Vincent</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename><surname>Virtanen</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Gannot</surname></persName>
		</editor>
		<imprint>
			<publisher>Wiley</publisher>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Multichannel audio source separation with deep neural networks</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Nugraha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Liutkus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Vincent</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE/ACM Trans. ASLP</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1652" to="1664" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A generic neural acoustic beamforming architecture for robust multi-channel speech processing</title>
		<author>
			<persName><forename type="first">J</forename><surname>Heymann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Drude</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Haeb-Umbach</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Speech &amp; Language</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="page" from="374" to="385" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Multichannel signal processing with deep neural networks for automatic speech recognition</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">N</forename><surname>Sainath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">W</forename><surname>Wilson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Narayanan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Variani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bacchiani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Shafran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Senior</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Chin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Misra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE/ACM Trans. ASLP</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="965" to="979" />
			<date type="published" when="2017-05">May 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">An analysis of environment, microphone and data simulation mismatches in robust speech recognition</title>
		<author>
			<persName><forename type="first">E</forename><surname>Vincent</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Watanabe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Nugraha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Barker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Marxer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Speech &amp; Language</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="page" from="535" to="557" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Statistical speech enhancement based on probabilistic integration of variational autoencoder and non-negative matrix factorization</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Bando</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mimura</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Itoyama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Yoshii</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kawahara</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE ICASSP</title>
		<meeting>IEEE ICASSP</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="716" to="720" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A variance modeling framework based on variational autoencoders for speech enhancement</title>
		<author>
			<persName><forename type="first">S</forename><surname>Leglaive</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Girin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Horaud</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE MLSP</title>
		<meeting>IEEE MLSP</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Bayesian multichannel speech enhancement with a deep speech prior</title>
		<author>
			<persName><forename type="first">K</forename><surname>Sekiguchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bando</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Yoshii</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kawahara</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. APSIPA</title>
		<meeting>APSIPA</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="1233" to="1239" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Semi-supervised multichannel speech enhancement with variational autoencoders and non-negative matrix factorization</title>
		<author>
			<persName><forename type="first">S</forename><surname>Leglaive</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Girin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Horaud</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE ICASSP</title>
		<meeting>IEEE ICASSP</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Speech enhancement with variational autoencoders and alpha-stable distributions</title>
		<author>
			<persName><forename type="first">S</forename><surname>Leglaive</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Liutkus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Girin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Horaud</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE ICASSP</title>
		<meeting>IEEE ICASSP</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Auto-encoding variational Bayes</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICLR</title>
		<meeting>ICLR</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Learning the parts of objects by nonnegative matrix factorization</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">D</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">S</forename><surname>Seung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">401</biblScope>
			<biblScope unit="issue">6755</biblScope>
			<biblScope unit="page" from="788" to="791" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">SVD based initialization: A head start for nonnegative matrix factorization</title>
		<author>
			<persName><forename type="first">C</forename><surname>Boutsidis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Gallopoulos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1350" to="1362" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Applications of "Student's" distribution</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Fisher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Metron</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="90" to="104" />
			<date type="published" when="1925">1925</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Speech enhancement in the DFT domain using Laplacian speech priors</title>
		<author>
			<persName><forename type="first">R</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Breithaupt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IWAENC</title>
		<meeting>IWAENC</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="87" to="90" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Stable non-Gaussian random processes: stochastic models with infinite variance</title>
		<author>
			<persName><forename type="first">G</forename><surname>Samoradnitsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Taqqu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1994">1994</date>
			<publisher>Chapman and Hall/CRC</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Alphastable multichannel audio source separation</title>
		<author>
			<persName><forename type="first">S</forename><surname>Leglaive</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Liutkus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Badeau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Richard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE ICASSP</title>
		<meeting>IEEE ICASSP</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="576" to="580" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Multichannel audio modeling with elliptically stable tensor decomposition</title>
		<author>
			<persName><forename type="first">M</forename><surname>Fontaine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F.-R</forename><surname>Stöter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Liutkus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Serizel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Badeau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. LVA/ICA</title>
		<meeting>LVA/ICA</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="13" to="23" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Alpha-stable low-rank plus residual decomposition for speech enhancement</title>
		<author>
			<persName><forename type="first">U</forename></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Erdogan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Leglaive</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Liutkus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Badeau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Richard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE ICASSP</title>
		<meeting>IEEE ICASSP</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Explaining the parameterized Wiener filter with alpha-stable processes</title>
		<author>
			<persName><forename type="first">M</forename><surname>Fontaine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Liutkus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Girin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Badeau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. WASPAA</title>
		<meeting>WASPAA</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Cauchy nonnegative matrix factorization</title>
		<author>
			<persName><forename type="first">A</forename><surname>Liutkus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Fitzgerald</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Badeau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. WASPAA</title>
		<meeting>WASPAA</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1" to="5" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Student's t multichannel nonnegative matrix factorization for blind source separation</title>
		<author>
			<persName><forename type="first">K</forename><surname>Kitamura</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bando</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Itoyama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Yoshii</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IWAENC</title>
		<meeting>IWAENC</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="1" to="5" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Generalized independent low-rank matrix analysis using heavy-tailed distributions for blind source separation</title>
		<author>
			<persName><forename type="first">D</forename><surname>Kitamura</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mogami</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Mitsui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Takamune</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Saruwatari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Ono</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Takahashi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Kondo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">EURASIP J. on Adv. in Signal Process</title>
		<imprint>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="25" />
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Indirect estimation of elliptical stable distributions</title>
		<author>
			<persName><forename type="first">M</forename><surname>Lombardi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Veredas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Statistics &amp; Data Analysis</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="2309" to="2324" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Multivariate stable distributions</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Press</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Multivariate Analysis</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="444" to="462" />
			<date type="published" when="1972">1972</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Algorithms for nonnegative matrix factorization with the β-divergence</title>
		<author>
			<persName><forename type="first">C</forename><surname>Févotte</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Idier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="2421" to="2456" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Under-determined reverberant audio source separation using a full-rank spatial covariance model</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">Q K</forename><surname>Duong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Vincent</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Gribonval</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. ASLP</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1830" to="1840" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Projection-based demixing of spatial audio</title>
		<author>
			<persName><forename type="first">D</forename><surname>Fitzgerald</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Liutkus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Badeau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE/ACM Trans. ASLP</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1556" to="1568" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">On information and sufficiency</title>
		<author>
			<persName><forename type="first">S</forename><surname>Kullback</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Leibler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ann. Math. Statist</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="79" to="86" />
			<date type="published" when="1951">1951</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Generalized Wiener filtering with fractional power spectrograms</title>
		<author>
			<persName><forename type="first">A</forename><surname>Liutkus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Badeau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE ICASSP</title>
		<meeting>IEEE ICASSP</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="266" to="270" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Multichannel nonnegative matrix factorization in convolutive mixtures for audio source separation</title>
		<author>
			<persName><forename type="first">A</forename><surname>Ozerov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Févotte</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. ASLP</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="550" to="563" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">First stereo audio source separation evaluation campaign: Data, algorithms and results</title>
		<author>
			<persName><forename type="first">E</forename><surname>Vincent</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Sawada</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Bofill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Makino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Rosca</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICA</title>
		<meeting>ICA</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="552" to="559" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<idno>P.862</idno>
		<title level="m">Perceptual evaluation of speech quality (PESQ): An objective method for end-to-end speech quality assessment of narrowband telephone networks and speech codecs</title>
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">An algorithm for intelligibility prediction of time-frequency weighted noisy speech</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">H</forename><surname>Taal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">C</forename><surname>Hendriks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Heusdens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Jensen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. ASLP</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="2125" to="2136" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICLR</title>
		<meeting>ICLR</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">On the difficulty of training recurrent neural networks</title>
		<author>
			<persName><forename type="first">R</forename><surname>Pascanu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICML</title>
		<meeting>ICML</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="1310" to="1318" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Weight normalization: A simple reparameterization to accelerate training of deep neural networks</title>
		<author>
			<persName><forename type="first">T</forename><surname>Salimans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. NIPS</title>
		<meeting>NIPS</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="901" to="909" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Ladder variational autoencoders</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">K</forename><surname>Sønderby</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Raiko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Maaløe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">K</forename><surname>Sønderby</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Winther</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. NIPS</title>
		<meeting>NIPS</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="3738" to="3746" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</teiCorpus></text>
</TEI>