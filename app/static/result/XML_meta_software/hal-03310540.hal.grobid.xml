<?xml version='1.0' encoding='utf-8'?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" version="1.1" xsi:schemaLocation="http://www.tei-c.org/ns/1.0 http://api.archives-ouvertes.fr/documents/aofr-sword.xsd">
  <teiHeader>
    <fileDesc>
      <titleStmt>
        <title>HAL TEI export of hal-03310540</title>
      </titleStmt>
      <publicationStmt>
        <distributor>CCSD</distributor>
        <availability status="restricted">
          <licence target="http://creativecommons.org/licenses/by/4.0/">Distributed under a Creative Commons Attribution 4.0 International License</licence>
        </availability>
        <date when="2024-04-29T11:45:36+02:00" />
      </publicationStmt>
      <sourceDesc>
        <p part="N">HAL API platform</p>
      </sourceDesc>
    </fileDesc>
  </teiHeader>
  <text>
    <body>
      <listBibl>
        <biblFull>
          <titleStmt>
            <title xml:lang="en">Reproducible Performance Optimization of Complex Applications on the Edge-to-Cloud Continuum</title>
            <author role="aut">
              <persName>
                <forename type="first">Daniel</forename>
                <surname>Rosendo</surname>
              </persName>
              <email type="md5">4dfedbf6d1e9a9a14875110c7ddaac6b</email>
              <email type="domain">inria.fr</email>
              <idno type="idhal" notation="string">daniel-rosendo</idno>
              <idno type="idhal" notation="numeric">746327</idno>
              <idno type="halauthorid" notation="string">50740-746327</idno>
              <idno type="ORCID">https://orcid.org/0000-0003-1175-8426</idno>
              <idno type="GOOGLE SCHOLAR">https://scholar.google.com/citations?user=7VLhPOAAAAAJ&amp;hl=en</idno>
              <affiliation ref="#struct-491076" />
              <affiliation ref="#struct-141072" />
            </author>
            <author role="aut">
              <persName>
                <forename type="first">Alexandru</forename>
                <surname>Costan</surname>
              </persName>
              <email type="md5">5332b665078fee64483b8a2cb4c0d534</email>
              <email type="domain">irisa.fr</email>
              <idno type="idhal" notation="string">alexandru-costan</idno>
              <idno type="idhal" notation="numeric">9361</idno>
              <idno type="halauthorid" notation="string">27975-9361</idno>
              <idno type="IDREF">https://www.idref.fr/220478279</idno>
              <idno type="ORCID">https://orcid.org/0000-0003-3111-6308</idno>
              <affiliation ref="#struct-117606" />
              <affiliation ref="#struct-491076" />
            </author>
            <author role="aut">
              <persName>
                <forename type="first">Gabriel</forename>
                <surname>Antoniu</surname>
              </persName>
              <email type="md5">f744d7a97b53f5050dfdd6c734bd83e1</email>
              <email type="domain">inria.fr</email>
              <idno type="idhal" notation="string">gabriel-antoniu</idno>
              <idno type="idhal" notation="numeric">746326</idno>
              <idno type="halauthorid" notation="string">28264-746326</idno>
              <idno type="IDREF">https://www.idref.fr/095615296</idno>
              <idno type="ORCID">https://orcid.org/0000-0001-6525-3736</idno>
              <idno type="GOOGLE SCHOLAR">https://scholar.google.fr/citations?hl=en&amp;user=durpySgAAAAJ</idno>
              <idno type="ORCID">https://orcid.org/0000-0003-0104-5430</idno>
              <affiliation ref="#struct-491076" />
            </author>
            <author role="aut">
              <persName>
                <forename type="first">Matthieu</forename>
                <surname>Simonin</surname>
              </persName>
              <email type="md5">d267ddb0a557f9167306c5ba14a32399</email>
              <email type="domain">inria.fr</email>
              <idno type="idhal" notation="string">matthieu-simonin</idno>
              <idno type="idhal" notation="numeric">6903</idno>
              <idno type="halauthorid" notation="string">23654-6903</idno>
              <affiliation ref="#struct-490914" />
            </author>
            <author role="aut">
              <persName>
                <forename type="first">Jean-Christophe</forename>
                <surname>Lombardo</surname>
              </persName>
              <email type="md5">8cd0ad7ff23d18a15d5cd9ea835fcf6c</email>
              <email type="domain">inria.fr</email>
              <idno type="idhal" notation="string">jean-christophe-lombardo</idno>
              <idno type="idhal" notation="numeric">21463</idno>
              <idno type="halauthorid" notation="string">16622-21463</idno>
              <idno type="ORCID">https://orcid.org/0000-0002-9656-4219</idno>
              <affiliation ref="#struct-141072" />
            </author>
            <author role="aut">
              <persName>
                <forename type="first">Alexis</forename>
                <surname>Joly</surname>
              </persName>
              <email type="md5">2969b8fd490aeeb72d850079cee7bbe0</email>
              <email type="domain">inria.fr</email>
              <idno type="idhal" notation="string">alexis-joly</idno>
              <idno type="idhal" notation="numeric">12088</idno>
              <idno type="halauthorid" notation="string">22964-12088</idno>
              <idno type="ORCID">https://orcid.org/0000-0002-2161-9940</idno>
              <idno type="IDREF">https://www.idref.fr/107969394</idno>
              <affiliation ref="#struct-141072" />
            </author>
            <author role="aut">
              <persName>
                <forename type="first">Patrick</forename>
                <surname>Valduriez</surname>
              </persName>
              <email type="md5">b7903099e0d3ee0b492cd1c7a982e35b</email>
              <email type="domain">inria.fr</email>
              <idno type="idhal" notation="string">patrick-valduriez</idno>
              <idno type="idhal" notation="numeric">172604</idno>
              <idno type="halauthorid" notation="string">22529-172604</idno>
              <idno type="ORCID">https://orcid.org/0000-0001-6506-7538</idno>
              <idno type="GOOGLE SCHOLAR">https://scholar.google.fr/citations?user=Vj0m2A0AAAAJ&amp;hl=fr</idno>
              <idno type="IDREF">https://www.idref.fr/028314417</idno>
              <orgName ref="#struct-300009" />
              <affiliation ref="#struct-141072" />
            </author>
            <editor role="depositor">
              <persName>
                <forename>Daniel</forename>
                <surname>Rosendo</surname>
              </persName>
              <email type="md5">4dfedbf6d1e9a9a14875110c7ddaac6b</email>
              <email type="domain">inria.fr</email>
            </editor>
            <funder ref="#projanr-41894" />
            <funder>HPC-BigData Inria Challenge (IPL)</funder>
          </titleStmt>
          <editionStmt>
            <edition n="v1" type="current">
              <date type="whenSubmitted">2021-08-03 19:37:07</date>
              <date type="whenModified">2023-07-05 17:05:49</date>
              <date type="whenReleased">2021-08-04 09:36:02</date>
              <date type="whenProduced">2021-09-07</date>
              <date type="whenEndEmbargoed">2021-07-30</date>
              <ref type="file" target="https://hal.science/hal-03310540/document">
                <date notBefore="2021-07-30" />
              </ref>
              <ref type="file" subtype="author" n="1" target="https://hal.science/hal-03310540/file/Cluster_2021_E2Clab_PlantNet_final.pdf">
                <date notBefore="2021-07-30" />
              </ref>
              <ref type="annex" subtype="undefined" n="0" target="https://hal.science/hal-03310540/file/main.pdf">
                <date notBefore="2021-08-03" />
              </ref>
              <ref type="externalLink" target="http://arxiv.org/pdf/2108.04033" />
            </edition>
            <respStmt>
              <resp>contributor</resp>
              <name key="908015">
                <persName>
                  <forename>Daniel</forename>
                  <surname>Rosendo</surname>
                </persName>
                <email type="md5">4dfedbf6d1e9a9a14875110c7ddaac6b</email>
                <email type="domain">inria.fr</email>
              </name>
            </respStmt>
          </editionStmt>
          <publicationStmt>
            <distributor>CCSD</distributor>
            <idno type="halId">hal-03310540</idno>
            <idno type="halUri">https://hal.science/hal-03310540</idno>
            <idno type="halBibtex">rosendo:hal-03310540</idno>
            <idno type="halRefHtml">&lt;i&gt;Cluster 2021 - IEEE International Conference on Cluster Computing&lt;/i&gt;, Sep 2021, Portland, OR, United States. pp.23-34, &lt;a target="_blank" href="https://dx.doi.org/10.1109/Cluster48925.2021.00043"&gt;&amp;#x27E8;10.1109/Cluster48925.2021.00043&amp;#x27E9;&lt;/a&gt;</idno>
            <idno type="halRef">Cluster 2021 - IEEE International Conference on Cluster Computing, Sep 2021, Portland, OR, United States. pp.23-34, &amp;#x27E8;10.1109/Cluster48925.2021.00043&amp;#x27E9;</idno>
          </publicationStmt>
          <seriesStmt>
            <idno type="stamp" n="UNIV-RENNES1">Université de Rennes 1</idno>
            <idno type="stamp" n="CNRS">CNRS - Centre national de la recherche scientifique</idno>
            <idno type="stamp" n="INRIA">INRIA - Institut National de Recherche en Informatique et en Automatique</idno>
            <idno type="stamp" n="UNIV-UBS">Université de Bretagne Sud</idno>
            <idno type="stamp" n="INSA-RENNES">Institut National des Sciences Appliquées de Rennes</idno>
            <idno type="stamp" n="INRIA-SOPHIA">INRIA Sophia Antipolis - Méditerranée</idno>
            <idno type="stamp" n="INRIA-RENNES">INRIA Rennes - Bretagne Atlantique</idno>
            <idno type="stamp" n="IRISA">Irisa</idno>
            <idno type="stamp" n="INRIASO">INRIA-SOPHIA</idno>
            <idno type="stamp" n="IRISA_SET">IRISA_SET</idno>
            <idno type="stamp" n="INRIA_TEST">INRIA - Institut National de Recherche en Informatique et en Automatique</idno>
            <idno type="stamp" n="LORIA2">Publications du LORIA</idno>
            <idno type="stamp" n="INRIA34">Montpellier</idno>
            <idno type="stamp" n="GRID5000" corresp="SILECS">Grid'5000</idno>
            <idno type="stamp" n="TESTALAIN1">TESTALAIN1</idno>
            <idno type="stamp" n="IRISA-INSA-R" corresp="INSA-RENNES">Institut de Recherche en Informatique et Systèmes Aléatoires - Composante INSA Rennes</idno>
            <idno type="stamp" n="ZENITH" corresp="LIRMM">Scientific Data Management</idno>
            <idno type="stamp" n="LIRMM">Laboratoire d'Informatique de Robotique et de Microélectronique de Montpellier</idno>
            <idno type="stamp" n="CENTRALESUPELEC">Ecole CentraleSupélec</idno>
            <idno type="stamp" n="INRIA2">INRIA 2</idno>
            <idno type="stamp" n="UR1-HAL">Publications labos UR1 dans HAL-Rennes 1</idno>
            <idno type="stamp" n="UR1-MATH-STIC">UR1 - publications Maths-STIC</idno>
            <idno type="stamp" n="UR1-UFR-ISTIC">UFR ISTIC Informatique et électronique</idno>
            <idno type="stamp" n="MIPS">Mathématiques, Informatique, Physique et Systèmes</idno>
            <idno type="stamp" n="UNIV-MONTPELLIER">Université de Montpellier</idno>
            <idno type="stamp" n="TEST-UR-CSS">TEST Université de Rennes CSS</idno>
            <idno type="stamp" n="UNIV-RENNES">Université de Rennes</idno>
            <idno type="stamp" n="INRIA-RENGRE">INRIA-RENGRE</idno>
            <idno type="stamp" n="INRIA-300009">Inria 300009</idno>
            <idno type="stamp" n="INSA-GROUPE">Groupe INSA</idno>
            <idno type="stamp" n="SILECS">Publications from users of the SILECS research infrastructure</idno>
            <idno type="stamp" n="ANR">ANR</idno>
            <idno type="stamp" n="UR1-MATH-NUM">Pôle UnivRennes - Mathématiques - Numérique </idno>
            <idno type="stamp" n="UM-2015-2021" corresp="UNIV-MONTPELLIER">Université de Montpellier (2015-2021)</idno>
            <idno type="stamp" n="IA">Intelligence Artificielle</idno>
          </seriesStmt>
          <notesStmt>
            <note type="audience" n="2">International</note>
            <note type="invited" n="0">No</note>
            <note type="popular" n="0">No</note>
            <note type="peer" n="1">Yes</note>
            <note type="proceedings" n="1">Yes</note>
          </notesStmt>
          <sourceDesc>
            <biblStruct>
              <analytic>
                <title xml:lang="en">Reproducible Performance Optimization of Complex Applications on the Edge-to-Cloud Continuum</title>
                <author role="aut">
                  <persName>
                    <forename type="first">Daniel</forename>
                    <surname>Rosendo</surname>
                  </persName>
                  <email type="md5">4dfedbf6d1e9a9a14875110c7ddaac6b</email>
                  <email type="domain">inria.fr</email>
                  <idno type="idhal" notation="string">daniel-rosendo</idno>
                  <idno type="idhal" notation="numeric">746327</idno>
                  <idno type="halauthorid" notation="string">50740-746327</idno>
                  <idno type="ORCID">https://orcid.org/0000-0003-1175-8426</idno>
                  <idno type="GOOGLE SCHOLAR">https://scholar.google.com/citations?user=7VLhPOAAAAAJ&amp;hl=en</idno>
                  <affiliation ref="#struct-491076" />
                  <affiliation ref="#struct-141072" />
                </author>
                <author role="aut">
                  <persName>
                    <forename type="first">Alexandru</forename>
                    <surname>Costan</surname>
                  </persName>
                  <email type="md5">5332b665078fee64483b8a2cb4c0d534</email>
                  <email type="domain">irisa.fr</email>
                  <idno type="idhal" notation="string">alexandru-costan</idno>
                  <idno type="idhal" notation="numeric">9361</idno>
                  <idno type="halauthorid" notation="string">27975-9361</idno>
                  <idno type="IDREF">https://www.idref.fr/220478279</idno>
                  <idno type="ORCID">https://orcid.org/0000-0003-3111-6308</idno>
                  <affiliation ref="#struct-117606" />
                  <affiliation ref="#struct-491076" />
                </author>
                <author role="aut">
                  <persName>
                    <forename type="first">Gabriel</forename>
                    <surname>Antoniu</surname>
                  </persName>
                  <email type="md5">f744d7a97b53f5050dfdd6c734bd83e1</email>
                  <email type="domain">inria.fr</email>
                  <idno type="idhal" notation="string">gabriel-antoniu</idno>
                  <idno type="idhal" notation="numeric">746326</idno>
                  <idno type="halauthorid" notation="string">28264-746326</idno>
                  <idno type="IDREF">https://www.idref.fr/095615296</idno>
                  <idno type="ORCID">https://orcid.org/0000-0001-6525-3736</idno>
                  <idno type="GOOGLE SCHOLAR">https://scholar.google.fr/citations?hl=en&amp;user=durpySgAAAAJ</idno>
                  <idno type="ORCID">https://orcid.org/0000-0003-0104-5430</idno>
                  <affiliation ref="#struct-491076" />
                </author>
                <author role="aut">
                  <persName>
                    <forename type="first">Matthieu</forename>
                    <surname>Simonin</surname>
                  </persName>
                  <email type="md5">d267ddb0a557f9167306c5ba14a32399</email>
                  <email type="domain">inria.fr</email>
                  <idno type="idhal" notation="string">matthieu-simonin</idno>
                  <idno type="idhal" notation="numeric">6903</idno>
                  <idno type="halauthorid" notation="string">23654-6903</idno>
                  <affiliation ref="#struct-490914" />
                </author>
                <author role="aut">
                  <persName>
                    <forename type="first">Jean-Christophe</forename>
                    <surname>Lombardo</surname>
                  </persName>
                  <email type="md5">8cd0ad7ff23d18a15d5cd9ea835fcf6c</email>
                  <email type="domain">inria.fr</email>
                  <idno type="idhal" notation="string">jean-christophe-lombardo</idno>
                  <idno type="idhal" notation="numeric">21463</idno>
                  <idno type="halauthorid" notation="string">16622-21463</idno>
                  <idno type="ORCID">https://orcid.org/0000-0002-9656-4219</idno>
                  <affiliation ref="#struct-141072" />
                </author>
                <author role="aut">
                  <persName>
                    <forename type="first">Alexis</forename>
                    <surname>Joly</surname>
                  </persName>
                  <email type="md5">2969b8fd490aeeb72d850079cee7bbe0</email>
                  <email type="domain">inria.fr</email>
                  <idno type="idhal" notation="string">alexis-joly</idno>
                  <idno type="idhal" notation="numeric">12088</idno>
                  <idno type="halauthorid" notation="string">22964-12088</idno>
                  <idno type="ORCID">https://orcid.org/0000-0002-2161-9940</idno>
                  <idno type="IDREF">https://www.idref.fr/107969394</idno>
                  <affiliation ref="#struct-141072" />
                </author>
                <author role="aut">
                  <persName>
                    <forename type="first">Patrick</forename>
                    <surname>Valduriez</surname>
                  </persName>
                  <email type="md5">b7903099e0d3ee0b492cd1c7a982e35b</email>
                  <email type="domain">inria.fr</email>
                  <idno type="idhal" notation="string">patrick-valduriez</idno>
                  <idno type="idhal" notation="numeric">172604</idno>
                  <idno type="halauthorid" notation="string">22529-172604</idno>
                  <idno type="ORCID">https://orcid.org/0000-0001-6506-7538</idno>
                  <idno type="GOOGLE SCHOLAR">https://scholar.google.fr/citations?user=Vj0m2A0AAAAJ&amp;hl=fr</idno>
                  <idno type="IDREF">https://www.idref.fr/028314417</idno>
                  <orgName ref="#struct-300009" />
                  <affiliation ref="#struct-141072" />
                </author>
              </analytic>
              <monogr>
                <meeting>
                  <title>Cluster 2021 - IEEE International Conference on Cluster Computing</title>
                  <date type="start">2021-09-07</date>
                  <date type="end">2021-09-10</date>
                  <settlement>Portland, OR</settlement>
                  <country key="US">United States</country>
                </meeting>
                <imprint>
                  <biblScope unit="pp">23-34</biblScope>
                  <date type="datePub">2021</date>
                </imprint>
              </monogr>
              <idno type="arxiv">2108.04033</idno>
              <idno type="doi">10.1109/Cluster48925.2021.00043</idno>
            </biblStruct>
          </sourceDesc>
          <profileDesc>
            <langUsage>
              <language ident="en">English</language>
            </langUsage>
            <textClass>
              <keywords scheme="author">
                <term xml:lang="en">Optimization</term>
                <term xml:lang="en">Computing Continuum</term>
                <term xml:lang="en">Methodology</term>
                <term xml:lang="en">Reproducibility</term>
              </keywords>
              <classCode scheme="halDomain" n="info.info-dc">Computer Science [cs]/Distributed, Parallel, and Cluster Computing [cs.DC]</classCode>
              <classCode scheme="halDomain" n="info.info-lg">Computer Science [cs]/Machine Learning [cs.LG]</classCode>
              <classCode scheme="halDomain" n="info.info-ai">Computer Science [cs]/Artificial Intelligence [cs.AI]</classCode>
              <classCode scheme="halDomain" n="info.info-pf">Computer Science [cs]/Performance [cs.PF]</classCode>
              <classCode scheme="halDomain" n="info.info-sy">Computer Science [cs]/Systems and Control [cs.SY]</classCode>
              <classCode scheme="halTypology" n="COMM">Conference papers</classCode>
              <classCode scheme="halOldTypology" n="COMM">Conference papers</classCode>
              <classCode scheme="halTreeTypology" n="COMM">Conference papers</classCode>
            </textClass>
            <abstract xml:lang="en">
              <p>In more and more application areas, we are witnessing the emergence of complex workflows that combine computing, analytics and learning. They often require a hybrid execution infrastructure with IoT devices interconnected to cloud/HPC systems (aka Computing Continuum). Such workflows are subject to complex constraints and requirements in terms of performance, resource usage, energy consumption and financial costs. This makes it challenging to optimize their configuration and deployment. We propose a methodology to support the optimization of real-life applications on the Edge-to-Cloud Continuum. We implement it as an extension of E2Clab, a previously proposed framework supporting the complete experimental cycle across the Edge-to-Cloud Continuum. Our approach relies on a rigorous analysis of possible configurations in a controlled testbed environment to understand their behaviour and related performance trade-offs. We illustrate our methodology by optimizing Pl@ntNet, a world-wide plant identification application. Our methodology can be generalized to other applications in the Edge-to-Cloud Continuum.</p>
            </abstract>
          </profileDesc>
        </biblFull>
      </listBibl>
    </body>
    <back>
      <listOrg type="structures">
        <org type="researchteam" xml:id="struct-491076" status="VALID">
          <idno type="RNSR">200920935W</idno>
          <orgName>Scalable Storage for Clouds and Beyond</orgName>
          <orgName type="acronym">KerData</orgName>
          <desc>
            <address>
              <addrLine>Campus de Beaulieu 35042 Rennes cedex</addrLine>
              <country key="FR" />
            </address>
            <ref type="url">http://www.inria.fr/equipes/kerdata</ref>
          </desc>
          <listRelation>
            <relation active="#struct-419153" type="direct" />
            <relation active="#struct-300009" type="indirect" />
            <relation active="#struct-490900" type="direct" />
            <relation active="#struct-490899" type="indirect" />
            <relation active="#struct-105160" type="indirect" />
            <relation active="#struct-117606" type="indirect" />
            <relation active="#struct-301232" type="indirect" />
            <relation active="#struct-172265" type="indirect" />
            <relation active="#struct-247362" type="indirect" />
            <relation active="#struct-411575" type="indirect" />
            <relation name="UMR6074" active="#struct-441569" type="indirect" />
            <relation active="#struct-481355" type="indirect" />
            <relation active="#struct-302102" type="indirect" />
          </listRelation>
        </org>
        <org type="researchteam" xml:id="struct-141072" status="OLD">
          <idno type="RNSR">201121208J</idno>
          <orgName>Scientific Data Management</orgName>
          <orgName type="acronym">ZENITH</orgName>
          <date type="end">2021-12-31</date>
          <desc>
            <address>
              <addrLine>LIRMM, 161 rue Ada, 34000 Montpellier</addrLine>
              <country key="FR" />
            </address>
            <ref type="url">https://team.inria.fr/zenith/</ref>
          </desc>
          <listRelation>
            <relation active="#struct-181" type="direct" />
            <relation name="UMR5506" active="#struct-410122" type="indirect" />
            <relation name="UMR5506" active="#struct-441569" type="indirect" />
            <relation active="#struct-34586" type="direct" />
            <relation active="#struct-300009" type="indirect" />
          </listRelation>
        </org>
        <org type="institution" xml:id="struct-117606" status="VALID">
          <idno type="ROR">https://ror.org/04xaa4j22</idno>
          <orgName>Institut National des Sciences Appliquées - Rennes</orgName>
          <orgName type="acronym">INSA Rennes</orgName>
          <desc>
            <address>
              <addrLine>20, avenue des Buttes de Coësmes - CS 70839 - 35708 Rennes cedex 7</addrLine>
              <country key="FR" />
            </address>
            <ref type="url">http://www.insa-rennes.fr/</ref>
          </desc>
          <listRelation>
            <relation active="#struct-301232" type="direct" />
          </listRelation>
        </org>
        <org type="researchteam" xml:id="struct-490914" status="VALID">
          <idno type="RNSR">201020965Z</idno>
          <orgName>Design and Implementation of Autonomous Distributed Systems</orgName>
          <orgName type="acronym">MYRIADS</orgName>
          <desc>
            <address>
              <addrLine>Campus de Beaulieu 35042 Rennes cedex</addrLine>
              <country key="FR" />
            </address>
            <ref type="url">http://www.inria.fr/equipes/myriads</ref>
          </desc>
          <listRelation>
            <relation active="#struct-419153" type="direct" />
            <relation active="#struct-300009" type="indirect" />
            <relation active="#struct-490900" type="direct" />
            <relation active="#struct-490899" type="indirect" />
            <relation active="#struct-105160" type="indirect" />
            <relation active="#struct-117606" type="indirect" />
            <relation active="#struct-301232" type="indirect" />
            <relation active="#struct-172265" type="indirect" />
            <relation active="#struct-247362" type="indirect" />
            <relation active="#struct-411575" type="indirect" />
            <relation name="UMR6074" active="#struct-441569" type="indirect" />
            <relation active="#struct-481355" type="indirect" />
            <relation active="#struct-302102" type="indirect" />
          </listRelation>
        </org>
        <org type="laboratory" xml:id="struct-419153" status="VALID">
          <idno type="RNSR">198018249C</idno>
          <idno type="ROR">https://ror.org/04040yw90</idno>
          <orgName>Inria Rennes – Bretagne Atlantique</orgName>
          <desc>
            <address>
              <addrLine>Campus de beaulieu35042 Rennes cedex</addrLine>
              <country key="FR" />
            </address>
            <ref type="url">http://www.inria.fr/centre/rennes</ref>
          </desc>
          <listRelation>
            <relation active="#struct-300009" type="direct" />
          </listRelation>
        </org>
        <org type="institution" xml:id="struct-300009" status="VALID">
          <idno type="ROR">https://ror.org/02kvxyf05</idno>
          <orgName>Institut National de Recherche en Informatique et en Automatique</orgName>
          <orgName type="acronym">Inria</orgName>
          <desc>
            <address>
              <addrLine>Domaine de VoluceauRocquencourt - BP 10578153 Le Chesnay Cedex</addrLine>
              <country key="FR" />
            </address>
            <ref type="url">http://www.inria.fr/en/</ref>
          </desc>
        </org>
        <org type="department" xml:id="struct-490900" status="VALID">
          <orgName>SYSTÈMES LARGE ÉCHELLE</orgName>
          <orgName type="acronym">IRISA-D1</orgName>
          <desc>
            <address>
              <country key="FR" />
            </address>
            <ref type="url">https://www.irisa.fr/fr/departements/d1-systemes-large-echelle</ref>
          </desc>
          <listRelation>
            <relation active="#struct-490899" type="direct" />
            <relation active="#struct-105160" type="indirect" />
            <relation active="#struct-117606" type="indirect" />
            <relation active="#struct-301232" type="indirect" />
            <relation active="#struct-172265" type="indirect" />
            <relation active="#struct-247362" type="indirect" />
            <relation active="#struct-300009" type="indirect" />
            <relation active="#struct-411575" type="indirect" />
            <relation name="UMR6074" active="#struct-441569" type="indirect" />
            <relation active="#struct-481355" type="indirect" />
            <relation active="#struct-302102" type="indirect" />
          </listRelation>
        </org>
        <org type="laboratory" xml:id="struct-490899" status="VALID">
          <idno type="IdRef">026386909</idno>
          <idno type="ISNI">0000 0001 2298 7270</idno>
          <idno type="RNSR">200012163A</idno>
          <idno type="ROR">https://ror.org/00myn0z94</idno>
          <orgName>Institut de Recherche en Informatique et Systèmes Aléatoires</orgName>
          <orgName type="acronym">IRISA</orgName>
          <date type="start">2017-01-01</date>
          <desc>
            <address>
              <addrLine>Avenue du général LeclercCampus de Beaulieu 35042 RENNES CEDEX</addrLine>
              <country key="FR" />
            </address>
            <ref type="url">http://www.irisa.fr</ref>
          </desc>
          <listRelation>
            <relation active="#struct-105160" type="direct" />
            <relation active="#struct-117606" type="direct" />
            <relation active="#struct-301232" type="indirect" />
            <relation active="#struct-172265" type="direct" />
            <relation active="#struct-247362" type="direct" />
            <relation active="#struct-300009" type="direct" />
            <relation active="#struct-411575" type="direct" />
            <relation name="UMR6074" active="#struct-441569" type="direct" />
            <relation active="#struct-481355" type="direct" />
            <relation active="#struct-302102" type="indirect" />
          </listRelation>
        </org>
        <org type="institution" xml:id="struct-105160" status="VALID">
          <idno type="ROR">https://ror.org/015m7wh34</idno>
          <orgName>Université de Rennes</orgName>
          <orgName type="acronym">UR</orgName>
          <desc>
            <address>
              <addrLine>Campus de Beaulieu, 263 avenue Général Leclerc, CS 74205, 35042 RENNES CEDEX</addrLine>
              <country key="FR" />
            </address>
            <ref type="url">https://www.univ-rennes.fr/</ref>
          </desc>
        </org>
        <org type="regroupinstitution" xml:id="struct-301232" status="VALID">
          <idno type="IdRef">162105150</idno>
          <orgName>Institut National des Sciences Appliquées</orgName>
          <orgName type="acronym">INSA</orgName>
          <desc>
            <address>
              <country key="FR" />
            </address>
          </desc>
        </org>
        <org type="institution" xml:id="struct-172265" status="VALID">
          <idno type="ROR">https://ror.org/04ed7fw48</idno>
          <orgName>Université de Bretagne Sud</orgName>
          <orgName type="acronym">UBS</orgName>
          <desc>
            <address>
              <addrLine>BP 92116 - 56321 Lorient cedex</addrLine>
              <country key="FR" />
            </address>
            <ref type="url">http://www.univ-ubs.fr/</ref>
          </desc>
        </org>
        <org type="institution" xml:id="struct-247362" status="VALID">
          <idno type="ROR">https://ror.org/03rxtdc22</idno>
          <orgName>École normale supérieure - Rennes</orgName>
          <orgName type="acronym">ENS Rennes</orgName>
          <desc>
            <address>
              <addrLine>Campus de Ker Lann - avenue Robert Schuman - 35170 Bruz</addrLine>
              <country key="FR" />
            </address>
            <ref type="url">http://www.ens-rennes.fr</ref>
          </desc>
        </org>
        <org type="institution" xml:id="struct-411575" status="VALID">
          <idno type="IdRef">184443237</idno>
          <idno type="ROR">https://ror.org/019tcpt25</idno>
          <orgName>CentraleSupélec</orgName>
          <desc>
            <address>
              <addrLine>3, rue Joliot Curie,Plateau de Moulon,91192 GIF-SUR-YVETTE Cedex</addrLine>
              <country key="FR" />
            </address>
            <ref type="url">http://www.centralesupelec.fr</ref>
          </desc>
        </org>
        <org type="regroupinstitution" xml:id="struct-441569" status="VALID">
          <idno type="IdRef">02636817X</idno>
          <idno type="ISNI">0000000122597504</idno>
          <idno type="ROR">https://ror.org/02feahw73</idno>
          <orgName>Centre National de la Recherche Scientifique</orgName>
          <orgName type="acronym">CNRS</orgName>
          <date type="start">1939-10-19</date>
          <desc>
            <address>
              <country key="FR" />
            </address>
            <ref type="url">https://www.cnrs.fr/</ref>
          </desc>
        </org>
        <org type="institution" xml:id="struct-481355" status="VALID">
          <idno type="IdRef">202743233</idno>
          <idno type="ROR">https://ror.org/030hj3061</idno>
          <orgName>IMT Atlantique</orgName>
          <orgName type="acronym">IMT Atlantique</orgName>
          <date type="start">2017-01-01</date>
          <desc>
            <address>
              <addrLine>Campus Brest : Technopôle Brest-Iroise CS 8381829238 BREST Cedex 3 -Campus Nantes : 4, rue Alfred Kastler- La chantrerie 44300 NANTES -Campus Rennes :  2 Rue de la Châtaigneraie, 35510 CESSON SEVIGNE</addrLine>
              <country key="FR" />
            </address>
            <ref type="url">https://www.imt-atlantique.fr</ref>
          </desc>
          <listRelation>
            <relation active="#struct-302102" type="direct" />
          </listRelation>
        </org>
        <org type="regroupinstitution" xml:id="struct-302102" status="VALID">
          <idno type="ROR">https://ror.org/025vp2923</idno>
          <orgName>Institut Mines-Télécom [Paris]</orgName>
          <orgName type="acronym">IMT</orgName>
          <date type="start">2012-03-01</date>
          <desc>
            <address>
              <addrLine>37-39 Rue Dareau, 75014 Paris</addrLine>
              <country key="FR" />
            </address>
            <ref type="url">http://www.mines-telecom.fr/</ref>
          </desc>
        </org>
        <org type="laboratory" xml:id="struct-181" status="OLD">
          <idno type="IdRef">139590827</idno>
          <idno type="ISNI">0000000405990488</idno>
          <idno type="RNSR">199111950H</idno>
          <idno type="ROR">https://ror.org/013yean28</idno>
          <orgName>Laboratoire d'Informatique de Robotique et de Microélectronique de Montpellier</orgName>
          <orgName type="acronym">LIRMM</orgName>
          <date type="start">1995-01-01</date>
          <date type="end">2021-12-31</date>
          <desc>
            <address>
              <addrLine>161 rue Ada - 34095 Montpellier</addrLine>
              <country key="FR" />
            </address>
            <ref type="url">https://www.lirmm.fr</ref>
          </desc>
          <listRelation>
            <relation name="UMR5506" active="#struct-410122" type="direct" />
            <relation name="UMR5506" active="#struct-441569" type="direct" />
          </listRelation>
        </org>
        <org type="institution" xml:id="struct-410122" status="OLD">
          <idno type="ISNI">0000000120970141</idno>
          <idno type="ROR">https://ror.org/051escj72</idno>
          <orgName>Université de Montpellier</orgName>
          <orgName type="acronym">UM</orgName>
          <date type="end">2021-12-31</date>
          <desc>
            <address>
              <addrLine>163 rue Auguste Broussonnet - 34090 Montpellier</addrLine>
              <country key="FR" />
            </address>
            <ref type="url">http://www.umontpellier.fr/</ref>
          </desc>
        </org>
        <org type="laboratory" xml:id="struct-34586" status="VALID">
          <idno type="RNSR">198318250R</idno>
          <idno type="ROR">https://ror.org/01nzkaw91</idno>
          <orgName>Inria Sophia Antipolis - Méditerranée</orgName>
          <orgName type="acronym">CRISAM</orgName>
          <desc>
            <address>
              <addrLine>2004 route des Lucioles BP 93 06902 Sophia Antipolis</addrLine>
              <country key="FR" />
            </address>
            <ref type="url">http://www.inria.fr/centre/sophia/</ref>
          </desc>
          <listRelation>
            <relation active="#struct-300009" type="direct" />
          </listRelation>
        </org>
      </listOrg>
      <listOrg type="projects">
        <org type="anrProject" xml:id="projanr-41894" status="VALID">
          <idno type="anr">ANR-15-CE25-0003</idno>
          <orgName>OverFlow</orgName>
          <desc>Workflow Data Management as a Service pour des Applications Multi-Site</desc>
          <date type="start">2015</date>
        </org>
      </listOrg>
    </back>
  <teiCorpus>
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Reproducible Performance Optimization of Complex Applications on the Edge-to-Cloud Continuum</title>
				<funder>
					<orgName type="full">HPC-BigData Inria Challenge (IPL)</orgName>
				</funder>
				<funder ref="#_PvTmqTM">
					<orgName type="full">Agence Nationale de la Recherche</orgName>
					<orgName type="abbreviated">ANR</orgName>
				</funder>
				<funder>
					<orgName type="full">Inria</orgName>
				</funder>
				<funder>
					<orgName type="full">CNRS</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher />
				<availability status="unknown"><licence /></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Daniel</forename><surname>Rosendo</surname></persName>
							<email>daniel.rosendo@inria.fr</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">University of Rennes</orgName>
								<orgName type="institution" key="instit2">Inria</orgName>
								<orgName type="institution" key="instit3">CNRS</orgName>
								<orgName type="institution" key="instit4">IRISA -Rennes</orgName>
								<address>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Alexandru</forename><surname>Costan</surname></persName>
							<email>alexandru.costan@inria.fr</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">University of Rennes</orgName>
								<orgName type="institution" key="instit2">Inria</orgName>
								<orgName type="institution" key="instit3">CNRS</orgName>
								<orgName type="institution" key="instit4">IRISA -Rennes</orgName>
								<address>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Gabriel</forename><surname>Antoniu</surname></persName>
							<email>gabriel.antoniu@inria.fr</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">University of Rennes</orgName>
								<orgName type="institution" key="instit2">Inria</orgName>
								<orgName type="institution" key="instit3">CNRS</orgName>
								<orgName type="institution" key="instit4">IRISA -Rennes</orgName>
								<address>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Matthieu</forename><surname>Simonin</surname></persName>
							<email>matthieu.simonin@inria.fr</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">University of Rennes</orgName>
								<orgName type="institution" key="instit2">Inria</orgName>
								<orgName type="institution" key="instit3">CNRS</orgName>
								<orgName type="institution" key="instit4">IRISA -Rennes</orgName>
								<address>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jean-Christophe</forename><surname>Lombardo</surname></persName>
							<email>jean-christophe.lombardo@inria.fr</email>
							<affiliation key="aff1">
								<orgName type="institution" key="instit1">University of Montpellier</orgName>
								<orgName type="institution" key="instit2">Inria</orgName>
								<orgName type="institution" key="instit3">CNRS</orgName>
								<orgName type="institution" key="instit4">LIRMM -Montpellier</orgName>
								<address>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Alexis</forename><surname>Joly</surname></persName>
							<email>alexis.joly@inria.fr</email>
							<affiliation key="aff1">
								<orgName type="institution" key="instit1">University of Montpellier</orgName>
								<orgName type="institution" key="instit2">Inria</orgName>
								<orgName type="institution" key="instit3">CNRS</orgName>
								<orgName type="institution" key="instit4">LIRMM -Montpellier</orgName>
								<address>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Patrick</forename><surname>Valduriez</surname></persName>
							<email>patrick.valduriez@inria.fr</email>
							<affiliation key="aff1">
								<orgName type="institution" key="instit1">University of Montpellier</orgName>
								<orgName type="institution" key="instit2">Inria</orgName>
								<orgName type="institution" key="instit3">CNRS</orgName>
								<orgName type="institution" key="instit4">LIRMM -Montpellier</orgName>
								<address>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Reproducible Performance Optimization of Complex Applications on the Edge-to-Cloud Continuum</title>
					</analytic>
					<monogr>
						<imprint>
							<date />
						</imprint>
					</monogr>
					<idno type="MD5">EDF42A1B16DFD58CFF177D44C1BB9EF3</idno>
					<idno type="DOI">10.1109/Cluster48925.2021.00043</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-04-12T14:45+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid" />
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Reproducibility</term>
					<term>Methodology</term>
					<term>Computing Continuum</term>
					<term>Optimization</term>
				</keywords>
			</textClass>
			<abstract>
<div><p>In more and more application areas, we are witnessing the emergence of complex workflows that combine computing, analytics and learning. They often require a hybrid execution infrastructure with IoT devices interconnected to cloud/HPC systems (aka Computing Continuum). Such workflows are subject to complex constraints and requirements in terms of performance, resource usage, energy consumption and financial costs. This makes it challenging to optimize their configuration and deployment.</p><p>We propose a methodology to support the optimization of reallife applications on the Edge-to-Cloud Continuum. We implement it as an extension of <software>E2Clab</software>, a previously proposed framework supporting the complete experimental cycle across the Edge-to-Cloud Continuum. Our approach relies on a rigorous analysis of possible configurations in a controlled testbed environment to understand their behaviour and related performance tradeoffs. We illustrate our methodology by optimizing <software ContextAttributes="used">Pl@ntNet</software>, a world-wide plant identification application. Our methodology can be generalized to other applications in the Edge-to-Cloud Continuum.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div><head>I. INTRODUCTION</head><p>The continuous increase of IoT devices and captured data requires rethinking where to process data. Instead of the traditional data center compute model, one main approach used in big data is to leverage compute resources distributed at multiple processing points in the system -from endpoint devices at the edge of the network to data centers or HPC systems at its core. This distributed infrastructure, referred to as the Computing Continuum <ref type="bibr" target="#b0">[1]</ref> (or Digital Continuum), combines heterogeneous computing resources that generate and process data across geographically distributed Edge, Fog, and Cloud/HPC infrastructures.</p><p>Real-world applications deployed on such hybrid infrastructure (e.g., smart factory <ref type="bibr" target="#b1">[2]</ref>, autonomous vehicles <ref type="bibr" target="#b2">[3]</ref>, among others) typically need to comply with many constraints related to resource consumption (e.g., GPU, CPU, memory, storage and bandwidth capacities), software components composing the application and requirements such as QoS, security, and privacy <ref type="bibr" target="#b3">[4]</ref>. Furthermore, optimizing application workflows on distributed and heterogeneous resources (i.e., minimizing processing latency, energy consumption, financial costs, etc.) is challenging. The parameter settings of the applications and the underlying infrastructure result in a complex multiinfrastructure configuration search space <ref type="bibr" target="#b4">[5]</ref>.</p><p>The intricacies of these configurations require, prior to production-level deployment, analysis in a controlled testbed environment in order to understand their performance tradeoffs (i.e., latency and energy consumption, throughput and resource usage, cost and service availability, etc.) <ref type="bibr" target="#b5">[6]</ref>, <ref type="bibr" target="#b6">[7]</ref>.</p><p>Let us illustrate this problem with <software ContextAttributes="used">Pl@ntNet</software> <ref type="bibr" target="#b7">[8]</ref>, a largescale participatory application for botanical data and AI-based plant identification. <software ContextAttributes="used">Pl@ntNet</software>'s main feature is a mobile app that allows smartphone users to identify plants from photos and share their observations (Figure <ref type="figure" target="#fig_7">1</ref>). It has more than 10 million users all around the world and processes about 400K plant images per day. One main challenge faced by <software ContextAttributes="used">Pl@ntNet</software> engineers is to anticipate the necessary evolution of the infrastructure to pass the upcoming spring peak (Figure <ref type="figure" target="#fig_0">2</ref>) and adapt the system configuration to some expected evolution of application usage (e.g., an increase of its number of users).</p><p>There are simulation and emulation tools for the Cloud, Fog, Edge, Fog-to-Cloud, Edge-to-Fog <ref type="bibr" target="#b8">[9]</ref>- <ref type="bibr" target="#b11">[12]</ref>. However, there is no solution for large-scale deployment and evaluation of reallife applications on testbeds that cover the entire Computing Continuum as a whole and guide application optimization (i.e., minimizing costs, latency, resource consumption, among others) of the entire application workflow.</p><p>In this paper, we propose a methodology to support the optimization of real-life applications on the Edge-to-Cloud Continuum. This methodology is useful to help decide on application configurations to optimize relevant metrics (e.g., performance, resource usage, energy consumption, etc.) by means of computationally tractable optimization techniques <ref type="bibr" target="#b12">[13]</ref>. It eases the configuration of the system components distributed on Edge, Fog, and Cloud infrastructures as well as the decision where to execute the application workflow components to minimize communication costs and end-to-end latency.</p><p>We implemented this methodology as an extension of the <software ContextAttributes="used">E2Clab</software> <ref type="bibr" target="#b13">[14]</ref> framework for automatic application deployment and reproducible experimentation. This paper has the following main contributions: 1) A methodology to optimize the performance of reallife applications on the Computing Continuum, lever-Fig. <ref type="figure" target="#fig_7">1</ref>: The <software ContextAttributes="used">Pl@ntNet</software> application.</p><p>aging computationally tractable optimization techniques (Section III). 2) An implementation of this optimization methodology as an extension of the <software ContextAttributes="used">E2Clab</software> framework for reproducible analysis of applications on the Edge-to-Cloud continuum. For this purpose, we enhanced <software ContextAttributes="used">E2Clab</software> with an optimization layer. To the best of our knowledge, this enhanced version of <software ContextAttributes="used">E2Clab</software> is the first framework to support the complete deployment and analysis cycle of a complex workflow executed on the Computing Continuum (Section III-D). 3) A large scale experimental validation of the proposed approach with the <software ContextAttributes="used">Pl@ntNet</software> application on 42 nodes of the Grid'5000 testbed <ref type="bibr" target="#b14">[15]</ref>. Our approach helps optimizing <software ContextAttributes="used">Pl@ntNet</software> software configurations across the continuum to minimize user response time (Section IV).</p></div>
<div><head>II. BACKGROUND</head><p>Application workflows that need to be deployed across Edge-to-Cloud infrastructures usually have to configure their software components while considering various infrastructure constraints. For instance, in the Cloud, configurations can include compute and storage configurations, the number of topics in a data ingestion system, reserved memory in data processing frameworks, the inter-cloud network latency, etc. In the Fog, they can include the streaming window size on gateways, the network latency and bandwidth between Fog devices, among others. In the Edge we can refer to device capabilities, the frequency of data emission, the power consumption, among others. These environment settings and configuration parameters are extremely vast and their combination of possibilities virtually unlimited. Hence, the process of searching the ideal deployment and configuration of those real-life applications is challenging given the search space complexity: bad choices may result in increased financial expenses during deployment and production phases, decreased processing efficiency and poor user experience. A. A real-life application: <software ContextAttributes="used">Pl@ntNet</software> Pl@ntNet is a participatory application and platform dedicated to the production of botanical data and plant identification. Currently, the data consists of +35K plant species collected from more than 200 countries. As illustrated in Figure <ref type="figure" target="#fig_7">1</ref>, using the <software ContextAttributes="used">Pl@ntNet</software> mobile application, users (located in the Edge) may identify plants from pictures taken by their phones. Before sending these pictures, some preprocessing is done to reduce the image size.</p><p>Then, the <software>Pl@ntNet</software> Identification Engine (located in the Cloud), subject to analysis in this work, is responsible for the automatic identification of species through Deep Learning. In a nutshell, the Identification Engine performs two main activities: (1) Species prediction: refers to the feature extraction and classification of user images; and (2) Similarity Search: searches for the images of the botanical databases that are the most similar to the user images. At the end of the processing, the Identification Engine returns the ranked list of most probable species with their respective, most similar plant pictures, allowing interactive validation by the users.</p><p>The processing performance of the Identification Engine strongly depends on the thread pool size configured to process the various tasks involved during the identification of users images. Table <ref type="table" target="#tab_0">I</ref> presents the execution order of all tasks, the thread pool they belong to, and in which hardware they take place. Table <ref type="table" target="#tab_1">II</ref> describes the role of each thread pool and an example of configuration currently used in the <software ContextAttributes="used">Pl@ntNet</software> production servers. This configuration was defined by <software ContextAttributes="used">Pl@ntNet</software> engineers based on their best practical experience with the <software ContextAttributes="used">Pl@ntNet</software> system considering mainly the following: (a) for thread pools using CPU: a machine with 40 CPU cores available; and (b) for the GPU thread pool: the maximum number of threads which fit in GPU memory.</p><p>The main performance metric for this application is the user response time. A preliminary analysis <ref type="bibr" target="#b15">[16]</ref> showed that to achieve a 4 seconds response time (the maximum tolerated by users) the thread pool and hardware configurations can not serve more than 120 simultaneous requests (3.86±0.13), as shown in Figure <ref type="figure">3</ref>. In this context, meaningful questions that arise are: Is there a better thread pool allocation that minimizes the user response time? How many more users can the system serve if we find a better thread pool configuration?  The answers to those questions and more analytical insights will be presented in Section IV through the use of our proposed methodology and its implementation in the <software ContextAttributes="used">E2Clab</software> framework.</p><p>Let us highlight that <software ContextAttributes="used">Pl@ntNet</software> is representative of other applications in the context of the Computing Continuum. As illustrated in Figure <ref type="figure" target="#fig_7">1</ref>, it consists of many geographically distributed devices (over 10 million users) that collect and send data (about 400K plant images per day), and perform preprocessing at the Edge, followed by extensive processing (e.g., species prediction, similarity search, etc.) in centralized Cloud/HPC infrastructures.</p></div>
<div><head>B. Formalizing deployment optimization on the Edge-to-Cloud Continuum</head><p>We describe our optimization problem by defining: the optimization variables, the objective function, and the constraints (Equation <ref type="formula" target="#formula_0">1</ref>).</p><formula xml:id="formula_0">min/max x fm(x), m = 1, 2, . . . , M subject to gj (x) ≤ 0, j = 1, 2, . . . , J Inequality constraints. h k (x) = 0, k = 1, 2, . . . , K Equality constraints. x L i ≤ xi ≤ x U i , i = 1, 2, . . . , I Bounds on variables.<label>(1)</label></formula><p>Typically, Edge-to-Cloud deployment optimization problems aim at optimizing metrics <ref type="bibr" target="#b5">[6]</ref>, <ref type="bibr" target="#b16">[17]</ref> related to: performance (e.g., execution time, latency, and throughput), resource usage (e.g., GPU, CPU, memory, storage, and network), energy consumption, financial costs, and quality attributes (e.g., reliability, security, and privacy). Therefore, regarding the formulation of an optimization problem and its mathematical representation in Equation 1, the optimization variables x refer to the variables associated with the optimization problem Fig. <ref type="figure">3</ref>: <software ContextAttributes="used">Pl@ntNet</software> Engine: user response time. (e.g., storage capacity of Edge devices, or number of cores on Fog nodes).</p><p>The objective function refers to the optimization objective, such as minimizing or maximizing a given metric or set of metrics (e.g., performance, energy consumption). The objective function maps the values of the optimization variables onto real numbers and may be classified as single-objective (such as minimizing Edge-to-Cloud processing latency) or multiobjective (e.g., minimizing energy consumption of Fog nodes and maximize throughput).</p><p>Finally, the constraints refer to requirements that a given solution must satisfy. Constraints may refer to a specific optimization variable (e.g., number of cores on Fog nodes between 10 and 20) and the metrics to be optimized by the objective function (e.g., the maximum response time must be less than 3 seconds).</p><p>Figure <ref type="figure" target="#fig_1">4</ref> depicts some examples of optimization problems. Left, one would like to answer the question: how to configure the system components to minimize processing latency? To reduce complexity, the optimization problem is divided into three sub-problems each one with the objective of minimizing the task processing time on the Edge, Fog, and Cloud infrastructures, under specific constraints. The right-hand example aims at answering the question: where should the workflow components be executed to minimize communication costs and end-to-end latency? This translates into a single multiobjective optimization problem (minimizing communication costs and end-to-end latency), as opposed to the previous example (several single-objective optimization problems). In order to model and solve such optimization problems, one may find multiple methods and packages in the literature. For instance, packages and libraries such as <software ContextAttributes="used">Scikit-Optimize</software> <ref type="bibr" target="#b17">[18]</ref>, <software ContextAttributes="used">Scikit-Learn</software> <ref type="bibr" target="#b18">[19]</ref>, <software ContextAttributes="used">Surrogate Modeling Toolbox</software> (<software ContextAttributes="used">SMT)</software> <ref type="bibr" target="#b19">[20]</ref>, <software ContextAttributes="used">DeepHyper</software> <ref type="bibr" target="#b20">[21]</ref>, etc., may be used to build surrogate models and then use those model to explore the search space of the optimization problem.</p></div>
<div><head>C. E2Clab: reproducible Edge-to-Cloud experiments</head><p><software ContextAttributes="used">E2Clab</software> <ref type="bibr" target="#b13">[14]</ref> is a framework that implements a rigorous methodology for designing experiments with real-world workloads on the Edge-to-Cloud Computing Continuum. This methodology, illustrated in Figure <ref type="figure" target="#fig_4">6</ref>, provides guidelines to move from real-world use cases to the design of relevant testbed setups for experiments enabling researchers to understand performance and to support the reproducibility of the experiments.</p><p><software ContextAttributes="used">E2Clab</software> architecture is described in Figure <ref type="figure" target="#fig_5">7</ref>. The idea is that experiments can accurately reproduce relevant behaviors of a given application workflow on representative settings of the physical infrastructure underlying this application.</p><p>The key features provided by <software ContextAttributes="used">E2Clab</software> are: (1) reproducible experiments; (2) the mapping of applications parts executed across the computing continuum with the physical testbed; (3) the support for experiment variation and transparent scaling of the scenario; (4) network emulation to define Edge-to-Cloud communication constraints; and (5) experiment deployment, monitoring and backup of results. <software ContextAttributes="used">E2Clab</software> is open source and is available at <ref type="bibr" target="#b21">[22]</ref>.</p></div>
<div><head>III. A METHODOLOGY FOR OPTIMIZING THE PERFORMANCE OF APPLICATIONS ON THE EDGE-TO-CLOUD CONTINUUM</head><p>Our optimization methodology supports reproducible parallel optimization of application workflows on large-scale testbeds. It consists of three main phases illustrated in Figure <ref type="figure" target="#fig_2">5</ref>.</p></div>
<div><head>A. Phase I: Initialization</head><p>This phase, depicted at the top of Figure <ref type="figure" target="#fig_2">5</ref>, consists in defining the optimization problem. The user must specify: the optimization variables that compose the search space to be explored (e.g., GPUs used for processing, Fog nodes in the scenario, network bandwidth, etc.); the objective (e.g., minimize end-to-end latency, maximize Fog gateway throughput, etc.); and constraints (e.g. the upper and lower bounds of optimization variables, budget, response time latency, etc.).</p><p>One may focus the optimization on: (1) specific parts of the infrastructure (e.g., only on geographically distributed Edge sites, or only on Fog-to-Cloud resources) by defining multiple, per infrastructure, optimization problems, as presented in the left side of Figure <ref type="figure" target="#fig_1">4</ref>. This approach reduces the search space complexity (in case of use cases with large search spaces) and hence the computing time; <ref type="bibr" target="#b1">(2)</ref> or the whole Edge-to-Cloud infrastructure as a single optimization problem, as presented in the right side of Figure <ref type="figure" target="#fig_1">4</ref>.</p></div>
<div><head>B. Phase II: Evaluation</head><p>This phase aims at defining the mathematical methods and optimization techniques used in the optimization cycle (presented in the middle of Figure <ref type="figure" target="#fig_2">5</ref>) to explore the search space. Such optimization cycle consists in: (1) parallel deployment of the application workflow in a large-scale testbed; (2) their simultaneous execution; (3) asynchronous model optimization; and (4) reconfiguration of the application workflow for a new evaluation.</p><p>This cycle continues until model convergence. Depending on the run time characteristics of the application workflows, their evaluations may be performed differently.</p><p>1) Long-time Running Applications: refer to experiments or simulations for which the evaluation of a single point in the search space requires a lot of time to complete (e.g., hours, or even days). Furthermore, since application workflows in the context of the Computing Continuum typically consist of cross-infrastructure parameter configurations resulting in a myriad of configuration possibilities, their optimization problem presents a complex and large search space.</p><p>For those long-time running applications, a variety of Bayesian Optimization <ref type="bibr" target="#b22">[23]</ref> methods (e.g., surrogate models as: Gaussian process (Kriging) <ref type="bibr" target="#b23">[24]</ref>, Decision Trees <ref type="bibr" target="#b24">[25]</ref>, Random Forest <ref type="bibr" target="#b25">[26]</ref>, Gradient Boosting Regression Trees <ref type="bibr" target="#b26">[27]</ref>, Support Vector Machine <ref type="bibr" target="#b27">[28]</ref>, Polynomial Regression <ref type="bibr" target="#b28">[29]</ref>, among others) may be applied as candidates to explore the search space. Their generation is described below.</p><p>Surrogate Model Building: this consists of three steps: (a) a few sample points are generated, respecting the upper and lower limits of each optimization variable that composes the search space. Sampling methods such as Latin Hypercube Sample <ref type="bibr" target="#b29">[30]</ref> or Low Discrepancy Sample <ref type="bibr" target="#b30">[31]</ref>   generated, it is used to explore the optimization search space by deciding the subsequent application configurations to be evaluated in parallel. As soon as the evaluations finish, the model is retrained and optimized asynchronously, then new points are suggested to be evaluated.</p><p>2) Short-time Running Applications: refer to the case when a few minutes are enough to evaluate a single point in the search space. Such applications also follow the optimization cycle previously presented. Besides, they may also use surrogate models to explore the search space. However, differently from Long-time Running Use Cases, they can use other optimization techniques such as evolutionary algorithms and swarm intelligence based algorithms (e.g., Genetic Algorithm <ref type="bibr" target="#b31">[32]</ref>, Differential Evolution <ref type="bibr" target="#b32">[33]</ref>, Simulated Annealing <ref type="bibr" target="#b33">[34]</ref>, Particle Swarm Optimization <ref type="bibr" target="#b34">[35]</ref>, etc.).</p></div>
<div><head>C. Phase III: Finalization</head><p>For reproducibility purposes, this last phase illustrated at the bottom of Figure <ref type="figure" target="#fig_2">5</ref> provides a summary of computations. Therefore, it provides: the definition of the optimization problem (optimization variables, objective, and constraints); the sample selection method; the surrogate models or search algorithms with their hyperparameters used to explore the search space of the optimization problem; and finally the best application configuration found. Providing all this information at the end of computations allows other researches to reproduce the research results.</p></div>
<div><head>D. Implementation as an extension of the E2Clab framework</head><p>To validate our optimization approach, we enhanced the <software ContextAttributes="used">E2Clab</software> framework for reproducible experimentation across the Edge-to-Cloud Continuum. We extended <ref type="bibr" target="#b21">[22]</ref> the <software ContextAttributes="used">E2Clab</software> framework <ref type="bibr" target="#b35">[36]</ref> with support for the performance optimization of application workflows. Figure <ref type="figure" target="#fig_4">6</ref> shows a holistic view of our enhanced methodology containing the extensions highlighted in dashed lines colored in red. As one may note, we have added a new sub-process named Define Optimization (detailed in Figure <ref type="figure" target="#fig_2">5</ref>) inside the Define the Experimental Environment process.</p><p>Figure <ref type="figure" target="#fig_5">7</ref> illustrates the <software ContextAttributes="used">E2Clab</software> architecture. We designed a new manager named Optimization Manager (which implements the optimization approach in Figure <ref type="figure" target="#fig_2">5</ref>). Its role is to: interpret the user-defined optimization setup defined in the optimizer conf configuration file and then automate the optimization cycle (1. parallel deployment of the application workflow in a large-scale testbed; 2. simultaneous application workflow execution; 3. asynchronous model optimization; and 4. reconfiguration of the application workflow for a new evaluation) in order to optimize the application workflow. Laslty, the Optimization Manager provides a summary of computations for reproducibility purposes.</p><p>The Optimization Manager takes advantage of Ray <ref type="bibr" target="#b36">[37]</ref> to run parallel application workflows on the Grid'5000 largescale testbed. Ray Tune <ref type="bibr" target="#b37">[38]</ref>   Ax <ref type="bibr" target="#b39">[40]</ref>, HEBO <ref type="bibr" target="#b40">[41]</ref>, among others). Next, users define in the run objective() function (Listing 1 line 28) their optimization logic, which runs in parallel to train the model. To do so, the Optimization class provides the following three methods: i) prepare(): for reproducibility of optimization evaluations, it generates a dedicated optimization directory for each model evaluation (Listing 1 line 30). ii) launch(): deploys the application on a large-scale testbed to perform a model evaluation (Listing 1 line 32). For reproducibility, deployment-related information are captured, such as physical machines, network constraints, and application configurations. iii) finalize(): for reproducibility purposes, it stores the optimization computations for a given model evaluation in the optimization directory created in the prepare() phase (Listing 1 line 34). Saved information refers to intermediate models throughout training and points evaluated. Listing 1 shows how one may define an optimization problem (e.g., <software ContextAttributes="used">Pl@ntNet</software> problem in Eq. 2). A detailed example may be found on the <software ContextAttributes="used">E2Clab</software> documentation Web page <ref type="bibr" target="#b35">[36]</ref>.</p></div>
<div><head>IV. EXPERIMENTAL VALIDATION</head><p>In this section we illustrate our proposed optimization methodology by showing how it can be used to analyze the performance of the <software>Pl@ntNet</software> botanical application and to find its thread pool configurations. The goal of our experiments is to answer the following research questions:</p><p>1) What is the software configuration, for a given hardware configuration, that minimizes the user response time? 2) How does the number of simultaneous users accessing the system impact on the user response time? 3) How do the Extraction and Similarity Search thread pool configurations impact the processing time and user response time?</p><p>The experimental setup is defined as follows: a) Scenario Configuration: the experiments are carried out on 42 nodes of the Grid'5000 <ref type="bibr" target="#b14">[15]</ref> testbed (clusters chifflot, chiclet, chetemi, chifflet, and gros). Since the <software ContextAttributes="used">Pl@ntNet Identification Engine</software> requires GPU, it is deployed on the chifflot machines (model Dell PowerEdge R740), which are equipped with Nvidia Tesla V100-PCIE-32GB GPUs, Intel Xeon Gold 6126 (Skylake, 2.60GHz, 2 CPUs/node, 12 cores/CPU), 192GB of memory, 480GB SSD, and 25Gbps Ethernet interface. The clients submitting requests to the <software ContextAttributes="used">Pl@ntNet</software> Identification Engine are deployed on the chiclet, chetemi, chifflet, and gros clusters. The network connection is configured with 10Gb.</p><p>b) Workloads: we defined three categories of workloads, according to the number of simultaneous requests (i.e., 80, 120, and 140) submitted to the <software ContextAttributes="used">Pl@ntNet</software> Identification Engine during the whole experiment execution. c) Configuration Parameters: Table <ref type="table" target="#tab_1">II</ref> presents the parameters used to configure the thread pool size of the <software ContextAttributes="used">Pl@ntNet</software> Engine. As presented in Equation <ref type="formula" target="#formula_1">2</ref>, these parameters refer to the optimization variables of the optimization problem.</p><p>d) Performance Metrics: the metric of interest is the user response time. In Equation 2, this metric is to be minimized as the optimization objective. The user response time refers to the average time that a user waits for the response to a request. Besides this metric, we also analyze the identification processing time, which refers to the average time to process a user request. The identification processing is divided into multiple tasks running in parallel, as described in Table <ref type="table" target="#tab_0">I</ref>.</p><p>We compare and analyze the user response time and identification processing time with respect to two thread pool configurations: baseline and preliminary optimum. The baseline refers to the current <software ContextAttributes="used">Pl@ntNet</software> configuration used in the production servers. This configuration was defined by <software ContextAttributes="used">Pl@ntNet</software> engineers based on their best practical experience with the <software ContextAttributes="used">Pl@ntNet</software> system, as explained in Subsection II-A and presented in Table <ref type="table" target="#tab_1">II</ref>.</p><p>The preliminary optimum configuration is the one found using our methodology. We named it preliminary since the optimization problem may have multiple minima and one may find other application configurations if a different technique is used (e.g., Gaussian Process (Kriging) <ref type="bibr" target="#b23">[24]</ref>, Gradient Boosting Regression Trees <ref type="bibr" target="#b26">[27]</ref>, among others). Besides, changes in the hardware configuration (e.g., size of GPU memory, number of CPU cores, among others) running the <software ContextAttributes="used">Pl@ntNet</software> application will require a new search for the thread pool sizes since their configuration strongly depends on the hardware. In this case, our optimization methodology should be applied again. In a subsequent step, we further refine the preliminary optimum In order to obtain accurate measurements we run each experiment (each thread pool configuration) 7 times and each experiment has a duration of 23 minutes (1380 seconds). Besides, during the execution of each experiment we collect the metric values every 10 seconds. Therefore, the user response time is presented with the mean and standard deviation regarding 966 measurements (138 * 7).</p><p>We highlight that, since through experiments we identified variations between measurements, we decided to repeat each configuration 6 times (7 experiments) to reduce the standard deviation of measurements. Besides, we run each experiment for 23 minutes with an interval of metric collection of 10 seconds to also minimize the standard deviation of the metrics collected. Furthermore, thanks to the repeatability feature provided in <software>E2Clab</software>, one may repeat those experiments easily by issuing the following command: e2clab optimize -repeat 6 -duration 1380 path/to/backup/experiments/ path/to/artifacts/.</p><p>A. What is the software configuration that minimizes the user response time?</p><p>The optimization problem to be solved can be stated as follows:</p><p>Find (http, download, <software>simsearch</software>, extract), in order to Minimize U serResponseT ime Subject to 20 ≤ (http, download, <software ContextAttributes="used">simsearch</software>) ≤ 60, P ool Size.</p><p>3 ≤ (extract) ≤ 9, P ool Size.</p><p>(</p><formula xml:id="formula_1">)<label>2</label></formula><p>The function UserResponseTime is given by the parallel execution of the <software>Pl@ntNet</software> workflow on the Grid'5000 testbed, as described in Phase II of our methodology.</p><p>In order to define the search space dimensions we run experiments to identify the maximum upper bounds of variables that do not increase the user response time compared to the baseline <software ContextAttributes="used">Pl@ntNet</software> configuration. Therefore, the lower and upper bounds of variables (see Equation <ref type="formula" target="#formula_1">2</ref>) are ±50% of the baseline configuration (recall Table <ref type="table" target="#tab_1">II</ref>), respectively.</p><p>The workload uses 80 simultaneous requests to the <software ContextAttributes="used">Pl@ntNet</software> Identification engine. We highlight that this number has to be bigger than the upper bound of the HTTP thread pool size since the HTTP pool refers to the simultaneous requests being processed. We leverage Bayesian Optimization since it is typically used for global optimization of black-box functions that are expensive to evaluate <ref type="bibr" target="#b41">[42]</ref>. Extra Trees regressor is used as surrogate model <ref type="bibr" target="#b17">[18]</ref> to model our expensive function. This surrogate model is improved by evaluating the User-ResponseTime function at the next points. The goal is to find the minimum of UserResponseTime function with as few evaluations as possible. Listing 1 lines 6 to 11 detail the search algorithm parameters. The minimization has converged after 9 evaluations and the results are presented in Table <ref type="table" target="#tab_2">III</ref> (considering a workload of 80 simultaneous requests). As one may note, the preliminary optimum configuration reduces the user response time by 7% and can serve 35% more simultaneous users (54 against 40, see the HTTP thread pool).</p><p>From the results, we highlight that thanks to our optimization methodology implemented in <software>E2Clab</software>, one may easily find an optimized application configuration. <software ContextAttributes="used">E2Clab</software> abstracts all the complexities to: define the whole optimization problem (recall to Listing 1); deploy the application; run parallel evaluations of the optimization in a large-scale testbed; and collect all the experiments results. In the next subsections we enhance our analysis in order to: (a) understand the performance of both configurations for different workloads; and (b) better understand the performance results and their correlation with the resource usage.</p><p>B. How does the number of simultaneous users accessing the system impact on the user response time?</p><p>In order to understand the impact of different workloads on the user response time, we defined three workloads that represent simultaneous requests submitted to the <software>Pl@ntNet</software> system. The goal of these experiments is to compare the performance gains of the preliminary optimum thread pool configuration (found using our methodology) against the baseline (current <software ContextAttributes="used">Pl@ntNet</software> configuration). Lastly, we exploit the maximum number of simultaneous requests that each configuration can handle considering the 3-4 seconds user response time constraint.</p><p>As presented in Figure <ref type="figure" target="#fig_8">8</ref>, we scale up the workloads as follows: 80, 120, and 140 simultaneous requests. As one may note, in Figure <ref type="figure" target="#fig_8">8</ref> the preliminary optimum configuration outperforms the baseline for all workloads. We highlight that, the difference between them varied as follows: 6.9%, 2.2%, and 6.7% for 80, 120, and 140 simultaneous requests, respectively.</p><p>The main observation is that the preliminary optimum configuration (found using our methodology) outperforms the baseline thanks to a better thread pool allocation that allows  the <software>Pl@ntNet</software> system to serve simultaneously 35% more requests (54 against 40) with a smaller user response time when compared to the baseline. We also highlight that, thanks to the transparent scaling feature provided by <software ContextAttributes="used">E2Clab</software>, one may easily scale up the workloads to analyze their impact on the application performance.</p><p>C. How do the Extraction and Similarity Search thread pool configurations impact the processing and user response times?</p><p>Since the extraction and similarity search tasks are the most time consuming compared to the remaining ones, we zoom our analysis on them in an attempt to improve even more the thread pool configuration and also to identify possible bottlenecks on the <software>Pl@ntNet</software> identification engine. The experiment aims to understand how variations in the preliminary optimum thread pool configuration of the extraction and similarity search tasks impact the user response time and the processing time of the identification tasks.</p><p>We apply Sensitivity Analysis techniques to explore the impact of such variations. From the existing Sensitivity Analysis methods we decided to use One-at-a-time (OAT) <ref type="bibr" target="#b42">[43]</ref>. OAT is a simple and common approach that consists in varying a single parameter at a time to identify the effect on the output.</p><p>In our case, the parameters are extract and <software ContextAttributes="used">simsearch</software> thread pool sizes. We vary the extract pool size in ±2 from the current size (7 threads), while the <software ContextAttributes="used">simsearch</software> in ±3 (current size is 53 and for simplification, we do not present in Figure <ref type="figure" target="#fig_12">10a</ref> the times for 50 and 51 since they are bigger than 52). These variations result in 10 new thread pool configurations to be evaluated. Therefore, we take advantage of <software ContextAttributes="used">E2Clab</software> to automatically run them in a reproducible way, following <software ContextAttributes="used">E2Clab</software>'s methodology.</p><p>Figure <ref type="figure" target="#fig_10">9</ref> shows the impact of extraction threads on: (a) the user response time and (b) the time to process each task. Furthermore, we also analyze their impact on resource usage, such as: (c) CPU usage (d) GPU memory, (e) system memory, (f) extract pool busy time, and (g) <software ContextAttributes="used">simsearch</software> pool busy time.</p><p>In Figure <ref type="figure" target="#fig_10">9a</ref>, we observe that the preliminary optimum configuration with 7 extract threads does not produce the minimum user response time, since using 6 extract threads reduces it by 8.5%. Decreasing to 5 threads or increasing it to 8 or 9 threads impacts negatively when compared to 6 threads. The explanation for this behaviour is given next.   Regarding the processing time (Figure <ref type="figure" target="#fig_10">9b</ref>), as expected, the wait-extract time reduces as we increase the number of extract threads, while the <software ContextAttributes="used">simsearch</software> task time increases. This time increase in the <software ContextAttributes="used">simsearch</software> task can be explained by Figure <ref type="figure" target="#fig_10">9c</ref>, since using 8 and 9 extract tasks results in a CPU usage of 100% during the whole application execution, so as those tasks compete for processing resources, allocating more extract threads impacts negatively on the <software ContextAttributes="used">simsearch</software> task time. As for the remaining sizes, they varied between 85% and 100%. This behaviour explains the results observed for the user response time presented in Figure <ref type="figure" target="#fig_10">9a</ref>. Furthermore, differently from the wait-extract time, the extract task time was not reduced when increasing the extract thread pool size.</p><p>By analyzing the impact on the GPU memory usage (Figure <ref type="figure" target="#fig_10">9d</ref>), we observe that it increases as we allocate more threads to the extract thread pool and it remains constant during the application execution. The GPU utilization for all thread pool sizes is between 35% and 60% most of the time, while the GPU power draw is between 50 Watts and 80 Watts. As the GPU memory usage, the system memory usage (Figure <ref type="figure" target="#fig_10">9e</ref>) of the Docker container running the <software ContextAttributes="used">Pl@ntNet Engine</software> also increases with the extract thread pool size.</p><p>Lastly, the extract thread pool busy time (Figure <ref type="figure" target="#fig_10">9f</ref>) is 100% during the whole application execution for thread pool sizes Fig. <ref type="figure" target="#fig_7">11</ref>: User response time: baseline vs optimums. of 5, 6, and 7, and between 80% and 100% for sizes of 8 and 9. This explains the higher and lower values, respectively, of the wait-extract times observed in Figure <ref type="figure" target="#fig_10">9b</ref>. For the similarity search (Figure <ref type="figure" target="#fig_10">9g</ref>), the thread pool busy time is between 80% and 100% for a size of 8 and 9. For the 5, 6, and 7 thread pool sizes it is 50%, 55%, and 60% busy in average, respectively. This also explains the higher values of wait-<software ContextAttributes="used">simsearch</software> for sizes 8 and 9 compared to 5, 6, and 7 in Figure <ref type="figure" target="#fig_10">9b</ref>.</p><p>Following our analysis, Figure <ref type="figure" target="#fig_12">10</ref> shows the impact of the thread pool size for similarity search on: (a) user response time and (b) processing time. Besides, in Figure <ref type="figure" target="#fig_12">10c</ref> and Figure <ref type="figure" target="#fig_12">10d</ref> we show the thread pool busy time for the similarity search and extract thread pools, respectively.</p><p>In Figure <ref type="figure" target="#fig_12">10a</ref>, as one may note, the preliminary optimum configuration with 53 threads may be increased to 55 threads in order to reduce by about 4% the user response time. Regarding the processing time (Figure <ref type="figure" target="#fig_12">10b</ref>), the <software ContextAttributes="used">simsearch</software> task time confirms what was observed with the user response time, that is, adding more than 55 threads is not worth to decrease the execution time of the <software ContextAttributes="used">simsearch</software> task.</p><p>Figure <ref type="figure" target="#fig_12">10c</ref> shows the correlation of the similarity search pool busy time with the <software ContextAttributes="used">simsearch</software> task time observed in Figure <ref type="figure" target="#fig_12">10b</ref> and explains its variation. Using 52 threads it is busy between 90% and 100%, while for 53 to 55 it is below 60%, and increases to about 80% with 56 threads. The impact of the similarity search thread pool variation on extract task (Figure <ref type="figure" target="#fig_12">10b</ref>) can be explained by Figure <ref type="figure" target="#fig_12">10d</ref>. Lower times in wait-extract for sizes 52 and 56 is due to a busy time between 90% and 100%. For sizes from 53 to 55, the busy time is 100%.</p><p>Since we observed a lower user response time after analyzing the impact of variations of the extract and <software ContextAttributes="used">simsearch</software> thread pool configurations on the user response time, we exploit this configuration (named refined optimum) with all the previously defined workloads. As presented in Table <ref type="table" target="#tab_3">IV</ref> and Figure <ref type="figure" target="#fig_7">11</ref>, we observed even better results for all workloads.</p><p>Let us note that for all workloads the refined optimum presents the best results, outperforming both baseline and preliminary optimum. Compared with the baseline, the difference between configurations varied with the workloads as follows: from 6.9% to 7.2%; from 2.2% to 6.3%; and from 6.7% to 9.8% for 80, 120, and 140 simultaneous requests, respectively.</p><p>In summary, the analysis presented in this section backed by our optimisation methodology helped to understand how variations in the thread pool configuration of the <software>Pl@ntNet</software> engine impact on the processing times (user response time and identification processing steps) by correlating them with the resource usage. Furthermore, this analysis helps to improve the performance of the application by supporting 35% more simultaneous users (54 against 40) and presenting a smaller user response time for different workloads (80, 120, and 140 simultaneous requests) and 30% less GPU memory utilization (7GB against 10GB), when compared to the baseline.</p><p>Let us also highlight that, despite our evaluations focusing on the <software>Pl@ntNet</software> as a use case, our methodology and its implementation in <software ContextAttributes="created">E2Clab</software> can be used to analyze other applications in the context of the Edge-to-Cloud Computing Continuum (more details in Section V-C).</p></div>
<div><head>V. DISCUSSION</head><p>The enhanced <software>E2Clab</software> exhibits a series of features that make it a promising platform for future performance optimization of applications on the Edge-to-Cloud Continuum through reproducible experiments. We briefly discuss them here.</p></div>
<div><head>A. Reproducible application optimization</head><p>Our optimization methodology is aligned with the Open Science <ref type="bibr" target="#b43">[44]</ref> goal to make scientific research processes more transparent and results more accessible. As presented in Section III, it is implemented as an extension of the <software ContextAttributes="created">E2Clab</software> framework for reproducible experimentation across the Edgeto-Cloud Continuum. It provides guidelines to systematically define the whole optimization cycle, such as: (Phase-I) defines the optimization problem and the application-related parameters to optimize; (Phase-II) defines the sampling methods and the optimization techniques and hyperparameters; and (Phase-III) provides access to the optimization results.</p><p>The whole optimization cycle is defined through a configuration file (Listing 1). This file was designed to be easy to use and to understand, and it can be easily adapted to different optimization problems (find out more in the documentation Web page <ref type="bibr" target="#b35">[36]</ref>). At the end of each optimization cycle, <software ContextAttributes="created">E2Clab</software> provides an archive of the generated data. Such archive consists of data from Phases I and II, needed to allow other researches to reproduce the research results. Regarding this work, the access to the experimental artifacts; definition of the experimental environment; and experimental results are publicly available at <ref type="bibr" target="#b44">[45]</ref>.</p></div>
<div><head>B. Scalable and parallel application optimization on largescale testbeds</head><p>The proposed optimization methodology enables scalable (on large-scale testbeds), parallel (through asynchronous model training) and reproducible (by following a rigorous experimental methodology) application optimization. This approach speeds up the search of application parameters thanks to parallel and asynchronous application deployments on largescale testbeds which helps to significantly reduce the application optimization time from days to hours compared to a sequential optimization approach.</p><p>The parallel evaluation of the application configuration has the potential to scale to hundreds of machines in a large-scale testbed. Therefore, one may compute simultaneously 10, 20, or even more (depending on the testbed limits and the hardware requirements of the application) evaluations of the objective function to speed-up the computations. We plan to explore this potential in future work.</p></div>
<div><head>C. Optimizing other applications</head><p>Our approach is generic: the optimization of other applications may be achieved by describing the application optimization problem in the optimization configuration file. It allows one to define the optimization cycle and easily adapt it to different optimization application-specific problems.</p><p>Furthermore, users may easily apply our methodology to their applications thanks to the Services abstraction provided by <software>E2Clab</software>. Services represent any system or a group of systems that provide a specific functionality or action in the scenario workflow. For instance, such services may refer to Flink, Spark or Kafka clusters, among others.</p><p>In order to support their applications, users have to implement their User-Defined Services. For this purpose, <software>E2Clab</software> provides a Service class in which users have to override a deploy method to define the deployment logic of their services, such as: the distribution of services to the physical machines; and to install the required software to run these services. Next, <software ContextAttributes="created">E2Clab</software>'s Service class provides a method to register the user services. Lastly, <software ContextAttributes="created">E2Clab</software> managers will be able to deploy each service on the testbed. Therefore, in the work described in this paper, we had to implement the <software ContextAttributes="created">Pl@ntNet</software> service.</p></div>
<div><head>VI. RELATED WORK</head><p>With the popularity of complex application workflows requiring hybrid execution infrastructures, the holistic analysis of such applications combining IoT Edge devices and Cloud/HPC systems has been a very active field of research in the last few years.</p><p>Existing solutions focus on the simulation and emulation of parts of the Edge-to-Cloud infrastructure. Edge-CloudSim <ref type="bibr" target="#b10">[11]</ref> is an environment for performance evaluation of Edge computing systems that provides simulation for Edge-based scenarios. Users may run experiments considering computational and networking resources. <software ContextAttributes="created">EmuFog</software> <ref type="bibr" target="#b11">[12]</ref> is an extensible emulation framework for Fog-based scenarios that allows the emulation of real applications and workloads. However, they focus on the Edge and Fog layers separately, not on the Edge-to-Cloud Continuum as a whole.</p><p>In <ref type="bibr" target="#b45">[46]</ref>, the authors proposed an approach for automated deployment (using Kubernetes <ref type="bibr" target="#b46">[47]</ref>) of Cloud applications in the Edge-to-Cloud Continuum. This approach explores methods for selection of the optimal infrastructure, satisfying QoS requirements of Cloud applications. While, A3-E <ref type="bibr" target="#b47">[48]</ref> provides a unified model for managing the life cycle of continuum applications (mobile, Edge, and Cloud resources). A3-E focuses on the placement of computation along the continuum based on the specific context and user requirements. However, both works fail on providing configuration control of the parameters of the application and of the underlying Edgeto-Cloud infrastructure; it is widely known and demonstrated that configuration strongly impacts performance. Thus, that support is essential for performing reproducible experiments.</p><p>In contrast, our optimization methodology integrates reproducibility by design, and its implementation within <software>E2Clab</software> enables instrumentation of real-life applications on large-scale testbeds across the entire Edge-to-Cloud Continuum.</p></div>
<div><head>VII. CONCLUSIONS</head><p>The optimization methodology proposed in this paper has proven useful for understanding and improving the performance of a real-life application used in production at largescale. Thanks to the extension presented in this work, <software>E2Clab</software> becomes, to the best of our knowledge, the first framework to support the complete deployment and analysis cycle of application workflows executed on the Computing Continuum, including deployment, configuration, monitoring, and gathering of results, and now performance optimization.</p><p>We have validated our proposed optimization methodology at large scale on 42 nodes of the Grid 5000 testbed. We have shown how it can be used to analyze and optimize the performance of the <software>Pl@ntNet</software> botanical application, used by more than 10 million users in 180 countries.</p><p>The thread pool allocation found using our methodology increases the number of simultaneous requests processed in parallel by 35% compared to the baseline; it reduces user response time for different workloads; and consumes 30% less GPU memory. Despite our focus on <software>Pl@ntNet</software>, the methodology can be generalized to other applications in the Edge-to-Cloud Continuum.</p></div><figure xml:id="fig_0"><head>Fig. 2 :</head><label>2</label><figDesc>Fig. 2: Exponential growth of new users every spring (peaks in May-June).</figDesc><graphic coords="3,340.85,50.54,193.32,123.28" type="bitmap" /></figure>
<figure xml:id="fig_1"><head>Fig. 4 :</head><label>4</label><figDesc>Fig. 4: Edge-to-Cloud Continuum optimization problems.</figDesc><graphic coords="4,311.98,175.15,251.05,163.15" type="bitmap" /></figure>
<figure xml:id="fig_2"><head>Fig. 5 :</head><label>5</label><figDesc>Fig. 5: Our proposed optimization methodology.</figDesc><graphic coords="5,48.96,50.54,251.04,174.14" type="bitmap" /></figure>
<figure xml:id="fig_3"><head /><label /><figDesc>may be applied; (b) then, from the generated sample, parallel experiments (deployment of application workflows) are run for each parameter set; (c) lastly, the surrogate model is trained on the dataset generated in the previous step. Model Retraining &amp; Application Optimization: once the surrogate model is trained on the sample points previously</figDesc></figure>
<figure xml:id="fig_4"><head>Fig. 6 :</head><label>6</label><figDesc>Fig. 6: Extended E2Clab experimental methodology.</figDesc><graphic coords="6,53.98,50.54,241.02,251.67" type="bitmap" /></figure>
<figure xml:id="fig_5"><head>Fig. 7 :</head><label>7</label><figDesc>Fig. 7: Extended E2Clab architecture.</figDesc><graphic coords="6,335.83,50.54,203.35,251.21" type="bitmap" /></figure>
<figure xml:id="fig_6"><head>23 " 33 # backup the optimization computations 34 self.finalize() 35 #</head><label>23333435</label><figDesc>provides state of the art search algorithms; manages model checkpoints and logging; and methods for analyzing training. User-defined optimization (i.e., how to setup an optimization?): the Optimization Manager offers a class-based API that allows researchers to setup and control the model training. Users have to inherit the Optimization class and define in the run() function (Listing 1 line 5) the optimization configuration through several state of the art single-objective and multi-objective Bayesian Optimization search algorithms (e.g., from libraries such as Scikit-Optimize [18], Dragonfly [39], 1 from e2clab.optimizer import Optimization 2 3 class UserDefinedOptimization(Optimization): http": tune.randint(20, 60), 24 "download": tune.randint(20, 60), 25 "simsearch": tune.randint(20, 60), 26 "extrac": tune.randint(3, 9)}) 27 28 def run_objective(self, _config): 29 # create an optimization directory 30 self.prepare() 31 # deploy the configs on the testbed 32 self.launch() report the metric value to Ray Tune</figDesc></figure>
<figure xml:id="fig_7"><head>Listing 1 :</head><label>1</label><figDesc>Example of a user-defined optimization in E2Clab.</figDesc></figure>
<figure xml:id="fig_8"><head>Fig. 8 :</head><label>8</label><figDesc>Fig. 8: User response time: baseline vs preliminary.</figDesc><graphic coords="8,61.52,50.54,225.95,106.38" type="bitmap" /></figure>
<figure xml:id="fig_9"><head /><label /><figDesc>(a) user response time. (b) processing time. (c) CPU usage. (d) GPU memory usage. (e) system memory usage.(f) extract pool busy time.(g) simsearch pool busy time.</figDesc></figure>
<figure xml:id="fig_10"><head>Fig. 9 :</head><label>9</label><figDesc>Fig. 9: Impact of extract thread variability.</figDesc><graphic coords="9,54.10,301.99,251.89,101.68" type="bitmap" /></figure>
<figure xml:id="fig_11"><head /><label /><figDesc>(a) user response time. (b) processing time. (c) simsearch pool busy time.(d) extract pool busy time.</figDesc></figure>
<figure xml:id="fig_12"><head>Fig. 10 :</head><label>10</label><figDesc>Fig. 10: Impact of similarity search thread variability.</figDesc><graphic coords="10,54.10,155.82,251.89,100.70" type="bitmap" /></figure>
<figure type="table" xml:id="tab_0"><head>TABLE I :</head><label>I</label><figDesc>Identification processing steps.</figDesc><table><row><cell>Task</cell><cell>Description</cell><cell>Thread pool</cell><cell>Hardware</cell></row><row><cell>pre-process</cell><cell>Decoding the query parame-ters.</cell><cell>HTTP</cell><cell>CPU</cell></row><row><cell>wait-download</cell><cell>Wait for an available download thread.</cell><cell>HTTP, Download</cell><cell>CPU</cell></row><row><cell>download</cell><cell>Download images.</cell><cell>Download</cell><cell>CPU</cell></row><row><cell>wait-extract</cell><cell>Wait for an available extractor thread.</cell><cell>HTTP, Extract</cell><cell>CPU, GPU</cell></row><row><cell>extract</cell><cell>DNN inference of the image.</cell><cell>Extract</cell><cell>GPU</cell></row><row><cell /><cell>Process classification and sim-</cell><cell /><cell /></row><row><cell>process</cell><cell>ilarity search output at query</cell><cell>HTTP</cell><cell>CPU</cell></row><row><cell /><cell>level.</cell><cell /><cell /></row><row><cell>wait-simsearch</cell><cell>Wait for an available similarity search thread.</cell><cell>HTTP, Simsearch</cell><cell>CPU</cell></row><row><cell>simsearch</cell><cell>Search the most similar images in our database.</cell><cell>Simsearch</cell><cell>CPU</cell></row><row><cell>post-process</cell><cell>Check processed query results and format the response.</cell><cell>HTTP</cell><cell>CPU</cell></row></table></figure>
<figure type="table" xml:id="tab_1"><head>TABLE II :</head><label>II</label><figDesc>Thread pool configuration of Pl@ntNet Engine.</figDesc><table><row><cell>Thread pool</cell><cell>Size (# threads)</cell><cell>Description</cell><cell>Hardware</cell></row><row><cell>HTTP</cell><cell>40</cell><cell># simultaneous requests being processed.</cell><cell>CPU</cell></row><row><cell>Download</cell><cell>40</cell><cell># simultaneous images being downloaded.</cell><cell>CPU</cell></row><row><cell>Extract</cell><cell>7</cell><cell># simultaneous inferences in a single GPU.</cell><cell>GPU</cell></row><row><cell>Simsearch</cell><cell>40</cell><cell># simultaneous similarity search.</cell><cell>CPU</cell></row></table></figure>
<figure type="table" xml:id="tab_2"><head>TABLE III :</head><label>III</label><figDesc>Baseline vs preliminary optimum configurations.</figDesc><table><row><cell>Thread pool</cell><cell>baseline</cell><cell>preliminary optimum</cell></row><row><cell>HTTP</cell><cell>40</cell><cell>54</cell></row><row><cell>Download</cell><cell>40</cell><cell>54</cell></row><row><cell>Extract</cell><cell>7</cell><cell>7</cell></row><row><cell>Simsearch</cell><cell>40</cell><cell>53</cell></row><row><cell cols="3">User response time 2.657 (±0.0914) 2.484 (±0.0912)</cell></row></table></figure>
<figure type="table" xml:id="tab_3"><head>TABLE IV :</head><label>IV</label><figDesc>Comparison of the three Pl@ntNet configurations.</figDesc><table><row><cell>Thread pool</cell><cell>baseline</cell><cell>preliminary optimum</cell><cell>refined optimum</cell></row><row><cell>HTTP</cell><cell>40</cell><cell>54</cell><cell>54</cell></row><row><cell>Download</cell><cell>40</cell><cell>54</cell><cell>54</cell></row><row><cell>Extract</cell><cell>7</cell><cell>7</cell><cell>6</cell></row><row><cell>Simsearch</cell><cell>40</cell><cell>53</cell><cell>53</cell></row><row><cell>User response</cell><cell>2.657</cell><cell>2.484</cell><cell>2.476</cell></row><row><cell>time</cell><cell>(±0.0914)</cell><cell>(±0.0912)</cell><cell>(±0.0826)</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>ACKNOWLEDGMENTS</head><p>This work was funded by <rs type="funder">Inria</rs> through the <rs type="funder">HPC-BigData Inria Challenge (IPL)</rs> and by <rs type="funder">French ANR OverFlow</rs> project (<rs type="grantNumber">ANR-15-CE25-0003</rs>). Experiments presented in this paper were carried out using the Grid'5000 testbed, supported by a scientific interest group hosted by <rs type="funder">Inria</rs> and including <rs type="funder">CNRS</rs>, RENATER and several Universities as well as other organizations. We also would like to thank <rs type="person">Romain Egele</rs>, <rs type="person">Jaehoon Koo</rs>, <rs type="person">Prasanna Balaprakash</rs>, and <rs type="person">Orcun Yildiz</rs> from <rs type="affiliation">Argonne National Laboratory</rs> for their support.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_PvTmqTM">
					<idno type="grant-number">ANR-15-CE25-0003</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<author>
			<persName><forename type="first">P</forename><surname>Beckman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Dongarra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Ferrier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Fox</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Moore</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Reed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Beck</surname></persName>
		</author>
		<title level="m">Harnessing the Computing Continuum for Programming Our World</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="215" to="230" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Adaptive computing optimization in softwaredefined network-based industrial internet of things with fog computing</title>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sensors</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page">2509</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Multi-objective optimization technique for resource allocation and task scheduling in vehicular cloud architecture: A hybrid adaptive nature inspired approach</title>
		<author>
			<persName><forename type="first">S</forename><surname>Midya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Roy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Majumder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Phadikar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Network and Computer Applications</title>
		<imprint>
			<biblScope unit="volume">103</biblScope>
			<biblScope unit="page" from="58" to="84" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Combining heuristics to optimize and scale the placement of iot applications in the fog</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Etchevers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Letondeur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Lebre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Coupaye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Desprez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE/ACM 11th International Conference on Utility and Cloud Computing (UCC)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2018">2018. 2018</date>
			<biblScope unit="page" from="153" to="163" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">The next grand challenges: Integrating the internet of things and data science</title>
		<author>
			<persName><forename type="first">R</forename><surname>Ranjan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Rana</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Nepal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Yousif</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>James</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Barr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Watson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">P</forename><surname>Jayaraman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Georgakopoulos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Cloud Computing</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="12" to="26" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Classification of optimization problems in fog computing</title>
		<author>
			<persName><forename type="first">J</forename><surname>Bellendorf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">Á</forename><surname>Mann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Future Generation Computer Systems</title>
		<imprint>
			<biblScope unit="volume">107</biblScope>
			<biblScope unit="page" from="158" to="176" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A survey on industrial internet of things: A cyber-physical systems perspective</title>
		<author>
			<persName><forename type="first">H</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Griffith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Golmie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="78" to="238" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A look inside the pl@ntnet experience</title>
		<author>
			<persName><forename type="first">A</forename><surname>Joly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Bonnet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Goëau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Barbe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Selmi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Champ</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Dufour-Kowalski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Affouard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Carré</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-F</forename><surname>Molino</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Multimedia Systems</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="751" to="766" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Cloudsim: a toolkit for modeling and simulation of cloud computing environments and evaluation of resource provisioning algorithms</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">N</forename><surname>Calheiros</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ranjan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Beloglazov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A</forename><surname>De Rose</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Buyya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Software: Practice and experience</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="23" to="50" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">ifogsim: A toolkit for modeling and simulation of resource management techniques in the internet of things, edge and fog computing environments</title>
		<author>
			<persName><forename type="first">H</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Vahid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">K</forename><surname>Dastjerdi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ghosh</surname></persName>
		</author>
		<author>
			<persName><surname>Buyya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Software: Practice and Experience</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1275" to="1296" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Edgecloudsim: An environment for performance evaluation of edge computing systems</title>
		<author>
			<persName><forename type="first">C</forename><surname>Sonmez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ozgovde</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Ersoy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions on Emerging Telecommunications Technologies</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page">3493</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Emufog: Extensible and scalable emulation of large-scale fog computing infrastructures</title>
		<author>
			<persName><forename type="first">R</forename><surname>Mayer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Graser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Saurez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Ramachandran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 IEEE Fog World Congress (FWC)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Intelligent optimisation techniques: genetic algorithms, tabu search, simulated annealing and neural networks</title>
		<author>
			<persName><forename type="first">D</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Karaboga</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012">2012</date>
			<publisher>Springer Science &amp; Business Media</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">E2clab: Exploring the computing continuum through repeatable, replicable and reproducible edge-to-cloud experiments</title>
		<author>
			<persName><forename type="first">D</forename><surname>Rosendo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Silva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Simonin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Costan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Antoniu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2020 IEEE International Conference on Cluster Computing (CLUSTER)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="176" to="186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Grid'5000: a large scale and highly reconfigurable experimental grid testbed</title>
		<author>
			<persName><forename type="first">R</forename><surname>Bolze</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Cappello</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Caron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Daydé</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Desprez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Jeannot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Jégou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lanteri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Leduc</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Melab</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The International Journal of High Performance Computing Applications</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="481" to="494" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<author>
			<persName><surname>Appdynamics</surname></persName>
		</author>
		<ptr target="https://www.appdynamics.com/media/uploaded-files/1432066155/white-paper-16-metrics-every-mobile-team-should-monitor.pdf" />
		<title level="m">16 metrics to ensure mobile app success</title>
		<imprint>
			<date type="published" when="2015-01">2015, jan</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Performance evaluation metrics for cloud, fog and edge computing: A review, taxonomy, benchmarks and standards for future research</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Aslanpour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Gill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">N</forename><surname>Toosi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Internet of Things</title>
		<imprint>
			<biblScope unit="page">100273</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<ptr target="https://scikit-optimize.github.io/stable/" />
		<title level="m">Sequential model-based optimization</title>
		<imprint>
			<publisher>Scikit-Optimize</publisher>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Scikit-learn: Machine learning in python</title>
		<author>
			<persName><forename type="first">F</forename><surname>Pedregosa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Varoquaux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gramfort</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Michel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Thirion</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Grisel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Blondel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Prettenhofer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Dubourg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">the Journal of machine Learning research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2825" to="2830" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">A python surrogate modeling framework with derivatives</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Bouhlel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">T</forename><surname>Hwang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Bartoli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Lafage</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Morlier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R R A</forename><surname>Martins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Engineering Software</title>
		<imprint>
			<biblScope unit="page">102662</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Deephyper: Asynchronous hyperparameter search for deep neural networks</title>
		<author>
			<persName><forename type="first">P</forename><surname>Balaprakash</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Salim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">D</forename><surname>Uram</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Vishwanath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Wild</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2018 IEEE 25th international conference on high performance computing (HiPC)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="42" to="51" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">E2clab source code</title>
		<ptr target="https://gitlab.inria.fr/E2Clab/e2clab" />
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Practical bayesian optimization of machine learning algorithms</title>
		<author>
			<persName><forename type="first">J</forename><surname>Snoek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">P</forename><surname>Adams</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1206.2944</idno>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Kriging models for global approximation in simulation-based multidisciplinary design optimization</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">W</forename><surname>Simpson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">M</forename><surname>Mauery</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Korte</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Mistree</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AIAA journal</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2233" to="2241" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">On the optimization of fuzzy decision trees</title>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Ye</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Fuzzy Sets and Systems</title>
		<imprint>
			<biblScope unit="volume">112</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="117" to="125" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Random forests</title>
		<author>
			<persName><forename type="first">L</forename><surname>Breiman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine learning</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="5" to="32" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Greedy function approximation: a gradient boosting machine</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Friedman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annals of statistics</title>
		<imprint>
			<biblScope unit="page" from="1189" to="1232" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Support vector machines</title>
		<author>
			<persName><forename type="first">I</forename><surname>Steinwart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Christmann</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008">2008</date>
			<publisher>Springer Science &amp; Business Media</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Modelling using polynomial regression</title>
		<author>
			<persName><forename type="first">E</forename><surname>Ostertagová</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Procedia Engineering</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="page" from="500" to="506" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Latin hypercube sampling and the propagation of uncertainty in analyses of complex systems</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Helton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">J</forename><surname>Davis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Reliability Engineering &amp; System Safety</title>
		<imprint>
			<biblScope unit="volume">81</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="23" to="69" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Computational investigations of lowdiscrepancy sequences</title>
		<author>
			<persName><forename type="first">L</forename><surname>Kocis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">J</forename><surname>Whiten</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Mathematical Software (TOMS)</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="266" to="294" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Genetic algorithm</title>
		<author>
			<persName><forename type="first">S</forename><surname>Mirjalili</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Evolutionary algorithms and neural networks</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="43" to="55" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Recent advances in differential evolution-an updated survey</title>
		<author>
			<persName><forename type="first">S</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Mullick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">N</forename><surname>Suganthan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Swarm and Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="1" to="30" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Simulated annealing</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Van Laarhoven</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">H</forename><surname>Aarts</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Simulated annealing: Theory and applications</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1987">1987</date>
			<biblScope unit="page" from="7" to="15" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Particle swarm optimization</title>
		<author>
			<persName><forename type="first">K.-L</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Swamy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Search and optimization by metaheuristics</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="153" to="173" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<ptr target="https://kerdata.gitlabpages.inria.fr/Kerdata-Codes/e2clab/" />
		<title level="m">Welcome to e2clab's documentation!</title>
		<imprint>
			<date type="published" when="2020-02">2020, feb</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<author>
			<persName><surname>Ray</surname></persName>
		</author>
		<ptr target="https://docs.ray.io/en/latest/index.html" />
		<title level="m">What is ray</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Tune: A research platform for distributed model selection and training</title>
		<author>
			<persName><forename type="first">R</forename><surname>Liaw</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Nishihara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Moritz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Gonzalez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Stoica</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1807.05118</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Tuning hyperparameters without grad students: Scalable and robust bayesian optimisation with dragonfly</title>
		<author>
			<persName><forename type="first">K</forename><surname>Kandasamy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">R</forename><surname>Vysyaraju</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Neiswanger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Paria</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">R</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schneider</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Poczos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">P</forename><surname>Xing</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1903.06694</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">BoTorch: A Framework for Efficient Monte-Carlo Bayesian Optimization</title>
		<author>
			<persName><forename type="first">M</forename><surname>Balandat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Karrer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">R</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Daulton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Letham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">G</forename><surname>Wilson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Bakshy</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/1910.06403" />
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">33</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Hebo: Heteroscedastic evolutionary bayesian optimisation</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">I</forename><surname>Cowen-Rivers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Lyu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Tutunov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Jianye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">B</forename><surname>Ammar</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2012.03826</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>winning submission to the NeurIPS 2020 Black Box Optimisation Challenge</note>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">A tutorial on bayesian optimization</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">I</forename><surname>Frazier</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1807.02811</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">A comparison of sensitivity analysis techniques</title>
		<author>
			<persName><forename type="first">D</forename><surname>Hamby</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Health physics</title>
		<imprint>
			<biblScope unit="volume">68</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="195" to="204" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Open science: one term, five schools of thought</title>
		<author>
			<persName><forename type="first">B</forename><surname>Fecher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Friesike</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Opening science</title>
		<imprint>
			<biblScope unit="page" from="17" to="47" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<ptr target="https://gitlab.inria.fr/E2Clab/Paper-Artifacts/plantnet" />
		<title level="m">E2clab experimental artifacts</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">An architecture and stochastic method for database container placement in the edge-fog-cloud continuum</title>
		<author>
			<persName><forename type="first">P</forename><surname>Kochovski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Sakellariou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bajec</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Drobintsev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Stankovski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2019 IEEE International Parallel and Distributed Processing Symposium (IPDPS)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="396" to="405" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Containers and cloud: From lxc to docker to kubernetes</title>
		<author>
			<persName><forename type="first">D</forename><surname>Bernstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Cloud Computing</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="81" to="84" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">A unified model for the mobile-edge-cloud continuum</title>
		<author>
			<persName><forename type="first">L</forename><surname>Baresi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">F</forename><surname>Mendonc ¸a</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Garriga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Guinea</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Quattrocchi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Internet Technology (TOIT)</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1" to="21" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</teiCorpus></text>
</TEI>