<?xml version='1.0' encoding='utf-8'?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" version="1.1" xsi:schemaLocation="http://www.tei-c.org/ns/1.0 http://api.archives-ouvertes.fr/documents/aofr-sword.xsd">
  <teiHeader>
    <fileDesc>
      <titleStmt>
        <title>HAL TEI export of lirmm-02266483</title>
      </titleStmt>
      <publicationStmt>
        <distributor>CCSD</distributor>
        <availability status="restricted">
          <licence target="http://creativecommons.org/licenses/by/4.0/">Distributed under a Creative Commons Attribution 4.0 International License</licence>
        </availability>
        <date when="2024-04-29T11:48:46+02:00" />
      </publicationStmt>
      <sourceDesc>
        <p part="N">HAL API platform</p>
      </sourceDesc>
    </fileDesc>
  </teiHeader>
  <text>
    <body>
      <listBibl>
        <biblFull>
          <titleStmt>
            <title xml:lang="en">SAVIME: A Database Management System for Simulation Data Analysis and Visualization</title>
            <author role="aut">
              <persName>
                <forename type="first">Hermano</forename>
                <surname>Lustosa</surname>
              </persName>
              <email type="md5">5591c50d7b64859fb5cc12bb28d505af</email>
              <email type="domain">lncc.br</email>
              <idno type="idhal" notation="numeric">968842</idno>
              <idno type="halauthorid" notation="string">930585-968842</idno>
              <affiliation ref="#struct-4626" />
            </author>
            <author role="aut">
              <persName>
                <forename type="first">Fabio</forename>
                <surname>Porto</surname>
              </persName>
              <email type="md5">d48ac90feaf7aadd7911e48f9e1f0abc</email>
              <email type="domain">lncc.br</email>
              <idno type="idhal" notation="numeric">932292</idno>
              <idno type="halauthorid" notation="string">433850-932292</idno>
              <orgName ref="#struct-4626" />
              <affiliation ref="#struct-4626" />
            </author>
            <author role="aut">
              <persName>
                <forename type="first">Patrick</forename>
                <surname>Valduriez</surname>
              </persName>
              <email type="md5">b7903099e0d3ee0b492cd1c7a982e35b</email>
              <email type="domain">inria.fr</email>
              <idno type="idhal" notation="string">patrick-valduriez</idno>
              <idno type="idhal" notation="numeric">172604</idno>
              <idno type="halauthorid" notation="string">22529-172604</idno>
              <idno type="ORCID">https://orcid.org/0000-0001-6506-7538</idno>
              <idno type="GOOGLE SCHOLAR">https://scholar.google.fr/citations?user=Vj0m2A0AAAAJ&amp;hl=fr</idno>
              <idno type="IDREF">https://www.idref.fr/028314417</idno>
              <orgName ref="#struct-300009" />
              <affiliation ref="#struct-141072" />
            </author>
            <editor role="depositor">
              <persName>
                <forename>Patrick</forename>
                <surname>Valduriez</surname>
              </persName>
              <email type="md5">b7903099e0d3ee0b492cd1c7a982e35b</email>
              <email type="domain">inria.fr</email>
            </editor>
          </titleStmt>
          <editionStmt>
            <edition n="v1" type="current">
              <date type="whenSubmitted">2019-11-08 14:38:49</date>
              <date type="whenWritten">2019</date>
              <date type="whenModified">2024-02-15 03:31:35</date>
              <date type="whenReleased">2019-11-08 14:45:28</date>
              <date type="whenProduced">2019-10-07</date>
              <date type="whenEndEmbargoed">2019-11-08</date>
              <ref type="file" target="https://hal-lirmm.ccsd.cnrs.fr/lirmm-02266483/document">
                <date notBefore="2019-11-08" />
              </ref>
              <ref type="file" subtype="author" n="1" target="https://hal-lirmm.ccsd.cnrs.fr/lirmm-02266483/file/sbbd19.pdf">
                <date notBefore="2019-11-08" />
              </ref>
              <ref type="externalLink" target="https://sol.sbc.org.br/index.php/sbbd/article/download/8810/8711" />
            </edition>
            <respStmt>
              <resp>contributor</resp>
              <name key="150418">
                <persName>
                  <forename>Patrick</forename>
                  <surname>Valduriez</surname>
                </persName>
                <email type="md5">b7903099e0d3ee0b492cd1c7a982e35b</email>
                <email type="domain">inria.fr</email>
              </name>
            </respStmt>
          </editionStmt>
          <publicationStmt>
            <distributor>CCSD</distributor>
            <idno type="halId">lirmm-02266483</idno>
            <idno type="halUri">https://hal-lirmm.ccsd.cnrs.fr/lirmm-02266483</idno>
            <idno type="halBibtex">lustosa:lirmm-02266483</idno>
            <idno type="halRefHtml">&lt;i&gt;SBBD 2019 - 34ª edição do Simpósio Brasileiro de Banco de Dados&lt;/i&gt;, SBC, Oct 2019, Fortaleza, Brazil. pp.1-12, &lt;a target="_blank" href="https://dx.doi.org/10.5753/sbbd.2019.8810"&gt;&amp;#x27E8;10.5753/sbbd.2019.8810&amp;#x27E9;&lt;/a&gt;</idno>
            <idno type="halRef">SBBD 2019 - 34ª edição do Simpósio Brasileiro de Banco de Dados, SBC, Oct 2019, Fortaleza, Brazil. pp.1-12, &amp;#x27E8;10.5753/sbbd.2019.8810&amp;#x27E9;</idno>
          </publicationStmt>
          <seriesStmt>
            <idno type="stamp" n="UNIV-RENNES1">Université de Rennes 1</idno>
            <idno type="stamp" n="CNRS">CNRS - Centre national de la recherche scientifique</idno>
            <idno type="stamp" n="INRIA">INRIA - Institut National de Recherche en Informatique et en Automatique</idno>
            <idno type="stamp" n="INRIA-SOPHIA">INRIA Sophia Antipolis - Méditerranée</idno>
            <idno type="stamp" n="IRISA">Irisa</idno>
            <idno type="stamp" n="INRIASO">INRIA-SOPHIA</idno>
            <idno type="stamp" n="INRIA_TEST">INRIA - Institut National de Recherche en Informatique et en Automatique</idno>
            <idno type="stamp" n="INRIA34">Montpellier</idno>
            <idno type="stamp" n="TESTALAIN1">TESTALAIN1</idno>
            <idno type="stamp" n="ZENITH" corresp="LIRMM">Scientific Data Management</idno>
            <idno type="stamp" n="LIRMM">Laboratoire d'Informatique de Robotique et de Microélectronique de Montpellier</idno>
            <idno type="stamp" n="INRIA2">INRIA 2</idno>
            <idno type="stamp" n="UR1-HAL">Publications labos UR1 dans HAL-Rennes 1</idno>
            <idno type="stamp" n="UR1-MATH-STIC">UR1 - publications Maths-STIC</idno>
            <idno type="stamp" n="UR1-UFR-ISTIC">UFR ISTIC Informatique et électronique</idno>
            <idno type="stamp" n="MIPS">Mathématiques, Informatique, Physique et Systèmes</idno>
            <idno type="stamp" n="UNIV-MONTPELLIER">Université de Montpellier</idno>
            <idno type="stamp" n="TEST-UR-CSS">TEST Université de Rennes CSS</idno>
            <idno type="stamp" n="UNIV-RENNES">Université de Rennes</idno>
            <idno type="stamp" n="INRIA-300009">Inria 300009</idno>
            <idno type="stamp" n="UR1-MATH-NUM">Pôle UnivRennes - Mathématiques - Numérique </idno>
            <idno type="stamp" n="UM-2015-2021" corresp="UNIV-MONTPELLIER">Université de Montpellier (2015-2021)</idno>
          </seriesStmt>
          <notesStmt>
            <note type="audience" n="2">International</note>
            <note type="invited" n="0">No</note>
            <note type="popular" n="0">No</note>
            <note type="peer" n="1">Yes</note>
            <note type="proceedings" n="1">Yes</note>
          </notesStmt>
          <sourceDesc>
            <biblStruct>
              <analytic>
                <title xml:lang="en">SAVIME: A Database Management System for Simulation Data Analysis and Visualization</title>
                <author role="aut">
                  <persName>
                    <forename type="first">Hermano</forename>
                    <surname>Lustosa</surname>
                  </persName>
                  <email type="md5">5591c50d7b64859fb5cc12bb28d505af</email>
                  <email type="domain">lncc.br</email>
                  <idno type="idhal" notation="numeric">968842</idno>
                  <idno type="halauthorid" notation="string">930585-968842</idno>
                  <affiliation ref="#struct-4626" />
                </author>
                <author role="aut">
                  <persName>
                    <forename type="first">Fabio</forename>
                    <surname>Porto</surname>
                  </persName>
                  <email type="md5">d48ac90feaf7aadd7911e48f9e1f0abc</email>
                  <email type="domain">lncc.br</email>
                  <idno type="idhal" notation="numeric">932292</idno>
                  <idno type="halauthorid" notation="string">433850-932292</idno>
                  <orgName ref="#struct-4626" />
                  <affiliation ref="#struct-4626" />
                </author>
                <author role="aut">
                  <persName>
                    <forename type="first">Patrick</forename>
                    <surname>Valduriez</surname>
                  </persName>
                  <email type="md5">b7903099e0d3ee0b492cd1c7a982e35b</email>
                  <email type="domain">inria.fr</email>
                  <idno type="idhal" notation="string">patrick-valduriez</idno>
                  <idno type="idhal" notation="numeric">172604</idno>
                  <idno type="halauthorid" notation="string">22529-172604</idno>
                  <idno type="ORCID">https://orcid.org/0000-0001-6506-7538</idno>
                  <idno type="GOOGLE SCHOLAR">https://scholar.google.fr/citations?user=Vj0m2A0AAAAJ&amp;hl=fr</idno>
                  <idno type="IDREF">https://www.idref.fr/028314417</idno>
                  <orgName ref="#struct-300009" />
                  <affiliation ref="#struct-141072" />
                </author>
              </analytic>
              <monogr>
                <title level="m">34th Brazilian Symposium on Databases</title>
                <meeting>
                  <title>SBBD 2019 - 34ª edição do Simpósio Brasileiro de Banco de Dados</title>
                  <date type="start">2019-10-07</date>
                  <date type="end">2019-10-10</date>
                  <settlement>Fortaleza</settlement>
                  <country key="BR">Brazil</country>
                </meeting>
                <respStmt>
                  <resp>conferenceOrganizer</resp>
                  <name>SBC</name>
                </respStmt>
                <imprint>
                  <biblScope unit="pp">1-12</biblScope>
                  <date type="datePub">2019-10</date>
                </imprint>
              </monogr>
              <idno type="doi">10.5753/sbbd.2019.8810</idno>
              <ref type="publisher">sbbd.org.br/2019</ref>
            </biblStruct>
          </sourceDesc>
          <profileDesc>
            <langUsage>
              <language ident="en">English</language>
            </langUsage>
            <textClass>
              <keywords scheme="author">
                <term xml:lang="en">Scientific data</term>
                <term xml:lang="en">SAVIME</term>
                <term xml:lang="en">SciDB</term>
                <term xml:lang="en">array DBMS</term>
              </keywords>
              <classCode scheme="halDomain" n="info.info-db">Computer Science [cs]/Databases [cs.DB]</classCode>
              <classCode scheme="halTypology" n="COMM">Conference papers</classCode>
              <classCode scheme="halOldTypology" n="COMM">Conference papers</classCode>
              <classCode scheme="halTreeTypology" n="COMM">Conference papers</classCode>
            </textClass>
            <abstract xml:lang="en">
              <p>Limitations in current DBMSs prevent their wide adoption in scientific applications. In order to make scientific applications benefit from DBMS support, enabling declarative data analysis and visualization over scientific data, we present an in-memory array DBMS system called SAVIME. In this work we describe the system SAVIME, along with its data model. Our preliminary evaluation show how SAVIME, by using a simple storage definition language (SDL) can outperform the state-of-the-art array database system, SciDB, during the process of data ingestion. We also show that is possible to use SAVIME as a storage alternative for a numerical solver without affecting its scalability.</p>
            </abstract>
            <particDesc>
              <org type="consortium">SciDISC Inria associated team with Brazil</org>
            </particDesc>
          </profileDesc>
        </biblFull>
      </listBibl>
    </body>
    <back>
      <listOrg type="structures">
        <org type="institution" xml:id="struct-4626" status="VALID">
          <idno type="ROR">https://ror.org/0498ekt05</idno>
          <orgName>Laboratorio Nacional de Computação Cientifica [Rio de Janeiro]</orgName>
          <orgName type="acronym">LNCC / MCT</orgName>
          <desc>
            <address>
              <addrLine>LNCC, Av. Getulio Vargas, 333, Quitandinha, 25651-075, Petropolis, RJ</addrLine>
              <country key="BR" />
            </address>
            <ref type="url">http://www.lncc.br</ref>
          </desc>
        </org>
        <org type="researchteam" xml:id="struct-141072" status="OLD">
          <idno type="RNSR">201121208J</idno>
          <orgName>Scientific Data Management</orgName>
          <orgName type="acronym">ZENITH</orgName>
          <date type="end">2021-12-31</date>
          <desc>
            <address>
              <addrLine>LIRMM, 161 rue Ada, 34000 Montpellier</addrLine>
              <country key="FR" />
            </address>
            <ref type="url">https://team.inria.fr/zenith/</ref>
          </desc>
          <listRelation>
            <relation active="#struct-181" type="direct" />
            <relation name="UMR5506" active="#struct-410122" type="indirect" />
            <relation name="UMR5506" active="#struct-441569" type="indirect" />
            <relation active="#struct-34586" type="direct" />
            <relation active="#struct-300009" type="indirect" />
          </listRelation>
        </org>
        <org type="laboratory" xml:id="struct-181" status="OLD">
          <idno type="IdRef">139590827</idno>
          <idno type="ISNI">0000000405990488</idno>
          <idno type="RNSR">199111950H</idno>
          <idno type="ROR">https://ror.org/013yean28</idno>
          <orgName>Laboratoire d'Informatique de Robotique et de Microélectronique de Montpellier</orgName>
          <orgName type="acronym">LIRMM</orgName>
          <date type="start">1995-01-01</date>
          <date type="end">2021-12-31</date>
          <desc>
            <address>
              <addrLine>161 rue Ada - 34095 Montpellier</addrLine>
              <country key="FR" />
            </address>
            <ref type="url">https://www.lirmm.fr</ref>
          </desc>
          <listRelation>
            <relation name="UMR5506" active="#struct-410122" type="direct" />
            <relation name="UMR5506" active="#struct-441569" type="direct" />
          </listRelation>
        </org>
        <org type="institution" xml:id="struct-410122" status="OLD">
          <idno type="ISNI">0000000120970141</idno>
          <idno type="ROR">https://ror.org/051escj72</idno>
          <orgName>Université de Montpellier</orgName>
          <orgName type="acronym">UM</orgName>
          <date type="end">2021-12-31</date>
          <desc>
            <address>
              <addrLine>163 rue Auguste Broussonnet - 34090 Montpellier</addrLine>
              <country key="FR" />
            </address>
            <ref type="url">http://www.umontpellier.fr/</ref>
          </desc>
        </org>
        <org type="regroupinstitution" xml:id="struct-441569" status="VALID">
          <idno type="IdRef">02636817X</idno>
          <idno type="ISNI">0000000122597504</idno>
          <idno type="ROR">https://ror.org/02feahw73</idno>
          <orgName>Centre National de la Recherche Scientifique</orgName>
          <orgName type="acronym">CNRS</orgName>
          <date type="start">1939-10-19</date>
          <desc>
            <address>
              <country key="FR" />
            </address>
            <ref type="url">https://www.cnrs.fr/</ref>
          </desc>
        </org>
        <org type="laboratory" xml:id="struct-34586" status="VALID">
          <idno type="RNSR">198318250R</idno>
          <idno type="ROR">https://ror.org/01nzkaw91</idno>
          <orgName>Inria Sophia Antipolis - Méditerranée</orgName>
          <orgName type="acronym">CRISAM</orgName>
          <desc>
            <address>
              <addrLine>2004 route des Lucioles BP 93 06902 Sophia Antipolis</addrLine>
              <country key="FR" />
            </address>
            <ref type="url">http://www.inria.fr/centre/sophia/</ref>
          </desc>
          <listRelation>
            <relation active="#struct-300009" type="direct" />
          </listRelation>
        </org>
        <org type="institution" xml:id="struct-300009" status="VALID">
          <idno type="ROR">https://ror.org/02kvxyf05</idno>
          <orgName>Institut National de Recherche en Informatique et en Automatique</orgName>
          <orgName type="acronym">Inria</orgName>
          <desc>
            <address>
              <addrLine>Domaine de VoluceauRocquencourt - BP 10578153 Le Chesnay Cedex</addrLine>
              <country key="FR" />
            </address>
            <ref type="url">http://www.inria.fr/en/</ref>
          </desc>
        </org>
      </listOrg>
    </back>
  <teiCorpus>
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">SAVIME: A Database Management System for Simulation Data Analysis and Visualization</title>
			</titleStmt>
			<publicationStmt>
				<publisher />
				<availability status="unknown"><licence /></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Hermano</forename><surname>Lustosa</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">National Laboratory for Scientific Computing (LNCC)</orgName>
								<address>
									<settlement>Petrópolis</settlement>
									<country key="BR">Brazil</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Fabio</forename><surname>Porto</surname></persName>
							<email>fporto@lncc.br</email>
							<affiliation key="aff0">
								<orgName type="laboratory">National Laboratory for Scientific Computing (LNCC)</orgName>
								<address>
									<settlement>Petrópolis</settlement>
									<country key="BR">Brazil</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Patrick</forename><surname>Valduriez</surname></persName>
							<email>patrick.valduriez@inria.fr</email>
							<affiliation key="aff1">
								<orgName type="institution" key="instit1">Inria</orgName>
								<orgName type="institution" key="instit2">LIRMM Montpellier</orgName>
								<address>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">SAVIME: A Database Management System for Simulation Data Analysis and Visualization</title>
					</analytic>
					<monogr>
						<imprint>
							<date />
						</imprint>
					</monogr>
					<idno type="MD5">CBAF9D8CD965FF3153FE2A2BCE39DF1D</idno>
					<idno type="DOI">10.5753/sbbd.2019.8810</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-04-12T14:48+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid" />
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div><p>Limitations in current DBMSs prevent their wide adoption in scientific applications. In order to make scientific applications benefit from DBMS support, enabling declarative data analysis and visualization over scientific data, we present an in-memory array DBMS system called <software>SAVIME</software>. In this work we describe the system <software ContextAttributes="created">SAVIME</software>, along with its data model. Our preliminary evaluation show how <software ContextAttributes="created">SAVIME</software>, by using a simple storage definition language (SDL) can outperform the state-of-the-art array database system, <software ContextAttributes="created">SciDB</software>, during the process of data ingestion. We also show that is possible to use <software ContextAttributes="created">SAVIME</software> as a storage alternative for a numerical solver without affecting its scalability.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div><head n="1.">Introduction</head><p>The increasing computational power of HPC machines allows for performing complex numerical simulations. These simulations produce huge datasets, which are analyzed and visualized to enable researchers to gain insights about the phenomena being studied. Traditionally, simulation code stores its raw data in the file system, and another <software ContextAttributes="created">application</software> reads it from disk, performs analysis and creates the visualization files. However, due to the I/O gap in HPC environments, doing so can be very inefficient for large scale simulations <ref type="bibr" target="#b0">[Ahrens 2015</ref>]. Two popular approaches, in-situ and in-transit analysis <ref type="bibr" target="#b12">[Oldfield et al. 2014]</ref>, have been proposed to address this problem by favoring intense memory usage instead of relying on disk storage.</p><p>DBMSs are not commonly adopted in any of these approaches. In-situ and intransist analysis relies on libraries, and the post-processing approach consists of storing data in scientific data formats such as HDF <ref type="bibr" target="#b8">[Group 2017</ref>] and <software ContextAttributes="created">NetCDF</software>[Unidata 2017]. DBMSs are considered inadequate for scientific data management due to many factors. The first one is the impedance mismatch problem <ref type="bibr" target="#b3">[Blanas et al. 2014</ref><ref type="bibr" target="#b7">, Gosink et al. 2006</ref>], i.e., the incompatibilities between the representation formats of the source data and the DBMS. This impedance mismatch yields costly conversions between formats, which adds prohibitive overhead during data ingestion. Also, data usage patterns for scientific applications are very different from those common in commercial applications. The workload is mainly analytical and not necessarily all data needs to be persisted. It is common that data is analyzed and summarized, having its volume being drastically reduced by either storing only the summarized version or by simply discarding parts which are not interesting. Some other key points also do not favor DBMS usage. Data is heterogeneous, comprising different formats and sources, making it hard to use a single database solution for all data. The analysis is also complex and, in many cases, cannot be easily done with a declarative language like <software ContextAttributes="created">SQL</software>.</p><p>However, for the vast variety of queries that can be expressed in a declarative language, a DBMS solution could offer a convenient and efficient way to perform analysis, given that the underlying data model is flexible enough to accomodate such data, and that the process of data ingestion is seamless, not incuring in costly data conversions.</p><p>Therefore, given the current lack of a database solution that could facilitate the simulation data analysis and visualization, we propose an array based data model <ref type="bibr" target="#b9">[Lustosa et al. 2017]</ref> named TARS, to cope with simulation data and to allow a more efficient representation, along with a prototype system that implements this model, currently named <software ContextAttributes="created">SAVIME</software>. <software ContextAttributes="created">SAVIME</software> supports a DDL and a SDL that enable fast data ingestion, and a DML that allows for declarative analysis and visualization of simulation data.</p><p>In this paper, we present <software>SAVIME</software> and the TARS data model, along with an evaluation in which we compare <software ContextAttributes="created">SAVIME</software> with <software ContextAttributes="created">SciDB</software>, the state-of-the-art array DBMS. This document is organized as follows. In Section 2 we discuss the TARS data model implemented in <software ContextAttributes="created">SAVIME</software>. In Section 3 we present <software ContextAttributes="created">SAVIME</software>, its execution model and its DDL, SDL and DML. In Section 4 we show the results of our evaluation comparing <software ContextAttributes="created">SAVIME</software> and <software ContextAttributes="created">SciDB</software> and embedding <software ContextAttributes="created">SAVIME</software> with a real life <software ContextAttributes="created">application</software>. In section 5, we discuss the related work and finally in Section 6 we conclude.</p></div>
<div><head n="2.">Typed Array Data Model</head><p>If carefully designed, arrays offer advantages when compared to tables. Cells in an array are ordered, unlike tuples in a relation. Thus, an array DBMS can quickly lookup cells by taking advantage of this ordering. Using arrays instead of tables can also save storage space, since array indexes do not need to be stored and can be inferred by the position of the cell. Furthermore, arrays can be split into subarrays, called tiles or chunks. These subarrays are used as processing and storage units, and help answering queries efficiently. Thus, if your data is array-ike, using an array database is the way to go.</p><p>However, current array data model implementations, e.g., <software>SciDB</software> and <software ContextAttributes="created">RasDaMan</software>, have limitations, preventing a more wide acceptance in scientific applications. In <software ContextAttributes="created">SciDB</software> [Paradigm4 2017] for instance, due to some representation constraints, it might be necessary to preload multidimensional data into an unidimensional array and then rearrange it during data loading. <software ContextAttributes="created">RasDaMan</software> requires either the creation of a <software ContextAttributes="created">script</software> or the generation of compatible file formats for data ingestion. The result is an inefficient loading process in both cases.</p><p>Scientists do not necessarily want to persist all data for a long period of time, instead they want to analyze huge dataset as switfly as possible. Therefore, adopting a DBMS which imposes high overhead for data ingestion does not make sense, even an array DBMS that offers a data representation adequate for scientific data, because the possible convenience of using a declarative query language does not compensate the trouble to ingest data into the system. In this section we present a briefly overview of the TARS model as presented in <ref type="bibr" target="#b9">[Lustosa et al. 2017</ref>].</p></div>
<div><head n="2.1.">Model Overview</head><p>Given the lack of flexibility in current array DBMSs, we propose the TARS data model to cope with the aforementioned issues. A TAR Schema (TARS) contains a set of Typed ARrays (TARs). A TAR has a set of dimensions and attributes. A TAR cell is a tuple of attributes accessed via a set of indexes. These indexes define the cell location within the TAR. A TAR has a type, formed by a set of roles. A role in a type defines a special purpose data element with specific semantics.</p><p>In TARS (Figure <ref type="figure">1</ref>), we define mapping functions as a way to provide support for sparse arrays, non-integer dimensions and heterogeneous memory layouts. With TARS, it is possible to combine array data from different sources, different storage layouts, and even with different deegres of sparsity by associating different mapping functions to different subarrays, or as we call them, subTARs.</p></div>
<div><head>Figure 1. Typed Array Schema Elements</head><p>A subTAR covers a n-dimensional slice of a TAR. Every subTAR is defined by the TAR region it represents and two mapping functions: position mapping function and data mapping function. The position mapping function reflects the actual data layout, since it defines where every TAR cell within a given subTAR ended in linear storage. Therefore, the position mapping function should implement the multidimensional linearization technique used for the data. The data mapping functions translate a linear address into data values. In a simple scenario, this function does basically a lookup into a linear array that stores the data. In a more complex scenario, it could compute a derived value from the actual subTAR data.</p></div>
<div><head n="2.2.">Physical Specification</head><p>In this section, we describe how the TARS data model is implemented in <software>SAVIME</software>. TARS structures are created in <software ContextAttributes="created">SAVIME</software> with the use of the supported SDL and DDL. Users can define TARs, datasets, and types. Once a TAR is defined and a series of datasets are loaded into the system, it is possible to specify a subTAR by attaching datasets to it. A dataset is a collection of data values of the same type, like a column in a column-store DBMS (<software ContextAttributes="created">SAVIME</software> uses vertical partitioning). A dataset can contain data for a TAR attribute within a TAR region specified by a subTAR.</p><p>TAR dimensions indexes form a domain of values that are represented in <software>SAVIME</software> in two main forms. It can be an implicitly defined range of equally spaced values, in which case, all the user must specify is the lower and upper bounds, and the spacing between two adjacent values. It is called implicit because these indexes do not need to be explicitly stored. For instance, the domain D i = (0.0, , 2.0 , 4.0 , 6.0 , 8.0 , 10.0) is defined by the lower bound 0.0, the upper bound 10.0 and all values are equally spaced in 2.0 units. Dimensions whose indexes do not conform with these constraints have an explicit definition. In this case, the user provides a dataset specifying the dimension indexes. For instance, consider the following domain D e = (1.2, , 2.3 , 4.7 , 7.9 , 13.2). It has a series of values that are not well-behaved and equally spaced, and thus, can not be represented implicitly.</p><p>The data representation within the subTAR requires the combination between the dimension domain and the dimension specifications. All subTARs in a TAR have a list of dimension specifications, one for each dimension in the TAR. These dimension specifications define the TAR region the subTAR encompasses, but they also are a fundamental part in the implementation of the mapping functions. These functions are defined conceptually in the model, but are implemented considering six possible configurations between dimension specifications (ORDERED, PARTIAL and TOTAL) types and dimension types (IMPLICIT and EXPLICIT).</p><p>An ORDERED dimension specification indicates that the indexes for the cells in that dimension are dense and sorted in some fashion. A PARTIAL dimension implementation, indicates that there are some holes in the datasets, meaning that some cells at given indexes are not present. Finally the TOTAL representation indicates that data is fully sparse and that all indexes must be given for every cell, in other words, it means that we have a degenerated array that is basically tabular data.</p></div>
<div><head n="3.">The system SAVIME</head><p><software>SAVIME</software> has a component-based architecture common to other DBMSs, containing modules such as an optimizer, a parser and an query processing engine, along with auxiliary modules to manage connections, metadata and storage. A <software ContextAttributes="created">SAVIME</software> client communicates with the <software ContextAttributes="created">SAVIME</software> server by using a simple protocol that allows both ends to exchange messages, queries and datasets. All modules are currently implemented as a series of C++ classes, each one of them with an abstract class interface and an underlying concrete implementation.</p></div>
<div><head n="3.1.">Languages DDL, SDL and DML</head><p><software>SAVIME</software>'s DDL supports operators to define TARS and Datasets, for instance, the commands:</p><p>CREATE_TAR("FooTAR", " * ", "Implicit, I, long, 1, 1000, 1 | Implicit, J, long, 1, 1000 , 1", "attrib, double"); CREATE_DATASET("FooBarDS1:double", "ds1_data_source"); CREATE_DATASET("FooBarDS2:double", "ds2_data_source"); LOAD_SUBTAR("FooTAR", "Ordered, I, 1, 100 | Ordered, J, 1, 100", "attrib, FooBarDS1"); LOAD_SUBTAR("FooTAR", "Ordered, J, 101, 200 | Ordered, I, 1, 100", "attrib, FooBarDS2");</p><p>Initially we can issue a CREATE TAR command to create a TAR name FooTAR. It has 2 dimension (I and J) whose indexes are long integers. These are implicit dimensions, whose domains are integers equally spaced by 1 unit from 1 to 1000. This TAR also has a single attribute named attrib whose type is a double precision real number.</p><p>After that we create 2 datasets named FooBarDS1 and FooBarDS2, they are double typed collections of values in a data source (usually a file or memory based file). Finally we issue 2 LOAD SUBTAR commands to create 2 new subtars for the TAR FooTAR, the first one ecompasses the region that contains the cell s whose indexes are in [1, 100]×[1, 100] for dimension I and J respectively, in both case we have an ordered representation indicating that data is dense and ordered first by the I index and second by J index. The second subtar, however, encompasses the cells whose indexes are in [1, 100] × [101, 200] but instead ordered first by J index and second by the I index. It is an example of how the SDL works, since users can express and consolidate data sources with different ordering layouts into a single TAR. The final part of the command indicates that datasets FooBarDS1 and FooBarDS2 are attached to the "attrib" attribute, meaning that the data for "attrib" in the cells whithin each subTAR region can be found in these datasets. <software>SAVIME</software> also supports a functional DML with operators similar to the ones implemented in <software ContextAttributes="created">SciDB</software>, for operations such as filtering data based on predicates, calculating derived values, joins and aggregations. Here is an example of a query in <software ContextAttributes="created">SAVIME</software>.</p></div>
<div><head>AGGREGATE(</head><p>WHERE( DERIVE(FooTAR, attrib2, attrib * attrib), attrib2 &gt;= 2.0 and attrib2 &lt;= 10.0 ), sum, attrib2, sum_attrib2, I );</p><p>This DML query consists of three nested operators. Initially, a new attribute called attrib2 is created by the operator DERIVE and its value is defined as the square of the attribute attrib. After that, the WHERE operator is called, it filters data according to the predicate, in this case, it returns a TAR whose cells have the value for attrib2 set between 2 and 10. Finally, we use the AGGREGATE operator to group data by dimension I indexes and sum the value for attrib2 creating the sum attrib2, the resulting TAR will present only one dimension (I) and a single attribute sum attrib2 whose values are the result of the sum of the attrib2 accross dimension J.</p></div>
<div><head n="3.2.">Query Processing</head><p>As presented in the previous section, a <software>SAVIME</software> query contains a series of nested operators. Most of them expect one or more input TARs, and originate a newly created output TAR.</p><p>Unless a special operator is called to materialize the query resulting TAR, it is generated as a stream of subTARs, sent to the client and then discarded. <software>SAVIME</software> operates TARs as a subTARs stream pipelined across operators. SubTARs are processed serially or in parallel with OpenMP constructs.</p><p>During query processing, when a subTAR for a TAR holding intermediated results is generated and passed on to the next operator, it is maintained in a temporary subTARs cache. These subTARs contain their own group of datasets that could require a lot of storage space or memory. Therefore, once a subTAR is no longer required by any operator, it must be removed from memory. An operator implementation is agnostic regarding its previous and posterior operations in the pipeline, and does not know when to free or not a subTAR. All the operators implementation needs to establish is when it will not require a given subTAR any longer. When this happens, the operator notifies the execution engine that it is done with a given subTAR and it is then discarded.</p><p>However, since the same subTAR can potentially be input into more than one operator during a query, freeing it upfront is not a good idea, because it might be required again. In this case, <software>SAVIME</software> would have to recreate it. To solve this problem, every subTAR has an associated counter initially set to the number of operators that have its TAR as their input. When an operator notifies the engine that it no longer needs that specific subTAR, the respective counter is decreased. Once the counter reaches zero, all operators possibly interested in the subTAR are done, and now it is safe to free the subTAR. This approach always frees the used memory as soon as possible and never requires a subTAR to be created twice. However, some operators might require many subTARs to be kept in memory before freeing them. In an environment with limited memory, it would not be feasible to cope with very large TARs in this case. A solution then, would be the adoption of a more economical approach, trading off space with time by freeing and regenerating the subTARs whenever memory is running low.</p></div>
<div><head n="4.">Experimental Evaluation</head><p>We ran a series of experiments in order to validate <software>SAVIME</software> as a feasible alternative to simulation data management. We compare <software ContextAttributes="created">SAVIME</software> with <software ContextAttributes="created">SciDB</software> and evaluate how <software ContextAttributes="created">SAVIME</software> affects the performance of actual simulation code.</p></div>
<div><head n="4.1.">SAVIME vs. SciDB</head><p>In this section, we compare <software>SAVIME</software>, <software ContextAttributes="created">SciDB</software> (version 16.9) and a third approach based on the usage of <software ContextAttributes="created">NetCDF</software> files (version 4.0), used as a baseline. All scripts, applications and queries used in our evaluation are available at github.com/hllustosa/ savime-testing.</p><p>We use two datasets, a dense and a sparse one, based on data from the HPC4e BSC seismic benchmark <ref type="bibr" target="#b4">[Center 2016</ref>] in our experiments. The dense dataset contains 500 trials (one dataset for each) for a 3D regular mesh with dimensions 201x501x501 containing a velocity field. In total, we have over 30 billion array cells and more than a 120 GB of data. All data is held in a single 4D structure (TAR in <software ContextAttributes="created">SAVIME</software>, array in <software ContextAttributes="created">SciDB</software> and in a single <software ContextAttributes="created">NetCDF</software> file) containing the X, Y, and Z dimensions, and an extra trial dimension to represent all 500 trials. Both structures have the same tiling configuration, i.e., the same number of chunks/subTARs (500 of them, one for each trial) with the same extents.</p><p>The sparse dataset is also a 4D structure with 500 simulation trials, but only a subset of the cells are present (around 24% of the dense dataset). It comprises almost 8 billion array cells and over 30 GB of data. We used a sparse 4D array/TAR in <software>SciDB</software> and <software ContextAttributes="created">SAVIME</software>, and a 2D dense array in <software ContextAttributes="created">NetCDF</software>. <software ContextAttributes="created">NetCDF</software> lacks the ability to natively represent sparse data, thus we indexed the x, y and z values and represented them as a single dimension and stored coordinate values as variables.</p><p>The computational resource used is the fatnode from the cluster Petrus at DEXLab. This fatnode has 6 Intel(R) Xeon(R) CPU E5-2690 processors amounting to 48 cores and over 700 GB of RAM. Data is kept in a shared-memory file system to simulate an in-transit data analysis, in which data is not kept on disk (for both <software>SAVIME</software> and <software ContextAttributes="created">SciDB</software>). Initially, we evaluate the loading time of 500 tiles/chunks in all three approaches, considering that data is being transferred and continually appended to a single array/TAR/file as it is being generated by a solver.</p><p>As we can see in Figure <ref type="figure">2</ref> on the left graph, the ingestion time taken by <software ContextAttributes="created">SciDB</software> is almost 20 times longer than the time taken by <software ContextAttributes="created">SAVIME</software>, due to costly rearrangements needed on data to make it conform with the underlying storage configuration. Besides, there is an extra overhead during the lightweight data compression done by <software ContextAttributes="created">SciDB</software>, which makes the dataset roughly 50% smaller when stored but increased loading time prohibitively. In contrast, <software ContextAttributes="created">SAVIME</software> does not alter or index the data during the process of data ingestion, therefore the loading process is computationally much cheaper.</p></div>
<div><head>Figure 2. Ingestion and query execution time</head><p>We evaluate the performance considering ordinary and exact window queries. Ordinary Window queries consist of retrieving a subset of the array defined by a range in all its dimensions. The performance for this type of queries depends on how data is chunked and laid out. High selectivity queries, which need to retrieve only a very small portion of the data tends to be faster than full scans. Therefore, we compared low and high selectivity queries, filtering from a single to all 500 tiles. We also considered the performance of exact window queries, which is the easiest type of Window Query. They consist of retrieving data for a single tile or chunk, meaning the system has close to zero work filtering out the result.</p><p>We implement these queries as specific operators in <software ContextAttributes="created">SAVIME</software> and <software ContextAttributes="created">SciDB</software>, and with the help with a custom OpenMP <software ContextAttributes="created">application</software> using the <software ContextAttributes="created">NetCDF</software> library. The experimental results are shown in Figure <ref type="figure">2</ref> on the right graph. The average time of 30 runs are presented.</p><p>We considered window queries with low selectivity (over 70 % of all cells in a tile) and high selectivity (around 20 % of all cells in a tile), and intersecting with only 1, 100 or even the total 500 tiles.</p><p>It is noticeable that <software>SAVIME</software> either outperforms <software ContextAttributes="created">SciDB</software> or is as efficient as it in all scenarios. The most important observation is that, even without any previous data preprocessing, <software ContextAttributes="created">SAVIME</software> is able to simply take advantage of the existing data structure to answer the queries efficiently, which validates the model as a feasible alternative to existing implementations. The results show that, for any storage alternative in both dense and sparse formats, the subsetting of a single tile is very efficient. The differences shown for the exact window query and for low and high selectivity window queries that touch a single tile are very small. <software ContextAttributes="created">SciDB</software> takes a few seconds in most cases, while <software ContextAttributes="created">SAVIME</software> takes in average 1 second. <software ContextAttributes="created">NetCDF</software> is the most efficient in this scenario, retrieving desired data in less than a second. However, for queries touching 100 or 500 chunks, we can see the differences between querying dense and the sparse arrays. The dense dataset is queried more efficiently, since it is possible to determine the exact position of every cell and read only the data of interest. It is not possible for sparse data, since one is not able to infer cell positions within the tiles. In this case, every single cell within all tiles that intersect with the range query must be checked.</p><p>In dense arrays, we can observe a reduced time for retrieving data in high selectivity queries in comparison with low selectivity queries. The execution time of window queries should depend only on the amount of data of interest, since cells can be accessed directly and thus, no extra cells need to be checked. The execution times considering 100 or 500 tiles in <software>SAVIME</software> and <software ContextAttributes="created">NetCDF</software> are in accordance with this premise. However, <software ContextAttributes="created">SciDB</software> shows poorer performance, being up to 8 times slower. It is very likely that <software ContextAttributes="created">SciDB</software> needs to process cells outside of the window of interest depending on the compression technique and the storage layout adopted. <software ContextAttributes="created">SciDB</software> seems to be more sensible to tiling granularity, requiring fine-grained tiles that match the window query to have a performance similar to the <software ContextAttributes="created">NetCDF</software> approach.</p><p>There is not much to be done for querying sparse arrays except for going through every cell in the tiles intersecting the window specified by the query. The query time for sparse data in all alternatives show very similar performance. The main difference is that for achieving this result with <software>NetCDF</software>, an OpenMP <software ContextAttributes="created">application</software> needed to be written, while the same result could be obtained with a one-line query in <software ContextAttributes="created">SAVIME</software> and <software ContextAttributes="created">SciDB</software>.</p><p>Our conclusion is that the regular chunking scheme imposed by <software>SciDB</software> not only slows down the ingestion process significanly as it has not real impact in improving performance for simples operations, since <software ContextAttributes="created">SAVIME</software> using a more flexible data model can solve similtar queries presenting a compatible performance.</p></div>
<div><head n="4.2.">Integration with Numerical Solver</head><p>In this section, we evaluate the amount of overhead imposed to the simulation code when integrating with <software ContextAttributes="created">SAVIME</software>. We use the simulation tools based on the MHM numerical method <ref type="bibr" target="#b6">[Gomes et al. 2017]</ref> as a representative numerical simulation <software ContextAttributes="created">application</software>. We compare three approaches. In the first approach, <software ContextAttributes="created">SAVIME</software> is used IN-TRANSIT, in a single node (fatnode) while the simulation code runs in a different set of nodes, and thus data needs to be transferred. In the second approach, <software ContextAttributes="created">SAVIME</software> is used IN-SITU, with individual <software ContextAttributes="created">SAVIME</software> instances running on each node, the same used by the simulation code. In this scenario, the data does not need to be transferred, since it is maintained in a local <software ContextAttributes="created">SAVIME</software> instance that shares the same computational resources used by the simulation code. In the third approach <software ContextAttributes="created">SAVIME</software> is not used, but instead, the data is stored in ENSIGHT files (the standard file format used by MHM), and analysis are performed by an ad-hoc Message Passing Interface <software ContextAttributes="created">application</software> in Python. This last scenario serves as a baseline implementation, thus we call it the baseline approach. The computational resource used is the Petrus cluster at DEXLab, with 8 nodes, each with 96 GB of RAM and 2 Intel(R) Xeon(R) CPU E5-2690 processors.</p><p>Preliminarily, we start the evaluation by measuring the overhead of loading data in a remote node running <software ContextAttributes="created">SAVIME</software>. In Figure <ref type="figure" target="#fig_0">3</ref> we can see the time of running the simulation and discarding the data, which is the time to solely carry out the computations without any I/O whatsoever and the time to transfer and load data into <software ContextAttributes="created">SAVIME</software>. We vary the size of the MHM meshes, which impact on the level of detail of the simulation. The larger the mesh size is, the more realistic and complex the simulation is, and also, more resources (time and memory) are consumed. Results show that for very small meshes, which are computationally cheap, the time to load data is more significant, and thus there is some overhead (around 40%) in storing data in <software ContextAttributes="created">SAVIME</software>. However, as meshes get larger, the time taken to compute them increases in a manner that the transfer and loading time is negligible in comparison to the time taken to compute the solution. The transfer and loading time is masked by the dominant process of solving the systems of equation. Therefore, this shows that, for large enough problems, it is possible to load data into <software ContextAttributes="created">SAVIME</software> without compromising the simulation code performance. However, under an impedance mismatch scenario, as observed with <software ContextAttributes="created">SciDB</software>, the loading time would be significant, impacting on the simulation cost.</p><p>To evaluate the integration between <software>SAVIME</software> and a simulation tool based on the MHM solver, we use a 2D transport problem over a mesh with 1.9 million points. We run the simulation up to the 100th time step, and store either in <software ContextAttributes="created">SAVIME</software> (approaches 1 and 2) or in an ENSIGHT file (approach 3), data from 50% of all the computed time steps. In both cases, data is always kept in a memory based file system, and never stored on disk.</p><p>Once data has been generated, it is analyzed with a PARAVIEW pipeline that carries out the computation of the gradient of the displacement field of the solution. This part is either done by a special operator in <software>SAVIME</software>, or by an AD-HOC MPI Python <software ContextAttributes="created">application</software> using the Catalyst library (baseline), depending on the approach being run. Additionally, we measure the cost of running the simulation without any further analysis, to highlight the simulation only cost.</p><p>Figure <ref type="figure" target="#fig_0">3</ref> shows the results when running the three approaches, varying the amount of MPI processes spawned or the number of cores used by the MHM simulation code. In this experiment, the simulation code runs and produces its results and then, the simulation output data is read and processed in the analysis step. The plot shows, for each evaluated number of MPI processes, the simulation time and the analysis time as stacked bars. The graph shows that the cost of the analysis process is significantly smaller than the cost for computing the simulation. Moreover, as the Simulation Only run shows, the overhead introduced by storing the data in <software ContextAttributes="created">SAVIME</software> or as an ENSIGHT file is negligible, which confirms the claim that <software ContextAttributes="created">SAVIME</software> can be introduced into the simulation process without incurring in extra overhead. From the point of view of the effect of <software ContextAttributes="created">SAVIME</software> on simulation scalability, the storage of data in <software ContextAttributes="created">SAVIME</software> does not impair the capability of the simulation code to scale up to 16 cores.</p><p>The IN-TRANSIT approach differs from the other two approaches since it uses a separate computational resource to execute the analysis step. As we see in Figure <ref type="figure" target="#fig_0">3</ref>, even when we increase the number of cores the simulation code uses, the analysis time does not change, because the analysis step is done in the fatnode, and always uses the same number of cores ( <ref type="formula">16</ref>) independently from the actual number of cores used by the simulation code. The IN-TRANSIT approach illustrates a scenario in which all data is sent to a single computational node and kept in a single <software ContextAttributes="created">SAVIME</software> instance. This approach offers some extra overhead and contention, since all data is sent to a single <software ContextAttributes="created">SAVIME</software> instance, but this enables posterior analysis that transverse the entire dataset without requiring further data transfers.</p><p>The <software>SAVIME</software> IN-SITU approach uses the same computational resources used by the simulation code. When we increase the number of cores used by the simulation code, we also increase the numbers of cores used by <software ContextAttributes="created">SAVIME</software> for analysis. The same is true for the baseline approach, meaning that the AD-HOC <software ContextAttributes="created">application</software> also uses the same number of cores the simulation code uses. Even though the <software ContextAttributes="created">SAVIME</software> IN-SITU approach is slightly slower than the baseline approach, we see that both are able to scale similarly. The difference observed in performance between using <software ContextAttributes="created">SAVIME</software> and coding a specialized <software ContextAttributes="created">application</software> becomes less significant as we increase the number of cores being used during the analysis phase. Nevertheless, the small performance loss in this case might be justified by the convenience of using a query language to express analysis instead of the extensive and error prone process of coding other applications to execute analysis.</p></div>
<div><head n="5.">Related Work</head><p>The definition of the first array data models and query languages dates back to the works of Baumann <ref type="bibr" target="#b1">[Baumann 1994</ref>] and Marathe <ref type="bibr">[Marathe and</ref><ref type="bibr" target="#b10">Salem 1997] [Marathe and</ref><ref type="bibr" target="#b11">Salem 1999]</ref>. Since that time, a myriad of systems emerged in order to allow for the storage and analysis of data over multidimensional arrays. Many array DBMSs have been proposed, the most prominent ones are <software ContextAttributes="created">RasDaMan</software> <ref type="bibr" target="#b2">[Baumann et al. 1997</ref>] and, more rencently, <software ContextAttributes="created">SciDB</software> <ref type="bibr" target="#b5">[Cudre-Mauroux et al. 2009</ref>].</p><p>Due to the fact that ingesting data into these systems is not an easy task, other arrays systems, such as <software ContextAttributes="created">ArrayBridge</software> <ref type="bibr" target="#b15">[Xing et al. 2017]</ref> and ChronoDB <ref type="bibr" target="#b16">[Zalipynis 2018</ref>] have been developed. <software ContextAttributes="created">ArrayBridge</software> works over <software ContextAttributes="created">SciDB</software>, and gives it the ability to work directly with HDF5 files. ChronoDB works over many file formats in the context of raster geospatial datasets. <software ContextAttributes="created">SAVIME</software> has the similar goal to ease data ingestion, however it does so by enabling seamless data ingestion considering many different array data source by supporting a SDL and a flexible data model, which makes it different from <software ContextAttributes="created">ArrayBridge</software>. <software ContextAttributes="created">SAVIME</software> also offers its own DML, while ChronoDB makes use of existing applications process data. <software ContextAttributes="created">SAVIME</software> is also different from TileDB <ref type="bibr" target="#b13">[Papadopoulos et al. 2016]</ref>, which is not exactly a DBMS with a declarative query language, but a library that deals with array data. In addition, <software ContextAttributes="created">SAVIME</software> is a specialized in-memory solution, while the rest of these systems are usually more disk oriented solutions.</p></div>
<div><head n="6.">Conclusion</head><p>The adoption of scientific file formats and I/O libraries rather than DBMSs for scientific data analysis is due to a series of problem concerning data representation and data ingestion in current solutions. To mitigate these problems, and to also offer the benefits of declarative array processing in memory, we propose a system called <software>SAVIME</software>. We showed how <software ContextAttributes="created">SAVIME</software>, by implementing the TARS data model, does not impose the huge overhead present in current database solutions for data ingestion, while also being able to take advantage of preexisting data layouts to answer queries efficiently.</p><p>We compared <software>SAVIME</software> with <software ContextAttributes="used">SciDB</software> and a baseline approach using the <software ContextAttributes="used">NetCDF</software> platform. The experimental results show that <software ContextAttributes="used">SciDB</software> suffers from the aforementioned problems, not being an ideal alternative and that <software ContextAttributes="used">SAVIME</software> enables faster data ingestion, while maintaining similar performance during window queries execution. We showed that <software ContextAttributes="used">SAVIME</software> can also match the performance of <software ContextAttributes="used">NetCDF</software> for loading and querying dense arrays while providing the benefits of a query language processing layer.</p><p>We also assess <software>SAVIME</software>'s performance when integrating with simulation code. In this evaluation, we showed that storing data in <software ContextAttributes="used">SAVIME</software> does not impair the scalability of the solver. In addition, results also show that it is possible to retrieve <software ContextAttributes="used">SAVIME</software> data and generate viz files efficiently by using the special purpose visualization operator.</p><p><software>SAVIME</software> is available at github.com/hllustosa/Savime. Future work might focus on the improvement and optimization of current operators, the development of new special purpose TAR operators.</p></div><figure xml:id="fig_0"><head>Figure 3 .</head><label>3</label><figDesc>Figure 3. Mesh size x Simulation Execution Time (left) and Simulation and Analysis Scalability (right)</figDesc><graphic coords="10,99.64,362.37,396.00,157.45" type="bitmap" /></figure>
<figure><head /><label /><figDesc /><graphic coords="4,99.64,343.71,395.99,212.69" type="bitmap" /></figure>
<figure><head /><label /><figDesc /><graphic coords="8,99.64,411.82,396.01,148.20" type="bitmap" /></figure>
			<note place="foot" xml:id="foot_0"><p>Scientific data is usually represented as multidimensional arrays, which are common as the result of scientific experiments, measurements and simulations. In short, an array is a regular structure formed by a set of dimensions. A set of indexes, one per dimension, identifies a cell that contains values for array attributes.</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Increasing scientific data insights about exascale class simulations under power and storage constraints</title>
		<author>
			<persName><forename type="first">J</forename><surname>Ahrens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer Graphics and Applications</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="8" to="11" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Management of multidimensional discrete data</title>
		<author>
			<persName><forename type="first">P</forename><surname>Baumann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The VLDB Journal</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="401" to="444" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">The rasdaman approach to multidimensional database management</title>
		<author>
			<persName><forename type="first">P</forename><surname>Baumann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Furtado</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ritsch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Widmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1997 ACM Symposium on Applied Computing, SAC '97</title>
		<meeting>the 1997 ACM Symposium on Applied Computing, SAC '97<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1997">1997</date>
			<biblScope unit="page" from="166" to="173" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Parallel data analysis directly on scientific file formats</title>
		<author>
			<persName><forename type="first">S</forename><surname>Blanas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Byna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Shoshani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 ACM SIGMOD International Conference on Management of Data, SIGMOD '14</title>
		<meeting>the 2014 ACM SIGMOD International Conference on Management of Data, SIGMOD '14<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="385" to="396" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">New hpc4e seismic test suite to increase the pace of development of new modelling and imaging technologies</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">S</forename><surname>Center</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016-01">2016. 01-feb-2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A demonstration of scidb: A science-oriented dbms</title>
		<author>
			<persName><forename type="first">P</forename><surname>Cudre-Mauroux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Kimura</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K.-T</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Rogers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Simakov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Soroush</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Velikhov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Balazinska</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Becla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Dewitt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Heath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Maier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Madden</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Patel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Stonebraker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zdonik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. VLDB Endow</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1534" to="1537" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">On the implementation of a scalable simulator for multiscale hybrid-mixed methods</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">T A</forename><surname>Gomes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">S</forename><surname>Pereira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Valentin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Paredes</surname></persName>
		</author>
		<idno>CoRR, abs/1703.10435</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Hdf5-fastquery: Accelerating complex queries on hdf datasets using fast bitmap indices</title>
		<author>
			<persName><forename type="first">L</forename><surname>Gosink</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Shalf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Stockinger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Bethel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SSDBM '06</title>
		<meeting><address><addrLine>Washington, DC, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="149" to="158" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Hdf5 -the hdf group</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">H</forename><surname>Group</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017-01">2017. 01-feb-2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">TARS: An Array Model with Rich Semantics for Multidimensional Data</title>
		<author>
			<persName><forename type="first">H</forename><surname>Lustosa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Lemus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Porto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Valduriez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conceptual Modeling : Research In Progress</title>
		<meeting><address><addrLine>Valencia, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017">2017. 2017</date>
		</imprint>
	</monogr>
	<note>ER FORUM</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A language for manipulating arrays</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">P</forename><surname>Marathe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Salem</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd International Conference on Very Large Data Bases, VLDB '97</title>
		<meeting>the 23rd International Conference on Very Large Data Bases, VLDB '97<address><addrLine>San Francisco, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1997">1997</date>
			<biblScope unit="page" from="46" to="55" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Query processing techniques for arrays</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">P</forename><surname>Marathe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Salem</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM SIGMOD Record</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="323" to="334" />
			<date type="published" when="1999">1999</date>
			<publisher>ACM</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Evaluation of methods to integrate analysis into a large-scale shock shock physics code</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Oldfield</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Moreland</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Fabian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Rogers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th ACM International Conference on Supercomputing, ICS '14</title>
		<meeting>the 28th ACM International Conference on Supercomputing, ICS '14<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="83" to="92" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">The tiledb array data storage manager</title>
		<author>
			<persName><forename type="first">S</forename><surname>Papadopoulos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Datta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Madden</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Mattson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. VLDB Endow</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="349" to="360" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Scidb</title>
	</analytic>
	<monogr>
		<title level="j">Paradigm</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<date type="published" when="2017-01">2017. 01-feb-2018. 2017. 01-feb-2018</date>
			<publisher>Unidata</publisher>
		</imprint>
	</monogr>
	<note>netcdf</note>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Array-Bridge: Interweaving declarative array processing with high-performance computing</title>
		<author>
			<persName><forename type="first">H</forename><surname>Xing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Floratos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Blanas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Byna</surname></persName>
		</author>
		<author>
			<persName><surname>Prabhat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Brown</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1702.08327</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv e-prints</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Chronosdb: Distributed, file based, geospatial array dbms</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A R</forename><surname>Zalipynis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. VLDB Endow</title>
		<meeting>VLDB Endow</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="1247" to="1261" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</teiCorpus></text>
</TEI>