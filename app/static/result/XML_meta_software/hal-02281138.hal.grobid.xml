<?xml version='1.0' encoding='utf-8'?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" version="1.1" xsi:schemaLocation="http://www.tei-c.org/ns/1.0 http://api.archives-ouvertes.fr/documents/aofr-sword.xsd">
  <teiHeader>
    <fileDesc>
      <titleStmt>
        <title>HAL TEI export of hal-02281138</title>
      </titleStmt>
      <publicationStmt>
        <distributor>CCSD</distributor>
        <availability status="restricted">
          <licence target="http://creativecommons.org/licenses/by/4.0/">Distributed under a Creative Commons Attribution 4.0 International License</licence>
        </availability>
        <date when="2024-04-29T11:48:25+02:00" />
      </publicationStmt>
      <sourceDesc>
        <p part="N">HAL API platform</p>
      </sourceDesc>
    </fileDesc>
  </teiHeader>
  <text>
    <body>
      <listBibl>
        <biblFull>
          <titleStmt>
            <title xml:lang="en">Song Lyrics Summarization Inspired by Audio Thumbnailing</title>
            <author role="aut">
              <persName>
                <forename type="first">Michael</forename>
                <surname>Fell</surname>
              </persName>
              <email type="md5">c8eacecf00aa8861807e95e501a20bd2</email>
              <email type="domain">unice.fr</email>
              <idno type="idhal" notation="numeric">1036897</idno>
              <idno type="halauthorid" notation="string">1429557-1036897</idno>
              <affiliation ref="#struct-178918" />
            </author>
            <author role="aut">
              <persName>
                <forename type="first">Elena</forename>
                <surname>Cabrio</surname>
              </persName>
              <idno type="halauthorid">779246-0</idno>
              <affiliation ref="#struct-178918" />
            </author>
            <author role="aut">
              <persName>
                <forename type="first">Fabien</forename>
                <surname>Gandon</surname>
              </persName>
              <email type="md5">44d5e01d52fbc50f3106821f63588881</email>
              <email type="domain">inria.fr</email>
              <ptr type="url" target="http://fabien.info" />
              <idno type="idhal" notation="string">fabien-gandon</idno>
              <idno type="idhal" notation="numeric">3342</idno>
              <idno type="halauthorid" notation="string">17533-3342</idno>
              <idno type="IDREF">https://www.idref.fr/076340074</idno>
              <idno type="ORCID">https://orcid.org/0000-0003-0543-1232</idno>
              <idno type="GOOGLE SCHOLAR">https://scholar.google.fr/citations?user=PVfj-SAAAAAJ</idno>
              <orgName ref="#struct-300009" />
              <affiliation ref="#struct-178918" />
            </author>
            <author role="aut">
              <persName>
                <forename type="first">Alain</forename>
                <surname>Giboin</surname>
              </persName>
              <email type="md5">da82c86ea2f6cf09b6d787fab157b77b</email>
              <email type="domain">inria.fr</email>
              <idno type="idhal" notation="string">alain-giboin</idno>
              <idno type="idhal" notation="numeric">22009</idno>
              <idno type="halauthorid" notation="string">25421-22009</idno>
              <idno type="ORCID">https://orcid.org/0000-0003-1007-0101</idno>
              <affiliation ref="#struct-178918" />
            </author>
            <editor role="depositor">
              <persName>
                <forename>Michael</forename>
                <surname>Fell</surname>
              </persName>
              <email type="md5">c8eacecf00aa8861807e95e501a20bd2</email>
              <email type="domain">unice.fr</email>
            </editor>
          </titleStmt>
          <editionStmt>
            <edition n="v1" type="current">
              <date type="whenSubmitted">2019-09-08 13:15:57</date>
              <date type="whenModified">2024-02-26 11:22:08</date>
              <date type="whenReleased">2019-09-09 09:57:54</date>
              <date type="whenProduced">2019-09-02</date>
              <date type="whenEndEmbargoed">2019-09-08</date>
              <ref type="file" target="https://hal.science/hal-02281138/document">
                <date notBefore="2019-09-08" />
              </ref>
              <ref type="file" subtype="author" n="1" target="https://hal.science/hal-02281138/file/Lyrics_Summarization__RANLP_final.pdf">
                <date notBefore="2019-09-08" />
              </ref>
            </edition>
            <respStmt>
              <resp>contributor</resp>
              <name key="657103">
                <persName>
                  <forename>Michael</forename>
                  <surname>Fell</surname>
                </persName>
                <email type="md5">c8eacecf00aa8861807e95e501a20bd2</email>
                <email type="domain">unice.fr</email>
              </name>
            </respStmt>
          </editionStmt>
          <publicationStmt>
            <distributor>CCSD</distributor>
            <idno type="halId">hal-02281138</idno>
            <idno type="halUri">https://hal.science/hal-02281138</idno>
            <idno type="halBibtex">fell:hal-02281138</idno>
            <idno type="halRefHtml">&lt;i&gt;RANLP 2019 - Recent Advances in Natural Language Processing&lt;/i&gt;, Sep 2019, Varna, Bulgaria</idno>
            <idno type="halRef">RANLP 2019 - Recent Advances in Natural Language Processing, Sep 2019, Varna, Bulgaria</idno>
          </publicationStmt>
          <seriesStmt>
            <idno type="stamp" n="UNICE">Université Nice Sophia Antipolis</idno>
            <idno type="stamp" n="UNIV-RENNES1">Université de Rennes 1</idno>
            <idno type="stamp" n="CNRS">CNRS - Centre national de la recherche scientifique</idno>
            <idno type="stamp" n="INRIA">INRIA - Institut National de Recherche en Informatique et en Automatique</idno>
            <idno type="stamp" n="INRIA-SOPHIA">INRIA Sophia Antipolis - Méditerranée</idno>
            <idno type="stamp" n="IRISA">Irisa</idno>
            <idno type="stamp" n="I3S">Laboratoire d'Informatique, Signaux et Systèmes de Sophia-Antipolis</idno>
            <idno type="stamp" n="INRIASO">INRIA-SOPHIA</idno>
            <idno type="stamp" n="INRIA_TEST">INRIA - Institut National de Recherche en Informatique et en Automatique</idno>
            <idno type="stamp" n="TESTALAIN1">TESTALAIN1</idno>
            <idno type="stamp" n="WIMMICS">WIMMICS: Web-Instrumented Man-Machine Interactions, Communities, and Semantics</idno>
            <idno type="stamp" n="INRIA2">INRIA 2</idno>
            <idno type="stamp" n="UR1-HAL">Publications labos UR1 dans HAL-Rennes 1</idno>
            <idno type="stamp" n="UR1-MATH-STIC">UR1 - publications Maths-STIC</idno>
            <idno type="stamp" n="UR1-UFR-ISTIC">UFR ISTIC Informatique et électronique</idno>
            <idno type="stamp" n="UNIV-COTEDAZUR">Université Côte d'Azur</idno>
            <idno type="stamp" n="TEST-UR-CSS">TEST Université de Rennes CSS</idno>
            <idno type="stamp" n="UNIV-RENNES">Université de Rennes</idno>
            <idno type="stamp" n="INRIA-300009">Inria 300009</idno>
            <idno type="stamp" n="TEST-HALCNRS">Collection test HAL CNRS</idno>
            <idno type="stamp" n="UR1-MATH-NUM">Pôle UnivRennes - Mathématiques - Numérique </idno>
          </seriesStmt>
          <notesStmt>
            <note type="audience" n="2">International</note>
            <note type="invited" n="0">No</note>
            <note type="popular" n="0">No</note>
            <note type="peer" n="1">Yes</note>
            <note type="proceedings" n="1">Yes</note>
          </notesStmt>
          <sourceDesc>
            <biblStruct>
              <analytic>
                <title xml:lang="en">Song Lyrics Summarization Inspired by Audio Thumbnailing</title>
                <author role="aut">
                  <persName>
                    <forename type="first">Michael</forename>
                    <surname>Fell</surname>
                  </persName>
                  <email type="md5">c8eacecf00aa8861807e95e501a20bd2</email>
                  <email type="domain">unice.fr</email>
                  <idno type="idhal" notation="numeric">1036897</idno>
                  <idno type="halauthorid" notation="string">1429557-1036897</idno>
                  <affiliation ref="#struct-178918" />
                </author>
                <author role="aut">
                  <persName>
                    <forename type="first">Elena</forename>
                    <surname>Cabrio</surname>
                  </persName>
                  <idno type="halauthorid">779246-0</idno>
                  <affiliation ref="#struct-178918" />
                </author>
                <author role="aut">
                  <persName>
                    <forename type="first">Fabien</forename>
                    <surname>Gandon</surname>
                  </persName>
                  <email type="md5">44d5e01d52fbc50f3106821f63588881</email>
                  <email type="domain">inria.fr</email>
                  <ptr type="url" target="http://fabien.info" />
                  <idno type="idhal" notation="string">fabien-gandon</idno>
                  <idno type="idhal" notation="numeric">3342</idno>
                  <idno type="halauthorid" notation="string">17533-3342</idno>
                  <idno type="IDREF">https://www.idref.fr/076340074</idno>
                  <idno type="ORCID">https://orcid.org/0000-0003-0543-1232</idno>
                  <idno type="GOOGLE SCHOLAR">https://scholar.google.fr/citations?user=PVfj-SAAAAAJ</idno>
                  <orgName ref="#struct-300009" />
                  <affiliation ref="#struct-178918" />
                </author>
                <author role="aut">
                  <persName>
                    <forename type="first">Alain</forename>
                    <surname>Giboin</surname>
                  </persName>
                  <email type="md5">da82c86ea2f6cf09b6d787fab157b77b</email>
                  <email type="domain">inria.fr</email>
                  <idno type="idhal" notation="string">alain-giboin</idno>
                  <idno type="idhal" notation="numeric">22009</idno>
                  <idno type="halauthorid" notation="string">25421-22009</idno>
                  <idno type="ORCID">https://orcid.org/0000-0003-1007-0101</idno>
                  <affiliation ref="#struct-178918" />
                </author>
              </analytic>
              <monogr>
                <meeting>
                  <title>RANLP 2019 - Recent Advances in Natural Language Processing</title>
                  <date type="start">2019-09-02</date>
                  <date type="end">2019-09-04</date>
                  <settlement>Varna</settlement>
                  <country key="BG">Bulgaria</country>
                </meeting>
                <imprint />
              </monogr>
            </biblStruct>
          </sourceDesc>
          <profileDesc>
            <langUsage>
              <language ident="en">English</language>
            </langUsage>
            <textClass>
              <classCode scheme="halDomain" n="info.info-ai">Computer Science [cs]/Artificial Intelligence [cs.AI]</classCode>
              <classCode scheme="halDomain" n="info">Computer Science [cs]</classCode>
              <classCode scheme="halDomain" n="info.info-cl">Computer Science [cs]/Computation and Language [cs.CL]</classCode>
              <classCode scheme="halTypology" n="COMM">Conference papers</classCode>
              <classCode scheme="halOldTypology" n="COMM">Conference papers</classCode>
              <classCode scheme="halTreeTypology" n="COMM">Conference papers</classCode>
            </textClass>
          </profileDesc>
        </biblFull>
      </listBibl>
    </body>
    <back>
      <listOrg type="structures">
        <org type="researchteam" xml:id="struct-178918" status="VALID">
          <idno type="RNSR">201221031M</idno>
          <orgName>Web-Instrumented Man-Machine Interactions, Communities and Semantics</orgName>
          <orgName type="acronym">WIMMICS</orgName>
          <desc>
            <address>
              <country key="FR" />
            </address>
            <ref type="url">http://wimmics.inria.fr/</ref>
          </desc>
          <listRelation>
            <relation active="#struct-34586" type="direct" />
            <relation active="#struct-300009" type="indirect" />
            <relation active="#struct-452156" type="direct" />
            <relation active="#struct-13009" type="indirect" />
            <relation active="#struct-117617" type="indirect" />
            <relation name="UMR7271" active="#struct-441569" type="indirect" />
            <relation active="#struct-1039632" type="indirect" />
          </listRelation>
        </org>
        <org type="laboratory" xml:id="struct-34586" status="VALID">
          <idno type="RNSR">198318250R</idno>
          <idno type="ROR">https://ror.org/01nzkaw91</idno>
          <orgName>Inria Sophia Antipolis - Méditerranée</orgName>
          <orgName type="acronym">CRISAM</orgName>
          <desc>
            <address>
              <addrLine>2004 route des Lucioles BP 93 06902 Sophia Antipolis</addrLine>
              <country key="FR" />
            </address>
            <ref type="url">http://www.inria.fr/centre/sophia/</ref>
          </desc>
          <listRelation>
            <relation active="#struct-300009" type="direct" />
          </listRelation>
        </org>
        <org type="institution" xml:id="struct-300009" status="VALID">
          <idno type="ROR">https://ror.org/02kvxyf05</idno>
          <orgName>Institut National de Recherche en Informatique et en Automatique</orgName>
          <orgName type="acronym">Inria</orgName>
          <desc>
            <address>
              <addrLine>Domaine de VoluceauRocquencourt - BP 10578153 Le Chesnay Cedex</addrLine>
              <country key="FR" />
            </address>
            <ref type="url">http://www.inria.fr/en/</ref>
          </desc>
        </org>
        <org type="department" xml:id="struct-452156" status="VALID">
          <orgName>Scalable and Pervasive softwARe and Knowledge Systems</orgName>
          <orgName type="acronym">Laboratoire I3S - SPARKS</orgName>
          <date type="start">2016-03-03</date>
          <desc>
            <address>
              <addrLine>Laboratoire I3SCS 4012106903 Sophia Antipolis Cedex</addrLine>
              <country key="FR" />
            </address>
            <ref type="url">http://www.i3s.unice.fr/sparks</ref>
          </desc>
          <listRelation>
            <relation active="#struct-13009" type="direct" />
            <relation active="#struct-117617" type="indirect" />
            <relation name="UMR7271" active="#struct-441569" type="indirect" />
            <relation active="#struct-1039632" type="indirect" />
          </listRelation>
        </org>
        <org type="laboratory" xml:id="struct-13009" status="VALID">
          <orgName>Laboratoire d'Informatique, Signaux, et Systèmes de Sophia Antipolis</orgName>
          <orgName type="acronym">I3S</orgName>
          <desc>
            <address>
              <addrLine>2000, route des Lucioles - Les Algorithmes - bât. Euclide B 06900 Sophia Antipolis</addrLine>
              <country key="FR" />
            </address>
            <ref type="url">http://www.i3s.unice.fr/</ref>
          </desc>
          <listRelation>
            <relation active="#struct-117617" type="direct" />
            <relation name="UMR7271" active="#struct-441569" type="direct" />
            <relation active="#struct-1039632" type="direct" />
          </listRelation>
        </org>
        <org type="institution" xml:id="struct-117617" status="VALID">
          <idno type="IdRef">026403498</idno>
          <idno type="ISNI">0000000123372892</idno>
          <idno type="ROR">https://ror.org/02k9vew78</idno>
          <orgName>Université Nice Sophia Antipolis (1965 - 2019)</orgName>
          <orgName type="acronym">UNS</orgName>
          <date type="start">1965-10-23</date>
          <date type="end">2019-12-31</date>
          <desc>
            <address>
              <addrLine>Parc Valrose, 06100 Nice</addrLine>
              <country key="FR" />
            </address>
            <ref type="url">http://unice.fr/</ref>
          </desc>
        </org>
        <org type="regroupinstitution" xml:id="struct-441569" status="VALID">
          <idno type="IdRef">02636817X</idno>
          <idno type="ISNI">0000000122597504</idno>
          <idno type="ROR">https://ror.org/02feahw73</idno>
          <orgName>Centre National de la Recherche Scientifique</orgName>
          <orgName type="acronym">CNRS</orgName>
          <date type="start">1939-10-19</date>
          <desc>
            <address>
              <country key="FR" />
            </address>
            <ref type="url">https://www.cnrs.fr/</ref>
          </desc>
        </org>
        <org type="regroupinstitution" xml:id="struct-1039632" status="VALID">
          <idno type="IdRef">241035694</idno>
          <idno type="ROR">https://ror.org/019tgvf94</idno>
          <orgName>Université Côte d'Azur</orgName>
          <orgName type="acronym">UniCA</orgName>
          <date type="start">2020-01-01</date>
          <desc>
            <address>
              <addrLine>Parc Valrose, 28, avenue Valrose 06108 Nice Cedex 2</addrLine>
              <country key="FR" />
            </address>
            <ref type="url">https://univ-cotedazur.fr</ref>
          </desc>
        </org>
      </listOrg>
    </back>
  <teiCorpus>
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Song Lyrics Summarization Inspired by Audio Thumbnailing</title>
				<funder ref="#_mxBdYgj">
					<orgName type="full">Agence Nationale de la Recherche</orgName>
					<orgName type="abbreviated">ANR</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher />
				<availability status="unknown"><licence /></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Michael</forename><surname>Fell</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Université Côte d'Azur</orgName>
								<orgName type="institution" key="instit2">CNRS</orgName>
								<orgName type="institution" key="instit3">Inria</orgName>
								<address>
									<region>I3S</region>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Elena</forename><surname>Cabrio</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Université Côte d'Azur</orgName>
								<orgName type="institution" key="instit2">CNRS</orgName>
								<orgName type="institution" key="instit3">Inria</orgName>
								<address>
									<region>I3S</region>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Fabien</forename><surname>Gandon</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Université Côte d'Azur</orgName>
								<orgName type="institution" key="instit2">CNRS</orgName>
								<orgName type="institution" key="instit3">Inria</orgName>
								<address>
									<region>I3S</region>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Alain</forename><surname>Giboin</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Université Côte d'Azur</orgName>
								<orgName type="institution" key="instit2">CNRS</orgName>
								<orgName type="institution" key="instit3">Inria</orgName>
								<address>
									<region>I3S</region>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Song Lyrics Summarization Inspired by Audio Thumbnailing</title>
					</analytic>
					<monogr>
						<imprint>
							<date />
						</imprint>
					</monogr>
					<idno type="MD5">5890B99F0AE91DC00C4EAA2BC38852A2</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-04-12T14:45+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid" />
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div><p>Given the peculiar structure of songs, applying generic text summarization methods to lyrics can lead to the generation of highly redundant and incoherent text. In this paper, we propose to enhance state-of-the-art text summarization approaches with a method inspired by audio thumbnailing. Instead of searching for the thumbnail clues in the audio of the song, we identify equivalent clues in the lyrics. We then show how these summaries that take into account the audio nature of the lyrics outperform the generic methods according to both an automatic evaluation and human judgments.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div><head n="1">Introduction</head><p>Automatic text summarization is the task of producing a concise and fluent summary while preserving key information content and overall meaning of a text <ref type="bibr" target="#b0">(Allahyari et al., 2017)</ref>. Numerous approaches have been developed to address this task and applied widely in various domains including news articles <ref type="bibr" target="#b7">(Cheng and Lapata, 2016)</ref>, scientific papers <ref type="bibr" target="#b24">(Mei and Zhai, 2008)</ref>, web content as blogs <ref type="bibr" target="#b16">(Hu et al., 2007)</ref>, customer reviews <ref type="bibr" target="#b33">(Pecar, 2018)</ref> and social media messages <ref type="bibr" target="#b14">(He and Duan, 2018)</ref>. Just as we may need to summarize a story, we may also need to summarize song lyrics, for instance to produce adequate snippets for a search engine dedicated to an online song collection or for music digital libraries. From a linguistic point of view however, lyrics are a very peculiar genre of document and generic summarization methods may not be appropriate when the input for summarization comes from a specific domain or type of genre as songs are <ref type="bibr" target="#b28">(Nenkova et al., 2011)</ref>. Compared to news documents, for instance, lyrics have a very different structure. Given the repeating forms, peculiar structure (e.g. the segmentation into verse, chorus, etc.) and other unique characteristics of song lyrics, we need the summariza-tion algorithms to take advantage of these additional elements to more accurately identify relevant information in song lyrics. But just as such characteristics enable the exploration of new approaches, other characteristics make the application of summarization algorithms very challenging, as the presence of repeated lines, the discourse structure that strongly depends on the interrelation of music and words in the melody composition, the heterogeneity of musical genres each featuring peculiar styles and wording <ref type="bibr" target="#b5">(Brackett, 1995)</ref>, and simply the fact that not all songs tell a story.</p><p>In this direction, this paper focuses on the following research questions: What is the impact of the context in summarizing song lyrics?. This question is broken down into two sub questions: 1) How do generic text summarization methods perform over lyrics? and 2) Can such peculiar context be leveraged to identify relevant sentences to improve song text summarization? To answer our research questions, we experiment with generic unsupervised state-of-the-art text summarization methods (i.e. <software>TextRank</software>, and a topic distribution based method) to perform lyrics summarization, and show that adding contextual information helps such models to produce better summaries. Specifically, we enhance text summarization approaches with a method inspired by audio thumbnailing techniques, that leverages the repetitive structure of song texts to improve summaries. We show how summaries that take into account the audio nature of the lyrics outperform the generic methods according to both an automatic evaluation over 50k lyrics, and judgments of 26 human subjects.</p><p>In the following, Section 2 reports on related work. Section 3 presents the lyrics summarization task and the proposed methods. Sections 4 and 5 report on the experiments and on the evaluation, respectively. Section 6 concludes the paper. This section reports on the related work on both text and audio summarization methods.</p></div>
<div><head n="2.1">Text Summarization</head><p>In the literature, there are two different families of approaches for automatic text summarization: extraction and abstraction <ref type="bibr" target="#b0">(Allahyari et al., 2017)</ref>. Extractive summarization methods identify important elements of the text and generate them verbatim (they depend only on extraction of sentences or words from the original text). In contrast, abstractive summarization methods interpret and examine the text to generate a new shorter text that conveys the most critical information from the original text. Even though summaries created by humans are usually not extractive, most of the summarization research has focused on extractive methods. Purely extractive summaries often give better results <ref type="bibr" target="#b27">(Nallapati et al., 2016)</ref>, due to the fact that latter methods cope with more complex problems such as semantic representation, inference and natural language generation. Existing abstractive summarizers often rely on an extractive pre-processing component to produce the abstract of the text <ref type="bibr" target="#b4">(Berg-Kirkpatrick et al., 2011;</ref><ref type="bibr" target="#b19">Knight and Marcu, 2000)</ref>. Consequently, in this paper we focus on extractive summarization methods, also given the fact that lyrics i) strongly use figurative language which makes abstractive summarization even more challenging; and ii) the choice of the words by the composer may also have an importance for capturing the style of the song.</p><p>In the following, we focus on unsupervised methods for text summarization, the ones targeted in our study (no available gold-standard of humanproduced summaries of song texts exists). Most methods have in common the process for summary generation: given a text, the importance of each sentence of that text is determined. Then, the sentences with highest importance are selected to form a summary. The ways different summarizers determine the importance of each sentence may differ: Statistics-based summarizers extract indicator features from each sentence, e.g. <ref type="bibr" target="#b12">(Fattah and Ren, 2009)</ref> use among others the sentence position and length and named entities as features. Topicbased summarizers aim to represent each sentence by its underlying topics. For instance, <ref type="bibr" target="#b15">(Hennig, 2009)</ref> apply Probabilistic Latent Semantic Analysis, while Latent Dirichlet Allocation is used in <ref type="bibr" target="#b1">(Arora and Ravindran, 2008)</ref> to model each sentence's distribution over latent topics. Another type of summarization methods is graph-based summarizers. Three of the most popular graphbased summarizers are <software ContextAttributes="used">TextRank</software> <ref type="bibr">(Mihalcea and Tarau, 2004)</ref>, LexRank <ref type="bibr" target="#b9">(Erkan and Radev, 2004)</ref>, and <ref type="bibr">(Parveen et al., 2015)</ref>. These methods work by constructing a graph whose nodes are sentences and whose graph edge weights are sentence similarities. Then, the sentences that are central to the graph are found by computing the PageRank <ref type="bibr" target="#b30">(Page et al., 1999)</ref>. Contrarily to all previously described methods, systems using supervised machine learning form another type of summarizers. For instance, (Fattah, 2014) treats extractive summarization as a binary classification task, where they extract indicator features from sentences of gold summaries and learn to detect the sentences that should be included in a summary.</p><p>Context-Specific Summarization. If specific knowledge about the application scenario or the domain of the summarized text is available, generic summarization methods can be adapted to take into account the prior information. In querybased summarization <ref type="bibr" target="#b29">(Otterbacher et al., 2005;</ref><ref type="bibr" target="#b38">Wang et al., 2016)</ref>, the user's query is taken into account when generating a summary. Summarization of a scientific paper can be improved by considering the citations of it, as in <ref type="bibr">(Delort et al., 2003)</ref>. However, to the best of our knowledge no summarization methods have been proposed for the domain of song texts. In this paper we present a summarization method that uses prior knowledge about the text it summarizes to help generic summarizers generate better summaries.</p><p>Evaluation Criteria and Methods. Summaries should i) contain the most important information from input documents, ii) not contain redundant information, iii) be readable, hence they should be grammatical and coherent <ref type="bibr">(Parveen and Strube, 2015)</ref>. While a multitude of methods to identify important sentences has been described above, several approaches aim to make summaries less redundant and more coherent. The simplest way to evaluate summaries is to let humans assess the quality, but this is extremely expensive. The factors that humans must consider when giving scores to each candidate summary are grammaticality, non redundancy, integration of most important pieces of information, structure and coherence <ref type="bibr" target="#b35">(Saggion and Poibeau, 2013)</ref>. The more common way is to let humans generate possibly multiple summaries for a text and then automatically assess how close a machine-made summary is to the human gold summaries computing ROUGE scores <ref type="bibr" target="#b21">(Lin, 2004)</ref>, which boils down to measuring ngram overlaps between gold summaries and automatic summary. More recently there have been attempts to rate summaries automatically without the need for gold summaries <ref type="bibr" target="#b28">(Nenkova et al., 2011)</ref>. The key idea is that a summary should be similar to the original text in regard to characteristic criteria as the word distribution. <ref type="bibr" target="#b23">(Mackie et al., 2014)</ref> find that topic words are a suitable metric to automatically evaluate micro blog summaries.</p></div>
<div><head n="2.2">Audio Summarization</head><p>Lyrics are texts that accompany music. Therefore, it is worthwhile to see if methods in audio summarization can be transferred to lyrics summarization. In audio summarization the goal is to find the most representative parts in a song, in Pop songs those are usually the chorus and the bridge, in instrumental music the main theme. The task of creating short audio summaries is also known as audio thumbnailing <ref type="bibr" target="#b3">(Bartsch and Wakefield, 2005;</ref><ref type="bibr" target="#b6">Chai and Vercoe, 2003;</ref><ref type="bibr" target="#b20">Levy et al., 2006)</ref>, as the goal is to produce a short representation of the music that fits onto a thumbnail, but still covers the most representative parts of it. In a recent approach of audio thumbnailing <ref type="bibr" target="#b17">(Jiang and Müller, 2015)</ref>, the authors generate a Double Thumbnail from a musical piece by finding the two most representative parts in it. For this, they search for candidate musical segments in an a priori unsegmented song. Candidate musical segments are defined as sequences of music that more or less exactly repeat themselves. The representativeness of each candidate segment to the whole piece is then estimated by their fitness metric. They define the fitness of a segment as a trade-off between how exactly a part is repeated and how much of the whole piece is covered by all repetitions of that segment. Then, the audio segments along with their fitness allow them to create an audio double thumbnail consisting of the two fittest audio segments.</p></div>
<div><head n="3">Lyrics Summarization</head><p>Song texts are arranged in segments and lines. For instance the song text depicted in Figure <ref type="figure" target="#fig_0">1</ref> consists of 8 segments and 38 lines. Given a song text S consisting of n lines of text, S = (x 1 , ..., x n ), we define the task of extractive lyrics summarization as the task of producing a concise summary sum of the song text, consisting of a subset of the original text lines: sum(S) ⊆ S, where usually |sum(S)| &lt;&lt; |S|. We define the goal of a summary as to preserve key information and the overall meaning of a song text. To address this task, we apply the following methods from the literature: the popular graph-based summarizer <software ContextAttributes="used">TextRank</software>; an adaptation of a topic-based method (<software ContextAttributes="used">TopSum</software>). Moreover, we introduce a method inspired by audio thumbnailing (which we dub Lyrics <software ContextAttributes="used">Thumbnail</software>) which aims at creating a summary from the most representative parts of the original song text. While for <software ContextAttributes="used">TextRank</software> we rely on the off-the-shelf implementation of <ref type="bibr" target="#b2">(Barrios et al., 2016)</ref>, in the following we describe the other two methods.</p></div>
<div><head n="3.1">TopSum</head><p>We implement a simple topic-based summarization model that aims to construct a summary whose topic distribution is as similar as possible to that of the original text. Following <ref type="bibr" target="#b18">(Kleedorfer et al., 2008)</ref>, we train a topic model by factorizing a tf-idf-weighted term-document matrix of a song text corpus (see Section 4.2) using non-negative matrix factorization into a term-topic and a topicdocument matrix. Given the learnt term-topic matrix, we compute a topic vector t for each new document (song text). In order to treat t as a (pseudo-) probability distribution over latent topics t i , we normalize t by applying λt.t/ t i ∈t t i to it. Given the distributions over latent topics for each song text, we then incrementally construct a summary by greedily adding one line from the original text at a time (same mechanism as in KLSum algorithm in <ref type="bibr" target="#b13">(Haghighi and Vanderwende, 2009</ref>)); that line x * of the original text that minimizes the distance between the topic distribution t S of the original text S and the topic distribution of the incremental summary sum(S):</p><formula xml:id="formula_0">x * = argmin x∈(S\sum(S)) {W (t S , t sum(S)+x )}</formula><p>W is the Wasserstein distance <ref type="bibr" target="#b37">(Villani, 2008)</ref> and is used to measure the distance between two probability distributions (an alternative to Jensen-Shannon divergence <ref type="bibr" target="#b22">(Louis and Nenkova, 2013)</ref>). </p></div>
<div><head n="3.2">Lyrics Thumbnail</head><p>Inspired by <ref type="bibr" target="#b17">(Jiang and Müller, 2015)</ref>, we transfer their fitness measure for audio segments to compute the fitness of lyrics segments. Analog to an audio thumbnail, we define a Lyrics <software ContextAttributes="used">Thumbnail</software> as the most representative and repetitive part of the song text. Consequently, it usually consists of (a part of) the chorus. In our corpus the segments are annotated (as double line breaks in the lyrics), so unlike in audio thumbnailing, we do not have to induce segments, but rather measure their fitness. In the following, we describe the fitness measure for lyrics segments and how we use this to produce a summary of the lyrics.</p><p>Lyrics Fitness Given a segmented song text S = (S 1 , ..., S m ) consisting of text segments S i , where each S i consists of |S i | text lines, we cluster the S i into partitions of similar segments. For instance, the lyrics in Figure <ref type="figure" target="#fig_0">1</ref> consists of 8 segments and 38 lines and the cluster of chorus consists of {S 5 , S 6 , S 7 }. The fitness F it of the segment cluster C ⊆ S is defined through the precision pr of the cluster and the coverage co of the cluster. pr describes how similar the segments in C are to each other while co is the relative amount of lyrics lines covered by C:</p><formula xml:id="formula_1">pr(C) = ( S i ,S j ∈C i&lt;j 1) -1 • S i ,S j ∈C i&lt;j sim(S i , S j ) co(C) = ( S i ∈S |S i |) -1 • S i ∈C |S i |</formula><p>where sim is a normalized similarity measure between text segments. F it is the harmonic mean between pr and co. The fitness of a segment S i is defined as the fitness of the cluster to which S i belongs:</p><formula xml:id="formula_2">∀S i ∈ C : F it(S i ) = F it(C) = 2 pr(C) • co(C) pr(C) + co(C)</formula><p>For lyrics segments without repetition the fitness is defined as zero. Based on the fitness F it for segments, we define a fitness measure for a text line x. This allows us to compute the fitness of arbitrary summaries (with no or unknown segmentation). If the text line x occurs f i (x) times in text segment S i , then its line fitness f it is defined as:</p><formula xml:id="formula_3">f it(x) = ( S i ∈S f i (x)) -1 • S i ∈S f i (x) • F it(S i )</formula><p>Fitness-Based Summary Analog to <ref type="bibr" target="#b17">(Jiang and Müller, 2015)</ref>'s audio thumbnails, we create fitness-based summaries for a song text. A Lyrics Double <software ContextAttributes="used">Thumbnail</software> consists of two segments: one from the fittest segment cluster (usually the chorus), and one from the second fittest segment cluster (usually the bridge).<ref type="foot" target="#foot_0">1</ref> If the second fittest cluster has a fitness of 0, we generate a Lyrics Single <software ContextAttributes="used">Thumbnail</software> solely from the fittest cluster (usually the chorus). If the thumbnail generated has a length of k lines and we want to produce a summary of p &lt; k lines, we select the p lines in the middle of the thumbnail following <ref type="bibr" target="#b6">(Chai and Vercoe, 2003)</ref>'s "Section-transition Strategy" that they find to capture the "hook" of the music more likely.<ref type="foot" target="#foot_1">2</ref> </p></div>
<div><head n="4">Experimental Setting</head><p>We now describe the WASABI dataset of song lyrics (Section 4.1), and the tested configurations of the summarization methods (Section 4.2).</p></div>
<div><head n="4.1">Dataset</head><p>From the WASABI corpus <ref type="bibr" target="#b25">(Meseguer-Brocal et al., 2017)</ref> we select a subset of 190k unique song texts with available genre information. As the corpus has spurious genres (416 different ones), we focus on the 10 most frequent ones in order to evaluate our methods dependent on the genre. We add 2 additional genres from the underrepresented Rap field (Southern Hip Hop and Gangsta Rap). The dataset contains 95k song lyrics.</p><p>To define the length of sum(S) (see Section 3), we rely on <ref type="bibr" target="#b3">(Bartsch and Wakefield, 2005</ref>) that recommend to create audio thumbnails of the median length of the chorus on the whole corpus. We therefore estimate the median chorus length on our corpus by computing a Lyrics Single <software ContextAttributes="used">Thumbnail</software> on each text, and we find the median chorus length to be 4 lines. Hence, we decide to generate summaries of such length for all lyrics and all summarization models to exclude the length bias in the methods comparison<ref type="foot" target="#foot_2">3</ref> . As the length of the lyrics thumbnail is lower-bounded by the length of the chorus in the song text, we keep only those lyrics with an estimated chorus length of at least 4. The final corpus of 12 genres consists of 50k lyrics with the following genre distribution: Rock: 8.4k, Country: 8.3k, Alternative Rock: 6.6k, Pop: 6.9k, R&amp;B: 5.2k, Indie Rock: 4.4k, Hip Hop: 4.2k, Hard Rock: 2.4k, Punk Rock: 2k, Folk: 1.7k, Southern Hip Hop: 281, Gangsta Rap: 185.</p></div>
<div><head n="4.2">Models and Configurations</head><p>We create summaries using the three summarization methods described in Section 3, i.e. a graphbased (<software ContextAttributes="used">TextRank</software>), a topic-based (<software ContextAttributes="used">TopSum</software>), and fitness-based (Lyrics <software ContextAttributes="used">Thumbnail</software>) method, plus two additional combined models (described below). While the Lyrics <software ContextAttributes="used">Thumbnail</software> is generated from the full segment structure of the lyrics including its duplicate lines, all other models are fed with unique text lines as input (i.e. rendundant lines are deleted). This is done to produce less redundant summaries, given that for instance, <software ContextAttributes="used">Tex-tRank</software> scores each duplicate line the same, hence it may create summaries with all identical lines. <software ContextAttributes="used">TopSum</software> can suffer from a similar shortcoming: if there is a duplicate line close to the ideal topic distribution, adding that line again will let the incremental summary under construction stay close to the ideal topic distribution. All models were instructed to produce summaries of 4 lines, as this is the estimated median chorus length in our corpus (see Section 4.1). The summary lines were arranged in the same order they appear in the original text. <ref type="foot" target="#foot_3">4</ref> We use the <software ContextAttributes="used">TextRank</software> implementation<ref type="foot" target="#foot_4">5</ref> of <ref type="bibr" target="#b2">(Barrios et al., 2016)</ref> without removing stop words (lyrics lines in input can be quite short, therefore we avoid losing all content of the line if removing stop words). The topic model for Top-Sum is built using non-negative matrix factorization with scikit-learn<ref type="foot" target="#foot_5">6</ref>  <ref type="bibr" target="#b34">(Pedregosa et al., 2011)</ref> for 30 topics on the full corpus of 190k lyrics. <ref type="foot" target="#foot_6">7</ref> For the topical distance, we only consider the distance between the 3 most relevant topics in the original text, following the intuition that one song text usually covers only a small amount of topics. The Lyrics <software ContextAttributes="used">Thumbnail</software> is computed using String-based distance between text segments to facilitate clustering. This similarity has been shown in <ref type="bibr" target="#b39">(Watanabe et al., 2016)</ref> to indicate segment borders successfully. In our implementation, segments are clustered using the DBSCAN <ref type="bibr" target="#b10">(Ester et al., 1996)</ref> algorithm. <ref type="foot" target="#foot_7">8</ref> We also produce two summaries by combining <software ContextAttributes="used">TextRank</software> + <software ContextAttributes="used">TopSum</software> and <software ContextAttributes="used">TextRank + TopSum</software> + Lyrics <software ContextAttributes="used">Thumbnail</software>, to test if summaries can benefit from the complementary perspectives the three different summarization methods take.</p><p>Model Combination For any lyrics line, we can obtain a score from each of the applied methods. <software>TextRank</software> provides a score for each line, <software ContextAttributes="created">TopSum</software> provides a distance between the topic distributions of an incremental summary and the original text, and f it provides the fitness of each line. We treat our summarization methods as blackboxes and use a simple method to combine the scores the different methods provide for each line. Given the original text separated into lines S = (x 1 , ..., x n ), a summary is constructed by greedily adding one line x * at a time to the incremental summary sum(S) ⊆ S such that the sum of normalized ranks of all scores is minimal:</p><formula xml:id="formula_4">x * = argmin x { A R A (x)}</formula><p>Here x ∈ (S \ sum(S)) and A ∈ {TextRank, <software>TopSum</software>, fit}.</p><p>The normalized rank R A (x) of the score that method A assigns to line x is computed as follows: first, the highest scores<ref type="foot" target="#foot_8">9</ref> are assigned rank 0, the second highest scores get rank 1, and so forth. Then the ranks are linearly scaled to the [0,1] interval, so each sum of ranks</p><formula xml:id="formula_5">A R A (x) is in [0,3].</formula><p>Model Nomenclature For abbreviation, we call the <software>TextRank</software> model henceforth M r , the Top-Sum model M s , the fitness-based summarizer M f , model combinations M rs and M rsf , respectively.</p></div>
<div><head n="5">Evaluation</head><p>We evaluate the quality of the produced lyrics summary both soliciting human judgments on the goodness and utility of a given summary (Section 5.1), and through an automatic evaluation of the summarization methods (Section 5.2) to provide a comprehensive evaluation.</p></div>
<div><head n="5.1">Human Evaluation</head><p>We performed human evaluation of the different summarization methods introduced before by asking participants to rate the different summaries presented to them by specifying their agreement / disagreement according to the following standard criteria <ref type="bibr">(Parveen and Strube, 2015)</ref>:</p><p>Informativeness: The summary contains the main points of the original song text.</p><p>Non-redundancy: The summary does not contain duplicate or redundant information.</p><p>Coherence: The summary is fluent to read and grammatically correct. Plus one additional criterion coming from our definition of the lyrics summarization task:</p><p>Meaning: The summary preserves the meaning of the original song text.</p></div>
<div><head>An experimental psychologist expert in Human</head><p>Computer Interaction advised us in defining the questionnaire and setting up the experiment. 26 participants -12 nationalities, 18 men, 8 women, aged from 21 to 59 -were taking a questionnaire (Google Forms), consisting of rating 30 items with respect to the criteria defined before on a Likert scale from 1 (low) to 5 (high). Each participant was presented with 5 different summaries -each produced by one of the previously described summarization models -for 6 different song texts. Participants were given example ratings for the different criteria in order to familiarize them with the procedure. Then, for each song text, the original song text along with its 5 summaries were presented in random order and had to be rated according to the above criteria. For the criterion of Meaning, we asked participants to give a short explanation in free text for their score. The selected 6 song texts 10 have a minimum and a median chorus length of 4 lines and are from different genres, i.e. Pop/Rock (4), Folk (1) and Rap (1), similar to our corpus genre distribution. Song texts were selected from different lengths (18-63 lines), genders of singer (3 male, 3 female), topics (family, life, drugs, relationship, depression), and mood (depressive, angry, hopeful, optimistic, energetic). The artist name and song title were not shown to the participants.</p></div>
<div><head>Results</head><p>Figure <ref type="figure" target="#fig_1">2</ref> shows the ratings obtained for each criterion. We examine the significant differences between the models performances by performing a paired two-tailed t-test. The significance levels are: 0.05 * , 0.01 * * , 0.001 * * * , and n.s. First, Informativeness and Meaning are rated higher * * for the combined model M rs compared to the single models M r and M s . Combining all three models improves the summaries further: both for Informativeness and Meaning the model M rsf is rated higher * * * than M rs . Further, summaries created by M rsf are rated higher * * * in Coherence than summaries from any other modelexcept from M f (n.s. difference). Summaries are rated on the same level (n.s. differences) for Non-redundancy in all but the M r and M f summaries, which are perceived as lower * * * in Nonredundancy than all others. Note, how the model M rsf is more stable than all others by exhibiting lower standard deviations in all criteria except 10 "Pills N Potions" by Nicki Minaj, "Hurt" by Nine Inch Nails, "Real to me" by Brian McFadden, "Somebody That I Used To Know" by Gotye, "Receive" by Alanis Morissette, "Let's Start A Band" by Amy MacDonald Overall, leveraging the Lyrics Fitness in a song text summary improves summary quality. Especially with respect to the criteria that, we believe, indicate the summary quality the most -Informativeness and Meaning -the M rsf method is significantly better performing and more consistent.</p><p>Figure <ref type="figure" target="#fig_0">1</ref> shows an example song text and example summaries from the experiment. Summary 1 is generated by M f and consists of the chorus. Summary 2 is made by the method M rsf and has relevant parts of the verses and the chorus, and was rated much higher in Informativeness and Meaning. We analyzed the free text written by the participants to comment on the Meaning criterion, but no relevant additional information was provided (the participants mainly summarized their ratings).</p></div>
<div><head n="5.2">Automatic Evaluation</head><p>We computed four different indicators of summary quality on the dataset of 50k songs described in Section 4.1. Three of the criteria use the similarity between probability distributions P, Q, which means we compute the Wasserstein distance between P and Q (cf. Section 3.1) and apply λx. x -1 to it. <ref type="foot" target="#foot_9">11</ref> The criteria are:</p><p>Distributional Semantics: similarity between the word distributions of original and summary, cf. <ref type="bibr" target="#b22">(Louis and Nenkova, 2013)</ref>. We give results relative to the similarity of the best performing model (=100%).</p><p>Topical: similarity between the topic distributions of original and summary. Restricted to the 3 most relevant topics of the original song text. We give results relative to the similarity of the best performing model (=100%).</p><p>Coherence: average similarity between word distributions in consecutive sentences of the summary, cf. <ref type="bibr" target="#b36">(ShafieiBavani et al., 2018)</ref>. We give results relative to the coherence of the original song text (=100%).</p><p>Lyrics fitness: average line-based fitness f it (cf. Section 3) of the lines in the summary. We give results relative to the Lyrics fitness of the original song text (=100%).</p><p>Results When evaluating each of the 12 genres, we found two clusters of genres to behave very similarly. Therefore, we report the results for these two groups: the Rap genre cluster contains Hip Hop, Southern Hip Hop, and Gangsta Rap. The Rock / Pop cluster contains the 9 other genres. Results of the different automatic evaluation metrics are shown in Table <ref type="table" target="#tab_0">1</ref>. Distributional Semantics metrics have previously been shown <ref type="bibr" target="#b22">(Louis and Nenkova, 2013;</ref><ref type="bibr" target="#b36">ShafieiBavani et al., 2018)</ref> to highly correlate with user responsiveness judgments. We would expect correlations of this metric with Informativeness or Meaning criteria therefore, as those criteria are closest to responsiveness, but we have found no large differences between the different models for this criterion. The summaries of the M s model have the highest similarity to the original text and the M f have the lowest similarity of 90%. The difference between the highest and lowest values are low.</p><p>For the Topical similarity, the results are mostly in the same order as the Distributional Semantics ones, but with much larger differences. While the M s model reaches the highest similarity, this is a self-fulfilling prophecy, as summaries of M s were generated with the objective of maximizing topical similarity. The other two models that incorporate M s (M rs and M rsf ), show a much higher topical similarity to the original text than M r and M f .</p><p>Coherence is rated best in M r with 110%. All other models show a coherence close to that of the original text -between 97% and 101%. We believe that the increased coherence of M r is not linguistically founded, but merely algorithmic. M r produces summaries of the most central sentences in a text. The centrality is using the concept of sentence similarity. Therefore, M r implicitly optimizes for the automatic evaluation metric of coherence, based on similar consecutive sentences. Sentence similarity seems to be insufficient to predict human judgments of coherence in this case.</p><p>As might be expected, methods explicitly incorporating the Lyrics fitness produce summaries with a fitness much higher than the original text -214% for the M f and 191% for the M rsf model. The methods not incorporating fitness produce summaries with much lower fitness than the original -M r 62%, M s 47%, and M rs 55%. In the Rap genre this fitness is even zero, i.e. summaries (in median) contain no part of the chorus.</p><p>Overall, no single automatic evaluation criterion was able to explain the judgments of our human participants. However, considering Topical similarity and fitness together gives us a hint. The model M f has high fitness (214%), but low Topical similarity (42%). The M s model has the highest Topical similarity (100%), but low fitness (47%). M rsf might be preferred by humans as it strikes a balance between Topical similarity (64%) and fitness (191%). Hence, M rsf succeeds in capturing lines from the most relevant parts of the lyrics, such as the chorus, while jointly representing the important topics of the song text.</p></div>
<div><head n="6">Conclusion</head><p>In this paper we have defined and addressed the task of lyrics summarization. We have applied both generic unsupervised text summarization methods (<software>TextRank</software> and a topic-based method we called <software ContextAttributes="created">TopSum</software>), and a method inspired by audio thumbnailing on 50k lyrics from the WASABI corpus. We have carried out an automatic evaluation on the produced summaries computing standard metrics in text summarization, and a human evaluation with 26 participants, showing that using a fitness measure transferred from the musicology literature, we can amend generic text summarization algorithms and produce better summaries.</p><p>In future work, we will model the importance of a line given the segment to avoid cutting off important parts of the chorus, as we sometimes observed. Moreover, we plan to address the challenging task of abstractive summarization over song lyrics, with the goal of creating a summary of song texts in prose-style -more similar to what humans would do, using their own words.</p></div><figure xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Song text of "Let's start a band" by Amy MacDonald along with two example summaries.</figDesc><graphic coords="5,72.00,62.81,453.55,179.02" type="bitmap" /></figure>
<figure xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Human ratings per summarization model in terms of average and standard deviation.</figDesc><graphic coords="8,128.69,62.81,340.15,176.61" type="bitmap" /></figure>
<figure type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Automatic evaluation results for the 5 summarization models and 2 genre clusters. Distributional Semantics and Topical are relative to the best model (=100%), Coherence and Fitness to the original text (=100%).</figDesc><table><row><cell>Evaluation criterion</cell><cell>Genre</cell><cell>Mr</cell><cell cols="3">Ms Mrs M f</cell><cell>M rsf</cell><cell>original text</cell></row><row><cell>Distributional Semantics [%]</cell><cell>Rock / Pop Rap</cell><cell>92 94 92</cell><cell>100 100 100</cell><cell>97 99 98</cell><cell>90 86 90</cell><cell>93 92 93</cell><cell>n/a</cell></row><row><cell /><cell>Rock / Pop</cell><cell>44</cell><cell>100</cell><cell>76</cell><cell>41</cell><cell>64</cell><cell /></row><row><cell>Topical [%]</cell><cell>Rap</cell><cell>58</cell><cell>100</cell><cell>80</cell><cell>48</cell><cell>66</cell><cell>n/a</cell></row><row><cell /><cell /><cell>46</cell><cell>100</cell><cell>77</cell><cell>42</cell><cell>64</cell><cell /></row><row><cell /><cell cols="2">Rock / Pop 110</cell><cell>95</cell><cell>99</cell><cell>99</cell><cell>100</cell><cell /></row><row><cell>Coherence [%]</cell><cell>Rap</cell><cell cols="2">112 115</cell><cell>112</cell><cell>107</cell><cell>107</cell><cell>100</cell></row><row><cell /><cell /><cell>110</cell><cell>97</cell><cell>101</cell><cell>100</cell><cell>101</cell><cell /></row><row><cell>Lyrics fitness [%]</cell><cell>Rock / Pop Rap</cell><cell>71 0 62</cell><cell>53 0 47</cell><cell>63 0 55</cell><cell>201 309 214</cell><cell>183 249 191</cell><cell>100</cell></row></table></figure>
			<note place="foot" n="1" xml:id="foot_0"><p>We pick the first occurring representative of the segment cluster. Which segment to pick from the cluster is a potential question for future work.</p></note>
			<note place="foot" n="2" xml:id="foot_1"><p>They also experiment with other methods to create a thumbnail, such as section initial or section ending.</p></note>
			<note place="foot" n="3" xml:id="foot_2"><p>We leave the study of other measures to estimate the summary length to future work.</p></note>
			<note place="foot" n="4" xml:id="foot_3"><p>In case of repeated parts, the first position of each line was used as original position.</p></note>
			<note place="foot" n="5" xml:id="foot_4"><p>https://github.com/summanlp/textrank</p></note>
			<note place="foot" n="6" xml:id="foot_5"><p>https://scikit-learn.org</p></note>
			<note place="foot" n="7" xml:id="foot_6"><p>loss='kullback-leibler'</p></note>
			<note place="foot" n="8" xml:id="foot_7"><p>eps=0.3, min samples=2   </p></note>
			<note place="foot" n="9" xml:id="foot_8"><p>In the case of topical distance, a "higher score" means a lower value.</p></note>
			<note place="foot" n="11" xml:id="foot_9"><p>This works as we always deal with distances &gt; 0.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgement</head><p>This work is partly funded by the <rs type="funder">French Research National Agency (ANR)</rs> under the <rs type="projectName">WASABI</rs> project (contract <rs type="grantNumber">ANR-16-CE23-0017-01</rs>).</p></div>
			</div>
			<listOrg type="funding">
				<org type="funded-project" xml:id="_mxBdYgj">
					<idno type="grant-number">ANR-16-CE23-0017-01</idno>
					<orgName type="project" subtype="full">WASABI</orgName>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Text summarization techniques: A brief survey</title>
		<author>
			<persName><forename type="first">Mehdi</forename><surname>Allahyari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Seyed</forename><surname>Amin Pouriyeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mehdi</forename><surname>Assefi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Saeid</forename><surname>Safaei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elizabeth</forename><forename type="middle">D</forename><surname>Trippe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Juan</forename><forename type="middle">B</forename><surname>Gutierrez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Krys</forename><surname>Kochut</surname></persName>
		</author>
		<idno>CoRR, abs/1707.02268</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Latent dirichlet allocation based multi-document summarization</title>
		<author>
			<persName><forename type="first">Rachit</forename><surname>Arora</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Balaraman</forename><surname>Ravindran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the second workshop on Analytics for noisy unstructured text data</title>
		<meeting>the second workshop on Analytics for noisy unstructured text data</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="91" to="97" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Variations of the similarity function of textrank for automated summarization</title>
		<author>
			<persName><forename type="first">Federico</forename><surname>Barrios</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Federico</forename><surname>López</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luis</forename><surname>Argerich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rosa</forename><surname>Wachenchauzer</surname></persName>
		</author>
		<idno>CoRR, abs/1602.03606</idno>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Audio thumbnailing of popular music using chromabased representations</title>
		<author>
			<persName><forename type="first">Mark</forename><forename type="middle">A</forename><surname>Bartsch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gregory</forename><forename type="middle">H</forename><surname>Wakefield</surname></persName>
		</author>
		<idno type="DOI">10.1109/TMM.2004.840597</idno>
	</analytic>
	<monogr>
		<title level="j">Trans. Multi</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="96" to="104" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Jointly learning to extract and compress</title>
		<author>
			<persName><forename type="first">Taylor</forename><surname>Berg-Kirkpatrick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Gillick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="481" to="490" />
		</imprint>
	</monogr>
	<note>HLT '11</note>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<author>
			<persName><forename type="first">David</forename><surname>Brackett</surname></persName>
		</author>
		<title level="m">Interpreting Popular Music</title>
		<imprint>
			<publisher>Cambridge University Press</publisher>
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Music thumbnailing via structural analysis</title>
		<author>
			<persName><forename type="first">Wei</forename><surname>Chai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Barry</forename><surname>Vercoe</surname></persName>
		</author>
		<idno type="DOI">10.1145/957013.957057</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the eleventh ACM international conference on Multimedia</title>
		<meeting>the eleventh ACM international conference on Multimedia</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="223" to="226" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Neural summarization by extracting sentences and words</title>
		<author>
			<persName><forename type="first">Jianpeng</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mirella</forename><surname>Lapata</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P16-1046</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 54th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="484" to="494" />
		</imprint>
	</monogr>
	<note>Long Papers</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Enhanced web document summarization using hyperlinks</title>
		<author>
			<persName><forename type="first">Jean</forename><surname>Yves</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bernadette</forename><surname>Bouchon-Meunier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maria</forename><surname>Rifqi</surname></persName>
		</author>
		<idno type="DOI">10.1145/900051.900097</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fourteenth ACM Conference on Hypertext and Hypermedia, HYPERTEXT '03</title>
		<meeting>the Fourteenth ACM Conference on Hypertext and Hypermedia, HYPERTEXT '03<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="208" to="215" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Lexrank: Graph-based lexical centrality as salience in text summarization</title>
		<author>
			<persName><forename type="first">Günes</forename><surname>Erkan</surname></persName>
		</author>
		<author>
			<persName><surname>Dragomir R Radev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of artificial intelligence research</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="457" to="479" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A density-based algorithm for discovering clusters in large spatial databases with noise</title>
		<author>
			<persName><forename type="first">Martin</forename><surname>Ester</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hans-Peter</forename><surname>Kriegel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jörg</forename><surname>Sander</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaowei</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Kdd</title>
		<imprint>
			<biblScope unit="volume">96</biblScope>
			<biblScope unit="page" from="226" to="231" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A hybrid machine learning model for multi-document summarization</title>
		<author>
			<persName><forename type="first">Mohamed</forename><surname>Abdel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fattah</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied intelligence</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="592" to="600" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Ga, mr, ffnn, pnn and gmm based models for automatic text summarization</title>
		<author>
			<persName><forename type="first">Mohamed</forename><surname>Abdel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fattah</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Fuji</forename><surname>Ren</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.csl.2008.04.002</idno>
	</analytic>
	<monogr>
		<title level="j">Comput. Speech Lang</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="126" to="144" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Exploring content models for multi-document summarization</title>
		<author>
			<persName><forename type="first">Aria</forename><surname>Haghighi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lucy</forename><surname>Vanderwende</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics</title>
		<meeting>Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="362" to="370" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Twitter summarization based on social network and sparse reconstruction</title>
		<author>
			<persName><forename type="first">Ruifang</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xingyi</forename><surname>Duan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Topic-based multi-document summarization with probabilistic latent semantic analysis</title>
		<author>
			<persName><forename type="first">Leonhard</forename><surname>Hennig</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference RANLP-2009</title>
		<meeting>the International Conference RANLP-2009</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="144" to="149" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Comments-oriented blog summarization by sentence extraction</title>
		<author>
			<persName><forename type="first">Meishan</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aixin</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ee-Peng</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ee-Peng</forename><surname>Lim</surname></persName>
		</author>
		<idno type="DOI">10.1145/1321440.1321571</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Sixteenth ACM Conference on Conference on Information and Knowledge Management, CIKM '07</title>
		<meeting>the Sixteenth ACM Conference on Conference on Information and Knowledge Management, CIKM '07<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="901" to="904" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Estimating double thumbnails for music recordings</title>
		<author>
			<persName><forename type="first">Nanzhu</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Meinard</forename><surname>Müller</surname></persName>
		</author>
		<idno type="DOI">10.1109/ICASSP.2015.7177949</idno>
	</analytic>
	<monogr>
		<title level="m">2015 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="146" to="150" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Oh oh oh whoah! towards automatic topic detection in song lyrics</title>
		<author>
			<persName><forename type="first">Florian</forename><surname>Kleedorfer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Knees</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tim</forename><surname>Pohle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Ismir</title>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="287" to="292" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Statisticsbased summarization -step one: Sentence compression</title>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Knight</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Marcu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Seventeenth National Conference on Artificial Intelligence and Twelfth Conference on Innovative Applications of Artificial Intelligence</title>
		<meeting>the Seventeenth National Conference on Artificial Intelligence and Twelfth Conference on Innovative Applications of Artificial Intelligence</meeting>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="703" to="710" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Extraction of high-level musical structure from audio data and its application to thumbnail generation</title>
		<author>
			<persName><forename type="first">Mark</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><surname>Sandler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Casey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2006 IEEE International Conference on Acoustics Speech and Signal Processing Proceedings</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="V" to="V" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Rouge: A package for automatic evaluation of summaries</title>
		<author>
			<persName><forename type="first">Chin-Yew</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Text Summarization Branches Out</title>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Automatically assessing machine summary content without a gold standard</title>
		<author>
			<persName><forename type="first">Annie</forename><surname>Louis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ani</forename><surname>Nenkova</surname></persName>
		</author>
		<idno type="DOI">10.1162/COLI_a_00123</idno>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">On choosing an effective automatic evaluation metric for microblog summarisation</title>
		<author>
			<persName><forename type="first">Stuart</forename><surname>Mackie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Mccreadie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Craig</forename><surname>Macdonald</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Iadh</forename><surname>Ounis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 5th Information Interaction in Context Symposium</title>
		<meeting>the 5th Information Interaction in Context Symposium</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="115" to="124" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Generating impact-based summaries for scientific literature</title>
		<author>
			<persName><forename type="first">Qiaozhu</forename><surname>Mei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chengxiang</forename><surname>Zhai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">WASABI: a Two Million Song Database Project with Audio and Cultural Metadata plus WebAudio enhanced Client Applications</title>
		<author>
			<persName><forename type="first">Gabriel</forename><surname>Meseguer-Brocal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Geoffroy</forename><surname>Peeters</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guillaume</forename><surname>Pellerin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michel</forename><surname>Buffa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elena</forename><surname>Cabrio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Catherine</forename><forename type="middle">Faron</forename><surname>Zucker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alain</forename><surname>Giboin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Isabelle</forename><surname>Mirbel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Romain</forename><surname>Hennequin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Manuel</forename><surname>Moussallam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Francesco</forename><surname>Piccoli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Fillon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Web Audio Conference 2017 -Collaborative Audio #WAC2017</title>
		<meeting><address><addrLine>London, United King</addrLine></address></meeting>
		<imprint>
			<publisher>Queen Mary University of London</publisher>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Textrank: Bringing order into text</title>
		<author>
			<persName><forename type="first">Paul</forename><surname>Rada</surname></persName>
		</author>
		<author>
			<persName><surname>Tarau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2004 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2004 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Summarunner: A recurrent neural network based sequence model for extractive summarization of documents</title>
		<author>
			<persName><forename type="first">Ramesh</forename><surname>Nallapati</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Feifei</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bowen</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Automatic summarization</title>
		<author>
			<persName><forename type="first">Ani</forename><surname>Nenkova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kathleen</forename><surname>Mckeown</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Foundations and Trends R in Information Retrieval</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">2-3</biblScope>
			<biblScope unit="page" from="103" to="233" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Using random walks for questionfocused sentence retrieval</title>
		<author>
			<persName><forename type="first">Jahna</forename><surname>Otterbacher</surname></persName>
		</author>
		<author>
			<persName><surname>Günes ¸erkan</surname></persName>
		</author>
		<author>
			<persName><surname>Dragomir R Radev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the conference on Human Language Technology and Empirical Methods in Natural Language Processing</title>
		<meeting>the conference on Human Language Technology and Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="915" to="922" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">The pagerank citation ranking: Bringing order to the web</title>
		<author>
			<persName><forename type="first">Lawrence</forename><surname>Page</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sergey</forename><surname>Brin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rajeev</forename><surname>Motwani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Terry</forename><surname>Winograd</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999">1999</date>
		</imprint>
		<respStmt>
			<orgName>Stanford InfoLab</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Topical coherence for graph-based extractive summarization</title>
		<author>
			<persName><forename type="first">Daraksha</forename><surname>Parveen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hans-Martin</forename><surname>Ramsl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Strube</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1949" to="1954" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Integrating importance, non-redundancy and coherence in graph-based extractive summarization</title>
		<author>
			<persName><forename type="first">Daraksha</forename><surname>Parveen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Strube</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th International Conference on Artificial Intelligence, IJCAI'15</title>
		<meeting>the 24th International Conference on Artificial Intelligence, IJCAI'15</meeting>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1298" to="1304" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Towards opinion summarization of customer reviews</title>
		<author>
			<persName><forename type="first">Samuel</forename><surname>Pecar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL 2018, Student Research Workshop</title>
		<meeting>ACL 2018, Student Research Workshop</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Scikit-learn: Machine learning in Python</title>
		<author>
			<persName><forename type="first">Fabian</forename><surname>Pedregosa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gael</forename><surname>Varoquaux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexandre</forename><surname>Gramfort</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vincent</forename><surname>Michel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bertrand</forename><surname>Thirion</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Olivier</forename><surname>Grisel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mathieu</forename><surname>Blondel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Prettenhofer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ron</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vincent</forename><surname>Dubourg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jake</forename><surname>Vanderplas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexandre</forename><surname>Passos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Cournapeau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mathieu</forename><surname>Brucher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mathieu</forename><surname>Perrot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Edouard</forename><surname>Duchesnay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2825" to="2830" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<author>
			<persName><forename type="first">Horacio</forename><surname>Saggion</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thierry</forename><surname>Poibeau</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-642-28569-1_1</idno>
		<title level="m">Automatic Text Summarization: Past, Present and Future</title>
		<meeting><address><addrLine>Berlin, Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="3" to="21" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Summarization evaluation in the absence of human model summaries using the compositionality of word embeddings</title>
		<author>
			<persName><forename type="first">Elaheh</forename><surname>Shafieibavani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohammad</forename><surname>Ebrahimi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Raymond</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fang</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th International Conference on Computational Linguistics</title>
		<meeting>the 27th International Conference on Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="905" to="914" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Optimal transport: old and new</title>
		<author>
			<persName><forename type="first">Cédric</forename><surname>Villani</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008">2008</date>
			<publisher>Springer Science &amp; Business Media</publisher>
			<biblScope unit="volume">338</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<author>
			<persName><forename type="first">Lu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hema</forename><surname>Raghavan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vittorio</forename><surname>Castelli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Radu</forename><surname>Florian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Claire</forename><surname>Cardie</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1606.07548</idno>
		<title level="m">A sentence compression based framework to query-focused multi-document summarization</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Modeling discourse segments in lyrics using repeated patterns</title>
		<author>
			<persName><forename type="first">Kento</forename><surname>Watanabe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuichiroh</forename><surname>Matsubayashi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Naho</forename><surname>Orita</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Naoaki</forename><surname>Okazaki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kentaro</forename><surname>Inui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Satoru</forename><surname>Fukayama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tomoyasu</forename><surname>Nakano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jordan</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Masataka</forename><surname>Goto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: Technical Papers</title>
		<meeting>COLING 2016, the 26th International Conference on Computational Linguistics: Technical Papers</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="1959" to="1969" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</teiCorpus></text>
</TEI>