<?xml version='1.0' encoding='utf-8'?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" version="1.1" xsi:schemaLocation="http://www.tei-c.org/ns/1.0 http://api.archives-ouvertes.fr/documents/aofr-sword.xsd">
  <teiHeader>
    <fileDesc>
      <titleStmt>
        <title>HAL TEI export of lirmm-03714595</title>
      </titleStmt>
      <publicationStmt>
        <distributor>CCSD</distributor>
        <availability status="restricted">
          <licence target="http://creativecommons.org/licenses/by-nc-nd/">Attribution - NonCommercial - NoDerivatives</licence>
        </availability>
        <date when="2024-04-29T11:46:11+02:00" />
      </publicationStmt>
      <sourceDesc>
        <p part="N">HAL API platform</p>
      </sourceDesc>
    </fileDesc>
  </teiHeader>
  <text>
    <body>
      <listBibl>
        <biblFull>
          <titleStmt>
            <title xml:lang="en">Rewriting the Infinite Chase</title>
            <author role="aut">
              <persName>
                <forename type="first">Michael</forename>
                <surname>Benedikt</surname>
              </persName>
              <email type="md5">87ae329df71d5eb978c5a7e508a76cfa</email>
              <email type="domain">comlab.ox.ac.uk</email>
              <idno type="idhal" notation="numeric">882923</idno>
              <idno type="halauthorid" notation="string">509687-882923</idno>
              <affiliation ref="#struct-302612" />
            </author>
            <author role="aut">
              <persName>
                <forename type="first">Maxime</forename>
                <surname>Buron</surname>
              </persName>
              <email type="md5">cbf4d9a7e9eb9481c56ab74764bd6a2b</email>
              <email type="domain">inria.fr</email>
              <idno type="idhal" notation="string">maxime-buron</idno>
              <idno type="idhal" notation="numeric">736667</idno>
              <idno type="halauthorid" notation="string">37466-736667</idno>
              <idno type="ORCID">https://orcid.org/0000-0002-8227-4771</idno>
              <idno type="IDREF">https://www.idref.fr/253133386</idno>
              <affiliation ref="#struct-1102911" />
            </author>
            <author role="aut">
              <persName>
                <forename type="first">Stefano</forename>
                <surname>Germano</surname>
              </persName>
              <email type="md5">bb7b7457519e8ab4492114b2c151fb91</email>
              <email type="domain">cs.ox.ac.uk</email>
              <idno type="idhal" notation="numeric">1146805</idno>
              <idno type="halauthorid" notation="string">2542108-1146805</idno>
              <affiliation ref="#struct-302612" />
            </author>
            <author role="aut">
              <persName>
                <forename type="first">Kevin</forename>
                <surname>Kappelmann</surname>
              </persName>
              <email type="md5">d6f579534a90a61479d5bbfb7cbc9f81</email>
              <email type="domain">tum.de</email>
              <idno type="idhal" notation="numeric">1146806</idno>
              <idno type="halauthorid" notation="string">2542109-1146806</idno>
              <affiliation ref="#struct-132871" />
            </author>
            <author role="aut">
              <persName>
                <forename type="first">Boris</forename>
                <surname>Motik</surname>
              </persName>
              <email type="md5">6841fec5b076df4da3e467f584798cf8</email>
              <email type="domain">cs.ox.ac.uk</email>
              <idno type="idhal" notation="numeric">1146807</idno>
              <idno type="halauthorid" notation="string">411562-1146807</idno>
              <affiliation ref="#struct-302612" />
            </author>
            <editor role="depositor">
              <persName>
                <forename>Maxime</forename>
                <surname>Buron</surname>
              </persName>
              <email type="md5">cbf4d9a7e9eb9481c56ab74764bd6a2b</email>
              <email type="domain">inria.fr</email>
            </editor>
          </titleStmt>
          <editionStmt>
            <edition n="v1" type="current">
              <date type="whenSubmitted">2022-07-05 16:47:43</date>
              <date type="whenModified">2024-03-07 14:26:04</date>
              <date type="whenReleased">2022-07-06 11:08:25</date>
              <date type="whenProduced">2022-09-05</date>
              <date type="whenEndEmbargoed">2022-07-05</date>
              <ref type="file" target="https://hal-lirmm.ccsd.cnrs.fr/lirmm-03714595/document">
                <date notBefore="2022-07-05" />
              </ref>
              <ref type="file" subtype="author" n="1" target="https://hal-lirmm.ccsd.cnrs.fr/lirmm-03714595/file/p2537-benedikt-long.pdf">
                <date notBefore="2022-07-05" />
              </ref>
            </edition>
            <respStmt>
              <resp>contributor</resp>
              <name key="562582">
                <persName>
                  <forename>Maxime</forename>
                  <surname>Buron</surname>
                </persName>
                <email type="md5">cbf4d9a7e9eb9481c56ab74764bd6a2b</email>
                <email type="domain">inria.fr</email>
              </name>
            </respStmt>
          </editionStmt>
          <publicationStmt>
            <distributor>CCSD</distributor>
            <idno type="halId">lirmm-03714595</idno>
            <idno type="halUri">https://hal-lirmm.ccsd.cnrs.fr/lirmm-03714595</idno>
            <idno type="halBibtex">benedikt:lirmm-03714595</idno>
            <idno type="halRefHtml">&lt;i&gt;VLDB 2022 - 48th International Conference on Very Large Databases&lt;/i&gt;, Sep 2022, Sydney, Australia. pp.3045-3057, &lt;a target="_blank" href="https://dx.doi.org/10.14778/3551793.3551851"&gt;&amp;#x27E8;10.14778/3551793.3551851&amp;#x27E9;&lt;/a&gt;</idno>
            <idno type="halRef">VLDB 2022 - 48th International Conference on Very Large Databases, Sep 2022, Sydney, Australia. pp.3045-3057, &amp;#x27E8;10.14778/3551793.3551851&amp;#x27E9;</idno>
            <availability status="restricted">
              <licence target="http://creativecommons.org/licenses/by-nc-nd/">Attribution - NonCommercial - NoDerivatives</licence>
            </availability>
          </publicationStmt>
          <seriesStmt>
            <idno type="stamp" n="CNRS">CNRS - Centre national de la recherche scientifique</idno>
            <idno type="stamp" n="INRIA">INRIA - Institut National de Recherche en Informatique et en Automatique</idno>
            <idno type="stamp" n="INRIA-SOPHIA">INRIA Sophia Antipolis - MÃ©diterranÃ©e</idno>
            <idno type="stamp" n="IATE">IngÃ©nierie des agropolymÃ¨res et technologies Ã©mergentes</idno>
            <idno type="stamp" n="INRIASO">INRIA-SOPHIA</idno>
            <idno type="stamp" n="INRIA_TEST">INRIA - Institut National de Recherche en Informatique et en Automatique</idno>
            <idno type="stamp" n="TESTALAIN1">TESTALAIN1</idno>
            <idno type="stamp" n="LIRMM">Laboratoire d'Informatique de Robotique et de MicroÃ©lectronique de Montpellier</idno>
            <idno type="stamp" n="INRIA2">INRIA 2</idno>
            <idno type="stamp" n="UNIV-MONTPELLIER">UniversitÃ© de Montpellier</idno>
            <idno type="stamp" n="INSTITUT-AGRO-MONTPELLIER">Institut Agro Montpellier</idno>
            <idno type="stamp" n="INRAE">Institut National de Recherche en Agriculture, Alimentation et Environnement</idno>
            <idno type="stamp" n="INRAEOCCITANIEMONTPELLIER" corresp="INRAE">INRAE Occitanie Montpellier</idno>
            <idno type="stamp" n="UM-2015-2021" corresp="UNIV-MONTPELLIER">UniversitÃ© de Montpellier (2015-2021)</idno>
            <idno type="stamp" n="UM-EPE" corresp="UNIV-MONTPELLIER">UniversitÃ© de Montpellier - EPE</idno>
            <idno type="stamp" n="BOREAL" corresp="LIRMM">ReprÃ©sentation de Connaissances et Langages Ã  Base de RÃ¨gles pour Raisonner sur les DonnÃ©es</idno>
            <idno type="stamp" n="INRIA-ROYAUMEUNI">INRIA-ROYAUMEUNI</idno>
            <idno type="stamp" n="INSTITUT-AGRO">Institut Agro</idno>
            <idno type="stamp" n="INRIA-ALLEMAGNE">INRIA-ALLEMAGNE</idno>
            <idno type="stamp" n="IA">Intelligence Artificielle</idno>
          </seriesStmt>
          <notesStmt>
            <note type="audience" n="2">International</note>
            <note type="invited" n="0">No</note>
            <note type="popular" n="0">No</note>
            <note type="peer" n="1">Yes</note>
            <note type="proceedings" n="1">Yes</note>
          </notesStmt>
          <sourceDesc>
            <biblStruct>
              <analytic>
                <title xml:lang="en">Rewriting the Infinite Chase</title>
                <author role="aut">
                  <persName>
                    <forename type="first">Michael</forename>
                    <surname>Benedikt</surname>
                  </persName>
                  <email type="md5">87ae329df71d5eb978c5a7e508a76cfa</email>
                  <email type="domain">comlab.ox.ac.uk</email>
                  <idno type="idhal" notation="numeric">882923</idno>
                  <idno type="halauthorid" notation="string">509687-882923</idno>
                  <affiliation ref="#struct-302612" />
                </author>
                <author role="aut">
                  <persName>
                    <forename type="first">Maxime</forename>
                    <surname>Buron</surname>
                  </persName>
                  <email type="md5">cbf4d9a7e9eb9481c56ab74764bd6a2b</email>
                  <email type="domain">inria.fr</email>
                  <idno type="idhal" notation="string">maxime-buron</idno>
                  <idno type="idhal" notation="numeric">736667</idno>
                  <idno type="halauthorid" notation="string">37466-736667</idno>
                  <idno type="ORCID">https://orcid.org/0000-0002-8227-4771</idno>
                  <idno type="IDREF">https://www.idref.fr/253133386</idno>
                  <affiliation ref="#struct-1102911" />
                </author>
                <author role="aut">
                  <persName>
                    <forename type="first">Stefano</forename>
                    <surname>Germano</surname>
                  </persName>
                  <email type="md5">bb7b7457519e8ab4492114b2c151fb91</email>
                  <email type="domain">cs.ox.ac.uk</email>
                  <idno type="idhal" notation="numeric">1146805</idno>
                  <idno type="halauthorid" notation="string">2542108-1146805</idno>
                  <affiliation ref="#struct-302612" />
                </author>
                <author role="aut">
                  <persName>
                    <forename type="first">Kevin</forename>
                    <surname>Kappelmann</surname>
                  </persName>
                  <email type="md5">d6f579534a90a61479d5bbfb7cbc9f81</email>
                  <email type="domain">tum.de</email>
                  <idno type="idhal" notation="numeric">1146806</idno>
                  <idno type="halauthorid" notation="string">2542109-1146806</idno>
                  <affiliation ref="#struct-132871" />
                </author>
                <author role="aut">
                  <persName>
                    <forename type="first">Boris</forename>
                    <surname>Motik</surname>
                  </persName>
                  <email type="md5">6841fec5b076df4da3e467f584798cf8</email>
                  <email type="domain">cs.ox.ac.uk</email>
                  <idno type="idhal" notation="numeric">1146807</idno>
                  <idno type="halauthorid" notation="string">411562-1146807</idno>
                  <affiliation ref="#struct-302612" />
                </author>
              </analytic>
              <monogr>
                <meeting>
                  <title>VLDB 2022 - 48th International Conference on Very Large Databases</title>
                  <date type="start">2022-09-05</date>
                  <date type="end">2022-09-09</date>
                  <settlement>Sydney</settlement>
                  <country key="AU">Australia</country>
                </meeting>
                <imprint>
                  <biblScope unit="volume">15</biblScope>
                  <biblScope unit="issue">11</biblScope>
                  <biblScope unit="pp">3045-3057</biblScope>
                  <date type="datePub">2022</date>
                </imprint>
              </monogr>
              <idno type="doi">10.14778/3551793.3551851</idno>
              <ref type="publisher">https://vldb.org/2022/</ref>
            </biblStruct>
          </sourceDesc>
          <profileDesc>
            <langUsage>
              <language ident="en">English</language>
            </langUsage>
            <textClass>
              <classCode scheme="halDomain" n="info.info-ai">Computer Science [cs]/Artificial Intelligence [cs.AI]</classCode>
              <classCode scheme="halDomain" n="info.info-db">Computer Science [cs]/Databases [cs.DB]</classCode>
              <classCode scheme="halDomain" n="info.info-lo">Computer Science [cs]/Logic in Computer Science [cs.LO]</classCode>
              <classCode scheme="halTypology" n="COMM">Conference papers</classCode>
              <classCode scheme="halOldTypology" n="COMM">Conference papers</classCode>
              <classCode scheme="halTreeTypology" n="COMM">Conference papers</classCode>
            </textClass>
            <abstract xml:lang="en">
              <p>Guarded tuple-generating dependencies (GTGDs) are a natural extension of description logics and referential constraints. It has long been known that queries over GTGDs can be answered by a variant of the chase-a quintessential technique for reasoning with dependencies. However, there has been little work on concrete algorithms and even less on implementation. To address this gap, we revisit Datalog rewriting approaches to query answering, where GTGDs are transformed to a Datalog program that entails the same base facts on each base instance. We show that the rewriting can be seen as containing "shortcut" rules that circumvent certain chase steps, we present several algorithms that compute the rewriting by simulating specific types of chase steps, and we discuss important implementation issues. Finally, we show empirically that our techniques can process complex GTGDs derived from synthetic and real benchmarks and are thus suitable for practical use.</p>
            </abstract>
          </profileDesc>
        </biblFull>
      </listBibl>
    </body>
    <back>
      <listOrg type="structures">
        <org type="institution" xml:id="struct-302612" status="VALID">
          <idno type="ROR">https://ror.org/052gg0110</idno>
          <orgName>University of Oxford</orgName>
          <desc>
            <address>
              <addrLine>Wellington Square, Oxford OX1 2JD</addrLine>
              <country key="GB" />
            </address>
            <ref type="url">http://www.ox.ac.uk/</ref>
          </desc>
        </org>
        <org type="researchteam" xml:id="struct-1102911" status="VALID">
          <idno type="RNSR">202224285F</idno>
          <orgName>ReprÃ©sentation de Connaissances et Langages Ã  Base de RÃ¨gles pour Raisonner sur les DonnÃ©es</orgName>
          <orgName type="acronym">BOREAL</orgName>
          <date type="start">2022-06-01</date>
          <desc>
            <address>
              <addrLine>LIRMM, 161 rue Ada, 34000 Montpellier</addrLine>
              <country key="FR" />
            </address>
            <ref type="url">https://www.lirmm.fr/equipes/BOREAL</ref>
          </desc>
          <listRelation>
            <relation active="#struct-34586" type="direct" />
            <relation active="#struct-300009" type="indirect" />
            <relation active="#struct-1100620" type="direct" />
            <relation name="UMR5506" active="#struct-441569" type="indirect" />
            <relation name="UMR5506" active="#struct-1100589" type="indirect" />
            <relation active="#struct-1100827" type="direct" />
            <relation name="UMR1208" active="#struct-577435" type="indirect" />
            <relation active="#struct-1096330" type="indirect" />
            <relation active="#struct-1042499" type="indirect" />
            <relation active="#struct-1100589" type="indirect" />
          </listRelation>
        </org>
        <org type="institution" xml:id="struct-132871" status="VALID">
          <idno type="IdRef">031660150</idno>
          <idno type="ISNI">0000000123369749</idno>
          <idno type="ROR">https://ror.org/02kkvpp62</idno>
          <orgName>Technische UniversitÃ¤t Munchen - Technical University Munich - UniversitÃ© Technique de Munich</orgName>
          <orgName type="acronym">TUM</orgName>
          <date type="start">1868-01-01</date>
          <desc>
            <address>
              <addrLine>Arcisstrasse 21, D- 80333 MÃ¼nchen</addrLine>
              <country key="DE" />
            </address>
            <ref type="url">https://www.tum.de</ref>
          </desc>
        </org>
        <org type="laboratory" xml:id="struct-34586" status="VALID">
          <idno type="RNSR">198318250R</idno>
          <idno type="ROR">https://ror.org/01nzkaw91</idno>
          <orgName>Inria Sophia Antipolis - MÃ©diterranÃ©e</orgName>
          <orgName type="acronym">CRISAM</orgName>
          <desc>
            <address>
              <addrLine>2004 route des Lucioles BP 93 06902 Sophia Antipolis</addrLine>
              <country key="FR" />
            </address>
            <ref type="url">http://www.inria.fr/centre/sophia/</ref>
          </desc>
          <listRelation>
            <relation active="#struct-300009" type="direct" />
          </listRelation>
        </org>
        <org type="institution" xml:id="struct-300009" status="VALID">
          <idno type="ROR">https://ror.org/02kvxyf05</idno>
          <orgName>Institut National de Recherche en Informatique et en Automatique</orgName>
          <orgName type="acronym">Inria</orgName>
          <desc>
            <address>
              <addrLine>Domaine de VoluceauRocquencourt - BP 10578153 Le Chesnay Cedex</addrLine>
              <country key="FR" />
            </address>
            <ref type="url">http://www.inria.fr/en/</ref>
          </desc>
        </org>
        <org type="laboratory" xml:id="struct-1100620" status="VALID">
          <idno type="IdRef">139590827</idno>
          <idno type="ISNI">0000000405990488</idno>
          <idno type="RNSR">199111950H</idno>
          <idno type="ROR">https://ror.org/013yean28</idno>
          <orgName>Laboratoire d'Informatique de Robotique et de MicroÃ©lectronique de Montpellier</orgName>
          <orgName type="acronym">LIRMM</orgName>
          <date type="start">2022-01-01</date>
          <desc>
            <address>
              <addrLine>161 rue Ada - 34095 Montpellier</addrLine>
              <country key="FR" />
            </address>
            <ref type="url">https://www.lirmm.fr</ref>
          </desc>
          <listRelation>
            <relation name="UMR5506" active="#struct-441569" type="direct" />
            <relation name="UMR5506" active="#struct-1100589" type="direct" />
          </listRelation>
        </org>
        <org type="regroupinstitution" xml:id="struct-441569" status="VALID">
          <idno type="IdRef">02636817X</idno>
          <idno type="ISNI">0000000122597504</idno>
          <idno type="ROR">https://ror.org/02feahw73</idno>
          <orgName>Centre National de la Recherche Scientifique</orgName>
          <orgName type="acronym">CNRS</orgName>
          <date type="start">1939-10-19</date>
          <desc>
            <address>
              <country key="FR" />
            </address>
            <ref type="url">https://www.cnrs.fr/</ref>
          </desc>
        </org>
        <org type="regroupinstitution" xml:id="struct-1100589" status="VALID">
          <idno type="ROR">https://ror.org/051escj72</idno>
          <orgName>UniversitÃ© de Montpellier</orgName>
          <orgName type="acronym">UM</orgName>
          <date type="start">2022-01-01</date>
          <desc>
            <address>
              <addrLine>163 rue Auguste Broussonnet - 34090 Montpellier</addrLine>
              <country key="FR" />
            </address>
            <ref type="url">http://www.umontpellier.fr/</ref>
          </desc>
        </org>
        <org type="laboratory" xml:id="struct-1100827" status="VALID">
          <idno type="ISNI">0000000403736662</idno>
          <idno type="RNSR">200317667V</idno>
          <idno type="ROR">https://ror.org/0000n5x09</idno>
          <orgName>IngÃ©nierie des Agro-polymÃ¨res et Technologies Ã‰mergentes</orgName>
          <orgName type="acronym">UMR IATE</orgName>
          <date type="start">2022-01-01</date>
          <desc>
            <address>
              <addrLine>Campus de la Gaillarde 2, place Pierre Viala 34 060 Montpellier CÃ©dex 02 - FRANCE</addrLine>
              <country key="FR" />
            </address>
            <ref type="url">http://umr-iate.cirad.fr/</ref>
          </desc>
          <listRelation>
            <relation name="UMR1208" active="#struct-577435" type="direct" />
            <relation active="#struct-1096330" type="direct" />
            <relation active="#struct-1042499" type="indirect" />
            <relation active="#struct-1100589" type="direct" />
          </listRelation>
        </org>
        <org type="institution" xml:id="struct-577435" status="VALID">
          <idno type="ROR">https://ror.org/003vg9w96</idno>
          <orgName>Institut National de Recherche pour lâ€™Agriculture, lâ€™Alimentation et lâ€™Environnement</orgName>
          <orgName type="acronym">INRAE</orgName>
          <date type="start">2020-01-01</date>
          <desc>
            <address>
              <country key="FR" />
            </address>
          </desc>
        </org>
        <org type="institution" xml:id="struct-1096330" status="VALID">
          <idno type="IdRef">261038990</idno>
          <idno type="ROR">https://ror.org/03rnk6m14</idno>
          <orgName>Institut Agro Montpellier</orgName>
          <date type="start">2022-01-01</date>
          <desc>
            <address>
              <addrLine>2, place Viala - Montpellier</addrLine>
              <country key="FR" />
            </address>
            <ref type="url">https://www.institut-agro-montpellier.fr/</ref>
          </desc>
          <listRelation>
            <relation active="#struct-1042499" type="direct" />
          </listRelation>
        </org>
        <org type="regroupinstitution" xml:id="struct-1042499" status="VALID">
          <idno type="IdRef">260373249</idno>
          <orgName>Institut national d'enseignement supÃ©rieur pour l'agriculture, l'alimentation et l'environnement</orgName>
          <orgName type="acronym">Institut Agro</orgName>
          <date type="start">2020-01-01</date>
          <desc>
            <address>
              <country key="FR" />
            </address>
            <ref type="url">https://www.institut-agro.fr</ref>
          </desc>
        </org>
      </listOrg>
    </back>
  <teiCorpus>
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Rewriting the Infinite Chase</title>
				<funder ref="#_QJ8duq6 #_wtb2T2a">
					<orgName type="full">EPSRC</orgName>
				</funder>
				<funder ref="#_WuMf5KZ #_Rn8xYqp">
					<orgName type="full">Concur</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher />
				<availability status="unknown"><licence /></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Michael</forename><surname>Benedikt</surname></persName>
							<email>michael.benedikt@cs.ox.ac.uk</email>
							<affiliation key="aff0">
								<orgName type="institution">Oxford University</orgName>
								<address>
									<settlement>Oxford</settlement>
									<country key="GB">United Kingdom</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Maxime</forename><surname>Buron</surname></persName>
							<email>maxime.buron@inria.fr</email>
							<affiliation key="aff1">
								<orgName type="laboratory">LIRMM</orgName>
								<orgName type="institution" key="instit1">Inria</orgName>
								<orgName type="institution" key="instit2">Univ. of Montpellier Montpellier</orgName>
								<address>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Stefano</forename><surname>Germano</surname></persName>
							<email>stefano.germano@cs.ox.ac.uk</email>
							<affiliation key="aff2">
								<orgName type="institution">Oxford University</orgName>
								<address>
									<settlement>Oxford</settlement>
									<country key="GB">United Kingdom</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Kevin</forename><surname>Kappelmann</surname></persName>
							<email>kevin.kappelmann@tum.de</email>
							<affiliation key="aff3">
								<orgName type="institution">Technical University of Munich</orgName>
								<address>
									<settlement>Munich</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Boris</forename><surname>Motik</surname></persName>
							<email>boris.motik@cs.ox.ac.uk</email>
							<affiliation key="aff4">
								<orgName type="institution">Oxford University</orgName>
								<address>
									<settlement>Oxford</settlement>
									<country key="GB">United Kingdom</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Rewriting the Infinite Chase</title>
					</analytic>
					<monogr>
						<idno type="ISSN">2150-8097</idno>
					</monogr>
					<idno type="MD5">EBBFC9FB5E63429CCFF9EA596F58F8A9</idno>
					<idno type="DOI">10.14778/3551793.3551851</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-04-12T14:46+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid" />
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div><p>Guarded tuple-generating dependencies (GTGDs) are a natural extension of description logics and referential constraints. It has long been known that queries over GTGDs can be answered by a variant of the chase-a quintessential technique for reasoning with dependencies. However, there has been little work on concrete algorithms and even less on implementation. To address this gap, we revisit Datalog rewriting approaches to query answering, where GTGDs are transformed to a Datalog program that entails the same base facts on each base instance. We show that the rewriting can be seen as containing "shortcut" rules that circumvent certain chase steps, we present several algorithms that compute the rewriting by simulating specific types of chase steps, and we discuss important implementation issues. Finally, we show empirically that our techniques can process complex GTGDs derived from synthetic and real benchmarks and are thus suitable for practical use.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div><head n="1">INTRODUCTION</head><p>Tuple-generating dependencies (TGDs) are a natural extension of description logics and referential constraints, and they are extensively used in databases. For example, they are used in data integration to capture semantic restrictions on data sources, mapping rules between data sources and the mediated schema, and constraints on the mediated schema. A fundamental computational problem in such applications is query answering under TGDs: given a query ğ‘„, a collection of facts ğ¼ , and a set of TGDs Î£, find all the answers to ğ‘„ that logically follow from ğ¼ and Î£. This problem has long been seen as a key component of a declarative data integration systems <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b32">33]</ref>, and it also arises in answering querying using views and accessing data sources with restrictions <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b36">37]</ref>.</p><p>The chase is a quintessential technique for reasoning with TGDs. It essentially performs "forward reasoning" by extending a set of given facts ğ¼ to a set ğ¼ â€² of all facts implied by ğ¼ and a set of TGDs Î£.</p><p>To answer a query, one can compute ğ¼ â€² using the chase and then evaluate the query in ğ¼ â€² . Unfortunately, the chase does not necessarily terminate, and in fact query answering for general TGDs is undecidable. Considerable effort was devoted to identifying classes of TGDs for which query answering is decidable. One line of work has focused on TGDs where the chase terminates; weakly-acyclic TGDs <ref type="bibr" target="#b20">[21]</ref> are perhaps the best-known such class. Another line of work focused on guarded TGDs (GTGDs). GTGDs are interesting since they can capture common constraints used in data integration, and ontologies expressed in variants of description logic (DL) <ref type="bibr" target="#b5">[6]</ref> can be translated directly into GTGDs. Example 1.1 illustrates the use of GTGDs used in a practical data integration scenario.</p><p>Example 1.1. The IEC Common Information Model (CIM) is an open model for describing power generation and distribution networks. It is frequently used as a semantic layer in applications that integrate data about power systems <ref type="bibr" target="#b21">[22]</ref>. CIM is defined in UML, but its formal semantics has been provided by a translation into an OWL ontology. The domain of CIM is described using classes and properties, which correspond to unary and binary relations, respectively. Moreover, semantic relationships between classes and properties are represented as OWL axioms, many of which can be translated into GTGDs. A significant portion of CIM describes power distribution equipment using GTGDs such as (1)- <ref type="bibr" target="#b3">(4)</ref>.</p><p>ACEquipment(ğ‘¥) â†’ âˆƒğ‘¦ hasTerminal(ğ‘¥, ğ‘¦) âˆ§ ACTerminal(ğ‘¦) <ref type="bibr" target="#b0">(1)</ref> ACTerminal(ğ‘¥) â†’ Terminal(ğ‘¥) <ref type="bibr" target="#b1">(2)</ref> hasTerminal(ğ‘¥, ğ‘§) âˆ§ Terminal(ğ‘§) â†’ Equipment(ğ‘¥) <ref type="bibr" target="#b2">(3)</ref> ACTerminal(ğ‘¥) â†’ âˆƒğ‘¦ partOf(ğ‘¥, ğ‘¦) âˆ§ ACEquipment(ğ‘¦) <ref type="bibr" target="#b3">(4)</ref> Data integration is then achieved by populating the vocabulary using mappings, which can be seen queries over the data sources that produce a set of facts called a base instance. A key issue in data integration is dealing with incompleteness of data sources. For example, it is not uncommon that one data source mentions two switches sw 1 and sw 2 , while another data source provides information about connected terminals only for switch sw 1 .</p><p>ACEquipment(sw 1 ) ACEquipment(sw 2 )</p><p>(5)</p><p>hasTerminal(sw 1 , trm 1 ) ACTerminal(trm 1 )</p><p>GTGDs can be used to complete the data. For example, if a user asks to list all pieces of equipment known to the system, both sw 1 and sw 2 will be returned, even though the base instance does not explicitly classify either switch as a piece of equipment. âŠ³ Even though the chase for GTGDs does not necessarily terminate, query answering for GTGDs is decidable <ref type="bibr" target="#b33">[34]</ref>. To prove decidability, one can argue that the result of a chase is tree-like-that is, the facts derived by the chase can be arranged into a particular kind of tree. Next, one can develop a finite representation of potentially infinite trees. One possibility is to describe the trees using a finite tree automaton, so query answering can be reduced to checking automaton emptiness. While theoretically elegant, this method is not amenable to practical use: building the automaton and the emptiness test are both complex and expensive, and such algorithms always exhibit worst-case complexity. Alternatively, one can use blocking to identify a tree prefix sufficient for query evaluation. Blocking is commonly used in description logic reasoning <ref type="bibr" target="#b5">[6]</ref>, and it was later lifted to guarded logic <ref type="bibr" target="#b26">[27]</ref>. However, blocking was shown to be impractical for query answering: the required tree prefix can be much larger than the base instance ğ¼ so, as ğ¼ grows in size, the size of the tree prefix becomes unmanageable.</p><p>More promising query answering techniques for GTGDs are based on Datalog rewriting <ref type="bibr" target="#b34">[35]</ref>. The idea was initially proposed by Marnette <ref type="bibr" target="#b34">[35]</ref>, and it was later extended to broader classes of TGDs <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b23">24]</ref> and settings <ref type="bibr" target="#b10">[11]</ref>. The main idea is to transform an input set of GTGDs Î£ into a set rew(Î£) of Datalog rules such that Î£ and rew(Î£) entail the same base facts on each base instance. Thus, given a base instance ğ¼ , instead of computing the chase of ğ¼ and Î£ (which may not terminate), we compute the chase ğ¼ â€² of ğ¼ and rew(Î£). Since Datalog rules essentially correspond to existential-free TGDs, ğ¼ â€² is always finite and it can be computed using optimized Datalog engines. Moreover, Î£ and rew(Î£) entail the same base facts on ğ¼ , so we can answer any existential-free conjunctive query (i.e., queries where all variables are answer variables) by evaluating in ğ¼ â€² . The restriction to existential-free queries is technical: existentially quantified variables in a query can be matched to objects introduced by existential quantification, and these are not preserved in a Datalog rewriting. However, practical queries are typically existential-free since all query variables are usually answer variables.</p><p>Example 1.2. A Datalog program consisting of rules (2)-( <ref type="formula">3</ref>) and ( <ref type="formula" target="#formula_1">7</ref>) is a rewriting of GTGDs (1)- <ref type="bibr" target="#b3">(4)</ref>.</p><formula xml:id="formula_1">ACEquipment(ğ‘¥) â†’ Equipment(ğ‘¥)<label>(7)</label></formula><p>Rule ( <ref type="formula" target="#formula_1">7</ref>) is a logical consequence of GTGDs ( <ref type="formula">1</ref>)- <ref type="bibr" target="#b2">(3)</ref>, and it provides a "shortcut" for the inferences of the other GTGDs. âŠ³ The advantage of rewriting-based approaches is scalability in the size of the base instance ğ¼ . Such techniques have been implemented and practically validated in the context of description logics <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b28">29]</ref>, but practical algorithms have not yet been proposed for GTGDs. This raises several theoretical and practical questions.</p><p>How to compute the Datalog rules needed for completeness? Existing Datalog rewriting algorithms often prove their correctness indirectly. For example, completeness of a rewriting algorithm for description logics <ref type="bibr" target="#b28">[29]</ref> uses a proof-theoretic argument, which does not provide an intuition about why the algorithm actually works.</p><p>Our first contribution is to relate Datalog rewriting approaches to the chase. Towards this goal, we introduce the one-pass variant of the chase, which we use to develop a general completeness criterion for Datalog rewriting algorithms. This, in turn, provides us with a better understanding of how rewriting algorithms work, and it allows us to discover new algorithms in a systematic way.</p><p>What does the space of rewriting algorithms look like? Computing the rewriting rew(Î£) usually requires extending Î£ with certain logical consequences of Î£. We show that we can select the relevant consequences using different criteria. Some methods require deriving TGDs with existential quantifiers in the head, others generate Datalog rules directly, and yet other methods derive logical implications with function symbols. We relate all of these methods to the one-pass chase mentioned earlier, and we provide theoretical worst-case guarantees about their performance.</p><p>How do we ensure scalability of rewriting algorithms? Implementations of Datalog rewriting algorithms have thus far been mainly considered in the setting of description logics <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b37">38]</ref>. To the best of our knowledge, we provide the first look at optimization and implementation of Datalog rewriting algorithms for GTGDs. We achieve scalability by developing and combining various indexing and redundancy elimination techniques.</p><p>How do we evaluate rewriting algorithms? We provide a benchmark for GTGD query answering algorithms, and we use it to evaluate our methods. To the best of our knowledge, this is the first attempt to evaluate query answering techniques for GTGDs.</p></div>
<div><head>Summary of contributions.</head><p>We give an extensive account of Datalog rewriting for GTGDs. In particular, we develop a theoretical framework that allows us to understand, motivate, and show completeness of rewriting algorithms. Moreover, we present several concrete algorithms, establish worst-case complexity bounds, and discuss their relationships. We complement this theoretical analysis with a discussion of how to adapt techniques from first-order theorem proving to the setting of GTGDs. Finally, we empirically evaluate our techniques using an extensive benchmark. All proofs and the details of one algorithm are given in the appendix of this paper. Our implementation and a more detailed account of our experimental results can be found online <ref type="bibr" target="#b12">[13]</ref>.</p></div>
<div><head n="2">RELATED WORK</head><p>Answering queries via rewriting has been extensively considered in description logics. For example, queries over ontologies in the DL-Lite family of languages can be rewritten into first-order queries <ref type="bibr" target="#b17">[18]</ref>, and fact entailment for SH IQ ontologies can be rewritten to disjunctive Datalog <ref type="bibr" target="#b28">[29]</ref>. These techniques provide the foundation for the Ontop <ref type="bibr" target="#b16">[17]</ref> and <software ContextAttributes="used">KAON2</software> <ref type="bibr" target="#b37">[38]</ref> systems, respectively.</p><p>In the context of TGDs, first-order rewritings were considered in data integration systems with inclusion and key dependencies <ref type="bibr" target="#b15">[16]</ref>. Datalog rewritings have been considered for GTGDs <ref type="bibr" target="#b34">[35]</ref> and their extensions such as frontier-guarded TGDs <ref type="bibr" target="#b10">[11]</ref>, and nearly frontierguarded and nearly guarded TGDs <ref type="bibr" target="#b23">[24]</ref>. The focus in these studies was to identify complexity bounds and characterize expressivity of TGD classes rather than provide practical algorithms. Existing implements of query answering for TGDs use first-order rewriting for linear TGDs <ref type="bibr" target="#b47">[48]</ref>, chase variants for TGDs with terminating chase <ref type="bibr" target="#b13">[14]</ref>, chase with blocking for warded TGDs <ref type="bibr" target="#b11">[12]</ref>, chase with the magic sets transformation for shy TGDs <ref type="bibr" target="#b2">[3]</ref>, and Datalog rewriting for separable and weakly separable TGDs <ref type="bibr" target="#b48">[49]</ref>. These TGD classes are all different from GTGDs, and we are unaware of any attempts to implement and evaluate GTGD rewriting algorithms.</p><p>Our algorithms are related to resolution-based decision procedures for variants of guarded logics <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b49">50]</ref>. Moreover, our characterization of Datalog rewritings is related to a chase variant used to answer queries over data sources with access patterns <ref type="bibr" target="#b3">[4]</ref>. Finally, a variant of the one-pass chase from Section 4 was generalized to the broader context of disjunctive GTGDs <ref type="bibr" target="#b30">[31]</ref>.</p></div>
<div><head n="3">PRELIMINARIES</head><p>In this section, we recapitulate the well-known definitions and notation that we use to formalize our technical results.</p><p>TGDs. Let consts, vars, and nulls be pairwise disjoint, infinite sets of constants, variables, and labeled nulls, respectively. A term is a constant, a variable, or a labeled null; moreover, a term is ground if it does not contain a variable. For ğ›¼ a formula or a set thereof, consts(ğ›¼), vars(ğ›¼), nulls(ğ›¼), and terms(ğ›¼) are the sets of constants, free variables, labeled nulls, and terms, respectively, in ğ›¼.</p><p>A schema is a set of relations, each of which is associated with a nonnegative integer arity. A fact is an expression of the form ğ‘…( Ã¬ ğ‘¡), where ğ‘… is an ğ‘›-ary relation and Ã¬</p><p>ğ‘¡ is a vector of ğ‘› ground terms; moreover, ğ‘…( Ã¬ ğ‘¡) is a base fact if Ã¬ ğ‘¡ contains only constants. An instance ğ¼ is a finite set of facts, and ğ¼ is a base instance if it contains only base facts. An atom is an expression of the form ğ‘…( Ã¬ ğ‘¡), where ğ‘… is an ğ‘›-ary relation and Ã¬</p><p>ğ‘¡ is a vector of ğ‘› terms not containing labeled nulls. Thus, each base fact is an atom. We often treat conjunctions as sets of conjuncts; for example, for ğ›¾ a conjunction of facts and ğ¼ an instance, ğ›¾ âŠ† ğ¼ means that each conjunct of ğ›¾ is contained ğ¼ .</p><p>A tuple generating dependency (TGD) is a first-order formula of the form âˆ€Ã¬ ğ‘¥ [ğ›½ â†’ âˆƒÃ¬ ğ‘¦ ğœ‚], where ğ›½ and ğœ‚ are conjunctions of atoms, ğœ‚ is not empty, the free variables of ğ›½ are Ã¬ ğ‘¥, and the free variables of ğœ‚ are contained in Ã¬ ğ‘¥ âˆª Ã¬ ğ‘¦. Conjunction ğ›½ is the body and formula âˆƒÃ¬ ğ‘¦ ğœ‚ is the head of the TGD. We often omit âˆ€Ã¬ ğ‘¥ when writing a TGD. A TGD is full if Ã¬ ğ‘¦ is empty; otherwise, the TGD is non-full. A TGD is in head-normal form if it is full and its head contains exactly one atom, or it is non-full and each head atom contains at least one existentially quantified variable. Each TGD can be easily transformed to an equivalent set of TGDs in head-normal form. A full TGD in head-normal form is a Datalog rule, and a Datalog program is a finite set of Datalog rules. The head-width (hwidth) and the body-width (bwidth) of a TGD are the numbers of variables in the head and body, respectively; these are extended to sets of TGDs by taking the maxima over all TGDs. The notion of an instance satisfying a TGD is inherited from first-order logic. A base fact ğ¹ is entailed by an instance ğ¼ and a finite set of TGDs Î£, written ğ¼, Î£ |= ğ¹ , if ğ¹ âˆˆ ğ¼ â€² holds for each instance ğ¼ â€² âŠ‡ ğ¼ that satisfies Î£.</p><p>A substitution ğœ is a function that maps finitely many variables to terms. The domain and the range of ğœ are dom(ğœ) and rng(ğœ), respectively. For ğ›¾ a term, a vector of terms, or a formula, ğœ (ğ›¾) is obtained by replacing each free occurrence of a variable ğ‘¥ in ğ›¾ such that ğ‘¥ âˆˆ dom(ğœ) with ğœ (ğ‘¥).</p><p>Fact Entailment for Guarded TGDs. Fact entailment for general TGDs is semidecidable, and many variants of the chase can be used to define a (possibly infinite) set of facts that is homomorphically contained in each modef of a base instance and a set of TGDs.</p><p>Fact entailment is decidable for guarded TGDs (GTGDs): a TGD âˆ€Ã¬ ğ‘¥ [ğ›½ â†’ âˆƒÃ¬ ğ‘¦ ğœ‚] is guarded if ğ›½ contains an atom (called a guard) that contains all variables of Ã¬ ğ‘¥. Note that a guard need not be unique in ğ›½. Let Î£ be a finite set of GTGDs. We say that a set of ground terms ğº is Î£-guarded by a fact ğ‘…( Ã¬ ğ‘¡) if ğº âŠ† Ã¬ ğ‘¡ âˆª consts(Î£). Moreover, ğº is Î£-guarded by a set of facts ğ¼ if ğº is Î£-guarded by some fact in ğ¼ . Finally, a fact ğ‘† ( Ã¬ ğ‘¢) is Î£-guarded by a fact ğ‘…( Ã¬ ğ‘¡) (respectively a set of facts ğ¼ ) if Ã¬ ğ‘¢ is Î£-guarded by ğ‘…( Ã¬ ğ‘¡) (respectively ğ¼ ). By adapting the reasoning techniques for guarded logics <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b46">47]</ref> and referential database constraints <ref type="bibr" target="#b29">[30]</ref>, fact entailment for GTGDs can be decided by a chase variant that works on tree-like structures. A chase tree ğ‘‡ consists of a directed tree, one tree vertex that is said to be recently updated, and a function mapping each vertex ğ‘£ in the tree to a finite set of facts ğ‘‡ (ğ‘£). A chase tree ğ‘‡ can be transformed to another chase tree ğ‘‡ â€² in the following two ways.</p><p>â€¢ One can apply a chase step with a GTGD ğœ = âˆ€Ã¬ ğ‘¥ [ğ›½ â†’ âˆƒÃ¬ ğ‘¦ ğœ‚] in head-normal form. The precondition is that there exist a vertex ğ‘£ in ğ‘‡ and a substitution ğœ with domain Ã¬ ğ‘¥ such that ğœ (ğ›½) âŠ† ğ‘‡ (ğ‘£). The result of the chase step is obtained as follows.</p><p>-If ğœ is full (and thus ğœ‚ is a single atom), then chase tree ğ‘‡ â€² is obtained from ğ‘‡ by making ğ‘£ recently updated in ğ‘‡ â€² and setting ğ‘‡ â€² (ğ‘£) = ğ‘‡ (ğ‘£) âˆª {ğœ (ğœ‚)}.</p><p>-If ğœ is not full, then ğœ is extended to a substitution ğœ â€² that maps each variable in Ã¬ ğ‘¦ to a labeled null not occurring in ğ‘‡ , and chase tree ğ‘‡ â€² is obtained from ğ‘‡ by introducing a fresh child ğ‘£ â€² of ğ‘£, making ğ‘£ â€² recently updated in ğ‘‡ â€² , and setting ğ‘‡ (ğ‘£ â€² ) = ğœ â€² (ğœ‚) âˆª {ğ¹ âˆˆ ğ‘‡ (ğ‘£) | ğ¹ is Î£-guarded by ğœ â€² (ğœ‚)}.</p><p>â€¢ One can apply a propagation step from a vertex ğ‘£ to a vertex ğ‘£ â€² in ğ‘‡ . Chase tree ğ‘‡ â€² is obtained from ğ‘‡ by making ğ‘£ â€² recently updated in ğ‘‡ â€² and setting ğ‘‡ â€² (ğ‘£ â€² ) = ğ‘‡ (ğ‘£ â€² ) âˆª ğ‘† for some nonempty set ğ‘† satisfying ğ‘† âŠ† {ğ¹ âˆˆ ğ‘‡ (ğ‘£) | ğ¹ is Î£-guarded by ğ‘‡ (ğ‘£ â€² )}.</p><p>A tree-like chase sequence for a base instance ğ¼ and a finite set of GTGDs Î£ in head-normal form is a finite sequence of chase trees ğ‘‡ 0 , . . . ,ğ‘‡ ğ‘› such that ğ‘‡ 0 contains exactly one root vertex ğ‘Ÿ that is recently updated in ğ‘‡ 0 and ğ‘‡ 0 (ğ‘Ÿ ) = ğ¼ , and each ğ‘‡ ğ‘– with 0 &lt; ğ‘– â‰¤ ğ‘› is obtained from ğ‘‡ ğ‘– -1 by a chase step with some ğœ âˆˆ Î£ or a propagation step. For each vertex ğ‘£ in ğ‘‡ ğ‘› and each fact ğ¹ âˆˆ ğ‘‡ ğ‘› (ğ‘£), this sequence is a tree-like chase proof of ğ¹ from ğ¼ and Î£. It is well known that ğ¼, Î£ |= ğ¹ if and only if there exists a tree-like chase proof of ğ¹ from ğ¼ and Î£ (e.g., <ref type="bibr" target="#b33">[34]</ref>). Example 4.3 in Section 4 illustrates these definitions. One can decide ğ¼, Î£ |= ğ¹ by imposing an upper bound on the size of chase trees that need to be considered <ref type="bibr" target="#b33">[34]</ref>.</p><p>Rewriting. A Datalog rewriting of a finite set of TGDs Î£ is a Datalog program rew(Î£) such that ğ¼, Î£ |= ğ¹ if and only if ğ¼, rew(Î£) |= ğ¹ for each base instance ğ¼ and each base fact ğ¹ . If Î£ contains GTGDs only, then a Datalog rewriting rew(Î£) is guaranteed to exist (which is not the case for general TGDs). Thus, we can reduce fact entailment for GTGDs to Datalog reasoning, which can be solved using highly optimized Datalog techniques <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b37">38]</ref>. For example, given a base instance ğ¼ , we can compute the materialization of rew(Î£) on ğ¼ by applying the rules of rew(Î£) to ğ¼ up to a fixpoint. This will compute precisely all base facts entailed by rew(Î£) (and thus also by Î£) on ğ¼ , and it can be done in time polynomial in the size of ğ¼ .</p><p>Encoding Existentials by Function Symbols. It is sometimes convenient to represent existentially quantified values using functional terms. In such cases, we use a slightly modified notions of terms, atoms, and rules. It will be clear from the context which definitions we use in different parts of the paper.</p><p>We adjust the notion of a term as either a constant, a variable, or an expression of the form ğ‘“ ( Ã¬ ğ‘¡) where ğ‘“ is an ğ‘›-ary function symbol and Ã¬ ğ‘¡ is a vector of ğ‘› terms. The notions of ground terms, (base) facts, and (base) instances, and atoms are the same as before, but they use the modified notion of terms. A rule is a first-order implication of the form âˆ€Ã¬ ğ‘¥ [ğ›½ â†’ ğ» ] where ğ›½ is a conjunction of atoms whose free variables are Ã¬ ğ‘¥, and ğ» is an atom whose free variables are contained in Ã¬ ğ‘¥; as for TGDs, we often omit âˆ€Ã¬ ğ‘¥. A rule thus contains no existential quantifiers, but its head contains exactly one atom that can contain function symbols. Also, a Datalog rule, a function-free rule, and a full TGD in head-normal form are all synonyms. Finally, a base fact still contains only constants.  <ref type="bibr" target="#b40">[41,</ref><ref type="bibr" target="#b41">42]</ref>.</p></div>
<div><head n="4">CHASE-BASED DATALOG REWRITING</head><p>Our objective is to develop rewriting algorithms that can handle complex GTGDs. Each algorithm will derive Datalog rules that provide "shortcuts" in tree-like chase proofs: instead of introducing a child vertex ğ‘£ â€² using a chase step with a non-full GTGD at vertex ğ‘£, performing some inferences in ğ‘£ â€² , and then propagating a derived fact ğ¹ back from ğ‘£ â€² to ğ‘£, these "shortcuts" will derive ğ¹ in one step without having to introduce ğ‘£ â€² . The main question is how to derive all "shortcuts" necessary for completeness while keeping the number of derivations low. In this section we lay the technical foundations that will allow us to study different strategies for deriving "shortcuts" in Section 5. We show that, instead of considering arbitrary chase proofs, we can restrict our attention to chase proofs that are one-pass according to Definition 4.1. Then, we identify the parts of such proofs that we need to be able to circumvent using "shortcuts". Finally, we present sufficient conditions that guarantee completeness of rewriting algorithms. We start by describing formally the structure of tree-like chase proofs. Definition 4.1. A tree-like chase sequence ğ‘‡ 0 , . . . ,ğ‘‡ ğ‘› for a base instance ğ¼ and a finite set of GTGDs Î£ in head-normal form is onepass if, for each 0 &lt; ğ‘– â‰¤ ğ‘›, chase tree ğ‘‡ ğ‘– is obtained by applying one of the following two steps to the recently updated vertex ğ‘£ of ğ‘‡ ğ‘– -1 : â€¢ a propagation step copying exactly one fact from ğ‘£ to its parent, or</p><p>â€¢ a chase step with a GTGD from Î£ provided that no propagation step from ğ‘£ to the parent of ğ‘£ is applicable.</p><p>Thus, each step in a tree-like chase sequence is applied to a "focused" vertex; steps with non-full TGDs move the "focus" from a parent to a child, and propagation steps move the "focus" in the opposite direction. Moreover, once a child-to-parent propagation takes place, the child cannot be revisited in further steps. Theorem 4.2 states a key property about chase proofs for GTGDs: whenever a proof exists, there exists a one-pass proof too. Example 4.3 illustrates important aspects of Definition 4.1 and Theorem 4.2. Theorem 4.2. For each base instance ğ¼ , each finite set of GTGDs Î£ in head-normal form, and each base fact ğ¹ such that ğ¼, Î£ |= ğ¹ , there exists a one-pass tree-like chase proof of ğ¹ from ğ¼ and Î£.</p><p>Example 4.3. Let ğ¼ = {ğ´(ğ‘, ğ‘)} and let Î£ contain GTGDs (8)- <ref type="bibr" target="#b12">(13)</ref>.</p><formula xml:id="formula_2">ğ´(ğ‘¥ 1 , ğ‘¥ 2 ) â†’ âˆƒğ‘¦ ğµ(ğ‘¥ 1 , ğ‘¦) âˆ§ ğ¶ (ğ‘¥ 1 , ğ‘¦)<label>(8)</label></formula><formula xml:id="formula_3">ğ¶ (ğ‘¥ 1 , ğ‘¥ 2 ) â†’ ğ· (ğ‘¥ 1 , ğ‘¥ 2 ) (9) ğµ(ğ‘¥ 1 , ğ‘¥ 2 ) âˆ§ ğ· (ğ‘¥ 1 , ğ‘¥ 2 ) â†’ ğ¸ (ğ‘¥ 1 )<label>(10)</label></formula><formula xml:id="formula_4">ğ´(ğ‘¥ 1 , ğ‘¥ 2 ) âˆ§ ğ¸ (ğ‘¥ 1 ) â†’ âˆƒğ‘¦ 1 , ğ‘¦ 2 ğ¹ (ğ‘¥ 1 , ğ‘¦ 1 ) âˆ§ ğ¹ (ğ‘¦ 1 , ğ‘¦ 2 ) (11) ğ¸ (ğ‘¥ 1 ) âˆ§ ğ¹ (ğ‘¥ 1 , ğ‘¥ 2 ) â†’ ğº (ğ‘¥ 1 )<label>(12)</label></formula><formula xml:id="formula_5">ğµ(ğ‘¥ 1 , ğ‘¥ 2 ) âˆ§ ğº (ğ‘¥ 1 ) â†’ ğ» (ğ‘¥ 1 )<label>(13)</label></formula><p>A tree-like chase sequence for ğ¼ and Î£ is shown in Figure <ref type="figure" target="#fig_4">1</ref>, and it provides a proof of the base fact ğ» (ğ‘) from ğ¼ and Î£. The recently updated vertex of each chase tree is shown in red. We denote the root vertex by ğ‘Ÿ , and its left and right children by ğ‘£ 1 and ğ‘£ 2 , respectively. The step producing ğ‘‡ 7 from ğ‘‡ 6 does not satisfy the requirements of one-pass chase: it propagates the fact ğº (ğ‘) from ğ‘£ 2 to ğ‘£ 1 , where the latter is a "sibling" of the former.</p><p>To obtain a one-pass chase sequence, we could try to "slow down" the propagation of ğº (ğ‘): we first propagate ğº (ğ‘) from ğ‘£ 2 to ğ‘Ÿ , and then from ğ‘Ÿ to ğ‘£ 1 . The former step is allowed in one-pass chase, but the latter step is not: once we leave the subtree rooted at ğ‘£ 1 , we are not allowed to revisit it later. Note, however, that ğµ(ğ‘, ğ‘› 1 ) and ğº (ğ‘) must occur jointly in a vertex of a chase tree in order to derive ğ» (ğ‘). Moreover, note that no reordering of chase steps will The solution, which is used in the proof of Theorem 4.2, is to replace propagation to the child by "regrowing" the entire subtree.</p><p>In our example, we replace the steps producing ğ‘‡ 7 and ğ‘‡ 8 with the steps shown in Figure <ref type="figure">2</ref>. Chase tree ğ‘‡ 1  7 is obtained from ğ‘‡ 6 by propagating ğº (ğ‘) from ğ‘£ 2 to ğ‘Ÿ . Then, instead of propagating ğº (ğ‘) from ğ‘Ÿ to ğ‘£ 1 , a new vertex ğ‘£ 3 is created in ğ‘‡ 2  7 by reapplying (8) and fact ğº (ğ‘) is pushed to ğ‘£ 3 as part of the chase step with a non-full GTGD. This allows ğ» (ğ‘) to be derived in vertex ğ‘£ 3 of ğ‘‡ 1  8 . Fact ğ· (ğ‘› 3 ) can be derived in vertex ğ‘£ 3 , but this is not needed to prove ğ» (ğ‘). Moreover, our chase is oblivious <ref type="bibr" target="#b33">[34]</ref>: a non-full TGD can be applied to the same facts several times, each time introducing a fresh vertex and fresh labeled nulls. The number of children of a vertex is thus not naturally bounded, and our objective is not to apply all chase steps exhaustively to obtain a universal model of Î£. Instead, we are interested only in chase proofs, which must only contain steps needed to demonstrate entailment of a specific fact. âŠ³ One-pass chase proofs are interesting because they can be decomposed into loops as described in Definition 4.4. Definition 4.4. For ğ‘‡ 0 , . . . ,ğ‘‡ ğ‘› a one-pass tree-like chase sequence for some ğ¼ and Î£, a loop at vertex ğ‘£ with output fact ğ¹ is a subsequence ğ‘‡ ğ‘– , . . . ,ğ‘‡ ğ‘— with 0 â‰¤ ğ‘– &lt; ğ‘— â‰¤ ğ‘› such that â€¢ ğ‘‡ ğ‘–+1 is obtained by a chase step with a non-full GTGD,</p><p>â€¢ ğ‘‡ ğ‘— is obtained by a propagation step that copies ğ¹ , and</p><p>â€¢ ğ‘£ is the recently updated vertex of both ğ‘‡ ğ‘– and ğ‘‡ ğ‘— .</p><p>The length of the loop is defined as ğ‘— -ğ‘–.</p><p>Example 4.5. Subsequence ğ‘‡ 0 ,ğ‘‡ 1 ,ğ‘‡ 2 ,ğ‘‡ 3 ,ğ‘‡ 4 of the chase trees from Example 4.3 is a loop at the root vertex ğ‘Ÿ with output fact ğ¸ (ğ‘): chase tree ğ‘‡ 1 is obtained by applying a non-full GTGD to ğ‘Ÿ , and chase tree ğ‘‡ 4 is obtained by propagating ğ¸ (ğ‘) back to ğ‘Ÿ . Analogously, ğ‘‡ 4 ,ğ‘‡ 5 ,ğ‘‡ 6 ,ğ‘‡ 1  7 is another loop at ğ‘Ÿ with output fact ğº (ğ‘). Finally, ğ‘‡ 1  7 ,ğ‘‡ 2  7 ,ğ‘‡ 1 8 ,ğ‘‡ 9 is a loop at ğ‘Ÿ with output fact ğ» (ğ‘). âŠ³ Thus, a loop is a subsequence of chase steps that move the "focus" from a parent to a child vertex, perform a series of inferences in the child and its descendants, and finally propagate one fact back to the parent. If non-full TGDs are applied to the child, then the loop can be recursively decomposed into further loops at the child. The properties of the one-pass chase ensure that each loop is finished as soon as a fact is derived in the child that can be propagated to the parent, and that the vertices introduced in the loop are not revisited at any later point in the proof. In this way, each loop at vertex ğ‘£ can be seen as taking the set ğ‘‡ ğ‘– (ğ‘£) as input and producing the output fact ğ¹ that is added to ğ‘‡ ğ‘— (ğ‘£). This leads us to the following idea: for each loop with the input set of facts ğ‘‡ ğ‘– (ğ‘£), a rewriting should contain a "shortcut" Datalog rule that derives the loop's output.</p><p>Example 4.6. One can readily check that rules ( <ref type="formula" target="#formula_6">14</ref>)-( <ref type="formula" target="#formula_8">16</ref>) provide "shortcuts" for the three loops identified in Example 4.5.</p><formula xml:id="formula_6">ğ´(ğ‘¥ 1 , ğ‘¥ 2 ) â†’ ğ¸ (ğ‘¥ 1 )<label>(14)</label></formula><formula xml:id="formula_7">ğ´(ğ‘¥ 1 , ğ‘¥ 2 ) âˆ§ ğ¸ (ğ‘¥ 1 ) â†’ ğº (ğ‘¥ 1 )<label>(15)</label></formula><formula xml:id="formula_8">ğ´(ğ‘¥ 1 , ğ‘¥ 2 ) âˆ§ ğº (ğ‘¥ 1 ) â†’ ğ» (ğ‘¥ 1 )<label>(16)</label></formula><p>Moreover, these are all relevant "shortcuts": the union of rules ( <ref type="formula" target="#formula_6">14</ref>)-( <ref type="formula" target="#formula_8">16</ref>) and the Datalog rules from Example 4.3-that is, rules ( <ref type="formula">9</ref>), ( <ref type="formula" target="#formula_3">10</ref>), <ref type="bibr" target="#b11">(12)</ref>, and (13)-is a rewriting of the set Î£ from Example 4.1. âŠ³ These ideas are formalized in Proposition 4.7, which will provide us with a correctness criterion for our algorithms. Proposition 4.7. A Datalog program Î£ â€² is a rewriting of a finite set of GTGDs Î£ in head-normal form if</p><formula xml:id="formula_9">â€¢ Î£ â€² is a logical consequence of Î£,</formula><p>â€¢ each Datalog rule of Î£ is a logical consequence of Î£ â€² , and</p><p>â€¢ for each base instance ğ¼ , each one-pass tree-like chase sequence ğ‘‡ 0 , . . . ,ğ‘‡ ğ‘› for ğ¼ and Î£, and each loop ğ‘‡ ğ‘– , . . . ,ğ‘‡ ğ‘— at the root vertex ğ‘Ÿ with output fact ğ¹ , there exist a Datalog rule ğ›½ â†’ ğ» âˆˆ Î£ â€² and a substitution ğœ such that ğœ (ğ›½) âŠ† ğ‘‡ ğ‘– (ğ‘Ÿ ) and ğœ (ğ» ) = ğ¹ .</p><p>Intuitively, the first condition ensures soundness: rewriting Î£ â€² should not derive more facts than Î£. The second condition ensures that Î£ â€² can mimic direct applications of Datalog rules from Î£ at the root vertex ğ‘Ÿ . The third condition ensures that Î£ â€² can reproduce the output of each loop at vertex ğ‘Ÿ using a "shortcut" Datalog rule.</p></div>
<div><head n="5">REWRITING ALGORITHMS</head><p>We now consider ways to produce "shortcut" Datalog rules satisfying Proposition 4.7. In Subsection 5.1 we present the ExbDR algorithm that manipulates GTGDs directly, and in Subsections 5.2 and 5.3 we present the <software>SkDR</software> and HypDR algorithms, respectively, that manipulate rules obtained by Skolemizing the input GTGDs. All of these algorithms can produce intermediate GTGDs/rules that are not necessarily Datalog rules. In Appendix E we present the FullDR algorithm that manipulates GTGDs, but derives only Datalog rules. However, the performance of FullDR proved to not be competitive, so we do not discuss it any further here.</p><p>Each algorithm is defined by an inference rule Inf that can be applied to several TGDs/rules to derive additional TGDs/rules. For simplicity, we use the same name for the rule and the resulting algorithm. Given a set of GTGDs Î£, the algorithm applies Inf to (the <software>Skolemization</software> of) Î£ as long as possible and then returns all produced Datalog rules. This process, however, can derive a large number of TGDs/rules, so it is vital to eliminate TGDs/rules whenever possible. We next define notions of redundancy that can be used to discard certain TGDs/rules produced by Inf.</p><formula xml:id="formula_10">Definition 5.1. A TGD ğœ 1 = âˆ€Ã¬ ğ‘¥ 1 [ğ›½ 1 â†’ âˆƒÃ¬ ğ‘¦ 1 ğœ‚ 1 ] is a syntactic tau- tology if it is in head-normal form and ğ›½ 1 âˆ© ğœ‚ 1 â‰  âˆ…. TGD ğœ 1 subsumes a TGD ğœ 2 = âˆ€Ã¬ ğ‘¥ 2 [ğ›½ 2 â†’ âˆƒÃ¬ ğ‘¦ 2 ğœ‚ 2 ] if there exists a substitution ğœ‡ such that dom(ğœ‡) = Ã¬ ğ‘¥ 1 âˆª Ã¬ ğ‘¦ 1 , ğœ‡ ( Ã¬ ğ‘¥ 1 ) âŠ† Ã¬ ğ‘¥ 2 , ğœ‡ ( Ã¬ ğ‘¦ 1 ) âŠ† Ã¬ ğ‘¦ 1 âˆª Ã¬ ğ‘¦ 2 , ğœ‡ (ğ‘¦) â‰  ğœ‡ (ğ‘¦ â€² ) for distinct ğ‘¦ and ğ‘¦ â€² in Ã¬ ğ‘¦ 1 , ğœ‡ (ğ›½ 1 ) âŠ† ğ›½ 2 , and ğœ‡ (ğœ‚ 1 ) âŠ‡ ğœ‚ 2 . A rule ğœ 1 = âˆ€Ã¬ ğ‘¥ 1 [ğ›½ 1 â†’ ğ» 1 ] is a syntactic tautology if ğ» 1 âˆˆ ğ›½ 1 . Rule ğœ 1 subsumes a rule ğœ 2 = âˆ€Ã¬ ğ‘¥ 2 [ğ›½ 2 â†’ ğ» 2 ] if there exists a substi- tution ğœ‡ such that ğœ‡ (ğ›½ 1 ) âŠ† ğ›½ 2 and ğœ‡ (ğ» 1 ) = ğ» 2 .</formula><p>A TGD/rule ğœ is contained in a set of TGDs/rules ğ‘† up to redundancy if ğœ is a syntactic tautology or some ğœ â€² âˆˆ ğ‘† subsumes ğœ.</p><p>The following example illustrates Definition 5.1.</p><p>Example 5.2. Rule ğ´(ğ‘¥) âˆ§ ğµ(ğ‘¥) â†’ ğ´(ğ‘¥) is a syntactic tautology: applying a chase step with it cannot produce a new fact. A non-full TGD in head-normal form cannot be a syntactic tautology since each head atom of such a TGD contains an existentially quantified variable that does not occur in the TGD body.</p><p>Rule</p><formula xml:id="formula_11">ğœ 1 = ğ´(ğ‘“ (ğ‘¥ 1 ), ğ‘“ (ğ‘¥ 1 )) âˆ§ ğµ(ğ‘¥ 1 ) â†’ ğµ(ğ‘“ (ğ‘¥ 1 )</formula><p>) is subsumed by rule ğœ 2 = ğ´(ğ‘¥ 2 , ğ‘¥ 3 ) â†’ ğµ(ğ‘¥ 2 ) using substitution ğœ‡ 1 that maps both ğ‘¥ 2 and ğ‘¥ 3 to ğ‘“ (ğ‘¥ 1 ). If ğœ 1 derives ğµ(ğ‘“ (ğ‘¡)) in one step from a set of facts ğ¼ by a substitution ğœ where ğœ (ğ‘¥ 1 ) = ğ‘¡, then ğœ 2 also derives ğµ(ğ‘“ (ğ‘¡)) from ğ¼ in one step by substitution ğœ â€¢ ğœ‡ 1 . Thus, rule ğœ 1 is not needed when rule ğœ 2 is present, so ğœ 1 can be discarded.</p><p>While syntactic tautologies and rule subsumption are standard in first-order theorem proving <ref type="bibr" target="#b7">[8]</ref>, subsumption of TGDs is more involved. TGD</p><formula xml:id="formula_12">ğœ 3 = ğ´(ğ‘¥ 1 , ğ‘¥ 1 ) âˆ§ ğµ(ğ‘¥ 1 ) â†’ âˆƒğ‘¦ 1 ğ¶ (ğ‘¥ 1 , ğ‘¦ 1 ) is subsumed by TGD ğœ 4 = ğ´(ğ‘¥ 2 , ğ‘¥ 3 ) â†’ âˆƒğ‘¦ 2 , ğ‘¦ 3 ğ¶ (ğ‘¥ 2 , ğ‘¦ 2 ) âˆ§ ğ· (ğ‘¥ 3 , ğ‘¦ 3 ) by substitu- tion ğœ‡ 2 where ğœ‡ 2 (ğ‘¥ 2 ) = ğœ‡ 2 (ğ‘¥ 3 ) = ğ‘¥ 1 , ğœ‡ 2 (ğ‘¦ 2 ) = ğ‘¦ 1 , and ğœ‡ 2 (ğ‘¦ 3 ) = ğ‘¦ 3 .</formula><p>The conditions on substitution ğœ‡ 2 in Definition 5.1 ensure that ğ‘¦ 2 and ğ‘¦ 3 are not mapped to each other or to ğ‘¥ 1 . Thus, as in the previous paragraph, the result of each chase step with ğœ 3 and substitutions ğœ and ğœ â€² can always be obtained (up to isomorphism) by a chase step with ğœ 4 and substitutions ğœ â€¢ ğœ‡ 2 and ğœ â€² â€¢ ğœ‡ 2 .</p><p>âŠ³ In Definition 5.3 we formalize the notion of applying Inf exhaustively up to redundancy. The definition, however, does not say how to actually do it: we discuss this and other issues in Section 6.</p><p>Definition 5.3. For Inf an inference rule and Î£ a finite set of GTGDs, Inf(Î£) is the subset of all Skolem-free Datalog rules of Î£ â€² , where Î£ â€² is the smallest set that contains up to redundancy each TGD/rule obtained by â€¢ transforming Î£ into head-normal form if Inf manipulates TGDs or Skolemizing Î£ if Inf manipulates rules, and â€¢ selecting an adequate number of premises in Î£ â€² , renaming any variables shared by distinct premises, applying Inf to the renamed premises, and transforming the result into head-normal form.</p></div>
<div><head n="5.1">The Existential-Based Rewriting</head><p>As we discussed in Section 4, each loop ğ‘‡ ğ‘– , . . . ,ğ‘‡ ğ‘— at vertex ğ‘£ in a one-pass chase sequence can be seen as taking ğ‘‡ ğ‘– (ğ‘£) as input and producing one fact included in ğ‘‡ ğ‘— (ğ‘£) as output. Let ğ‘£ â€² be child of ğ‘£ introduced inğ‘‡ ğ‘–+1 . The idea behind the ExbDR algorithm is to derive all GTGDs such that, for each ğ‘˜ with ğ‘– &lt; ğ‘˜ â‰¤ ğ‘—, all facts of ğ‘‡ ğ‘˜ (ğ‘£ â€² ) ğ´(ğ‘, ğ‘) ğµ(ğ‘, ğ‘› 1 ), ğ¶ (ğ‘, ğ‘› 1 )</p><formula xml:id="formula_13">ğ· (ğ‘, ğ‘› 1 ) ğ¸ (ğ‘)<label>(8) (9)</label></formula><p>(17) = ( <ref type="formula" target="#formula_2">8</ref>) + (9) (10) (18) = ( <ref type="formula" target="#formula_15">17</ref>) + (10)</p><p>Figure <ref type="figure">3</ref>: Deriving "shortcuts" for the loop ğ‘‡ 0 -ğ‘‡ 4 in ExbDR can be derived from the input ğ‘‡ ğ‘– (ğ‘£) in one step. The output of the loop can then also be derived from ğ‘‡ ğ‘– (ğ‘£) in one step by full GTGD, so this GTGD provides us with the desired loop "shortcut". Before formalizing this idea, we slightly adapt the notion of unification.</p><p>Definition 5.4. For ğ‘‹ a set of variables, an ğ‘‹ -unifier and an ğ‘‹ -MGU ğœƒ of atoms ğ´ 1 , . . . , ğ´ ğ‘› and ğµ 1 , . . . , ğµ ğ‘› are defined as in Section 3, but with the additional requirement that ğœƒ (ğ‘¥) = ğ‘¥ for each ğ‘¥ âˆˆ ğ‘‹ .</p><p>It is straightforward to see that an ğ‘‹ -MGU is unique up to the renaming of variables not contained in ğ‘‹ , and that it can be computed as usual while treating variables in ğ‘‹ as if they were constants. We are now ready to formalize the ExbDR algorithm. </p><formula xml:id="formula_14">ğœ = âˆ€Ã¬ ğ‘¥ [ğ›½ â†’ âˆƒÃ¬ ğ‘¦ ğœ‚ âˆ§ ğ´ 1 âˆ§ â€¢ â€¢ â€¢ âˆ§ ğ´ ğ‘› ] with ğ‘› â‰¥ 1 and ğœ â€² = âˆ€Ã¬ ğ‘§ [ğ´ â€² 1 âˆ§ â€¢ â€¢ â€¢ âˆ§ ğ´ â€² ğ‘› âˆ§ ğ›½ â€² â†’ ğ» â€² ] and, for ğœƒ a Ã¬ ğ‘¦-MGU of ğ´ 1 , . . . , ğ´ ğ‘› and ğ´ â€² 1 , . . . , ğ´ â€² ğ‘› , , if ğœƒ ( Ã¬ ğ‘¥) âˆ© Ã¬ ğ‘¦ = âˆ… and vars(ğœƒ (ğ›½ â€² )) âˆ© Ã¬ ğ‘¦ = âˆ…, it derives ğœƒ (ğ›½) âˆ§ ğœƒ (ğ›½ â€² ) â†’ âˆƒÃ¬ ğ‘¦ ğœƒ (ğœ‚) âˆ§ ğœƒ (ğ´ 1 ) âˆ§ â€¢ â€¢ â€¢ âˆ§ ğœƒ (ğ´ ğ‘› ) âˆ§ ğœƒ (ğ» â€² ).</formula><p>Example 5.6. Consider again the set Î£ from Example 4.3. The idea behind the ExbDR algorithm is illustrated in Figure <ref type="figure">3</ref>, which summarizes the steps of the loop ğ‘‡ 0 ,ğ‘‡ 1 ,ğ‘‡ 2 ,ğ‘‡ 3 ,ğ‘‡ 4 from Figure <ref type="figure" target="#fig_4">1</ref>. We denote the vertices by ğ‘Ÿ and ğ‘£ 1 as in Example 4.3.</p><p>Fact ğ´(ğ‘, ğ‘) is the input to the loop, and the first step of the loop derives ğµ(ğ‘, ğ‘› 1 ) and ğ¶ (ğ‘, ğ‘› 1 ) using GTGD <ref type="bibr" target="#b7">(8)</ref>. Next, GTGD (9) evolves vertex ğ‘£ 1 by deriving ğ· (ğ‘, ğ‘› 1 ). To capture this, the ExbDR inference rule combines <ref type="bibr" target="#b7">(8)</ref>, the GTGD that creates ğ‘£ 1 , with (9), the GTGD that evolves ğ‘£ 1 . This produces GTGD <ref type="bibr" target="#b16">(17)</ref>, which derives all facts of ğ‘£ 1 from the input fact in one step. Vertex ğ‘£ 1 is evolved further using GTGD <ref type="bibr" target="#b9">(10)</ref> to derive ğ¸ (ğ‘). To reflect this, the ExbDR inference rule combines ( <ref type="formula" target="#formula_15">17</ref>) and <ref type="bibr" target="#b9">(10)</ref> to produce <ref type="bibr" target="#b17">(18)</ref>, which again derives all facts of ğ‘£ 1 from the loop's input in one step.</p><formula xml:id="formula_15">ğ´(ğ‘¥ 1 , ğ‘¥ 2 ) â†’ âˆƒğ‘¦ ğµ(ğ‘¥ 1 , ğ‘¦) âˆ§ ğ¶ (ğ‘¥ 1 , ğ‘¦) âˆ§ ğ· (ğ‘¥ 1 , ğ‘¦)<label>(17)</label></formula><formula xml:id="formula_16">ğ´(ğ‘¥ 1 , ğ‘¥ 2 ) â†’ âˆƒğ‘¦ ğµ(ğ‘¥ 1 , ğ‘¦) âˆ§ ğ¶ (ğ‘¥ 1 , ğ‘¦) âˆ§ ğ· (ğ‘¥ 1 , ğ‘¦) âˆ§ ğ¸ (ğ‘¥ 1 )<label>(18)</label></formula><p>Fact ğ¸ (ğ‘) does not contain the labeled null ğ‘› 1 that is introduced when creating ğ‘£ 1 , so it can be propagated to the root vertex ğ‘Ÿ as the output of the loop. This is reflected in <ref type="bibr" target="#b17">(18)</ref>: atom ğ¸ (ğ‘¥ 1 ) does not contain any existential variables. Definition 5.3 requires each derived GTGD to be brought into head-normal, so ( <ref type="formula" target="#formula_16">18</ref>) is broken up into ( <ref type="formula" target="#formula_15">17</ref>) and ( <ref type="formula" target="#formula_6">14</ref>). The latter GTGD is full, and it provides us with the desired shortcut for the loop.</p><p>Next, <ref type="bibr" target="#b11">(12)</ref> and atom ğ¹ (ğ‘¥ 1 , ğ‘¦ 1 ) of ( <ref type="formula">11</ref>) produce <ref type="bibr" target="#b18">(19)</ref>, and transformation into head-normal form produces <ref type="bibr" target="#b10">(11)</ref> and <ref type="bibr" target="#b14">(15)</ref>. Moreover, ( <ref type="formula" target="#formula_2">8</ref>) and ( <ref type="formula" target="#formula_5">13</ref>) produce <ref type="bibr" target="#b19">(20)</ref>, and transformation (20) into head-normal form produces ( <ref type="formula" target="#formula_8">16</ref>) and <ref type="bibr" target="#b20">(21)</ref>.</p><formula xml:id="formula_17">ğ´(ğ‘¥ 1 , ğ‘¥ 2 ) âˆ§ ğ¸ (ğ‘¥ 1 ) â†’ âˆƒğ‘¦ 1 , ğ‘¦ 2 ğ¹ (ğ‘¥ 1 , ğ‘¦ 1 ) âˆ§ ğ¹ (ğ‘¦ 1 , ğ‘¦ 2 ) âˆ§ ğº (ğ‘¥ 1 ) (19) ğ´(ğ‘¥ 1 , ğ‘¥ 2 ) âˆ§ ğº (ğ‘¥ 1 ) â†’ âˆƒğ‘¦ ğµ(ğ‘¥ 1 , ğ‘¦) âˆ§ ğ¶ (ğ‘¥ 1 , ğ‘¦) âˆ§ ğ» (ğ‘¥ 1 )<label>(20)</label></formula><formula xml:id="formula_18">ğ´(ğ‘¥ 1 , ğ‘¥ 2 ) âˆ§ ğº (ğ‘¥ 1 ) â†’ âˆƒğ‘¦ ğµ(ğ‘¥ 1 , ğ‘¦) âˆ§ ğ¶ (ğ‘¥ 1 , ğ‘¦)<label>(21)</label></formula><p>GTGD ( <ref type="formula" target="#formula_18">21</ref>) is subsumed by ( <ref type="formula" target="#formula_2">8</ref>) so it can be dropped. No further inferences are possible after this, so all derived full GTGDs are returned as the rewriting of Î£. âŠ³ Before proceeding, we present an auxiliary result showing certain key properties of the ExbDR inference rule. Proposition 5.7. Each application of the ExbDR inference rule to ğœ, ğœ â€² , and ğœƒ as in Definition 5.5 satisfies the following properties. 1. Some atom</p><formula xml:id="formula_19">ğ´ â€² ğ‘– with 1 â‰¤ ğ‘– â‰¤ ğ‘› is a guard in ğœ â€² . 2. For each 1 â‰¤ ğ‘– â‰¤ ğ‘› such that ğ´ â€²</formula><p>ğ‘– is a guard of ğœ â€² , and for ğœ the Ã¬ ğ‘¦-MGU of ğ´ â€² ğ‘– and the corresponding atom</p><formula xml:id="formula_20">ğ´ ğ‘– such that ğœ ( Ã¬ ğ‘¥) âˆ© Ã¬ ğ‘¦ = âˆ…, it is the case that vars ğœ (ğ´ â€² ğ‘— ) âˆ© Ã¬ ğ‘¦ â‰  âˆ… for each 1 â‰¤ ğ‘— â‰¤ ğ‘›. 3.</formula><p>The result is a GTGD whose body and head width are at most bwidth(Î£) and hwidth(Î£), respectively.</p><p>In the second claim of Proposition 5.7, ğœ unifies only ğ´ ğ‘– and ğ´ â€² ğ‘– , whereas ğœƒ unifies all ğ´ 1 , . . . , ğ´ ğ‘› and ğ´ â€² 1 , . . . , ğ´ â€² ğ‘› ; thus, ğœ and ğœƒ are not necessarily the same. The third claim is needed to prove termination of ExbDR.</p><p>Proposition 5.7 can be used to guide the application of the ExbDR inference rule. Consider an attempt to apply the ExbDR inference rule to two candidate GTGDs ğœ = ğ›½ â†’ âˆƒÃ¬ ğ‘¦ ğœ‚ and ğœ â€² = ğ›½ â€² â†’ ğ» â€² . The first claim of Proposition 5.7 tells us that a guard of ğœ â€² will definitely participate in the inference. Thus, we can choose one such guard ğº â€² âˆˆ ğ›½ â€² of ğœ â€² and try to find a Ã¬ ğ‘¦-MGU ğœ of ğº â€² and a counterpart atom ğº âˆˆ ğœ‚ from the head of ğœ. Next, we need to check whether ğœ ( Ã¬ ğ‘¥) âˆ© Ã¬ ğ‘¦ = âˆ…; if not, there is no way for ğœƒ ( Ã¬ ğ‘¥) âˆ© Ã¬ ğ‘¦ = âˆ… to hold so the inference is not possible. By the second claim of Proposition 5.7, all candidates for the atoms participating in the inference will contain a variable that is mapped by ğœ to a member of Ã¬ ğ‘¦; thus,</p><formula xml:id="formula_21">ğ‘† â€² = ğœ (ğ´ â€² ) | ğ´ â€² âˆˆ ğ›½ â€² âˆ§ vars(ğœ (ğ´ â€² )) âˆ© Ã¬</formula><p>ğ‘¦ â‰  âˆ… is the set of all relevant side atoms. Note that we apply ğœ to the atoms in ğ‘† â€² to simplify further matching. The next step is to identify the corresponding head atoms of ğœ. To achieve this, for each atom ğ´ â€² âˆˆ ğ‘† â€² of the form ğ‘…(ğ‘¡ 1 , . . . , ğ‘¡ ğ‘› ), we identify the set ğ¶ [ğ´ â€² ] of candidate counterpart atoms as the set of atoms of the form ğ‘…(ğ‘  1 , . . . , ğ‘  ğ‘› ) âˆˆ ğœ (ğœ‚) such that, for each argument position ğ‘– with 1</p><formula xml:id="formula_22">â‰¤ ğ‘– â‰¤ ğ‘›, if either ğ‘¡ ğ‘– âˆˆ Ã¬ ğ‘¦ or ğ‘  ğ‘– âˆˆ Ã¬</formula><p>ğ‘¦, then ğ‘¡ ğ‘– = ğ‘  ğ‘– . Finally, we consider each possible combination ğ‘† of such candidates, and we try to find an MGU ğœƒ of sets ğ‘† and ğ‘† â€² . If unification succeeds, we derive the corresponding GTGD. Program ExbDR(Î£) can thus be large in the worst case. In Section 7 we show empirically that rewritings are suitable for practical use. From a theoretical point of view, checking fact entailment via ExbDR(Î£) is worst-case optimal. To see why, let ğ‘Ÿ , ğ‘, and ğ‘ be as in Theorem 5.8, and consider a base instance ğ¼ with ğ‘ â€² constants. The fixpoint of ExbDR(Î£) on ğ¼ contains at most ğ‘Ÿ (ğ‘ + ğ‘ â€² ) ğ‘ facts, and it can be computed in time ğ‘‚ (ğ‘Ÿ (ğ‘ + ğ‘ â€² ) ğ‘ â€¢ |ExbDR(Î£)|): each rule ğœ âˆˆ ExbDR(Î£) is guarded so we can apply a chase step with ğœ by matching a guard and then checking the remaining body atoms. Hence, we can compute ExbDR(Î£) and find its fixpoint in 2Exp-Time, in ExpTime if the relation arity is fixed, and in PTime if Î£ is fixed (i.e., if we consider data complexity). These results match the lower bounds for checking fact entailment for GTGDs <ref type="bibr" target="#b33">[34]</ref>.</p></div>
<div><head n="5.2">Using Skolemization</head><p>The ExbDR algorithm exhibits two drawbacks. First, each application of the ExbDR inference rule potentially introduces a head atom, so the rule heads can get very long. Second, each inference requires matching a subset of body atoms of ğœ â€² to a subset of the head atoms of ğœ; despite the optimizations outlined after Proposition 5.7, this can be costly, particularly when rule heads are long.</p><p>We would ideally derive GTGDs with a single head atom and unify just one body atom of ğœ â€² with the head atom of ğœ, but this does not seem possible if we stick to manipulating GTGDs. For example, atoms ğ¶ (ğ‘¦) and ğ· (ğ‘¦) of GTGD <ref type="bibr" target="#b16">(17)</ref> refer to the same labeled null (represented by variable ğ‘¦), and this information would be lost if we split <ref type="bibr" target="#b16">(17)</ref> into two GTGDs. We thus need a way to refer to the same existentially quantified object in different logical formulas. This can be achieved by replacing existentially quantified variables by Skolem terms, which in turns gives rise to the <software ContextAttributes="used">SkDR</software> algorithm from Definition 5.10. Before presenting the algorithm, in Definition 5.9 we generalize the notion of guardedness to rules. </p><formula xml:id="formula_23">ğœ = ğ›½ â†’ ğ» and ğœ â€² = ğ´ â€² âˆ§ ğ›½ â€² â†’ ğ» â€² such that</formula><p>â€¢ ğ›½ is Skolem-free and ğ» contains a Skolem symbol, and</p><p>â€¢ ğ´ â€² contains a Skolem symbol, or ğœ â€² is Skolem-free and ğ´ â€² contains all variables of ğœ â€² , and, for ğœƒ an MGU of ğ» and ğ´ â€² , it derives</p><formula xml:id="formula_24">ğœƒ (ğ›½) âˆ§ ğœƒ (ğ›½ â€² ) â†’ ğœƒ (ğ» â€² ).</formula><p>Example 5.11. Skolemizing GTGDs <ref type="bibr" target="#b7">(8)</ref> and <ref type="bibr" target="#b10">(11)</ref> produces rules ( <ref type="formula">22</ref>)- <ref type="bibr" target="#b22">(23)</ref>, and ( <ref type="formula" target="#formula_26">24</ref>)- <ref type="bibr" target="#b24">(25)</ref>, respectively.</p><formula xml:id="formula_25">ğ´(ğ‘¥ 1 , ğ‘¥ 2 ) â†’ ğµ(ğ‘¥ 1 , ğ‘“ (ğ‘¥ 1 , ğ‘¥ 2 )) (22) ğ´(ğ‘¥ 1 , ğ‘¥ 2 ) â†’ ğ¶ (ğ‘¥ 1 , ğ‘“ (ğ‘¥ 1 , ğ‘¥ 2 ))<label>(23)</label></formula><formula xml:id="formula_26">ğ´(ğ‘¥ 1 , ğ‘¥ 2 ) âˆ§ ğ¸ (ğ‘¥ 1 ) â†’ ğ¹ (ğ‘¥ 1 , ğ‘”(ğ‘¥ 1 , ğ‘¥ 2 ))<label>(24)</label></formula><formula xml:id="formula_27">ğ´(ğ‘¥ 1 , ğ‘¥ 2 ) âˆ§ ğ¸ (ğ‘¥ 1 ) â†’ ğ¹ (ğ‘”(ğ‘¥ 1 , ğ‘¥ 2 ), â„(ğ‘¥ 1 , ğ‘¥ 2 ))<label>(25)</label></formula><p>Intuitively, rules ( <ref type="formula">22</ref>) and ( <ref type="formula" target="#formula_25">23</ref>) jointly represent the facts introduced by the non-full GTGD (8): functional term ğ‘“ (ğ‘¥ 1 , ğ‘¥ 2 ) allows both rules to "talk" about the same labeled nulls. This allows the <software ContextAttributes="used">SkDR</software> inference rule to simulate the ExbDR inference rule while unifying just pairs of atoms. In particular, <software ContextAttributes="used">SkDR</software> combines ( <ref type="formula">22</ref>) and ( <ref type="formula" target="#formula_3">10</ref>) to obtain <ref type="bibr" target="#b25">(26)</ref>; it combines ( <ref type="formula" target="#formula_25">23</ref>) and ( <ref type="formula">9</ref>) to obtain <ref type="bibr" target="#b26">(27)</ref>; and it combines ( <ref type="formula" target="#formula_28">26</ref>) and ( <ref type="formula" target="#formula_29">27</ref>) to obtain the "shortcut" rule <ref type="bibr" target="#b13">(14)</ref>.</p><formula xml:id="formula_28">ğ´(ğ‘¥ 1 , ğ‘¥ 2 ) âˆ§ ğ· (ğ‘¥ 1 , ğ‘“ (ğ‘¥ 1 , ğ‘¥ 2 )) â†’ ğ¸ (ğ‘¥ 1 )<label>(26)</label></formula><formula xml:id="formula_29">ğ´(ğ‘¥ 1 , ğ‘¥ 2 ) â†’ ğ· (ğ‘¥ 1 , ğ‘“ (ğ‘¥ 1 , ğ‘¥ 2 ))<label>(27)</label></formula><p>The rules with Skolem-free bodies derived in this way allow us to reconstruct derivations in one step analogously to Example 5.6, and the rules with Skolem symbols in body atoms capture the intermediate derivation steps. For example, rules ( <ref type="formula" target="#formula_28">26</ref>) and ( <ref type="formula" target="#formula_30">28</ref>) capture the result of matching the first and the second body atom, respectively, of rule <ref type="bibr" target="#b9">(10)</ref> to facts produced by rules ( <ref type="formula">22</ref>) and ( <ref type="formula" target="#formula_29">27</ref>), respectively.</p><p>To complete the rewriting, <software ContextAttributes="used">SkDR</software> combines ( <ref type="formula" target="#formula_26">24</ref>) with ( <ref type="formula" target="#formula_4">12</ref>) to obtain <ref type="bibr" target="#b14">(15)</ref>, and it combines ( <ref type="formula">22</ref>) with ( <ref type="formula" target="#formula_5">13</ref>) to derive <ref type="bibr" target="#b15">(16)</ref>. However, <software ContextAttributes="used">SkDR</software> also combines ( <ref type="formula" target="#formula_3">10</ref>) and ( <ref type="formula" target="#formula_29">27</ref>) into ( <ref type="formula" target="#formula_30">28</ref>), which with ( <ref type="formula">22</ref>) derives ( <ref type="formula" target="#formula_6">14</ref>) the second time. These inferences are superfluous: they just process the two body atoms of (10) in a different order. Also, <software ContextAttributes="used">SkDR</software> combines ( <ref type="formula" target="#formula_4">12</ref>) and ( <ref type="formula" target="#formula_27">25</ref>) into rule <ref type="bibr" target="#b28">(29)</ref>, which is a "deadend" in that it does not further contribute to a Datalog rule.</p><formula xml:id="formula_30">ğ´(ğ‘¥ 1 , ğ‘¥ 2 ) âˆ§ ğµ(ğ‘¥ 1 , ğ‘“ (ğ‘¥ 1 , ğ‘¥ 2 )) â†’ ğ¸ (ğ‘¥ 1 )<label>(28)</label></formula><formula xml:id="formula_31">ğ´(ğ‘¥ 1 , ğ‘¥ 2 ) âˆ§ ğ¸ (ğ‘¥ 1 ) âˆ§ ğ¸ (ğ‘”(ğ‘¥ 1 , ğ‘¥ 2 )) â†’ ğº (ğ‘”(ğ‘¥ 1 , ğ‘¥ 2 ))<label>(29)</label></formula><p>Our HypDR algorithm in Subsection 5.3 can avoid these overheads, but at the expense of using more than two rules at a time. âŠ³ Proposition 5.12 and Theorem 5.13 capture the relevant properties of the <software>SkDR</software> algorithm. Proposition 5.12. Each application of the <software ContextAttributes="used">SkDR</software> inference rule to rules ğœ and ğœ â€² as in Definition 5.10 produces a guarded rule. Theorem 5.13. Program <software ContextAttributes="used">SkDR</software>(Î£) is a Datalog rewriting of a finite set of GTGDs Î£. Moreover, the rewriting can be computed in time ğ‘‚ (ğ‘ ğ‘Ÿ ğ‘‘ â€¢ (ğ‘’+ğ‘¤ ğ‘ +ğ‘ ) ğ‘‘ğ‘ ) for ğ‘Ÿ the number of relations in Î£, ğ‘ the maximum relation arity in Î£, ğ‘’ the number of existential quantifiers in Î£, ğ‘¤ ğ‘ = bwidth(Î£), ğ‘ = |consts(Î£)|, and some ğ‘ and ğ‘‘.</p><p>It is natural to wonder whether <software>SkDR</software> is guaranteed to be more efficient than ExbDR. We next show that neither algorithm is generally better: there exist families of inputs on which <software ContextAttributes="used">SkDR</software> performs exponentially more inferences than ExbDR, and vice versa. Proposition 5.14. There exists a family {Î£ ğ‘› } ğ‘›âˆˆN of finite sets of GTGDs such that the number of GTGDs derived by ExbDR is ğ‘‚ (2 ğ‘› ) times larger than the number of rules derived by SkDR on each Î£ ğ‘› .</p><p>Proof. For each ğ‘› âˆˆ N, let Î£ ğ‘› contain the following GTGDs.</p><formula xml:id="formula_32">ğ´(ğ‘¥) â†’ âˆƒÃ¬ ğ‘¦ ğµ 1 (ğ‘¥, ğ‘¦ 1 ) âˆ§ â€¢ â€¢ â€¢ âˆ§ ğµ ğ‘› (ğ‘¥, ğ‘¦ ğ‘› ) (<label>30</label></formula><formula xml:id="formula_33">)</formula><formula xml:id="formula_34">ğµ ğ‘– (ğ‘¥ 1 , ğ‘¥ 2 ) âˆ§ ğ¶ ğ‘– (ğ‘¥ 1 ) â†’ ğ· ğ‘– (ğ‘¥ 1 , ğ‘¥ 2 ) for 1 â‰¤ ğ‘– â‰¤ ğ‘›<label>(31)</label></formula><p>On such Î£ ğ‘› , ExbDR derives a GTGD of the form <ref type="bibr" target="#b31">(32)</ref> for each subset {ğ‘˜ 1 , . . . , ğ‘˜ ğ‘š } âŠ† {1, . . . , ğ‘›}, and there are 2 ğ‘› such TGDs. In contrast, the <software ContextAttributes="used">Skolemization</software> of (30) consists of ğ‘› rules shown in equation <ref type="bibr" target="#b32">(33)</ref>, so <software ContextAttributes="used">SkDR</software> derives just ğ‘› rules shown in equation <ref type="bibr" target="#b33">(34)</ref>.</p><formula xml:id="formula_35">ğ´(ğ‘¥) âˆ§ ğ‘š ğ‘–=1 ğ¶ ğ‘˜ ğ‘– (ğ‘¥) â†’ âˆƒÃ¬ ğ‘¦ ğ‘› ğ‘–=1 ğµ ğ‘– (ğ‘¥, ğ‘¦ ğ‘– ) âˆ§ ğ‘š ğ‘–=1 ğ· ğ‘˜ ğ‘– (ğ‘¥, ğ‘¦ ğ‘˜ ğ‘– ) (32) ğ´(ğ‘¥) â†’ ğµ ğ‘– (ğ‘¥, ğ‘“ ğ‘– (ğ‘¥)) for 1 â‰¤ ğ‘– â‰¤ ğ‘› (33) ğ´(ğ‘¥) âˆ§ ğ¶ ğ‘– (ğ‘¥) â†’ ğ· ğ‘– (ğ‘¥, ğ‘“ ğ‘– (ğ‘¥)) for 1 â‰¤ ğ‘– â‰¤ ğ‘› â–¡(34)</formula><p>Proposition 5.15. There exists a family {Î£ ğ‘› } ğ‘›âˆˆN of finite sets of GTGDs such that the number of rules derived by SkDR is ğ‘‚ (2 ğ‘› ) times larger than the number of TGDs derived by ExbDR on each Î£ ğ‘› .</p><p>Proof. For each ğ‘› âˆˆ N, let Î£ ğ‘› contain the following GTGDs.</p><formula xml:id="formula_36">ğ´(ğ‘¥) â†’ âˆƒğ‘¦ ğµ 1 (ğ‘¥, ğ‘¦) âˆ§ â€¢ â€¢ â€¢ âˆ§ ğµ ğ‘› (ğ‘¥, ğ‘¦)<label>(35)</label></formula><formula xml:id="formula_37">ğµ 1 (ğ‘¥ 1 , ğ‘¥ 2 ) âˆ§ â€¢ â€¢ â€¢ âˆ§ ğµ ğ‘› (ğ‘¥ 1 , ğ‘¥ 2 ) â†’ ğ¶ (ğ‘¥ 1 )<label>(36)</label></formula><p>On such Î£ ğ‘› , ExbDR derives just GTGD (37) in one step. In contrast, the <software ContextAttributes="used">Skolemization</software> of ( <ref type="formula" target="#formula_36">35</ref>) consists of ğ‘› rules of the form <ref type="bibr" target="#b37">(38)</ref> for each 1 â‰¤ ğ‘– â‰¤ ğ‘›. Thus, <software ContextAttributes="used">SkDR</software> combines these with (36) to derive 2 ğ‘› -1 rules of the form <ref type="bibr" target="#b38">(39)</ref>, one for each subset {ğ‘˜ 1 , . . . , ğ‘˜ ğ‘š } âŠŠ {1, . . . , ğ‘›}.</p><formula xml:id="formula_38">ğ´(ğ‘¥) â†’ ğ¶ (ğ‘¥)<label>(37)</label></formula><formula xml:id="formula_39">ğ´(ğ‘¥) â†’ ğµ ğ‘– (ğ‘¥, ğ‘“ (ğ‘¥))<label>(38)</label></formula><formula xml:id="formula_40">ğ´(ğ‘¥) âˆ§ ğµ ğ‘˜ 1 (ğ‘¥, ğ‘“ (ğ‘¥)) âˆ§ â€¢ â€¢ â€¢ âˆ§ ğµ ğ‘˜ ğ‘š (ğ‘¥, ğ‘“ (ğ‘¥)) â†’ ğ¶ (ğ‘¥) â–¡ (39)</formula></div>
<div><head n="5.3">Combining Several SkDR Steps into One</head><p>The <software>SkDR</software> algorithm can produce many rules with Skolem symbols in the body, which is the main reason for Proposition 5.15. We next present the HypDR algorithm, which uses the hyperresolution inference rule as a kind of "macro" to combine several <software ContextAttributes="used">SkDR</software> steps into one. We show that this can be beneficial for several reasons.</p><p>Definition 5.16. The Hyperresolution Rewriting inference rule HypDR takes guarded rules </p><formula xml:id="formula_41">ğœ 1 = ğ›½ 1 â†’ ğ» 1 . . . ğœ ğ‘› = ğ›½ ğ‘› â†’ ğ» ğ‘› and ğœ â€² = ğ´ â€² 1 âˆ§ â€¢ â€¢ â€¢ âˆ§ ğ´ â€² ğ‘› âˆ§ ğ›½ â€² â†’ ğ» â€² such that â€¢ for each ğ‘– with 1 â‰¤ ğ‘– â‰¤ ğ‘›,</formula><formula xml:id="formula_42">ğœƒ (ğ›½ 1 ) âˆ§ â€¢ â€¢ â€¢ âˆ§ ğœƒ (ğ›½ ğ‘› ) âˆ§ ğœƒ (ğ›½ â€² ) â†’ ğœƒ (ğ» â€² ).</formula><p>Example 5.17. The HypDR inference rule simulates chase steps in the child vertex of a loop analogously to ExbDR: all body atoms matching a fact introduced in the child vertex are resolved in one step. We can see two benefits of this on our running example.</p><p>First, HypDR derives ( <ref type="formula" target="#formula_29">27</ref>) from ( <ref type="formula" target="#formula_25">23</ref>) and ( <ref type="formula">9</ref>), and it derives ( <ref type="formula" target="#formula_6">14</ref>) from ( <ref type="formula" target="#formula_3">10</ref>), <ref type="bibr" target="#b21">(22)</ref>, and <ref type="bibr" target="#b26">(27)</ref>. Rule ( <ref type="formula" target="#formula_6">14</ref>) is derived just once, and without intermediate rules ( <ref type="formula" target="#formula_28">26</ref>) and <ref type="bibr" target="#b27">(28)</ref>. In other words, the HypDR inference rule does not resolve the body atoms of a rule in every possible order. As Proposition 5.20 below shows, this can reduce the number of derived rules by an exponential factor.</p><p>Second, HypDR derives only rules with Skolem-free bodies, and thus does not derive the "dead-end" rule <ref type="bibr" target="#b28">(29)</ref>. In other words, all consequences of HypDR derive in one step one fact in the child vertex of a loop from the loop's input ğ‘‡ ğ‘– (ğ‘£).</p><p>The downside of HypDR is that more than two rules can participate in an inference. This requires more complex unification and selection of candidates that can participate in an inference. âŠ³ Proof. For each ğ‘› âˆˆ N, let Î£ ğ‘› contain the following GTGDs.</p><formula xml:id="formula_43">ğ´(ğ‘¥) â†’ âˆƒğ‘¦ ğµ(ğ‘¥, ğ‘¦)<label>(40)</label></formula><formula xml:id="formula_44">ğµ(ğ‘¥ 1 , ğ‘¥ 2 ) âˆ§ ğ¶ ğ‘– (ğ‘¥ 1 ) â†’ ğ· ğ‘– (ğ‘¥ 1 , ğ‘¥ 2 ) for 1 â‰¤ ğ‘– â‰¤ ğ‘› (41) ğ· 1 (ğ‘¥ 1 , ğ‘¥ 2 ) âˆ§ â€¢ â€¢ â€¢ âˆ§ ğ· ğ‘› (ğ‘¥ 1 , ğ‘¥ 2 ) â†’ ğ¸ (ğ‘¥ 1 )<label>(42)</label></formula><p>Skolemizing ( <ref type="formula" target="#formula_43">40</ref>) produces <ref type="bibr" target="#b42">(43)</ref>. Thus, <software ContextAttributes="used">SkDR</software> combines <ref type="bibr" target="#b42">(43)</ref> with each (41) to derive each <ref type="bibr" target="#b43">(44)</ref>, and it uses ( <ref type="formula" target="#formula_46">44</ref>) and ( <ref type="formula" target="#formula_44">42</ref>) to derive 2 ğ‘› -1 rules of the form <ref type="bibr" target="#b44">(45)</ref> for each set of indexes ğ¼ satisfying âˆ… âŠŠ ğ¼ âŠ† {1, . . . , ğ‘›}; note that none of these rules are redundant.</p><formula xml:id="formula_45">ğ´(ğ‘¥) â†’ ğµ(ğ‘¥, ğ‘“ (ğ‘¥))<label>(43)</label></formula><formula xml:id="formula_46">ğ´(ğ‘¥) âˆ§ ğ¶ ğ‘– (ğ‘¥) â†’ ğ· ğ‘– (ğ‘¥, ğ‘“ (ğ‘¥)) for 1 â‰¤ ğ‘– â‰¤ ğ‘›<label>(44)</label></formula><formula xml:id="formula_47">ğ´(ğ‘¥) âˆ§ ğ‘– âˆˆğ¼ ğ¶ ğ‘– (ğ‘¥) âˆ§ ğ‘— âˆˆ {1,...,ğ‘›}\ğ¼ ğ· ğ‘— (ğ‘¥, ğ‘“ (ğ‘¥)) â†’ ğ¸ (ğ‘¥)<label>(45)</label></formula><p>In contrast, HypDR derives each (44) just like <software ContextAttributes="used">SkDR</software>, and it combines in one step <ref type="bibr" target="#b41">(42)</ref> and all <ref type="bibr" target="#b43">(44)</ref> to derive <ref type="bibr" target="#b44">(45)</ref> for ğ¼ = {1, . . . , ğ‘›}. â–¡</p></div>
<div><head n="6">IMPLEMENTATION AND OPTIMIZATIONS</head><p>In this section, we discuss numerous issues that have to be addressed to make the computation of a rewriting practical.</p><p>Computing Inf(Î£) in Practice. Definition 5.3 does not specify how to compute the set Î£ â€² , and redundancy elimination makes this question nontrivial. When Inf derives a TGD/rule ğœ, we can apply subsumption in two ways. First, we can discard ğœ if ğœ is subsumed by a previously derived TGD/rule; this is known as forward subsumption. Second, if ğœ is not discarded, we can discard each previously derived TGD/rule that is subsumed by ğœ; this is known as backward subsumption. The set of derived TGD/rules can thus grow and shrink, so the application of Inf has to be carefully structured to ensure that all inferences are performed eventually.</p><p>We address this problem by a variant of the Otter loop <ref type="bibr" target="#b35">[36]</ref> used in first-order theorem provers. The pseudo-code is shown in Algorithm 1. The algorithm maintains two sets of TGDs/rules: the worked-off set W contain TGDs/rules that have been processed by Inf, and the unprocessed set U contains TGDs/rules that are still to be processed. Set W is initially empty (line 1), and set U is initialized to the head-normal form of Î£ if Inf manipulates TGDs, or to the <software ContextAttributes="used">Skolemization</software> of Î£ if Inf manipulates rules. The algorithm then processes each ğœ âˆˆ U until U becomes empty (lines 3-10). It is generally beneficial to process shorter TGDs/rules first as that improves chances of redundancy elimination. After moving ğœ to W (line 5), Choose some ğœ âˆˆ U and remove it from U 5:</p><formula xml:id="formula_48">W = W âˆª {ğœ } 6:</formula><p>Let E be the result of applying Inf to ğœ and a subset of W and transforming the result into head-normal form 7:</p><p>for each ğœ â€² âˆˆ E do 8:</p><p>if ğœ â€² is not contained in W âˆª U up to redundancy then 9:</p><p>Remove from W and U each ğœ â€²â€² subsumed by ğœ â€² 10:</p><formula xml:id="formula_49">U = U âˆª {ğœ â€² } 11: return {ğœ âˆˆ W | ğœ is a Skolem-free Datalog rule}</formula><p>the algorithm applies Inf to ğœ and W and transforms the results into head-normal form (line 6). The algorithm discards each resulting ğœ â€² âˆˆ E that is a syntactic tautology or is forward-subsumed by an element of W âˆª U (line 8). If ğœ â€² is not discarded, the algorithm applies backward subsumption to ğœ â€² , W, and U (line 9) and adds ğœ â€² to U (line 10). When all TGDs/rules are processed, the algorithm returns all Skolem-free Datalog rules from W (line 11). The result of applying Inf to TGDs/rules in W is thus contained in W âˆª U up to redundancy at all times so, upon algorithm's termination, set W satisfies the condition on Î£ â€² from Definition 5.3.</p><p>Checking Subsumption. Checking whether TGD/rule ğœ 1 subsumes ğœ 2 is NP-complete <ref type="bibr" target="#b31">[32]</ref>, and the main difficulty is in matching the variables of ğœ 1 to the variables of ğœ 2 . Thus, we use an approximate check in our implementation. First, we normalize each TGD to use fixed variables ğ‘¥ 1 , ğ‘¥ 2 , . . . and ğ‘¦ 1 , ğ‘¦ 2 , . . .: we sort the body and head atoms by their relations using an arbitrary, but fixed ordering and breaking ties arbitrarily, and then we rename all variables so that the ğ‘– ğ‘¡â„ distinct occurrence of a universally (respectively existentially) quantified variable from left to right is ğ‘¥ ğ‘– (respectively ğ‘¦ ğ‘– ). To see whether</p><formula xml:id="formula_50">ğœ 1 = ğ›½ 1 â†’ âˆƒÃ¬ ğ‘¦ ğœ‚ 1 subsumes ğœ 2 = ğ›½ 2 â†’ âˆƒÃ¬ ğ‘¦ ğœ‚ 2 ,</formula><p>we determine whether ğ›½ 1 âŠ† ğ›½ 2 and ğœ‚ 1 âŠ‡ ğœ‚ 2 holds, which requires only polynomial time. We use a similar approximation for rules. Variable normalization ensures termination, and using a modified subsumption check does not affect the correctness of the rewriting: set W may contain more TGDs/rules than strictly necessary, but these are all logical consequences of (the <software>Skolemization</software> of) Î£.</p><p>Subsumption Indexing. Sets W and U can be large, so we use a variant of feature vector indexing <ref type="bibr" target="#b43">[44]</ref> to retrieve subsumption candidates in W âˆª U. For simplicity, we consider only TGDs in the following discussion, but rules can be handled analogously. Note that a TGD ğœ 1 can subsume TGD ğœ 2 only if the set of relations occurring in the body of ğœ 1 (respectively the head of ğœ 2 ) is a subset of the set of relations occurring in the body of ğœ 2 (respectively the head of ğœ 1 ). Thus, we can reduce the problem of retrieving subsumption candidates to the problem of, given a domain set ğ·, a set ğ‘ of subsets of ğ·, a subset ğ‘† âŠ† ğ·, and âŠ²âŠ³ âˆˆ {âŠ†, âŠ‡}, retrieving each ğ‘† â€² âˆˆ ğ‘ satisfying ğ‘† â€² âŠ²âŠ³ ğ‘†. The set-trie data structure <ref type="bibr" target="#b42">[43]</ref> can address this problem. The idea is to order ğ· in an arbitrary, yet fixed way, so that we can treat each subset of ğ‘ as a word over ğ·. We then index ğ‘ by constructing a trie over the words representing the elements of ğ‘ . Finally, we retrieve all ğ‘† â€² âˆˆ ğ‘ satisfying ğ‘† â€² âŠ²âŠ³ ğ‘† by traversing the trie, where the ordering on ğ· allows us to considerably reduce the number of vertices we visit during the traversal. A minor issue is that retrieving TGDs that subsume a given TGD requires both subset and superset testing for body and head relations, respectively, and vice versa for retrieval of subsumed TGDs. To address this, we introduce a distinct symbol ğ‘… ğ‘ and ğ‘… â„ for each relation ğ‘… occurring in Î£, and we represent each TGD ğœ as a feature vector ğ¹ ğœ of these symbols corresponding to the body and head of ğœ. Moreover, we combine in the obvious way the subset and superset retrieval algorithms. For example, when searching for a TGD ğœ â€² âˆˆ W âˆª U that subsumes a given TGD ğœ, we use the subset retrieval for the symbols ğ‘… ğ‘ and the superset retrieval for symbols ğ‘… â„ . Finally, we order these symbols by the decreasing frequency of the order of the symbols' occurrence in the set Î£ of input TGDs, and moreover we order each ğ‘… ğ‘ before all ğ‘… â„ . Relation Clustering. We observed that the subsumption indexes can easily get very large, so index traversal can become a considerable source of overhead. To reduce the index size, we group the symbols ğ‘… ğ‘ and ğ‘… â„ into clusters ğ¶ ğ‘ and ğ¶ â„ , respectively. Then, the feature vector ğ¹ ğœ associated with each TGD ğœ consists of all clusters ğ¶ ğ‘ and ğ¶ â„ that contain a relation occurring in the body and head, respectively, of ğœ. We adapt the trie traversal algorithms in the obvious way to take into account this change. The number of clusters is computed using the average numbers of symbols and atoms in the input TGDs, and clusters are computed with the aim of balancing the number of TGDs stored in each leaf vertex.</p><p>Unification Indexing. We construct indexes over W that allow us to quickly identify TGDs/rules that can participate in an inference with some ğœ. For TGDs, we maintain a hash table that maps each relation ğ‘… to a set of TGDs containing ğ‘… in the body, and another hash table that does the same but for TGD heads. To index rules, we use a variant of a path indexing <ref type="bibr" target="#b44">[45]</ref>: each atom in a rule is represented as a sequence of relations and function symbols occurring in the atom, and such sequences are entered into two tries (one for body and one for head atoms). Then, given rule ğœ, we consider each body and head atom ğ´ of ğœ, we convert ğ´ into the corresponding sequence, and we use the sequence to query the relevant trie for all candidates participating in an inference with ğœ on ğ´.</p><p>Cheap Lookahead Optimization. Consider an application of the ExbDR inference rule to GTGDs ğœ and ğœ â€² as in Definition 5.5, producing a GTGD ğœ â€²â€² where vars(ğœƒ (ğ» â€² )) âˆ© Ã¬ ğ‘¦ â‰  âˆ… and the relation of ğ» â€² does not occur in the body of a GTGD in Î£. In each one-pass chase sequence for some base instance and Î£, no GTGD of Î£ can be applied to a fact obtained by instantiating ğœƒ (ğ» â€² ), so deriving this fact is redundant. Consequently, we can drop such ğœ â€²â€² as soon as we derive it in line 6. Analogously, when the <software>SkDR</software> inference rule is applied to rules ğœ and ğœ â€² as in Definition 5.10, we can drop the resulting rule if ğœƒ (ğ» â€² ) is not full and it contains a relation not occurring in the body of a GTGD in Î£.</p></div>
<div><head n="7">EXPERIMENTAL EVALUATION</head><p>We implemented a system that can produce a Datalog rewriting of a set of GTGDs using our algorithms, and we conducted an empirical evaluation using a comprehensive collection of 428 synthetic and </p></div>
<div><head n="7.1">Input GTGDs, Competitors, &amp; Test Setting</head><p>Before discussing our results, we next describe our test setting.</p><p>Input GTGDs. We are unaware of any publicly available sets of GTGDs that we could readily use in our evaluation, so we derived the input GTGDs for our evaluation from the ontologies in the Oxford Ontology Library <ref type="bibr" target="#b39">[40]</ref>. At the time of writing, this library contained 787 ontologies, each assigned a unique five-digit identifier.</p><p>After removing closely-related ontology variants, we were left with 428 core ontologies. We loaded each ontology using the parser from the Graal system <ref type="bibr" target="#b8">[9]</ref>, discarded axioms that cannot be translated into GTGDs, and converted the remaining axioms into GTGDs. We used the standard translation of description logics into first-order logic <ref type="bibr" target="#b5">[6]</ref>, where each class corresponds to a unary relation, and each property corresponds to a binary relation. We thus obtained 428 sets of input GTGDs with properties shown in Table <ref type="table" target="#tab_4">1</ref>.</p><p>To evaluate our algorithms on TGDs containing relations of arity higher than two, we devised a way to "blow up" relation arity. Given a set of GTGDs and a blowup factor ğ‘, our method proceeds as follows. First, in each atom of each GTGD, it replaces each variable argument with ğ‘ fresh variables uniquely associated with the variable; for example, for ğ‘ = 2, atom ğ´(ğ‘¥, ğ‘¦) is transformed into atom ğ´(ğ‘¥ 1 , ğ‘¥ 2 , ğ‘¦ 1 , ğ‘¦ 2 ). Next, the method randomly introduces fresh head and body atoms over the newly introduced variables; in doing so, it ensures that the new atoms do not introduce patterns that would prevent application of the ExbDR inference rule.</p><p>Competitors. We compared the ExbDR, <software ContextAttributes="used">SkDR</software>, and HypDR algorithms, implemented as described in Section 6. As noted in Section 2, no existing system we are aware of implements a Datalog rewriting algorithm for GTGDs. However, the <software ContextAttributes="used">KAON2</software> system <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b38">39]</ref> can rewrite GTGDs obtained from OWL ontologies, so we used <software ContextAttributes="used">KAON2</software> as a baseline in our experiments with OWL-based GTGDs. We made sure that all inputs to <software ContextAttributes="used">KAON2</software> and our algorithms include only GTGDs that all methods can process.</p><p>Test Setting. We conducted all experiments on a laptop with an Intel Core i5-6500 CPU @ 3. <ref type="bibr" target="#b19">20</ref>   </p></div>
<div><head n="7.2">Experiments with GTGDs from Ontologies</head><p>We computed the Datalog rewriting of GTGDs obtained from OWL ontologies using our three algorithms and <software ContextAttributes="used">KAON2</software>. Figure <ref type="figure" target="#fig_5">4</ref> shows the number of inputs that each algorithm processed in a given time, provides information about the inputs and outputs of each system, and compares the performance among systems. The input size for ExbDR is the number of GTGDs after transforming the input into head-normal form, and for <software ContextAttributes="used">SkDR</software> and HypDR it is the number of rules after <software ContextAttributes="used">Skolemization</software>. Input size is not available for <software ContextAttributes="used">KAON2</software> since this system reads an OWL ontology and transforms it into GTGDs internally. The output size is the number of Datalog rules in the rewriting. Finally, the blowup is the ratio of the output and the input sizes. Each input GTGD contained at most seven body atoms. Out of 428 inputs, 349 were processed within the ten minute limit by our three systems, and 334 inputs were processed by all four systems. Moreover, 32 inputs, each containing between 20,270 and 221,648 GTGD, were not processed by any system.</p><p>Discussion. As one can see in Figure <ref type="figure" target="#fig_5">4</ref>, all algorithms were able to compute the rewriting of large inputs containing 100k+ GTGDs. Moreover, for the vast majority of inputs that were successfully processed, the size of the rewriting and the number of body atoms in the rewriting are typically of the same order of magnitude as the input. Hence, the worst-case exponential blowup from Theorems 5.8, 5.13, and 5.19 does not appear in practice: the size of the rewriting seems to be determined primarily by the input size.</p><p>Relative Performance. No system can be identified as the best in general, but HypDR seems to offer the best performance on average. The algorithm was able to process most inputs; it was at least 35% faster than the other systems on the slowest input; it was never slower by an order of magnitude; there were only 14 inputs that could be processed by some other algorithm but not HypDR; and the output of HypDR does not differ significantly from the output of <software>SkDR</software>. This is in line with our motivation for HypDR outlined in Example 5.17. Specifically, HypDR derives rules with just one head atom, but it does not derive intermediate rules with functional body atoms. The main source of overhead in HypDR seems to be more complex selection of rules participating in an inference.</p><p>Impact of Subsumption. All algorithms spend a considerable portion of their running time checking TGD/rule subsumption, so it is natural to wonder whether this overhead is justified. To answer this question, we ran our three approaches using a modification of Algorithm 1: we replaced the check for containment up to redundancy in line 8 with just checking ğœ â€² âˆ‰ W âˆª U, and we removed line 9. Note that our normalization of variables described in Section 6 still guarantees termination. This change significantly increased the number of derivations: the numbers of derived TGDs/rules increased on average by a factor of 104, 185, and 103 on ExbDR, <software>SkDR</software>, and HypDR, respectively. Interestingly, this increase did not affect the performance uniformly. While <software ContextAttributes="used">SkDR</software> was able to process 12 inputs an order of magnitude faster, ExbDR and HypDR timed out on 72 and 17 additional inputs, respectively. This, we believe, is due to how different inference rules select inference candidates. The <software ContextAttributes="used">SkDR</software> rule is applied to just pairs of rules, and candidate pairs can be efficiently retrieved using unification indexes. In contrast, ExbDR requires matching several head atoms with as many body atoms, which makes developing a precise index for candidate pair retrieval difficult; thus, as the number of derived TGDs increases, the number of false candidates retrieved from the index increases as well. Finally, HypDR can be applied to an arbitrary number of rules, so selecting inference candidates clearly becomes more difficult as the number of derived rules increases.</p><p>Impact of Structural Transformation. <software ContextAttributes="used">KAON2</software> uses structural transformation <ref type="bibr" target="#b6">[7]</ref> to simplify ontology axioms before translating them into GTGDs. For example, axiom ğ´ âŠ‘ âˆƒğµ.âˆƒğ¶.ğ· is transformed into ğ´ âŠ‘ âˆƒğµ.ğ‘‹ and ğ‘‹ âŠ‘ âˆƒğ¶.ğ· for ğ‘‹ a fresh class. The resulting axioms have simpler structure, which is often beneficial to performance. To see how this transformation affects our algorithms, we reran our experiments while transforming the input axioms in the same way as in <software ContextAttributes="used">KAON2</software>. This indeed improved the performance of <software ContextAttributes="used">SkDR</software> by one order of magnitude on 22 ontologies, and it did not hurt the performance of HypDR. The main challenge is to generalize this transformation to arbitrary GTGDs: whereas description logic axioms exhibit syntactic nesting that lends itself naturally to this transformation, it is less clear how to systematically apply this transformation to TGDs, where heads and bodies consist of "flat" conjunctions. We leave this question for future work.</p></div>
<div><head n="7.3">End-to-End Experiments</head><p>To validate our approach end-to-end, we selected ten inputs where ExbDR produced the largest rewritings. For each of these, we generated a large base instance using WatDiv <ref type="bibr" target="#b1">[2]</ref>, and we computed the fixpoint of the rewriting and the instance using the RDFox <ref type="bibr" target="#b45">[46]</ref> Datalog system v5.4. Table <ref type="table" target="#tab_6">2</ref> summarizes our results. All programs used in this experiment are at least several orders of magnitude larger than what is usually encountered in practical applications of Datalog, but RDFox nevertheless computed the fixpoint of all rewritings in a few minutes. Moreover, although the fixpoints seem to be an order of magnitude larger than the base instance, this is not a problem for highly optimized systems such as RDFox. Hence, checking fact entailment via rewritings produced by our algorithms is feasible in practice.</p></div>
<div><head n="7.4">GTGDs With Relations of Higher Arity</head><p>Finally, we computed the rewriting of GTGDs obtained by blowing up relation arity as described in Subsection 7.1 using a blowup factor of five. We did not use <software ContextAttributes="used">KAON2</software> since this system supports relations of arity at most two. Figure <ref type="figure" target="#fig_3">5</ref> summarizes our results. Out of 428 inputs, 187 were processed within the ten minute limit by our three systems, and 128 inputs were not processed by any system.</p><p>While HypDR performed best on GTGDs derived from ontologies, Figure <ref type="figure" target="#fig_3">5</ref> shows it to be worst-performing on higher-arity GTGDs: it successfully processed only 199 inputs within the ten minute timeout, whereas <software ContextAttributes="used">SkDR</software> and ExbDR processed 238 and 274 inputs, respectively. This is mainly due to additional body atoms introduced by our "blowup" method: these increase the number of rules participating in an application of the HypDR inference rule, which makes selecting the participating rules harder.</p><p>This experiment proved to be more challenging, as most problems discussed in Section 6 became harder. For example, in ExbDR, higher arity of atoms increases the likelihood that an atom retrieved through a unification index does not unify with a given atom, and that the atoms of the selected GTGDs cannot be successfully matched. Subsumption indexing is also more difficult for similar reasons. However, the inputs used in this experiment consist of a large numbers of GTGDs with relations of arity ten, so they can be seen as a kind of a "stress test". Our algorithms were able to  process more than half of such inputs, which leads us to believe that they can also handle more well-behaved GTGDs used in practice.</p></div>
<div><head n="8">CONCLUSION</head><p>We presented several algorithms for rewriting a finite set of guarded TGDs into a Datalog program that entails the same base facts on each base instance. Our algorithms are based on a new framework that establishes a close connection between Datalog rewritings and a particular style of the chase. In future, we plan to generalize our framework to wider classes of TGDs, such as frontier-guarded TGDs, as well as provide rewritings for conjunctive queries under certain answer semantics. Moreover, we shall investigate whether the extension of our framework to disjunctive guarded TGDs <ref type="bibr" target="#b30">[31]</ref> can be used to obtain practical algorithms for rewriting disjunctive guarded TGDs into disjunctive Datalog programs.</p></div>
<div><head>A PROOFS FOR SECTION 4: ONE-PASS CHASE PROOFS</head><p>In Section 4 we introduced the notion of a one-pass chase proof, which allows us to establish a completeness criterion for saturations that is tied to the chase. We provide details of the proofs in this appendix.</p><p>A.1 Proof of Theorem 4.2: Existence of One-Pass Chase Proofs Theorem 4.2. For each base instance ğ¼ , each finite set of GTGDs Î£ in head-normal form, and each base fact ğ¹ such that ğ¼, Î£ |= ğ¹ , there exists a one-pass tree-like chase proof of ğ¹ from ğ¼ and Î£.</p><p>Throughout this section, we fix an arbitrary base instance ğ¼ and a finite set of GTGDs Î£. It is known that ğ¼, Î£ |= ğ¹ if and only if there exists a tree-like chase proof of ğ¹ from ğ¼ and Î£. We next prove Theorem 4.2 by showing that each such proof can be transformed to a one-pass chase proof of ğ¹ from ğ¼ and Î£. This argument was developed jointly with Antoine Amarilli, and it is related to proofs by Amarilli and Benedikt <ref type="bibr" target="#b3">[4]</ref> and Kappelmann <ref type="bibr" target="#b30">[31]</ref>; however, note that Definition 4.1 imposes slightly stronger conditions on one-pass chase sequences than related definitions in those works.</p><p>Towards our goal, we first state two basic properties of tree-like chase sequences. The first claim is a variation of the well-known fact that any chase tree produced for GTGDs represents a tree decomposition <ref type="bibr" target="#b14">[15]</ref>. The second claim captures the idea that, as the chase progresses, facts may be added within a vertex, but this will not produced new guarded sets of terms.</p><p>Lemma A.1. Let ğ‘‡ 0 , . . . ,ğ‘‡ ğ‘› be an arbitrary tree-like chase sequence for ğ¼ and Î£. 1. For each 0 â‰¤ ğ‘– â‰¤ ğ‘›, all vertices ğ‘£ 1 and ğ‘£ 2 in ğ‘‡ ğ‘– , each set ğº of ground terms that is Î£-guarded by ğ‘‡ ğ‘– (ğ‘£ 1 ) and by ğ‘‡ ğ‘– (ğ‘£ 2 ), and each vertex ğ‘£ 3 on the unique path in ğ‘‡ ğ‘– between ğ‘£ 1 and ğ‘£ 2 , set ğº is Î£-guarded by ğ‘‡ ğ‘– (ğ‘£ 3 ).</p><p>2. For each 0 â‰¤ ğ‘– â‰¤ ğ‘›, each vertex ğ‘£ in ğ‘‡ ğ‘– , each set ğº of ground terms that is Î£-guarded by ğ‘‡ ğ‘– (ğ‘£), and each 0 â‰¤ ğ‘— â‰¤ ğ‘– such that ğ‘‡ ğ‘— contains ğ‘£, set ğº is Î£-guarded by ğ‘‡ ğ‘— (ğ‘£).</p><p>Proof of Claim 1. The proof is by induction on ğ‘– with 0 â‰¤ ğ‘– â‰¤ ğ‘›. For ğ‘– = 0, chase tree ğ‘‡ 0 contains just one vertex so the claim holds trivially. Now assume that the property holds for some 0 â‰¤ ğ‘– &lt; ğ‘› and consider ways in which ğ‘‡ ğ‘–+1 can be derived from ğ‘‡ ğ‘– . First, ğ‘‡ ğ‘–+1 can be obtained by applying a chase step to ğ‘‡ ğ‘– at vertex ğ‘£ with some GTGD ğœ âˆˆ Î£. Let ğ‘£ 1 be the recently updated vertex of ğ‘‡ ğ‘–+1 . Thus, ğ‘£ 1 is either ğ‘£ or a fresh child of ğ‘£. Moreover, consider each fact ğ‘…( Ã¬ ğ‘¡) derived by the step, each set of ground terms ğº âŠ† Ã¬ ğ‘¡, each vertex ğ‘£ 2 such that ğº is Î£-guarded by ğ‘‡ ğ‘–+1 (ğ‘£ 2 ), and each vertex ğ‘£ 3 on the unique path in ğ‘‡ ğ‘–+1 between ğ‘£ 1 and ğ‘£ 2 . If ğº contains a labeled null that is freshly introduced in ğ‘‡ ğ‘–+1 , the claim holds trivially because ğ‘£ 2 and ğ‘£ 3 are necessarily the same as ğ‘£ 1 . Otherwise, ğœ is guarded, so ğ‘‡ ğ‘– (ğ‘£) contains a fact ğ‘† ( Ã¬ ğ‘¢) such that ğº âŠ† Ã¬ ğ‘¢. But then, ğº is Î£-guarded by ğ‘‡ ğ‘– (ğ‘£ 3 ) by the induction assumption. Moreover, ğ‘‡ ğ‘– (ğ‘£ 3 ) âŠ† ğ‘‡ ğ‘–+1 (ğ‘£ 3 ) ensures that ğº is Î£-guarded by ğ‘‡ ğ‘–+1 (ğ‘£ 3 ), as required. Second, ğ‘‡ ğ‘–+1 can be obtained by applying a propagation step to ğ‘‡ ğ‘– , but then the property clearly holds. â–¡</p><p>Proof of Claim 2. The proof is by induction on ğ‘– with 0 â‰¤ ğ‘– â‰¤ ğ‘›. The base case for ğ‘– = 0 is trivial. For the induction step, assume that the property holds for some ğ‘–. If ğ‘‡ ğ‘–+1 is obtained from ğ‘‡ ğ‘– by a chase step with a non-full GTGD, then the claim clearly holds for ğ‘‡ ğ‘–+1 because the step introduces a fresh vertex that does not occur in any ğ‘‡ ğ‘— with 0 â‰¤ ğ‘— â‰¤ ğ‘–. Otherwise, ğ‘‡ ğ‘–+1 is obtained by extending some ğ‘‡ ğ‘– (ğ‘£), so consider an arbitrary fact ğ¹ âˆˆ ğ‘‡ ğ‘–+1 (ğ‘£) \ ğ‘‡ ğ‘– (ğ‘£). Clearly, ğ¹ is Î£-guarded by ğ‘‡ ğ‘– (ğ‘£): if the step involves a full GTGD, then a body atom of the GTGD is matched to a fact ğ¹ â€² âˆˆ ğ‘‡ ğ‘– (ğ‘£) such that ğ¹ is Î£-guarded by ğ¹ â€² ; moreover, if the step involves propagation, then by definition there exists a fact ğ¹ â€² âˆˆ ğ‘‡ ğ‘– (ğ‘£) such that ğ¹ is Î£-guarded by ğ¹ â€² . Thus, each set of ground terms ğº that is Î£-guarded by ğ‘‡ ğ‘–+1 (ğ‘£) is also Î£-guarded by ğ¹ â€² âˆˆ ğ‘‡ ğ‘– (ğ‘£), so the claim holds. â–¡</p><p>In the rest of the proof, we show how to convert an arbitrary tree-like chase proof into a one-pass one through a series of transformations. Before proceeding, we next describe formally the types of chase sequence that we consider in our transformations.</p></div>
<div><head>Definition A.2.</head><p>â€¢ A chase sequence is local if each propagation step in the sequence copies just one fact to either the parent or a child vertex.</p><p>â€¢ A chase sequence is rootward if each propagation step in the sequence copies just one fact from a child to its parent.</p><p>â€¢ A chase sequence is almost one-pass if it is rootward and each chase or propagation step is applied to the recently updated vertex or an ancestor thereof, and a chase step is applied only if a propagation step is not applicable to the recently updated vertex or an ancestor thereof.</p><p>Note that facts can still be copied from a parent to a child in a rootward chase sequence, but this can be done only in chase steps with non-full GTGDs that introduce a child. Furthermore, the use of "almost" in the "almost one-pass" reflects the caveat that, in an almost one-pass chase sequence, a step can be applied to an ancestor of the recently updated vertex, thus "jumping rootward" in the tree, whereas such steps are forbidden in a one-pass chase sequence.</p><p>We capture formally the relationship between the chase sequences produced by our transformations using the notion introduced in Definition A.3.</p><p>Definition A.3. A chase tree ğ‘‡ is a subset of a chase tree ğ‘‡ â€² , written ğ‘‡ âŠ† ğ‘‡ â€² , if the tree of ğ‘‡ is a subtree of ğ‘‡ â€² (i.e., the root of ğ‘‡ is the root of ğ‘‡ â€² , and whenever vertex ğ‘£ is a parent of vertex ğ‘£ â€² in ğ‘‡ , then ğ‘£ is a parent of ğ‘£ â€² in ğ‘‡ â€² ), and ğ‘‡ (ğ‘£) âŠ† ğ‘‡ â€² (ğ‘£) holds for each vertex ğ‘£ of ğ‘‡ .</p><p>We are now ready to present our transformations, which we capture in a series of lemmas. We next summarize the main intuitions.</p><p>â€¢ In Lemma A.4, we show that an arbitrary chase sequence can be transformed into a local chase sequence by "slowing down" propagation steps so that facts are copied only between vertices that are adjacent in a chase tree. â€¢ In Lemma A.5, we show that each local chase sequence can be transformed into a rootward chase sequence. Intuitively, instead of propagating a fact from a parent to a child, we "regrow" a clone of the relevant child and the entire subtree underneath. The relevant fact is then copied as part of the chase step with the non-full GTGD that "regrows" the child's clone. â€¢ In Lemma A.6, we show that each rootward chase sequence can be transformed to an almost one-pass chase sequence. The main difficulty arises due to the fact that steps in a rootward chase sequence can be applied to arbitrary vertices. We address this problem by shuffling and regrowing parts of the chase trees. â€¢ Finally, in Lemma A.7, we show that each almost one-pass chase proof can be transformed to a one-pass chase proof by pruning irrelevant parts of the chase sequence.</p><p>Lemma A.4. For each tree-like chase sequence ğ‘‡ 0 , . . . ,ğ‘‡ ğ‘› for ğ¼ and Î£, there exists a local tree-like chase sequence ğ‘‡ 0 , . . . ,ğ‘‡ ğ‘š for ğ¼ and Î£ such that ğ‘‡ ğ‘› âŠ† ğ‘‡ ğ‘š .</p><p>Proof. Each propagation step in ğ‘‡ 0 , . . . ,ğ‘‡ ğ‘› that copies more than one fact can clearly be "expanded" into several steps, each copying just one fact. Moreover, due to Claim 1 of Lemma A.1, each propagation step that copies a fact ğ¹ between vertices ğ‘£ and ğ‘£ â€² that are further apart can be "expanded" into several steps that propagate ğ¹ to all vertices on the unique path between ğ‘£ and ğ‘£ â€² . â–¡ Lemma A.5. For each local tree-like chase sequence ğ‘‡ 0 , . . . ,ğ‘‡ ğ‘› for ğ¼ and Î£, there exists a rootward tree-like chase sequence ğ‘‡ 0 , . . . ,ğ‘‡ ğ‘š for ğ¼ and Î£ such that (S1) ğ‘‡ ğ‘› âŠ† ğ‘‡ ğ‘š , and (S2) for each vertex ğ‘£ in ğ‘‡ ğ‘› that is introduced by a chase step with a non-full GTGD ğœ âˆˆ Î£ and substitutions ğœ and ğœ â€² , vertex ğ‘£ is introduced into some ğ‘‡ ğ‘˜ with 0 â‰¤ ğ‘˜ â‰¤ ğ‘š by a chase step with the same ğœ, ğœ, and ğœ â€² .</p><p>Proof. Let ğ‘‡ 0 , . . . ,ğ‘‡ ğ‘› be an arbitrary local tree-like chase sequence for ğ¼ and Î£. We prove the claim by induction on 0 â‰¤ ğ‘– â‰¤ ğ‘›. The induction base ğ‘– = 0 holds trivially. For the induction step, we assume that the claim holds for some ğ‘– with 0 â‰¤ ğ‘– &lt; ğ‘›. By the inductive assumption, there exists a rootward chase sequence ğ‘‡ 0 , . . . ,ğ‘‡ ğ‘— for ğ¼ such that ğ‘‡ ğ‘– âŠ† ğ‘‡ ğ‘— and property (S2) holds. Let ğ‘£ be the vertex of ğ‘‡ ğ‘– to which a chase or propagation step is applied to derive ğ‘‡ ğ‘–+1 . By Definition A.3, chase tree ğ‘‡ ğ‘— contains vertex ğ‘£ and ğ‘‡ ğ‘– (ğ‘£) âŠ† ğ‘‡ ğ‘— (ğ‘£) holds. We now consider ways in which ğ‘‡ ğ‘–+1 can be derived from ğ‘‡ ğ‘– .</p><p>Assume that ğ‘‡ ğ‘–+1 is obtained from ğ‘‡ ğ‘– by a chase step with non-full TGD ğœ âˆˆ Î£, and let ğ‘£ â€² be the child of ğ‘£ introduced by the step. Without loss of generality, we can choose ğ‘£ â€² and the fresh labeled nulls such that they do not occur in ğ‘‡ ğ‘— . Now let ğ‘‡ ğ‘—+1 be obtained from ğ‘‡ ğ‘— by adding ğ‘£ â€² as a child of ğ‘£ and setting ğ‘‡ ğ‘—+1 (ğ‘£ â€² ) = ğ‘‡ ğ‘–+1 (ğ‘£ â€² ). Clearly, ğ‘‡ 0 , . . . ,ğ‘‡ ğ‘— ,ğ‘‡ ğ‘—+1 is a rootward chase sequence such that ğ‘‡ ğ‘–+1 âŠ† ğ‘‡ ğ‘—+1 and property (S2) hold, as required.</p><p>Assume that ğ‘‡ ğ‘–+1 is obtained from ğ‘‡ ğ‘– by a chase step with a full TGD ğœ âˆˆ Î£ deriving a fact ğ¹ , or by a rootward propagation step that copies a fact ğ¹ from ğ‘‡ ğ‘– (ğ‘£) to the parent of ğ‘£. Let ğ‘£ â€² be the recently updated vertex of ğ‘‡ ğ‘–+1 . Chase tree ğ‘‡ ğ‘— clearly contains ğ‘£ â€² . If ğ¹ âˆˆ ğ‘‡ ğ‘— (ğ‘£ â€² ), then sequence ğ‘‡ 0 , . . . ,ğ‘‡ ğ‘— satisfies the inductive property. If ğ‘‡ ğ‘–+1 is obtained from ğ‘‡ ğ‘– by a propagation step, then ğ¹ is Î£-guarded by ğ‘‡ ğ‘– (ğ‘£ â€² ). But then, ğ‘‡ ğ‘– (ğ‘£ â€² ) âŠ† ğ‘‡ ğ‘— (ğ‘£ â€² ) ensures that ğ¹ is also Î£-guarded by ğ‘‡ ğ‘— (ğ‘£ â€² ) and thus the propagation step is applicable to vertices ğ‘£ and ğ‘£ â€² in ğ‘‡ ğ‘— . Now let ğ‘‡ ğ‘—+1 to be the same as ğ‘‡ ğ‘— but with ğ‘‡ ğ‘—+1 (ğ‘£ â€² ) = ğ‘‡ ğ‘— (ğ‘£ â€² ) âˆª {ğ¹ } and with ğ‘£ â€² being the recently updated vertex. Clearly, ğ‘‡ 0 , . . . ,ğ‘‡ ğ‘— ,ğ‘‡ ğ‘—+1 is a rootward chase sequence satisfying ğ‘‡ ğ‘–+1 âŠ† ğ‘‡ ğ‘—+1 , as required. Moreover, property (S2) holds by the induction hypothesis.</p><p>The only remaining case is when ğ‘‡ ğ‘–+1 is obtained from ğ‘‡ ğ‘– by applying a propagation step that copies one fact ğ¹ to a child ğ‘£ â€² of ğ‘£. By Definition A.3, chase tree ğ‘‡ ğ‘— contains vertex ğ‘£ â€² and ğ‘‡ ğ‘– (ğ‘£ â€² ) âŠ† ğ‘‡ ğ‘— (ğ‘£ â€² ) holds. Sequence ğ‘‡ 0 , . . . ,ğ‘‡ ğ‘— satisfies the inductive property if ğ¹ âˆˆ ğ‘‡ ğ‘— (ğ‘£ â€² ) holds, so we next assume ğ¹ âˆ‰ ğ‘‡ ğ‘— (ğ‘£ â€² ). We next show that we can simulate propagation by "replaying" the chase steps that generate ğ‘£ â€² and all of its descendants. Towards this goal, let ğ‘‡ ğ‘˜ be the chase tree in the original sequence where ğ‘£ â€² is first introduced by applying a chase step with the non-full GTGD ğœ = ğ›½ â†’ âˆƒÃ¬ ğ‘¦ ğœ‚ âˆˆ Î£, and let ğœ and ğœ â€² be substitutions used in the step. By the inductive property (S2), there exists â„“ 0 with 0 &lt; â„“ 0 â‰¤ ğ‘— such that ğ‘£ â€² is introduced in ğ‘‡ â„“ 0 as the result of applying a chase step with the same non-full TGD ğœ and substitutions ğœ and ğœ â€² . Finally, let ğ‘‡ â„“ 0 , . . . ,ğ‘‡ â„“ ğ‘š be the subsequence of ğ‘‡ 0 , . . . ,ğ‘‡ ğ‘— consisting of precisely those chase trees that were obtained by applying a chase or a propagation step to ğ‘£ â€² or a descendant of ğ‘£ â€² . In other words, the chase steps producing ğ‘‡ â„“ 0 , . . . ,ğ‘‡ â„“ ğ‘š are exactly the steps that we need to "replay" to simulate the propagation of ğ¹ from ğ‘£ to ğ‘£ â€² .</p><p>Our objective is to "replay" the steps producing ğ‘‡ â„“ 0 , . . . ,ğ‘‡ â„“ ğ‘š so that they introduce exactly the same vertices and labeled nulls, which is needed because property (S1) talks about exact containment of the final chase trees of the two sequences (rather than containment up to isomorphism). A technical issue is that these vertices and labeled nulls already occur in the sequence ğ‘‡ 0 , . . . ,ğ‘‡ ğ‘— ; thus, if we extended this sequence directly, we could not "reapply" the chase steps with non-full GTGDs, which by definition introduce fresh vertices and labeled nulls. To get around this, we first perform the following renaming step. Let ğ‘ be the set of labeled nulls introduced by the chase steps with non-full TGDs in subsequence ğ‘‡ â„“ 0 , . . . ,ğ‘‡ â„“ ğ‘š , and let ğ‘Š be the set of introduced vertices (thus, ğ‘Š contains ğ‘£ â€² and all of its descendants). Moreover, let ğ‘ˆ 0 , . . . , ğ‘ˆ ğ‘— be the chase sequence obtained by uniformly replacing in ğ‘‡ 0 , . . . ,ğ‘‡ ğ‘— each labeled null in ğ‘ with a distinct, fresh labeled null, and by uniformly replacing each vertex ğ‘¤ âˆˆ ğ‘Š by a fresh vertex.</p><p>We next describe the chase trees that will be produced by "replaying" the steps producing the subsequence ğ‘‡ â„“ 0 , . . . ,ğ‘‡ â„“ ğ‘š . Intuitively, we must "graft" the results of these steps onto ğ‘ˆ ğ‘— : for ğ‘£ â€² or a descendant of ğ‘£ â€² we take the results of the chase steps in the subsequence, and for each other vertex we copy the content from ğ‘ˆ ğ‘— . Formally, let ğ‘‰ 0 , . . . , ğ‘‰ ğ‘š be the sequence obtained from the subsequence ğ‘‡ â„“ 0 , . . . ,ğ‘‡ â„“ ğ‘š using the following steps.</p><p>(R1) For each 0 â‰¤ ğ‘ â‰¤ ğ‘š and each vertex ğ‘¤ in ğ‘ˆ ğ‘— such that ğ‘¤ is neither ğ‘£ â€² nor a descendant of ğ‘£ â€² in ğ‘ˆ ğ‘— , we set ğ‘‰ ğ‘ (ğ‘¤) = ğ‘ˆ ğ‘— (ğ‘¤).</p><p>(R2) For each 0 â‰¤ ğ‘ â‰¤ ğ‘š and each vertex ğ‘¤ that occurs in ğ‘‡ â„“ ğ‘ such that ğ‘¤ is ğ‘£ â€² or a descendant of ğ‘£ â€² in ğ‘‡ â„“ ğ‘ , we set ğ‘‰ ğ‘ (ğ‘¤) = ğ‘‡ â„“ ğ‘ (ğ‘¤).</p><p>(R3) We add to ğ‘‰ 0 (ğ‘£ â€² ) each fact ğº âˆˆ ğ‘ˆ ğ‘— (ğ‘£) that is Î£-guarded by ğœ â€² (ğœ‚).</p><p>(R4) We analogously extend each ğ‘‰ ğ‘ with 1 â‰¤ ğ‘ â‰¤ ğ‘š to ensure that each chase step with a non-full GTGD correctly propagates all relevant facts to a child.</p><p>We now argue that ğ‘ˆ 0 , . . . , ğ‘ˆ ğ‘— , ğ‘‰ 0 , . . . , ğ‘‰ ğ‘š is a rootward chase sequence that satisfies properties (S1) and (S2). Towards this goal, we make the following observations.</p><p>â€¢ Sequence ğ‘ˆ 0 , . . . , ğ‘ˆ ğ‘— is a rootward chase sequence produced by the same steps as ğ‘‡ 0 , . . . ,ğ‘‡ ğ‘— , but with the vertices in ğ‘Š and labeled nulls in ğ‘ uniformly renamed. Also, due to step (R4), ğ‘‰ 0 , . . . , ğ‘‰ ğ‘š is a rootward chase sequence produced by the same steps as ğ‘‡ â„“ 0 , . . . ,ğ‘‡ â„“ ğ‘š .</p><p>â€¢ Chase tree ğ‘‰ 0 coincides with ğ‘ˆ ğ‘— on each vertex that is not ğ‘£ â€² or a descendant of ğ‘£ â€² . Moreover, ğ‘ˆ ğ‘— does not contain a labeled null in ğ‘ , and it does not contain ğ‘£ â€² or a descendant of ğ‘£ â€² ; thus, ğ‘‰ 0 can be seen as the result of applying to ğ‘ˆ ğ‘— a chase step with the non-full GTGD ğœ and substitutions ğœ and ğœ â€² that introduces vertex ğ‘£ â€² as a child of ğ‘£.</p><p>â€¢ We now show that property (S2) is satisfied-that is, that ğ‘‡ ğ‘–+1 âŠ† ğ‘‰ ğ‘š holds. Towards this goal, consider an arbitrary vertex ğ‘¤ occurring in ğ‘‡ ğ‘–+1 ; by the induction assumption, we have ğ‘‡ ğ‘– (ğ‘¤) âŠ† ğ‘‡ ğ‘— (ğ‘¤). If ğ‘¤ is neither ğ‘£ â€² nor a descendant thereof, then neither ğ‘¤ nor a labeled null occurring in ğ‘‡ ğ‘– (ğ‘¤) was renamed in ğ‘ˆ ğ‘— , so we have ğ‘‡ ğ‘— (ğ‘¤) = ğ‘ˆ ğ‘— (ğ‘¤) = ğ‘‰ ğ‘š (ğ‘¤), where the last equality is ensured by step (R1); thus, ğ‘‡ ğ‘–+1 (ğ‘¤) = ğ‘‡ ğ‘– (ğ‘¤) âŠ† ğ‘‰ ğ‘š (ğ‘¤) holds, as required. Now assume that ğ‘¤ is ğ‘£ â€² or a descendant thereof. Then, ğ‘‡ ğ‘— (ğ‘¤) = ğ‘‡ â„“ ğ‘š (ğ‘¤) holds by the fact that ğ‘‡ â„“ ğ‘š is the last place in ğ‘‡ 0 , . . . ,ğ‘‡ ğ‘— where ğ‘£ â€² or a descendant of ğ‘£ â€² was modified, and ğ‘‡ â„“ ğ‘š (ğ‘¤) = ğ‘‰ ğ‘š (ğ‘¤) holds by step (R2); putting it all together, we have ğ‘‡ ğ‘– (ğ‘¤) âŠ† ğ‘‰ ğ‘š (ğ‘¤). Now if ğ‘¤ is not ğ‘£ â€² (i.e., ğ‘¤ is a descendant of ğ‘£ â€² ), then ğ‘‡ ğ‘–+ğ‘– (ğ‘¤) = ğ‘‡ ğ‘– (ğ‘¤) âŠ† ğ‘‰ ğ‘š (ğ‘¤) holds, as required.</p><p>We finally consider the case when ğ‘¤ is ğ‘£ â€² , so ğ‘‡ ğ‘–+1 (ğ‘£ â€² ) = ğ‘‡ ğ‘– (ğ‘£ â€² ) âˆª {ğ¹ }. Since the propagation step is applicable to ğ‘‡ ğ‘– , fact ğ¹ is Î£-guarded by ğ‘‡ ğ‘– (ğ‘£ â€² ). By Claim 2 of Lemma A.1, fact ğ¹ is also Î£-guarded by ğ‘‡ ğ‘˜ (ğ‘£ â€² ). Finally, by the definition of a chase step with a non-full TGD, fact ğ¹ is Î£-guarded by ğœ â€² (ğœ‚). But then, step (R3) ensures ğ¹ âˆˆ ğ‘‰ 0 (ğ‘£ â€² ) âŠ† ğ‘‰ ğ‘š (ğ‘£ â€² ). Consequently, ğ‘‡ ğ‘–+ğ‘– (ğ‘£ â€² ) âŠ† ğ‘‰ ğ‘š (ğ‘£ â€² ) holds, as required.</p><p>â€¢ We now show that property (S2) is satisfied. To this end, consider an arbitrary vertex ğ‘¤ in ğ‘‡ ğ‘–+1 introduced by a chase step with a non-full GTGD ğœ and substitutions ğœ and ğœ â€² . If ğ‘¤ is not ğ‘£ â€² or a descendant thereof, then the labeled nulls introduced by the chase step are not renamed in ğ‘ˆ 0 , . . . , ğ‘ˆ ğ‘— , so the claim holds by the induction assumption. Otherwise, the chase steps producing ğ‘‰ 0 , . . . , ğ‘‰ ğ‘š are exactly the same as the chase steps producing ğ‘‡ â„“ 0 , . . . ,ğ‘‡ â„“ ğ‘š , so the claim holds by the induction assumption too. â–¡ Lemma A.6. For each rootward tree-like chase sequence ğ‘‡ 0 , . . . ,ğ‘‡ ğ‘› for ğ¼ and Î£, there exists an almost one-pass chase sequence ğ‘‡ 0 , . . . ,ğ‘‡ ğ‘š for ğ¼ and Î£ such that ğ‘‡ ğ‘› âŠ† ğ‘‡ ğ‘š .</p><p>Proof. Let ğ‘‡ 0 , . . . ,ğ‘‡ ğ‘› be an arbitrary rootward tree-like chase sequence for ğ¼ and Î£. The induction base ğ‘– = 0 holds trivially. For the induction step, we assume that the claim holds for some ğ‘– with 0 â‰¤ ğ‘– &lt; ğ‘›. By the inductive assumption, there exists an almost one-pass chase sequence ğ‘‡ 0 , . . . ,ğ‘‡ ğ‘— for ğ¼ and Î£ such that ğ‘‡ ğ‘– âŠ† ğ‘‡ ğ‘— holds. Now assume that ğ‘‡ ğ‘–+1 is obtained by applying a chase or a propagation step to some vertex ğ‘£ of ğ‘‡ ğ‘– , and let ğ‘˜ be the maximal number such that 0 â‰¤ ğ‘˜ â‰¤ ğ‘— and ğ‘£ is recently updated in ğ‘‡ ğ‘˜ . Such ğ‘˜ clearly exists since ğ‘£ occurs in ğ‘‡ ğ‘— , and ğ‘‡ ğ‘– (ğ‘£) âŠ† ğ‘‡ ğ‘˜ (ğ‘£) holds because ğ‘˜ is maximal. We now consider ways in which ğ‘‡ ğ‘–+1 can be derived from ğ‘‡ ğ‘– .</p><p>Assume that ğ‘‡ ğ‘–+1 is obtained from ğ‘‡ ğ‘– by a chase step with non-full GTGD ğœ âˆˆ Î£ and substitutions ğœ and ğœ â€² , and let ğ‘£ â€² be the child of ğ‘£ introduced by the step. Without loss of generality, we can choose ğ‘£ â€² and the fresh labeled nulls such that they do not occur in ğ‘‡ ğ‘— . We shall now "move" this chase step so that it is performed immediately after ğ‘‡ ğ‘˜ . Towards this goal, we describe the chase trees that are obtained by this move. For each ğ‘ with ğ‘˜ â‰¤ ğ‘ â‰¤ ğ‘—, let ğ‘ˆ ğ‘ be the chase tree obtained from ğ‘‡ ğ‘ by adding vertex ğ‘£ â€² and letting ğ‘ˆ ğ‘ (ğ‘£ â€² ) = ğ‘‡ ğ‘–+1 (ğ‘£ â€² ). We now argue that ğ‘‡ 0 , . . . ,ğ‘‡ ğ‘˜ , ğ‘ˆ ğ‘˜ , . . . , ğ‘ˆ ğ‘— is an almost one-pass chase sequence satisfying the conditions of the lemma.</p><p>â€¢ Chase tree ğ‘ˆ ğ‘˜ can be seen as obtained from ğ‘‡ ğ‘˜ by a chase step with ğœ and substitutions ğœ and ğœ â€² . Moreover, for each ğ‘ with ğ‘˜ â‰¤ ğ‘ &lt; ğ‘—, chase tree ğ‘ˆ ğ‘+1 is obtained from ğ‘ˆ ğ‘ in the same way as ğ‘‡ ğ‘+1 is obtained from ğ‘‡ ğ‘ . Thus, all preconditions of all chase steps are satisfied.</p><p>â€¢ Chase tree ğ‘ˆ ğ‘˜ is obtained from ğ‘‡ ğ‘˜ by applying the chase step to the recently updated vertex ğ‘£ of ğ‘‡ ğ‘˜ . Moreover, if ğ‘˜ &lt; ğ‘—, then ğ‘‡ ğ‘˜+1 is obtained from ğ‘‡ ğ‘˜ by applying a step to ğ‘£ or an ancestor of ğ‘£, and so ğ‘ˆ ğ‘˜+1 is obtained from ğ‘ˆ ğ‘˜ by applying a step to an ancestor of the recently updated vertex of ğ‘ˆ ğ‘˜ . Thus, the sequence is almost one-pass.</p><p>â€¢ The construction clearly satisfies ğ‘‡ ğ‘–+1 âŠ† ğ‘ˆ ğ‘— .</p><p>In the rest of this proof we consider the case when ğ‘‡ ğ‘–+1 is obtained from ğ‘‡ ğ‘– by a chase step with a full GTGD ğœ âˆˆ Î£ deriving a fact ğ¹ , or by a propagation step that copies a fact ğ¹ from ğ‘‡ ğ‘– (ğ‘£) to the parent of ğ‘£. Let ğ‘£ â€² be the recently updated vertex of ğ‘‡ ğ‘–+1 . Chase tree ğ‘‡ ğ‘— clearly contains ğ‘£ â€² . If ğ¹ âˆˆ ğ‘‡ ğ‘˜ (ğ‘£ â€² ), then sequence ğ‘‡ 0 , . . . ,ğ‘‡ ğ‘— satisfies the inductive property, so we next assume that ğ¹ âˆ‰ ğ‘‡ ğ‘˜ (ğ‘£ â€² ) holds. We shall now transform ğ‘‡ 0 , . . . ,ğ‘‡ ğ‘— so that this step is applied immediately after ğ‘‡ ğ‘˜ , and fact ğ¹ is propagated towards the root as far as possible. Since this will move the recently updated vertex towards the root, we will then "reapply" all relevant steps from ğ‘‡ 0 , . . . ,ğ‘‡ ğ‘— to "regrow" the relevant part of the sequence. In each case, we specify the structure of the chase trees and discuss the steps that produce these trees.</p><p>Let ğ‘ˆ 0 be obtained from ğ‘‡ ğ‘˜ by adding ğ¹ to ğ‘‡ ğ‘˜ (ğ‘£). We argue that ğ‘ˆ 0 can be seen as being obtained from ğ‘‡ ğ‘˜ by the same step that produces ğ‘‡ ğ‘–+1 from ğ‘‡ ğ‘– .</p><p>â€¢ If ğ‘‡ ğ‘–+1 is obtained from ğ‘‡ ğ‘– by a chase step with a full GTGD, then ğ¹ âˆ‰ ğ‘‡ ğ‘˜ (ğ‘£ â€² ) holds ensures that the same step is applicable to ğ‘‡ ğ‘˜ (ğ‘£ â€² ) (where ğ‘£ â€² = ğ‘£).</p><p>â€¢ If ğ‘‡ ğ‘–+1 is obtained from ğ‘‡ ğ‘– by a propagation step, then ğ¹ is Î£-guarded by ğ‘‡ ğ‘– (ğ‘£ â€² ). But then, ğ‘‡ ğ‘– (ğ‘£ â€² ) âŠ† ğ‘‡ ğ‘— (ğ‘£ â€² ) ensures that ğ¹ is also Î£-guarded by ğ‘‡ ğ‘— (ğ‘£ â€² ), and Claim 2 of Lemma A.1 ensures that ğ¹ is Î£-guarded by ğ‘‡ ğ‘˜ (ğ‘£ â€² ). Thus, the propagation step is applicable to vertices ğ‘£ and ğ‘£ â€² in ğ‘‡ ğ‘˜ .</p><p>Moreover, let ğ‘ˆ 1 , . . . , ğ‘ˆ ğ‘  be the chase trees obtained by propagating ğ¹ starting from ğ‘ˆ 0 towards the root using local steps as long as possible.</p><p>Clearly, ğ‘‡ 0 , . . . ,ğ‘‡ ğ‘˜ , ğ‘ˆ 0 , ğ‘ˆ 1 , . . . , ğ‘ˆ ğ‘  is a correctly formed almost one-pass chase sequence. Let ğ‘£ â€²â€² be the recently updated vertex of ğ‘ˆ ğ‘  , We cannot simply append the step producing ğ‘‡ ğ‘˜+1 after ğ‘ˆ ğ‘  because this step might not be applicable to ğ‘£ â€²â€² or an ancestor thereof. Thus, to obtain the chase sequence satisfying the claim of the lemma, we shall find a place in sequence ğ‘‡ 0 , . . . ,ğ‘‡ ğ‘— where vertex ğ‘£ â€²â€² is introduced, and we shall "replay" all steps from that point onwards. In doing so, we shall use chase steps that introduce the same vertices and labeled nulls, so we will first need to rename these in the sequence ğ‘‡ 0 , . . . ,ğ‘‡ ğ‘˜ , ğ‘ˆ 0 , ğ‘ˆ 1 , . . . , ğ‘ˆ ğ‘  .</p><p>Let â„“ be the smallest integer such that ğ‘‡ â„“ contains ğ‘£ â€²â€² . Clearly, â„“ â‰¤ ğ‘˜ holds. Now let ğ‘ be the set of labeled nulls introduced by applying a chase step to ğ‘£ â€²â€² or a descendant thereof, and let ğ‘Š the the set of descendants of ğ‘£ â€²â€² in the sequence ğ‘‡ 0 , . . . ,ğ‘‡ ğ‘— . Moreover, let</p><formula xml:id="formula_51">ğ‘‡ â€² 0 , . . . ,ğ‘‡ â€² ğ‘˜ , ğ‘ˆ â€² 0 , ğ‘ˆ â€² 1 , . . .</formula></div>
<div><head>, ğ‘ˆ</head><p>â€² ğ‘  be the chase sequence obtained by uniformly replacing in ğ‘‡ 0 , . . . ,ğ‘‡ ğ‘˜ , ğ‘ˆ 0 , ğ‘ˆ 1 , . . . , ğ‘ˆ ğ‘  each labeled null in ğ‘ with a distinct, fresh labeled null, and by uniformly replacing each vertex ğ‘¤ âˆˆ ğ‘Š by a fresh vertex.</p><p>We now transform chase trees ğ‘‡ â„“+1 , . . . ,ğ‘‡ ğ‘— into chase tress ğ‘‰ â„“+1 , . . . , ğ‘‰ ğ‘— that reflect the result of "replaying" after ğ‘ˆ â€² ğ‘  the steps producing the former sequence. Intuitively, each ğ‘‰ ğ‘ is a "union" of ğ‘ˆ ğ‘  and ğ‘‡ ğ‘ . Formally, for each ğ‘ with â„“ &lt; ğ‘ â‰¤ ğ‘—, we define ğ‘‰ ğ‘ as follows. â€¢ For â„“ â‰¤ ğ‘ &lt; ğ‘—, either ğ‘‰ ğ‘+1 is obtained from ğ‘‰ ğ‘ (or ğ‘ˆ â€² ğ‘  in case ğ‘ = â„“) by the same step that produces ğ‘‡ ğ‘+1 from ğ‘‡ ğ‘ , or the step is not applicable. In the latter case, we can simply drop such ğ‘‰ ğ‘+1 from the sequence. By dropping all such ğ‘‰ ğ‘+1 , we clearly obtain a valid almost one-pass chase sequence.</p><p>â€¢ We have ğ‘‡ ğ‘– âŠ† ğ‘‡ ğ‘— by the induction assumption, and steps (S1)-(S3) clearly ensure ğ‘‡ ğ‘– âŠ† ğ‘‰ ğ‘— . Moreover, ğ‘‡ ğ‘–+1 differs from ğ‘‡ ğ‘– only in vertex ğ‘£ â€² , where ğ‘‡ ğ‘–+1 (ğ‘£ â€² ) = ğ‘‡ (ğ‘£ â€² ) âˆª {ğ¹ } holds. Our construction, however, clearly ensures ğ¹ âˆˆ ğ‘ˆ â€² ğ‘  (ğ‘£ â€²â€² ), and step (S4) ensures that ğ¹ is propagated in each chase step with a non-full GTGD introducing a vertex on the unique path from ğ‘£ â€²â€² to ğ‘£ â€² . Thus, ğ‘‡ ğ‘–+1 âŠ† ğ‘‰ ğ‘— holds. â–¡ Lemma A.7. For each base fact ğ¹ and each almost one-pass tree-like chase proof of ğ¹ from ğ¼ and Î£, there exists a one-pass tree-like chase proof of ğ¹ from ğ¼ and Î£.</p><p>Proof. Consider an arbitrary base fact ğ¹ and an arbitrary almost one-pass tree-like chase proof ğ‘‡ 0 , . . . ,ğ‘‡ ğ‘› of ğ¹ from ğ¼ and Î£. Since ğ¹ is a base fact, without loss of generality we can assume that ğ¹ occurs in the facts of the root vertex. Now let ğ‘‡ ğ‘– be the first chase tree that contains ğ¹ in the root, and let ğ‘Š be the set containing each non-root vertex ğ‘£ occurring in any of the chase trees such that no propagation step is applied to ğ‘£. We transform this proof to a one-pass proof as follows. First, we delete each ğ‘‡ ğ‘— with ğ‘– &lt; ğ‘— â‰¤ ğ‘›. Next, we delete in each remaining ğ‘‡ ğ‘— each vertex ğ‘£ âˆˆ ğ‘Š and each descendant of ğ‘£. Finally, we delete each remaining ğ‘‡ ğ‘— that is equal to ğ‘‡ ğ‘—+1 . After this transformation, every vertex has a propagation step applied to it. It is straightforward to see that the result is a one-pass tree-like chase sequence. Moreover, since ğ¹ occurs in the root, the sequence is a tree-like chase proof of ğ¹ from ğ¼ and Î£. â–¡</p><p>A. â€¢ each Datalog rule of Î£ is a logical consequence of Î£ â€² , and</p><p>â€¢ for each base instance ğ¼ , each one-pass tree-like chase sequence ğ‘‡ 0 , . . . ,ğ‘‡ ğ‘› for ğ¼ and Î£, and each loop ğ‘‡ ğ‘– , . . . ,ğ‘‡ ğ‘— at the root vertex ğ‘Ÿ with output fact ğ¹ , there exist a Datalog rule ğ›½ â†’ ğ» âˆˆ Î£ â€² and a substitution ğœ such that ğœ (ğ›½) âŠ† ğ‘‡ ğ‘– (ğ‘Ÿ ) and ğœ (ğ» ) = ğ¹ .</p><p>Proof. Let Î£ and Î£ â€² be as specified in the proposition, let ğ¼ be an arbitrary base instance, and let ğ¹ be an arbitrary base fact. Since Î£ â€² is a logical consequence of Î£, it is clear that ğ¼, Î£ â€² |= ğ¹ implies ğ¼, Î£ |= ğ¹ . Thus, we assume that ğ¼, Î£ |= ğ¹ holds, and we prove that ğ¼, Î£ â€² |= ğ¹ holds as well. By Theorem 4.2, there exists a one-pass tree-like chase proof ğ‘‡ 0 , . . . ,ğ‘‡ ğ‘› of ğ¹ from ğ¼ and Î£. Without loss of generality, we can assume that ğ¹ is produced in the last step of the proof, and so the recently updated vertex of ğ‘‡ ğ‘› is root vertex ğ‘Ÿ . Let ğ‘– 0 &lt; â€¢ â€¢ â€¢ &lt; ğ‘– ğ‘š be exactly the indexes between 0 and ğ‘› such that the recently updated vertex of ğ‘‡ ğ‘– ğ‘— is ğ‘Ÿ . We next construct a tree-like chase sequence ğ‘‡ 0 , . . . ,ğ‘‡ ğ‘˜ for ğ¼ and Î£ â€² such that ğ‘‡ ğ‘› (ğ‘Ÿ ) âŠ† ğ‘‡ ğ‘˜ (ğ‘Ÿ ). To formalize our inductive construction of this chase sequence, we shall also construct a sequence of indexes â„“ 0 , . . . , â„“ ğ‘š such that â„“ ğ‘š = ğ‘˜ and, for each ğ‘— with 0 â‰¤ ğ‘— â‰¤ ğ‘š, we have ğ‘‡ ğ‘– ğ‘— (ğ‘Ÿ ) âŠ† ğ‘‡ â„“ ğ‘— (ğ‘Ÿ ); in other words, each index â„“ ğ‘— helps us establish the inductive property by relating ğ‘‡ ğ‘– ğ‘— and ğ‘‡ â„“ ğ‘— . For the base case, ğ‘– 0 = 0 holds by the definition of a tree-like chase proof; thus, we set ğ‘‡ 0 = ğ‘‡ 0 and â„“ 0 = 0, and the required property clearly holds. For the inductive step, we consider arbitrary 0 &lt; ğ‘— â‰¤ ğ‘š such that the claim holds for ğ‘— -1, and assume that the sequence constructed thus far is ğ‘‡ â„“ 0 , . . . ,ğ‘‡ â„“ ğ‘— -1 . We have the following two cases.</p><p>â€¢ The recently updated vertex of ğ‘‡ ğ‘– ğ‘— -1 is ğ‘Ÿ . Thus, ğ‘– ğ‘— -1 = ğ‘– ğ‘— -1 , and ğ‘‡ ğ‘– ğ‘— is obtained from ğ‘‡ ğ‘– ğ‘— by with a full GTGD ğ›½ â†’ ğ» âˆˆ Î£ producing a fact ğº âˆˆ ğ‘‡ ğ‘– ğ‘— (ğ‘Ÿ ). The second condition of the proposition ensures that ğ›½ â†’ ğ» is a logical consequence of Î£ â€² , so ğº can be derived from ğ‘‡ â„“ 1 (ğ‘Ÿ ) and the Datalog rules of Î£ â€² using â„˜ steps. We then define â„“ ğ‘— = â„“ ğ‘— -1 + â„˜, and we append the corresponding steps to obtain the sequence ğ‘‡ 0 , . . . ,ğ‘‡ We finally prove a property that will be needed in the proofs in Appendices B-E. This property intuitively ensures that, as soon as a fact ğ¹ is derived in the child vertex of a loop such that ğ¹ does not contain any null values introduced by the child, the loop is completed and ğ¹ is propagated to the parent vertex.</p><p>Proposition A.8. For each loop ğ‘‡ ğ‘– , . . . ,ğ‘‡ ğ‘— at a vertex ğ‘£ in a one-pass tree-like chase proof for some ğ¼ and Î£, for ğ‘– &lt; ğ‘˜ â‰¤ ğ‘—, and for ğ‘£ â€² the vertex introduced in ğ‘‡ ğ‘–+1 , set terms ğ‘‡ ğ‘˜ (ğ‘£ â€² ) \ nulls ğ‘‡ ğ‘–+1 (ğ‘£ â€² ) is Î£-guarded by ğ‘‡ ğ‘– (ğ‘£).</p><p>Proof. Consider an arbitrary loop ğ‘‡ ğ‘– , . . . ,ğ‘‡ ğ‘— at a vertex ğ‘£ in a one-pass tree-like chase proof for some ğ¼ and Î£, and let ğ‘£ â€² be the child of ğ‘£ introduced by the chase step producing ğ‘‡ ğ‘–+1 . We prove the claim by induction on ğ‘˜ with ğ‘– &lt; ğ‘˜ â‰¤ ğ‘—. For the induction base ğ‘˜ = ğ‘– + 1, the definition of a chase step with a non-full GTGD clearly ensures this claim for ğ‘‡ ğ‘–+1 (ğ‘£ â€² ). For the induction step, consider an arbitrary ğ‘˜ such that the claim holds. Our claim holds trivially if ğ‘‡ ğ‘˜+1 (ğ‘£ â€² ) = ğ‘‡ ğ‘˜ (ğ‘£ â€² ), so we assume that ğ‘‡ ğ‘˜+1 (ğ‘£ â€² ) \ ğ‘‡ ğ‘˜ (ğ‘£ â€² ) contains exactly one fact ğ¹ , which can be derived in one of the following two ways.</p><p>â€¢ Assume ğ¹ is obtained by a propagation step to vertex ğ‘£ â€² . Then, ğ¹ is Î£-guarded by ğ‘‡ ğ‘˜ (ğ‘£ â€² ), so terms(ğ¹ ) âŠ† terms ğ‘‡ ğ‘˜ (ğ‘£ â€² ) âˆª consts(Î£) holds.</p><p>â€¢ Assume ğ¹ is obtained by applying a full GTGD ğœ âˆˆ Î£ to ğ‘‡ ğ‘˜ (ğ‘£ â€² ) using a substitution ğœ. Then, ğœ contains a guard atom ğ´ in the body such that ğœ (ğ´) âŠ† ğ‘‡ ğ‘˜ (ğ‘£ â€² ); moreover, the head ğœ contains all variables of ğ´, and so we have terms(ğ¹ ) âŠ† terms ğ‘‡ ğ‘˜ (ğ‘£ â€² ) âˆª consts(Î£).</p><p>Either Proof of Correctness. Let Î£ â€² be the set Î£ closed under the ExbDR inferences rule as specified in Definition 5.3. It is straightforward to see that Î£ â€² is a logical consequence of Î£, so ExbDR(Î£) is also a logical consequence of Î£. Moreover, ExbDR(Î£) contains each full GTGD of Î£ up to redundancy, so each full GTGD of Î£ is logically entailed by ExbDR(Î£). We next consider an arbitrary base instance ğ¼ and a one-pass tree-like chase sequence for ğ¼ and Î£, and we show the following property:</p><p>(â™¦) for each loop ğ‘‡ ğ‘– , . . . ,ğ‘‡ ğ‘— in the sequence at some vertex ğ‘£ with output fact ğ¹ , there exist a full GTGD ğ›½ â†’ ğ» âˆˆ Î£ â€² and a substitution ğœ such that ğœ (ğ›½) âŠ† ğ‘‡ ğ‘– (ğ‘£) and ğ¹ = ğœ (ğ» ). Since ExbDR(Î£) contains all full TGDs of Î£ â€² and this property holds for the root vertex ğ‘Ÿ , Proposition 4.7 ensures that ExbDR(Î£) is a rewriting of Î£.</p><p>Our proof is by induction on the length of the loop. The base case and the inductive step have the same structure, so we consider them jointly. Thus, consider an arbitrary loop ğ‘‡ ğ‘– ,ğ‘‡ ğ‘–+1 , . . . ,ğ‘‡ ğ‘— -1 ,ğ‘‡ ğ‘— at vertex ğ‘£ in the sequence, and assume that the claim holds for all shorter loops in the sequence. By the definition of the loop, chase tree ğ‘‡ ğ‘–+1 is obtained from ğ‘‡ ğ‘– by applying a chase step to some non-full TGD âˆ€Ã¬ ğ‘¥ [ğ›½ 0 â†’ âˆƒÃ¬ ğ‘¦ ğœ‚ 0 ] âˆˆ Î£. Let ğœ 0 and ğœ â€² 0 be the substitutions used in this chase step, let ğ‘ = nulls(rng(ğœ â€² 0 )) \ nulls(rng(ğœ 0 )), let ğ‘£ â€² be the child of ğ‘£ introduced in ğ‘‡ ğ‘–+1 , and let ğ‘† âŠ† ğ‘‡ ğ‘– (ğ‘£) be the facts that are copied to ğ‘‡ ğ‘–+1 (ğ‘£ â€² ) because they are Î£-guarded by ğœ â€² 0 (ğœ‚ 0 ). Thus, we have ğ‘‡ ğ‘–+1 (ğ‘£ â€² ) = ğ‘† âˆª ğœ â€² 0 (ğœ‚ 0 ). By Proposition A.8 and the fact that a chase step is applied only if propagation to the parent is not applicable, the output fact of the loop is added to ğ‘‡ ğ‘— -1 (ğ‘£ â€² ) in step ğ‘— -1, and in ğ‘‡ ğ‘— this fact is propagated back to ğ‘‡ ğ‘— (ğ‘£). In other words, for each ğ‘˜ with ğ‘– &lt; ğ‘˜ &lt; ğ‘— -1, each fact in ğ‘‡ ğ‘˜ (ğ‘£ â€² ) \ ğ‘† contains at least one labeled null from ğ‘ , or the fact would be Î£-guarded by ğ‘‡ ğ‘– (ğ‘£) and thus propagated back to vertex ğ‘£. We show that, in the loop ğ‘‡ ğ‘– ,ğ‘‡ ğ‘–+1 , . . . ,ğ‘‡ ğ‘— -1 ,ğ‘‡ ğ‘— fixed above, the following property holds for each ğ‘˜ with ğ‘– &lt; ğ‘˜ &lt; ğ‘— -1:</p><p>(â™¢) there exist a GTGD âˆ€Ã¬ ğ‘¥ [ğ›½ â†’ âˆƒÃ¬ ğ‘¦ ğœ‚] âˆˆ Î£ â€² , a substitution ğœ such that ğœ (ğ›½) âŠ† ğ‘‡ ğ‘– (ğ‘£), and a substitution ğœ â€² that extends ğœ by mapping Ã¬ ğ‘¦ to fresh labeled nulls such that ğ‘‡ ğ‘˜ (ğ‘£ â€² ) âŠ† ğ‘† âˆª ğœ â€² (ğœ‚). We prove (â™¢) by induction on ğ‘˜. We have already proved the base case ğ‘˜ = ğ‘– + 1 above. For the inductive step, assume that (â™¢) holds for some ğ‘˜, so there exists a GTGD âˆ€Ã¬ ğ‘¥ [ğ›½ â†’ âˆƒÃ¬ ğ‘¦ ğœ‚] âˆˆ Î£ â€² and substitutions ğœ and ğœ â€² satisfying (â™¢) for ğ‘˜. Now consider ğ‘‡ ğ‘˜+1 . Property (â™¢) holds by the inductive hypothesis if ğ‘‡ ğ‘˜+1 (ğ‘£ â€² ) = ğ‘‡ ğ‘˜ (ğ‘£ â€² )-that is, if the step involves a descendant of ğ‘£ â€² . Otherwise, ğ‘‡ ğ‘˜+1 (ğ‘£ â€² ) = ğ‘‡ ğ‘˜ (ğ‘£ â€² ) âˆª {ğº } where fact ğº is obtained in one of the following two ways.</p><p>â€¢ A full GTGD in Î£ derives ğº from ğ‘‡ ğ‘˜ (ğ‘£ â€² ). Set Î£ â€² contains this GTGD up to redundancy, so by Definition 5.1 there exist a full GTGD ğ›½ â€²â€² â†’ ğ» â€² âˆˆ Î£ â€² and a substitution ğœŒ such that ğœŒ (ğ›½ â€²â€² ) âŠ† ğ‘‡ ğ‘˜ (ğ‘£ â€² ) and ğœŒ (ğ» â€² ) = ğº. â€¢ Fact ğº is the output of a loop at vertex ğ‘£ â€² . But then, this loop is shorter than ğ‘‡ ğ‘– , . . . ,ğ‘‡ ğ‘— so, by property (â™¦), there exists a full GTGD ğ›½ â€²â€² â†’ ğ» â€² âˆˆ Î£ â€² and a substitution ğœŒ such that ğœŒ (ğ›½ â€²â€² ) âŠ† ğ‘‡ ğ‘˜ (ğ‘£ â€² ) and ğœŒ (ğ» â€² ) = ğº. Since ğœ‚ is in head-normal form, each atom in ğœ â€² (ğœ‚) contains at least one labeled null of ğ‘ . Now let ğ´ â€² 1 , . . . , ğ´ â€² ğ‘› be the atoms of ğ›½ â€²â€² that are matched to the atoms in ğœ â€² (ğœ‚). Atom ğœŒ (ğ» â€² ) contains at least one labeled null of ğ‘ , so ğ‘› â‰¥ 1. Thus, we can assume that ğ›½ â€²â€² â†’ ğ» â€² is of the form ğ´ Moreover, some ğ´ â€² ğ‘– is a guard so all variables of ğ´ â€² 1 âˆ§ â€¢ â€¢ â€¢ âˆ§ ğ´ â€² ğ‘› âˆ§ ğ›½ â€² â†’ ğ» â€² participate in unification, and thus we can extend ğœ and ğœ â€² to substitutions ğœ and ğœ â€² , respectively, covering these variables such that ğœ (ğœƒ (ğ›½)) âˆª ğœ (ğœƒ (ğ›½ â€² )) âŠ† ğ‘‡ ğ‘– (ğ‘£) and ğ‘‡ ğ‘˜+1 (ğ‘£ â€² ) âŠ† ğ‘† âˆª ğœ â€² (ğœƒ (ğœ‚)) âˆª ğœ â€² (ğœƒ (ğ» â€² )). Set Î£ â€² contains ğœ up to redundancy. Since ğº âˆ‰ ğ‘‡ ğ‘˜ (ğ‘£ â€² ), GTGD ğœ is not a syntactic tautology, so there exists a GTGD âˆ€Ã¬ ğ‘¥ 1 [ğ›½ 1 â†’ âˆƒÃ¬ ğ‘¦ 1 ğœ‚ 1 ] âˆˆ Î£ â€² and substitution ğœ‡ such that dom(ğœ‡) = Ã¬ ğ‘¥ 1 âˆª Ã¬ ğ‘¦ 1 , ğœ‡ ( Ã¬ ğ‘¥ 1 ) âŠ† Ã¬ ğ‘¥ 2 , ğœ‡ ( Ã¬ ğ‘¦ 1 ) âŠ† Ã¬ ğ‘¦ 1 âˆª Ã¬ ğ‘¦ 2 and ğœ‡ (ğ‘¦) â‰  ğœ‡ (ğ‘¦ â€² ) for distinct ğ‘¦ and ğ‘¦ â€² in Ã¬ ğ‘¦ 1 , and ğœ‡ (ğ›½ 1 ) âŠ† ğœƒ (ğ›½) âˆ§ ğœƒ (ğ›½ â€² ) and ğœ‡ (ğœ‚ 1 ) âŠ‡ ğœƒ (ğœ‚) âˆ§ ğœƒ (ğ» â€² ). Now let ğœ 1 be the substitution defined as ğœ 1 (ğ‘¥) = ğœ (ğœ‡ (ğ‘¥)) on each ğ‘¥ âˆˆ Ã¬ ğ‘¥, and let ğœ â€² 1 be the extension of ğœ 1 to Ã¬ ğ‘¦ 1 such that ğœ â€² 1 (ğ‘¦) = ğœ â€² (ğœ‡ (ğ‘¦)) for each ğ‘¦ âˆˆ Ã¬ ğ‘¦. Clearly, ğœ 1 (ğ›½ 1 ) âŠ† ğ‘‡ ğ‘˜ (ğ‘£ â€² ) and ğ‘‡ ğ‘˜+1 (ğ‘£ ) âŠ† ğ‘† âˆª ğœ â€² 1 (ğœ‚ 1 ) hold, so property (â™¢) is satisfied. To complete the proof, consider now the derivation of ğ‘‡ ğ‘— -1 . By property (â™¢), there exists a GTGD âˆ€Ã¬ ğ‘¥ [ğ›½ â†’ âˆƒÃ¬ ğ‘¦ ğœ‚] âˆˆ Î£ â€² and substitutions ğœ and ğœ â€² such that ğœ (ğ›½) âŠ† ğ‘‡ ğ‘– (ğ‘£) and ğ‘‡ ğ‘— -2 (ğ‘£ â€² ) = ğ‘† âˆª ğœ â€² (ğœ‚). Then, as above, Î£ â€² contains a full TGD of the form ğ´ â€² 1 âˆ§ â€¢ â€¢ â€¢ âˆ§ ğ´ â€² ğ‘› âˆ§ ğ›½ â€² â†’ ğ» â€² that satisfies ğœŒ (ğ´ â€² 1 ) âˆª â€¢ â€¢ â€¢ âˆª ğœŒ (ğ´ â€² ğ‘› ) âŠ† ğœ â€² (ğœ‚) and ğœŒ (ğ›½ â€² ) âŠ† ğ‘† for some substitution ğœŒ. A minor difference is that ğœŒ (ğ» â€² ) does not contain a labeled null introduced by ğœ â€² (ğœ‚ 0 ), so ğ‘› = 0 is possible; however, in such a case, this TGD immediately satisfies property (â™¦). Moreover, if ğ‘› &gt; 0, then ğ›½ â†’ âˆƒÃ¬ ğ‘¦ ğœ‚ can again be resolved with ğ´ â€² 1 âˆ§ â€¢ â€¢ â€¢ âˆ§ ğ´ â€² ğ‘› âˆ§ ğ›½ â€² â†’ ğ» â€² to produce ğœƒ (ğ›½) âˆ§ ğœƒ (ğ›½ â€² ) â†’ âˆƒÃ¬ ğ‘¦ ğœƒ (ğœ‚) âˆ§ ğœƒ (ğ» â€² ) âˆˆ Î£ â€² satisfying vars(ğœƒ (ğ» â€² )) âˆ© Ã¬ ğ‘¦ = âˆ…. This TGD is transformed into head-normal form by Definition 5.3, so âˆ€Ã¬ ğ‘¥ [ğœƒ (ğ›½) âˆ§ ğœƒ (ğ›½ â€² ) â†’ ğœƒ (ğ» â€² )] is contained in Î£ â€² up to redundancy. But then, Î£ â€² contains a full GTGD that satisfies property (â™¦) by the same argument as above. â–¡</p><p>Proof of Complexity. Fix Î£, ğ‘Ÿ , ğ‘¤ ğ‘ , ğ‘¤ â„ , ğ‘, and ğ‘ as stated in the theorem. The number of different body atoms of arity ğ‘ constructed using ğ‘Ÿ relations, ğ‘¤ ğ‘ variables, and ğ‘ constants is clearly bounded by â„“ ğ‘ = ğ‘Ÿ â€¢ (ğ‘¤ ğ‘ + ğ‘) ğ‘ . Moreover, by the third claim of Proposition 5.7, the number of variables in the head of each TGD is bounded by ğ‘¤ â„ , so the number of head atoms is bounded by â„“ â„ = ğ‘Ÿ â€¢ (ğ‘¤ â„ + ğ‘) ğ‘ . The body (resp. head) of each GTGD corresponds to a subset of these atoms, so number of different GTGDs up to variable renaming is bounded by â„˜ = 2 â„“ ğ‘ â€¢ 2 â„“ â„ . Thus, the ExbDR inference rule needs to be applied to at most â„˜ 2 = 2 2(â„“ ğ‘ +â„“ â„ ) pairs of GTGDs. For each such pair, one might need to consider each possible way to match the â„“ ğ‘ body atoms of ğœ â€² to â„“ â„ head atoms of ğœ, and there are at most (â„“ â„ ) â„“ ğ‘ â‰¤ 2 â„“ ğ‘ â€¢â„“ â„ of these. Consequently, unifier ğœƒ may need to be computed at most 2 2(â„“ ğ‘ +â„“ â„ ) â€¢ 2 â„“ ğ‘ â€¢â„“ â„ â‰¤ 2 5â€¢â„“ ğ‘ â€¢â„“ â„ = 32 â„“ ğ‘ â€¢â„“ â„ times. To check whether TGD ğœ</p><formula xml:id="formula_52">1 = âˆ€Ã¬ ğ‘¥ 1 [ğ›½ 1 â†’ Ã¬ ğ‘¦ 1 ğœ‚ 1 ] is subsumed by ğœ 2 = âˆ€Ã¬ ğ‘¥ 2 [ğ›½ 2 â†’ Ã¬ ğ‘¦ 2 ğœ‚ 2 ]</formula><p>, we can proceed as follows. First, we consider all possible ways to match an atom of ğ›½ 1 to an atom of ğ›½ 2 ; since both conjunctions contain at most â„“ ğ‘ atoms, there are at most â„“ ğ‘ â„“ ğ‘ â‰¤ 2 â„“ ğ‘ 2 such matchings. Second, we analogously consider each of at most 2 (â„“ â„ ) 2 ways to match an atom of ğœ‚ 2 to an atom of ğœ‚ 1 . Once all atoms have been matched, we try to find a substitution ğœ‡ satisfying Definition 5.1 in linear time. Thus, a subsumption check for pairs of TGDs takes at most 2 â„“ ğ‘ 2 â€¢ 2 â„“ â„ 2 steps. Finally, unification of atoms requires time that is linear in ğ‘, and all other steps require linear time too. â–¡ C PROOFS FOR <software>SkDR</software> C.1 Proof of Proposition 5.12: Properties of <software ContextAttributes="used">SkDR</software></p><p>We reuse results by de Nivelle <ref type="bibr" target="#b18">[19]</ref> about unification of atoms in guarded rules. The variable depth [19, Definition 3] of an atom is defined as -1 if the atom is ground, or as the maximum number of nested function symbols that contain a variable of the atom. Moreover, an atom is weakly covering <ref type="bibr" target="#b18">[19,</ref><ref type="bibr">Definition 6]</ref> if each nonground functional subterm of the atom contains all variables of the atom. Finally, de Nivelle [19, Theorem 1] says that, for ğœƒ an MGU of weakly covering atoms ğ´ and ğµ, atom ğ¶ = ğœƒ (ğ´) = ğœƒ (ğµ) is also weakly covering, the variable depth of ğ¶ is bounded by the variable depth of ğ´ and ğµ, and the number of variables of ğ¶ is bounded by the number of variables of ğ´ and ğµ too.</p><p>Proposition 5.12. Each application of the SkDR inference rule to rules ğœ and ğœ â€² as in Definition 5.10 produces a guarded rule.</p><p>Proof. Consider arbitrary rules ğœ = ğ›½ â†’ ğ» and ğœ â€² = ğ´ â€² âˆ§ ğ›½ â€² â†’ ğ» â€² and an MGU ğœƒ of ğ» and ğ´ â€² satisfying the preconditions of the SkDR inference rule. Atom ğ» thus contains a Skolem symbol, and rule ğœ is guarded; consequently, atom ğ» is weakly covering, it contains a term of the form ğ‘“ ( Ã¬ ğ‘¡) where Ã¬ ğ‘¡ consists of constants and all variables of the rule, and the variable depth of ğ» is at most one. The corresponding atom ğ´ â€² can be of the following two forms.</p><p>â€¢ Atom ğ´ â€² is Skolem-free. But then, ğ´ â€² contains all variables of ğœ â€² , and it is clearly weakly covering. By de Nivelle <ref type="bibr">[19,</ref>   </p></div><figure xml:id="fig_0"><head>Definition 5 . 5 .</head><label>55</label><figDesc>The Existential-Based Datalog Rewriting inference rule ExbDR takes two guarded TGDs</figDesc></figure>
<figure xml:id="fig_1"><head>Theorem 5 . 8 .</head><label>58</label><figDesc>Program ExbDR(Î£) is a Datalog rewriting of a finite set of GTGDs Î£. Moreover, the rewriting can be computed in time ğ‘‚ (ğ‘ ğ‘Ÿ ğ‘‘ â€¢ (ğ‘¤ ğ‘ +ğ‘ ) ğ‘‘ğ‘ â€¢ğ‘Ÿ ğ‘‘ â€¢ (ğ‘¤ â„ +ğ‘ ) ğ‘‘ğ‘ ) for ğ‘Ÿ the number of relations in Î£, ğ‘ the maximum relation arity in Î£, ğ‘¤ ğ‘ = bwidth(Î£), ğ‘¤ â„ = hwidth(Î£), ğ‘ = |consts(Î£)|, and some ğ‘ and ğ‘‘.</figDesc></figure>
<figure xml:id="fig_2"><head>Definition 5 . 9 .</head><label>59</label><figDesc>Rule âˆ€Ã¬ ğ‘¥ [ğ›½ â†’ ğ» ] is guarded if each function symbol in the rule is a Skolem symbol, the body ğ›½ contains a Skolem-free atom ğ´ âˆˆ ğ›½ such that vars(ğ´) = Ã¬ ğ‘¥, and each Skolem term in the rule is of the form ğ‘“ ( Ã¬ ğ‘¡) where vars ğ‘“ ( Ã¬ ğ‘¡) = Ã¬ ğ‘¥ and Ã¬ ğ‘¡ is function-free. Definition 5.10. The Skolem Datalog Rewriting inference rule SkDR takes two guarded rules</figDesc></figure>
<figure xml:id="fig_3"><head>Proposition 5 .</head><label>5</label><figDesc>18 and Theorem 5.19 capture the properties of HypDR, and Proposition 5.20 compares it to SkDR. Proposition 5.18. Each application of the HypDR inference rule to rules ğœ 1 , . . . , ğœ ğ‘› and ğœ â€² as in Definition 5.16 produces a guarded rule. Theorem 5.19. Program HypDR(Î£) is a Datalog rewriting of a finite set of GTGDs Î£. Moreover, the rewriting can be computed in time time ğ‘‚ (ğ‘ ğ‘Ÿ ğ‘‘ â€¢ (ğ‘’+ğ‘¤ ğ‘ +ğ‘ ) ğ‘‘ğ‘ ) for ğ‘Ÿ the number of relations in Î£, ğ‘ the maximum relation arity in Î£, ğ‘’ the number of existential quantifiers in Î£, ğ‘¤ ğ‘ = bwidth(Î£), ğ‘ = |consts(Î£)|, and some ğ‘ and ğ‘‘. Proposition 5.20. There exists a family {Î£ ğ‘› } ğ‘›âˆˆN of finite sets of GTGDs such that SkDR derives ğ‘‚ (2 ğ‘› ) more rules than HypDR on each Î£ ğ‘› .</figDesc></figure>
<figure xml:id="fig_4"><head>Algorithm 1</head><label>1</label><figDesc>Computing Inf(Î£) for Î£ a finite set of GTGDs 1: W = âˆ… 2: U = the head-normal form or the Skolemization of Î£ 3: while U â‰  âˆ… do 4:</figDesc></figure>
<figure xml:id="fig_5"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Results for TGDs Derived from Ontologies</figDesc></figure>
<figure xml:id="fig_6"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Results for TGDs with Higher-Arity Relations</figDesc></figure>
<figure xml:id="fig_7"><head>(</head><label /><figDesc>S1) The chase tree ğ‘‰ ğ‘ contains the union of the vertices of ğ‘ˆ â€² ğ‘  and ğ‘‡ ğ‘ . (S2) For each vertex ğ‘¤ occurring only in ğ‘ˆ â€² ğ‘  (resp. ğ‘‡ ğ‘ ), we define ğ‘‰ ğ‘ (ğ‘¤) = ğ‘ˆ â€² ğ‘  (ğ‘¤) (resp. ğ‘‰ ğ‘ (ğ‘¤) = ğ‘‡ ğ‘ (ğ‘¤)). (S3) For each vertex ğ‘¤ occurring in both ğ‘ˆ â€² ğ‘  and ğ‘‡ ğ‘ , we define ğ‘‰ ğ‘ (ğ‘¤) = ğ‘ˆ â€² ğ‘  (ğ‘¤) âˆª ğ‘‡ ğ‘ (ğ‘¤). (S4) If ğ‘‡ ğ‘ is obtained by applying to a vertex ğ‘¤ of ğ‘‡ ğ‘ -1 a chase step with a non-full GTGD ğœ = âˆ€Ã¬ ğ‘¥ [ğ›½ â†’ âˆƒÃ¬ ğ‘¦ ğœ‚] and substitutions ğœ and ğœ â€² , then, for ğ‘¤ â€² the child of ğ‘¤ introduced by the step, we extend ğ‘‰ ğ‘ (ğ‘¤ â€² ) with each fact ğº âˆˆ ğ‘‰ ğ‘ -1 (ğ‘¤) that is Î£-guarded by ğœ â€² (ğœ‚). We now argue that ğ‘‡ â€² â„“+1 , . . . , ğ‘‰ ğ‘— contains an almost one-pass chase sequence for Î£ and ğ¼ that satisfies the conditions of this lemma. â€¢ Sequence ğ‘‡ â€² 0 , . . . ,ğ‘‡ â€² ğ‘˜ , ğ‘ˆ â€² 0 , ğ‘ˆ â€² 1 , . . . , ğ‘ˆ â€² ğ‘  is clearly a valid almost one-pass chase sequence.</figDesc></figure>
<figure xml:id="fig_8"><head>â€² 1 âˆ§</head><label>1</label><figDesc>â€¢ â€¢ â€¢ âˆ§ ğ´ â€² ğ‘› âˆ§ ğ›½ â€² â†’ ğ» â€² where {ğœŒ (ğ´ â€² 1 ), . . . , ğœŒ (ğ´ â€² ğ‘› )} âŠ† ğœ â€² (ğœ‚) and ğœŒ (ğ›½ â€² ) âŠ† ğ‘†. Also, since ğ›½ â€²â€² â†’ ğ» â€² is guarded, at least one of ğ´ â€² ğ‘– is a guard for ğ›½ â€²â€² â†’ ğ» â€² . Let ğ´ 1 , . . . , ğ´ ğ‘› be the atoms of ğœ‚ such that ğœ â€² (ğ´ ğ‘– ) = ğœŒ (ğ´ â€² ğ‘– ) for 1 â‰¤ ğ‘– â‰¤ ğ‘›. Since ğœ â€² maps each ğ‘¦ âˆˆ Ã¬ ğ‘¦ to a distinct labeled null that does not occur in ğ‘‡ ğ‘– , we have ğœ â€² ( Ã¬ ğ‘¥) âˆ© ğœ â€² ( Ã¬ ğ‘¦) = âˆ…. Thus, there exists a Ã¬ ğ‘¦-MGU ğœƒ of ğ´ 1 , . . . , ğ´ ğ‘› and ğ´ â€² 1 , . . . , ğ´ â€² ğ‘› satisfying ğœƒ ( Ã¬ ğ‘¥) âˆ© Ã¬ ğ‘¦ = âˆ…. Conjunction ğœŒ (ğ›½ â€² ) does not contain a labeled null of ğ‘ , so vars(ğœƒ (ğ›½ â€² )) âˆ© Ã¬ ğ‘¦ = âˆ… holds. Thus, the preconditions of the ExbDR inference rule are satisfied for âˆ€Ã¬ ğ‘¥ [ğ›½ â†’ âˆƒÃ¬ ğ‘¦ ğœ‚] and ğ´ â€² 1 âˆ§ â€¢ â€¢ â€¢ âˆ§ ğ´ â€² ğ‘› âˆ§ ğ›½ â€² â†’ ğ» â€² , so the ExbDR rule derives ğœ = ğœƒ (ğ›½) âˆ§ ğœƒ (ğ›½ â€² ) â†’ âˆƒÃ¬ ğ‘¦ ğœƒ (ğœ‚) âˆ§ ğœƒ (ğ» â€² ).</figDesc></figure>
<figure xml:id="fig_9"><head>Theorem 5 . 13 .</head><label>513</label><figDesc>Program SkDR(Î£) is a Datalog rewriting of a finite set of GTGDs Î£. Moreover, the rewriting can be computed in time ğ‘‚ (ğ‘ ğ‘Ÿ ğ‘‘ â€¢ (ğ‘’+ğ‘¤ ğ‘ +ğ‘ ) ğ‘‘ğ‘ ) for ğ‘Ÿ the number of relations in Î£, ğ‘ the maximum relation arity in Î£, ğ‘’ the number of existential quantifiers in Î£, ğ‘¤ ğ‘ = bwidth(Î£), ğ‘ = |consts(Î£)|, and some ğ‘ and ğ‘‘.</figDesc></figure>
<figure type="table" xml:id="tab_0"><head /><label /><figDesc>Skolemization allow us to replace existential quantifiers in TGDs by functional terms. Specifically, let ğœ = âˆ€Ã¬ ğ‘¥ [ğ›½ â†’ âˆƒÃ¬ ğ‘¦ ğœ‚], and let ğœ be a substitution defined on each ğ‘¦ âˆˆ Ã¬ ğ‘¦ as ğœ (ğ‘¦) = ğ‘“ ğœ,ğ‘¦ ( Ã¬ ğ‘¥) where ğ‘“ ğœ,ğ‘¦ is a fresh | Ã¬ ğ‘¥ |-ary Skolem symbol uniquely associated with ğœ and ğ‘¦. Then, the Skolemization of ğœ produces rules âˆ€Ã¬ ğ‘¥ [ğ›½ â†’ ğœ (ğ» )] for each atom ğ» âˆˆ ğœ‚. Moreover, the Skolemization Î£ â€² of a finite set of TGDs Î£ is the union of the rules obtained by Skolemizing each ğœ âˆˆ Î£. It is well known that ğ¼, Î£ |= ğ¹ if and only if ğ¼, Î£ â€² |= ğ¹ for each base instance ğ¼ and each base fact ğ¹ . Unification. A unifier of atoms ğ´ 1 , . . . , ğ´ ğ‘› and ğµ 1 , . . . , ğµ ğ‘› is a substitution ğœƒ such that ğœƒ (ğ´ ğ‘– ) = ğœƒ (ğµ ğ‘– ) for 1 â‰¤ ğ‘– â‰¤ ğ‘›. Such ğœƒ is a most general unifier (MGU) if, for each unifier ğœ of ğ´ 1 , . . . , ğ´ ğ‘› and ğµ 1 , . . . , ğµ ğ‘› , there exists a substitution ğœŒ such that ğœ = ğœŒ â€¢ ğœƒ (where â€¢ is function composition). An MGU is unique up to variable renaming if it exists, and it can be computed in time ğ‘‚ ( ğ‘› ğ‘–=1 |ğ´ ğ‘– | + |ğµ ğ‘– |) where |ğ´ ğ‘– | and |ğµ ğ‘– | are the encoding sizes of ğ´ ğ‘– and ğµ ğ‘–</figDesc><table /></figure>
<figure type="table" xml:id="tab_2"><head /><label /><figDesc>derive ğ» (ğ‘): we must first produce ğ‘£ 1 to be able to derive ğ‘£ 2 , and we must combine ğº (ğ‘) from ğ‘£ 2 and ğµ(ğ‘, ğ‘› 1 ) from ğ‘£ 1 .</figDesc><table><row><cell /><cell cols="2">ğ´(ğ‘, ğ‘)</cell><cell /><cell /><cell /><cell>ğ´(ğ‘, ğ‘)</cell></row><row><cell>ğ‘‡ 1 7</cell><cell cols="2">ğ¸ (ğ‘) ğº (ğ‘)</cell><cell /><cell cols="2">ğ‘‡ 2 7</cell><cell>ğ¸ (ğ‘) ğº (ğ‘)</cell></row><row><cell cols="2">ğµ(ğ‘, ğ‘›1)</cell><cell>ğ¸ (ğ‘)</cell><cell /><cell cols="2">ğµ(ğ‘, ğ‘›1)</cell><cell>ğ¸ (ğ‘)</cell><cell>ğµ(ğ‘, ğ‘›3)</cell></row><row><cell cols="2">ğ¶ (ğ‘, ğ‘›1)</cell><cell cols="2">ğ¹ (ğ‘, ğ‘›2)</cell><cell cols="2">ğ¶ (ğ‘, ğ‘›1)</cell><cell>ğ¹ (ğ‘, ğ‘›2)</cell><cell>ğ¶ (ğ‘, ğ‘›3)</cell></row><row><cell cols="2">ğ· (ğ‘, ğ‘›1)</cell><cell cols="2">ğ¹ (ğ‘›2, ğ‘›3)</cell><cell cols="2">ğ· (ğ‘, ğ‘›1)</cell><cell>ğ¹ (ğ‘›2, ğ‘›3)</cell><cell>ğ¸ (ğ‘)</cell></row><row><cell cols="2">ğ¸ (ğ‘)</cell><cell>ğº (ğ‘)</cell><cell /><cell>ğ¸ (ğ‘)</cell><cell /><cell>ğº (ğ‘)</cell><cell>ğº (ğ‘)</cell></row><row><cell /><cell /><cell /><cell /><cell /><cell /><cell>ğ´(ğ‘, ğ‘)</cell></row><row><cell>ğ‘‡ 1 8</cell><cell cols="2">ğ´(ğ‘, ğ‘) ğ¸ (ğ‘) ğº (ğ‘)</cell><cell /><cell /><cell /><cell>ğ‘‡9</cell><cell>ğ» (ğ‘) ğ¸ (ğ‘) ğº (ğ‘)</cell></row><row><cell>ğµ(ğ‘, ğ‘›1) ğ¶ (ğ‘, ğ‘›1) ğ· (ğ‘, ğ‘›1) ğ¸ (ğ‘)</cell><cell cols="2">ğ¸ (ğ‘) ğ¹ (ğ‘, ğ‘›2) ğ¹ (ğ‘›2, ğ‘›3) ğº (ğ‘)</cell><cell cols="2">ğµ(ğ‘, ğ‘›3) ğ¶ (ğ‘, ğ‘›3) ğ¸ (ğ‘) ğº (ğ‘) ğ» (ğ‘)</cell><cell cols="2">ğµ(ğ‘, ğ‘›1) ğ¶ (ğ‘, ğ‘›1) ğ· (ğ‘, ğ‘›1) ğ¸ (ğ‘)</cell><cell>ğ¸ (ğ‘) ğ¹ (ğ‘, ğ‘›2) ğ¹ (ğ‘›2, ğ‘›3) ğº (ğ‘)</cell><cell>ğµ(ğ‘, ğ‘›3) ğ¶ (ğ‘, ğ‘›3) ğ¸ (ğ‘) ğº (ğ‘) ğ» (ğ‘)</cell></row><row><cell cols="7">Figure 2: One-Pass Chase Sequence Obtained from Figure 1</cell></row></table></figure>
<figure type="table" xml:id="tab_3"><head /><label /><figDesc>conjunction ğ›½ ğ‘– is Skolem-free and atom ğ» ğ‘– contains a Skolem symbol, and â€¢ rule ğœ â€² is Skolem-free, and, for ğœƒ an MGU of ğ» 1 , . . . , ğ» ğ‘› and ğ´ â€²</figDesc><table /><note><p>1 , . . . , ğ´ â€² ğ‘› , if conjunction ğœƒ (ğ›½ â€² ) is Skolem-free, it derives</p></note></figure>
<figure type="table" xml:id="tab_4"><head>Table 1 :</head><label>1</label><figDesc>Input GTGDs at a Glance</figDesc><table><row><cell>Inputs</cell><cell /><cell># Full TGDs</cell><cell># Non-Full TGDs</cell></row><row><cell /><cell>Min</cell><cell cols="2">Max Avg Med Min</cell><cell>Max Avg Med</cell></row><row><cell>428</cell><cell cols="2">1 171,905 11,030 789</cell><cell>2 156,743 5,255 283</cell></row><row><cell cols="4">realistic inputs. Our objectives were to show that our algorithms</cell></row><row><cell cols="4">can indeed rewrite complex GTGDs, and that the rewriting can</cell></row><row><cell cols="4">be successfully processed by modern Datalog systems. In Subsec-</cell></row><row><cell cols="4">tion 7.1 we describe the test setting. Then, in Subsection 7.2 we</cell></row><row><cell cols="4">discuss the rewriting experiments with GTGDs obtained from on-</cell></row><row><cell cols="4">tologies, and in Subsection 7.3 we validate the usefulness of the</cell></row><row><cell cols="4">rewriting approach end-to-end. Finally, in Subsection 7.4 we discuss</cell></row><row><cell cols="4">rewriting GTGDs of higher arity. Due to the very large number of</cell></row><row><cell cols="4">inputs, we can only summarize our results in this paper; however,</cell></row><row><cell cols="4">our complete evaluation results are available online [13].</cell></row></table></figure>
<figure type="table" xml:id="tab_5"><head /><label /><figDesc>GHz and 16 GB of RAM, running Ubuntu 20.04.4 LTS and Java 11.0.15. In each test run, we loaded a set of TGDs, measured the wall-clock time required to compute</figDesc><table><row><cell /><cell /><cell cols="2">Time (s)</cell><cell /><cell /><cell /><cell /></row><row><cell /><cell cols="2">585</cell><cell cols="2">ExbDR</cell><cell /><cell /><cell /></row><row><cell /><cell cols="2">100</cell><cell>SkDR</cell><cell /><cell /><cell /><cell /></row><row><cell /><cell /><cell /><cell cols="2">HypDR</cell><cell /><cell /><cell /></row><row><cell /><cell cols="2">10</cell><cell cols="2">KAON2</cell><cell /><cell /><cell /></row><row><cell /><cell /><cell>1</cell><cell /><cell /><cell /><cell /><cell /></row><row><cell /><cell cols="2">0.1</cell><cell /><cell /><cell /><cell /><cell /></row><row><cell /><cell /><cell /><cell cols="5">Nr. of Processed Sets of TGDs</cell></row><row><cell /><cell /><cell /><cell /><cell /><cell>ExbDR</cell><cell cols="3">SkDR HypDR KAON2</cell></row><row><cell cols="4"># of Processed Inputs</cell><cell /><cell>367</cell><cell>377</cell><cell cols="2">382</cell><cell>362</cell></row><row><cell cols="4">Max. Processed Input Size</cell><cell /><cell cols="4">185,515 324,092 324,092</cell><cell>N/A</cell></row><row><cell cols="3">Max. Output Size</cell><cell /><cell /><cell cols="4">196,594 124,846 124,846</cell><cell>61,964</cell></row><row><cell cols="3">Max. Size Blowup</cell><cell /><cell /><cell>8.95</cell><cell>8.85</cell><cell cols="2">8.85</cell><cell>N/A</cell></row><row><cell cols="5">Max. Body Atoms in Output</cell><cell>7</cell><cell>6</cell><cell /><cell>6</cell><cell>4</cell></row><row><cell cols="3"># Blowup â‰¥ 1.5</cell><cell /><cell /><cell>26</cell><cell>14</cell><cell /><cell>16</cell><cell>N/A</cell></row><row><cell>Time (s)</cell><cell>Min. Max. Avg. Med.</cell><cell /><cell /><cell /><cell>0.05 582.18 23.23 0.82</cell><cell>0.05 584.79 14.34 0.52</cell><cell cols="2">0.04 404.34 6.38 0.55</cell><cell>0.21 547.53 18.66 0.49</cell></row><row><cell /><cell /><cell cols="4">time (ğ‘Œ )/time (ğ‘‹ ) â‰¥ 10</cell><cell cols="3">ğ‘‹ and ğ‘Œ both fail</cell></row><row><cell>ğ‘‹</cell><cell>ğ‘Œ</cell><cell cols="4">ExbDR SkDR HypDR KAON2</cell><cell cols="3">ExbDR SkDR HypDR KAON2</cell></row><row><cell cols="2">ExbDR</cell><cell /><cell>19</cell><cell>0</cell><cell>19</cell><cell>61</cell><cell /></row><row><cell cols="2">SkDR</cell><cell>37</cell><cell /><cell>0</cell><cell>26</cell><cell>33</cell><cell>51</cell></row><row><cell cols="2">HypDR</cell><cell>37</cell><cell>12</cell><cell /><cell>31</cell><cell>35</cell><cell>43</cell><cell>46</cell></row><row><cell cols="2">KAON2</cell><cell>35</cell><cell>15</cell><cell>0</cell><cell /><cell>37</cell><cell>47</cell><cell>46</cell><cell>66</cell></row></table></figure>
<figure type="table" xml:id="tab_6"><head>Table 2 :</head><label>2</label><figDesc>Computing the Fixpoint of the Rewriting</figDesc><table><row><cell cols="5">Ont. ID # Rules # Input Facts # Output Facts Time (s)</cell></row><row><cell>00387</cell><cell>63,422</cell><cell>4,403,105</cell><cell>51,439,424</cell><cell>53</cell></row><row><cell>00448</cell><cell>67,986</cell><cell>5,510,444</cell><cell>107,235,697</cell><cell>110</cell></row><row><cell>00470</cell><cell>75,146</cell><cell>10,532,943</cell><cell>141,396,446</cell><cell>242</cell></row><row><cell>00471</cell><cell>78,977</cell><cell>11,077,423</cell><cell>128,954,126</cell><cell>253</cell></row><row><cell>00472</cell><cell>75,146</cell><cell>10,533,008</cell><cell>141,396,576</cell><cell>279</cell></row><row><cell>00473</cell><cell>78,977</cell><cell>11,077,459</cell><cell>128,954,198</cell><cell>291</cell></row><row><cell>00573</cell><cell>113,959</cell><cell>9,197,254</cell><cell>155,118,592</cell><cell>206</cell></row><row><cell>00682</cell><cell>68,461</cell><cell>5,183,460</cell><cell>105,431,952</cell><cell>101</cell></row><row><cell>00684</cell><cell>81,553</cell><cell>6,057,017</cell><cell>66,981,628</cell><cell>109</cell></row><row><cell>00686</cell><cell>124,846</cell><cell>10,402,324</cell><cell>166,366,039</cell><cell>238</cell></row></table></figure>
<figure type="table" xml:id="tab_8"><head /><label /><figDesc>2 Proof of Proposition 4.7: Rewriting Criterion Using One-pass Chase Proofs Proposition 4.7. A Datalog program Î£ â€² is a rewriting of a finite set of GTGDs Î£ in head-normal form if â€¢ Î£ â€² is a logical consequence of Î£,</figDesc><table /></figure>
<figure type="table" xml:id="tab_9"><head /><label /><figDesc>â„“ ğ‘— -1 , . . . ,ğ‘‡ â„“ ğ‘— . â€¢ Otherwise, ğ‘‡ ğ‘– ğ‘— -1 , . . . ,ğ‘‡ ğ‘– ğ‘— is a loop at the root vertex ğ‘Ÿ with some output fact ğº âˆˆ ğ‘‡ ğ‘– ğ‘— (ğ‘Ÿ ). The third condition of the proposition ensures that there exists a Datalog rule ğ›½ â†’ ğ» âˆˆ Î£ â€² and a substitution ğœ such that ğœ (ğ›½) âŠ† ğ‘‡ ğ‘– (ğ‘Ÿ ) and ğœ (ğ» ) = ğº. We define â„“ ğ‘— = â„“ ğ‘— -1 + 1, and we define ğ‘‡ â„“ ğ‘— as the the chase tree containing just the root vertex ğ‘Ÿ such that ğ‘‡ â„“ ğ‘— (ğ‘Ÿ ) = ğ‘‡ â„“ ğ‘— -1 (ğ‘Ÿ ) âˆª {ğº }; thus, ğ‘‡ â„“ ğ‘— is obtained from ğ‘‡ â„“ ğ‘— -1 by applying the Datalog rule ğ›½ â†’ ğ» âˆˆ Î£ â€² to the root vertex ğ‘Ÿ . Moreover, ğ‘‡ ğ‘– ğ‘— (ğ‘Ÿ ) âŠ† ğ‘‡ â„“ ğ‘— (ğ‘Ÿ ) clearly holds, as required.</figDesc><table /><note><p>â–¡ A.3 Proof of Proposition A.8: Properties of One-Pass Chase Proofs</p></note></figure>
<figure type="table" xml:id="tab_10"><head /><label /><figDesc>way, we have terms ğ‘‡ ğ‘˜+1 (ğ‘£ â€² ) âŠ† terms ğ‘‡ ğ‘˜ (ğ‘£ â€² ) âˆª consts(Î£). By the induction assumption, set terms ğ‘‡ ğ‘˜ (ğ‘£ â€² ) \ nulls(ğ‘‡ ğ‘–+1 (ğ‘£ â€² )) is Î£-guarded by ğ‘‡ ğ‘– (ğ‘£), and so set terms ğ‘‡ ğ‘˜ 1 (ğ‘£ â€² ) \ nulls(ğ‘‡ ğ‘–+1 (ğ‘£ â€² )) is also Î£-guarded by ğ‘‡ ğ‘– (ğ‘£), as required.â–¡ B PROOFS FOR ExbDR B.1 Proof of Proposition 5.7: Properties of ExbDR Proposition 5.7. Each application of the ExbDR inference rule to ğœ, ğœ â€² , and ğœƒ as in Definition 5.5 satisfies the following properties. 1. Some atom ğ´ â€² ğ‘– with 1 â‰¤ ğ‘– â‰¤ ğ‘› is a guard in ğœ â€² . 2. For each 1 â‰¤ ğ‘– â‰¤ ğ‘› such that ğ´ â€² ğ‘– is a guard of ğœ â€² , and for ğœ the Ã¬ ğ‘¦-MGU of ğ´ â€² ğ‘– and the corresponding atom ğ´ ğ‘– such that ğœ ( Ã¬ ğ‘¥) âˆ© Ã¬ ğ‘¦ = âˆ…, it is the case that vars ğœ (ğ´ â€² ğ‘— ) âˆ© Ã¬ ğ‘¦ â‰  âˆ… for each 1 â‰¤ ğ‘— â‰¤ ğ‘›. 3. The result is a GTGD whose body and head width are at most bwidth(Î£) and hwidth(Î£), respectively. Proof of Claim 1. Let ğº be a guard for ğœ â€² . For the sake of a contradiction, assume that ğº is not one of the atoms ğ´ â€² ğ´ 1 , atom ğ´ â€² 1 contains at some position a variable ğ‘§ such that ğœƒ (ğ‘§) = ğ‘¦. Since ğº is a guard for ğœ â€² , variable ğ‘§ occurs in ğº. Therefore, we have vars(ğœƒ (ğº)) âˆ© Ã¬ ğ‘¦ â‰  âˆ…, which contradicts the requirement vars(ğœƒ (ğ›½ â€² )) âˆ© Ã¬ ğ‘¦ = âˆ… of the ExbDR inference rule. â–¡ Proof of Claim 2. Consider arbitrary ğ‘– such that 1 â‰¤ ğ‘– â‰¤ ğ‘› and ğ´ â€² ğ‘– is a guard of ğœ â€² , and let ğœ be an MGU of ğ´ â€² ğ‘– and the corresponding atom ğ´ ğ‘– of ğœ. Since ğœƒ is a unifier of ğ´ â€² ğ‘– and ğ´ ğ‘– as well as of other pairs of atoms, there clearly exists a substitution ğœŒ such that ğœƒ = ğœŒ â€¢ ğœ. Now consider an arbitrary ğ´ â€² ğ‘— with 1 â‰¤ ğ‘— â‰¤ ğ‘› in ğœ â€² . Substitution ğœƒ matches ğ´ â€² ğ‘— to the corresponding atom ğ´ ğ‘— in the head of ğœ. Since TGD ğœ is in head-normal form, atom ğ´ ğ‘— contains at least one variable ğ‘¦ âˆˆ Ã¬ ğ‘¦. Since ğœƒ (ğ‘¦) = ğ‘¦, we necessarily have ğ‘¦ âˆˆ vars(ğœƒ (ğ´ â€² ğ‘— )). Consequently, atom ğ´ â€² ğ‘— contains some variable ğ‘§ such that ğœƒ (ğ‘§) = ğ‘¦. Since ğ´ â€² ğ‘– is a guard for ğœ â€² , variable ğ‘§ occurs in ğ´ â€² ğ‘– . Now assume for the sake of a contradiction that ğœ (ğ‘§) â‰  ğ‘¦.Then ğœ (ğ‘§) = ğœ (ğ‘¥) for some ğ‘¥ âˆˆ vars(ğ´ ğ‘– ) and ğ‘¦ = ğœƒ (ğ‘§) = ğœŒ (ğœ (ğ‘§)) = ğœŒ (ğœ (ğ‘¥)) ğœƒ (ğ‘¥). However, this contradicts the requirement ğœƒ ( Ã¬ ğ‘¥) âˆ© Ã¬ ğ‘¦ = âˆ… of the ExbDR inference rule. â–¡ Proof of Claim 3. By Claim 1, there exists ğ‘– with 1 â‰¤ ğ‘– â‰¤ ğ‘› such that atom ğ´ â€² ğ‘– is a guard for ğœ â€² . Thus, vars(ğ›½ â€² ) âˆª vars(ğ» â€² ) âŠ† vars(ğ´ â€² ğ‘– ). The ExbDR inference rule ensures vars(ğœƒ (ğ›½ â€² )) âˆ© Ã¬ ğ‘¦ = âˆ…, which in turn ensures vars(ğœƒ (ğ›½ â€² )) âŠ† vars(ğœƒ (ğ´ â€² ğ‘– )) \ Ã¬ ğ‘¦. Now let ğº be a guard for ğœ. We clearly have vars(ğœƒ (ğ›½)) âŠ† vars(ğœƒ (ğº)). Moreover, ğœƒ (ğ‘¦ ğ‘– ) = ğ‘¦ ğ‘– and ğœƒ (ğ‘¥) âˆ© Ã¬ ğ‘¦ = âˆ… ensure vars(ğœƒ (ğœ‚)) âˆª vars(ğœƒ (ğ´ ğ‘– )) âŠ† vars(ğœƒ (ğº)) âˆª Ã¬ ğ‘¦. Thus, ğœƒ (ğº) is a guard for the TGD produced by the ExbDR inference rule. Finally, since ğº contains all variables of ğœ, the widths of the resulting TGD and ğœ are equal. â–¡ B.2 Proof of Theorem 5.8: Correctness and Complexity of ExbDR Theorem 5.8. Program ExbDR(Î£) is a Datalog rewriting of a finite set of GTGDs Î£. Moreover, the rewriting can be computed in time ğ‘‚ (ğ‘ ğ‘Ÿ ğ‘‘ â€¢ (ğ‘¤ ğ‘ +ğ‘ ) ğ‘‘ğ‘ â€¢ğ‘Ÿ ğ‘‘ â€¢ (ğ‘¤ â„ +ğ‘ ) ğ‘‘ğ‘ ) for ğ‘Ÿ the number of relations in Î£, ğ‘ the maximum relation arity in Î£, ğ‘¤ ğ‘ = bwidth(Î£), ğ‘¤</figDesc><table /><note><p>1 , . . . , ğ´ â€² ğ‘› -that is, ğº âˆˆ ğ›½ â€² . Since ğ‘› â‰¥ 1, atom ğ´ â€² 1 in the body of ğœ â€² is matched to ğ´ 1 in the head of ğœ. Since ğœ is in head-normal form, ğ´ 1 contains at least one variable ğ‘¦ âˆˆ Ã¬ ğ‘¦. Moreover, the conditions of the ExbDR inference rule ensure ğœƒ (ğ‘¦) = ğ‘¦. Since ğ‘¦ does not occur in ğ´ â€² 1 and ğœƒ unifies ğ´ â€² 1 and â„ = hwidth(Î£), ğ‘ = |consts(Î£)|, and some ğ‘ and ğ‘‘.</p></note></figure>
<figure type="table" xml:id="tab_11"><head /><label /><figDesc>Theorem 1], atom ğœƒ (ğ´ â€² ) is weakly covering and has variable depth at most one; consequently, each atom in rule ğœƒ (ğ´ â€² ) âˆ§ ğœƒ (ğ›½ â€² ) â†’ ğœƒ (ğ» â€² ) is weakly covering and has variable depth at most one. Moreover, the variable depth of ğœƒ (ğ» ) is also at most one, which can be only if ğœƒ maps each variable in ğ» to another variable or a constant. Thus, each atom in rule ğœƒ (ğ›½) â†’ ğœƒ (ğ» ) is weakly covering and has variable depth at most one; moreover, ğœƒ (ğ›½) contains an atom that contains all variables of the rule. But then, rule ğœƒ (ğ›½) âˆ§ ğœƒ (ğ›½ â€² ) â†’ ğœƒ (ğ» â€² ) is guarded, as required.â€¢ Atom ğ´ â€² contains a Skolem symbol. But then, ğ´ â€² is weakly covering by the definition of guarded rules, and its variable depth is at most one. By de Nivelle [19, Theorem 1], atom ğœƒ (ğ» ) = ğœƒ (ğ´ â€² ) is weakly covering and has variable depth at most one, which can be the case only if ğœƒ maps all variables to other variables or constants. Consequently, rules ğœƒ (ğ›½) â†’ ğœƒ (ğ» ) and ğœƒ (ğ´ â€² ) âˆ§ ğœƒ (ğ›½ â€² ) â†’ ğœƒ (ğ» â€² ) are both guarded. But then, rule ğœƒ (ğ›½) âˆ§ ğœƒ (ğ›½ â€² ) â†’ ğœƒ (ğ» â€² ) is guarded, as required.</figDesc><table /><note><p>â–¡ C.2 Proof of Theorem 5.13: Correctness and Complexity of <software>SkDR</software></p></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>ACKNOWLEDGMENTS</head><p>This work was funded by the <rs type="funder">EPSRC</rs> <rs type="grantName">grants OASIS</rs> (<rs type="grantNumber">EP/S032347/1</rs>), <rs type="projectName">AnaLOG</rs> (<rs type="grantNumber">EP/P025943/1</rs>), <rs type="funder">Concur</rs> (<rs type="grantNumber">EP/V050869/1</rs>), and <rs type="projectName">QUINTON</rs> (<rs type="grantNumber">EP/T022124/1</rs>). For the purpose of Open Access, the author has applied a CC BY public copyright licence to any Author Accepted Manuscript (AAM) version arising from this submission.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funded-project" xml:id="_QJ8duq6">
					<idno type="grant-number">EP/S032347/1</idno>
					<orgName type="grant-name">grants OASIS</orgName>
					<orgName type="project" subtype="full">AnaLOG</orgName>
				</org>
				<org type="funding" xml:id="_wtb2T2a">
					<idno type="grant-number">EP/P025943/1</idno>
				</org>
				<org type="funded-project" xml:id="_WuMf5KZ">
					<idno type="grant-number">EP/V050869/1</idno>
					<orgName type="project" subtype="full">QUINTON</orgName>
				</org>
				<org type="funding" xml:id="_Rn8xYqp">
					<idno type="grant-number">EP/T022124/1</idno>
				</org>
			</listOrg>
			<div type="annex">
<div><p>Proof of Correctness. Let Î£ be an arbitrary finite set of GTGDs, and let Î£ â€² be the set of rules obtained from Î£ as specified in Definition 5.3. It is straightforward to see that Î£ â€² is a logical consequence of the <software>Skolemization</software> of Î£, so <software ContextAttributes="used">SkDR</software>(Î£) is also a logical consequence of Î£. Moreover, <software ContextAttributes="used">SkDR</software>(Î£) contains each full TGD of Î£ up to redundancy, so each full TGD of Î£ is logically entailed by <software ContextAttributes="used">SkDR</software>(Î£). We next consider an arbitrary base instance ğ¼ and a one-pass tree-like chase sequence for ğ¼ and Î£, and we show the following property:</p><p>(â™¦) for each loop ğ‘‡ ğ‘– , . . . ,ğ‘‡ ğ‘— in the sequence at some vertex ğ‘£ with output fact ğ¹ , there exist a Skolem-free rule ğ›½ â†’ ğ» âˆˆ Î£ â€² and a substitution ğœ such that ğœ (ğ›½) âŠ† ğ‘‡ ğ‘– (ğ‘£) and ğ¹ = ğœ (ğ» ).</p><p>Since <software>SkDR</software>(Î£) contains all Skolem-free rules of Î£ â€² and this property holds for the root vertex ğ‘Ÿ , Proposition 4.7 ensures that SkDR(Î£) is a rewriting of Î£.</p><p>Our proof is by induction in the length of the loop. The base case and the inductive step have the same structure, so we consider them jointly. Thus, consider an arbitrary loop ğ‘‡ ğ‘– ,ğ‘‡ ğ‘–+1 , . . . ,ğ‘‡ ğ‘— -1 ,ğ‘‡ ğ‘— at vertex ğ‘£ in the sequence, and assume that the claim holds for all shorter loops in the sequence. By the definition of a loop, chase tree ğ‘‡ ğ‘–+1 is obtained from ğ‘‡ ğ‘– by applying a chase step to some non-full GTGD ğœ âˆˆ Î£ and substitution ğ›¾. Let ğ‘£ â€² be the child of ğ‘£ introduced in ğ‘‡ ğ‘–+1 , let ğ‘† âŠ† ğ‘‡ ğ‘– (ğ‘£) be the facts that are copied to ğ‘‡ ğ‘–+1 (ğ‘£ â€² ) because they are Î£-guarded by the instantiated head of ğœ, let ğ‘ = {ğ‘› 1 , . . . , ğ‘› ğ‘š } be the set of labeled nulls introduced in the chase step for the existentially quantified variables ğ‘¦ 1 , . . . , ğ‘¦ ğ‘š of ğœ, let ğœˆ be a function that maps each labeled null ğ‘› ğ‘– to the ground term ğ‘“ ğ‘– (ğ›¾ ( Ã¬ ğ‘¥)) where ğ‘“ ğ‘– is the symbol used in the Skolemization of ğ‘¦ ğ‘– . For ğ‘ˆ a set of facts, let ğœˆ (ğ‘ˆ ) be the result of replacing each occurrence of a labeled null ğ‘› âˆˆ dom(ğœˆ) in ğ‘ˆ with ğœˆ (ğ‘›) and eliminating any duplicate facts in the result. Clearly, the inverse function ğœˆ -is well-defined, and we define ğœˆ -(ğ‘ˆ ) for ğ‘ˆ a set of facts in the obvious way. By Proposition A.8 and the fact that propagation is applied eagerly, the output fact of the loop is added to ğ‘‡ ğ‘— -1 (ğ‘£ â€² ) in step ğ‘— -1, and in ğ‘‡ ğ‘— this fact is propagated back to ğ‘‡ ğ‘— (ğ‘£). In other words, for each ğ‘˜ with ğ‘– &lt; ğ‘˜ &lt; ğ‘— -1, each fact in ğ‘‡ ğ‘˜ (ğ‘£ â€² ) \ ğ‘† contains at least one labeled null from ğ‘ , or the fact would be Î£-guarded by ğ‘‡ ğ‘– (ğ‘£) and would thus be propagated back to vertex ğ‘£. We now show that the following property holds for each ğ‘˜ with ğ‘– &lt; ğ‘˜ â‰¤ ğ‘— -1:</p><p>(â™¢) for each fact ğº âˆˆ ğ‘‡ ğ‘˜ (ğ‘£ â€² ) \ ğ‘†, there exist a rule ğ›½ â†’ ğ» âˆˆ Î£ â€² and a substitution ğœ such that ğ›½ is Skolem-free, ğœ (ğ›½) âŠ† ğœˆ (ğ‘‡ ğ‘– (ğ‘£)), and ğœ (ğ» ) = ğœˆ (ğº).</p><p>Property (â™¢) implies (â™¦): fact ğ¹ does not contain a labeled null from ğ‘ , so the rule ğ›½ â†’ ğ» âˆˆ Î£ â€² whose existence is implied by (â™¢) for ğ‘˜ = ğ‘— -1 is actually a Skolem-free rule that satisfies (â™¦).</p><p>We next prove property (â™¢) by a nested induction on ğ‘˜. For the base case ğ‘˜ = ğ‘– + 1, property (â™¢) holds due to the fact that Î£ â€² contains the rules obtained by Skolemizing GTGD ğœ. For the inductive step, assume that (â™¢) holds for some ğ‘˜ and consider the possible ways to obtain ğ‘‡ ğ‘˜+1 from ğ‘‡ ğ‘˜ . Property (â™¢) holds by the inductive hypothesis if ğ‘‡ ğ‘˜+1 (ğ‘£ â€² ) = ğ‘‡ ğ‘˜ (ğ‘£ â€² )-that is, if the step involves a descendant of ğ‘£ â€² . Otherwise, ğ‘‡ ğ‘˜+1 (ğ‘£ â€² ) = ğ‘‡ ğ‘˜ (ğ‘£ â€² ) âˆª {ğº } where fact ğº is obtained in one of the following two ways.</p><p>â€¢ A full TGD in Î£ derives ğº from ğ‘‡ ğ‘˜ (ğ‘£ â€² ). Set Î£ â€² contains this TGD up to redundancy, so by Definition 5.1 there exist a Skolem-free rule ğ›½ â€²â€² â†’ ğ» â€² âˆˆ Î£ â€² and a substitution ğœ â€² such that ğœ â€² (ğ›½ â€²â€² ) âŠ† ğœˆ (ğ‘‡ ğ‘˜ (ğ‘£ â€² )) and ğœ â€² (ğ» â€² ) = ğœˆ (ğº). â€¢ Fact ğº is the output of a loop at vertex ğ‘£ â€² . But then, this loop is shorter than ğ‘‡ ğ‘– , . . . ,ğ‘‡ ğ‘— so, by property (â™¦), there exist a Skolem-free rule ğ›½ â€²â€² â†’ ğ» â€² âˆˆ Î£ â€² and a substitution ğœ â€² such that ğœ â€² (ğ›½ â€²â€² ) âŠ† ğœˆ (ğ‘‡ ğ‘˜ (ğ‘£ â€² )) and ğœ â€² (ğ» â€² ) = ğœˆ (ğº). Now let ğ‘Š = {ğµ â€² âˆˆ ğ›½ â€²â€² | ğœ â€² (ğµ â€² ) âˆ‰ ğ‘† }. We next show that set Î£ â€² contains up to redundancy the result of "resolving away" each atom ğµ â€² âˆˆ ğ‘Š . A slight complication arises due to the fact that the <software>SkDR</software> inference rule considers only two rules at a time, and that the result of each inference is contained in Î£ â€² up to redundancy. Thus, we will achieve our goal by showing that the <software ContextAttributes="used">SkDR</software> inference rule can be applied up to ğ‘› = |ğ‘Š | times. Our proof is by induction on 1 â‰¤ â„“ â‰¤ ğ‘›. Towards this goal, we shall define ğ‘› rules ğ›½ â€²â€² â„“ â†’ ğ» â€² â„“ , substitutions ğœ â€² â„“ , and sets of atoms ğ‘Š = ğ‘Š 0 âŠ‹ â€¢ â€¢ â€¢ âŠ‹ ğ‘Š ğ‘› for â„“ with 0 â‰¤ â„“ â‰¤ ğ‘› satisfying the following invariant:</p><p>). For â„“ = ğ‘›, we have ğ‘Š ğ‘› = âˆ…, and so property ( * ) implies property (â™¢), as required. Our construction proceeds as follows.</p><p>For the base case â„“ = 0, property ( * ) clearly holds for ğ›½ â€²â€² 0 = ğ›½ â€²â€² , ğœ â€² 0 = ğœ â€² , and let ğ‘Š 0 = ğ‘Š . For the induction step, assume that ( * ) holds for some 0 â‰¤ â„“ &lt; ğ‘›, so ğ›½ â€²â€² â„“ â†’ ğ» â€² â„“ , ğœ â€² â„“ , and ğ‘Š â„“ satisfying ( * ) have been defined. First, assume that there exists</p><p>Otherwise, we consider the following possibilities.</p><p>where atom ğ´ â€² â„“ contains a Skolem symbol, in which case this atom contains all variables of the rule.</p><p>Either way, there exists ğµ â€² âˆˆ ğ‘Š â„“ such that ğœ â€² â„“ (ğ´ â€² â„“ ) = ğœ â€² (ğµ â€² ) where ğœ â€² (ğµ â€² ) âˆˆ ğ‘‡ ğ‘˜ (ğ‘£ â€² ) \ ğ‘†. Thus, by property (â™¢), these exist a rule ğ›½ â„“ â†’ ğ» â„“ âˆˆ Î£ â€² and a substitution ğœ â„“ such that ğ›½ â„“ is Skolem-free, ğœ â„“ (ğ›½ â„“ ) âŠ† ğœˆ (ğ‘‡ ğ‘– (ğ‘£)), and ğœ â„“ (ğ» â„“ ) = ğœ â€² (ğµ â€² ); the last observation ensures that ğ» â„“ contains a Skolem symbol. Moreover, there exists an MGU ğœƒ â„“ of ğ» â„“ and ğ´ â€² â„“ , so the SkDR inference rule is applicable to</p><p>is not a syntactic tautology. Thus, by Definition 5.1, there exist a rule</p><p>Then, property ( * ) clearly holds for ğ›½ â€²â€² â„“+1 â†’ ğ» â€² â„“+1 , ğœ â€² â„“+1 , and ğ‘Š â„“+1 , as required. â–¡ Proof of Complexity. Fix Î£, ğ‘Ÿ , ğ‘¤ ğ‘ , ğ‘’, ğ‘, and ğ‘ as stated in the theorem. Skolemizing a GTGD âˆ€Ã¬ ğ‘¥ [ğ›½ â†’ âˆƒÃ¬ ğ‘¦ ğœ‚] produces guarded rules in which each atom is of the form ğ‘…(ğ‘¡ 1 , . . . , ğ‘¡ ğ‘› ) such that each ğ‘¡ ğ‘– is a constant, a variable from Ã¬ ğ‘¥, or a term of the form ğ‘“ ( Ã¬ ğ‘¥) where ğ‘“ is a Skolem symbol. Moreover, each atom obtained from ğ‘…(ğ‘¡ 1 , . . . , ğ‘¡ ğ‘› ) by the <software>SkDR</software> inference rule is obtained by replacing a variable in Ã¬ ğ‘¥ with another variable or a constant. Thus, atom ğ‘…(ğ‘¡ 1 , . . . , ğ‘¡ ğ‘› ) cannot contain more than | Ã¬ ğ‘¥ | variables. Since the number of different symbols obtained by <software ContextAttributes="used">Skolemization</software> is clearly bounded by ğ‘’, the number of different atoms of such form is bounded by â„“ = ğ‘Ÿ â€¢ (ğ‘¤ ğ‘ + ğ‘’ + ğ‘) ğ‘ . The body of each guarded rule corresponds to a subset of these atoms, so the number of different rules up to variable remaining is bounded by 2 â„“ â€¢ â„“ â‰¤ 2 â„“ â€¢ 2 â„“ = 2 2â„“ = â„˜. By Definition 5.3, the result of applying the <software ContextAttributes="used">SkDR</software> inference rule is retained in set Î£ â€² only if the set does not contain a variable renaming of the result. Thus, the <software ContextAttributes="used">SkDR</software> inference rule needs to be applied to at most â„˜ 2 = 2 4â„“ pairs of rules. For each pair, one might need to unify at most â„“ body atoms of one rule with the head atom of the other rule, so the unifier ğœƒ may need to be computed at most â„˜ 2 â€¢ â„“ â‰¤ â„˜ 2 â€¢ 2 â„“ = 2 5â„“ = 32 â„“ times. We can check subsumption between a pair of rules analogously to Theorem 5.8: for each of at most 2 â„“ 2 ways to match the body atoms of one rule to the body atoms of another rule, we try to find a substitution ğœ‡ satisfying Definition 5.   Proof of Correctness. The correctness proof for HypDR is almost identical to the correctness proof in Theorem 5.13, so we outline just the difference. In particular, we wish to prove properties (â™¦) and (â™¢) exactly as stated in Theorem 5.13 using the same proof structure. In the proof of property (â™¢), we establish existence of a Skolem-free rule ğ›½ â€²â€² â†’ ğ» â€² âˆˆ Î£ â€² and a substitution ğœ â€² such that ğœ â€² (ğ›½ â€²â€² ) âŠ† ğœˆ (ğ‘‡ ğ‘˜ (ğ‘£ â€² )) and ğœ â€² (ğ» â€² ) = ğœˆ (ğº) in exactly the same way. The difference to the proof of Theorem 5.13 is that we "resolve away" all relevant body atoms of ğ›½ â€²â€² in one step. To this end, let ğ´ â€² 1 , . . . , ğ´ â€² ğ‘› be precisely the atoms of ğ›½ â€²â€² such that ğœ â€² (ğ´ â€² ğ‘– ) âˆ‰ ğ‘† for each 1 â‰¤ ğ‘– â‰¤ ğ‘›. Thus, we can assume that the rule is of the form</p><p>, and ğœ â€² (ğ›½ â€² ) âŠ† ğ‘† clearly holds. By property (â™¢), for each 1 â‰¤ â„“ â‰¤ ğ‘›, there exist a rule ğ›½ â„“ â†’ ğ» â„“ âˆˆ Î£ â€² and substitution ğœ â„“ such that ğ›½ â„“ is Skolem-free and ğœ â„“ (ğ» â„“ ) = ğœ â€² (ğ´ â€² â„“ ); the last observation ensures that ğ» â„“ contains a Skolem symbol. Finally, there exists an MGU ğœƒ of ğ» 1 , . . . , ğ» ğ‘› and ğ´ â€² 1 , . . . , ğ´ â€² ğ‘› . Since ğœ â€² (ğ›½ â€² ) âŠ† ğ‘†, conjunction ğœƒ (ğ›½ â€² ) is Skolem-free. Thus, the HypDR inference rule is applicable to</p><p>) is not a syntactic tautology so, by Definition 5.1, there exist a rule ğ›½ â†’ ğ» âˆˆ Î£ â€² and substitution ğœ‡ such that ğœ‡ (ğ›½) âŠ† ğœƒ (ğ›½ 1 ) âˆª â€¢ â€¢ â€¢ âˆª ğœƒ (ğ›½ ğ‘› ) âˆª ğœƒ (ğ›½ â€² ) and ğœ‡ (ğ» ) = ğœƒ (ğ» â€² ). Let ğœ be the substitution defined on each variable ğ‘¥ in ğ›½ â†’ ğ» such that ğœ (ğ‘¥) = ğœ (ğœ‡ (ğ‘¥)). Then, ğœ (ğ›½) âŠ† ğ‘† and ğœ (ğ» ) = ğœ â€² (ğ» â€² ) = ğœˆ (ğº), as required for property (â™¢). â–¡ Proof of Complexity. Fix Î£, ğ‘Ÿ , ğ‘¤ ğ‘ , ğ‘’, ğ‘, and ğ‘ as stated in the theorem. In the same way as in the complexity proof of Theorem 5.13, the number of different atoms can be bounded by â„“ = ğ‘Ÿ â€¢ (ğ‘¤ ğ‘ + ğ‘’ + ğ‘) ğ‘ , and the number of different rules can be bounded by â„˜ = 2 2â„“ . Now we can apply the HypDR inference rule as follows: we choose one of the â„˜ rules that plays the role of ğœ â€² and then, for each of the at most â„“ body atoms in ğœ â€² , we select one of the â„˜ rules that play the role of rules ğœ ğ‘– . Hence, there are at most â„˜ â€¢ â„˜ â„“ = â„˜ â„“+1 different applications of the HypDR inference rule. Thus, we may need to compute the unifier ğœƒ at most (2 2â„“ ) â„“+1 = 2 2â„“ 2 +2â„“ â‰¤ 2 3â„“ 2 times. Finally, the times needed for subsumption checking, unification, and all other steps can be bounded analogously as in the complexity proof of Theorem 5. <ref type="bibr" target="#b12">13</ref>. â–¡</p></div>
<div><head>E THE FullDR ALGORITHM: CREATING DATALOG RULES DIRECTLY</head><p>The algorithms presented in the body of the paper all create the Datalog rules needed for the final rewriting as well as intermediate non-full TGDs or rules that are discarded after all inferences are performed. We now present an algorithm that produces only Datalog rules. Similar algorithms have appeared in the prior literature <ref type="bibr" target="#b3">[4]</ref>. After presenting such an algorithm, we explain the shortcomings of this approach.</p><p>Definition E.1. The Full Datalog Rewriting inference rule FullDR can be applied in two ways, depending on the types of TGDs it takes.</p><p>â€¢ The (COMPOSE) variant of the FullDR inference rule takes full TGDs</p><p>and a substitution ğœƒ such that </p><p>â€¢ The (PROPAGATE) variant of the FullDR inference rule takes TGDs</p><p>and Proof of Correctness. The proof follows the same structure as the correctness proof of Theorem 5.8: we show that property (â™¦) holds for each loop on a one-pass tree-like chase sequence for ğ¼ and Î£; a minor difference is that the TGD whose existence is implied by (â™¦) is not necessarily guarded, but has width bounded by hwidth(ğœ). To this end, we consider an arbitrary loop ğ‘‡ ğ‘– ,ğ‘‡ ğ‘–+1 , . . . ,ğ‘‡ ğ‘— -1 ,ğ‘‡ ğ‘— at vertex ğ‘£ in the sequence, and assume that the claim holds for all shorter loops in the sequence. By the definition of the loop, chase tree ğ‘‡ ğ‘–+1 is obtained from ğ‘‡ ğ‘– by applying a chase step to some non-full TGD âˆ€Ã¬ ğ‘¥ [ğ›½ 0 â†’ âˆƒÃ¬ ğ‘¦ ğœ‚ 0 ] âˆˆ Î£. Let ğœ 0 and ğœ â€² 0 be the substitutions used in this chase step, and let ğ‘£ â€² be the child of ğ‘£ introduced in ğ‘‡ ğ‘–+1 . Note that ğ‘‡ ğ‘–+1 (ğ‘£ â€² ) contains at most hwidth(Î£) + |consts(Î£)| distinct terms. We show by another induction on ğ‘˜ that the following property holds for each ğ‘˜ with ğ‘– &lt; ğ‘˜ â‰¤ ğ‘— -1:</p><p>(â™¢) for each fact ğº âˆˆ ğ‘‡ ğ‘˜ (ğ‘£ â€² ) \ ğ‘‡ ğ‘–+1 (ğ‘£ â€² ), there exist a full TGD âˆ€Ã¬ ğ‘¥ [ğ›½ â†’ ğ» ] âˆˆ Î£ â€² of width at most width(Î£) and a substitution ğœ such that ğœ (ğ›½) âŠ† ğ‘‡ ğ‘–+1 (ğ‘£ â€² ) and ğœ (ğ» ) = ğº. For the base case ğ‘˜ = ğ‘– + 1, property (â™¢) holds vacuously because ğ‘‡ ğ‘˜ (ğ‘£ â€² ) \ ğ‘‡ ğ‘–+1 (ğ‘£ â€² ) = âˆ…. For the inductive step, assume that (â™¢) holds for some ğ‘˜ and consider the possible ways to obtain ğ‘‡ ğ‘˜+1 from ğ‘‡ ğ‘˜ . Property (â™¢) holds by the inductive hypothesis if ğ‘‡ ğ‘˜+1 (ğ‘£ â€² ) = ğ‘‡ ğ‘˜ (ğ‘£ â€² )-that is, if the step involves a descendant of ğ‘£ â€² . Otherwise, ğ‘‡ ğ‘˜+1 (ğ‘£ â€² ) = ğ‘‡ ğ‘˜ (ğ‘£ â€² ) âˆª {ğº } where fact ğº is obtained in one of the following two ways.</p><p>â€¢ A full TGD in Î£ derives ğº from ğ‘‡ ğ‘˜ (ğ‘£ â€² ). Set Î£ â€² contains this TGD up to redundancy, so by Definition 5.1 there exist a full TGD ğ›½ â€²â€² â†’ ğ» â€² âˆˆ Î£ â€² and a substitution ğœ such that ğœ (ğ›½ â€²â€² ) âŠ† ğ‘‡ ğ‘˜ (ğ‘£ â€² ) and ğœ (ğ» â€² ) = ğº. â€¢ Fact ğº is the output of a loop at vertex ğ‘£ â€² . But then, this loop is shorter than ğ‘‡ ğ‘– , . . . ,ğ‘‡ ğ‘— so, by property (â™¦), there exists a full TGD ğ›½ â€²â€² â†’ ğ» â€² âˆˆ Î£ â€² and a substitution ğœ such that ğœ (ğ›½ â€²â€² ) âŠ† ğ‘‡ ğ‘˜ (ğ‘£ â€² ) and ğœ (ğ» â€² ) = ğº. Either way, the width of rule ğ›½ â€²â€² â†’ ğ» â€² is bounded by width(Î£), and we can assume that</p><p>for each 1 â‰¤ â„“ â‰¤ ğ‘›, and ğœ (ğ›½ â€² ) âŠ† ğ‘‡ ğ‘–+1 (ğ‘£ â€² ). By property (â™¢), for each 1 â‰¤ â„“ â‰¤ ğ‘› there exist a full TGD ğ›½ â„“ â†’ ğ» â„“ âˆˆ Î£ â€² and a substitution ğœ â„“ such that ğœ â„“ (ğ›½ â„“ ) âŠ† ğ‘‡ ğ‘–+1 (ğ‘£ â€² ) and ğœ â„“ (ğ» â„“ ) = ğ›¾ (ğ´ â€² â„“ ). Moreover, set rng(ğœ â„“ ) clearly contains at most hwidth(Î£) + |consts(Î£)| distinct terms. But then, there exist substitutions ğœƒ 1 , . . . , ğœƒ ğ‘› that allow us to iteratively compose each ğ›½ â„“ â†’ ğ» â„“ with</p><p>to obtain a full TGD subsumed by some ğœ âˆˆ Î£ â€² and substitution ğœ 1 such that ğœ and ğœ 1 satisfy property (â™¢). To complete the proof, consider an arbitrary fact ğ¹ âˆˆ ğ‘‡ ğ‘— -1 (ğ‘£ â€² ) \ ğ‘‡ ğ‘–+1 (ğ‘£ â€² ) that is propagated from ğ‘£ â€² to ğ‘£ in ğ‘‡ ğ‘— , and let ğ›½ â€²â€² â†’ ğ» â€² âˆˆ Î£ â€² and ğœ be the TGD and substitution whose existence is guaranteed by property (â™¢). Now if ğœ (ğ›½ â€²â€² ) âŠ† ğ‘‡ ğ‘–+1 (ğ‘£ â€² ) \ ğœ â€² 0 (ğœ‚ 0 ), then TGD ğ›½ â€²â€² â†’ ğ» â€² satisfies property (â™¦). Otherwise, we can assume that the rule is of the form</p><p>where ğœ (ğ´ â€² ğ‘– ) âˆˆ ğœ â€² 0 (ğœ‚ 0 ) for each 1 â‰¤ ğ‘– â‰¤ ğ‘›, and ğœ (ğ›½ â€² ) âŠ† ğ‘‡ ğ‘–+1 (ğ‘£ â€² ) \ ğœ â€² 0 (ğœ‚ 0 ). Moreover, rng(ğœ) clearly contains at most hwidth(Î£) + |consts(Î£)| distinct terms. But then, there exists a substitution ğœƒ that allows us to apply the (PROPAGATE) variant of the FullDR inference rule to ğ›½ 0 â†’ âˆƒÃ¬ ğ‘¦ ğœ‚ 0 and ğ´ â€² 1 âˆ§ â€¢ â€¢ â€¢ âˆ§ ğ´ â€² ğ‘› âˆ§ ğ›½ â€² â†’ ğ» â€² to obtain a full TGD subsumed by some TGD ğœ âˆˆ Î£ â€² and substitution ğœ 1 such that ğœ and ğœ 1 satisfy property (â™¦). â–¡ Proof of Complexity. The proof is analogous to the proof of complexity of Theorem 5.8. In particular, the (PROPAGATE) variant of the FullDR inference rule is analogous to the ExbDR inference rule, so we can bound in the same way the number of candidate rule pairs and possible ways to match body atoms of ğœ â€² to head atoms of ğœ by 32 â„“ 2</p><p>, where â„“ = ğ‘Ÿ â€¢ (ğ‘¤ + ğ‘) ğ‘ . Once a candidate pair of ğœ and ğœ â€² has been selected, we need to consider all possible substitutions ğœƒ . Each such ğœƒ is defined on at most 2ğ‘¤ variables Ã¬ ğ‘¥ âˆª Ã¬ ğ‘§. Moreover, each variable is mapped to one of the ğ‘¤ + ğ‘ variables or to one of the ğ‘ constants in consts(Î£). Hence, there are at most (ğ‘¤ + 2ğ‘) 2ğ‘¤ â‰¤ 4 (ğ‘¤+2ğ‘ ) â€¢ğ‘¤ â‰¤ 4 (ğ‘¤+ğ‘ ) 2 different substitutions ğœƒ . Consequently, the (PROPAGATE) variant of the FullDR inference rule can be applied at most 32 â„“ 2 â€¢ 4 (ğ‘¤+ğ‘ ) 2 &lt; 32 ğ‘›â€¢ (ğ‘¤+ğ‘ ) 2ğ‘+1 times. Applications of the (COMPOSE) variant can be bounded analogously. Finally, the times needed for subsumption checking, unification, and all other steps can be bounded analogously as in the complexity proof of Theorem 5.8, with a minor difference that only body atoms need to be matched in the subsumption checks. â–¡</p><p>The FullDR algorithm has several obvious weak points. First, it considers all possible ways to compose Datalog rules as long as this produces a rule with at most hwidth(Î£) + |consts(Î£)| variables. This may seem unnecessary, but the (COMPOSE) variant of the FullDR inference rule cannot be simply dropped while retaining completeness. To understand why, consider an arbitrary loop ğ‘‡ ğ‘– , . . . ,ğ‘‡ ğ‘— at vertex ğ‘£ with output fact ğ¹ in a one-pass chase proof: the (PROPAGATE) variant of the FullDR inference reflects only the chase step that derives the loop's output ğ¹ , so the (COMPOSE) variant is needed to reflects the chase steps that produce facts derived in the child of ğ‘£ that are not propagated back to ğ‘£. Second, it is not clear how one efficiently obtains the atoms ğ´ 1 , . </p><p>The (COMPOSE) variant of the FullDR inference rule should be applied to GTGDs ( <ref type="formula">47</ref>) and ( <ref type="formula">48</ref>), but it is not clear which unifier ğœƒ , identifying variables ğ‘§ ğ‘– in the latter with variables ğ‘¥ ğ‘– in the former, one should use. The standard resolution inference rule from first-order theorem proving would consider only the MGU ğœƒ that maps ğ‘§ 3 to ğ‘¥ 4 ; however, this would produce the resolvent ğ‘† (ğ‘¥ 1 , ğ‘¥ 2 , ğ‘¥ 3 , ğ‘¥ 4 ) âˆ§ ğ‘‡ (ğ‘§ 1 , ğ‘§ 2 , ğ‘¥ 4 ) â†’ ğ‘ƒ (ğ‘§ 1 ) containing more than hwidth(Î£) = 4 variables, so this rule is not derived by the (COMPOSE) variant. Eliminating the upper bound on the number of variables is not a solution: doing so would allow the derivation of full TGDs with an unbounded number of variables, which would prevent termination. Instead, the (COMPOSE) variant requires us to consider every possible substitution ğœƒ that maps variables ğ‘¥ 1 , . . . , ğ‘¥ </p><p>need to be considered, which is clearly infeasible in practice. âŠ³ Nevertheless, we implemented FullDR using the subsumption and indexing techniques described in Section 6. Unsurprisingly, we did not find FullDR competitive in our experiments. In fact, FullDR timed out on 173 ontologies, and there are only three ontologies where another algorithm reached the timeout but FullDR did not. For this reason, we do not discuss the results with FullDR in Section 7.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Rewriting Guarded Existential Rules into Small Datalog Programs</title>
		<author>
			<persName><forename type="first">Shqiponja</forename><surname>Ahmetaj</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Magdalena</forename><surname>Ortiz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mantas</forename><surname>Simkus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICDT. Schloss Dagstuhl-Leibniz-Zentrum fuer Informatik</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">1-4</biblScope>
			<biblScope unit="page">24</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Diversified Stress Testing of RDF Data Management Systems</title>
		<author>
			<persName><forename type="first">GÃ¼nes</forename><surname>AluÃ§</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Olaf</forename><surname>Hartig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Tamer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Khuzaima</forename><surname>Ã–zsu</surname></persName>
		</author>
		<author>
			<persName><surname>Daudjee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ISWC. Springer</title>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="197" to="212" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Magic-Sets for Datalog with Existential Quantifiers</title>
		<author>
			<persName><forename type="first">Mario</forename><surname>Alviano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicola</forename><surname>Leone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marco</forename><surname>Manna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Giorgio</forename><surname>Terracina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pierfrancesco</forename><surname>Veltri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Datalog</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">0</biblScope>
			<biblScope unit="page" from="31" to="43" />
			<date type="published" when="2012">2012</date>
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">When Can We Answer Queries Using Result-Bounded Data Interfaces? Log</title>
		<author>
			<persName><forename type="first">Antoine</forename><surname>Amarilli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Benedikt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Methods Comput. Sci</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1" to="14" />
			<date type="published" when="2022">2022. 2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Modal languages and bounded fragments of predicate logic</title>
		<author>
			<persName><forename type="first">Hajnal</forename><surname>AndrÃ©ka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Johan</forename><surname>Van Benthem</surname></persName>
		</author>
		<author>
			<persName><forename type="first">IstvÃ¡n</forename><surname>NÃ©meti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Philosophical Logic</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="217" to="274" />
			<date type="published" when="1998">1998. 1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">The Description Logic Handbook: Theory, Implementation and Applications</title>
		<editor>F. Baader, D. Calvanese, D. McGuinness, D. Nardi, and P. F. Patel-Schneider</editor>
		<imprint>
			<date type="published" when="2007">2007</date>
			<publisher>Cambridge University Press</publisher>
			<pubPlace>Cambridge, UK</pubPlace>
		</imprint>
	</monogr>
	<note>2nd ed.</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Normal Form Transformations</title>
		<author>
			<persName><forename type="first">M</forename><surname>Baaz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Egly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Leitsch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Handbook of Automated Reasoning</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Robinson</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Voronkov</surname></persName>
		</editor>
		<meeting><address><addrLine>Amsterdam, The Netherlands</addrLine></address></meeting>
		<imprint>
			<publisher>Elsevier Science</publisher>
			<date type="published" when="2001">2001</date>
			<biblScope unit="volume">I</biblScope>
			<biblScope unit="page" from="273" to="333" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Resolution Theorem Proving</title>
		<author>
			<persName><forename type="first">Leo</forename><surname>Bachmair</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Harald</forename><surname>Ganzinger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Handbook of automated reasoning</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="19" to="99" />
			<date type="published" when="2001">2001. 2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Graal: A Toolkit for Query Answering with Existential Rules</title>
		<author>
			<persName><forename type="first">J.-F</forename><surname>Baget</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>LeclÃ¨re</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M.-L</forename><surname>Mugnier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Rocher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Sipieter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">RuleML</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="328" to="344" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Walking the complexity lines for generalized guarded existential rules</title>
		<author>
			<persName><forename type="first">Jean-FranÃ§ois</forename><surname>Baget</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marie-Laure</forename><surname>Mugnier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Rudolph</surname></persName>
		</author>
		<author>
			<persName><forename type="first">MichaÃ«l</forename><surname>Thomazo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI. AAAI Press</title>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="712" to="717" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Rewriting Guarded Negation Queries</title>
		<author>
			<persName><forename type="first">Vince</forename><surname>BÃ¡rÃ¡ny</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Benedikt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Balder</forename><surname>Ten</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cate</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">MFCS. Springer</title>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="98" to="110" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">The Vadalog System: Datalog-based Reasoning for Knowledge Graphs</title>
		<author>
			<persName><forename type="first">Luigi</forename><surname>Bellomarini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Emanuel</forename><surname>Sallinger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Georg</forename><surname>Gottlob</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. VLDB Endow</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="975" to="987" />
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Guarded Saturation</title>
		<author>
			<persName><forename type="first">Michael</forename><surname>Benedikt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maxime</forename><surname>Buron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefano</forename><surname>Germano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Kappelmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Boris</forename><surname>Motik</surname></persName>
		</author>
		<ptr target="https://krr-oxford.github.io/Guarded-saturation/" />
		<imprint>
			<date type="published" when="2021-07-04">2021. July 4, 2022</date>
			<publisher>GitHub</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Benchmarking the Chase</title>
		<author>
			<persName><forename type="first">Michael</forename><surname>Benedikt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">George</forename><surname>Konstantinidis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Giansalvatore</forename><surname>Mecca</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Boris</forename><surname>Motik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paolo</forename><surname>Papotti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Donatello</forename><surname>Santoro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Efthymia</forename><surname>Tsamoura</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">PODS. ACM</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="37" to="52" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Taming the Infinite Chase: Query Answering under Expressive Relational Constraints</title>
		<author>
			<persName><forename type="first">Andrea</forename><surname>CalÃ¬</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Georg</forename><surname>Gottlob</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Kifer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Artificial Intelligence Research</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="page" from="115" to="174" />
			<date type="published" when="2013">2013. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Query rewriting and answering under constraints in data integration systems</title>
		<author>
			<persName><forename type="first">Andrea</forename><surname>CalÃ¬</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Domenico</forename><surname>Lembo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Riccardo</forename><surname>Rosati</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI. Morgan Kaufmann</title>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="16" to="21" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Ontop: Answering SPARQL queries over relational databases</title>
		<author>
			<persName><forename type="first">Diego</forename><surname>Calvanese</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Cogrel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sarah</forename><surname>Komla-Ebri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roman</forename><surname>Kontchakov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Davide</forename><surname>Lanti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Martin</forename><surname>Rezk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mariano</forename><surname>Rodriguez-Muro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guohui</forename><surname>Xiao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Semantic Web</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="471" to="487" />
			<date type="published" when="2017">2017. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Tractable Reasoning and Efficient Query Answering in Description Logics: The DL-Lite Family</title>
		<author>
			<persName><forename type="first">Diego</forename><surname>Calvanese</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Giuseppe</forename><forename type="middle">De</forename><surname>Giacomo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Domenico</forename><surname>Lembo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maurizio</forename><surname>Lenzerini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Riccardo</forename><surname>Rosati</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Autom. Reason</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="385" to="429" />
			<date type="published" when="2007">2007. 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">A Resolution Decision Procedure for the Guarded Fragment</title>
		<author>
			<persName><forename type="first">Hans</forename><surname>De</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nivelle</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CADE. Springer</title>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="191" to="204" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Query reformulation with constraints</title>
		<author>
			<persName><forename type="first">A</forename><surname>Deutsch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Popa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Tannen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIGMOD Record</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="65" to="73" />
			<date type="published" when="2006">2006. 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Data exchange: semantics and query answering</title>
		<author>
			<persName><forename type="first">R</forename><surname>Fagin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">G</forename><surname>Kolaitis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Popa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Theoretical Computer Science</title>
		<imprint>
			<biblScope unit="volume">336</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="89" to="124" />
			<date type="published" when="2005">2005. 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">An Ontology-Based Reasoning Approach for Electric Power Utilities</title>
		<author>
			<persName><forename type="first">Mohamed</forename><surname>Gaha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arnaud</forename><surname>Zinflou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christian</forename><surname>Langheit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexandre</forename><surname>Bouffard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mathieu</forename><surname>Viau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luc</forename><surname>Vouligny</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">RR. Springer</title>
		<imprint>
			<biblScope unit="page" from="95" to="108" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">A Superposition Decision Procedure for the Guarded Fragment with Equality</title>
		<author>
			<persName><forename type="first">H</forename><surname>Ganzinger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>De Nivelle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 14th IEEE Symposium on Logic in Computer Science (LICS '99)</title>
		<meeting>of the 14th IEEE Symposium on Logic in Computer Science (LICS '99)</meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="295" to="305" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Expressiveness of Guarded Existential Rule Languages</title>
		<author>
			<persName><forename type="first">Georg</forename><surname>Gottlob</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Rudolph</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mantas</forename><surname>Simkus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">PODS. ACM</title>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="27" to="38" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Data Integration: The Teenage Years</title>
		<author>
			<persName><forename type="first">Alon</forename><surname>Halevy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anand</forename><surname>Rajaraman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joann</forename><surname>Ordille</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">VLDB. ACM</title>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="9" to="16" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Answering queries using views: A survey</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Alon</surname></persName>
		</author>
		<author>
			<persName><surname>Halevy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">VLDB Journal</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="270" to="294" />
			<date type="published" when="2001">2001. 2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Guarded Logics: Algorithms and Bisimulation</title>
		<author>
			<persName><forename type="first">Colin</forename><surname>Hirsch</surname></persName>
		</author>
		<ptr target="http://www.umbrialogic.com/hirsch-thesis.pdf" />
		<imprint>
			<date type="published" when="2002-07-04">2002. July 4, 2022</date>
			<pubPlace>Aachen, Germany</pubPlace>
		</imprint>
		<respStmt>
			<orgName>RWTH Aachen</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D. Dissertation</note>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Reducing S H I Q -Description Logic to Disjunctive Datalog Programs</title>
		<author>
			<persName><forename type="first">Ullrich</forename><surname>Hustadt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Boris</forename><surname>Motik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ulrike</forename><surname>Sattler</surname></persName>
		</author>
		<editor>KR.</editor>
		<imprint>
			<date type="published" when="2004">2004</date>
			<publisher>AAAI Press</publisher>
			<biblScope unit="page" from="152" to="162" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Reasoning in description logics by a reduction to disjunctive datalog</title>
		<author>
			<persName><forename type="first">Ullrich</forename><surname>Hustadt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Boris</forename><surname>Motik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ulrike</forename><surname>Sattler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Automated Reasoning</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="351" to="384" />
			<date type="published" when="2007">2007. 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Testing Containment of Conjunctive Queries under Functional and Inclusion Dependencies</title>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">S</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anthony</forename><forename type="middle">C</forename><surname>Klug</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JCSS</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="167" to="189" />
			<date type="published" when="1984">1984. 1984</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Decision Procedures for Guarded Logics</title>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Kappelmann</surname></persName>
		</author>
		<idno>CoRR abs/1911.03679</idno>
		<ptr target="http://arxiv.org/abs/1911.03679" />
		<imprint>
			<date type="published" when="2019-07-04">2019. 2019. July 4, 2022</date>
			<biblScope unit="page">92</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">NP-Completeness of the Set Unification and Matching Problems</title>
		<author>
			<persName><forename type="first">Deepak</forename><surname>Kapur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paliath</forename><surname>Narendran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CADE. Springer</title>
		<imprint>
			<date type="published" when="1986">1986</date>
			<biblScope unit="page" from="489" to="495" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Logic-Based Techniques in Data Integration</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Alon</surname></persName>
		</author>
		<author>
			<persName><surname>Levy</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000">2000</date>
			<publisher>Kluwer Academic Publishers</publisher>
			<biblScope unit="page" from="575" to="595" />
			<pubPlace>Norwell, MA, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">A General Datalog-Based Framework for Tractable Query Answering over Ontologies</title>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Lukasiewicz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrea</forename><surname>CalÃ¬</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Georg</forename><surname>Gottlob</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Web Semantics</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">0</biblScope>
			<biblScope unit="page" from="57" to="83" />
			<date type="published" when="2012">2012. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Resolution and Datalog Rewriting Under Value Invention and Equality Constraints</title>
		<author>
			<persName><forename type="first">Bruno</forename><surname>Marnette</surname></persName>
		</author>
		<idno>CoRR abs/1212.0254</idno>
		<imprint>
			<date type="published" when="2012">2012. 2012</date>
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Otter-The CADE-13 Competition Incarnations</title>
		<author>
			<persName><forename type="first">William</forename><surname>Mccune</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Larry</forename><surname>Wos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Automated Reasoning</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="211" to="220" />
			<date type="published" when="1997">1997. 1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">The backchase revisited</title>
		<author>
			<persName><forename type="first">M</forename><surname>Meier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">VLDB J</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="495" to="516" />
			<date type="published" when="2014">2014. 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Reasoning in description logics using resolution and deductive databases</title>
		<author>
			<persName><forename type="first">Boris</forename><surname>Motik</surname></persName>
		</author>
		<ptr target="http://digbib.ubka.uni-karlsruhe.de/volltexte/1000003797" />
		<imprint>
			<date type="published" when="2006-07-04">2006. July 4, 2022</date>
			<pubPlace>Karlsruhe, Germany</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Karlsruhe Institute of Technology</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D. Dissertation</note>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">The KAON2 System</title>
		<author>
			<persName><forename type="first">Boris</forename><surname>Motik</surname></persName>
		</author>
		<ptr target="http://kaon2.semanticweb.org/" />
		<imprint>
			<date type="published" when="2022-07-04">2022. July 4, 2022</date>
		</imprint>
		<respStmt>
			<orgName>Karslruhe Institute of Technology</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Oxford Ontology Library</title>
		<ptr target="http://krr-nas.cs.ox.ac.uk/ontologies/" />
		<imprint>
			<date type="published" when="2021-07-04">2021. July 4, 2022</date>
			<publisher>Oxford KR group</publisher>
		</imprint>
		<respStmt>
			<orgName>Oxford University</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Linear Unification</title>
		<author>
			<persName><forename type="first">Mike</forename><surname>Paterson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><forename type="middle">N</forename><surname>Wegman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Comput. Syst. Sci</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="158" to="167" />
			<date type="published" when="1978">1978. 1978</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">A machine-oriented logic based on the resolution principle</title>
		<author>
			<persName><forename type="first">John</forename><surname>Alan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robinson</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JACM</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="23" to="41" />
			<date type="published" when="1965">1965. 1965</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Index Data Structure for Fast Subset and Superset Queries</title>
		<author>
			<persName><forename type="first">Iztok</forename><surname>Savnik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CD-ARES</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="134" to="148" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Simple and Efficient Clause Subsumption with Feature Vector Indexing</title>
		<author>
			<persName><forename type="first">Stephan</forename><surname>Schulz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Automated Reasoning and Mathematics</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="45" to="67" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">The Path-Indexing Method for Indexing Terms</title>
		<author>
			<persName><forename type="first">Mark</forename><forename type="middle">E</forename><surname>Stickel</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1989">1989</date>
		</imprint>
		<respStmt>
			<orgName>SRI</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">The RDFox System. Oxford Semantic Technologies</title>
		<ptr target="https://www.oxfordsemantic.tech/" />
		<imprint>
			<date type="published" when="2022-07-04">2022. July 4, 2022</date>
			<publisher>Oxford Semantic Technologies</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Why Is Modal Logic so Robustly Decidable?</title>
		<author>
			<persName><forename type="first">Moshe</forename><forename type="middle">Y</forename><surname>Vardi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">DIMACS Series in Discrete Mathematics and Theoretical Computer Science</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="149" to="184" />
			<date type="published" when="1997">1997</date>
			<publisher>American Mathematical Society</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">NYAYA: A System Supporting the Uniform Management of Large Sets of Semantic Data</title>
		<author>
			<persName><forename type="first">Roberto</forename><surname>De</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Virgilio</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Giorgio</forename><surname>Orsi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Letizia</forename><surname>Tanca</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Riccardo</forename><surname>Torlone</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICDE. IEEE Computer Society</title>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="1309" to="1312" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Query Answering for Existential Rules via Efficient Datalog Rewriting</title>
		<author>
			<persName><forename type="first">Zhe</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peng</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kewen</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhiqiang</forename><surname>Zhuang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hai</forename><surname>Wan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI. ijcai.org</title>
		<imprint>
			<date type="published" when="1933">2021. 1933-1939</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Deciding the Loosely Guarded Fragment and Querying Its Horn Fragment Using Resolution</title>
		<author>
			<persName><forename type="first">Sen</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Renate</forename><forename type="middle">A</forename><surname>Schmidt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="3080" to="3087" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</teiCorpus></text>
</TEI>