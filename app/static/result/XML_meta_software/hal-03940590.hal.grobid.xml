<?xml version='1.0' encoding='utf-8'?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" version="1.1" xsi:schemaLocation="http://www.tei-c.org/ns/1.0 http://api.archives-ouvertes.fr/documents/aofr-sword.xsd">
  <teiHeader>
    <fileDesc>
      <titleStmt>
        <title>HAL TEI export of hal-03940590</title>
      </titleStmt>
      <publicationStmt>
        <distributor>CCSD</distributor>
        <availability status="restricted">
          <licence target="http://creativecommons.org/licenses/by/">Attribution</licence>
        </availability>
        <date when="2024-04-29T04:02:11+02:00" />
      </publicationStmt>
      <sourceDesc>
        <p part="N">HAL API platform</p>
      </sourceDesc>
    </fileDesc>
  </teiHeader>
  <text>
    <body>
      <listBibl>
        <biblFull>
          <titleStmt>
            <title xml:lang="en">Enumerating Regular Languages with Bounded Delay</title>
            <author role="aut">
              <persName>
                <forename type="first">Antoine</forename>
                <surname>Amarilli</surname>
              </persName>
              <email type="md5">23b295775b0422fd250d7085ddb340b8</email>
              <email type="domain">a3nm.net</email>
              <idno type="idhal" notation="string">a3nm</idno>
              <idno type="idhal" notation="numeric">4934</idno>
              <idno type="halauthorid" notation="string">16025-4934</idno>
              <idno type="ORCID">https://orcid.org/0000-0002-7977-4441</idno>
              <idno type="VIAF">https://viaf.org/viaf/61147602413357640283</idno>
              <idno type="IDREF">https://www.idref.fr/195286677</idno>
              <affiliation ref="#struct-554328" />
              <affiliation ref="#struct-121818" />
              <affiliation ref="#struct-563936" />
            </author>
            <author role="aut">
              <persName>
                <forename type="first">Mikaël</forename>
                <surname>Monet</surname>
              </persName>
              <email type="md5">6993dabf9e3bed50493f1aeab5876d8c</email>
              <email type="domain">inria.fr</email>
              <idno type="idhal" notation="numeric">1085321</idno>
              <idno type="halauthorid" notation="string">1055808-1085321</idno>
              <affiliation ref="#struct-432648" />
            </author>
            <editor role="depositor">
              <persName>
                <forename>Mikaël</forename>
                <surname>Monet</surname>
              </persName>
              <email type="md5">6993dabf9e3bed50493f1aeab5876d8c</email>
              <email type="domain">inria.fr</email>
            </editor>
            <funder ref="#projanr-50788" />
          </titleStmt>
          <editionStmt>
            <edition n="v1" type="current">
              <date type="whenSubmitted">2023-01-16 11:20:03</date>
              <date type="whenWritten">2022-09</date>
              <date type="whenModified">2024-01-24 09:54:24</date>
              <date type="whenReleased">2023-01-16 14:47:25</date>
              <date type="whenProduced">2023-03-07</date>
              <date type="whenEndEmbargoed">2023-01-16</date>
              <ref type="file" target="https://hal.science/hal-03940590/document">
                <date notBefore="2023-01-16" />
              </ref>
              <ref type="file" n="1" target="https://hal.science/hal-03940590/file/enumerating.pdf">
                <date notBefore="2023-01-16" />
              </ref>
              <ref type="externalLink" target="http://arxiv.org/pdf/2209.14878" />
            </edition>
            <respStmt>
              <resp>contributor</resp>
              <name key="967253">
                <persName>
                  <forename>Mikaël</forename>
                  <surname>Monet</surname>
                </persName>
                <email type="md5">6993dabf9e3bed50493f1aeab5876d8c</email>
                <email type="domain">inria.fr</email>
              </name>
            </respStmt>
          </editionStmt>
          <publicationStmt>
            <distributor>CCSD</distributor>
            <idno type="halId">hal-03940590</idno>
            <idno type="halUri">https://hal.science/hal-03940590</idno>
            <idno type="halBibtex">amarilli:hal-03940590</idno>
            <idno type="halRefHtml">&lt;i&gt;STACS&lt;/i&gt;, Mar 2023, Hamburg, Germany. &lt;a target="_blank" href="https://dx.doi.org/10.4230/LIPIcs.STACS.2023.8"&gt;&amp;#x27E8;10.4230/LIPIcs.STACS.2023.8&amp;#x27E9;&lt;/a&gt;</idno>
            <idno type="halRef">STACS, Mar 2023, Hamburg, Germany. &amp;#x27E8;10.4230/LIPIcs.STACS.2023.8&amp;#x27E9;</idno>
            <availability status="restricted">
              <licence target="http://creativecommons.org/licenses/by/">Attribution</licence>
            </availability>
          </publicationStmt>
          <seriesStmt>
            <idno type="stamp" n="INSTITUT-TELECOM">Institut Mines Télécom</idno>
            <idno type="stamp" n="CNRS">CNRS - Centre national de la recherche scientifique</idno>
            <idno type="stamp" n="INRIA">INRIA - Institut National de Recherche en Informatique et en Automatique</idno>
            <idno type="stamp" n="ENST">Ecole Nationale Supérieure des Télécommunications</idno>
            <idno type="stamp" n="INRIA-LILLE">INRIA Lille - Nord Europe</idno>
            <idno type="stamp" n="TELECOM-PARISTECH" corresp="INSTITUT-TELECOM">Télécom Paris</idno>
            <idno type="stamp" n="PARISTECH">ParisTech</idno>
            <idno type="stamp" n="INRIA_TEST">INRIA - Institut National de Recherche en Informatique et en Automatique</idno>
            <idno type="stamp" n="TESTALAIN1">TESTALAIN1</idno>
            <idno type="stamp" n="CRISTAL">Centre de Recherche en Informatique, Signal et Automatique de Lille (CRISTAL)</idno>
            <idno type="stamp" n="INRIA2">INRIA 2</idno>
            <idno type="stamp" n="CRISTAL-LINKS" corresp="CRISTAL">CRISTAL-LINKS</idno>
            <idno type="stamp" n="UNIV-LILLE">Université de Lille</idno>
            <idno type="stamp" n="LTCI" corresp="TELECOM-PARISTECH">Laboratoire Traitement et Communication de l'Information</idno>
            <idno type="stamp" n="INFRES" corresp="TELECOM-PARISTECH">Département Informatique et Réseaux</idno>
            <idno type="stamp" n="DIG" corresp="TELECOM-PARISTECH">Equipe Data, Intelligence and Graphs</idno>
            <idno type="stamp" n="IP_PARIS">Institut Polytechnique de Paris</idno>
            <idno type="stamp" n="INSTITUTS-TELECOM" corresp="INSTITUT-TELECOM">composantes instituts telecom </idno>
            <idno type="stamp" n="ANR">ANR</idno>
          </seriesStmt>
          <notesStmt>
            <note type="commentary">STACS'2023</note>
            <note type="audience" n="2">International</note>
            <note type="invited" n="0">No</note>
            <note type="popular" n="0">No</note>
            <note type="peer" n="1">Yes</note>
            <note type="proceedings" n="1">Yes</note>
          </notesStmt>
          <sourceDesc>
            <biblStruct>
              <analytic>
                <title xml:lang="en">Enumerating Regular Languages with Bounded Delay</title>
                <author role="aut">
                  <persName>
                    <forename type="first">Antoine</forename>
                    <surname>Amarilli</surname>
                  </persName>
                  <email type="md5">23b295775b0422fd250d7085ddb340b8</email>
                  <email type="domain">a3nm.net</email>
                  <idno type="idhal" notation="string">a3nm</idno>
                  <idno type="idhal" notation="numeric">4934</idno>
                  <idno type="halauthorid" notation="string">16025-4934</idno>
                  <idno type="ORCID">https://orcid.org/0000-0002-7977-4441</idno>
                  <idno type="VIAF">https://viaf.org/viaf/61147602413357640283</idno>
                  <idno type="IDREF">https://www.idref.fr/195286677</idno>
                  <affiliation ref="#struct-554328" />
                  <affiliation ref="#struct-121818" />
                  <affiliation ref="#struct-563936" />
                </author>
                <author role="aut">
                  <persName>
                    <forename type="first">Mikaël</forename>
                    <surname>Monet</surname>
                  </persName>
                  <email type="md5">6993dabf9e3bed50493f1aeab5876d8c</email>
                  <email type="domain">inria.fr</email>
                  <idno type="idhal" notation="numeric">1085321</idno>
                  <idno type="halauthorid" notation="string">1055808-1085321</idno>
                  <affiliation ref="#struct-432648" />
                </author>
              </analytic>
              <monogr>
                <meeting>
                  <title>STACS</title>
                  <date type="start">2023-03-07</date>
                  <date type="end">2023-03-09</date>
                  <settlement>Hamburg</settlement>
                  <country key="DE">Germany</country>
                </meeting>
                <imprint>
                  <date type="datePub">2023</date>
                </imprint>
              </monogr>
              <idno type="arxiv">2209.14878</idno>
              <idno type="doi">10.4230/LIPIcs.STACS.2023.8</idno>
            </biblStruct>
          </sourceDesc>
          <profileDesc>
            <langUsage>
              <language ident="en">English</language>
            </langUsage>
            <textClass>
              <keywords scheme="author">
                <term xml:lang="en">Regular language</term>
                <term xml:lang="en">Constant-delay enumeration</term>
                <term xml:lang="en">Edit distance</term>
                <term xml:lang="en">constant-delay enumeration</term>
                <term xml:lang="en">edit distance</term>
                <term xml:lang="en">Theory of computation → Formal languages and automata theory</term>
              </keywords>
              <classCode scheme="halDomain" n="info">Computer Science [cs]</classCode>
              <classCode scheme="halTypology" n="COMM">Conference papers</classCode>
              <classCode scheme="halOldTypology" n="COMM">Conference papers</classCode>
              <classCode scheme="halTreeTypology" n="COMM">Conference papers</classCode>
            </textClass>
            <abstract xml:lang="en">
              <p>We study the task, for a given language $L$, of enumerating the (generallyinfinite) sequence of its words, without repetitions, while bounding thedelay between two consecutive words. To allow for delay bounds that do not depend on the current word length,we assume a model where we produce each word by editing the preceding word witha small edit script, rather than writing out the word from scratch. Inparticular, this witnesses that the language is orderable, i.e., we canwrite its words as an infinite sequence such that the Levenshtein edit distancebetween any two consecutive words is bounded by a value that depends only on the language. For instance,$(a+b)^*$ is orderable (with a variant of the Gray code), but $a^* + b^*$ isnot.We characterize which regular languages are enumerable in this sense, andshow that this can be decided in PTIME in an input deterministic finiteautomaton (DFA) for the language. In fact, we show that, given a DFA $A$,we can compute in PTIME automata $A_1, \ldots, A_t$ such that $L(A)$ is partitionedas $L(A_1) \sqcup \ldots \sqcup L(A_t)$ and every $L(A_i)$ is orderable inthis sense. Further, we show that the value of $t$ obtained is optimal, i.e., we cannot partition $L(A)$into less than $t$ orderable languages.In the case where $L(A)$ is orderable (i.e., $t=1$), we show that the ordering can beproduced by a bounded-delay algorithm: specifically, the algorithm runs in asuitable pointer machine model, and produces a sequence of bounded-length editscripts to visit the words of $\L(A)$ without repetitions, with bounded delay -- exponential in $|A|$ --between each script. In fact, we show that we can achieve this while onlyallowing the edit operations push and pop at the beginning andend of the word, which implies that the word can in fact be maintained ina double-ended queue.By contrast, when fixing the distance bound $d$ between consecutive wordsand the number of classes of the partition, it is NP-hard in the input DFA $A$to decide if $L(A)$ is orderable in this sense, already for finite languages. Last, we study the model where push-pop edits are only allowed at the end ofthe word, corresponding to a case where the word is maintained on a stack.We show that these operations are strictly weaker and that the slenderlanguages are precisely those that can be partitioned into finitely manylanguages that are orderable in this sense. For the slender languages, we can againcharacterize the minimal number of languages in the partition, and achievebounded-delay enumeration.</p>
            </abstract>
          </profileDesc>
        </biblFull>
      </listBibl>
    </body>
    <back>
      <listOrg type="structures">
        <org type="researchteam" xml:id="struct-554328" status="VALID">
          <orgName>Data, Intelligence and Graphs</orgName>
          <orgName type="acronym">DIG</orgName>
          <date type="start">2019-02-21</date>
          <desc>
            <address>
              <addrLine>Télécom Paris 19 Place Marguerite Perey 91120 Palaiseau</addrLine>
              <country key="FR" />
            </address>
            <ref type="url">https://www.telecom-paris.fr/fr/recherche/laboratoires/laboratoire-traitement-et-communication-de-linformation-ltci/les-equipes-de-recherche/data-intelligence-and-graphs-dig</ref>
          </desc>
          <listRelation>
            <relation active="#struct-484335" type="direct" />
            <relation active="#struct-302102" type="indirect" />
            <relation active="#struct-1048346" type="indirect" />
          </listRelation>
        </org>
        <org type="department" xml:id="struct-121818" status="VALID">
          <orgName>Département Informatique et Réseaux</orgName>
          <orgName type="acronym">INFRES</orgName>
          <desc>
            <address>
              <addrLine>46, rue Barrault 75013 Paris</addrLine>
              <country key="FR" />
            </address>
            <ref type="url">https://www.telecom-paris.fr/fr/recherche/laboratoires/laboratoire-traitement-et-communication-de-linformation-ltci/les-departements-denseignement-et-recherche</ref>
          </desc>
          <listRelation>
            <relation active="#struct-300362" type="direct" />
          </listRelation>
        </org>
        <org type="regroupinstitution" xml:id="struct-563936" status="VALID">
          <orgName>Institut Polytechnique de Paris</orgName>
          <orgName type="acronym">IP Paris</orgName>
          <date type="start">2019-06-02</date>
          <desc>
            <address>
              <country key="FR" />
            </address>
            <ref type="url">https://www.ip-paris.fr</ref>
          </desc>
        </org>
        <org type="researchteam" xml:id="struct-432648" status="VALID">
          <idno type="RNSR">201321077H</idno>
          <orgName>Linking Dynamic Data</orgName>
          <orgName type="acronym">LINKS</orgName>
          <date type="start">2015-01-01</date>
          <desc>
            <address>
              <country key="FR" />
            </address>
            <ref type="url">http://www.inria.fr/equipes/links</ref>
          </desc>
          <listRelation>
            <relation active="#struct-104752" type="direct" />
            <relation active="#struct-300009" type="indirect" />
            <relation active="#struct-410272" type="direct" />
            <relation name="UMR9189" active="#struct-120930" type="indirect" />
            <relation name="UMR9189" active="#struct-374570" type="indirect" />
            <relation name="UMR9189" active="#struct-441569" type="indirect" />
          </listRelation>
        </org>
        <org type="laboratory" xml:id="struct-484335" status="VALID">
          <idno type="IdRef">162384270</idno>
          <idno type="ISNI">0000 0000 9194 9502</idno>
          <idno type="RNSR">200319327Z</idno>
          <idno type="ROR">https://ror.org/057er4c39</idno>
          <orgName>Laboratoire Traitement et Communication de l'Information</orgName>
          <orgName type="acronym">LTCI</orgName>
          <date type="start">2017-01-01</date>
          <desc>
            <address>
              <addrLine>Télécom Paris 19 Place Marguerite Perey 91120 PALAISEAU</addrLine>
              <country key="FR" />
            </address>
            <ref type="url">https://www.telecom-paris.fr/fr/recherche/laboratoires/laboratoire-traitement-et-communication-de-linformation-ltci</ref>
          </desc>
          <listRelation>
            <relation active="#struct-302102" type="direct" />
            <relation active="#struct-1048346" type="direct" />
          </listRelation>
        </org>
        <org type="regroupinstitution" xml:id="struct-302102" status="VALID">
          <idno type="ROR">https://ror.org/025vp2923</idno>
          <orgName>Institut Mines-Télécom [Paris]</orgName>
          <orgName type="acronym">IMT</orgName>
          <date type="start">2012-03-01</date>
          <desc>
            <address>
              <addrLine>37-39 Rue Dareau, 75014 Paris</addrLine>
              <country key="FR" />
            </address>
            <ref type="url">http://www.mines-telecom.fr/</ref>
          </desc>
        </org>
        <org type="institution" xml:id="struct-1048346" status="VALID">
          <idno type="IdRef">026375273</idno>
          <idno type="ISNI">0000 0001 2108 2779</idno>
          <idno type="ROR">https://ror.org/01naq7912</idno>
          <orgName>Télécom Paris</orgName>
          <date type="start">2019-06-12</date>
          <desc>
            <address>
              <addrLine>19 Place Marguerite Perey 91120 Palaiseau </addrLine>
              <country key="FR" />
            </address>
            <ref type="url">https://www.telecom-paris.fr</ref>
          </desc>
        </org>
        <org type="institution" xml:id="struct-300362" status="VALID">
          <idno type="ROR">https://ror.org/01naq7912</idno>
          <orgName>Télécom ParisTech</orgName>
          <date type="start">2008-01-01</date>
          <date type="end">2019-06-11</date>
          <desc>
            <address>
              <addrLine>46 rue Barrault 75634 Paris Cedex 13</addrLine>
              <country key="FR" />
            </address>
            <ref type="url">https://www.telecom-paris.fr</ref>
          </desc>
        </org>
        <org type="laboratory" xml:id="struct-104752" status="VALID">
          <idno type="RNSR">200818245B</idno>
          <idno type="ROR">https://ror.org/04eej9726</idno>
          <orgName>Inria Lille - Nord Europe</orgName>
          <desc>
            <address>
              <addrLine>Parc Scientifique de la Haute Borne 40, avenue Halley Bât.A, Park Plaza 59650 Villeneuve d'Ascq</addrLine>
              <country key="FR" />
            </address>
            <ref type="url">http://www.inria.fr/lille/</ref>
          </desc>
          <listRelation>
            <relation active="#struct-300009" type="direct" />
          </listRelation>
        </org>
        <org type="institution" xml:id="struct-300009" status="VALID">
          <idno type="ROR">https://ror.org/02kvxyf05</idno>
          <orgName>Institut National de Recherche en Informatique et en Automatique</orgName>
          <orgName type="acronym">Inria</orgName>
          <desc>
            <address>
              <addrLine>Domaine de VoluceauRocquencourt - BP 10578153 Le Chesnay Cedex</addrLine>
              <country key="FR" />
            </address>
            <ref type="url">http://www.inria.fr/en/</ref>
          </desc>
        </org>
        <org type="laboratory" xml:id="struct-410272" status="VALID">
          <idno type="IdRef">18388695X</idno>
          <idno type="RNSR">201521249L</idno>
          <idno type="ROR">https://ror.org/05vrs3189</idno>
          <orgName>Centre de Recherche en Informatique, Signal et Automatique de Lille - UMR 9189</orgName>
          <orgName type="acronym">CRIStAL</orgName>
          <date type="start">2015-01-01</date>
          <desc>
            <address>
              <addrLine>Université de Lille - Campus scientifique - Bâtiment ESPRIT - Avenue Henri Poincaré - 59655 Villeneuve d’Ascq</addrLine>
              <country key="FR" />
            </address>
            <ref type="url">https://www.cristal.univ-lille.fr/</ref>
          </desc>
          <listRelation>
            <relation name="UMR9189" active="#struct-120930" type="direct" />
            <relation name="UMR9189" active="#struct-374570" type="direct" />
            <relation name="UMR9189" active="#struct-441569" type="direct" />
          </listRelation>
        </org>
        <org type="institution" xml:id="struct-120930" status="VALID">
          <idno type="IdRef">256304629</idno>
          <idno type="ISNI">0000000122034461</idno>
          <idno type="ROR">https://ror.org/01x441g73</idno>
          <orgName>Centrale Lille</orgName>
          <desc>
            <address>
              <addrLine>École Centrale de Lille - Cité Scientifique - CS 20048 59651 Villeneuve d'Ascq Cedex</addrLine>
              <country key="FR" />
            </address>
            <ref type="url">https://centralelille.fr/</ref>
          </desc>
        </org>
        <org type="regroupinstitution" xml:id="struct-374570" status="VALID">
          <idno type="IdRef">223446556</idno>
          <idno type="ISNI">0000 0001 2242 6780</idno>
          <idno type="ROR">https://ror.org/02kzqn938</idno>
          <idno type="Wikidata">Q3551621</idno>
          <orgName>Université de Lille</orgName>
          <desc>
            <address>
              <addrLine>EPE Université de Lille. -- 42 rue Paul Duez, 59000 Lille</addrLine>
              <country key="FR" />
            </address>
            <ref type="url">https://www.univ-lille.fr/</ref>
          </desc>
        </org>
        <org type="regroupinstitution" xml:id="struct-441569" status="VALID">
          <idno type="IdRef">02636817X</idno>
          <idno type="ISNI">0000000122597504</idno>
          <idno type="ROR">https://ror.org/02feahw73</idno>
          <orgName>Centre National de la Recherche Scientifique</orgName>
          <orgName type="acronym">CNRS</orgName>
          <date type="start">1939-10-19</date>
          <desc>
            <address>
              <country key="FR" />
            </address>
            <ref type="url">https://www.cnrs.fr/</ref>
          </desc>
        </org>
      </listOrg>
      <listOrg type="projects">
        <org type="anrProject" xml:id="projanr-50788" status="VALID">
          <idno type="anr">ANR-19-CE48-0019</idno>
          <orgName>EQUUS</orgName>
          <desc>Réponse efficace aux requêtes sous mises à jour</desc>
          <date type="start">2019</date>
        </org>
      </listOrg>
    </back>
  <teiCorpus>
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Enumerating Regular Languages with Bounded Delay</title>
				<funder ref="#_BymTNsp">
					<orgName type="full">Agence Nationale de la Recherche</orgName>
					<orgName type="abbreviated">ANR</orgName>
				</funder>
				<funder ref="#_S7J6K2x">
					<orgName type="full">Deutsche Forschungsgemeinschaft (DFG, German Research Foundation</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher />
				<availability status="unknown"><licence /></availability>
				<date type="published" when="2023-01-07">7 Jan 2023</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Antoine</forename><forename type="middle">Amarilli</forename><surname>Ltci</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Télécom Paris</orgName>
								<orgName type="institution" key="instit2">Institut Polytechnique de Paris</orgName>
								<address>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Mikaël</forename><surname>Monet</surname></persName>
							<affiliation key="aff1">
								<orgName type="laboratory">UMR 9189 CRIStAL</orgName>
								<orgName type="institution" key="instit1">Univ. Lille</orgName>
								<orgName type="institution" key="instit2">Inria</orgName>
								<orgName type="institution" key="instit3">CNRS</orgName>
								<orgName type="institution" key="instit4">Centrale Lille</orgName>
								<address>
									<postCode>F-59000</postCode>
									<settlement>Lille</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Enumerating Regular Languages with Bounded Delay</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2023-01-07">7 Jan 2023</date>
						</imprint>
					</monogr>
					<idno type="MD5">14F35B5CA6F9EFC2985457DC397347EC</idno>
					<idno type="DOI">10.4230/LIPIcs.STACS.2023.8</idno>
					<idno type="arXiv">arXiv:2209.14878v3[cs.FL]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-04-12T14:50+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid" />
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>2012 ACM Subject Classification Theory of computation Ñ Formal languages and automata theory Regular language</term>
					<term>constant-delay enumeration</term>
					<term>edit distance</term>
				</keywords>
			</textClass>
			<abstract>
<div><p>We study the task, for a given language L, of enumerating the (generally infinite) sequence of its words, without repetitions, while bounding the delay between two consecutive words. To allow for delay bounds that do not depend on the current word length, we assume a model where we produce each word by editing the preceding word with a small edit script, rather than writing out the word from scratch. In particular, this witnesses that the language is orderable, i.e., we can write its words as an infinite sequence such that the Levenshtein edit distance between any two consecutive words is bounded by a value that depends only on the language. For instance, pa `bq ˚is orderable (with a variant of the Gray code), but a ˚`b ˚is not.</p><p>We characterize which regular languages are enumerable in this sense, and show that this can be decided in PTIME in an input deterministic finite automaton (DFA) for the language. In fact, we show that, given a DFA A, we can compute in PTIME automata A1, . . . , At such that LpAq is partitioned as LpA1q \ . . . \ LpAtq and every LpAiq is orderable in this sense. Further, we show that the value of t obtained is optimal, i.e., we cannot partition LpAq into less than t orderable languages.</p><p>In the case where LpAq is orderable (i.e., t " 1), we show that the ordering can be produced by a bounded-delay algorithm: specifically, the algorithm runs in a suitable pointer machine model, and produces a sequence of bounded-length edit scripts to visit the words of LpAq without repetitions, with bounded delay -exponential in |A| -between each script. In fact, we show that we can achieve this while only allowing the edit operations push and pop at the beginning and end of the word, which implies that the word can in fact be maintained in a double-ended queue.</p><p>By contrast, when fixing the distance bound d between consecutive words and the number of classes of the partition, it is NP-hard in the input DFA A to decide if LpAq is orderable in this sense, already for finite languages.</p><p>Last, we study the model where push-pop edits are only allowed at the end of the word, corresponding to a case where the word is maintained on a stack. We show that these operations are strictly weaker and that the slender languages are precisely those that can be partitioned into finitely many languages that are orderable in this sense. For the slender languages, we can again characterize the minimal number of languages in the partition, and achieve bounded-delay enumeration.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div><head n="1">Introduction</head><p>Enumeration algorithms <ref type="bibr">[24,</ref><ref type="bibr">27]</ref> are a way to study the complexity of problems beyond decision or function problems, where we must produce a large number of outputs without repetitions. In such algorithms, the goal is usually to minimize the worst-case delay between any two consecutive outputs. The best possible bound is to make the delay constant, i.e., independent from the size of the input. This is the case, for example, when enumerating the results of acyclic free-connex conjunctive queries <ref type="bibr" target="#b6">[7]</ref> or of MSO queries over trees <ref type="bibr" target="#b5">[6,</ref><ref type="bibr">15]</ref>. Unfortunately, constant-delay is an unrealistic requirement when the objects to enumerate can have unbounded size, simply because of the time needed to write them out. Faced by this problem, one option is to neglect this part of the running time, e.g., following Ruskey's "Do not count the output principle" <ref type="bibr">[22, p. 8]</ref>. In this work, we address this challenge in a different way: we study enumeration where each new object is not written from scratch but produced by editing the previous object, by a small sequence of edit operations called an edit script. This further allows us to study the enumeration of infinite collections of objects, with an algorithm that runs indefinitely and ensures that each object is produced after some finite number of steps, and exactly once. The size of the edit scripts must be bounded, i.e., it only depends on the collection of objects to enumerate, but not on the size of the current object. The algorithm thus outputs an infinite series of edit scripts such that applying them successively yields the infinite collection of all objects. In particular, the algorithm witnesses that the collection admits a so-called ordering: it can be ordered as an infinite sequence with a bound on the edit distance between any two consecutive objects, namely, the number of edit operations.</p><p>In this paper, we study enumeration for regular languages in this sense, with the Levenshtein edit distance and variants thereof. One first question is to determine if a given regular language L admits an ordering, i.e., can we order its words such that the Levenshtein distance of any two consecutive words only depends on L and not on the word lengths? For instance, the language a ˚is easily orderable in this sense. The language a ˚b˚i s orderable, e.g., following any Hamiltonian path on the infinite N ˆN grid. More interestingly, the language pa `bq ˚is orderable, for instance by considering words by increasing length and using a Gray code <ref type="bibr">[18]</ref>, which enumerates all n-bit words by changing only one bit at each step. More complex languages such as apa `bcq ˚`bpcbq ˚ddd ˚can also be shown to be orderable (as our results will imply). However, one can see that some languages are not orderable, e.g., a ˚`b ˚. We can nevertheless generalize orderability by allowing multiple "threads": then we can partition a ˚`b ˚as a ˚and b ˚, both of which are orderable. This leads to several questions: Can we characterize the orderable regular languages? Can every regular language be partitioned as a finite union of orderable languages? And does this lead to a (possibly multi-threaded) enumeration algorithm with bounded delay (i.e., depending only on the language but not on the current word length)? easily applied in constant-time to a word represented in a double-ended queue; by contrast, Levenshtein edit operations are more difficult to implement, because they refer to integer word positions that change whenever characters are inserted or deleted. <ref type="foot" target="#foot_0">1</ref>And indeed, this result on the push-pop distance then allows us to design a bounded-delay algorithm for LpAq, which produces a sequence of bounded edit scripts of push or pop operations that enumerates LpAq. The length of the edit scripts is polynomial in |A| and the delay of our algorithm is exponential in |A|, but crucially it remains bounded throughout the (generally infinite) execution of the algorithm, and does not depend on the size of the words that are achieved. Formally, we show: § Result 1. Given a DFA A, one can compute in PTIME automata A 1 , . . . , A t for some t ď |A| such that LpAq is the disjoint union of the LpA i q, and we can enumerate each LpA i q with bounded delay for the push-pop distance with distance bound 48|A| 2 and exponential delay in |A|. Further, LpAq has no partition of cardinality t ´1 into orderable languages, even for the Levenshtein distance.</p><p>Thus, we show that orderability and enumerability, for the push-pop or Levenshtein edit distance, are in fact all logically equivalent on regular languages, and we characterize them (and find the optimal partition cardinality) in PTIME. By contrast, as was pointed out in <ref type="bibr">[19]</ref>, testing orderability for a fixed distance d is NP-hard in the input DFA, even for finite languages.</p><p>Last, we study the push-pop-right distance, which only allows edits at the end of the word. The motivation for studying this distance is that it corresponds to enumeration algorithms in which the word is maintained on a stack. We show that, among the regular languages, the slender languages <ref type="bibr">[20]</ref> are then precisely those that can be partitioned into finitely many orderable languages, and that these languages are themselves enumerable. Further, the optimal cardinality of the partition can again be computed in PTIME: § Result 2. Given a DFA A, then LpAq is partitionable into finitely many orderable languages for the push-pop-right distance if and only if LpAq is slender (which we can test in PTIME in A). Further, in this case, we can compute in PTIME the smallest partition cardinality, and each language in the partition is enumerable with bounded delay with distance bound 2|A| and linear delay in |A|.</p><p>In terms of proof techniques, our PTIME characterization of Result 1 relies on a notion of interchangeability of automaton states, defined via paths between states and via states having common loops. We then show orderability by establishing stratum-connectivity, i.e., for any stratum of words of the language within some length interval, there are finite sequences obeying the distance bound that connect any two words in that stratum. We show stratum-connectivity by pumping and de-pumping loops close to the word endpoints. We then deduce an ordering from this by adapting a standard technique <ref type="bibr">[26]</ref> of visiting a spanning tree and enumerating even and odd levels in alternation (see also <ref type="bibr">[23,</ref><ref type="bibr" target="#b13">14]</ref>). The bounded-delay enumeration algorithm then proceeds by iteratively enlarging a custom data structure called a word DAG, where the construction of the structure for a stratum is amortized by enumerating the edit scripts to achieve the words of the previous stratum.</p></div>
<div><head>Related work.</head><p>As we explained, enumeration has been extensively studied for many structures <ref type="bibr">[27]</ref>. For regular languages specifically, some authors have studied the problem of enumerating their words in radix order [16, <ref type="bibr" target="#b0">1,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b10">11]</ref>. For instance, the authors of <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2]</ref> provide an algorithm that enumerates all words of a regular language in that order, with a delay of Op|w|q for w the next word to enumerate. Thus, this delay is not bounded, and the requirement to enumerate in radix order makes it challenging to guarantee a bounded distance between consecutive words (either in the Levenshtein or push-pop distance), which is necessary for bounded-delay enumeration in our model. Indeed, our results show that not all regular languages are orderable in our sense, whereas their linear-delay techniques apply to all regular languages.</p><p>We have explained that enumeration for pa `bq ˚relates to Gray codes, of which there exist several variants <ref type="bibr">[18]</ref>. Some variants, e.g., the so-called middle levels problem <ref type="bibr">[17]</ref>, aim at enumerating binary words of a restricted form; but these languages are typically finite (i.e., words of length n), and their generalization is typically not regular. While Gray codes typically allow arbitrary substitutions, one work has studied a variant that only allows restricted operations on the endpoints <ref type="bibr" target="#b9">[10]</ref>, implying the push-pop orderability of the specific language pa `bq ˚.</p><p>Independently, some enumeration problems on automata have been studied recently in the database theory literature, in particular for document spanners <ref type="bibr" target="#b8">[9]</ref>, which can be defined by finite automata with capture variables. It was recently shown <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b2">3]</ref> that we can enumerate in constant delay all possible assignments of the capture variables of a fixed spanner on an input word. In these works, the delay is constant in data complexity, which means that it only depends on the (fixed) automaton, and does not depend on the word; this matches what we call bounded delay in our work (where there is no input word and the automaton is given as input). However, our results do not follow from these works, which focus on the enumeration of results of constant size. Some works allow second-order variables and results of non-constant size <ref type="bibr" target="#b3">[4]</ref> but the delay would then be linear in each output, hence unbounded.</p><p>Paper structure. We give preliminaries in Section 2. In Section 3 we present our PTIME construction of a partition of a regular language into finitely many orderable languages, and prove that the cardinality of the obtained partition is minimal for orderability. We then show in Section 4 that each term of the union is orderable, and then that it is enumerable in Section 5. We present the NP-hardness result on testing orderability for a fixed distance and our results on push-pop-right operations in Section 6. We conclude and mention some open problems in Section 7. Due to space constraints, we mostly present the general structure of the proofs and give the main ideas; detailed proofs of all statements can be found in the appendix.</p></div>
<div><head n="2">Preliminaries</head><p>We fix a finite non-empty alphabet Σ of letters. A word is a finite sequence w " a 1 ¨¨¨a n of letters. We write |w| " n, and write for the empty word. We write Σ ˚the infinite set of words over Σ. A language L is a subset of Σ ˚. For k P N, we denote L ăk the language tw P L | |w| ă ku. In particular we have L ă0 " H.</p><p>In this paper we study regular languages. Recall that such a language can be described by a deterministic finite automaton (DFA) A " pQ, Σ, q 0 , F, δq, which consists of a finite set Q of states, an initial state q 0 P Q, a set F Ď Q of final states, and a partial transition function δ : Q ˆΣ Ñ Q. We write |A| the size of representing A, which is Op|Q| ˆ|Σ|q. A (directed) path in A from a state q P Q to a state q 1 P Q is a sequence of states q " q 0 , . . . , q n " q 1 where for each 0 ď i ă n we have q i`1 " δpq i , a i q for some a i . For a suitable choice a 0 , . . . , a n´1 , we call the word a 0 ¨¨¨a n´1 P Σ ˚a label of the path. In particular, there is an empty path with label from every state to itself. The language LpAq accepted by A consists of the words w that label a path from q 0 to some final state. We assume without loss of generality that all automata are trimmed, i.e., every state of Q has a path from q 0 and has a path to some final state; this can be enforced in linear time.</p><p>Edit distances. For an alphabet Σ, we denote by δ Lev : Σ ˚ˆΣ ˚Ñ N the Levenshtein edit distance: given u, v P Σ ˚, the value δ Lev pu, vq is the minimum number of edits needed to transform u into v, where the edit operations are single-letter insertions, deletions or substitutions (we omit their formal definitions).</p><p>While our lower bounds hold for the Levenshtein distance, our positive results already hold with a restricted set of 2|Σ| `2 edit operations called the push-pop edit operations: <software>pushLpaq</software> and <software ContextAttributes="used">pushRpaq</software> for a P Σ, which respectively insert a at the beginning and at the end of the word, and popLpq and popRpq, which respectively remove the first and last character of the word (and cannot be applied if the word is empty). Thus, we define the push-pop edit distance, denoted δ pp , like δ Lev but allowing only these edit operations.</p><p>Orderability. Fixing a distance function δ : Σ ˚ˆΣ ˚Ñ N over Σ ˚, for a language L Ď Σ ånd d P N, a d-sequence in L is a (generally infinite) sequence s of words w 1 , . . . , w n , . . . of L without repetition, such that for every two consecutive words w i , w i`1 in s we have δpw i , w i`1 q ď d. We say that s starts at w 1 and, in case s is finite and has n elements, that s ends at w n (or that s is between w 1 and w n ). A d-ordering of L is a d-sequence s in L such that every word of L occurs in s; equivalently, it is a permutation of L such that any two consecutive words are at distance at most d. An ordering is a d-ordering for some d P N. If these exist, we call the language L, respectively, d-orderable and orderable. We call L pt, dq-partition-orderable if it can be partitioned into t languages that each are d-orderable: § Definition 2.1. Let L be a language and t, d P N. We call L pt, dq-partition-orderable if L has a partition L " Ů 1ďiďt L i such that each L i is d-orderable. <ref type="foot" target="#foot_1">2</ref>Note that, if we allowed repetitions in d-orderings, then the language of any DFA A would be Op|A|q-orderable: indeed, any word w can be transformed into a word w 1 of length Op|A|q by iteratively removing simple loops in the run of w. By contrast, we will see in Section 3 that allowing a constant number of repetitions of each word makes no difference. § Example 2.2. We consider the Levenshtein distance in this example. The language paaq is p1, 2q-partition-orderable (i.e., 2-orderable) and not pk, 1q-partition-orderable for any k P N. The language a ˚`b ˚is p2, 1q-partition-orderable and not orderable, i.e., not d-orderable for any d P N. Any finite language is d-orderable with d the maximal length of a word in L. The non-regular language ta n 2</p><p>| n P Nu is not pt, dq-partition-orderable for any t, d P N.</p><p>Enumeration algorithms. We study enumeration algorithms, which output a (generally infinite) sequence of edit scripts σ 1 , σ 2 , . . .. We only study enumeration algorithms where each edit script σ i is a finite sequence of push-pop edit operations. The algorithm enumerates a language L if the sequence satisfies the following condition: letting w 1 be the result of applying σ 1 on the empty word, w 2 be the result of applying σ 2 to w 1 , and so on, then all w i are distinct and L " tw 1 , w 2 , . . .u. If L is infinite then the algorithm does not terminate, but the infinite sequence ensures that every w P L is produced as the result of applying (to ) some finite prefix σ 1 , . . . , σ n of the output. We aim for bounded-delay algorithms, i.e., each edit script must be output in time that only depends on the language L that is enumerated, but not on the current length of the words. Formally, the algorithm can emit any push-pop edit operation and a delimiter Output, it must successively emit the edit operations of σ i followed by Output, and there is a bound T ą 0 (the delay) depending only on L such that the first Output is emitted at most T operations after the beginning of the algorithm, and for each i ą 1 the i-th Output is emitted at most T operations after the pi ´1q-th Output. Note that our notion of delay also accounts for what is usually called the preprocessing phase in the literature, i.e., the phase before the first result is produced. Crucially the words w i obtained by applying the edit scripts σ i are not written, and T does not depend on their length.</p><p>We say that a bounded-delay algorithm d-enumerates a language L if it produces a d-ordering of L (for the push-pop distance). Thus, if L is d-enumerable (by an algorithm), then L is in particular d-orderable, and we will show that for regular languages, the converse also holds. § Example 2.3. Consider the regular language L :" a ˚b˚`b˚a˚. This language is 2-orderable for the push-pop distance. Indeed, we can order it by increasing word length, finishing for word length i by the word a i as follows. We start by length zero with the empty word (so the first edit script is empty), then, assuming we have ordered all words of L of size ď i while finishing with a i , we continue with words of L of size i `1 in the following manner: we push-right the letter b to obtain a i b, and then we "shift" with edit scripts of the form ppushRpbq; popLpqq until we obtain b i`1 , and then we shift again with edit scripts of the form ppushRpaq; popLpqq until we obtain a i`1 as promised. This gives us an enumeration algorithm for L, shown in Algorithm 1. As such, the delay of Algorithm 1 is not bounded, because of the time needed to increment the integer variable size: this variable becomes arbitrarily large throughout the enumeration, so it is not realistic to assume that we can increment it in constant time. This can however be fixed by working in a suitable pointer machine model, as explained next.</p><p>Note that our enumeration algorithms run indefinitely, and thus use unbounded memory: this is unavoidable because their output would necessarily be ultimately periodic otherwise, which is not suitable in general (see Appendix A.1). To avoid specifying the size of memory cells or the complexity of arithmetic computations (e.g., incrementing the integer size in Algorithm 1), we consider a different model called pointer machines <ref type="bibr">[25]</ref> which only allows arithmetic on a bounded domain. We use this model for our enumeration algorithms (but not, e.g., our other complexity results such as PTIME bounds).</p><p>Intuitively, a pointer machine works with records consisting of a constant number of labeled fields holding either data values (in our case of constant size, i.e., constantly many possible values) or pointers (whose representation is not specified). The machine has memory consisting of a finite but unbounded collection of records, a constant number of which are designated as registers and are always accessible. The machine can allocate records in constant time, retrieving a pointer to the memory location of the new record. We can access the fields of records, read or write pointers, dereference them, and test them for equality, all in constant time, but we cannot perform any other manipulation on pointers or other arithmetic operations. (We can, however, count in unary with a linked list, or perform arbitrary operations on the constant-sized data values.) See Appendix A.2 for details. easily be adapted to a pointermachine algorithm that 2-enumerates L, maintaining the word in a double-ended queue (deque) and keeping pointers to the first and last positions in order to know when to stop the for loops. Deques can indeed be simulated in this machine model, e.g., with linked lists.</p></div>
<div><head n="3">Interchangeability partition and orderability lower bound</head><p>In this section, we start the proof of our main result, Result 1. Let A be the DFA and let Q be its set of states. The result is trivial if the language LpAq is finite, as we can always enumerate it naively with distance Op|A|q and some arbitrary delay bound, so in the rest of the proof we assume that LpAq is infinite. We will first define a notion of interchangeability on DFAs by introducing the notions of connectivity and compatibility on DFA states (this notion will be used in the next section to characterize orderability). We then partition LpAq into languages LpA 1 q \ ¨¨¨\ LpA t q following a so-called interchangeability partition, with each A i having this interchangeability property. Last, we show in the section our lower bound establishing that t is optimal. Interchangeability. To define our notion of interchangeability, we first define the loopable states of the DFA as those that are part of a non-empty cycle (possibly a self-loop): § Definition 3.1. For a state q P Q, we let A q be the DFA obtained from A by setting q as the only initial and final state. We call q loopable if LpA q q ‰ t u, and non-loopable otherwise.</p><p>We then define the interchangeability relation on loopable states as the transitive closure of the union of two relations, called connectivity and compatibility: § Definition 3.2. We say that two loopable states q and q 1 are connected if there is a directed path from q to q 1 , or from q 1 to q. We say that two loopable states q, q 1 are compatible if LpA q q X LpA q 1 q ‰ t u. These two relations are symmetric and reflexive on loopable states. We then say that two loopable states q and q 1 are interchangeable if they are in the transitive closure of the union of the connectivity and compatibility relations. In other words, q and q 1 are interchangeable if there is a sequence q " q 0 , . . . , q n " q 1 of loopable states such that for any 0 ď i ă n, the states q i and q i`1 are either connected or compatible. Interchangeability is then an equivalence relation over loopable states.</p><p>Note that if two loopable states q, q 1 are in the same strongly connected component (SCC) of A then they are connected, hence interchangeable. Thus, we can equivalently see the interchangeability relation at the level of SCCs (excluding those that do not contain a loopable state, i.e., excluding the trivial SCCs containing only one state having no self-loop). § Definition 3.3. We call classes of interchangeable states, or simply classes, the equivalence classes of the interchangeability relation. Recall that, as LpAq is infinite, there is at least one class. We say that the DFA A is interchangeable if the partition has only one class, in other words, if all loopable states of A are interchangeable. § Example 3.4. The DFA A 1 shown in Figure <ref type="figure" target="#fig_0">1a</ref> for the language pa `bq ˚has only one loopable state, so A 1 is interchangeable.</p><p>The DFA A 2 shown in Figure <ref type="figure" target="#fig_0">1b</ref> for the language a ˚b˚h as two loopable states 0 and 1 which are connected, hence interchangeable. Thus, A 2 is interchangeable.</p><p>The DFA A 3 shown in Figure <ref type="figure" target="#fig_0">1c</ref> for the language c ˚pa ˚`b ˚q has three loopable states: 0, 1 and 2. The states 0 and 1 are connected, and 0 and 2 are also connected, so all loopable states are interchangeable and A 3 is interchangeable.</p><p>The DFA A 4 shown in Figure <ref type="figure" target="#fig_0">1d</ref> for the language a ˚`b ˚has two loopable states 1 and 2 which are neither connected nor compatible. So A 4 is not interchangeable.</p><p>The DFA A 5 shown in Figure <ref type="figure" target="#fig_0">1e</ref> for the language apa `bcq ˚`bpcbq ˚ddd ˚mentioned in the introduction has five loopable states: 1, 2, 3, 4, and 6. Then 1 and 2 are connected, 3 and 4 are connected, 3 and 6 are connected, and 1 and 4 are compatible (with the word bc). Hence, all loopable states are interchangeable and A 5 is interchangeable.</p><p>The DFA A 6 shown in Figure <ref type="figure" target="#fig_0">1f</ref> for the language a ˚b˚`b˚a˚f rom Example 2.3 has four loopable states: 1, 2, 3, and 4. Then 1 and 2 are connected, 3 and 4 are connected, and (for instance) 1 and 4 are compatible (with the word a). Hence all loopable states are interchangeable and A 6 is interchangeable.</p><p>Interchangeability partition. We now partition LpAq using interchangeable DFAs: § Definition 3.5. An interchangeability partition of A is a sequence A 1 , . . . , A t of DFAs such that LpAq is the disjoint union of the LpA i q and every A i is interchangeable. Its cardinality is the number t of DFAs.</p><p>Let us show how to compute an interchangeability partition whose cardinality is the number of classes. We will later show that this cardinality is optimal. Here is the statement: § Proposition 3.6. We can compute in polynomial time in A an interchangeability partition A 1 , . . . , A t of A, with t ď |A| the number of classes of interchangeable states.</p><p>Intuitively, the partition is defined following the classes of A. Indeed, considering any word w P LpAq and its accepting run ρ in A, for any loopable state q and q 1 traversed in ρ, the word w witnesses that q and q 1 are connected, hence interchangeable. Thus, we would like to partition the words of LpAq based on the common class of the loopable states traversed in their accepting run. The only subtlety is that LpAq may also contain words whose accepting run does not traverse any loopable state, called non-loopable words. For instance, is a non-loopable word of LpA 5 q for A 5 given in Figure <ref type="figure" target="#fig_0">1e</ref>. Let us formally define the non-loopable words, and our partition of the loopable words based on the interchangeability classes: § Definition 3.7. A word w " a 1 ¨¨¨a n of LpAq is loopable if, considering its accepting run q 0 , . . . , q n with q 0 the initial state and q i " δpq i´1 , a i q for 1 ď i ď n, one of the q i is loopable. Otherwise, w is non-loopable. We write NLpAq the set of the non-loopable words of LpAq.</p><p>Letting C be a class of interchangeable states, we write LpA, Cq the set of (loopable) words of LpAq whose accepting run traverses a state of C.</p><p>We then have the following, with finiteness of NLpAq shown by the pigeonhole principle: § Claim 3.8. The language LpAq can be partitioned as NLpAq and LpA, C 1 q, . . . , LpA, C t q over the classes C 1 , . . . , C t of interchangeable states, and further NLpAq is finite.</p><p>We now construct an interchangeability partition of A of the right cardinality by defining one DFA A i for each class of interchangeable states, where we simply remove the loopable states of the other classes. These DFAs are interchangeable by construction. We modify the DFAs to ensure that the non-loopable words are only captured by A 1 . This construction (explained in the appendix) is doable in PTIME, in particular the connectivity and compatibility relations can be computed in PTIME, testing compatibility by checking the nonemptiness of product automata. This establishes Proposition 3.6.</p></div>
<div><head>Lower bound.</head><p>We have shown how to compute an interchangeability partition of a DFA A with cardinality the number t of classes. Let us now show that this value of t is optimal, in the sense that LpAq cannot be partitioned into less than t orderable (even non-regular) languages. This lower bound holds even when allowing Levenshtein edits. Formally: § Theorem 3.9. For any partition of the language LpAq as LpAq " L 1 \ ¨¨¨\ L t 1 if for each 1 ď i ď t 1 the language L i is orderable for the Levenshtein distance, then we have t 1 ě t for t the number of classes of A. This establishes the negative part of Result 1. Incidentally, this lower bound can also be shown even if the unions are not disjoint, indeed even if we allow repetitions, provided that there is some constant bound on the number of repetitions of each word. Theorem 3.9 can be shown from the following claim which establishes that sufficiently long words from different classes are arbitrarily far away for the Levenshtein distance: § Proposition 3.10. Letting C 1 , . . . , C t be the classes of A, for any distance d P N, there is a threshold l P N such that for any two words u P LpA, C i q and v P LpA, C j q with i ‰ j and |u| ě l and |v| ě l, we have δ Lev pu, vq ą d.</p><p>This proposition implies Theorem 3.9 because, if we could partition LpAq into less than t orderable languages, then some ordering must include infinitely many words from two different classes LpA, C i q and LpA, C j q, hence alternate infinitely often between the two. Fix the distance d, and consider a point when all words of L of length ď maxpl, max wPNLpAq |w|q have been enumerated, for l the threshold of the proposition: then it is no longer possible for any ordering to move from one class to another, yielding a contradiction. As for the proof of Proposition 3.10, we give a sketch below (the complete proofs are in appendix):</p><p>Proof sketch. Given a sufficiently long word u P LpA, C i q, by the pigeonhole principle its run must contain a large number of loops over some state q P C i . Assume that we can edit u into v P LpA, C j q with d edit operations: this changes at most d of these loops. Now, considering the accepting run of v and using the pigeonhole principle again on the sequence of endpoints of contiguous unmodified loops, we deduce that some state q 1 occurs twice; then q 1 P C j by definition of LpA, C j q. The label of the resulting loop on q 1 is then also the label of a loop on q, so q and q 1 are compatible, hence C i " C j . đ</p></div>
<div><head n="4">Orderability upper bound</head><p>We have shown in the previous section that we could find an interchangeability partition of any regular language LpAq into languages LpA 1 q, . . . , LpA t q of interchangeable DFAs, for t the number of classes. We know by our lower bound (Theorem 3.9) that we cannot hope to order LpAq with less than t sequences. Thus, in this section, we focus on each interchangeable A i separately, and show how to order LpA i q as one sequence. Hence, we fix for this section a DFA A that is interchangeable, write k its number of states, and show that LpAq is orderable. We will in fact show that this is the case for the push-pop distance: § Theorem 4.1. For any interchangeable DFA A, the language LpAq is 48k 2 -orderable for the push-pop distance.</p><p>We show this result in the rest of this section, and strengthen it in the next section to a bounded-delay algorithm. Before starting, we give an overview of the structure of the proof. The proof works by first introducing d-connectivity of a language (not to be confused with the connectivity relation on loopable automaton states). This weaker notion is necessary for d-orderability, but for finite languages we will show a kind of converse: d-connectivity implies 3d-orderability. We will then show that LpAq is stratum-connected, i.e., the finite strata of words of LpAq in some length interval are each d-connected for some common d. Last, we will show show that this implies orderability, using the result on finite languages.</p><p>Connectivity implies orderability on finite languages. We now define d-connectivity: § Definition 4.2. A language L is d-connected if for every pair of words u, v P L, there exists a d-sequence in L between u and v.</p><p>Clearly d-connectivity is a necessary condition for d-orderability: indeed if w 1 , w 2 , . . . is a d-ordering of L, and u " w i , v " w j are two words of L with i ď j (without loss of generality), then w i , w i`1 , . . . , w j is indeed a d-sequence in L between u and v. What is more, for finite languages, the converse holds, up to multiplying the distance by a constant factor: § Lemma 4.3. Let L be a finite language that is d-connected and s ‰ e be words of L. Then there exists a 3d-ordering of L starting at s and ending at e. Proof sketch. We use the fact, independently proved by Sekanina and by <ref type="bibr">Karaganis [23,</ref><ref type="bibr" target="#b13">14]</ref>, that the cube of every connected graph G has a Hamiltonian path between any pair of vertices (see also <ref type="bibr">[18]</ref>). One algorithmic way to see this is by traversing a spanning tree of G and handling odd-depth and even-depth nodes in prefix and postfix fashion (see, e.g., <ref type="bibr">[26]</ref>). Applying this to the graph G whose vertices are the words of L and where two words w, w 1 are connected by an edge when δpw, w 1 q ď d yields the result. đ</p><p>The constant 3 in this lemma is optimal, as follows from <ref type="bibr">[21]</ref>; see Appendix C for more details. Note that the result does not hold for infinite languages: a ˚`b ˚is 1-connected (via ) but not d-orderable for any d.</p><p>Stratum-connectivity. To show orderability for infinite languages, we will decompose them into strata, which simply contain the words in a certain length range. Formally: § Definition 4.4. Let L be a language, let ą 0 be an integer, and let i ą 0. The i-th stratum of width (or -stratum) of L, written strat pL, iq, is L ăi zL ăpi´1q .</p><p>We will show that, for the language LpAq of our interchangeable DFA A, we can pick and d such that every -stratum of LpAq is d-connected, i.e., LpAq is p , dq-stratum-connected: § Definition 4.5. Let L be a regular language and fix , d ą 0. We say that L is p , dqstratum-connected if every -stratum strat pL, iq is d-connected.</p><p>Note that our example language a ˚`b ˚, while 1-connected, is not p , dq-stratum-connected for any , d, because any i-th -stratum for i ą d is not d-connected. We easily show that stratum-connectivity implies orderability: § Lemma 4.6. Let L be an infinite language recognized by a DFA with k 1 states, and assume that L is p , dq-stratum-connected for some ě 2k 1 and some d ě 3k 1 . Then L is 3d-orderable.</p><p>Proof sketch. We show by pumping that we can move across contiguous strata. Thus, we combine orderings on each stratum obtained by Lemma 4.3 with well-chosen endpoints. đ</p><p>We can then show using several pumping and de-pumping arguments that the language of our interchangeable DFA A is p , dq-stratum-connected for :" 8k 2 and d :" 16k 2 . § Proposition 4.7. The language LpAq is p8k 2 , 16k 2 q-stratum-connected.</p></div>
<div><head>Proof sketch.</head><p>As there are only a finite number of non-loopable words, we focus on loopable words. Consider a stratum S and two loopable words u and v of S. Their accepting runs involve loopable states, respectively q and q 1 , that are interchangeable because A is. We first show that u is d-connected (in S) to a normal form: a repeated loop on q plus a prefix and suffix whose length is bounded, i.e., only depends on the language. We impose this in two steps: first we move the last occurrence of q in u near the end of the word by pumping at the left end and de-pumping at the right end, second we pump the loop on q at the right end while de-pumping the left end. This can be done while remaining in the stratum S. We obtain similarly a normal form consisting of a repeated loop on q 1 with bounded-length prefix and suffix that is d-connected to v in S.</p><p>Then we do an induction on the number of connectivity and compatibility relations needed to witness that q and q 1 are interchangeable. If q " q 1 , we conclude using the normal forms of u and v. If q is connected to q 1 , we impose the normal form on u, then we modify it to a word whose accepting run also visits q 1 , and we apply the previous case. If q is compatible with q 1 , we conclude using the normal form with some loop label z in A q X A q 1 (of length ď k 2 ) that witnesses their compatibility. The induction case is then easy. đ</p><p>From this, we deduce with Lemma 4.6 that LpAq is 48k 2 -orderable, so Theorem 4.1 holds. Note that the construction ensures that the words are ordered stratum after stratum, so "almost" by increasing length: in the ordering that we obtain, after producing some word w, we will never produce words of length less than |w| ´ .</p></div>
<div><head n="5">Bounded-delay enumeration</head><p>In this section, we show how the orderability result of the previous section yields a boundeddelay algorithm. We use the pointer-machine model from Section 2, which we modify for convenience to allow data values and the number of fields of records to be exponential in the automaton (but fixed throughout the enumeration, and independent on the size of words): see Appendix D.1 for explanations on why we can do this. We show: § Theorem 5.1. There is an algorithm which, given an interchangeable DFA A with k states, enumerates the language LpAq with push-pop distance bound 48k 2 and exponential delay in |A|.</p><p>Let us accordingly fix the interchangeable DFA A with k states. Following Proposition 4.7, we let d :" 16k 2 and :" 8k 2 .</p><p>Overall amortized scheme. The algorithm will consider the strata of the input language L and will run two processes in parallel: the first process simply enumerates a previously prepared sequence of edit scripts that gives a 3d-ordering of some stratum, while the second process computes the sequences for subsequent strata (and of course imposing that the endpoints of the sequences for contiguous strata are sufficiently close).</p><p>The challenging part is to prepare efficiently the sequences for all strata, and in particular to build a data structure that represents the strata. We will require of our algorithm that it processes each stratum in amortized linear time in its size. Formally, letting N j :" |strat pL, jq| be the number of words of the j-th stratum for all j ě 1, there is a value C P N that is exponential in |A| such that, after having run for C ř i j"1 N j steps, the algorithm is done processing the i-th stratum. Note that this is weaker than processing each separate stratum in linear time: the algorithm can go faster to process some strata and spend this spared time later so that some later strata are processed arbitrarily slowly relative to their size.</p><p>If we can achieve amortized linear time, then the overall algorithm runs with bounded delay. To see why, notice that the prepared sequence for the i-th stratum has length at least its size N i , and we can show that the size N i`1 of the next stratum is within a factor of N i that only depends on L (this actually holds for any infinite regular language and does not use interchangeability): § Lemma 5.2. Letting C A :" pk `1q|Σ| `k`1 , for all i ě 1 we have</p><formula xml:id="formula_0">N i {C A ď N i`1 ď C A N i .</formula><p>Proof. Each word in the pi `1q-th stratum of L can be transformed into a word in the i-th stratum as follows: letting k be the number of DFA states, first remove a prefix of length at most `k to get a word (not necessarily in L) of length i ´k ´1, and then add back a prefix corresponding to some path of length ď k from the initial state to get a word in the i-th stratum of L as desired. Now, for any word w of the i-th stratum, the number of words of the pi `1q-th stratum that lead to w in this way is bounded by C A , by considering the reverse of this rewriting, i.e., all possible ways to rewrite w by removing a prefix of length at most k and then adding a prefix of length at most `k. A simple union bound gives N i`1 ď C A N i . Now, a similar argument in the other direction gives</p><formula xml:id="formula_1">N i {C A ď N i`1 .</formula><p>đ</p><p>Thanks to this lemma, it suffices to argue that we can process the strata in amortized linear time, preparing 3d-orderings for each stratum: enumerating these orderings in parallel with the first process thus guarantees (non-amortized) bounded delay.</p><p>Preparing the enumeration sequence. We now explain in more detail the working of the amortized linear time algorithm. The algorithm consists of two components. The first component runs in amortized linear time over the successive strata, and prepares a sequence Γ 1 , Γ 2 , . . . of concise graph representations of each stratum, called stratum graphs; for each i ě 1, after C ř i j"1 N j computation steps, it has finished preparing the i-th stratum graph Γ i in the sequence. The second component will run as soon as some stratum graph Γ i is finished: it reads the graph Γ i and computes a 3d-ordering for strat pL, iq in (non-amortized) linear-time, using Lemma 4.3. Let us formalize the notion of a stratum graph: § Definition 5.3. Let ∆ be the set of all push-pop edit scripts of length at most d; note that |∆| ď p2|Σ| `2q d`1 , and this bound only depends on the alphabet and on d. For i ě 1, the i-th stratum graph is the edge-labeled directed graph Γ i " pV i , η i q where the nodes V i " tv w | w P strat pL, iqu correspond to words of the i-th stratum, and the directed (labeled) edges are given by the function η i : V i ˆ∆ Ñ V i Y tKu and describe the possible scripts: for each v w P V i and each s P ∆, if the script s is applicable to w and the resulting word w 1 is in strat pL, iq then ηpv w , sq " v w 1 , otherwise ηpv w , sq " K.</p><p>In our machine model, each node v w of Γ i is a record with |∆| pointers, i.e., we do not store the word w. Hence, Γ i has linear size in N i .</p><p>A stratum graph sequence is an infinite sequence pΓ 1 , v s1 , v e1 q, pΓ 2 , v s2 , v e2 q, . . . consisting of the successive stratum graphs together with couples of nodes of these graphs such that, for all i ě 1, s i and e i are distinct words of the i-th stratum, and we have δ pp pe i , s i`1 q ď d.</p><p>We can now present the second component of our algorithm. Note that the algorithm runs on the in-memory representations of the stratum graphs, in which, e.g., the subscripts are not stored. § Proposition 5.4. For i ě 1, given the stratum graph Γ i and starting and ending nodes v si ‰ v ei of Γ i , we can compute in time Op|Γ i |q a sequence of edit scripts σ 1 , . . . , σ Ni´1 such that, letting s i " u 1 , . . . , u Ni be the successive results of applying σ 1 , . . . , σ Ni´1 starting with s i , then u 1 , . . . , u Ni is a 3d-ordering of strat pL, iq starting at s i and ending at e i .</p><p>Proof sketch. We apply the spanning tree enumeration technique from Lemma 4.3 (in Op|Γ i |q) on Γ i , starting with v si and ending with v ei , and read the scripts from the edge labels. đ</p><p>In the rest of the section we present the first component of our enumeration algorithm: § Proposition 5.5. There is an integer C P N exponential in |A| such that we can produce a stratum graph sequence pΓ 1 , v s1 , v e1 q, pΓ 2 , v s2 , v e2 q, . . . for L in amortized linear time, i.e., for each i ě 1, after having run C ř i j"1 N j steps, the algorithm is done preparing pΓ i , v si , v ei q.</p><p>Word DAGs. The algorithm to prove Proposition 5.5 will grow a large structure in memory, common to all strata, from which we can easily compute the pΓ i , v si , v ei q. We call this structure a word DAG. A word DAG is informally a representation of a collection of words, each of which has outgoing edges corresponding to the possible left and right push operations. § Definition 5.6. Let Λ :" tpushRpaq | a P Σu Y tpushLpaq | a P Σu be the set of labels corresponding to the possible left and right push operations. A pre-word DAG is an edgelabeled directed acyclic graph (DAG) G " pV, η, rootq where V is a set of anonymous vertices, root P V is the root, and η : V ˆΛ Ñ V Y tKu represents the labeled edges in the following way: for each node v P V and label s P Λ, if ηpv, sq ‰ K then v has one successor ηpv, sq for label s, and none otherwise. We impose:</p><p>The root has no incoming edges. All other nodes have exactly two incoming edges: one labeled <software>pushRpaq</software> for some a P Σ, the other labeled pushLpbq for some b P Σ. Each node stores two pointers leading to these two parents, which may be identical. All nodes can be reached from the root via at least one directed path. The root has one outgoing edge for each child, i.e., for all s P Λ, we have ηproot, sq ‰ K. The word represented by a directed path from the root to a node n is defined inductively: the word represented by the empty path is , the word represented by a path P, <software ContextAttributes="used">pushRpaq</software> is wa where w is the word represented by P , the word represented by a path P, <software ContextAttributes="used">pushLpaq</software> is aw where w is the word represented by P . The pre-word DAG G is called a word DAG if for each node n, all paths from root to n represent the same word. This word is then called the word represented by n.</p><p>Example pre-word DAGs and word DAGs are shown on Figures <ref type="figure" target="#fig_3">3</ref> and<ref type="figure">4</ref> in the appendix. In our machine model, each node is represented by a record; crucially, like for stratum graphs, the word that the node represents is not explicitly written.</p><p>Crucially, word DAGs do not us allow not to create two different nodes that represent the same word -these would be problematic since we have to enumerate without repetition. § Fact 5.7. There are no two different nodes in a word DAG that represent the same word.</p><p>We can then show the following theorem, intuitively saying that we can discover all the words of the language by only visiting words that are not too far from it: § Proposition 5.8. We can build a word DAG G representing the words of L in amortized linear time: specifically, for some value C that is exponential in |A|, for all i, after C ři j"1 N j computation steps, for each word w of Σ ˚whose push-pop distance to a word of Ť i j"1 strat pL, jq is no greater than d, then G contains a node that represents w. Moreover, there is also a value D exponential in |A| such that any node that is eventually created in the word DAG represents a word that is at push-pop distance at most D from a word of L.</p><p>Proof sketch. We progressively add nodes to a word DAG while efficiently preserving its properties, and thus avoid creating duplicate nodes. By labeling each node with the element of Q Y tKu achieved by the word represented by that node, and also by the distance to the closest known word of L, we can restrict the exploration to nodes corresponding to words that are close to the words of L, which ensures the amortized linear time bound. đ This is enough to prove Proposition 5.5: we run the algorithm of Proposition 5.8 and, whenever it has built a stratum, construct the stratum graph Γ i and nodes v si , v ei by exploring the relevant nodes of the word DAG. Full proofs are deferred to the appendix.</p></div>
<div><head n="6">Extensions</head><p>Complexity of determining the optimal distance. We have shown in Result 1 that, given a DFA A, we can compute in PTIME a minimal cardinality partition of LpAq into languages that are each d-orderable, for d " 48|A| 2 . However, we may achieve a smaller distance d if we increase the cardinality, e.g., a ˚`bbba ˚is p1, 3q-partition-orderable and not p1, dqpartition-orderable for d ă 3, but is p2, 1q-partition-orderable. This tradeoff between t and d seems difficult to characterize, and in fact it is NP-hard to determine if an input DFA is pt, dq-partition-orderable, already for fixed t, d and for finite languages. Indeed, there is a simple reduction pointed out in <ref type="bibr">[19]</ref> from the Hamiltonian path problem on grid graphs <ref type="bibr" target="#b12">[13]</ref>: § Proposition 6.1 <ref type="bibr">([19]</ref>). For any fixed t, d ě 1, it is NP-complete, given a DFA A with LpAq finite, to decide if LpAq is pt, dq-partition-orderable (with the push-pop or Levenshtein distance).</p></div>
<div><head>Push-pop-right distance.</head><p>A natural restriction of the push-pop distance would be to only allow editions at the right endpoint of the word, called the push-pop-right distance. A d-ordering for this distance witnesses that the words of the language can be produced successively while being stored in a stack, each word being produced after at most d edits.</p><p>Unlike the push-pop distance, one can show that some regular languages are not even partition-orderable for this distance, e.g., a ˚b˚i s not pt, dq-partition-orderable with any t, d P N. The enumerable regular languages for this distance in fact correspond to the well-known notion of slender languages. Recall that a regular language L is slender [20] if there is a bound C P N such that, for each n ě 0, we have |L X Σ n | ď C. It is known [20] that we can test in PTIME if an input DFA represents a slender language. Rephrasing Result 2 from the introduction, we can show that a regular language is enumerable for the push-pop-right distance if and only if it is slender; further, if it is, then we can tractably compute the optimal number t of sequences (by counting the number of different paths to loops in the automaton), and we can do the enumeration with bounded delay: § Theorem 6.2. Given a DFA A, the language LpAq is pt, dq-partition-orderable for the push-pop-right distance for some t, d P N if and only if LpAq is slender. Further, if LpAq is slender, we can compute in PTIME the smallest t such that LpAq is pt, dq-partition-orderable for some d P N for the push-pop-right distance.</p><p>In addition, there is an algorithm which, given a DFA A for which LpAq is slender and t " 1, enumerates the language LpAq with push-pop-right distance bound 2k and linear delay in |A|. Further, the sequence of edit scripts produced by the algorithm is ultimately periodic.</p><p>Of course, our results for the push-pop-right distance extend to the push-pop-left distance up to reversing the language, except for the complexity results because the reversal of the input DFA is generally no longer deterministic.</p></div>
<div><head n="7">Conclusion and future work</head><p>We have introduced the problem of ordering languages as sequences while bounding the maximal distance between successive words, and of enumerating these sequences with small edit scripts to achieve bounded delay. Our main result is a PTIME characterization of the regular languages that can be ordered in this sense for the push-pop distance (or equivalently the Levenshtein distance), for any specific number of sequences; and a bounded-delay enumeration algorithm for the orderable regular languages. Our characterization uses the number of classes of interchangeable states of a DFA A for the language, which, as our results imply, is an intrinsic parameter of LpAq, shared by all (trimmed) DFAs recognizing the same language. We do not know if this parameter can be of independent interest. Our work opens several questions for future research. The questions of orderability and enumerability can be studied for more general languages (e.g., context-free languages), other distances (in particular substitutions plus push-right operations, corresponding to the Hamming distance on a right-infinite tape), or other enumeration models (e.g., reusing factors of previous words). We also do not know the computational complexity, e.g., of optimizing the distance while allowing any finite number of threads, in particular for slender languages. Another complexity question is to understand if the bounded delay of our enumeration algorithm could be made polynomial in the input DFA rather than exponential, or what delay can be achieved if the input automaton is nondeterministic.</p></div>
<div><head>A Proofs for Section 2 (Preliminaries)</head></div>
<div><head>A.1 Necessity of unbounded memory</head><p>We substantiate the claim that in general it is necessary for the memory usage to grow indefinitely. First note that, if the memory usage is bounded by some constant, then it is clear that the enumeration is ultimately periodic: once the memory has reached its maximal number of records, as there are only finitely many possible graph structures of pointers and finitely many possible choices of data values (from a constant alphabet), then there are only finitely many possible states of the memory, so considering the algorithm as a function mapping one memory state to the next and optionally producing some values, this function must be eventually periodic, and so is the output. We show that, if the memory usage is bounded so that the sequence of edit scripts is ultimately periodic, then we can only achieve slender languages (c.f. Section 6 for the formal definition of slender languages). Hence, this is in general not sufficient (consider, e.g., pa `bq ˚, which is enumerable but not slender). § Proposition A.1. Let L be a language achieved by a sequence of edit scripts which is ultimately periodic. Then L is slender.</p><p>With regular languages, this proposition admits a converse: the regular slender languages can be achieved by unions of ultimately periodic sequences of edit scripts (see Proposition E.7 which shows it for one term of the union).</p><p>We now prove the proposition:</p><p>Proof of Proposition A.1. Consider the ultimately periodic suffix u of edit scripts, and let N be its length. Let ∆ be the difference in length between the size of the current word under construction between the beginning and end of an occurrence of ∆, and let M be a value such the length varies by at most M while reading u: specifically, if the length before reading u is N , then the length after reading u is N `∆ and the intermediate lengths are between N ´M and N `M . If ∆ ď 0, then the language is finite as the lengths of words visited during the rest of the enumeration when starting the periodic part at length N 0 is upper bounded by N 0 `M . Hence, it is in particular slender.</p><p>If ∆ ą 0, let us assume that we start the periodic part of the enumeration at a point where the current size of the word minus M is greater than any word size seen in the non-periodic part of the enumeration. Now, for any word length, we can only edit scripts producing words of this length for p2M `1q ˆ|u| steps, which is constant, so we can only produce a constant number of words of every length. This is the definition of a slender language, so we conclude. đ</p></div>
<div><head>A.2 Details about the machine model</head><p>We first elaborate on the standard notion of a pointer machine from <ref type="bibr">[25]</ref>. In this model, the memory consists of a finite but unbounded collection of records. Each record consists of a constant number of fields. The fields are either data values or pointers, and the number of possible data values is also constant. The machine can allocate records in constant time (retrieving a pointer to the new record), dereference a pointer in constant time to access a field of the corresponding record, test pointers for equality, and perform arbitrary operations on the data values (as there is only a constant set of possible values). However, no arithmetic operations involving pointers are permitted. In contrast with the RAM model, the pointer machine model makes it possible to work with memory that grows in an unbounded fashion, without worrying about how pointers are represented (they are assumed to take constant space) and how the memory is addressed.</p><p>We next clarify how we represent the automaton given as input to the algorithm. The automaton is given as a linked list of states, with a pointer to the initial state, and an indication on each state of whether it is final or not and a pointer to an adjacency list for this state. The adjacency list of a state q is again a linked list containing one element for each letter a of the alphabet Σ, in order. For each state q and letter a, the adjacency list item contains a pointer to an object representing the letter a, which the machine can use to output in constant time <software>pushLpaq</software> or <software ContextAttributes="used">pushRpaq</software> and a pointer to the target state of the transition (or an indication that the transition is undefined).</p></div>
<div><head>B</head><p>Proofs for Section 3 (Interchangeability partition and orderability lower bound) § Proposition 3.6. We can compute in polynomial time in A an interchangeability partition A 1 , . . . , A t of A, with t ď |A| the number of classes of interchangeable states.</p><p>To prove this result, we first show the auxiliary claim stated in the main text: § Claim 3.8. The language LpAq can be partitioned as NLpAq and LpA, C 1 q, . . . , LpA, C t q over the classes C 1 , . . . , C t of interchangeable states, and further NLpAq is finite.</p><p>Proof. We first show that these sets are pairwise disjoint. This is clear by definition for NLpAq and LpA, Cq for any class C of interchangeable states. Further, for C ‰ C 1 , we also have that LpA, Cq X LpA, C 1 q " H, because for any word w in their intersection, considering the accepting run of w, it must go via a loopable state q of C and a loopable state q 1 of C 1 , so this run witnesses that q and q 1 are connected, hence interchangeable, which would contradict the fact that C and C 1 are in different classes.</p><p>We next show both inclusions. By definition, a word of LpAq is either loopable, hence in some LpA, Cq, or non-loopable and in NLpAq. For the converse inclusion, by definition again all words of NLpAq and LpA, Cq for any class C are in LpAq.</p><p>Last, the fact that NLpAq is finite is because any non-loopable word w has length at most |A| ´1, because otherwise by the pigeonhole principle the same state q would appear twice in its accepting run, witnessing that q is loopable and contradicting the fact that w is non-loopable. Thus, there are finitely many words in NLpAq. đ</p><p>We are now ready to prove Proposition 3.6:</p><p>Proof of Proposition 3.6. Given the automaton A with state space Q, we first materialize in PTIME the connectivity and compatibility relations by naively testing every pair of states. Note that to test the compatibility of two states q and q 1 we build the automaton A q and A q 1 , build their intersection automaton by the product construction, and check for emptiness, which is doable in PTIME. We then materialize the interchangeability relation, and compute the classes C 1 , . . . , C t . Note that t ď |Q|.</p><p>The high-level argument is that we create one copy of A for each class C i , but ensure that only the first copy accepts the non-loopable words. For this, we need to duplicate the automaton in two copies, so as to keep track of whether the run has passed through a loopable state or not, and ensure that in all automata but the first, the states of the first copy (where we accept the non-loopable words) are non-final.</p><p>Formally, we modify A to a DFA A 1 by doing the following: the new state space is Q ˆt0, 1u, the final states are the pq, bq for q final in A and b P t0, 1u, the initial state is pq 0 , bq for q 0 the initial state of A and b being 1 if q 0 is loopable (which happens only when NLpAq " H) and 0 otherwise, and the transitions are:</p><p>For every q P Q and a P Σ such that δpq, aq is non-loopable, the transitions δppq, bq, aq " pδpq, aq, bq for all b P t0, 1u For every q P Q and a P Σ such that δpq, aq is loopable, the transitions δppq, bq, aq " pδpq, aq, 1q for all b P t0, 1u. We then trim A 1 . Note that if q 0 is loopable in A then this in fact removes all states of the form pq, 0q: indeed no such state is reachable from pq 0 , 1q, simply because there are no transitions from states with second component 1 to states with second component 0.</p><p>Clearly the DFA A 1 is such that LpA 1 q " LpAq. However, A 1 intuitively keeps track of whether a loopable state has been visited, as is reflected in the second component of the states. Further, the loopable states of A are in bijection with the loopable states of A 1 by the operation mapping a loopable state q of A to the state pq, 1q of A 1 . Indeed, pq, 1q is clearly a loopable state of A 1 , and this clearly describes the loopable states of A 1 with second component 1. Further, the states of A 1 with second component 0 are non-loopable because any loop involving such a state pq, 0q would witness a loop on the corresponding states of A, so that they would be loopable in A, and each transition of the loop in A 1 would then lead by definition to a state of the form pq 1 , 1q, which is impossible because no transition can then lead back to a state of the form pq 2 , 0q. Last, the interchangeability relationship on A 1 is the same as that relationship on A up to adding the second component with value 1, because all loopable states of A 1 all have that value in their second component as we explained, and the states and transitions with value 1 in the second component are isomorphic to A so the compatibility and connectivity relationships are the same.</p><p>We now compute copies A 1 , . . . , A t of the DFA A 1 , and modify them as follows: for each 1 ď i ď t, we remove from A i the states pq, 1q for each q in a class C j with j ‰ i. Further, for i ą 1, we make non-final all states with second component 0 (but leave these states final in A 1 ). This process is in polynomial time. Further, we claim that each A i is interchangeable. Indeed, its loopable states are precisely the loopable states of A that are in C i (up to adding the second component with value 1), because removing states from different classes does not change the loopable or non-loopable status of states in C i . Further, for any two loopable states q and q 1 of C i (modified to add the second component with value 1), the fact that they are interchangeable in A was witnessed by a sequence q " q 0 , . . . , q n " q 1 with q j and q j`1 being either connected or compatible in A for all 0 ď j ă n. Note that when two states q i and q i`1 are connected, then there is a sequence of loopable states q i " q 1 i,0 , . . . , q 1 i,ni where any two consecutive loopable states q 1 i,j and q 1 i,j`1 for 0 ď j ă n i are connected via a (directed) path consisting only of non-loopable states, which we call immediately connected. Hence, up to modifying the previous path to a longer path q " q 0 , . . . , q m " q 1 , we can assume that two successive loopable states q j and q j`1 with all 0 ď j ă n are either compatible or immediately connected. Now, the path witnesses that all q j for 0 ď j ď m are also in C i (up to adding the second component). Further, for any two loopable states in A that are compatible or immediately connected in A, this compatibility or immediate connectivity relation still holds when removing loopable states that are not in C i (up to adding the second component). Thus, the same path witnesses that the loopable states q and q 1 are still interchangeable in A i . This implies that indeed A i is interchangeable, as all its loopable states are in the same class, which is exactly C i (up to changing the second component).</p><p>It remains to show that LpA 1 q, . . . , LpA t q is a partition of LpAq. For this, we show that LpA 1 q " LpA, C 1 q Y NLpAq and LpA i q " LpA, C i q for i ą 1; this suffices to conclude by Claim 3.8.</p><p>We first show that LpA, C i q Ď LpA i q for 1 ď i ď t. This is because the accepting run of a word of LpA, C i q must go through a state of C i , and we have argued in the proof of Claim 3.8 that it does not use any state of C j for j ‰ i. Thus, we can build a corresponding path in A i , where the second component of each state is 0 until we reach the first state of C i in the accepting run, and 1 afterwards. Note that if the initial state is in C i then we defined the initial state of A 1 to have second component 1, so the path can start with second component one. In particular, letting q the final state reached in A by the accepting run, the corresponding run in A i reaches pq, 1q, which is final, and the word is accepted by A i .</p><p>We then show that NLpAq Ď LpA 1 q. This is because the accepting run of a non-loopable word of A goes only through non-loopable states, hence does not go through states of C j with j ‰ 1, hence we can reflect the accepting path in A 1 and reach a final state, witnessing that the word is accepted. Now, we show that LpA i q Ď LpA, C i q for i ą 1. This is because an accepting run for a word w of LpA i q must finish by a state of the form pq, 1q where q is final, as these are the only final states of A i . Thus, there is an accepting path for the word in A, and w P LpAq. Further, the construction of A 1 , hence of A i , guarantees that, if we reach a state with second component 1, then we have gone via a state pq, 1q with q loopable in A. The construction of A i further guarantees that this q must be in C i . Considering the accepting path of w in A, we see that this path goes through the state q, so that w P LpA, C i q.</p><p>Last, we show that LpA 1 q Ď LpA, C 1 q Y NLpAq. Considering a word w P LpA 1 q and its accepting run, there are two possibilities. Either the run ends at a state of the form pq, 1q, in which case the same reasoning as in the previous paragraph shows that w P LpA, C 1 q. Or the run ends at a state of the form pq, 0q. In this case, the construction of A 1 , hence of A 1 , guarantees that the entire accepting path only goes via states of the form pq 1 , 0q, so the corresponding run in A only goes via non-loopable states and w P NLpAq.</p><p>The claims that we established together with Claim 3.8 show that LpA 1 q, . . . , LpA t q is indeed a partition of LpAq, concluding the proof.</p><p>đ § Proposition 3.10. Letting C 1 , . . . , C t be the classes of A, for any distance d P N, there is a threshold l P N such that for any two words u P LpA, C i q and v P LpA, C j q with i ‰ j and |u| ě l and |v| ě l, we have δ Lev pu, vq ą d.</p><p>Proof. Fix the distance d P N, and let k be the number of states of the automaton A. We prove that the claim holds for the threshold l :" k ˆpkpd `1q `1q.</p><p>Assume by contradiction that there exist words u P LpA, C i q and v P LpA, C j q with i ‰ j such that |u| ě l, |v| ě l and δpu, vq ď d. By the pigeonhole principle, there must be a state q occurring in at least kpd `1q `1 positions in the accepting run for u, i.e., we can write u " hu 1 ¨¨¨u kpd`1q t for some h and t where each u i starts and ends at q. This implies in particular that q is loopable so it is in the class C i as explained in the proof of Claim 3.8.</p><p>As δpu, vq ď d, consider an arbitrary edit script that transforms u into v using at most d edit operations of the Levenshtein distance. Observe then that some contiguous sequence of k of the u j 's must be untouched by these edit operations. That is, we can write v " h 1 u i ¨¨¨u i`k´1 t 1 for some h 1 and t 1 . Now, by the pigeonhole principle again, in the accepting run of v, of the k `1 states at the endpoints of the u i , . . . , u i`k´1 , two must be the same, say q 1 . So we can write v " h 2 u l ¨¨¨u r t 2 for some h 2 and t 2 and i ď l ă r ď i `k ´1, where in the accepting run 0 1 2 3 4 5 of v we have the same state q 1 at the beginning and end of u l ¨¨¨u r . We know in particular that q 1 is loopable, so it is in C j , again using the argument in the proof of Claim 3.8. But now the word u l ¨¨¨u r is the label of a path in A from q 1 to q 1 as seen on the accepting run of v in the previous paragraph, and it is also the label of a path in A from q to q, as seen on the accepting run of u earlier. Thus, the states q and q 1 are compatible, and they are in the same class, which contradicts the fact that q and q 1 were in different classes. This concludes the proof. đ</p><formula xml:id="formula_2">1 1 2 1 3 1 4 1 5 1</formula><p>From Proposition 3.10, we can show Theorem 3.9:</p><p>Proof of Theorem 3.9. We proceed by contradiction and assume that LpAq is pt ´1, dqpartition-orderable for some bound d ą 0 on the Levenshtein distance, i.e., we have partitioned LpAq " Ů 1ďiďt´1 L i where each L i is d-orderable, i.e., has a d-sequence s i . Let l be the threshold given by Proposition 3.10, let l 1 be the maximal length of a non-loopable word in NLpAq, which is finite by Claim 3.8, and let l 2 " maxpl, l 1 q. There is some index p ą 0 such that, for all 1 ď i ď t ´1, all words of length ď l 2 of LpAq are only present in the initial prefix of length p of the s i , in particular this is the case of all non-loopable words. Now, as there are t ´1 d-sequences and t classes, and as the languages of each of the t classes are infinite, there must be a d-sequence which after point p contains infinitely many words from two different subsets LpA, C i q and LpA, C j q with i ‰ j. In particular, there must be an index p 1 ą p such that the p 1 -th word of s i is a word of LpA, C i q of length ą l 2 , hence ě l, and the pp 1 `1q-th word of s is a loopable word of LpAq also of length ě l 2 which is not in LpA, C i q, hence it is in some LpA, C k q with k ‰ i. However, we know by Proposition 3.10 that the words in LpA, C i q of length ě l are at Levenshtein distance ą d from the words of LpA, C k q of length ě l. This contradicts the fact that s i is a d-sequence, and concludes the proof.</p><p>We last substantiate the remark made in the main text that the proof still applies if we allow each word to be repeated some constant number C of times. The proof above works as-is, except that we now define p ą 0 to be the smallest index after which there are no longer any occurrences of any word of length ď l 2 in the remainder of all sequences s i : as there are only finitely many words occurring finitely many times, this is well-defined. The rest of the proof is unchanged. đ The result follows from the following claim on trees: § Lemma C.1 <ref type="bibr">([23, 14]</ref>). Let T be a tree, i.e., an acyclic connected undirected graph. Let s ‰ e be arbitrary nodes of T . We can compute in linear time in T a sequence s " n 1 , . . . , n m " e enumerating all nodes of T exactly once, starting and ending at s and e respectively, such that the distance between any two consecutive nodes is at most 3.</p></div>
<div><head>C</head><p>As we explained in the main text, Lemma C.1 was already shown independently by Sekanina and by <ref type="bibr">Karaganis [23,</ref><ref type="bibr" target="#b13">14]</ref>. However, we give our own algorithmic proof of this result, to emphasize the fact that the Hamiltonian path in question can be computed in linear time: we will need this fact in Section 5. Our algorithmic proof uses the method of exploring trees and enumerating nodes differently depending on the parity of their depth (see, e.g., <ref type="bibr">[26]</ref>). The same algorithm can be easily derived from the proof of <ref type="bibr" target="#b13">[14]</ref>, by turning the inductive argument into a recursive algorithm.</p><p>Optimality of the constant 3. Before giving our proof of Lemma C.1, we show that the value 3 in this lemma is optimal, as was claimed in the main text: § Claim C.2. There is an acyclic connected undirected graph T such that any sequence enumerating all nodes of T exactly once must contain a pair of vertices at distance ě 3.</p><p>Claim C.2 is implied by the results of [21] giving a (non-trivial) characterization of the trees for which it is possible to achieve a distance of 2 instead of 3. A slightly weaker result (applying to Hamiltonian cycles, corresponding in our setting to sequences that additionally have to start and end at vertices which are at distance ď 3) is also given as Exercise 4.1.19 b in <ref type="bibr" target="#b7">[8]</ref>. We again give a self-contained proof for convenience:</p><p>Proof of Claim C.2. Consider the tree pictured on Figure <ref type="figure" target="#fig_1">2</ref>, and some sequence n 1 , . . . , n 11 enumerating its nodes. Assume by contradiction that the sequence achieves a distance ď 2, i.e., all pairs of consecutive vertices in the sequence is at distance ď 2. Consider the vertices 1 1 , 2 1 , 3 1 , 4 1 , and 5 1 of the tree. The first and last position of the sequence may be covering at most two of these vertices, so there must be at least three of these values that occur at positions of the sequence which are not the first or last position. Without loss of generality, we assume up to symmetry that these are 1 1 , 2 1 , and 3 1 , occurring in this order, and we write l, m, r the positions where they occur in the sequence. In other words, we have n l " 1 1 , n m " 2 1 , and n r " 3 1 , for some positions 2 ď l ă m ă r ď 10. Now, given that n l " 1 1 and n m " 2 1 and the distance between 1 1 and 2 1 in the graph is four, we know that these values cannot be consecutive, i.e., we must have m ´l ě 2. For the same reason, we must have r ´m ě 2. From this, we deduce that the indices l ´1, l, l `1, r ´1, r, r `1 are pairwise distinct and are all indices in t1, . . . , 11u. Now, as n l " 1 1 , we know that the only possibility to respect the distance bound is that one of n l´1 , n l`1 is 0 and the other is 1. Likewise, one of n r´1 and n r`1 is 0 and the other is 3. As 0 occurs only once and the indexes are pairwise distinct, this is a contradiction. đ Now, to justify that the constant 3 is optimal, not only in Claim C.2, but also in Lemma 4.3, it suffices to notice that the tree used in the proof (Figure <ref type="figure" target="#fig_1">2</ref>) can be realized in the proof, with the push-pop distance or push-pop-right distance. Indeed, consider for instance the language L " t , a, aa, b, bb, c, cc, d, dd, e, eeu. This language is 1-connected, and the graph connecting the nodes at edit distance 1 in the push-pop or (equivalently) the push-pop-right distance is exactly the tree of Figure <ref type="figure" target="#fig_1">2</ref>, so while it has a 3-ordering we know that it cannot have a 2-ordering. For the Levenshtein distance, we replace by xxxx, replace a by axxxx and a 2 by a 2 xxxx, replace b by xbxxx and b 2 by xb 2 xxx, and so on. The language is 1-connected, and the graph connecting the nodes at distance 1 in the Levenshtein distance is again exactly the tree of Figure <ref type="figure" target="#fig_1">2</ref>. This is because no edit can insert, remove, or substitute an x (it would not give a word of the language because the number of x-es would not be correct); clearly the tree root is connected to its children (by an insertion) and each child to its respective child (by an insertion again); and no other connections are possible (in particular substitutions applied to words of the language never give a word of the language). Proving the result. We now prove Lemma C.1:</p><p>Proof of Lemma C.1. We root T at the starting node s, yielding a rooted tree where s is the root and e is an arbitrary node different from s. We call special the nodes in the unique path from s to e, including s and e. We order the children of each special node except e to ensure that their unique special child is the last child.</p><p>We first explain how to enumerate all nodes of T except e and its descendants, while obeying the distance requirement. To do this, we will handle differently the nodes depending on (the parity of) their depth in T . We will ensure that the enumeration starts at s, and ends:</p><p>If e is at even depth, then we finish at the parent of e.</p><p>If e is at odd depth and was the only child of its parent, then we finish at the parent of e.</p><p>If e is at odd depth and its parent has other children, then we finish at a sibling of e. To do this, we start processing at the root, where processing a node n means the following:</p><p>For nodes n at even depth (in particular n " s), no matter whether they are special or not, we process them in prefix order: enumerate n, then recursively processing their children in order.</p><p>For non-special nodes n at odd depth, we process them in postfix order: recursively processing their children in order, then enumerate n.</p><p>For special nodes n at odd depth, we process them in a kind of infix order: recursively process their children in order except the last (if any), then enumerate n, then recursively process their last child (which is again special, or is e). We finish this process when we recursively process e. Then it is clear that the enumeration starts at s, and visits all nodes of T except e and its children. We check that it finishes at the right node:</p><p>If e is at even depth, then its parent n was a node at odd depth which was special. We finished the enumeration by recursively processing n, processing all other children of n, then enumerating n, so indeed we finish at the parent of n.</p><p>If e is at odd depth, then its parent n was a node at even depth. We finished the enumeration by recursively processing n. Then there are two cases: If e was the only child of n, then the processing of n enumerated n and then recursed on e, so the claim is correct.</p><p>If e was one of the children of n, then it was the last child, so the processing of n enumerated n, then recursively processed all its other children, before recursively processing e. Now, the other children were non-special nodes at odd depth, so when we processed the last children, the enumeration finished by enumerating that other child, which is a sibling of e as claimed.</p><p>We then check that this enumeration respects the distance condition, by checking that any two consecutive nodes in this enumeration are at distance less than 3.</p><p>When we enumerate a node n at even depth, then we have just started to process it; let us study what comes after n. Either n has children or it does not:</p><p>If n has no children, then n is not the root s. Then the parent n 1 of n is a node at odd depth. Either it is special or non-special. If n 1 is non-special, then either n was the last child or not. If n was the last child, we next enumerate n 1 , so the distance is 1.</p><p>If n was not the last child, we next enumerate the next child of n 1 , which is at even depth and is not e, and the distance is 2. If n 1 is special, then n was not the last child because the last child of a special node different from e has children (as the special nodes are the nodes in the path from the root to e). Either n was the penultimate child or not. If it is not the penultimate child, then we next enumerate the next child of n 1 and the distance is 2. If it is the penultimate child, then we next enumerate n 1 and the distance is 1.</p><p>If n has children, then if its only child is e we have finished. Otherwise, we will produce another node. Specifically, we next recurse on the first child n 1 , which is not e, and either we first enumerate n 1 (if it has no children, or is a special node whose only child is e) and the distance is 1, or we enumerate the first child of n 1 (which is at even depth) and the distance is 2. When we enumerate a node n at odd depth which is non-special, then we have just finished processing it. Then its parent n 1 was at even depth. Either n was the last child of n 1 or not:</p><p>If n was the last child of n 1 , we go back to the parent n 2 of n 1 , which is at odd depth.</p><p>If n 1 was the last child of n 2 , we enumerate n 2 , at distance 2. If n 1 was not the last child of n 2 but was its last non-special child, then n 2 itself is special and we next enumerate n 2 , at distance 2 (before recursing in the special child). Last, if the next sibling of n 1 is non-special, then from n 2 we recurse into it (it is at even depth) and enumerate it, for a distance of 3.</p><p>If n was not the last child of n 1 , then we next recurse in the next child n 2 , which is at odd depth. If n 2 has no other children, or if its only child is special, we next produce n 2 for a distance of 2. Otherwise we recurse in the first child of n 2 , which is at even depth, and produce it for a distance of 3. When we enumerate a node n at odd depth which is special, then we are about to recurse in its special child. Either it is e and we have finished, or it is a node at even depth and we enumerate it for a distance of 1.</p><p>Hence, in all cases the distance within that first part of the enumeration is at most 3.</p><p>We now explain how to enumerate the remaining nodes, i.e., the subtree of T rooted at e, including e. For this, we consider the depth of the nodes from the parent of e, i.e., e is now considered at odd depth, its children (if they exist) are at even depth, and so on. We re-do the previously described enumeration scheme on that subtree, except that there are no special nodes. It is clear that this defines an enumeration sequence which visits the entire subtree, ends at e (as it is at odd depth), and respects the distance bound from the previous proof. (More specifically, considering a subtree of T rooted at a non-special node n at odd depth in the previous proof, when we started processing that subtree, the enumeration clearly covered all its nodes, finished at n, respected the distance bound, and there were no special nodes in that subtree, so this shows that correctness also holds when applying that scheme on the subtree rooted at e.)</p><p>Hence, the last point to show is that the distance between the last node of the first part of the enumeration and the first node of the second part of the enumeration is at most 3. Now, the first part ended either at the parent of e or a sibling of e, i.e., at distance 2 to e. Now, the second phase of the enumeration starts on e at odd depth, so either e was in fact a leaf and we enumerate it for a distance 2, or we recurse on the first child of e, which is now at even depth, and enumerate it, for a total distance of 3. Hence, the entire enumeration respects the distance bound of 3. This concludes the proof.</p><p>đ for all i ě 2, and such that s i ‰ e i for all i ě 2 and δ pp pe i , s i`1 q ď d. We will show that such a ladder exists, which will suffice to show that L is 3d-orderable. Indeed, because each p , dq-stratum is d-connected, we know by Lemma 4.3 that there exists a 3d-ordering s 1 of strat pL, 1q that ends at e 1 (and starts at an arbitrary word of strat pL, 1q), and also, for i ě 2, that there exists a 3d-ordering s i of strat pL, iq that starts at s i and ends at e i . Now, the order s 0 s 1 . . . is clearly a 3d-order of L.</p><formula xml:id="formula_3">Last</formula><p>Hence, let us show that a ladder exists. As L is infinite, we know that the DFA A has a loopable state q. Let rz be a word of q such that z is the label of a simple loop on a loopable state on q: by the pigeonhole principle, we can ensure |rz| ď k 1 . Now, using the fact that the DFA is trimmed, let t be a word such that rt is accepted: we can ensure |t| ă k 1 . Now consider the sequence of words w i :" rz i t for all i ě 0, which are all accepted. By definition the length difference between w i and w i`1 is at most k 1 for each i ě 0, and the push-pop distance between them is at most 3k 1 , as evidenced by popping right t and pushing right zt; so it is ď d.</p><p>We now observe that, as ě 2k 1 , each stratum contains at least two distinct w i : in particular the rt and rzt are words of the first stratum because their length is strictly less than 2k 1 . For each stratum i ě 1, we choose s i to be the shortest w j such that w j is in strat pL, iq, and choose e i to be the longest such w j . Thus, e i ‰ s i for all i ě 2, and δ pp pe i , s i`1 q ď d for all i ě 1. We have thus defined a ladder, which as we argued concludes the proof. đ</p></div>
<div><head>C.3 Proof of Proposition 4.7</head><p>We now prove the main technical result of this section, namely: § Proposition 4.7. The language LpAq is p8k 2 , 16k 2 q-stratum-connected.</p><p>We let p , dq :" p8k 2 , 16k 2 q. We show this result in the remainder of the appendix. If LpAq is finite, then clearly it consists only of words of length ď k, so the first stratum is trivially d-connected because d ě 2k and the other strata are empty, hence vacuously d-connected.</p><p>Thus, in the sequel, we assume that LpAq is infinite, in particular it contains infinitely many loopable words.</p><p>To show that LpAq is d-stratum connected, take i ě 1 and let us show that the i-th -stratum S " strat pLpAq, iq is d-connected. This will indeed be enough by Lemma 4.6. In the rest of the proof we only work with the language S, so d-sequences, d-connectivity between words, always require that the words of the sequences are in S.</p><p>Let us first take care of the non-loopable words, and show that each non-loopable word is at distance ď d from a loopable word of S. For this, taking a non-loopable word w, we know from the proof of Claim 3.8 that |w| ď k ´1. From the definition of (specifically, since ě k ´1), we know that we are in the first stratum, i.e., i " 1. As d ě 2k, we can simply edit w into a loopable word by first removing all letters of w, then adding all letters of some loopable word of length at most k ´1, which must exist because LpAq is infinite and we can simply choose any word whose accepting path goes via some loopable state and does not go twice through the same state.</p><p>We will now show the result statement: any two words u and v of S are d-connected. By what we showed, we can assume that u and v are loopable.</p><p>It will often be necessary to adjust our constructions depending on the length of a word w P S, because when modifying w we wish to ensure that it remains in S, in particular that it has the right length. So we will call a word w P S short if it is in the lower half of the stratum, and long otherwise. Formally, considering a word w 1 of S, we know that its length is pi ´1q ˆ8k 2 ď |w 1 | ă i ˆ8k 2 , i.e., p2i ´2q ˆ4k 2 ď |w 1 | ă 2i ˆ4k 2 : we call valid a word satisfying this condition on length, so that a word is in S iff it is valid and is accepted by A. Now, we call w 1 short if p2i ´2q ˆ4k 2 ď |w 1 | ă p2i ´1q ˆ4k 2 and long if p2i ´1q ˆ4k 2 ď |w 1 | ă 2i ˆ4k 2 . This ensures that increasing the length of a short word by at most k 2 , or by at most 4k, gives a valid word (which may be long or short); and likewise decreasing the length of a long word by at most k 2 or by at most 4k gives a valid word (which may also be long or short). Further the definition ensures that ě 7k, which we will use at some point as a bound on the size of the first stratum.</p><p>We will first show that all loopable words of S are d-connected to loopable words of S of a specific form, where, up to a prefix and suffix whose length only depends on the language, the words consists of a power of a word which labels a loop on some loopable state (on which we must impose a length bound). We will apply this to loops of length at most k 2 , because of our choice of . § Lemma C.3. Let w be a loopable word of S, let q be a loopable state that occurs in the run of w, let e be the label of a loop on q, i.e., a non-empty word of LpA q q, such that |e| ď k 2 . Then w is d-connected to some word se n t with |s| ď k and |t| ď k.</p><p>To show the lemma, we will first show that we can "move" the latest occurrence of q near the end of the word by making edits of length at most 2k. To this end, we define the q-measure of a word w 1 and a state q occurring in w 1 as the smallest possible length of t 1 when writing w 1 " r 1 t 1 such that q is reached between r 1 and t 1 . We then claim: § Claim C.4. Any loopable word w of S where some loopable state q occurs is 2k-connected to some word w 1 of q-measure ď k.</p><p>Proof. We show the claim by induction on the measure of w. The base case is when the measure is ď k, in which case the result is immediate. So let us show the induction claim: given w with measure ą k, we will show that it is 2k-connected to some word (in S) with strictly smaller measure. Note that we can assume that |w| ě k, as otherwise its measure is ă k.</p><p>Intuitively, we want to de-pump a simple loop in the suffix of length k to decrease the measure, but if the word is short we first want to make it long by pumping some loop as close to the beginning as possible. So the first step is to make w long if it is short, and then the second step is to decrease the measure (potentially making the word short again) and conclude by induction hypothesis.</p><p>The first step works by repeating the following process, which does not increase the measure. Formally, as w contains a loopable state and the non-loopable states occur at most once, we can write w " ρτ with the length |ρ| of ρ being minimal (in particular ď k) such that the state between ρ and τ is loopable. Let σ be a simple loop on q, i.e., σ P LpA q qzt u. Observe that then |ρσ| ď k. By pumping, we know that ρστ is accepted by A. We obtain ρστ by editing w " ρτ in the following way: we pop left elements of ρ, i.e., at most k edits, then push ρσ, i.e., at most k edits. Note that, writing the original w as s 1 t 1 with q reached between s 1 and t 1 and |s 1 | being maximal, the modification described here modifies a prefix of the word which is no longer than s 1 , and makes s 1 longer (thus making w longer). Repeating this process thus gives us a word w 1 which is no longer short, and where the measure is unchanged because σ was added on the first occurrence of a loopable state, hence on or before the last occurrence of q. As we enlarge the word at each step by at most |σ| ď k, and stop it when the word is no longer short, the definition of being short ensures that the eventual result w 1 of this process is not too big, i.e., w 1 is still valid; and w is 2k-connected to it. Now, the second step on a word w 1 which is long is to make the measure decrease. For this, we simply write w 1 " r 1 t 1 with |t 1 | the measure of w 1 . If |t 1 | ď k, we conclude by the base case. Otherwise, by the pigeonhole principle, we can find two occurrences of the same state in the run within the suffix t 1 ; we write w 1 " ρστ with |στ | ď k as small as possible (i.e., we take the first occurrence of a repeated state when reading the run from right to left) such that some state q 1 occurs between ρ and σ and between σ and τ . Note that q 1 ‰ q, otherwise we would have concluded by the base case. By depumping, we know that ρτ is accepted by the automaton, and as q ‰ q 1 it has strictly smaller q-measure. We obtain ρτ from w 1 " ρστ in a similar way to that of the previous paragraph: we pop right elements of στ , i.e., at most k edits, then we push right the elements of τ , i.e., at most k edits. The length of the resulting word is decreased by σ, i.e., by at most k, so the definition of being long ensures that the resulting word is in S. Thus, we know that w 1 , hence w is 2k-connected to a word of S with smaller q-measure. We conclude by the induction hypothesis that w is 2k-connected to a word with q-measure ď k, which concludes the proof. đ</p><p>With this claim, we can show Lemma C.3:</p><p>Proof of Lemma C.3. Fix the word w and the loopable state q. By Claim C.4, we know that w is 2k-connected to a word w 1 of S with w 1 " r 1 t 1 , |t 1 | ď k, and q is achieved between r 1 and t 1 . Fix e the label of the loop to achieve. We will intuitively repeat two operations, starting with the word w 1 , depending on whether the current word is long or short, with each word obtained being a word of S that is at distance ď d from the previous one. We stop the process as soon as we obtain a word of the desired form.</p><p>If the current word is short, we add a copy of e just before t 1 , by popping t 1 and then pushing et 1 . This takes 2k `|e| operations, which is ď d because |e| ď k 2 , and we know that the result is accepted by the automaton. Further, as the length increased by |e| and |e| ď k 2 , the definition of ensures that the word is still in S (but it may be long).</p><p>If the current word is long, we make it shorter by editing the left endpoint. Formally, as a long word has length ě k, we can write w 1 " ρτ with |ρ| ď k, and furthermore ρ does not overlap the copies of e that have been inserted so far, otherwise the word would already be of the desired form. By the pigeonhole principle, there is a state q 1 occurring twice in ρ, i.e., we can write ρ " ρ 1 σρ 2 , such that ρ 1 ρ 2 τ is accepted by the automaton, and by taking q 1 to be the first such state we can have |ρ 1 σ| ď k. We can obtain ρ 1 ρ 2 τ from w 1 by popping left ρ 1 σ and pushing left ρ 1 , i.e., at most 2k operations. Further, as the length decreased by at most k, the definition of ensures that the word is still in S (but it may be short).</p><p>It is clear that repeating this process enlarges a factor of the form e i inside the word (specifically, the word ends with e i t with i increasing), while the word remains in S, so we will eventually obtain a word of S of the form se n t with |s| ď k and |t| ď k to which the word w 1 , hence the original word w, is d-connected. This establishes the claimed result. đ Now that we have established Lemma C.3, we have a kind of "normal form" for words, i.e., we will always be able to enforce that form on the words that we consider.</p><p>Let u and v be two loopable words, and let p and q be any loopable states reached in the accepting run of u and v respectively. We know that the automaton A is interchangeable, so p and q are interchangeable, and there exists a sequence p " q 0 , . . . , q h " q witnessing this, with any two successive q i and q i`1 for 1 ď i ă h being either connected or compatible. We show that u and v are d-connected by induction on the value h.</p><p>Base case h " 0. The base case is h " 0, i.e., p " q. In this case, let e be an arbitrary non-empty word in A q of length ď k. We know by applying Lemma C.3 to u that u is d-connected to a word of the form u 1 " se n t with |s| ď k and |t| ď k, and by applying the lemma to v we know that v is d-connected to a word of the form v 1 " xe m y with |x| ď k and |y| ď k. We now claim the following, to be reused later: § Claim C.5. Consider words of S of the form u 1 " su 2 t and v 1 " xv 2 y with |s| ď k and |t| ď k and |x| ď k and |y| ď k and u 2 and v 2 both being powers of some word λ. Then δ pp pu 1 , v 1 q ď `8k.</p><p>Proof. First note that, because u 2 and v 2 are powers of a common word, we have δ pp pu 2 , v 2 q " ||u 2 | ´|v 2 ||, simply by making their length equal by adding or removing powers of λ. Now, the distance from u 1 to v 1 is at most |s| `|t| `|x| `|y| `||u 2 | ´|v 2 ||, by popping s and t, then making the length of the middle parts u 2 and v 2 equal via the previous observation, then pushing x and y. As the two words u 1 and v 1 are in S, their length difference is at most , i.e., ||u Now, applying Claim C.5 to our u 1 and v 1 with λ " e, we know that δ pp pu 1 , v 1 q ď `8k, so the distance is at most d because d ě `8k. This shows that u 1 and v 1 , hence u and v, are d-connected, establishing the base case h " 0.</p><p>Base case h " 1. We show a second base case, with h " 1, which will make the induction case trivial afterwards. In this case, u and v respectively contain loopable states q and q 1 which are either connected or compatible. We deal with each case separately.</p><p>Base case h " 1 with two connected states. if q and q 1 are connected, it means that there is path from q to q 1 in the automaton, or vice-versa. We assume that there is a path from q to q 1 , otherwise the argument is symmetric up to exchanging u and v. Up to making this path simple, let π be the label of such a path in the automaton, with |π| ď k, and let π 1 be the label of a simple path in the automaton from q 1 to some final state; hence |ππ 1 | ď 2k. Let e be a non-empty word of length ď k accepted by A q . We know by Lemma C.3 that u is d-connected to a word of the form u 1 " se n t with |s| ď k and |t| ď k and q occurring before and after each occurrence of e. Intuitively, we want to replace t by ππ 1 , to obtain a word to which u 1 is d-connected and which goes through q 1 , so that we can apply the first base case h " 0, but the subtlety is that doing this could make us leave the stratum S. We adjust for this by adding or removing occurrences of e to achieve the right length. Formally, if u 1 ď 5k then because ě 5k we know that u 1 is in the first stratum and that se n ππ 1 has length at most 7k, so as ě 7k and d ě 3k we know that u 1 is d-connected to u 2 " se n ππ 1 which is in S. Otherwise, we assume that u 1 ě 5k, so that e n ě 3k. There are three subcases: either</p><formula xml:id="formula_4">|t| " |ππ 1 |, or |t| ă |ππ 1 |, or |t| ą |ππ 1 |.</formula><p>In the first subcase where |t| " |ππ 1 |, then we know that u 1 is 3k-connected to the word u 2 " se n ππ 1 , which is accepted by A and is in S because |u 1 | " |u 2 |. In the second subcase where |t| ă |ππ 1 |, if u 1 is short then we conclude like in the previous subcase, using the fact that |u 1 | ď |u 2 | ď |u 1 | `2k so u 2 is in S by the definition of . If u 1 is long then we can choose some number η such that 2k ď |e η | ď 3k, which is possible because |e| ď k. Now we know that from u 1 we can obtain the word se n´η ππ 1 , which is well-defined because e n ě 3k so n ě η, is accepted by A, and has length at most |u 1 | and at least |u 1 | ´|e η |, i.e., length at least |u 1 | ´3k, so it is still in S by the definition of . In the third subcase where |t| ą |ππ 1 |, if u 1 is long then we conclude like in the first subcase because 1 is short then we choose some number η like in the second subcase, and obtain from u 1 the word se n`η ππ 1 , which is accepted by A, is longer than u 1 , and has length at most |u 1 | `3k so is still in S.</p><formula xml:id="formula_5">|u 1 | ´k ď |u 2 | ď |u 1 |, so u 2 is in S. If u</formula><p>In all three subcases we have shown that u 1 is d-connected to a word u 2 in S whose accepting path goes through q 1 because u 2 finishes by ππ 1 and the state immediately before was q so π brings us to q 1 . By the base case h " 0, we know that u 2 and v, whose accepting runs both include the state q 1 , are d-connected.</p><p>Base case h " 1 with two compatible states. Second, if q and q 1 are compatible, we know that there is some non-empty witnessing word z which is both in A q and in A q 1 . Up to taking a simple path in the product of these two automata, we can choose z to have length ď k 2 . By Lemma C.3, we know that u is d-connected to a word u 1 " sz n t with |s| ď k and |t| ď k and q at the beginning and end of every occurrence of z. Likewise, applying the lemma to v, we know that v is d-connected to a word v 1 " xz m y with |x| ď k and |y| ď k and q at the beginning and end of every occurrence of z. We now conclude like in the base case h " 0, by applying Claim C.5 with λ " z. Induction case. Let u and v be two loopable words, and p and q be loopable states respectively occurring in the accepting run of u and of v, and consider a sequence p " q 0 , . . . , q h " q witnessing this, with h ě 1. Let w be any word of S whose accepting path goes via the state q h´1 , which must exist, e.g., taking some path in the automaton that goes via q h´1 and then repeating some loop of size ď k on the loopable state q h´1 . By applying the induction hypothesis, we know that u is d-connected to w. By applying the case h " 1, we know that w is d-connected to v. Thus, u is d-connected to v. This shows the claim, and concludes the induction, proving Proposition 4.7.</p></div>
<div><head>D Proofs for Section 5 (Bounded-delay enumeration) D.1 Details on the machine model</head><p>Throughout Section 5, we phrase our algorithms in a slight variant of the pointer machine model presented in Section 2 and Appendix A.2. The modification is that the number of fields of records, and the number of possible data values, is no longer constant, but is allowed to depend on the input automaton, specifically it can be exponential in the input automaton. This allows us to talk, e.g., of records whose fields are indexed by edit scripts of constant length, or of data values denoting integers that are exponential in the automaton; and to allow arbitrary arithmetics on these. However, crucially, the number of fields and the data values do not depend on the current length of words when we enumerate, or on the current memory size. Intuitively, as our enumeration algorithm generally runs indefinitely, the unbounded memory size will eventually be much larger than the exponential quantity on the input used to bound the number of fields and the number of data values; and our use of a pointer machine model means that the resulting pointers cannot be used for arithmetic operations.</p><p>Let us now explain why this difference in our definition of the pointer machine model is in fact inessential. For any number x, it is easy to see that a pointer machine allowing x fields per pointer and x different data values can be emulated by a pointer machine in the standard sense presented in Section 2, e.g., which allows only 2 fields per pointer and 2 different data values. Indeed, the x different data values can be coded, e.g., in unary as linked lists of length up to x, and records with x fields can be coded as a linked list of records, each of which contains one data field and one continuation field pointing to the next record. Operations on data values can be emulated by a hardcoded program that allocates a new linked list whose length is a function of the length of the two other lists, and accessing a field of a record can be emulated by a hardcoded program that follows the linked lists of records to retrieve the correct field. The overhead induced by the emulation is a multiplicative factor in the number x. Now, recall that our goal in Section 5 is to show Theorem 5.1, which claims an exponential delay in the input automaton. Thus, we can work in the modified pointer machine model where the quantity x is exponential in the input automaton, because the resulting algorithm can be emulated by an algorithm on a pointer machine model in the standard sense, multiplying only by an exponential factor in the automaton, and yielding an overall complexity which is still exponential in the automaton.</p></div>
<div><head>D.2 Second component: Proof of Proposition 5.4</head><p>In this section we give the proofs for our bounded-delay enumeration algorithm (Theorem 5.1). We start by presenting in more details what we called the second component of the amortized linear time algorithm, namely: § Proposition 5.4. For i ě 1, given the stratum graph Γ i and starting and ending nodes v si ‰ v ei of Γ i , we can compute in time Op|Γ i |q a sequence of edit scripts σ 1 , . . . , σ Ni´1 such that, letting s i " u 1 , . . . , u Ni be the successive results of applying σ 1 , . . . , σ Ni´1 starting with s i , then u 1 , . . . , u Ni is a 3d-ordering of strat pL, iq starting at s i and ending at e i .</p><p>Proof. First, observe that by Proposition 4.7, the undirected graph corresponding to Γ i is connected. We then compute in linear time in Γ i a spanning tree T of Γ i : this can indeed be done in linear time in our pointer machine model using any standard linear-time algorithm for computing spanning trees, e.g., following a DFS exploration, with the stack of the DFS being implemented as a linked list. Notice that, importantly, the number of edges of Γ i , hence its size, is linear in N i , since all nodes have bounded degree (namely, exponential in |A|).</p><p>Next, we apply the enumeration technique described in the proof of Lemma C.1 on the tree T and starting node v si and exit node v ei , which yields a sequence v si " n 1 , . . . , n |Ni| " v ei enumerating all nodes of T exactly once, and where the distance between any two consecutive nodes (in T ) is at most 3. The traversal can easily be implemented by a recursive algorithm: we prepare an output doubly linked list containing the nodes to enumerate, and when we enumerate a node in the algorithm, we append it to the end of this linked list, so that, at the end of the algorithm, the 3-ordering of the nodes of the graph is stored in that linked list.</p><p>We must simply justify that the recursive algorithm can indeed be implemented in our machine model. For this, we store the recursion stack in a linked list. To make this explicit, we can say that the stack contains two kinds of pairs, where n is a node of T : pexplore, nq, meaning "call the exploration function on node n"; and penumerate, nq, meaning "append n to the output linked list". Initially, the stack contains only pexplore, v si q for v si the root of T . At each step, we pop the first pair of the stack and do what it says, namely:</p><p>If it is pexplore, nq, we call the exploration function on n; If it is penumerate, nq, we append n to the output list; If the stack is empty, the exploration is finished. The recursive exploration function can then be implemented as follows:</p><p>When we explore a node n that is at even depth, we push at the beginning of the recursion stack the following list of elements in order: penumerate, nq, pexplore, n 1 1 q, . . ., pexplore, n 1 m q for n 1 1 , . . . , n 1 m the children of n; When we explore a node n at odd depth that is not special, we push at the beginning of the recursion stack the following list of elements in order: pexplore, n 1 1 q, . . ., pexplore, n 1 m q, penumerate, nq for n 1  1 , . . . , n 1 m the children of n; When we explore a node n at odd depth that is special and has ě 1 children n 1  1 . . . n 1 m , we push at the beginning of the recursion stack the following list in order: pexplore, n 1 1 q, . . ., pexplore, n 1 m´1 q, penumerate, nq, pexplore, n 1 m q. Once we have the sequence v si " n 1 , . . . , n |Ni| " v ei produced in the output doubly linked list, the last step is to compute in linear time the sequence σ 1 , . . . , σ Ni´1 of edit scripts. We determine each edit script by reading the edge labels of Γ i ; formally, to determine σ j , we simply re-explore Γ i from n j at distance 3, which is in time exponential in |A|, and when we find n j`1 we concatenate the labels of the (directed) edges of Γ i that lead from n j to n j`1 . This indeed gives us what we wanted and concludes the proof. đ</p></div>
<div><head>D.3 First component: Proof of Proposition 5.5</head><p>In the rest of this appendix, we will present the formal details of the first component of our enumeration algorithm, that is: § Proposition 5.5. There is an integer C P N exponential in |A| such that we can produce a stratum graph sequence pΓ 1 , v s1 , v e1 q, pΓ 2 , v s2 , v e2 q, . . . for L in amortized linear time, i.e., for each i ě 1, after having run C ř i j"1 N j steps, the algorithm is done preparing pΓ i , v si , v ei q.</p><p>To show Proposition 5.5, we first prove Fact 5.7: The labels pushL and pushR are abbreviated for legibility. In the left pre-word DAG, the four paths to the top node that start to the left of the root all represent the word baa, whereas the four paths to that same node that start to the right of the root all represent the word bba. In the right pre-word DAG, the left topmost node represents ab and bb and the right topmost node represents aa and ba. The criteria of word DAGs, and our construction to enlarge them, are designed to prevent these problems. </p></div>
<div><head>Rpaq Lpaq</head><p>Figure <ref type="figure">4</ref> An example word DAG. We annotate the nodes with the word that they represent, even though in the memory representation the nodes are anonymous and the words are not represented. The labels pushL and pushR are abbreviated for legibility. § Fact 5.7. There are no two different nodes in a word DAG that represent the same word.</p><p>Proof. Let us write G " pV, η, rootq. Assume by way of contradiction that some word w is represented by two distinct nodes n 1 ‰ n 2 of the word DAG, and take |w| to be minimal. Then w cannot be the empty word because root is the only node reachable by a empty path from root, so that n 1 ‰ root and n 2 ‰ root. Thus, we can write w as w " aw 1 for a P Σ. Now, consider the <software>pushLpaq</software>-predecessors n 1  1 and n 1 2 of n 1 and n 2 , respectively (which must exist because n 1 and n 2 are not root). Then, taking any path from root to n 1 1 (resp., to n 1 2 ) and continuing it to a path to n 1 (resp., to n 2 ), we know that n 1 (resp., n 2 ) must represent w 1 . As |w 1 | ă |w|, by minimality of w, we must have n 1  1 " n 1 2 . But then this node has two distinct successors n 1 and n 2 for the same label <software ContextAttributes="used">pushLpaq</software>, a contradiction. đ</p><p>We then prove Proposition 5.8, whose statement we recall here: § Proposition 5.8. We can build a word DAG G representing the words of L in amortized linear time: specifically, for some value C that is exponential in |A|, for all i, after C ři j"1 N j computation steps, for each word w of Σ ˚whose push-pop distance to a word of Ť i j"1 strat pL, jq is no greater than d, then G contains a node that represents w. Moreover, there is also a value D exponential in |A| such that any node that is eventually created in the word DAG represents a word that is at push-pop distance at most D from a word of L.</p><p>At a high level, we will prove Proposition 5.8 by first explaining how to enlarge word DAGs, which would allow us to use them to represent all words of Σ ˚; and then explaining how we can specifically build them to efficiently reach the words that are close to L.</p><p>But before doing so, we first make two simple observations about word DAGs that will be useful for the rest of the proof. Here is the first one: § Claim D.1. In a word DAG, we cannot have a node n with edges <software>pushLpaq</software> and pushRpbq to the same node n 1 with a ‰ b.</p><p>Proof. Letting v be the word captured by n, the node n 1 would witness that we have av " vb. This equation is clearly unsatisfiable as a ‰ b so the number of occurrences of a and b in the left-hand-side and right-hand-side are clearly different. đ</p><p>Our second observation is that we can have a node n with edges <software>pushLpaq</software> and <software ContextAttributes="used">pushRpaq</software> to the same node n 1 , but this happens if and only if n (and therefore n 1 ) captures a word of the form a i for some i ě 0: § Claim D.2. If a node n has edges <software ContextAttributes="used">pushLpaq</software> and <software ContextAttributes="used">pushRpaq</software> to the same node n 1 , then n (and therefore n 1 ) capture a power of a.</p><p>Proof. Letting v the word captured by n, the node n 1 witnesses that we have av " va. We show by induction on length that v " a i . The base case is trivial for a length of 0, and for a length of 1 indeed the only solution is a. For the induction, if we have a solution of length n `1, then it starts and ends with a, i.e., it is of the form av 2 a with v 2 of length n ´1. Injecting this in the equation, we get a 2 v 2 a " av 2 a 2 , and simplifying av 2 " v 2 a, i.e., v 2 satisfies the same equation. By induction hypothesis we have v 2 " a n´1 , and then v " a n`1 , establishing the induction case and concluding the proof. đ</p><p>We are ready to explain how we enlarge word DAGs. Enlarging a word DAG. We will start from the initial word DAG, which we define to be the word DAG whose nodes are trootu Y tv a | a P Σu and where each v a is both the <software ContextAttributes="used">pushRpaq</software> and the <software ContextAttributes="used">pushLpaq</software>-successor of root for all a P Σ. For instance, the initial word DAG for alphabet Σ " ta, b, cu is shown in Figure <ref type="figure" target="#fig_5">5</ref>. It is clear that this is indeed a word DAG. § Definition D.3. Given a word DAG G and a node n of G, we say that n is complete if it has 2|Σ| outgoing edges; and incomplete otherwise.</p><p>For instance, the root of the initial word DAG is complete, but its children are not. We next explain how to complete an incomplete node. § Definition D.4. For a node n of G which is incomplete, we define the completion G Ò n of G on n as follows.</p><p>First, for each label <software ContextAttributes="used">pushLpaq</software> with a P Σ for which n has no outgoing edge, we do what follows, which is illustrated in Figure <ref type="figure" target="#fig_6">6</ref> for different cases. We consider the successive strict ancestors n 1 , . . . , n m of n for labels of the form pushRpbq for b P Σ which do not have an <software ContextAttributes="used">pushLpaq</software>-successor (there may be none, in which case m " 0). We also consider n m`1 the closest ancestor of n via labels of the form pushRpbq that has a <software ContextAttributes="used">pushLpaq</software> child, and call this child n 1 m`1 . Notice that n m`1 is well-defined (because the root has a successor for each label). Notice further that if m ě 1 then n m is a pushRpbq-child of n m`1 , and if m " 0 then n itself is the pushRpbq-child of n m`1 . We let pushRpb 1 q, . . . , pushRpb m q, pushRpb m`1 q be the labels of the edges to n, n 1 , . . . , n m along this path.</p><p>We then create <software ContextAttributes="used">pushLpaq</software>-successors n 1 1 , . . . , n 1 m of n 1 , . . . , n m respectively, and set the other predecessor of each of them to be, respectively, n 2 with label pushRpb 2 q, . . ., n 1 m`1 with label pushRpb m`1 q, We call these newly created nodes pillar nodes. Then we create a new node n 1 , and set it as the <software ContextAttributes="used">pushLpaq</software>-successor of n and the pushRpb 1 q-successor of n 1  1 . Note that, in the case where n 1  1 " n (which can only happen when m " 0 and b 1 " a by Claim D.1), we handle two labels at once, i.e., we set n 1 as the <software ContextAttributes="used">pushLpaq</software>-and <software ContextAttributes="used">pushRpaq</software>-child of n as illustrated in Figure <ref type="figure" target="#fig_6">6c</ref>.</p><p>Second, for each label <software>pushRpaq</software> with a P Σ for which n has no outgoing edge, we do the corresponding operation on a path of labels of the form pushLpbq, exchanging the role of the two kinds of labels.</p><p>Thus, when completing an incomplete node n, two types of nodes are added to the word DAG: children of n, and pillar nodes (possibly for several labels). Further, notice that during this process, it is possible that another node has been completed; for instance, this could happen to n 1  1 from Figure <ref type="figure" target="#fig_6">6c</ref>. We prove next that this completion procedure does not break the properties of word DAGs, and moreover that it can be performed in linear time with respect to the number of newly created nodes (including pillar nodes). Note that the number of pillar nodes created may be arbitrarily large, and it is the reason why the complexity in Proposition 5.8 is</p><formula xml:id="formula_6">n 3 n 2 n 1 n n 1 n 1 3 n 1 2 n 1 1 Rpb 3 q Rpb 2 q Rpb 1 q Lpaq Lpaq Lpaq Lpaq Rpb 3 q Rpb 2 q</formula><p>Rpb 1 q (a) Case m " 2 and a ‰ b1. The pillar nodes are n 1 2 and n 1 1 .</p><formula xml:id="formula_7">n 1 n n 1 n 1 1 Rpb 1 q Lpaq Lpaq Rpb 1 q (b) Case m " 0 and a ‰ b1.</formula><p>There is no pillar node.</p><formula xml:id="formula_8">n 1 n n 1</formula></div>
<div><head>Rpaq Lpaq</head><p>Lpaq Rpaq (c) Case m " 0 and a " b1.</p><p>There is no pillar node. stated as amortized linear time. We do not see a way to avoid this, as the existence of all predecessors of a node seems crucial to continue the construction and ensure that we do not create multiple nodes for the same word (i.e., that we respect the properties of word DAGs).</p><p>Let us show these results: § Lemma D.5. For any word DAG G and incomplete node n of G, then G Ò n is a word DAG. Further, G Ò n has at least one additional node, and the running time to build it is proportional to the number of new nodes that are created.</p><p>Proof. We claim that the result is still a pre-word DAG. First, by definition all newly created nodes have exactly two parents, one with a label of the form <software>pushLpaq</software> and one with a label of the form pushRpbq for some a, b P Σ. Further, everything is still reachable from the root, and the root is obviously still complete. Hence G Ò n is indeed a pre-word DAG.</p><p>We show next that it is also a word DAG, by checking that this holds after each step where we handle one missing outgoing label on n, say <software>pushLpaq</software>. Since all new paths in the word DAG after the operation end on one of the new nodes, it suffices to check that every new node represents only one word. But it is clear by construction that any path from the root to a new node must go through one of the nodes n 1 m`1 , n m , . . . , n 1 , n, which therefore all capture a unique word. Specifically, letting w be the word captured by n m`1 , we know that n 1 m`1 captures aw, that n m captures wb m`1 , ..., that n 1 captures wb m`1 ¨¨¨b 2 , and n captures wb m`1 ¨¨¨b 1 , and the words captured by the new nodes are then defined in the expected way.</p><p>The claim about the running time is immediate, noting that the node was asserted to be incomplete so there is at least one successor to create. đ</p><p>Hence, one could in principle build the successive strata of L by starting from the initial word DAG, keeping a FIFO queue (e.g., as a linked list) of the nodes that are still incomplete, and progressively enlarging the word DAG with this operation, thus eventually reaching all words of Σ ˚. The problem with this naive exploration strategy is that, for most languages, it will not yield the amortized linear time bound that we wanted. This is simply because the strata of our language L can be much smaller than those of Σ ˚.</p><p>For this reason, we explain next how to guide the construction of the word DAG to only reach words that are at bounded push-pop distance from words of the language.</p><p>From now on, to alleviate notation, we will often identify the nodes of the word DAG with the words that they represent -but we recall that the words are not really written in the nodes of the word DAG, in particular algorithms on word DAGs do not consider them.</p><p>Word DAGs for our regular language L. Intuitively, we would like to be able to efficiently decide if a node n of the word DAG that we are building represents a word that is in the language L " LpAq or not. Indeed, informally, if we could do this, as we know that every stratum is d-connected by Proposition 4.7 and has words that are close to words of adjacent strata, it would be enough to only enlarge the word DAG by exploring the d-neighborhood of words in L.</p><p>To do this, for each node n of G, letting w be the word represented by n, we will annotate n by the state q that is reached in the partial run of w from the initial state of A (or by K if this state is undefined). We can annotate the newly created nodes efficiently when we enlarge a word DAG: for instance, if we have a <software>pushRpaq</software>-successor n 1 of n in the word DAG, then we could simply annotate q 1 by δpq, aq. The same situation does not work if n 1 is a <software ContextAttributes="used">pushLpaq</software>-successor, but we will always be able to define the annotation of new nodes by following the pushR-transitions from states with a known annotation.</p><p>We will also annotate each node of the word DAG by the distance to the closest word of the language that is in the word DAG, if this distance is ă d, or by 8 otherwise. Moreover, for a technical reason that will become clear later, we will also annotate every node of the word DAG with the modulo of its depth, i.e., the length of the unique word that the node represents. Note that these values are all bounded by an exponential function of the input, so they can be represented in our machine model. We formalize this next. § Definition D.6. An A-word DAG is a word DAG where each node n is additionally annotated with:</p><p>An element of Q Y tKu, called the state annotation; An integer in t0, . . . , d ´1u Y t8u, called the distance annotation; An integer in t0, . . . , ´1u, called the modulo annotation. We then additionally require that:</p><p>The state annotation represents the state that is reached by reading w in A, where w is the word represented by n (and K if we do not reach any state). For every node n, letting i be the shortest distance of an undirected path between n and a node representing a word of the language, the integer labeling n is i if i ă d and 8 otherwise.</p><p>For every node n, letting w be the word that it represents, then the modulo annotation of n is congruent with |w| modulo . We say that a node is successful if m corresponds to a word accepted by the automaton, i.e., it is labeled by a final state. Equivalently, its distance annotation is then 0.</p><p>The initial A-word DAG is defined in the expected way by annotating the initial word DAG with the correct elements. We show that these new annotations can be maintained when we complete a node, in linear time in the number of newly created nodes: § Lemma D.7. If G is an A-word DAG, for an incomplete node n, we can extend G to an A-word DAG also denoted G Ò n consisting of the word DAG G Ò n and correctly updating the annotations. The running time is again proportional in the number of created nodes (recall that A and d and are fixed).</p><p>Note that the state annotation and modulo annotation will be assigned once when a node is created and never modified afterwards, whereas the distance annotation can be modified after the node is created, if we later discover a new word of L sufficiently close to the node. We prove the lemma:</p><p>Proof of Lemma D.7. For the state annotation, we consider two cases, depending on whether the missing outgoing edge of node n that we are completing was a <software ContextAttributes="used">pushRpaq</software>-or a pushLpaqsuccessor. If it was a <software ContextAttributes="used">pushRpaq</software> successor, then all newly created nodes have a pushRpaqpredecessor that was already in the A-word DAG before the operation so we can easily determine their annotation by looking at the transition function of A. If it was a pushLpaqsuccessor (the case of Figure <ref type="figure" target="#fig_6">6</ref>), then we can determine the state annotation of each new node by starting from the state annotation of node n 1 m`1 from the construction (which was in the A-word DAG before the operation), again by simply reading the transition function of A. This can clearly be done in linear time in the number of created nodes.</p><p>It is clear how to compute the modulo annotation of each newly created node, counting from the modulo annotation of the expanded node, modulo .</p><p>Next, we update the distance annotations. These distance annotations only need to be updated on the nodes of the word DAG that are within a distance ă d of the newly created nodes, so we recompute them there: for every new node, we explore its neighborhood in the word DAG up to a distance of d ´1 and update the distances of nodes in that neighborhood.</p><p>For the running time claim, we use the fact that the degree of the word DAG is at most 2|Σ| `2, so the neighborhood at distance d ´1 of any node in G is of size exponential in |A|, namely, it has size ď ř d´1 j"0 p2|Σ| `2q j ď p2|Σ| `2q d . If we create N nodes, updating the distances is thus done in linear time in N . đ</p><p>We are now ready to describe the exploration algorithm of Proposition 5.8.</p></div>
<div><head>Initialization.</head><p>First expand the initial A-word DAG by increasing length until the incomplete nodes are exactly the nodes representing words of Σ ˚of length , so that all words of Σ ˚of length ď are in the A-word DAG. This can be done in time exponential in |A| as there are ď |Σ| `1 such words. Then prepare a set of empty FIFO queues B 0 , . . . , B ´1, each being implemented as a doubly linked list in our machine model. Also initialize an empty buffer B as a linked list, and fill this buffer by adding a pointer to all the nodes of the word DAG that are incomplete (their depth is ) and whose distance annotation is ă 8. Also add for each such node a pointer to its (unique) occurrence in B.</p><p>Intuitively, all queues B j and the buffer B will hold (nodes corresponding to) words that are incomplete and whose distance annotation is ă d. Moreover, each B j will hold nodes whose length is j modulo , and the buffer B will also hold words whose length is 0 modulo (intuitively corresponding to the nodes of the next strata). This is indeed true after the initialization step, and we will prove that this will always hold, since the algorithm will continue as follows:</p></div>
<div><head>Indefinitely repeat the following operation:</head><p>If one of the queues B j is not empty, consider the smallest j such that B j is not empty, pop a node n from B j and expand it, i.e., build the A-word DAG G Ò n. When creating new nodes with this operation, if their (updated) distance annotation is ă 8 (i.e., ă d), then: if the newly created node n 1 is a child of the node n, then, letting t be the modulo annotation of n 1 , we put n 1 into the queue B t if j ă ´1 and into the buffer B otherwise (i.e., if j " ´1); if the newly created node n 1 is a pillar node then we put n 1 in queue B t where t is its modulo annotation. Notice that all newly created nodes are incomplete by construction. Similarly, when updating the distance annotation of nodes that already existed, if they are incomplete and their updated distance goes from 8 to ă d then we put them in queue B i where i is their modulo annotation. Whenever we add a node to one of the lists or to the buffer, we also add in the node a pointer to its occurrence in this list/buffer. Moreover, when we make a node complete, either by expanding it or by attaching new edges to it when completing another node (which can be detected in the construction), we remove this node from the queue it was in (if any), using the pointer to find this occurrence. All of this can be performed in time exponential in |A|, for each new node added during this expansion step. If all queues B j are empty, then transfer all elements of the buffer B to the queue B 0 (in a constant number of operations as we work with linked lists). This ends the description of the algorithm. Next we analyse it.</p><p>We define the 1st phase of the algorithm as the initialization phase, and for i ě 2, we define the i-th phase to be the i ´1-th execution of the above while loop. During the i-th phase, we intuitively enlarge the word DAG with words of the i-th stratum, plus possibly some words of lower strata because of pillar nodes.</p><p>We now show that this algorithm meets the requirements of Proposition 5.8. To this end, we first show that the algorithm only discovers nodes that are sufficiently close to words of the language, i.e., it does not "waste time" materializing nodes that are too far away and will not yield words of the language. In other words, we first show the claim corresponding to the last sentence of Proposition 5.8. This is clear for the children of nodes that we expand: when we expand a node n, its distance is ă d, so its new children n 1 will be at distance ď d. However, the expansion may create an unbounded number of pillar nodes and we have a priori no distance bound on these. Fortunately, these nodes in fact represent factors of the word represented by n 1 . Thus, we show that the distance bound on n 1 extends to give a weaker distance bound on these nodes: § Lemma D.8. For any word w of length ě 2d at push-pop distance ď d to a word of L, for any factor w 1 of w, then w 1 is at push-pop distance ď 6d to a word of L.</p><p>Note that the distance bound in this result is weaker than what is used in the algorithm to decide which nodes to expand, i.e., the distance is ď 6d and not ď d. So the pillar nodes may have distance annotation 8. Still, the weaker bound will imply (in the next proposition) that all words created in the word DAG obey some distance bound.</p><p>We can now prove the lemma:</p><p>Proof of Lemma D.8. As |w| ě 2d, we can write w " sut with |s|, |t| ě d. Moreover, any word v at push-pop distance ď d from w can be written as v " ρuτ with |ρ|, |τ | ď 2d. Take v to be such a word in L, which exists by hypothesis. Now, the factor w 1 of w is either a factor of u, or may include parts of s and/or of t. But in all cases we can write it w 1 " s 1 u 1 t 1 with |s 1 |, |t 1 | ď d and u 1 a factor of u. Now, by considering the accepting run of v and the occurrence of u 1 inside, considering the states q l and q r before and after this occurrence of u 1 in the accepting run, we know we can take words ρ 1 leading from the initial state to q l and τ 1 from q r to a final state, having length ď |Q| ď d, so that v 1 " ρ 1 u 1 τ 1 is a word of L. But then observe that w 1 " s 1 u 1 t 1 is at push-pop distance at most 6d from v 1 " ρ 1 u 1 τ 1 : we can pop left s 1 (at most d), push left ρ 1 (at most 2d), pop right t 1 (at most d) and then push right τ 1 (at most 2d). This concludes since v 1 is in L. đ</p><p>This allows us to show that indeed, all words that will eventually be discovered by the algorithm are within some bounded distance of a word of the language. Formally: § Proposition D.9. There is a value D exponential in |A| such that any (node corresponding to a) word w that is added to the word DAG at some point is at push-pop distance at most D from a word of the language. Proof. To account for initialization phase, let D 1 be the maximal push-pop distance of a word (of Σ ˚) of length ă 2d to a word of the language. Now, let D :" maxpD 1 , 6dq, and let us show that this value of D is suitable.</p><p>Let w be a word that is discovered by the algorithm. If |w| ă 2d then we are done by our choice of D 1 , so assume |w| ď 2d. This implies that w has been discovered during some i-th phase for i ě 2 (since the initialization phase only discovers words of size ď and d " 2 ). Now, at the moment where w was discovered, there are two cases. The first case is when w was created as a child of a node w 1 that we have expanded, hence whose annotation was ă d, so w itself is at distance at most d, hence at most D, from a word of the language. The second case is when w is was created as an ancestor of a child of a node w 2 that has been expanded (i.e., w is a pillar node), hence a factor of w 2 : then Lemma D.8 applies because w 2 is at push-pop distance at most d of a word of the language by the same reasoning and moreover we have |w 2 | ě |w| since w 2 is a factor of w, and since |w| ě 2d by hypothesis we have indeed |w 2 | ě 2d, so our choice of D works. đ</p><p>Notice that Proposition D.9 would hold no matter in which order we expand incomplete nodes of the word DAG.</p><p>Next, we show that, thanks to our exploration strategy, the algorithm discovers all words of the language, stratum by stratum. The proof is more involved. We start by proving the property that we informally mentioned after describing the initialization step of the algorithm. § Claim D.10. For all i ě 1, all the words in the word DAG that are discovered before or during the i-th phase have length ď i . Moreover, during the i-th phase, each queue B j only ever contains words whose length is ď i ´1 and is j modulo , and the buffer B only ever contains words whose length is 0 modulo .</p></div>
<div><head>Proof. By induction on i.</head><p>Case i " 1. This is trivially true for the 1st phase (the initialization phase).</p><p>Case i ą 1. By induction hypothesis, at the beginning of the i-th phase the word DAG only contains nodes of size ď pi ´1q , hence ď i . Moreover, considering the last step of the pi ´1q-th phase, we see that B 0 only contains words of size pi ´1q , and this is allowed. Now, let n 1 , n 2 , . . . be the words that are discovered during the i-th phase of the algorithm, considering that, e.g., when we expand a node n for some missing <software>pushRpaq</software>-label, we first "discover" its <software ContextAttributes="used">pushRpaq</software>-child, and then discover the pillar nodes (if any) in descending order. Then we show the following claim by induction on j: (‹) [the node n j has size ď i and, if at some point we add it to some queue B t then its size is ď i ´1 and is t modulo and if we add it to B its size is 0 modulo ]. This is clear of the first word that we discover: indeed, n 1 is a child of the very first node that we popped from B 0 to expand, so the size of n 1 is exactly pi ´1q `1 and, since its modulo annotation is then 1, the only queue to which we could ever add it is B 1 and pi ´1q `1 ď i ´1 indeed as ě 2. Let now n j`1 be the pj `1q-th word discovered during the first phase and assume p‹q to hold for all previously discovered nodes of that phase. We first show that |n j`1 | ď i . Consider indeed the moment that this node was discovered: it was either the child of some node n ρ for ρ ď j that we expanded, or it was a pillar node of some node n ρ that we expanded. Since p‹q is true for n ρ and since we never expand nodes of the buffer B during a phase, it follows that indeed |n j`1 | ď i . We next show the claim on the queues/buffer. Observe then that the only problematic case is if we add n j`1 to the queue B 0 and |n j`1 | " i ; indeed, it is clear that when we add a node to some queue its modulo is correct with respect to that queue, so the only constraint that could be violated is that |n j`1 | ď i ´1. So let us assume that |n j`1 | " i by way of contradiction. But then, considering again how we have discovered n j`1 , we see that the only possibility is that it is a child of some node n ρ that we have expanded (n j`1 cannot be a pillar node because all nodes n j 1 with j 1 ď j have size ď i and we defined that in the discovering order we discover children of expanded nodes before their pillars), but then by induction hypothesis n ρ must have been popped from the B ´1 queue and then the algorithm must have added n j`1 into B and not into B 0 . This concludes the proof. đ</p><p>Next, we observe that every word of the pi `1q-th stratum can be obtained from some word of the i-th stratum by a specific sequence of at most d push-pop edits. This claim is reminiscent of the proof of Lemma 4.6, where we showed the existence of so-called ladders. Let us formally state the result that we need: § Claim D.11. For any i ě 1, for any word w of strat pL, i `1q, there is a word w 1 P strat pL, iq with push-pop distance at most d to w and that can be built from w as follows: first remove a prefix of length at most `|Q| to get a word w 2 (not necessarily in L) of length exactly i ´|Q| ´1, and then add back a prefix corresponding to some path of length ď |Q| from the initial state to get w as desired.</p><p>Proof. The prefix removal and substitution is simply by replacing a prefix of an accepting run with some simple path from the initial state that leads to the same state: note that the exact same argument was already used in the proof of Lemma 5.2. The fact that w 1 can be chosen to have length exactly i ´|Q| ´1 is simply because ě |Q|. For the distance bound, notice that `2|Q| ď d. đ</p><p>These observations allow us to show that the algorithm discovers all words of the language, stratum by stratum: § Proposition D.12. For i ě 1, at the end of the i-th phase, the algorithm has discovered all words of Ť i j"1 strat pL, jq.</p><p>Proof. We show this by induction on i.</p><p>Case i " 1. This is trivially true for the initialization step. Case i ą 1. By induction hypothesis we know that the algorithm has discovered all words of Ť i´1 j"1 strat pL, jq. So, let w P strat pL, iq and we show that the algorithm will discover w during the i-th phase, which would conclude the proof. By Claim D.11 there is a word w 1 P strat pL, i ´1q such that δ pp pw, w 1 q ď d and that can be transformed into w by first popping-left a prefix of size at most |Q|, obtaining a word w 2 whose size is exactly pi ´1q ´|Q| ´1, and then pushing-left a prefix of size at most `|Q| to obtain w. Thus, let us write w " w 2 a 1 . . . a t with a j P Σ and t ď `|Q|. Now, by induction hypothesis, the algorithm has discovered w 1 during the pi ´1q-th phase, and by the properties of a word DAG the word w 2 is stored at a node which is an ancestor of w 1 and has also been discovered. Crucially, notice that thanks to its size, w 2 is actually in the pi ´1q-th stratum of L. Now, this means that, at some point of the i´1-th phase, the algorithm has discovered w 2 . Hence, at some point during the pi ´1q-th phase, the algorithm has already discovered both w 1 and w 2 , and in fact all nodes in some simple path from w 1 to w 2 . But then at that point, the distance annotation of w 2 was ă d, since it is then at distance ď |Q| ă d in the word DAG from w 1 . Thus, during the i ´1-th phase, all children of w 2 , and all its descendants up to a depth of |Q| `1, must have been created, because 2|Q| `1 ă d, and then the prefix w 2 a 1 . . . a |Q|`1 of w of length pi ´1q was added to the buffer B, and then in queue B 0 at the end of that phase. We now show that all longer prefixes of w, i.e., all prefixes of w which are of the form w 2 a 1 . . . a |Q|`1 a |Q|`1`1 ¨¨¨a t , including w itself, were discovered. We know that the prefix w 2 a 1 . . . a |Q|`1 was discovered and put in the buffer B for the pi ´1q-th phase. Now, during the i-th phase, we have also completed this node w 2 a 1 . . . a |Q|`1 , and its descendants up to depth , because again, `2|Q| ď d. Thus, indeed w was discovered, which concludes the proof. đ</p><p>We point out that, when we are at the i-th phase, we can create arbitrarily long paths of pillar nodes during a single expansion operation, including nodes representing words having length ă pi ´1q . However, the above Proposition implies that no such node can represent a word of the language, because all the words of L of the pi ´1q-th stratum have already been discovered.</p><p>The last ingredient to show Proposition 5.8 is then to prove that by the end of the pi`2q-th phase, the algorithm has discovered all words whose push-pop distance to a word of the first i-th strata is no greater than d. Formally: § Proposition D.13. For all i ě 1, by the end of the pi `2q-th phase, the algorithm has discovered all words of Σ ˚whose push-pop distance to a word of the i first strata is no greater than d.</p><p>Proof. We know by Proposition D.12 that by the end of the i-th phase (hence by the end of the pi `2q-th phase) the algorithm has discovered all words of Ť i j"1 strat pL, jq. Let w be a word that is at distance d from some word w 1 of Ť i j"1 strat pL, jq, and let us show that the algorithm discovers it by the end of the pi `2q-th phase. We show it by induction on t :" δ pp pw, w 1 q. If t " 0 then w " w 1 and we are done. For the inductive case let t ą 1 and assume this is true for all j ď t. As δ pp pw, w 1 q " t, there is a sequence of t push/pop operations that transform w into w 1 . Let w 2 be the word just before w that this sequence defines. By induction hypothesis we will have discovered w 2 by the end of the pi `2q-th phase. But then observe that |w 2 | ď pi `2q ´2 because d ď 2 . But then it is clear that we will also discover w by the end of the pi `2q-th phase, because w 2 will be made complete before the end of the pi `2q-th phase. Indeed, the distance annotation of w 2 is ă d as witnessed by w 1 . Further, we have |w 2 | ď |w 1 | `d, and as d " 2 and |w 1 | ă i , we have w 2 ă pi `2q , so indeed we will complete it before the pi `2q-th phase concludes. đ</p><p>We are now equipped to prove Proposition 5.8, which claims that the word DAG construction is in amortized linear time and that all created nodes are within some bounded distance to words of the language (keeping in mind that the latter was already established in Proposition D.9): Proof of Proposition 5.8. By Proposition D.13 and Proposition D.9, it is enough to show that there is a value C exponential in |A| such that for all i ě 1, after C ˆři j"1 N i , the algorithm has finished the pi `2q-th phase. Consider then the point P in the execution of the algorithm where it has finished the pi `2q-th phase, and let us find out how much time this has taken. By Claim D.10 at P the algorithm has not discovered any word of length ą pi `2q . Moreover, we know by Proposition D.9 that all the words represented by the nodes added to the word DAG are within some bounded push-pop distance D from words of the language. Note that it could be the case that the witnessing words of the language are not yet discovered, in particular that there are in higher strata. However, we can let K " rD{ s, and then we know that any word discovered is at distance at most D from a word of the first i `2 `K strata.</p><p>Letting as usual N i be the size of the i-th -stratum of L, we then have that the algorithm has discovered at most ř i`2`K j"1 p2|Σ| `2q D N j nodes. Moreover, for C A the bound from Lemma 5.2, we have for all i the inequality N i`1 ď C A N i , so that we can bound the number of discovered nodes at follows: and because each stratum is d-connected, we know that we will see every node that corresponds to a word of the i-th stratum. So the linked list stores all nodes of the i-th stratum. These form the vertices of Γ i . For each node n in the list corresponding to a word w, we do an exploration of all the (not necessarily simple) undirected paths of length ď d that start from n in the word DAG, where we remember the edit script corresponding to the current path (i.e., each time we traverse an edge in the forward direction we append its operation to the script; each time we traverse an edge pushL or pushR in the reverse direction we append popL and popR respectively to the script). We consider all marked nodes seen in this exploration, and add edges from the vertex for w in Γ i to these other nodes with the label of these edges being the edit script of the corresponding path. By p‹q, this indeed builds all the edges of Γ i . This process takes total time proportional in N i , because d only depends on the language and the degree of the word DAG also only depends on the language. Last, we pick our starting and ending vertices for the current stratum i. Knowing the ending point v ei´1 of the pi ´1q-th stratum, we know that there was some word of the current stratum at distance ď d of v ei´1 , so we explore from v ei´1 in the word DAG and find a witnessing node, which we pick as starting node v si . For the ending node of the i-th stratum, we consider all nodes of strat pL, iq again and explore all possible edit scripts for them to check if there is a node of the next stratum at distance ď d; we know that this must succeed by Claim D.11. We pick any one of them as v ei Last, we unmark all the nodes that we had previously marked in the word DAG, again in linear time in the size of the current stratum. This indeed computes in linear time the stratum graph Γ i . The amortized linear time bound for this whole algorithm can then be shown using the same reasoning as in the proof of the amortized linear time bound for Proposition 5.8. đ</p><p>Finally we show our bounded-delay enumerability result (Theorem 5.1):</p><p>Proof of Theorem 5.1. As we have already explained in Section 5, we simply have to combine the two components of our enumeration algorithm: let us call A the algorithm from Proposition 5.5 with K A the value in its amortized linear time complexity (called C in the statement), and B that of Proposition 5.4, with K B the value in its (non-amortized) linear time complexity (i.e., for each i it runs in time K B |Γ i |). Last, let C A be the value from Lemma 5.2. We first show that there is an algorithm C that produces the sequences of edit scripts (and stores them in a FIFO implemented as a double-ended linked list, to be read later) in amortized linear time, i.e., for some K C , for all i ě 1, after K C ř i j"1 N i computation steps, the algorithm C has produced a sequence of edit scripts corresponding to all the words of the first ď i strata. To do this we simply start algorithm A, and whenever it has produced pΓ i , v si , v ei q we pause A and run algorithm B on it, resuming A afterwards. Notice that the size |Γ i | of Γ i is ď C S N i for some value C S exponential in |A|. This is because the nodes of Γ i correspond to words of the i-th strata and its degree is bounded by definition. Then it is clear that after a number of computation steps</p><formula xml:id="formula_9">K A ř i j"1 N i `ři j"1 K B C S N i " pK A `KB C S q ř i j"</formula><p>1 N i we have indeed computed the sequence of edit scripts for strata ď i, so we can take K C :" K A `KB C S .</p><p>Our bounded-delay algorithm C 1 to enumerate LpAq is then as follows:</p><p>We initialize by launching C until it has produced the sequence of edit scripts for the first stratum. We store the sequence of edit scripts in a FIFO. Then, we continue the execution of C to produce the rest of the sequence of edit scripts at the end of the FIFO. However, every E :" p1 `CA qK C steps of C, we output one edit script from the prepared sequence, i.e., from the beginning of the FIFO. We know that the edit script sequence thus produced is correct (it is the one produced by C), and that algorithm C 1 has bounded delay (namely, delay E `E1 for E 1 the constant time needed to read one edit script from the FIFO and output it), but the only point to show is that we never try to pop from the FIFO at a point when it is empty, i.e., we never "run out" of prepared edit scripts.</p><p>To see why this is true, we know that C adds edit script sequences to the FIFO for each stratum, i.e., once we have concluded the computation of the i-th stratum graph Γ i and the execution of algorithm B over Γ i , we add precisely N i edit scripts to the FIFO. So it suffices to show that, for any i, the FIFO does not run out after we have enumerated the edit scripts for the strata 1, . . . , i. Formally, we must show that for any i ě 1, after we have popped ř i j"1 N j edit scripts from the FIFO, then algorithm C must have already added to the FIFO the edit scripts for the pi `1q-th stratum. We know that the time needed for algorithm C to finish processing the pi `1q-th stratum is at most Proof. Our proof will show NP-hardness both for the push-pop distance and for the Levenshtein distance (both problems being a priori incomparable). We denote the distance by δ.</p><formula xml:id="formula_10">K C ř i`1 1 N i , which by Lemma 5.2 is ď K C ř i j"1 N j `CA N i ď E ř i j"1 N j . Now,</formula><p>The membership in NP is immediate as a witnessing t-tuple of edit script sequences has polynomial size. Recall that a grid graph is a finite node-induced subgraph of the infinite grid. Fix the integers d ě 1 and t ě 1. We work on the alphabet Σ " ta, bu. We reduce from the Hamiltonian path problem on grid graphs, which is NP-hard <ref type="bibr" target="#b12">[13]</ref>. Given a grid graph G, letting n be its number of vertices, we assume without loss of generality that G is connected, as otherwise it trivially does not have a Hamiltonian path. Hence, up to renormalizing, we can see each vertex of G as a pair pi, jq such that two vertices pi, jq and pi 1 , j 1 q are adjacent if and only if |i ´i1 | `|j ´j1 | " 1, with 0 ď i, j ď n. (Indeed, if some node is labeled p0, 0q and the graph is connected, then any vertex must have values pi, jq with i `j ď n.)</p><p>We code G as a set of words of size polynomial in G defined as follows: for each vertex pi, jq we have the word n pi,jq :" a di b d`1 a dj . Let L 1 be the language of these words. Then, let L be L 1 with the set of t ´1 words b pj`1qpd`1q for 1 ď j ď t ´1. This coding is in polynomial time, and we can obtain from L 1 a DFA recognizing it in polynomial time.</p><p>Let us show that the reduction is correct. For this, let us first observe that L is pt, dqenumerable iff L 1 is p1, dq-enumerable. Indeed, if L 1 is p1, dq-enumerable then we enumerate L by adding one singleton sequence for each of the t ´1 words of LzL 1 . Conversely, if L is pt, dq-enumerable then as the words of L 1 zL are at distance ą d from one another on from the words of L 1 (as each edit can only change the number of b's by one), then each of the t ´1 words of L 1 zL must be enumerated in its own singleton sequence, and L 1 is p1, dq-enumerable. Now, we define G 1 to be the graph whose nodes are the words of L 1 and where we connect two words if they are different and the distance between them is ď d. Clearly G 1 has a Hamiltonian path iff L 1 is d-orderable. We claim that G 1 is isomorphic to G, which concludes the proof because then G has a Hamiltonian path iff G 1 does. So let us take two distinct vertices pi, jq, pi 1 , j 1 q of G and show that they are adjacent in G 1 (i.e., |i ´i1 | `|j ´j1 | " 1) iff a id b d`1 a jd is at distance ď d (for the Levenshtein or push/pop distance) to a i 1 d b d`1 a j 1 d . For the forward direction, it is clear that increasing/decreasing i or j amounts to pushing/popping a d at the beginning or end of the word. For the backward direction, proving the contrapositive, if the vertices are not adjacent then either |i ´i1 | ě 2 or |j ´j1 | ě 2 or both i ‰ i 1 and j ‰ j 1 . In all three cases, noting that all words reachable at Levenshtein edit distance ď d must include some b's in the middle, if we edit one of the words with ď d operations then the endpoints of the longest contiguous block of b's cannot have moved by more than d{2 relative to where they were in the original word, so the only operations that can give a word of the right form amount to modifying the number of a's to the left or right of the block of b's, and with d editions we cannot change both numbers nor can we change a number by at least 2d.</p><p>We have shown that G and G 1 are isomorphic, which establishes the correctness of the reduction and concludes the proof. đ</p></div>
<div><head>E.2 Proof of the results on the push-pop-right distance</head><p>We prove our result on the push-pop-right distance in this section: § Theorem 6.2. Given a DFA A, the language LpAq is pt, dq-partition-orderable for the push-pop-right distance for some t, d P N if and only if LpAq is slender. Further, if LpAq is slender, we can compute in PTIME the smallest t such that LpAq is pt, dq-partition-orderable for some d P N for the push-pop-right distance.</p><p>In addition, there is an algorithm which, given a DFA A for which LpAq is slender and t " 1, enumerates the language LpAq with push-pop-right distance bound 2k and linear delay in |A|. Further, the sequence of edit scripts produced by the algorithm is ultimately periodic.</p><p>We start with the proof of the characterization: LpAq is pt, dq-partition-orderable for the push-pop-right distance iff LpAq is slender.</p><p>We consider the infinite tree T whose nodes are Σ ˚and where, for every w P Σ ˚and a P Σ, the node w has an a-labeled edge to the node wa (i.e., wa is a child of w). A L-infinite branch of this tree is an infinite branch of the tree such that there are infinitely many nodes n on that branch that have a descendant in L. Formally, there is an infinite sequence w " a 1 a 2 ¨¨¨(i.e., an infinite word, corresponding to a branch) such that, for infinitely many values i 1 , i 2 , . . ., there are words x j such that a 1 ¨¨¨a ij x j is a word of L.</p><p>We show that a pt, dq-partition-orderable regular language for the push-pop-right distance must contain finitely many L-infinite branches: § Claim E.1. If L is pt, dq-partition-orderable language for the push-pop-right distance and is regular, then it must contain at most t L-infinite branches.</p><p>Proof. We show that a language with ě t `1 many L-infinite branches is not pt, dq-partitionorderable. Indeed, assume by contradiction that it is, for some distance d. Consider a depth m at which the t `1 L-infinite branches have diverged, i.e., we have distinct nodes n 1 , . . . , n t`1 at depth m that all have infinitely many descendants in L. Consider a moment at which all words of the language of length ď m `d have been enumerated. Then by the pigeonhole principle there must be some language in the partition that still has infinitely many words to enumerate from two different branches, say descendants of n i and n j with i ‰ j. Now, all descendants of n i at depth ą d are at distance ą d from all descendants of n j at depth ą d, which contradicts the assumption that the language in the partition can move from one to the other. đ</p><p>And we show that a regular language having finitely many L-infinite branches must be slender. § Claim E.2. If a regular language L has finitely many L-infinite branches, then it is slender. This follows from an ancillary claim shown by pumping: § Claim E.3. For an infinite regular language L, there is a value d P N such that, for each word w, there is an L-infinite branch in T such that w is at depth at most d from a node of the branch.</p><p>Proof. Let d be the number of states of a DFA recognizing L. As L is infinite, it clearly has at least some L-infinite branch obtained by considering rs ˚t for s a simple loop on a loopable state. Hence, the claim is trivial if w has length ă d because the root is a node of this L-infinite branch.</p><p>If |w| ě d, we know that there is some loopable state of w that occurs in the suffix of length d, i.e., we can write w " rt where the state q between r and t is loopable. Now, let s be a loop on q of length at most d, and consider the word sequence w i " rs i t of L starting at w 1 " w. All words of w i are in L. Further, let w 1 i be the sequence where w 1 1 is the least common ancestor (LCA) of w 1 and w 2 , w 1  2 is the LCA of w 2 and w 3 , and so on: clearly w 1</p><p>i " rs i for all i (but they are not words of L), in particular each w 1 i is an ancestor of w 1 i`1 , so the infinite sequence of the w 1 i defines an infinite branch in T . And is an L-infinite branch, because each w 1 i has a descendant. Thus indeed w is at depth d from a node of this infinite branch.</p><p>đ</p><p>We can then prove Claim E.2:</p><p>Proof of Claim E.2. If L is finite then it is slender. Otherwise, letting d be the number of states of a DFA recognizing L, we know by Claim E.3 that all words of the language must be at depth ď d from a node of some L-infinite branch, hence of one of the finite collection of L-infinite branches. This directly implies that L is slender, because for any length n ě d, considering L X Σ n , the number of nodes of T at depth n that can be in L are the descendants of the nodes of the branches at depth between n and n ´d, i.e., some number that only depends on the language. đ Thanks to Claims E.1 and E.2, we know that, among the regular languages, only the slender languages can be pt, dq-partition-orderable language for the push-pop-right distance. Indeed, if a language is pt, dq-partition-orderable then it has finitely many L-infinite branches by the first claim, which implies that it is slender by the second claim. So in the sequel it suffices to focus on slender languages.</p><p>We will refine a known characterization of slender languages. We know from [20, Chapter XII, Theorem 4.23] the following characterization: § Theorem E. <ref type="bibr">4 ([20]</ref>). The following are equivalent on a regular language L: L is slender L can be written as a union of regular expressions of the form xy ˚z.</p><p>The minimal DFA for L does not have a connected pair of simple cycles. This implies in particular that we can check in PTIME whether a language is slender given a DFA A for the language, by computing in PTIME the minimal DFA equivalent to A, and then checking if there are two connected simple cycles.</p><p>For t P N, a t-slender language is one that can be written as a disjoint union of a finite language L 1 and of t languages r i s i L i with r i and s i words and L i a finite language, for 1 ď i ď t, and all r i are pairwise incomparable (i.e., they are pairwise distinct and none is a strict prefix of another) and no word of r i is a prefix of a word of L 1 . Consider a trimmed DFA A, its non-loopable prefixes are the words w such that reading w in A brings us to a loopable state, and reading any strict prefix of w does not. We claim the following: § Proposition E.5. The following are equivalent on a regular language L: L is recognized by a DFA without a connected pair of simple cycles and with exactly t non-loopable prefixes.</p><p>L can be written as a t-slender language.</p><p>This proposition implies in particular that a slender language is necessarily t-slender for some t, by considering its minimal DFA and counting the minimal infinitely continuable prefixes. Note that, given a DFA, we can compute in PTIME the equivalent minimal DFA and count in PTIME the non-loopable prefixes. We prove the proposition:</p><p>Proof of Proposition E.5. If L is recognized by an automaton of the prescribed form, we can write L as a disjoint union of the non-loopable words (a finite language) and the languages r i L qi where the r i are the non-loopable prefixes and the L qi is the language accepted by starting at the loopable state q i at which we get after reading the non-loopable prefix. (Some of the q i may be identical.) Note that by construction the r i are pairwise incomparable and none is a prefix of a non-loopable word. Now, each L qi can be decomposed between the words accepted without going to q i again, and those where we do. As L has no connected pair of simple cycles, if we do not go to q i again, then we cannot complete the simple cycle on q i and we cannot go to another cycle, so the possible words leading to a finite state form a finite language L i . If we do, then the word starts with the (unique) label of the (unique) simple cycle starting at q i , i.e., s i , and then we have a word of L qi . Thus, we can write L as a disjoint union of the non-loopable words and of the r i ps i q ˚Li with L i finite.</p><p>Conversely, if L is written as a t-slender language then we obtain the automaton in the obvious way: start with an acyclic DFA A for the finite language, construct DFAs A i for each s i L i which have exactly one simple cycle on which the initial state is located, then for each r i extend A with a path labeled by r i going from the initial state to the initial state of A i : some states of the path may already exist (because of the words of L 1 or of the other words of r i ), but the condition on the r i and on L 1 guarantee that we always create at least one new transition. The resulting automaton accepts by construction the words of L 1 and the words of the r i s i L i , and for any accepting path in the automaton either it ends at a state of A and the accepted word is a word of L 1 , or it goes into an A i and the accepted word is a word of some r i s i L i đ</p><p>We now claim that the t-slender languages are precisely those that are pt, dq-partitionorderable for some d: § Proposition E.6. A t-slender language is pt, dq-partition-orderable for some d. Conversely, if a regular language is pt, dq-partition-orderable then it is t-slender. the automaton is trimmed, so we know that we achieve a new non-loopable word every k steps at most, for k the number of automaton states. Now, we continue the enumeration sequence with an edit script that goes from the last produced word to the word corresponding to the unique path from an initial state to the first state q of the loop. We are now ready to start the computation of the periodic part of the ultimately periodic sequence.</p><p>To do this, we first enumerate all words that can be accepted from q without going back to q. This can be done by a DFS in the same way that we did previously, with the same distance and complexity bounds. Next, from the last word enumerated in this fashion, we pop until we arrive to a state of the loop, then we complete the loop to reach the state q. This completes the description of the periodic part.</p><p>Note that, in all cases, the distance between two words, hence the delay in producing the corresponding elements of the sequence, is at most 2k. This is because, when going from one word to the next, the algorithm is always popping a simple path of states, and pushing a simple path, so each state can at most occur twice. The only exception is the previous paragraph, where we pop until we arrive to a state of the loop, then push a completion of the loop: the next produced word may then be pushing states that already occur in the completion of the loop, but these states occur at most two times in total and did not occur in the pop, so the overall bound still applies. đ</p></div><figure xml:id="fig_0"><head>Figure 1</head><label>1</label><figDesc>Figure 1 Example DFAs from Example 3.4</figDesc></figure>
<figure xml:id="fig_1"><head>Figure 2</head><label>2</label><figDesc>Figure 2 Tree used in the proof of Claim C.2</figDesc></figure>
<figure xml:id="fig_2"><head>Proofs for Section 4 (C. 1 Proof of Lemma 4 . 3 § 4 . 3 .</head><label>414343</label><figDesc>Orderability upper bound) Lemma Let L be a finite language that is d-connected and s ‰ e be words of L. Then there exists a 3d-ordering of L starting at s and ending at e.</figDesc></figure>
<figure xml:id="fig_3"><head>Figure 3</head><label>3</label><figDesc>Figure 3Two example pre-word DAGs which are not word DAGs. The labels pushL and pushR are abbreviated for legibility. In the left pre-word DAG, the four paths to the top node that start to the left of the root all represent the word baa, whereas the four paths to that same node that start to the right of the root all represent the word bba. In the right pre-word DAG, the left topmost node represents ab and bb and the right topmost node represents aa and ba. The criteria of word DAGs, and our construction to enlarge them, are designed to prevent these problems.</figDesc></figure>
<figure xml:id="fig_5"><head>Figure 5</head><label>5</label><figDesc>Figure<ref type="bibr" target="#b4">5</ref> The initial word DAG for alphabet ta, b, cu, with pushL and pushR respectively shortened to L and R for brevity.</figDesc></figure>
<figure xml:id="fig_6"><head>Figure 6</head><label>6</label><figDesc>Figure 6 Figures illustrating the completion procedure from Definition D.4 for a label of the form pushLpaq P Σ, in the different possible cases. Only the nodes of the word DAG that are mentioned in the procedure are drawn. Dotted edges, and nodes that are the successors of dotted edges, are created by the completion procedure illustrated. The case m ě 1 and a " b1 cannot occur by definition of nm.</figDesc></figure>
<figure type="table" xml:id="tab_0"><head>Algorithm 1</head><label>1</label><figDesc>Push-pop enumeration algorithm for the language a ˚b˚`b˚a˚f rom Example 2.3.// The first edit script is empty, corresponding to the empty word.</figDesc><table><row><cell>Output;</cell></row><row><cell>int size " 0;</cell></row><row><cell>while true do</cell></row><row><cell>size``;</cell></row><row><cell>pushRpbq ; Output;</cell></row><row><cell>for int j " 0; j ă size ´1; j``do</cell></row><row><cell>pushRpbq ; popLpq ; Output;</cell></row><row><cell>end</cell></row><row><cell>for int j " 0; j ă size; j``do</cell></row><row><cell>pushRpaq ; popLpq ; Output;</cell></row><row><cell>end</cell></row><row><cell>end</cell></row><row><cell>§ Example 2.4. Continuing Example 2.3, Algorithm 1 can</cell></row></table></figure>
<figure type="table" xml:id="tab_1"><head /><label /><figDesc>, we can easily prove Lemma 4.3 from Lemma C.1: Consider the (finite) undirected graph G " pL, ttu, vu | δpu, vq ď du. Since L is d-connected, G is connected (in the usual sense) and so it has a spanning tree T . Now, applying Lemma C.1 on T gives us a sequence enumerating exactly once every vertex of G starting and ending at the requisite nodes, such that the distance between any two nodes in the sequence is at most 3 in T , hence at most 3 in G, so the distance between the words is at most 3d.</figDesc><table><row><cell>Proof of Lemma 4.3.</cell></row></table><note><p><p><p>đ</p>C.2 Proof of Lemma 4.6 § Lemma 4.6. Let L be an infinite language recognized by a DFA with k 1 states, and assume that L is p , dq-stratum-connected for some ě 2k 1 and some d ě 3k 1 . Then L is 3d-orderable.</p>Proof. A p , dq-ladder of L consists of two infinite sequences e 1 , . . . , e n , . . . of exit points, and s 2 , . . . , s n , . . . of starting points, such that e i P strat pL, iq for all i ě 1 and s i P strat pL, iq</p></note></figure>
<figure type="table" xml:id="tab_2"><head /><label /><figDesc>1 | ´|v 1 || ď . Now |u 1 | " |s| `|t| `|u 2 | and |v 1 | " |x| `|y| `|v 2 |, so by the triangle inequality the length difference ||u 2 | ´|v 2 || between the middle parts u 2 and v 2 is at most `|s| `|t| `|x| `|y|, so δ pp pu 1 , v 1 q ď `2p|s| `|t| `|x| `|y|q, i.e., at most `8k, establishing the result. đ</figDesc><table /></figure>
<figure type="table" xml:id="tab_3"><head /><label /><figDesc>by the definition of algorithm C 1 , if we have popped ř i j"1 N j edit scripts from the FIFO, then we have already run at least E ř i j"1 N j steps of algorithm C. Hence, we know that algorithm C has finished producing the edit scripts for the pi `1q-th stratum and the FIFO is not empty. This concludes the proof.</figDesc><table /><note><p>đ E Proofs for Section 6 (Extensions) E.1 Proof of the complexity results § Proposition 6.1 ([19]). For any fixed t, d ě 1, it is NP-complete, given a DFA A with LpAq finite, to decide if LpAq is pt, dq-partition-orderable (with the push-pop or Levenshtein distance).</p></note></figure>
			<note place="foot" n="1" xml:id="foot_0"><p>There is, in fact, an Ωplog |w|{ log log |w|q lower bound on the complexity of applying Levenshtein edit operations and querying which letter occurs at a given position: crucially, this bound depends on the size of the word. See https://cstheory.stackexchange.com/q/46746 for details. This is in contrast to the application of push-pop-right edit operations, which can be performed in constant time (independent from the word length) when the word is stored in a double-ended queue.</p></note>
			<note place="foot" n="2" xml:id="foot_1"><p>We use Ů for disjoint unions.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p>We thank <rs type="person">Florent Capelli</rs> and <rs type="person">Charles Paperman</rs> for their insights during initial discussions about this problem. We thank user pcpthm on the <rs type="institution">Theoretical Computer Science Stack Exchange</rs> forum for giving the argument for Proposition 6.1 in [19]. We thank <rs type="person">Jeffrey Shallit</rs> for pointing us to related work. We thank <rs type="person">Torsten Mütze</rs> and <rs type="person">Arturo Merino</rs> for other helpful pointers. We thank the anonymous reviewers for their valuable feedback. Finally, we are grateful to <rs type="person">Louis Jachiet</rs> and <rs type="person">Lê Thành Dũng</rs> (<rs type="person">Tito</rs>) <rs type="person">Nguyễn</rs> for feedback on the draft.</p></div>
			</div>
			<div type="funding">
<div><p>Funding <rs type="person">Antoine Amarilli</rs>: Partially supported by the <rs type="funder">ANR</rs> project <rs type="projectName">EQUUS</rs> <rs type="grantNumber">ANR-19-CE48-0019</rs> and by the <rs type="funder">Deutsche Forschungsgemeinschaft (DFG, German Research Foundation</rs>) -<rs type="grantNumber">431183758</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funded-project" xml:id="_BymTNsp">
					<idno type="grant-number">ANR-19-CE48-0019</idno>
					<orgName type="project" subtype="full">EQUUS</orgName>
				</org>
				<org type="funding" xml:id="_S7J6K2x">
					<idno type="grant-number">431183758</idno>
				</org>
			</listOrg>

			<div type="availability">
<div><p>https://arxiv.org/abs/2209.14878 <ref type="bibr" target="#b4">[5]</ref> </p></div>
			</div>

			<div type="annex">
<div><head>Enumerating Regular Languages with Bounded Delay</head><p>Hence, this value is C 1 ř i j"1 N j for some value C 1 exponential in |A|. Thus, the total number of nodes added to the word DAG is indeed proportional to ř i j"1 N j . Now, as we only add nodes by performing completions, and only consider nodes on which there is indeed a completion to perform (in particular removing from the lists B j the nodes that have become complete), Lemma D.7 ensures that the running time satisfies a similar bound, which is what we needed to show. đ</p><p>Next, we show Proposition 5.5, which claims that we can produce the stratum graph sequence in amortized linear time:</p><p>Proof of Proposition 5.5. For this, we will extend the algorithm from Proposition 5.8 to compute the stratum graphs. Specifically: once we have finished the pi `2q-th phase (during which we discover all nodes of the pi `2q-th stratum), and before entering the pi `3q-th phase, we prepare in linear time in N i the stratum graph Γ i for stratum i and the corresponding starting and exit nodes. Note that we can easily compute the first stratum graph Γ 1 during the initialization, as well as starting and exit points for it; we pick an exit point for the 1st stratum which is a word that is at distance ď d to a word of the second stratum, as can be checked by naively testing all possible edit scripts of at most d operations. All of this can be computed by a naive algorithm, and will only increase the delay by an amount that is exponential in |A|. Also notice the following claim p‹q by the end of the pi `2q-th phase, we have found all words of Σ ˚whose push-pop distance to a word of Ť i j"1 strat pL, jq is ď d, and these words are all of size at least pi ´3q and at most pi `2q : this is by Proposition D.13 and because 2 ě d. We can moreover easily modify the algorithm of Proposition 5.8 so that it keeps, when it is in the i-th phase, a pointer to some successful node w i of the i ´2-th stratum (or a null pointer when i ă 3).</p><p>Let us explain how we compute the stratum graph Γ i in linear time in N i after the pi `2q-th phase has concluded. We assume that we already know the ending point v ei´1 of the previous phase, and that it was picked to ensure that there was a word of strat pL, iq at distance ď d (as we did above for the 1st stratum). We do the computation in four steps: First, we explore the A-word DAG using a DFS (e.g., with a stack implemented as a linked list, and without taking into account the orientation of the edges) starting from the node w i from the i-th strata, only visiting nodes corresponding to words of length ě pi ´3q and ď pi `2q (which can be detected with the modulo annotations). During this exploration, whenever we see a successful node that is in the i-th strata, we store it in a linked list (also marking it in the word DAG). This is in linear time in the number of nodes created in this length interval, hence, by Lemma 5.2, in linear time in N i . By p‹q, Proof. For the first claim, it suffices to show that a 1-slender language is d-orderable for the push-pop-right distance for some d. This is easy: first enumerate the words of L 1 in some naive way, and then enumerate the words of rL 2 , then rsL 2 , etc. The distance within each sequence is bounded because L 1 and L 2 are finite, and the distance when going from the last word of rs i L 2 to the first word of rs i`1 L 2 is bounded too.</p><p>For the second claim, we know by Claim E.1 that a regular language L that is pt, dqpartition-orderable for some d must have at most t L-infinite branches. Now, we know by Claim E.2 that L must then be slender. Assuming by way of contradiction that L is not t-slender, by Theorem E.4 together with Proposition E.5 we know L must be t 1 -slender for some t 1 , implying that L is t 1 -slender for some t 1 ą t. Now, being t 1 -slender implies that L has t 1 infinite L-branches, namely, those starting at the r i which are pairwise incomparable. This contradicts our assumption that L has at most t L-infinite branches, and concludes the proof.</p><p>đ</p><p>We have thus shown the first part of Theorem 6.2: if the language LpAq is pt, dq-partitionorderable for the push-pop-right distance for some t, d P N then it is t-slender by the proposition, and conversely if it is slender then it is t-slender for some t by Theorem E.4 and Proposition E.5 and is then pt, dq-partition-orderable for some d P N by the proposition. Further, if L is slender, using the characterization of Proposition E.5 we can compute in PTIME the smallest t such that L is t-slender, and then we know that L is pt, dq-partitionorderable for some d but not pt ´1, dq-partition-orderable, thanks to the proposition.</p><p>We last show that, if t " 1, we can compute the description of an ultimately periodic sequence of edit scripts that enumerates LpAq respecting a linear bound on the push-pop-right distance and in linear delay: § Proposition E.7. There is an algorithm which, given a DFA A with k states representing a 1-slender language, computes a sequence of edit scripts that enumerates LpAq and is ultimately periodic, with push-pop-right distance bound 2k and delay linear in |A|.</p><p>Note that this proposition admits a converse: the ultimately periodic sequences of edit scripts can only achieve slender languages (see Proposition A.1).</p><p>We now prove the proposition:</p><p>Proof of Proposition E.7. Recall that we are given the input DFA in the way described in Appendix A.2. We first locate in the input DFA the unique simple cycle and path from the initial state to that simple cycle: this can be performed in linear time by running a depth-first search (DFS) on the automaton from the initial state, marking states when the DFS starts visiting them and is done visiting them. We stop at the moment where the exploration reaches a vertex which is currently being visited: then the recursion stack gives us (from bottom to top) the unique path from the initial state to a state of the loop, and then the loop itself. We now start the computation of the ultimately periodic sequence by producing scripts to enumerate all words of the finite language L 1 of the non-loopable words. For this, we perform a DFS from the initial state where we do not mark vertices as visited (so as to enumerate all paths). We do so on a slightly modified version of the automaton where we remove the states of the loop (as we must produce only non-loopable words), and where we trim the automaton to remove all states which no longer have a path to an accepting state. Each time we reach a final state in the DFS, we produce an edit sequence achieving the word described by the recursion stack from the previously produced word; this is easy to do by stacking push and pop operations which correspond to what the DFS does. Remember that</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Three new algorithms for regular language enumeration</title>
		<author>
			<persName><forename type="first">Margareta</forename><surname>Ackerman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Erkki</forename><surname>Mäkinen</surname></persName>
		</author>
		<ptr target="https://maya-ackerman.com/wp-content/uploads/2018/09/ThreeNewAlgorithmsForRegularLanEnum.pdf" />
	</analytic>
	<monogr>
		<title level="m">ICCC</title>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Efficient enumeration of words in regular languages</title>
		<author>
			<persName><forename type="first">Margareta</forename><surname>Ackerman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeffrey</forename><surname>Shallit</surname></persName>
		</author>
		<ptr target="https://maya-ackerman.com/wp-content/uploads/2018/09/Enumeration_AckermanShallit_TCS.pdf" />
	</analytic>
	<monogr>
		<title level="j">Theoretical Computer Science</title>
		<imprint>
			<biblScope unit="volume">410</biblScope>
			<biblScope unit="issue">37</biblScope>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Constant-delay enumeration for nondeterministic document spanners</title>
		<author>
			<persName><forename type="first">Antoine</forename><surname>Amarilli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pierre</forename><surname>Bourhis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefan</forename><surname>Mengel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthias</forename><surname>Niewerth</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/1807.09320" />
	</analytic>
	<monogr>
		<title level="m">ICDT</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Enumeration on trees with tractable combined complexity and efficient updates</title>
		<author>
			<persName><forename type="first">Antoine</forename><surname>Amarilli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pierre</forename><surname>Bourhis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefan</forename><surname>Mengel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthias</forename><surname>Niewerth</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/1812.09519" />
	</analytic>
	<monogr>
		<title level="m">PODS</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Enumerating regular languages with bounded delay</title>
		<author>
			<persName><forename type="first">Antoine</forename><surname>Amarilli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mikaël</forename><surname>Monet</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2209.14878" />
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note>Full version with proofs</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">MSO queries on tree decomposable structures are computable with linear delay</title>
		<author>
			<persName><forename type="first">Guillaume</forename><surname>Bagan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CSL</title>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">On acyclic conjunctive queries and constant delay enumeration</title>
		<author>
			<persName><forename type="first">Guillaume</forename><surname>Bagan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arnaud</forename><surname>Durand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Étienne</forename><surname>Grandjean</surname></persName>
		</author>
		<ptr target="https://grandjean.users.greyc.fr/Recherche/PublisGrandjean/EnumAcyclicCSL07.pdf" />
	</analytic>
	<monogr>
		<title level="m">CSL</title>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Graph Theory</title>
		<author>
			<persName><forename type="first">Adrian</forename><surname>Bondy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><forename type="middle">S R</forename><surname>Murty</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">Graduate Texts in Mathematics</title>
		<imprint>
			<date type="published" when="2008">2008</date>
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Document spanners: A formal approach to information extraction</title>
		<author>
			<persName><forename type="first">Ronald</forename><surname>Fagin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benny</forename><surname>Kimelfeld</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Frederick</forename><surname>Reiss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stijn</forename><surname>Vansummeren</surname></persName>
		</author>
		<ptr target="https://pdfs.semanticscholar.org/8df0/ad1c6aa0df93e58071b8afe3371a16a3182f.pdf" />
	</analytic>
	<monogr>
		<title level="j">J. ACM</title>
		<imprint>
			<biblScope unit="volume">62</biblScope>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">The shuffle exchange network has a Hamiltonian path</title>
		<author>
			<persName><forename type="first">Rainer</forename><surname>Feldmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Mysliwietz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mathematical systems theory</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">5</biblScope>
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Recognizing lexicographically smallest words and computing successors in regular languages</title>
		<author>
			<persName><forename type="first">Lukas</forename><surname>Fleischer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeffrey</forename><surname>Shallit</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Foundations of Computer Science</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">06</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Constant delay algorithms for regular document spanners</title>
		<author>
			<persName><forename type="first">Fernando</forename><surname>Florenzano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cristian</forename><surname>Riveros</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Martin</forename><surname>Ugarte</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stijn</forename><surname>Vansummeren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Domagoj</forename><surname>Vrgoc</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/1803.05277" />
	</analytic>
	<monogr>
		<title level="m">PODS</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Hamilton paths in grid graphs</title>
		<author>
			<persName><forename type="first">Alon</forename><surname>Itai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christos</forename><forename type="middle">H</forename><surname>Papadimitriou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jayme</forename><forename type="middle">Luiz</forename><surname>Szwarcfiter</surname></persName>
		</author>
		<ptr target="http://www.cs.technion.ac.il/~itai/publications/Algorithms/Hamilton-paths.pdf" />
	</analytic>
	<monogr>
		<title level="j">SIAM Journal on Computing</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="676" to="686" />
			<date type="published" when="1982">1982</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">On the cube of a graph</title>
		<author>
			<persName><forename type="first">Jerome</forename><forename type="middle">J</forename><surname>Karaganis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Canadian Mathematical Bulletin</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="1968">1968</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Enumeration of monadic second-order queries on trees</title>
		<author>
			<persName><forename type="first">Wojciech</forename><surname>Kazana</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luc</forename><surname>Segoufin</surname></persName>
		</author>
		<ptr target="https://hal.archives-ouvertes.fr/docs/00/90/70/85/PDF/cdlin-survey.pdf" />
	</analytic>
	<monogr>
		<title level="j">TOCL</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">4</biblScope>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">On lexicographic enumeration of regular and context-free languages</title>
		<author>
			<persName><forename type="first">Erkki</forename><surname>Mäkinen</surname></persName>
		</author>
		<ptr target="http://cyber.bibl.u-szeged.hu/index.php/actcybern/article/view/3479/3464" />
	</analytic>
	<monogr>
		<title level="j">Acta Cybernetica</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="55" to="61" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Proof of the middle levels conjecture</title>
		<author>
			<persName><forename type="first">Torsten</forename><surname>Mütze</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/1404.4442" />
	</analytic>
	<monogr>
		<title level="j">Proceedings of the London Mathematical Society</title>
		<imprint>
			<biblScope unit="volume">112</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="677" to="713" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Combinatorial gray codes-An updated survey</title>
		<author>
			<persName><forename type="first">Torsten</forename><surname>Mütze</surname></persName>
		</author>
		<ptr target="https://cstheory.stackexchange.com/q/51653" />
	</analytic>
	<monogr>
		<title level="m">Enumerating finite set of words with Hamming distance 1. Theoretical Computer Science Stack Exchange</title>
		<imprint>
			<date type="published" when="2022-07-02">2022. 2022-07-02</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<author>
			<persName><forename type="first">Jean-Éric</forename><surname>Pin</surname></persName>
		</author>
		<ptr target="https://www.irif.fr/~jep/PDF/MPRI/MPRI.pdf" />
		<title level="m">Mathematical foundations of automata theory</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Hamiltonian paths in the square of a tree</title>
		<author>
			<persName><forename type="first">Jakub</forename><surname>Radoszewski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wojciech</forename><surname>Rytter</surname></persName>
		</author>
		<ptr target="https://www.mimuw.edu.pl/~rytter/MYPAPERS/isaac2011_rytter.pdf" />
	</analytic>
	<monogr>
		<title level="m">ISAAC</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Combinatorial generation</title>
		<author>
			<persName><forename type="first">Frank</forename><surname>Ruskey</surname></persName>
		</author>
		<ptr target="https://page.math.tu-berlin.de/~felsner/SemWS17-18/Ruskey-Comb-Gen.pdf" />
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
	<note>Preliminary working draft</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">On an ordering of the set of vertices of a connected graph</title>
		<author>
			<persName><forename type="first">Milan</forename><surname>Sekanina</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Publ. Fac. Sci. Univ. Brno</title>
		<imprint>
			<biblScope unit="volume">412</biblScope>
			<date type="published" when="1960">1960</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Enumeration complexity</title>
		<author>
			<persName><forename type="first">Yann</forename><surname>Strozecki</surname></persName>
		</author>
		<ptr target="http://eatcs.org/beatcs/index.php/beatcs/article/view/596" />
	</analytic>
	<monogr>
		<title level="j">Bulletin of EATCS</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">129</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">A class of algorithms which require nonlinear time to maintain disjoint sets</title>
		<author>
			<persName><forename type="first">Robert</forename><surname>Endre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tarjan</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of computer and system sciences</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="110" to="127" />
			<date type="published" when="1979">1979</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Two general methods to reduce delay and change of enumeration algorithms</title>
		<author>
			<persName><forename type="first">Takeaki</forename><surname>Uno</surname></persName>
		</author>
		<author>
			<persName><forename type="first">;</forename><surname>Kunihiro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wasa</forename></persName>
		</author>
		<ptr target="https://arxiv.org/abs/1605.05102" />
		<imprint>
			<date type="published" when="2003">2003. 2016</date>
		</imprint>
	</monogr>
	<note type="report_type">Technical report</note>
	<note>Enumeration of enumeration algorithms</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</teiCorpus></text>
</TEI>