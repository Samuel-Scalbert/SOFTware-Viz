<?xml version='1.0' encoding='utf-8'?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" version="1.1" xsi:schemaLocation="http://www.tei-c.org/ns/1.0 http://api.archives-ouvertes.fr/documents/aofr-sword.xsd">
  <teiHeader>
    <fileDesc>
      <titleStmt>
        <title>HAL TEI export of lirmm-03799097</title>
      </titleStmt>
      <publicationStmt>
        <distributor>CCSD</distributor>
        <availability status="restricted">
          <licence target="http://creativecommons.org/licenses/by/4.0/">Distributed under a Creative Commons Attribution 4.0 International License</licence>
        </availability>
        <date when="2024-04-29T11:45:31+02:00" />
      </publicationStmt>
      <sourceDesc>
        <p part="N">HAL API platform</p>
      </sourceDesc>
    </fileDesc>
  </teiHeader>
  <text>
    <body>
      <listBibl>
        <biblFull>
          <titleStmt>
            <title xml:lang="en">Data and Machine Learning Model Management with Gypscie</title>
            <author role="aut">
              <persName>
                <forename type="first">Patrick</forename>
                <surname>Valduriez</surname>
              </persName>
              <email type="md5">b7903099e0d3ee0b492cd1c7a982e35b</email>
              <email type="domain">inria.fr</email>
              <idno type="idhal" notation="string">patrick-valduriez</idno>
              <idno type="idhal" notation="numeric">172604</idno>
              <idno type="halauthorid" notation="string">22529-172604</idno>
              <idno type="ORCID">https://orcid.org/0000-0001-6506-7538</idno>
              <idno type="GOOGLE SCHOLAR">https://scholar.google.fr/citations?user=Vj0m2A0AAAAJ&amp;hl=fr</idno>
              <idno type="IDREF">https://www.idref.fr/028314417</idno>
              <affiliation ref="#struct-1100621" />
            </author>
            <author role="aut">
              <persName>
                <forename type="first">Fabio</forename>
                <surname>Porto</surname>
              </persName>
              <email type="md5">d48ac90feaf7aadd7911e48f9e1f0abc</email>
              <email type="domain">lncc.br</email>
              <idno type="idhal" notation="numeric">932292</idno>
              <idno type="halauthorid" notation="string">433850-932292</idno>
              <affiliation ref="#struct-4626" />
            </author>
            <editor role="depositor">
              <persName>
                <forename>Patrick</forename>
                <surname>Valduriez</surname>
              </persName>
              <email type="md5">b7903099e0d3ee0b492cd1c7a982e35b</email>
              <email type="domain">inria.fr</email>
            </editor>
            <funder ref="#projeurop-716602" />
          </titleStmt>
          <editionStmt>
            <edition n="v1" type="current">
              <date type="whenSubmitted">2022-10-05 16:17:51</date>
              <date type="whenWritten">2022</date>
              <date type="whenModified">2023-11-17 10:08:22</date>
              <date type="whenReleased">2022-10-07 14:45:29</date>
              <date type="whenProduced">2022-09-26</date>
              <date type="whenEndEmbargoed">2022-10-05</date>
              <ref type="file" target="https://hal-lirmm.ccsd.cnrs.fr/lirmm-03799097/document">
                <date notBefore="2022-10-05" />
              </ref>
              <ref type="file" subtype="author" n="1" target="https://hal-lirmm.ccsd.cnrs.fr/lirmm-03799097/file/CARLA_Gypscie_SAVIME.pdf">
                <date notBefore="2022-10-05" />
              </ref>
            </edition>
            <respStmt>
              <resp>contributor</resp>
              <name key="150418">
                <persName>
                  <forename>Patrick</forename>
                  <surname>Valduriez</surname>
                </persName>
                <email type="md5">b7903099e0d3ee0b492cd1c7a982e35b</email>
                <email type="domain">inria.fr</email>
              </name>
            </respStmt>
          </editionStmt>
          <publicationStmt>
            <distributor>CCSD</distributor>
            <idno type="halId">lirmm-03799097</idno>
            <idno type="halUri">https://hal-lirmm.ccsd.cnrs.fr/lirmm-03799097</idno>
            <idno type="halBibtex">valduriez:lirmm-03799097</idno>
            <idno type="halRefHtml">&lt;i&gt;CARLA 2022 - Workshop on HPC and Data Sciences meet Scientific Computing&lt;/i&gt;, SCALAC, Sep 2022, Porto Alegre, Brazil. pp.1-2</idno>
            <idno type="halRef">CARLA 2022 - Workshop on HPC and Data Sciences meet Scientific Computing, SCALAC, Sep 2022, Porto Alegre, Brazil. pp.1-2</idno>
          </publicationStmt>
          <seriesStmt>
            <idno type="stamp" n="CNRS">CNRS - Centre national de la recherche scientifique</idno>
            <idno type="stamp" n="INRIA">INRIA - Institut National de Recherche en Informatique et en Automatique</idno>
            <idno type="stamp" n="INRIA-SOPHIA">INRIA Sophia Antipolis - Méditerranée</idno>
            <idno type="stamp" n="INRIASO">INRIA-SOPHIA</idno>
            <idno type="stamp" n="OPENAIRE">OpenAIRE</idno>
            <idno type="stamp" n="INRIA_TEST">INRIA - Institut National de Recherche en Informatique et en Automatique</idno>
            <idno type="stamp" n="TESTALAIN1">TESTALAIN1</idno>
            <idno type="stamp" n="ZENITH" corresp="LIRMM">Scientific Data Management</idno>
            <idno type="stamp" n="LIRMM">Laboratoire d'Informatique de Robotique et de Microélectronique de Montpellier</idno>
            <idno type="stamp" n="INRIA2">INRIA 2</idno>
            <idno type="stamp" n="UNIV-MONTPELLIER">Université de Montpellier</idno>
            <idno type="stamp" n="UM-2015-2021" corresp="UNIV-MONTPELLIER">Université de Montpellier (2015-2021)</idno>
            <idno type="stamp" n="UM-EPE" corresp="UNIV-MONTPELLIER">Université de Montpellier - EPE</idno>
            <idno type="stamp" n="IA">Intelligence Artificielle</idno>
            <idno type="stamp" n="INRIA-BRASIL">Inria-Brasil</idno>
          </seriesStmt>
          <notesStmt>
            <note type="audience" n="2">International</note>
            <note type="invited" n="0">No</note>
            <note type="popular" n="0">No</note>
            <note type="peer" n="1">Yes</note>
            <note type="proceedings" n="1">Yes</note>
          </notesStmt>
          <sourceDesc>
            <biblStruct>
              <analytic>
                <title xml:lang="en">Data and Machine Learning Model Management with Gypscie</title>
                <author role="aut">
                  <persName>
                    <forename type="first">Patrick</forename>
                    <surname>Valduriez</surname>
                  </persName>
                  <email type="md5">b7903099e0d3ee0b492cd1c7a982e35b</email>
                  <email type="domain">inria.fr</email>
                  <idno type="idhal" notation="string">patrick-valduriez</idno>
                  <idno type="idhal" notation="numeric">172604</idno>
                  <idno type="halauthorid" notation="string">22529-172604</idno>
                  <idno type="ORCID">https://orcid.org/0000-0001-6506-7538</idno>
                  <idno type="GOOGLE SCHOLAR">https://scholar.google.fr/citations?user=Vj0m2A0AAAAJ&amp;hl=fr</idno>
                  <idno type="IDREF">https://www.idref.fr/028314417</idno>
                  <affiliation ref="#struct-1100621" />
                </author>
                <author role="aut">
                  <persName>
                    <forename type="first">Fabio</forename>
                    <surname>Porto</surname>
                  </persName>
                  <email type="md5">d48ac90feaf7aadd7911e48f9e1f0abc</email>
                  <email type="domain">lncc.br</email>
                  <idno type="idhal" notation="numeric">932292</idno>
                  <idno type="halauthorid" notation="string">433850-932292</idno>
                  <affiliation ref="#struct-4626" />
                </author>
              </analytic>
              <monogr>
                <meeting>
                  <title>CARLA 2022 - Workshop on HPC and Data Sciences meet Scientific Computing</title>
                  <date type="start">2022-09-26</date>
                  <settlement>Porto Alegre</settlement>
                  <country key="BR">Brazil</country>
                </meeting>
                <respStmt>
                  <resp>conferenceOrganizer</resp>
                  <name>SCALAC</name>
                </respStmt>
                <editor>Advanced Computing System for Latin America and the Caribbean (SCALAC)</editor>
                <imprint>
                  <biblScope unit="pp">1-2</biblScope>
                  <date type="datePub">2022-09</date>
                </imprint>
              </monogr>
              <ref type="publisher">http://www.carla22.org/pages/workshops/hpcdatasciencesmeetscientificcomputing.html</ref>
            </biblStruct>
          </sourceDesc>
          <profileDesc>
            <langUsage>
              <language ident="en">English</language>
            </langUsage>
            <textClass>
              <classCode scheme="halDomain" n="info.info-db">Computer Science [cs]/Databases [cs.DB]</classCode>
              <classCode scheme="halDomain" n="info.info-ai">Computer Science [cs]/Artificial Intelligence [cs.AI]</classCode>
              <classCode scheme="halTypology" n="COMM">Conference papers</classCode>
              <classCode scheme="halOldTypology" n="COMM">Conference papers</classCode>
              <classCode scheme="halTreeTypology" n="COMM">Conference papers</classCode>
            </textClass>
            <abstract xml:lang="en">
              <p>As predictive analytics using ML models (or models for short) become preva- lent in different stages of scientific exploration, a new set of artifacts are pro- duced during the models’ life-cycle that need to be managed [2]. In addition to the models with their evolving versions, ML life-cycle artifacts include the collected training data and pre-processing workflows, data labels and selected features, model training, tuning and monitoring statistics and provenance in- formation. However, to realize the full potential of data science, these artifacts must be built and combined, which can be very complex as there can be many to select from. Furthermore, they should be shared and reused, in particular, in different execution environments such as HPC or Spark clusters. In order to support the complete ML life-cycle process and produced arti- facts, we have been developing the Gypscie framework, which offers collaborat- ing researchers a common software infrastructure to develop, share, improve and publish ML artifacts.</p>
            </abstract>
            <particDesc>
              <org type="consortium">Inria associated team HPPDASC</org>
            </particDesc>
          </profileDesc>
        </biblFull>
      </listBibl>
    </body>
    <back>
      <listOrg type="structures">
        <org type="researchteam" xml:id="struct-1100621" status="VALID">
          <idno type="RNSR">201121208J</idno>
          <orgName>Scientific Data Management</orgName>
          <orgName type="acronym">ZENITH</orgName>
          <date type="start">2022-01-01</date>
          <desc>
            <address>
              <addrLine>LIRMM, 161 rue Ada, 34000 Montpellier</addrLine>
              <country key="FR" />
            </address>
            <ref type="url">https://team.inria.fr/zenith/</ref>
          </desc>
          <listRelation>
            <relation active="#struct-34586" type="direct" />
            <relation active="#struct-300009" type="indirect" />
            <relation active="#struct-1100620" type="direct" />
            <relation name="UMR5506" active="#struct-441569" type="indirect" />
            <relation name="UMR5506" active="#struct-1100589" type="indirect" />
          </listRelation>
        </org>
        <org type="institution" xml:id="struct-4626" status="VALID">
          <idno type="ROR">https://ror.org/0498ekt05</idno>
          <orgName>Laboratorio Nacional de Computação Cientifica [Rio de Janeiro]</orgName>
          <orgName type="acronym">LNCC / MCT</orgName>
          <desc>
            <address>
              <addrLine>LNCC, Av. Getulio Vargas, 333, Quitandinha, 25651-075, Petropolis, RJ</addrLine>
              <country key="BR" />
            </address>
            <ref type="url">http://www.lncc.br</ref>
          </desc>
        </org>
        <org type="laboratory" xml:id="struct-34586" status="VALID">
          <idno type="RNSR">198318250R</idno>
          <idno type="ROR">https://ror.org/01nzkaw91</idno>
          <orgName>Inria Sophia Antipolis - Méditerranée</orgName>
          <orgName type="acronym">CRISAM</orgName>
          <desc>
            <address>
              <addrLine>2004 route des Lucioles BP 93 06902 Sophia Antipolis</addrLine>
              <country key="FR" />
            </address>
            <ref type="url">http://www.inria.fr/centre/sophia/</ref>
          </desc>
          <listRelation>
            <relation active="#struct-300009" type="direct" />
          </listRelation>
        </org>
        <org type="institution" xml:id="struct-300009" status="VALID">
          <idno type="ROR">https://ror.org/02kvxyf05</idno>
          <orgName>Institut National de Recherche en Informatique et en Automatique</orgName>
          <orgName type="acronym">Inria</orgName>
          <desc>
            <address>
              <addrLine>Domaine de VoluceauRocquencourt - BP 10578153 Le Chesnay Cedex</addrLine>
              <country key="FR" />
            </address>
            <ref type="url">http://www.inria.fr/en/</ref>
          </desc>
        </org>
        <org type="laboratory" xml:id="struct-1100620" status="VALID">
          <idno type="IdRef">139590827</idno>
          <idno type="ISNI">0000000405990488</idno>
          <idno type="RNSR">199111950H</idno>
          <idno type="ROR">https://ror.org/013yean28</idno>
          <orgName>Laboratoire d'Informatique de Robotique et de Microélectronique de Montpellier</orgName>
          <orgName type="acronym">LIRMM</orgName>
          <date type="start">2022-01-01</date>
          <desc>
            <address>
              <addrLine>161 rue Ada - 34095 Montpellier</addrLine>
              <country key="FR" />
            </address>
            <ref type="url">https://www.lirmm.fr</ref>
          </desc>
          <listRelation>
            <relation name="UMR5506" active="#struct-441569" type="direct" />
            <relation name="UMR5506" active="#struct-1100589" type="direct" />
          </listRelation>
        </org>
        <org type="regroupinstitution" xml:id="struct-441569" status="VALID">
          <idno type="IdRef">02636817X</idno>
          <idno type="ISNI">0000000122597504</idno>
          <idno type="ROR">https://ror.org/02feahw73</idno>
          <orgName>Centre National de la Recherche Scientifique</orgName>
          <orgName type="acronym">CNRS</orgName>
          <date type="start">1939-10-19</date>
          <desc>
            <address>
              <country key="FR" />
            </address>
            <ref type="url">https://www.cnrs.fr/</ref>
          </desc>
        </org>
        <org type="regroupinstitution" xml:id="struct-1100589" status="VALID">
          <idno type="ROR">https://ror.org/051escj72</idno>
          <orgName>Université de Montpellier</orgName>
          <orgName type="acronym">UM</orgName>
          <date type="start">2022-01-01</date>
          <desc>
            <address>
              <addrLine>163 rue Auguste Broussonnet - 34090 Montpellier</addrLine>
              <country key="FR" />
            </address>
            <ref type="url">http://www.umontpellier.fr/</ref>
          </desc>
        </org>
      </listOrg>
      <listOrg type="projects">
        <org type="europeanProject" xml:id="projeurop-716602" status="INCOMING">
          <idno type="number"> 101016478</idno>
          <orgName>RISC2</orgName>
          <desc>RISC2</desc>
        </org>
      </listOrg>
    </back>
  <teiCorpus>
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Data and Machine Learning Model Management with Gypscie</title>
			</titleStmt>
			<publicationStmt>
				<publisher />
				<availability status="unknown"><licence /></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Patrick</forename><surname>Valduriez</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Data and Machine Learning Model Management with Gypscie</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="laboratory">CARLA 2022 -Workshop on HPC and Data Sciences meet Scientific Computing</orgName>
								<orgName type="institution">SCALAC</orgName>
								<address>
									<addrLine>Sep 2022</addrLine>
									<settlement>Porto Alegre</settlement>
									<country key="BR">Brazil</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Fabio</forename><surname>Porto</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Data and Machine Learning Model Management with Gypscie</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="laboratory">CARLA 2022 -Workshop on HPC and Data Sciences meet Scientific Computing</orgName>
								<orgName type="institution">SCALAC</orgName>
								<address>
									<addrLine>Sep 2022</addrLine>
									<settlement>Porto Alegre</settlement>
									<country key="BR">Brazil</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Data and Machine Learning Model Management with Gypscie</title>
					</analytic>
					<monogr>
						<imprint>
							<date />
						</imprint>
					</monogr>
					<idno type="MD5">EC752A1369948160AE097AA458312692</idno>
					<idno type="DOI">10.1109/ICDE.2017.112</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-04-12T14:50+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid" />
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract />
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div><head>Data and Machine Learning Model Management with Gypscie</head><p>Fabio Porto 1[0000-0002-4597-4832] and Patrick Valduriez 2,<ref type="foot" target="#foot_0">3</ref>[0000-0001-6506-7538]</p><p>1 Laboratório Nacional de Computação Científica, Petropolis, RJ, Brazil 2 Inria, University of Montpellier,CNRS, LIRMM, Montpellier, France fporto@lncc.br, patrick.valduriez@inria.fr</p><p>The synergy of big data and machine learning (ML) has led to the new data science, with many benefits for data-intensive applications in terms of more accurate predictive data analysis and better decision making. For instance, in the context of the HPDaSc (High Performance Data Science) project between Inria and Brazil 3 , we have shown the importance of realtime analytics using ML models to make critical high-consequence decisions, e.g., preventing an oil drill from getting stuck in the ocean subsurface salt layer based on a driller's realtime data, predicting extreme weather events and supporting realtime analytics based on the visualization of simulated data of the cardio vascular system, or the effectiveness of ML to deal with scientific data, e.g., computing Probability Density Functions (PDFs) over simulated seismic data using Spark.</p><p>As predictive analytics using ML models (or models for short) become prevalent in different stages of scientific exploration, a new set of artifacts are produced during the models' life-cycle that need to be managed <ref type="bibr" target="#b1">[2]</ref>. In addition to the models with their evolving versions, ML life-cycle artifacts include the collected training data and pre-processing workflows, data labels and selected features, model training, tuning and monitoring statistics and provenance information. However, to realize the full potential of data science, these artifacts must be built and combined, which can be very complex as there can be many to select from. Furthermore, they should be shared and reused, in particular, in different execution environments such as HPC or Spark clusters.</p><p>In order to support the complete ML life-cycle process and produced artifacts, we have been developing the Gypscie framework, which offers collaborating researchers a common software infrastructure to develop, share, improve and publish ML artifacts. Figure <ref type="figure">1</ref> depicts the framework architecture.</p><p>Gypscie offers a web interface that easy the accomplishment of complex ML model tasks, even by non computer science savvy researchers. It also offers a notebook interface and an API for direct python <software ContextAttributes="created">scripts</software> integration with the framework services. Users can build dataflows graphically to model data preprocessing tasks. Registered dataflows can be scheduled for execution and, during run time, have their activites and involved data recorded for provenance. Models can be trained using registered datasets and have stored the corresponding testing performance metrics. We integrate the Databrics MLFlow component 4 to interface Gypscie with different machine learning execution engines. Three Fig. <ref type="figure">1</ref>. Gypscie Architecture aspects of Gypscie stand out. Multiple-Environments: Tasks in Gypscie can be scheduled in environments that best fit the running process. For data transformation processes, data locality is prioritized and Big Data frameworks like <software ContextAttributes="created">Apache Spark</software> and <software ContextAttributes="created">Dask</software> are usual choices. The Santos Dumont HPC system is a strong candidate for large scale data processing and their usage in large model training. Model composition: Gypscie automatically selects and allocates multiple spatio-temporal deep learning models, using the DJEnsemble approach <ref type="bibr" target="#b2">[3]</ref>. The composition of published models is a particular motivation for sharing models within the framework. <software ContextAttributes="created">SAVIME</software>: A multi-dimensional array in-memory DBMS <ref type="bibr" target="#b0">[1]</ref> that enriches the framework with declarative, SQL-Like, query processing that is used to explore registered datasets and invoke ML models. <software ContextAttributes="created">SAVIME</software> can process the datasets directly from their raw format with no data ingestion cost.</p><p>A first version of Gypscie has been deployed on two different applications. The first one supports oil exploration by managing models that predict the rupture of platforms stabilizers, as well as the corresponding online monitoring data. The second one refers to ML models predicting extreme rainfall events in the city of Rio de Janeiro. The latter runs on a shared-nothing cluster at LNCC and work is in progress to enable scheduling ML training using the Santos Dumont HPC system.</p></div>			<note place="foot" n="3" xml:id="foot_0"><p>https://team.inria.fr/zenith/hpdasc</p></note>
			<note place="foot" n="4" xml:id="foot_1"><p>https://github.com/mlflow/mlflow</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Savime: An array dbms for simulation analysis and ml models prediction</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">S</forename><surname>Lustosa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Silva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">R</forename><surname>Da Silva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Valduriez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Porto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Information and Data Management</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2021-02">Feb 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Towards unified data and lifecycle management for deep learning</title>
		<author>
			<persName><forename type="first">H</forename><surname>Miao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">S</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Deshpande</surname></persName>
		</author>
		<idno type="DOI">10.1109/ICDE.2017.112</idno>
		<ptr target="https://doi.org/10.1109/ICDE.2017.112" />
	</analytic>
	<monogr>
		<title level="m">IEEE 33rd International Conference on Data Engineering (ICDE)</title>
		<imprint>
			<date type="published" when="2017">2017. 2017</date>
			<biblScope unit="page" from="571" to="582" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Djensemble: A cost-based selection and allocation of a disjoint ensemble of spatio-temporal models</title>
		<author>
			<persName><forename type="first">R</forename><surname>Pereira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Souto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Chaves</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Zorilla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Tsan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Rusu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Ogasawara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ziviani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Porto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SSDBM 2021</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="226" to="231" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</teiCorpus></text>
</TEI>