<?xml version='1.0' encoding='utf-8'?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" version="1.1" xsi:schemaLocation="http://www.tei-c.org/ns/1.0 http://api.archives-ouvertes.fr/documents/aofr-sword.xsd">
  <teiHeader>
    <fileDesc>
      <titleStmt>
        <title>HAL TEI export of hal-03807530</title>
      </titleStmt>
      <publicationStmt>
        <distributor>CCSD</distributor>
        <availability status="restricted">
          <licence target="http://creativecommons.org/licenses/by/4.0/">Distributed under a Creative Commons Attribution 4.0 International License</licence>
        </availability>
        <date when="2024-04-22T04:08:07+02:00" />
      </publicationStmt>
      <sourceDesc>
        <p part="N">HAL API platform</p>
      </sourceDesc>
    </fileDesc>
  </teiHeader>
  <text>
    <body>
      <listBibl>
        <biblFull>
          <titleStmt>
            <title xml:lang="en">Chop and change: Anaphora resolution in instructional cooking videos</title>
            <author role="aut">
              <persName>
                <forename type="first">Cennet</forename>
                <surname>Oguz</surname>
              </persName>
              <idno type="halauthorid">2607658-0</idno>
              <affiliation ref="#struct-258630" />
            </author>
            <author role="aut">
              <persName>
                <forename type="first">Ivana</forename>
                <surname>Kruijff-Korbayová</surname>
              </persName>
              <idno type="halauthorid">907824-0</idno>
              <affiliation ref="#struct-258630" />
            </author>
            <author role="aut">
              <persName>
                <forename type="first">Pascal</forename>
                <surname>Denis</surname>
              </persName>
              <email type="md5">89fd4466c5a169e94f8fab315f79441d</email>
              <email type="domain">inria.fr</email>
              <idno type="idhal" notation="string">pascal-denis</idno>
              <idno type="idhal" notation="numeric">1744</idno>
              <idno type="halauthorid" notation="string">1313-1744</idno>
              <idno type="IDREF">https://www.idref.fr/031934684</idno>
              <affiliation ref="#struct-432650" />
            </author>
            <author role="aut">
              <persName>
                <forename type="first">Emmanuel</forename>
                <surname>Vincent</surname>
              </persName>
              <email type="md5">06c8a35e507be1d816f58461ca2239ea</email>
              <email type="domain">inria.fr</email>
              <idno type="idhal" notation="string">emmanuelv</idno>
              <idno type="idhal" notation="numeric">1256</idno>
              <idno type="halauthorid" notation="string">4290-1256</idno>
              <idno type="ORCID">https://orcid.org/0000-0002-0183-7289</idno>
              <idno type="IDREF">https://www.idref.fr/089360176</idno>
              <affiliation ref="#struct-420403" />
            </author>
            <author role="aut">
              <persName>
                <forename type="first">Josef</forename>
                <surname>van Genabith</surname>
              </persName>
              <idno type="halauthorid">497137-0</idno>
              <affiliation ref="#struct-258630" />
            </author>
            <editor role="depositor">
              <persName>
                <forename>Emmanuel</forename>
                <surname>Vincent</surname>
              </persName>
              <email type="md5">06c8a35e507be1d816f58461ca2239ea</email>
              <email type="domain">inria.fr</email>
            </editor>
            <funder>This research was funded by the joint IMPRESS (01|S20076) project between the French National Institute for Research in Digital Science and Technology (Inria) and the German Research Center for Artificial Intelligence (DFKI)</funder>
          </titleStmt>
          <editionStmt>
            <edition n="v1" type="current">
              <date type="whenSubmitted">2022-10-10 00:42:45</date>
              <date type="whenModified">2024-01-24 09:54:24</date>
              <date type="whenReleased">2022-10-10 10:03:49</date>
              <date type="whenProduced">2022-11-20</date>
              <date type="whenEndEmbargoed">2022-10-10</date>
              <ref type="file" target="https://inria.hal.science/hal-03807530/document">
                <date notBefore="2022-10-10" />
              </ref>
              <ref type="file" subtype="author" n="1" target="https://inria.hal.science/hal-03807530/file/oguz_AACL22.pdf">
                <date notBefore="2022-10-10" />
              </ref>
            </edition>
            <respStmt>
              <resp>contributor</resp>
              <name key="150572">
                <persName>
                  <forename>Emmanuel</forename>
                  <surname>Vincent</surname>
                </persName>
                <email type="md5">06c8a35e507be1d816f58461ca2239ea</email>
                <email type="domain">inria.fr</email>
              </name>
            </respStmt>
          </editionStmt>
          <publicationStmt>
            <distributor>CCSD</distributor>
            <idno type="halId">hal-03807530</idno>
            <idno type="halUri">https://inria.hal.science/hal-03807530</idno>
            <idno type="halBibtex">oguz:hal-03807530</idno>
            <idno type="halRefHtml">&lt;i&gt;Findings of AACL-IJCNLP 2022 - 2nd Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics - 12th International Joint Conference on Natural Language Processing&lt;/i&gt;, Nov 2022, Taipeh, Taiwan</idno>
            <idno type="halRef">Findings of AACL-IJCNLP 2022 - 2nd Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics - 12th International Joint Conference on Natural Language Processing, Nov 2022, Taipeh, Taiwan</idno>
          </publicationStmt>
          <seriesStmt>
            <idno type="stamp" n="CNRS">CNRS - Centre national de la recherche scientifique</idno>
            <idno type="stamp" n="INRIA">INRIA - Institut National de Recherche en Informatique et en Automatique</idno>
            <idno type="stamp" n="INRIA-LILLE">INRIA Lille - Nord Europe</idno>
            <idno type="stamp" n="INRIA_TEST">INRIA - Institut National de Recherche en Informatique et en Automatique</idno>
            <idno type="stamp" n="INRIA-LORRAINE">INRIA Nancy - Grand Est</idno>
            <idno type="stamp" n="LORIA2">Publications du LORIA</idno>
            <idno type="stamp" n="INRIA-NANCY-GRAND-EST">INRIA Nancy - Grand Est</idno>
            <idno type="stamp" n="TESTALAIN1">TESTALAIN1</idno>
            <idno type="stamp" n="CRISTAL">Centre de Recherche en Informatique, Signal et Automatique de Lille (CRISTAL)</idno>
            <idno type="stamp" n="UNIV-LORRAINE">Université de Lorraine</idno>
            <idno type="stamp" n="INRIA2">INRIA 2</idno>
            <idno type="stamp" n="CRISTAL-MAGNET" corresp="CRISTAL">CRISTAL-MAGNET</idno>
            <idno type="stamp" n="LORIA">Laboratoire Lorrain de Recherche en Informatique et ses Applications</idno>
            <idno type="stamp" n="LORIA-NLPKD" corresp="LORIA">Department of Natural Language Processing &amp; Knowledge Discovery</idno>
            <idno type="stamp" n="UNIV-LILLE">Université de Lille</idno>
            <idno type="stamp" n="HYAIAI">Hybrid Approaches for Interpretable Artificial Intelligence</idno>
            <idno type="stamp" n="INRIA-ALLEMAGNE">INRIA-ALLEMAGNE</idno>
          </seriesStmt>
          <notesStmt>
            <note type="audience" n="2">International</note>
            <note type="invited" n="0">No</note>
            <note type="popular" n="0">No</note>
            <note type="peer" n="1">Yes</note>
            <note type="proceedings" n="1">Yes</note>
          </notesStmt>
          <sourceDesc>
            <biblStruct>
              <analytic>
                <title xml:lang="en">Chop and change: Anaphora resolution in instructional cooking videos</title>
                <author role="aut">
                  <persName>
                    <forename type="first">Cennet</forename>
                    <surname>Oguz</surname>
                  </persName>
                  <idno type="halauthorid">2607658-0</idno>
                  <affiliation ref="#struct-258630" />
                </author>
                <author role="aut">
                  <persName>
                    <forename type="first">Ivana</forename>
                    <surname>Kruijff-Korbayová</surname>
                  </persName>
                  <idno type="halauthorid">907824-0</idno>
                  <affiliation ref="#struct-258630" />
                </author>
                <author role="aut">
                  <persName>
                    <forename type="first">Pascal</forename>
                    <surname>Denis</surname>
                  </persName>
                  <email type="md5">89fd4466c5a169e94f8fab315f79441d</email>
                  <email type="domain">inria.fr</email>
                  <idno type="idhal" notation="string">pascal-denis</idno>
                  <idno type="idhal" notation="numeric">1744</idno>
                  <idno type="halauthorid" notation="string">1313-1744</idno>
                  <idno type="IDREF">https://www.idref.fr/031934684</idno>
                  <affiliation ref="#struct-432650" />
                </author>
                <author role="aut">
                  <persName>
                    <forename type="first">Emmanuel</forename>
                    <surname>Vincent</surname>
                  </persName>
                  <email type="md5">06c8a35e507be1d816f58461ca2239ea</email>
                  <email type="domain">inria.fr</email>
                  <idno type="idhal" notation="string">emmanuelv</idno>
                  <idno type="idhal" notation="numeric">1256</idno>
                  <idno type="halauthorid" notation="string">4290-1256</idno>
                  <idno type="ORCID">https://orcid.org/0000-0002-0183-7289</idno>
                  <idno type="IDREF">https://www.idref.fr/089360176</idno>
                  <affiliation ref="#struct-420403" />
                </author>
                <author role="aut">
                  <persName>
                    <forename type="first">Josef</forename>
                    <surname>van Genabith</surname>
                  </persName>
                  <idno type="halauthorid">497137-0</idno>
                  <affiliation ref="#struct-258630" />
                </author>
              </analytic>
              <monogr>
                <meeting>
                  <title>Findings of AACL-IJCNLP 2022 - 2nd Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics - 12th International Joint Conference on Natural Language Processing</title>
                  <date type="start">2022-11-20</date>
                  <date type="end">2022-11-23</date>
                  <settlement>Taipeh</settlement>
                  <country key="TW">Taiwan</country>
                </meeting>
                <imprint />
              </monogr>
            </biblStruct>
          </sourceDesc>
          <profileDesc>
            <langUsage>
              <language ident="en">English</language>
            </langUsage>
            <textClass>
              <classCode scheme="halDomain" n="info.info-cl">Computer Science [cs]/Computation and Language [cs.CL]</classCode>
              <classCode scheme="halTypology" n="COMM">Conference papers</classCode>
              <classCode scheme="halOldTypology" n="COMM">Conference papers</classCode>
              <classCode scheme="halTreeTypology" n="COMM">Conference papers</classCode>
            </textClass>
            <abstract xml:lang="en">
              <p>Linguistic ambiguities arising from changes in entities in action flows are a key challenge in instructional cooking videos. In particular, temporally evolving entities present rich and to date understudied challenges for anaphora resolution. For example "oil" mixed with "salt" is later referred to as a "mixture". In this paper we propose novel annotation guidelines to annotate recipes for the anaphora resolution task, reflecting change in entities. Moreover, we present experimental results for end-to-end multimodal anaphora resolution with the new annotation scheme and propose the use of temporal features for performance improvement.</p>
            </abstract>
            <particDesc>
              <org type="consortium">IMPRESS</org>
            </particDesc>
          </profileDesc>
        </biblFull>
      </listBibl>
    </body>
    <back>
      <listOrg type="structures">
        <org type="institution" xml:id="struct-258630" status="VALID">
          <orgName>Deutsches Forschungszentrum für Künstliche Intelligenz GmbH = German Research Center for Artificial Intelligence</orgName>
          <orgName type="acronym">DFKI</orgName>
          <desc>
            <address>
              <addrLine>Stuhlsatzenhausweg 3Campus D3_2D-66123 Saarbruecken</addrLine>
              <country key="DE" />
            </address>
            <ref type="url">http://www.dfki.de</ref>
          </desc>
        </org>
        <org type="researchteam" xml:id="struct-432650" status="VALID">
          <idno type="RNSR">201321079K</idno>
          <orgName>Machine Learning in Information Networks</orgName>
          <orgName type="acronym">MAGNET</orgName>
          <date type="start">2015-01-01</date>
          <desc>
            <address>
              <country key="FR" />
            </address>
            <ref type="url">http://www.inria.fr/equipes/magnet</ref>
          </desc>
          <listRelation>
            <relation active="#struct-104752" type="direct" />
            <relation active="#struct-300009" type="indirect" />
            <relation active="#struct-410272" type="direct" />
            <relation name="UMR9189" active="#struct-120930" type="indirect" />
            <relation name="UMR9189" active="#struct-374570" type="indirect" />
            <relation name="UMR9189" active="#struct-441569" type="indirect" />
          </listRelation>
        </org>
        <org type="researchteam" xml:id="struct-420403" status="VALID">
          <idno type="RNSR">201421147E</idno>
          <orgName>Speech Modeling for Facilitating Oral-Based Communication</orgName>
          <orgName type="acronym">MULTISPEECH</orgName>
          <desc>
            <address>
              <country key="FR" />
            </address>
            <ref type="url">http://www.inria.fr/equipes/multispeech</ref>
          </desc>
          <listRelation>
            <relation active="#struct-129671" type="direct" />
            <relation active="#struct-300009" type="indirect" />
            <relation active="#struct-423086" type="direct" />
            <relation active="#struct-206040" type="indirect" />
            <relation active="#struct-413289" type="indirect" />
            <relation name="UMR7503" active="#struct-441569" type="indirect" />
          </listRelation>
        </org>
        <org type="laboratory" xml:id="struct-104752" status="VALID">
          <idno type="RNSR">200818245B</idno>
          <idno type="ROR">https://ror.org/04eej9726</idno>
          <orgName>Inria Lille - Nord Europe</orgName>
          <desc>
            <address>
              <addrLine>Parc Scientifique de la Haute Borne 40, avenue Halley Bât.A, Park Plaza 59650 Villeneuve d'Ascq</addrLine>
              <country key="FR" />
            </address>
            <ref type="url">http://www.inria.fr/lille/</ref>
          </desc>
          <listRelation>
            <relation active="#struct-300009" type="direct" />
          </listRelation>
        </org>
        <org type="institution" xml:id="struct-300009" status="VALID">
          <idno type="ROR">https://ror.org/02kvxyf05</idno>
          <orgName>Institut National de Recherche en Informatique et en Automatique</orgName>
          <orgName type="acronym">Inria</orgName>
          <desc>
            <address>
              <addrLine>Domaine de VoluceauRocquencourt - BP 10578153 Le Chesnay Cedex</addrLine>
              <country key="FR" />
            </address>
            <ref type="url">http://www.inria.fr/en/</ref>
          </desc>
        </org>
        <org type="laboratory" xml:id="struct-410272" status="VALID">
          <idno type="IdRef">18388695X</idno>
          <idno type="RNSR">201521249L</idno>
          <idno type="ROR">https://ror.org/05vrs3189</idno>
          <orgName>Centre de Recherche en Informatique, Signal et Automatique de Lille - UMR 9189</orgName>
          <orgName type="acronym">CRIStAL</orgName>
          <date type="start">2015-01-01</date>
          <desc>
            <address>
              <addrLine>Université de Lille - Campus scientifique - Bâtiment ESPRIT - Avenue Henri Poincaré - 59655 Villeneuve d’Ascq</addrLine>
              <country key="FR" />
            </address>
            <ref type="url">https://www.cristal.univ-lille.fr/</ref>
          </desc>
          <listRelation>
            <relation name="UMR9189" active="#struct-120930" type="direct" />
            <relation name="UMR9189" active="#struct-374570" type="direct" />
            <relation name="UMR9189" active="#struct-441569" type="direct" />
          </listRelation>
        </org>
        <org type="institution" xml:id="struct-120930" status="VALID">
          <idno type="IdRef">256304629</idno>
          <idno type="ISNI">0000000122034461</idno>
          <idno type="ROR">https://ror.org/01x441g73</idno>
          <orgName>Centrale Lille</orgName>
          <desc>
            <address>
              <addrLine>École Centrale de Lille - Cité Scientifique - CS 20048 59651 Villeneuve d'Ascq Cedex</addrLine>
              <country key="FR" />
            </address>
            <ref type="url">https://centralelille.fr/</ref>
          </desc>
        </org>
        <org type="regroupinstitution" xml:id="struct-374570" status="VALID">
          <idno type="IdRef">223446556</idno>
          <idno type="ISNI">0000 0001 2242 6780</idno>
          <idno type="ROR">https://ror.org/02kzqn938</idno>
          <idno type="Wikidata">Q3551621</idno>
          <orgName>Université de Lille</orgName>
          <desc>
            <address>
              <addrLine>EPE Université de Lille. -- 42 rue Paul Duez, 59000 Lille</addrLine>
              <country key="FR" />
            </address>
            <ref type="url">https://www.univ-lille.fr/</ref>
          </desc>
        </org>
        <org type="regroupinstitution" xml:id="struct-441569" status="VALID">
          <idno type="IdRef">02636817X</idno>
          <idno type="ISNI">0000000122597504</idno>
          <idno type="ROR">https://ror.org/02feahw73</idno>
          <orgName>Centre National de la Recherche Scientifique</orgName>
          <orgName type="acronym">CNRS</orgName>
          <date type="start">1939-10-19</date>
          <desc>
            <address>
              <country key="FR" />
            </address>
            <ref type="url">https://www.cnrs.fr/</ref>
          </desc>
        </org>
        <org type="laboratory" xml:id="struct-129671" status="VALID">
          <idno type="RNSR">198618246Y</idno>
          <idno type="ROR">https://ror.org/03fcjvn64</idno>
          <orgName>Inria Nancy - Grand Est</orgName>
          <desc>
            <address>
              <addrLine>615 rue du Jardin Botanique 54600 Villers-lès-Nancy</addrLine>
              <country key="FR" />
            </address>
            <ref type="url">http://www.inria.fr/nancy</ref>
          </desc>
          <listRelation>
            <relation active="#struct-300009" type="direct" />
          </listRelation>
        </org>
        <org type="department" xml:id="struct-423086" status="VALID">
          <orgName>Department of Natural Language Processing &amp; Knowledge Discovery</orgName>
          <orgName type="acronym">LORIA - NLPKD</orgName>
          <desc>
            <address>
              <country key="FR" />
            </address>
            <ref type="url">http://www.loria.fr/en/research/departments/natural-language-processing-and-knowledge-discovery/</ref>
          </desc>
          <listRelation>
            <relation active="#struct-206040" type="direct" />
            <relation active="#struct-300009" type="indirect" />
            <relation active="#struct-413289" type="indirect" />
            <relation name="UMR7503" active="#struct-441569" type="indirect" />
          </listRelation>
        </org>
        <org type="laboratory" xml:id="struct-206040" status="VALID">
          <idno type="IdRef">067077927</idno>
          <idno type="ISNI">0000000121795429</idno>
          <idno type="RNSR">198912571S</idno>
          <idno type="IdUnivLorraine">[UL]RSI--</idno>
          <idno type="ROR">https://ror.org/02vnf0c38</idno>
          <orgName>Laboratoire Lorrain de Recherche en Informatique et ses Applications</orgName>
          <orgName type="acronym">LORIA</orgName>
          <date type="start">2012-01-01</date>
          <desc>
            <address>
              <addrLine>Campus Scientifique BP 239 54506 Vandoeuvre-lès-Nancy Cedex</addrLine>
              <country key="FR" />
            </address>
            <ref type="url">http://www.loria.fr</ref>
          </desc>
          <listRelation>
            <relation active="#struct-300009" type="direct" />
            <relation active="#struct-413289" type="direct" />
            <relation name="UMR7503" active="#struct-441569" type="direct" />
          </listRelation>
        </org>
        <org type="institution" xml:id="struct-413289" status="VALID">
          <idno type="IdRef">157040569</idno>
          <idno type="IdUnivLorraine">[UL]100--</idno>
          <idno type="ROR">https://ror.org/04vfs2w97</idno>
          <orgName>Université de Lorraine</orgName>
          <orgName type="acronym">UL</orgName>
          <date type="start">2012-01-01</date>
          <desc>
            <address>
              <addrLine>34 cours Léopold - CS 25233 - 54052 Nancy cedex</addrLine>
              <country key="FR" />
            </address>
            <ref type="url">http://www.univ-lorraine.fr/</ref>
          </desc>
        </org>
      </listOrg>
    </back>
  <teiCorpus>
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Chop and Change: Anaphora Resolution in Instructional Cooking Videos</title>
			</titleStmt>
			<publicationStmt>
				<publisher />
				<availability status="unknown"><licence /></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Cennet</forename><surname>Oguz</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">German Research Center for Artificial Intelligence (DFKI)</orgName>
								<orgName type="institution">Saarland Informatics</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Ivana</forename><surname>Kruijff-Korbayova</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">German Research Center for Artificial Intelligence (DFKI)</orgName>
								<orgName type="institution">Saarland Informatics</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Pascal</forename><surname>Denis</surname></persName>
							<affiliation key="aff1">
								<orgName type="laboratory">UMR 9189 CRIStAL</orgName>
								<orgName type="institution" key="instit1">Univ. Lille</orgName>
								<orgName type="institution" key="instit2">Inria</orgName>
								<orgName type="institution" key="instit3">CNRS</orgName>
								<orgName type="institution" key="instit4">Centrale Lille</orgName>
								<address>
									<postCode>F-59000</postCode>
									<settlement>Lille</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Emmanuel</forename><surname>Vincent</surname></persName>
							<email>emmanuel.vincent@inria.fr</email>
							<affiliation key="aff2">
								<orgName type="institution" key="instit1">Université de Lorraine</orgName>
								<orgName type="institution" key="instit2">CNRS</orgName>
								<orgName type="institution" key="instit3">Inria</orgName>
								<orgName type="institution" key="instit4">LORIA</orgName>
								<address>
									<postCode>F-54000</postCode>
									<settlement>Nancy</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Josef</forename><surname>Van Genabith</surname></persName>
							<email>josef.van_genabith@dfki.depascal.denis</email>
							<affiliation key="aff0">
								<orgName type="laboratory">German Research Center for Artificial Intelligence (DFKI)</orgName>
								<orgName type="institution">Saarland Informatics</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Stefan</forename><surname>Baumann</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Arndt</forename><forename type="middle">2012</forename><surname>Riester</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Alexey</forename><surname>Dosovitskiy</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Lucas</forename><surname>Beyer</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Dirk</forename><surname>Kolesnikov</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Xiaohua</forename><surname>Weissenborn</surname></persName>
						</author>
						<author>
							<persName><surname>Zhai</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Thomas</forename><surname>Unterthiner</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Mostafa</forename><surname>Dehghani</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Georg</forename><surname>Minderer</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Sylvain</forename><surname>Heigold</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Jakob</forename><surname>Gelly</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Christian</forename><surname>Druckenbrodt</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Timothy</forename><surname>Baldwin</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Olga</forename><surname>Russakovsky</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Jia</forename><surname>Deng</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Hao</forename><surname>Su</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Jonathan</forename><surname>Krause</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Sanjeev</forename><surname>Satheesh</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Sean</forename><surname>Ma</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Zhiheng</forename><surname>Huang</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Aditya</forename><surname>Karpathy</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Michael</forename><surname>Khosla</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Alexan</forename><surname>Bernstein</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Niki</forename><surname>Parmar</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Llion</forename><surname>Uszkoreit</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Aidan</forename><forename type="middle">N</forename><surname>Jones</surname></persName>
						</author>
						<author>
							<persName><surname>Gomez</surname></persName>
						</author>
						<author>
							<persName><forename type="first">R</forename><surname>Weischedel</surname></persName>
						</author>
						<author>
							<persName><forename type="first">S</forename><surname>Pradhan</surname></persName>
						</author>
						<author>
							<persName><forename type="first">L</forename><surname>Ramshaw</surname></persName>
						</author>
						<author>
							<persName><forename type="first">J</forename><surname>Kaufman</surname></persName>
						</author>
						<title level="a" type="main">Chop and Change: Anaphora Resolution in Instructional Cooking Videos</title>
					</analytic>
					<monogr>
						<imprint>
							<date />
						</imprint>
					</monogr>
					<idno type="MD5">23CD77E4E00A5EAC54F37CA20FD1C2F7</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-04-12T14:44+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid" />
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div><p>Linguistic ambiguities arising from changes in entities in action flows are a key challenge in instructional cooking videos. In particular, temporally evolving entities present rich and to date understudied challenges for anaphora resolution. For example "oil" mixed with "salt" is later referred to as a "mixture". In this paper we propose novel annotation guidelines to annotate recipes for the anaphora resolution task, reflecting change in entities. Moreover, we present experimental results for end-to-end multimodal anaphora resolution with the new annotation scheme and propose the use of temporal features for performance improvement. their intrinsic multimodality <ref type="bibr" target="#b5">(Huang et al., 2016)</ref>. 041 Krishnaswamy and Pustejovsky (2019) point to 042 various "channels of information" in the transmis-043 sion of each modality. A "shared reference of enti-044 ties" is introduced when two modalities refer to the 045 same description (Krishnaswamy and Pustejovsky, 046 2020). As presented in cooking instructions of 047 videos when two modalities refer to the same en-048 tity, the use of a referring expression is affected by 049 both modalities. For example, the cubes is used 050 in Figure 1a to denote the bread pieces in the text 051 modality because the instruction chop the bread 052 shaped them into cubes in the video modality. The 053 choice of referring expressions might also differ 054 with respect to the changes of the entities. In Fig-055 ure 1b the same nominal phrase refers to a different 056 1 object (the whole salmon piece; and then one of the 057 halves) whereas in Figure 1c a coreferential pro-058 noun is used although the object has changed. Fig-059 ure 1c is in fact the most well-behaved in terms of 060 keeping the language expressions consistent across 061 instructions and with the entities being referred to. 062 Figure 1d shows the use of null arguments: the sec-063 ond instruction cook in the oven does not explicitly 064 mention what to cook, whereas the image of the 065 instruction displays it. 066 The main contributions of this paper are as 067 follows: (i) We propose an anaphora annotation 068 scheme for instructional cooking videos that allows 069 us to address linguistic ambiguities in anaphora res-070 olution. In particular, we define different types of 071 anaphoric relations to keep track of spatio-temporal 072 changes of entities. We also provide a clear defi-073 nition of "identity of reference" and specify cate-074 gories that make an essential change resulting in a 075 different entity. (ii) We annotate the YouCookII 076 dataset (Zhou et al., 2018b,a) according to our 077 scheme and make it publicly available. 1 (iii) Null 078 anaphors, e.g., mix in the bowl, are included in 079 the annotation thanks to cooking videos that of-080 fer the precise visual observation of null anaphors 081 to annotators. (iv) We provide a baseline multi-082 modal anaphora resolution model for this dataset. 083 In particular, we adapt an end-to-end (Lee et al., 084 2017) coreference model for the anaphora resolu-085 tion task. (v) We offer a novel method to improve 086 anaphora resolution models for instructional lan-087 guage by leveraging temporal features capturing 088 temporal order of instructions instead of using the 089 token distance as Lee et al. (2017) and Yu and Poe-090 sio (2020).</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div><head n="1">Introduction</head><p>Anaphora resolution is the task of identifying the antecedent of an anaphor, i.e., find a language expression that a given entity refers to. For example, in the sentence take a potato and wash it, the pronoun it is an anaphor that refers to the antecedent a potato. This is a challenging NLP task which has been attracting much attention <ref type="bibr" target="#b13">(Poesio et al., 2018;</ref><ref type="bibr">Fang et al., 2021</ref><ref type="bibr">Fang et al., , 2022))</ref>. Different types of anaphoric relations have been identified and described in the scientific literature, e.g., identity <ref type="bibr" target="#b12">(Poesio and Artstein, 2008)</ref>, near-identity <ref type="bibr" target="#b19">(Recasens et al., 2011;</ref><ref type="bibr" target="#b2">Hovy et al., 2013)</ref>, and bridging <ref type="bibr" target="#b0">(Asher and Lascarides, 1998)</ref>.</p><p>Recipes provide a rich source for referring expressions <ref type="bibr" target="#b7">(Kiddon et al., 2015)</ref> of transformed entities, and offer a challenge for anaphora resolution Anaphoric Relations: identity, near-identity, association. Anaphoras mainly come in two forms:</p><p>coreference and bridging. Coreference is defined as language expressions referring to the same entity <ref type="bibr">(Weischedel et al., 2012)</ref>, whereas bridging is an anaphoric phenomenon based on a non-identical associated antecedent via lexical-semantic, framebased, or encyclopedic relations <ref type="bibr" target="#b0">(Asher and Lascarides, 1998)</ref>. A coreferring anaphor and its an-  <ref type="bibr" target="#b13">Poesio et al., 2018)</ref>. There are many extant hypotheses explaining how bridging relations function with different annotation schemes for bridging <ref type="bibr" target="#b1">(Hou et al., 2018)</ref>. The ARRAU corpus <ref type="bibr" target="#b13">(Poesio et al., 2018)</ref> consists of general language annotated with bridging relations of noun phrases (such as set membership, subset, possession and unrestricted.)  <ref type="bibr">(Clark, 1975;</ref><ref type="bibr" target="#b0">Asher and Lascarides, 1998;</ref><ref type="bibr" target="#b12">Poesio and Artstein, 2008;</ref><ref type="bibr" target="#b13">Poesio et al., 2018)</ref>  </p><formula xml:id="formula_0">Markert</formula></div>
<div><head n="4">Annotation Categories and Guidelines</head><p>In this section, we explain our strategy of mention selection and the use of our annotation schema on the YouCookII data.</p></div>
<div><head n="4.1">Mention Selection</head><p>In our work, we segment multiple-action instructions, e.g., put the chickpeas into the processor and blend all the ingredients, into single-action instructions put the chickpeas into the processor and blend all the ingredients while preserving the order of actions. Each recipe instruction contains one predicate and 0 to 8 entities. Null arguments and ellipses are extremely common in recipes <ref type="bibr" target="#b7">(Kiddon et al., 2015;</ref><ref type="bibr" target="#b5">Huang et al., 2016)</ref>, since some objects are not verbally expressed, but deduced from the context of the remaining elements or videos.</p><p>For example stir for 5 minutes does not explicitly mention the entity to be stirred. Nominal phrases with (in)definite noun phrases and pronouns are also used to mention the objects of recipes as in the following instruction: coat the pork in the marinade and place it in the oven. Therefore, we consider null arguments (i.e., null anaphors) and nominal phrases to define mentions. Contrary to ONTONOTES <ref type="bibr">(Weischedel et al., 2012)</ref>, we include expressions that do not refer to any other mention as singletons in the annotation.</p></div>
<div><head n="4.2">Anaphoric Relations and Entity Change</head><p>In this section, we explain how we define anaphoric relations occurring in the recipes with state changes  is not reduced to its parts for the anaphor, and the antecedent is not mixed with other entities to produce a new entity for the anaphor, then we define such entities as near-identical. For example, an egg or a potato are accepted as near-identical entities before and after boiling.</p></div>
<div><head n="4.2.4">Bridging</head><p>In bridging, the antecedent is related and not iden-  The selection of ϵ as the antecedent collapses two different situations: (1) the span is not an entity, or (2) the span is an entity but it is not referent <ref type="bibr" target="#b10">(Lee et al., 2017)</ref> </p><formula xml:id="formula_1">g i = [x * START(i) , x * END(i) , ϕ(i)] ϕ(i) = WIDTH(END(i) -START(i)).</formula><p>START(i) and END(i) represent the starting and ending token indexes for g i , respectively. ϕ(i) is 465 the width feature of the span where WIDTH(.) is 466 the embedding function of the predefined bins of 467 <ref type="bibr">[1,</ref><ref type="bibr">2,</ref><ref type="bibr">3,</ref><ref type="bibr">4,</ref><ref type="bibr">8,</ref><ref type="bibr">16]</ref> as defined by Clark and Manning 468 <ref type="bibr">(2016)</ref>.</p></div>
<div><head>469</head><p>The use of head attention <ref type="bibr" target="#b10">(Lee et al., 2017</ref>; Yu and 470 <ref type="bibr">Poesio, 2020;</ref><ref type="bibr">Fang et al., 2021)</ref>   </p></div>
<div><head n="5.2.3">Anaphora Resolution</head></div>
<div><head>483</head><p>For anaphora resolution, the representation of span 484 pair g ij is obtained by concatenating the two span 485 embeddings [g i , g j ] and their element-wise multi-486 plication, g i • g j , among others:</p><formula xml:id="formula_2">487 g ij = [g i , g j , g i • g j , v i • v j , ϕ dist (i, j)] ϕ dist (i, j) = DISTANCE(START(j) -START(i))</formula></div>
<div><head>488</head><p>where the feature vector ϕ dist (i, j) is the distance 489 between the index of span i and span j. DIS-490 TANCE(•) is an embedding function of the prede-491 fined bins of <ref type="bibr">[1, 2, 3.., 30]</ref> as defined by Clark and 492 <ref type="bibr">Manning (2016)</ref>.</p></div>
<div><head>493</head><p>For anaphora resolution, we minimize the cross 494 entropy loss for candidate span pairs with 495 sigmoid(FFNN(g ij )). 496</p></div>
<div><head n="5.2.4">Relation Classification</head></div>
<div><head>497</head><p>As shown in Table <ref type="table">1</ref>, the number of observed hy-498 ponym, reduce, set-member, and part-of instance 499 relations is low. Therefore, we define the anaphoric 500 relations in term of the three main categories: coref-501 erence, near-identity, and bridging.</p></div>
<div><head>502</head><p>To learn the vectors for each relation of feature 503 vector g ij , we apply an FFNN layer:</p><formula xml:id="formula_3">504 coreference ij = FFNN(g ij ) n-identity ij = FFNN(g ij ) bridging ij = FFNN(g ij ).</formula><p>505 Then, we concatenate coreference ij , n-identity ij , 506 and bridging ij into the relation vector rel ij :</p><formula xml:id="formula_4">rel ij = [coreference ij , n-identity ij , briding ij ].</formula><p>To classify the anaphoric relation for each input pair, we then compute softmax(FFNN([g ij , rel ij ]).</p></div>
<div><head n="5.3">Temporal Features</head><p>Recipe instructions are written with an implied temporal order <ref type="bibr" target="#b6">(Jermsurawong and Habash, 2015)</ref>, and the entities involved go through this temporal order until the cooking is complete. We propose to select the number of instructions (see Figure <ref type="figure" target="#fig_3">2</ref>) as the temporal marker of entities instead of token distance ϕ dist (ij) to avoid issues with different instruction and entity lengths. We design our experiments to explain how the temporal stage of entities in action flows influences the pair representation of mentions in cooperating with the anaphora resolution model. Thus, we formulate our temporal features as</p><formula xml:id="formula_5">ϕ temp (i, j) = TEMPORAL(#a j -#a i )</formula><p>where TEMPORAL(•) is an embedding function that uses the list of bins <ref type="bibr">[1,2,3..,30]</ref>. #a i refers to the instruction index of span i and #a j to the instruction index of span j. We concatenate ϕ temp (i, j) in place of ϕ dist (i, j) to obtain the vector representation of a span pair:</p><formula xml:id="formula_6">g ij = [g i , g j , g i • g j , v i • v j , ϕ temp (i, j))].</formula><p>Token distance varies depending on the use of token numbers in instructions and entities. For example, the instruction mix red chili cinnamon stick cloves cumin seeds mustard seeds pepper garlic vinegar sugar and wine might also be written mix red chili cinnamon stick cloves cumin seeds mustard seeds followed by add pepper garlic vinegar in the bowl and mix with sugar and wine. Therefore, temporal features are not captured well by token distance in instructional language.</p><p>6 Experimental Setup</p></div>
<div><head n="6.1">Input</head><p>Cooking Instructions. To encode the recipes we use <ref type="bibr">BERT (Devlin et al., 2019)</ref>, a bidirectional transformer model trained on a masked language modeling task. First, we fine-tune BERT-largeuncased by using the YouCookII dataset <ref type="bibr">(Zhou et al., 2018a)</ref>   Our observations show that improvements in re-lation classification are propagated from the preceding anaphora resolution task in the end-to-end system for gold spans.</p></div>
<div><head>Additionally, binary mention detection results</head><p>show a precision of 0.92, a recall of 0.88, and an F1score of 0.90. However, the differences between the scores in anaphora resolution and relation classification results for the candidate and gold spans (see Table <ref type="table" target="#tab_3">2</ref>) reveal issues in transferring the mention features. We observe the main problem of mention detection in distinguishing the singletons.</p></div>
<div><head n="6.4.2">Anaphora Resolution</head><p>We detect a significant improvement in anaphora </p></div>
<div><head n="6.4.3">Relation Classification</head><p>Table <ref type="table" target="#tab_3">2</ref> shows that temporal features significantly improve anaphora resolution results for gold spans.</p><p>Especially for bridging pairs, a noteworthy benefit of temporal features can also be observed in gold and candidate spans. However, the mistakes can also be observed in the results of near-identity and coreference classification for candidate spans.</p></div>
<div><head>666</head><p>Overall, the end-to-end model suffers from mis-  </p></div><figure xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Examples from the YouCookII dataset showing the effect of the temporal changes on the entities and the referring expressions. Each row displays a different use of expressions and entities.</figDesc></figure>
<figure xml:id="fig_1"><head /><label /><figDesc>tecedent in a text refer to the same entity (identity relation), e.g., a black Mercedes and the car, while in bridging, an anaphor and its antecedent refer to different entities (non-identity relation), e.g., the car and the engine in the utterance I saw [a black Mercedes] parked outside the restaurant. [The car] belonged to Bill. [The engine] was still running. (Poesio and Artstein, 2008). As Rösiger et al. (2018) point out, bridging studies so far employ various methods to describe bridging dissimilar to the coreference definition. Nevertheless, both the concept of sameness in the coreference definition and the bridging associations neglect the changes referents may undergo. Therefore, the concept of near-identity was introduced by Recasens et al. (2010, 2012) as a middle ground between coreference and bridging. It addresses spatio-temporal changes of entities, e.g., the entity Postville in the text: On homecoming night [Postville] feels like Hometown, . . . it's become a miniature Ellis Island . . . For those who prefer [the old Postville], Mayor John Hyman has a simple . . . . This sample exemplifies the referential ambiguity, arising from two language expressions referring to "almost" the same entity, i.e., Postville and the old Postville (Recasens et al., 2010). Rösiger et al. (2018) and Poesio et al. (2018) claim that the introduction of the additional near-identity category in between coreference and bridging introduces more uncertainty. Nevertheless, we consider the near-identity relationship suitable because spatiotemporal changes are essential in recipes and the information they convey describes the visual content. Coreference and Bridging Annotations. Coreference is a well studied and clearly defined concept with some noticeable exceptions. In recent years several annotated corpora with different coreference guidelines have been released. OntoNotes v5.0 (Weischedel et al., 2012) exclusively focus on coreference using a schema similar to CoNLL-2012 (Pradhan et al., 2012) and WikiCoref (Ghad-dar and Langlais, 2016) with two different relations: one is identity, a symmetrical and transitive relation, and the other appositive for adjacent noun phrases. The extraction of the mentions and the use of prepositions in mentions are crucial questions for corerefence annotation (Rösiger et al., 2018;</figDesc></figure>
<figure xml:id="fig_2"><head /><label /><figDesc>et al. (2012) present ISnotes derived from OntoNotes with unrestricted bridging relations in addition to OntoNotes coreferences. The BASHI corpus (Rösiger, 2018) is based on OntoNotes content and the bridging relations in the BASHI corpus restrict the bridging anaphors to be truly anaphoric, i.e., not interpretable without an antecedent. All aforementioned annotation studies focus solely on the anaphoric relation between two discourse entities and neglect the change of entities over time. Instructional language raises a novel question in anaphora resolution: the definition of anaphoric relations based on the change of language with entities that undergo change. Therefore, RecipeRef (Fang et al., 2022) considers the state changes for preparing the annotation guideline for recipe text based on the ChEMU-Ref (Fang et al., 2021) anaphora annotation on chemistry patent documents. RecipeRef annotation was applied to the RecipeDB data (Batra et al., 2020) that was aggregated from recipe websites and each recipe was divided into two parts, the ingredients section, and the cooking instructions. The cooking instructions of RecipeDB contains only textual instructions without any visual content. The state changes are addressed in RecipeRef as a subtype of bridging relation, even though bridging is clearly defined as an associative relation in the literature</figDesc></figure>
<figure xml:id="fig_3"><head>228 ure 2 .</head><label>2</label><figDesc>Here, we use the YouCookII annotation, all 229 instructions for each video are manually annotated 230 with temporal boundaries and described by impera-231 tive English sentences. Since the video inputs show 232 the entities and actions clearly, the use of refer-233 ring expressions and null entities is very common 234 contrary to textual recipes. Instruction. Each video recipe contains 3 to 15 instructions. Each instruction is a temporallyaligned imperative sentence that is described according to the corresponding action on the video by human annotators. The instructions are not uttered by the instructor of the video but annotated by the human annotator from a third-person viewpoint while watching the video. Each instruction defines an action, i.e., a predicate, applied to a set of objects, i.e., entities. Video segments provide the visual status of the spatio-temporal changes for the mentioned entities for each instruction. Unlike other common types of texts, cooking instructions focus on processes and entities undergoing change during the process. So, the corresponding videos in the YouCookII dataset enable us to comprehend the use of referring expressions of entities for each change.</figDesc></figure>
<figure xml:id="fig_4"><head /><label /><figDesc>Figure 2: Example of annotation of a recipe from the YouCookII dataset named "stone baked pizza". The start point of each arrow denotes the anaphor and the end point the corresponding antecedent. The antecedent and anaphor pairs are highlighted in the same color. Grey boxes represent new entities (e.g., singletons) without antecedent.</figDesc></figure>
<figure xml:id="fig_5"><head /><label /><figDesc>tical; in contrast to coreference the anaphor is also not interchangeable with the given antecedent. As mentioned in Section 2, various phenomena are identified as bridging, resulting in diverse guidelines for bridging annotations. In accordance with the variety of associations, we assign different anaphora relations in our annotation schema.PRODUCED:We define PRODUCED as the relationship when the anaphor refers to an antecedent producing the anaphor. The antecedent is always an instruction with predicates and given ingredients. Here, the anaphor may refer to a group of instructions as the corresponding antecedent. For example, the dough is produced by the instruction mix water and flour or dressing is produced by the 358 instruction mix yogurt and pepper. 359 REDUCED: We define REDUCED as the bridg-360 ing relation linking an entity. The anaphor might 361 be a number expression (e.g., to the whole entity), 362 an indefinite pronoun (some), or an indefinite noun 363 phrase (e.g., one piece). We use REDUCED in cases 364 when the anaphor means a part of the correspond-365 ing antecedent, provided no mereological relation 366 exists. For example one slice is reduced from a 367 bread by the instruction slice the bread into pieces. 368 SET-MEMBER: In a recipe, SET-MEMBER refers 369 to a relation between a group of entities and its 370 definite subset. In other words, this relation defines 371 a bridge from a subset or element to the whole 372 collection. For example, cucumber, tomato, and 373 lettuce is an antecedent of the anaphor ingredients 374 in cut the ingredients. 375 PART-OF: The antecedent may associate in a 376 mereological relationship with the anaphor, and 377 cannot be captured well by pre-defined lexical re-378 lations. For example, the antecedent lemon in the 379 instruction cut the lemon relates to the anaphor 380 seeds in take the seeds out. year Master student in Computational 385 Linguistics. Five rounds of annotation training 386 were completed prior to beginning the official an-387 notation. In each round, the two annotators indifor the creation of a new entity and refer-394 ence, α = 0.95 for the selection of the antecedent 395 and α = 0.93 for selection of anaphoric relations. , we present our end-to-end multi-398 modal anaphora resolution model. Figure 3 shows 399 our joint neural model similar to Yu and Poesio 400 (2020) and Fang et al. (2021), adapted from Lee 401 et al. (2017). We extend the model with novel 402 temporal features, see Section 5.3.</figDesc></figure>
<figure xml:id="fig_6"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Proposed anaphora resolution architecture. The CNN Layer is a convolutional layer with five input channels (one per frame). The FFNN Block refers to a layer block with FFNN+ReLU+Dropout, w t indicates the t-th word of Recipe R. ViT is a Transformer-based model to represent the features of the video inputs.</figDesc></figure>
<figure xml:id="fig_7"><head /><label /><figDesc>is very common in 471 coreference/anaphora resolution models. However, 472 we disregard the head representation of spans for 473 two reasons: (1) the common use of null anaphors 474 in our data: instead the instruction a i of the null 475 anaphor is used for extracting the vector represen-476 tation, (2) the self-attention mechanism (Vaswani 477 et al., 2017) of the BERT model implicitly captures 478 the mention head word. 479 The mention score softmax(FFNN(g i )) is com-480 puted for each span, and the mention model is 481 trained using the cross-entropy loss.</figDesc></figure>
<figure xml:id="fig_8"><head /><label /><figDesc>482</figDesc></figure>
<figure xml:id="fig_9"><head>573(</head><label /><figDesc>2020), we analyze the performance of our end-to-574 end anaphora resolution model with its subtasks. 575 For mention detection, anaphora resolution and 576 relation classification we report F1-scores. 577 To evaluate mention detection, precision is com-578 puted as the fraction of correctly detected mentions 579 among all detected mentions whereas recall is the 580 fraction of correctly detected mentions among all 581 gold mentions. The F1-score for anaphora resolution is computed where precision is the result of dividing the number of correctly predicted pairs by the total number of predicted pairs and recall is computed by dividing the number of correctly predicted pairs by the total number of gold pairs. To evaluate relation classification we compute the F1-score where precision is computed by dividing the number of correctly predicted relations by the total number of predicted relations and recall is computed by dividing the number of correctly predicted relations by the total number of gold re-We investigate the anaphora resolution and relation classification results of gold and candidate spans comparing the F1-scores with the distance and temporal features. Overall, our results in Table 2 demonstrate that replacing token distance with our temporal features improves anaphora resolution and relation classification for both candidate and gold spans.The performance of each task is propagated to subsequent tasks due to the sequential structure of the end-to-end system (see Section 5). The difference between the results of candidate and gold spans demonstrates that the mention detection model propagates errors to anaphora resolution and relation classification. For example, temporal features are not predictive features for anaphoric relations, but they are valuable for finding the antecedent of an anaphor, i.e., anaphora resolution.</figDesc></figure>
<figure xml:id="fig_10"><head /><label /><figDesc>resolution with temporal features, since temporal features often conspire to reduce unwelcome lexical similarity. For example, potato-→ it -→ potato, the first potato is the antecedent of it, and it is the antecedent of the second potato. Temporal features prevent predicting the first potato as an antecedent for the second potato and designate the anaphora link from the second potato to it, because it is in the instruction closer in the temporal line. The improvements with temporal features reveal the issues of contextualized embeddings. While we use contextualized embeddings, the bias of lexical similarity induces complexity to link the anaphor with a correct antecedent; as recurrent in the bacon -→ bacon -→ fried bacon sample in Figure 2. The sliced bacon is predicted as the antecedent of the bacon of instruction 3, and it is also the antecedent of fried bacon of instruction 8. This issue occurs for rare entities and predicates. When we compare the false positives in accordance with temporality, the improvement due to temporal features mainly affects pronoun resolution. Hence, we observe that the antecedents of pronouns are closer to the pronouns. Some anomalies can be observed in the results of anaphora resolution with candidate spans due to the propagated error from mention detection. For example, we have the candidate spans the pizza, pizza dough, and the pizza dough for the mention the pizza dough of instruction 4 with the same temporal features.</figDesc></figure>
<figure xml:id="fig_11"><head /><label /><figDesc>relations are due to sin-675 gleton spans (non-referents) whereas false positive 676 coreference and near-identical relations are due to 677 the preference for surface words with/without state 678 changes. For instance, in the example wash the egg 679 coreference ------→ boil the egg near-identity -------→ crack the egg, 680 the use of the same words for changing entities 681 introduces an immense modelling challenge. 682 7 Conclusion and Future Work 683 We introduce a novel anaphora annotation scheme 684 including the state changes of entities and near-685 identical relations. This fresh approach relies on 686 video inputs for visual observation for anaphora an-687 notation. Likewise, we provide baseline anaphora 688 resolution results with novel temporal features on 689 the annotated data. In future work, the mention 690 detection model will be designed to perform with 691 null entities and singleton mentions to improve the 692 performance of the end-to-end model. Addition-693 ally, different visual feature extraction methods for 694 single frames, e.g., CLIP (Radford et al., 2021) 695 or for videos, e.g., S3D (Xie et al., 2018) will be 696 investigated to find the best way of learning from 697 cooking videos for anaphora resolution.</figDesc></figure>
<figure xml:id="fig_12"><head /><label /><figDesc>to thank Iuliia Zaitova for help-700 ing with the annotation study. This research was 701 funded by the joint IMPRESS (01|S20076) project 702 between the French National Institute for Research 703 in Digital Science and Technology (Inria) and the</figDesc></figure>
<figure type="table" xml:id="tab_0"><head>000 unconstrained instructional 216 videos from 89 cooking recipes. The videos pro- 217 vide a visual input of the corresponding objects to 218 observe the changes clearly. To obtain a variety of 219 ingredients and their state changes, we choose at</head><label /><figDesc /><table><row><cell /><cell /><cell>Train</cell><cell>Test</cell></row><row><cell /><cell>Coreference</cell><cell>891</cell><cell>330</cell></row><row><cell /><cell>Hyponmy</cell><cell>47</cell><cell>10</cell></row><row><cell /><cell>Near-Identity</cell><cell>699</cell><cell>217</cell></row><row><cell /><cell>Bridging</cell><cell>602</cell><cell>217</cell></row><row><cell /><cell>Produce</cell><cell>507</cell><cell>182</cell></row><row><cell /><cell>Reduce</cell><cell>40</cell><cell>22</cell></row><row><cell /><cell>Set-member</cell><cell>44</cell><cell>9</cell></row><row><cell /><cell>Part-of</cell><cell>11</cell><cell>4</cell></row><row><cell /><cell>Instruction</cell><cell>2,829</cell><cell>984</cell></row><row><cell /><cell>Token</cell><cell cols="2">8,754 2,966</cell></row><row><cell /><cell>Recipe</cell><cell>264</cell><cell>89</cell></row><row><cell /><cell>Entity</cell><cell cols="2">5,669 1,927</cell></row><row><cell /><cell>Null Entity</cell><cell>465</cell><cell>168</cell></row><row><cell /><cell>Pronoun Entity</cell><cell>206</cell><cell>61</cell></row><row><cell /><cell cols="3">Table 1: Statistics of annotated data with the number of</cell></row><row><cell /><cell cols="3">annotated samples with anaphoric relations.</cell></row><row><cell /><cell cols="3">of state changes by annotating the null entities in</cell><cell>207</cell></row><row><cell /><cell cols="3">recipes; (4) the judgement of anaphoric relations</cell><cell>208</cell></row><row><cell /><cell cols="3">of state changes and different semantic relations</cell><cell>209</cell></row><row><cell /><cell cols="3">such as identity, non-identity, near-identity, and</cell><cell>210</cell></row><row><cell /><cell>association.</cell><cell /><cell>211</cell></row><row><cell /><cell>3 Corpus</cell><cell /><cell>212</cell></row><row><cell /><cell cols="3">We use the YouCookII dataset (Zhou et al., 2018a)</cell><cell>213</cell></row><row><cell /><cell cols="3">that includes manually provided descriptions (i.e.,</cell><cell>214</cell></row><row><cell /><cell cols="3">instructions) of actions in the cooking videos. The</cell><cell>215</cell></row><row><cell /><cell cols="3">dataset contains 2,220</cell></row><row><cell /><cell cols="3">least three random samples for each the 89 cooking</cell><cell>221</cell></row><row><cell /><cell cols="3">recipes for the training set and one sample for the</cell><cell>222</cell></row><row><cell /><cell cols="3">test set. There is no intersection between training</cell><cell>223</cell></row><row><cell /><cell cols="3">and test recipe samples. In total, we have 264 train-</cell><cell>224</cell></row><row><cell /><cell cols="3">ing documents and 89 test documents as shown in</cell><cell>225</cell></row><row><cell /><cell>Table 1.</cell><cell /><cell>226</cell></row><row><cell>. Besides, null anaphors are not included in the annotation of RecipeRef, despite their frequent use in recipes.</cell><cell cols="3">Recipe A recipe is text containing a list of cook-ing instructions with a list of ingredients, see Fig-</cell><cell>227</cell></row><row><cell>Several important questions remain open regard-</cell><cell /><cell /></row><row><cell>ing anaphora resolution, and RecipeRef annotation,</cell><cell /><cell /></row><row><cell>including: (1) interpretation of the state changes</cell><cell /><cell /></row><row><cell>of entities over time; (2) addressing the referring</cell><cell /><cell /></row><row><cell>expression in anaphora resolution with data that</cell><cell /><cell /></row><row><cell>has different modalities; (3) obtaining the sequence</cell><cell /><cell /></row></table></figure>
<figure type="table" xml:id="tab_1"><head /><label /><figDesc>For example the herb refers to the entities mint and parsley in the instruction Wash mint and parsley. Here again the anaphor may refer to a group of entities as the cor-</figDesc><table><row><cell>responding antecedent.</cell><cell /></row><row><cell>4.2.3 Near-Identity</cell><cell /></row><row><cell>Some actions alter either the physical or chemical</cell><cell /></row><row><cell>properties of the entities involved. For instance,</cell><cell /></row><row><cell>boiling a potato or an egg changes their chemi-</cell><cell /></row><row><cell>cal properties whereas cutting a potato or an egg</cell><cell /></row><row><cell>changes their physical properties. Here, anaphor</cell><cell /></row><row><cell>and antecedent entities are neither identical nor</cell><cell /></row><row><cell>associated, they are partially the same entity shar-</cell><cell /></row><row><cell>ing many crucial commonalities, but differing in</cell><cell /></row><row><cell>at least one crucial dimension. For this type of</cell><cell /></row><row><cell>anaphoric relation, Recasens et al. (2010) propose</cell><cell /></row><row><cell>the near-identity relation to describe the spatio-</cell><cell /></row><row><cell /><cell>299</cell></row><row><cell>For example, a tomato is the same tomato after</cell><cell>300</cell></row><row><cell>washing, or a piece of meat is the same amount of</cell><cell>301</cell></row><row><cell>meat after putting it in a pan.</cell><cell>302</cell></row><row><cell>4.2.2 Hyponymy</cell><cell /></row></table><note><p><p><p><p><p>The antecedent and anaphor pairs are highlighted in the same color. Grey boxes represent new entities (e.g., singletons) without antecedent.</p>of entities, see Figure</p>2</p>. It is worth noting that 284 the recipe videos are exploited to judge the "same-285 ness" of entities after an action (e.g., wash, cut, 286 etc.) was applied. Thus, the visual features from 287 cooking videos clarify the state change of enti-288 ties in the instructions and our annotation does not 289 rely only on the mental image of entities based on 290 text only settings as in other coreference datasets 291 (Weischedel et al., 2012; Pradhan et al., 2012) and 292 anaphora datasets (Roesiger, 2016; Poesio and Art-293 stein, 2008; Fang et al., 2021, 2022).</p>294 4.2.1 Coreference 295 The anaphor and the antecedent are identical and 296 point to the same entity. Some actions such as 297 washing or transferring the result to another con-298 tainer preserve the properties of the entity involved. 303 The hyponymy relation was considered as bridging 304 by Poesio and Vieira (1998), however Baumann and Riester (2012) use the term not as context-306 dependent but as "lexical accessibility" to define 307 the hyponymy relation between words as corefer-308 ence, as Rösiger et al. (2018). temporal changes of the entities as a middle ground between coreference and bridging. Even though Rösiger et al. (2018) claim that additional categories between coreference and bridging introduce further uncertainty which makes the annotation process more arduous, we consider the near identity relationship more suitable because spatio-temporal changes are essential in recipes and the information they convey describes the visual content. Therefore, if they are not the same entity, the antecedent</p></note></figure>
<figure type="table" xml:id="tab_3"><head>Table 2 :</head><label>2</label><figDesc>after removing our test recipes. Because of sub word embeddings, there are different Average evaluation results over 3 runs of the proposed anaphora resolution model on our annotated test data for 200 epochs. w Temporal and w/o Temporal refer to the results with or without temporal features, respectively. Candidate Spans refers to all the possible spans of continuous tokens extracted from the recipes whereas Gold Spans refers the mentions with nominal phrases, null anaphors, and instructions. choices of presenting words. We use the first sub-</figDesc><table><row><cell /><cell /><cell /><cell>Candidate Spans</cell><cell /><cell /><cell>Gold Spans</cell></row><row><cell /><cell /><cell cols="6">Precision Recall F1-score Precision Recall F1-score</cell></row><row><cell /><cell>w/o Temporal</cell><cell /><cell /><cell /><cell /><cell /></row><row><cell /><cell cols="2">Anaphora Resolution 48.1</cell><cell>34.1</cell><cell>39.9</cell><cell>48.9</cell><cell>46.7</cell><cell>47.8</cell></row><row><cell /><cell>Coreference</cell><cell>34.2</cell><cell>43.4</cell><cell>38.2</cell><cell>40.1</cell><cell>47.5</cell><cell>43.5</cell></row><row><cell /><cell>Near-identity</cell><cell>66.8</cell><cell>37.0</cell><cell>47.7</cell><cell>78.5</cell><cell>38.8</cell><cell>51.9</cell></row><row><cell /><cell>Bridging</cell><cell>12.0</cell><cell>37.5</cell><cell>18.2</cell><cell>16.7</cell><cell>45.0</cell><cell>24.3</cell></row><row><cell /><cell>Overall Relation</cell><cell>21.6</cell><cell>44.6</cell><cell>29.2</cell><cell>28.4</cell><cell>50.3</cell><cell>36.3</cell></row><row><cell /><cell>w Temporal</cell><cell /><cell /><cell /><cell /><cell /></row><row><cell /><cell cols="2">Anaphora Resolution 48.7</cell><cell>34.2</cell><cell>40.0</cell><cell>51.2</cell><cell>50.0</cell><cell>50.6</cell></row><row><cell /><cell>Coreference</cell><cell>29.1</cell><cell>45.8</cell><cell>35.6</cell><cell>46.1</cell><cell>50.6</cell><cell>48.3</cell></row><row><cell /><cell>Near-identity</cell><cell>57.0</cell><cell>33.8</cell><cell>42.4</cell><cell>90.1</cell><cell>44.7</cell><cell>59.7</cell></row><row><cell /><cell>Bridging</cell><cell>14.7</cell><cell>41.9</cell><cell>21.7</cell><cell>24.4</cell><cell>43.7</cell><cell>31.3</cell></row><row><cell /><cell>Overall Relation</cell><cell>22.6</cell><cell>46.2</cell><cell>30.4</cell><cell>32.6</cell><cell>54.3</cell><cell>40.8</cell></row><row><cell>551</cell><cell /><cell /><cell /><cell /><cell /><cell /></row><row><cell>552</cell><cell cols="3">token for representing the word as proposed by</cell><cell /><cell /><cell /></row><row><cell>553</cell><cell cols="3">Devlin et al. (2019). Additionally, due to the struc-</cell><cell /><cell /><cell /></row><row><cell>554</cell><cell cols="3">ture of multiple successive layers, the last hidden</cell><cell /><cell /><cell /></row><row><cell>555</cell><cell cols="3">layer is used to represent the words in recipes.</cell><cell /><cell /><cell /></row><row><cell>556</cell><cell cols="3">Video Frames. To encode each video frame, ViT</cell><cell /><cell /><cell /></row><row><cell>557</cell><cell cols="3">(Dosovitskiy et al., 2021) is pre-trained on Ima-</cell><cell /><cell /><cell /></row><row><cell>558</cell><cell cols="3">geNet (Russakovsky et al., 2015) and fine-tuned on</cell><cell /><cell /><cell /></row><row><cell>559</cell><cell cols="3">Food-101 (Bossard et al., 2014) images. In the end,</cell><cell /><cell /><cell /></row><row><cell>560</cell><cell cols="3">each instruction (i.e., segment) is represented by a</cell><cell /><cell /><cell /></row><row><cell>561</cell><cell>3,840-dimensional vector v i .</cell><cell /><cell /><cell /><cell /><cell /></row><row><cell>562</cell><cell>6.2 Experiments</cell><cell /><cell /><cell /><cell /><cell /></row><row><cell>563</cell><cell cols="3">Candidate Spans Without any pruning, we con-</cell><cell /><cell /><cell /></row><row><cell>564</cell><cell cols="3">sider all continuous tokens (Clark and Manning,</cell><cell /><cell /><cell /></row><row><cell>565</cell><cell cols="3">2016; Lee et al., 2017) as a potential spans for the</cell><cell /><cell /><cell /></row><row><cell>566</cell><cell>training and testing phases.</cell><cell /><cell /><cell /><cell /><cell /></row><row><cell>567</cell><cell cols="3">Gold Spans In order to investigate the perfor-</cell><cell /><cell /><cell /></row><row><cell>568</cell><cell cols="3">mance of anaphora resolution and relation classifi-</cell><cell /><cell /><cell /></row><row><cell>569</cell><cell cols="3">cation models without mention detection noise, we</cell><cell /><cell /><cell /></row><row><cell>570</cell><cell cols="3">also consider gold spans for the training and testing</cell><cell /><cell /><cell /></row><row><cell>571</cell><cell>phases.</cell><cell /><cell /><cell /><cell /><cell /></row><row><cell>572</cell><cell>6.3 Evaluation</cell><cell /><cell /><cell /><cell /><cell /></row><row><cell /><cell cols="3">Following Hou et al. (2018) and Yu and Poesio</cell><cell /><cell /><cell /></row></table></figure>
			<note place="foot" xml:id="foot_0"><p>Journal of Semantics, 15(1):83-113.</p></note>
			<note place="foot" xml:id="foot_1"><p>Devansh Batra, Nirav Diwan, Utkarsh Upadhyay,</p></note>
			<note place="foot" xml:id="foot_2"><p>Jushaan Singh Kalra, Tript Sharma, Aman Kumar</p></note>
			<note place="foot" xml:id="foot_3"><p>Sharma, Dheeraj Khanna, Jaspreet Singh Marwah, 712</p></note>
		</body>
		<back>
			<div type="annex">
<div><head>German Research Center for Artificial Intelligence</head></div>
<div><head n="705">(DFKI).</head><p>Srilakshmi Kalathil, Navjot Singh, Rudraksh Tuwani,</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Bridging. 768 Evaluation</title>
		<author>
			<persName><forename type="first">Nicholas</forename><surname>Asher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Lascarides</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">LREC'16)</title>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page">769</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Unrestricted bridging resolution</title>
		<author>
			<persName><forename type="first">Yufang</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Katja</forename><surname>Markert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Strube</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="237" to="284" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Events are not simple: Identity, non-identity, and quasi-identity</title>
		<author>
			<persName><forename type="first">Eduard</forename><surname>Hovy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Teruko</forename><surname>Mitamura</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Felisa</forename><surname>Verdejo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jun</forename><surname>Araki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Philpot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Workshop on Events: Definition, Detection, Coreference, and Representation</title>
		<meeting><address><addrLine>Atlanta, Georgia</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="21" to="28" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Finding" it": Weakly-supervised reference-aware visual grounding in instructional videos</title>
		<author>
			<persName><surname>De-An</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shyamal</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lucio</forename><surname>Buch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Animesh</forename><surname>Dery</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Li</forename><surname>Garg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Juan</forename><forename type="middle">Carlos</forename><surname>Fei-Fei</surname></persName>
		</author>
		<author>
			<persName><surname>Niebles</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="5948" to="5957" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Unsupervised visual-linguistic reference resolution in instructional videos</title>
		<author>
			<persName><surname>De-An</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joseph</forename><forename type="middle">J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Li</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Juan</forename><forename type="middle">Carlos</forename><surname>Fei-Fei</surname></persName>
		</author>
		<author>
			<persName><surname>Niebles</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="2183" to="2192" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Visual storytelling</title>
		<author>
			<persName><forename type="first">Ting-Hao</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Francis</forename><surname>Ferraro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nasrin</forename><surname>Mostafazadeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ishan</forename><surname>Misra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aishwarya</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaodong</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pushmeet</forename><surname>Kohli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dhruv</forename><surname>Batra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="1233" to="1239" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Predicting the structure of cooking recipes</title>
		<author>
			<persName><forename type="first">Jermsak</forename><surname>Jermsurawong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nizar</forename><surname>Habash</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D15-1090</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Lisbon, Portugal</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="781" to="786" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Mise en place: Unsupervised interpretation of instructional recipes</title>
		<author>
			<persName><forename type="first">Chloé</forename><surname>Kiddon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thandavam</forename><surname>Ganesa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luke</forename><surname>Ponnuraj</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yejin</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName><surname>Choi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="982" to="992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Generating a novel dataset of multimodal referring expressions</title>
		<author>
			<persName><forename type="first">Nikhil</forename><surname>Krishnaswamy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Pustejovsky</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/W19-0507</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th International Conference on Computational Semantics -Short Papers</title>
		<meeting>the 13th International Conference on Computational Semantics -Short Papers<address><addrLine>Gothenburg, Sweden</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="44" to="51" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">A formal analysis of multimodal referring strategies under common ground</title>
		<author>
			<persName><forename type="first">Nikhil</forename><surname>Krishnaswamy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Pustejovsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twelfth Language Resources and Evaluation Conference</title>
		<meeting>the Twelfth Language Resources and Evaluation Conference<address><addrLine>Marseille, France</addrLine></address></meeting>
		<imprint>
			<publisher>European Language Resources Association</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="5919" to="5927" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">End-to-end neural coreference resolution</title>
		<author>
			<persName><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luheng</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mike</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D17-1018</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Copenhagen, Denmark</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="188" to="197" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Collective classification for fine-grained information status</title>
		<author>
			<persName><forename type="first">Katja</forename><surname>Markert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yufang</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Strube</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 50th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="795" to="804" />
		</imprint>
	</monogr>
	<note>Long Papers</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Anaphoric annotation in the ARRAU corpus</title>
		<author>
			<persName><forename type="first">Massimo</forename><surname>Poesio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ron</forename><surname>Artstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Sixth International Conference on Language Resources and Evaluation (LREC'08)</title>
		<meeting>the Sixth International Conference on Language Resources and Evaluation (LREC'08)<address><addrLine>Marrakech, Morocco</addrLine></address></meeting>
		<imprint>
			<publisher>European Language Resources Association (ELRA</publisher>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Anaphora resolution with the ARRAU corpus</title>
		<author>
			<persName><forename type="first">Massimo</forename><surname>Poesio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yulia</forename><surname>Grishina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Varada</forename><surname>Kolhatkar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nafise</forename><surname>Moosavi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ina</forename><surname>Roesiger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Roussel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fabian</forename><surname>Simonjetz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexandra</forename><surname>Uma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Olga</forename><surname>Uryupina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Juntao</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Heike</forename><surname>Zinsmeister</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/W18-0702</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First Workshop on Computational Models of Reference, Anaphora and Coreference</title>
		<meeting>the First Workshop on Computational Models of Reference, Anaphora and Coreference<address><addrLine>New Orleans, Louisiana</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="11" to="22" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">A corpusbased investigation of definite description use</title>
		<author>
			<persName><forename type="first">Massimo</forename><surname>Poesio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Renata</forename><surname>Vieira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="183" to="216" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Conll-2012 shared task: Modeling multilingual unrestricted coreference in ontonotes</title>
		<author>
			<persName><forename type="first">Alessandro</forename><surname>Sameer Pradhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nianwen</forename><surname>Moschitti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Olga</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuchen</forename><surname>Uryupina</surname></persName>
		</author>
		<author>
			<persName><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Joint Conference on EMNLP and CoNLL-Shared Task</title>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="1" to="40" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Learning transferable visual models from natural language supervision</title>
		<author>
			<persName><forename type="first">Alec</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jong</forename><forename type="middle">Wook</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Hallacy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aditya</forename><surname>Ramesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gabriel</forename><surname>Goh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sandhini</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Girish</forename><surname>Sastry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amanda</forename><surname>Askell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pamela</forename><surname>Mishkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jack</forename><surname>Clark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="8748" to="8763" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title />
		<author>
			<persName><surname>Pmlr</surname></persName>
		</author>
		<imprint />
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">A typology of near-identity relations for coreference (NIDENT)</title>
		<author>
			<persName><forename type="first">Marta</forename><surname>Recasens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eduard</forename><surname>Hovy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">Antònia</forename><surname>Martí</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Seventh International Conference on Language Resources and Evaluation (LREC'10)</title>
		<meeting>the Seventh International Conference on Language Resources and Evaluation (LREC'10)<address><addrLine>Valletta, Malta</addrLine></address></meeting>
		<imprint>
			<publisher>European Language Resources Association (ELRA)</publisher>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Identity, non-identity, and near-identity: Addressing the complexity of coreference</title>
		<author>
			<persName><forename type="first">Marta</forename><surname>Recasens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eduard</forename><surname>Hovy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M Antònia</forename><surname>Martí</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Lingua</title>
		<imprint>
			<biblScope unit="volume">121</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1138" to="1152" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Annotating near-identity from coreference disagreements</title>
		<author>
			<persName><forename type="first">Marta</forename><surname>Recasens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">Antònia</forename><surname>Martí</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Constantin</forename><surname>Orasan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eighth International Conference on Language Resources and Evaluation (LREC'12)</title>
		<meeting>the Eighth International Conference on Language Resources and Evaluation (LREC'12)<address><addrLine>Istanbul, Turkey</addrLine></address></meeting>
		<imprint>
			<publisher>European Language Resources Association (ELRA</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="165" to="172" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">SciCorp: A corpus of English scientific articles annotated for information status analysis</title>
		<author>
			<persName><forename type="first">Ina</forename><surname>Roesiger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Tenth International Conference on Language Resources and Evaluation (LREC'16)</title>
		<meeting>the Tenth International Conference on Language Resources and Evaluation (LREC'16)<address><addrLine>Portorož, Slovenia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="1743" to="1749" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</teiCorpus></text>
</TEI>