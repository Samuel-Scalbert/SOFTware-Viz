<?xml version='1.0' encoding='utf-8'?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" version="1.1" xsi:schemaLocation="http://www.tei-c.org/ns/1.0 http://api.archives-ouvertes.fr/documents/aofr-sword.xsd">
  <teiHeader>
    <fileDesc>
      <titleStmt>
        <title>HAL TEI export of hal-02065993</title>
      </titleStmt>
      <publicationStmt>
        <distributor>CCSD</distributor>
        <availability status="restricted">
          <licence target="http://creativecommons.org/licenses/by/4.0/">Distributed under a Creative Commons Attribution 4.0 International License</licence>
        </availability>
        <date when="2024-04-27T09:10:40+02:00" />
      </publicationStmt>
      <sourceDesc>
        <p part="N">HAL API platform</p>
      </sourceDesc>
    </fileDesc>
  </teiHeader>
  <text>
    <body>
      <listBibl>
        <biblFull>
          <titleStmt>
            <title xml:lang="en">Speeding up RDF aggregate discovery through sampling</title>
            <author role="aut">
              <persName>
                <forename type="first">Ioana</forename>
                <surname>Manolescu</surname>
              </persName>
              <email type="md5">198b5d07a89578a2f2e563c17579cde7</email>
              <email type="domain">inria.fr</email>
              <idno type="idhal" notation="string">ioana-manolescu</idno>
              <idno type="idhal" notation="numeric">742652</idno>
              <idno type="halauthorid" notation="string">16724-742652</idno>
              <idno type="ORCID">https://orcid.org/0000-0002-0425-2462</idno>
              <idno type="GOOGLE SCHOLAR">https://scholar.google.com/citations?user=q6Ft35wAAAAJ&amp;hl=en</idno>
              <affiliation ref="#struct-451441" />
            </author>
            <author role="aut">
              <persName>
                <forename type="first">Mirjana</forename>
                <surname>Mazuran</surname>
              </persName>
              <idno type="halauthorid">715423-0</idno>
              <affiliation ref="#struct-451441" />
            </author>
            <editor role="depositor">
              <persName>
                <forename>Mirjana</forename>
                <surname>Mazuran</surname>
              </persName>
              <email type="md5">58ae00caea3b0374a9394f233cfd76a8</email>
              <email type="domain">inria.fr</email>
            </editor>
            <funder>∗M. Mazuran is supported by the H2020 research program under grant.</funder>
          </titleStmt>
          <editionStmt>
            <edition n="v1" type="current">
              <date type="whenSubmitted">2019-03-19 17:03:35</date>
              <date type="whenModified">2023-03-24 14:53:10</date>
              <date type="whenReleased">2019-03-20 09:17:00</date>
              <date type="whenProduced">2019-03-26</date>
              <date type="whenEndEmbargoed">2019-03-13</date>
              <ref type="file" target="https://inria.hal.science/hal-02065993/document">
                <date notBefore="2019-03-13" />
              </ref>
              <ref type="file" subtype="author" n="1" target="https://inria.hal.science/hal-02065993/file/main-bigvis2019-CAMERA-READY.pdf">
                <date notBefore="2019-03-13" />
              </ref>
            </edition>
            <respStmt>
              <resp>contributor</resp>
              <name key="712527">
                <persName>
                  <forename>Mirjana</forename>
                  <surname>Mazuran</surname>
                </persName>
                <email type="md5">58ae00caea3b0374a9394f233cfd76a8</email>
                <email type="domain">inria.fr</email>
              </name>
            </respStmt>
          </editionStmt>
          <publicationStmt>
            <distributor>CCSD</distributor>
            <idno type="halId">hal-02065993</idno>
            <idno type="halUri">https://inria.hal.science/hal-02065993</idno>
            <idno type="halBibtex">manolescu:hal-02065993</idno>
            <idno type="halRefHtml">&lt;i&gt;BigVis 2019 - 2nd International Workshop on Big Data Visual Exploration and Analytics&lt;/i&gt;, Mar 2019, Lisbon, Portugal</idno>
            <idno type="halRef">BigVis 2019 - 2nd International Workshop on Big Data Visual Exploration and Analytics, Mar 2019, Lisbon, Portugal</idno>
          </publicationStmt>
          <seriesStmt>
            <idno type="stamp" n="X">Ecole Polytechnique</idno>
            <idno type="stamp" n="CNRS">CNRS - Centre national de la recherche scientifique</idno>
            <idno type="stamp" n="INRIA">INRIA - Institut National de Recherche en Informatique et en Automatique</idno>
            <idno type="stamp" n="LIX">Laboratoire d'informatique de l'école polytechnique</idno>
            <idno type="stamp" n="INRIA-SACLAY" corresp="INRIA">INRIA Saclay - Ile de France</idno>
            <idno type="stamp" n="X-LIX" corresp="X">Laboratoire d'informatique de l'X (LIX)</idno>
            <idno type="stamp" n="X-DEP" corresp="X">Polytechnique</idno>
            <idno type="stamp" n="X-DEP-INFO" corresp="X-DEP">Département d'informatique</idno>
            <idno type="stamp" n="INRIA_TEST">INRIA - Institut National de Recherche en Informatique et en Automatique</idno>
            <idno type="stamp" n="TESTALAIN1">TESTALAIN1</idno>
            <idno type="stamp" n="INRIA2">INRIA 2</idno>
            <idno type="stamp" n="UNIV-PARIS-SACLAY">Université Paris-Saclay</idno>
            <idno type="stamp" n="INRIA-SACLAY-2015" corresp="UNIV-PARIS-SACLAY">INRIA-SACLAY-2015</idno>
            <idno type="stamp" n="X-SACLAY" corresp="UNIV-PARIS-SACLAY">X-SACLAY</idno>
            <idno type="stamp" n="GS-COMPUTER-SCIENCE">Graduate School Computer Science</idno>
            <idno type="stamp" n="INRIA_WEB">Inria &amp; web</idno>
          </seriesStmt>
          <notesStmt>
            <note type="audience" n="2">International</note>
            <note type="invited" n="0">No</note>
            <note type="popular" n="0">No</note>
            <note type="peer" n="1">Yes</note>
            <note type="proceedings" n="1">Yes</note>
          </notesStmt>
          <sourceDesc>
            <biblStruct>
              <analytic>
                <title xml:lang="en">Speeding up RDF aggregate discovery through sampling</title>
                <author role="aut">
                  <persName>
                    <forename type="first">Ioana</forename>
                    <surname>Manolescu</surname>
                  </persName>
                  <email type="md5">198b5d07a89578a2f2e563c17579cde7</email>
                  <email type="domain">inria.fr</email>
                  <idno type="idhal" notation="string">ioana-manolescu</idno>
                  <idno type="idhal" notation="numeric">742652</idno>
                  <idno type="halauthorid" notation="string">16724-742652</idno>
                  <idno type="ORCID">https://orcid.org/0000-0002-0425-2462</idno>
                  <idno type="GOOGLE SCHOLAR">https://scholar.google.com/citations?user=q6Ft35wAAAAJ&amp;hl=en</idno>
                  <affiliation ref="#struct-451441" />
                </author>
                <author role="aut">
                  <persName>
                    <forename type="first">Mirjana</forename>
                    <surname>Mazuran</surname>
                  </persName>
                  <idno type="halauthorid">715423-0</idno>
                  <affiliation ref="#struct-451441" />
                </author>
              </analytic>
              <monogr>
                <meeting>
                  <title>BigVis 2019 - 2nd International Workshop on Big Data Visual Exploration and Analytics</title>
                  <date type="start">2019-03-26</date>
                  <settlement>Lisbon</settlement>
                  <country key="PT">Portugal</country>
                </meeting>
                <imprint>
                  <date type="datePub">2019-03-26</date>
                </imprint>
              </monogr>
            </biblStruct>
          </sourceDesc>
          <profileDesc>
            <langUsage>
              <language ident="en">English</language>
            </langUsage>
            <textClass>
              <classCode scheme="halDomain" n="info">Computer Science [cs]</classCode>
              <classCode scheme="halDomain" n="info.info-db">Computer Science [cs]/Databases [cs.DB]</classCode>
              <classCode scheme="halTypology" n="COMM">Conference papers</classCode>
              <classCode scheme="halOldTypology" n="COMM">Conference papers</classCode>
              <classCode scheme="halTreeTypology" n="COMM">Conference papers</classCode>
            </textClass>
            <abstract xml:lang="en">
              <p>RDF graphs can be large and complex; finding out interesting information within them is challenging. One easy method for users to discover such graphs is to be shown interesting aggregates (un-der the form of two-dimensional graphs, i.e., bar charts), where interestingness is evaluated through statistics criteria. Dagger [5] pioneered this approach, however its is quite inefficient, in particular due to the need to evaluate numerous, expensive aggregation queries. In this work, we describe Dagger + , which builds upon Dagger and leverages sampling to speed up the evaluation of potentially interesting aggregates. We show that Dagger + achieves very significant execution time reductions, while reaching results very close to those of the original, less efficient system.</p>
            </abstract>
          </profileDesc>
        </biblFull>
      </listBibl>
    </body>
    <back>
      <listOrg type="structures">
        <org type="researchteam" xml:id="struct-451441" status="VALID">
          <idno type="RNSR">201622056J</idno>
          <orgName>Rich Data Analytics at Cloud Scale</orgName>
          <orgName type="acronym">CEDAR</orgName>
          <date type="start">2016-01-01</date>
          <desc>
            <address>
              <addrLine>1 rue Honoré d'Estienne d'OrvesBâtiment Alan TuringCampus de l'École Polytechnique91120 Palaiseau</addrLine>
              <country key="FR" />
            </address>
          </desc>
          <listRelation>
            <relation active="#struct-2071" type="direct" />
            <relation active="#struct-300340" type="indirect" />
            <relation name="UMR7161" active="#struct-441569" type="indirect" />
            <relation active="#struct-118511" type="direct" />
            <relation active="#struct-300009" type="indirect" />
          </listRelation>
        </org>
        <org type="laboratory" xml:id="struct-2071" status="VALID">
          <idno type="IdRef">196509955</idno>
          <idno type="RNSR">200519331V</idno>
          <orgName>Laboratoire d'informatique de l'École polytechnique [Palaiseau]</orgName>
          <orgName type="acronym">LIX</orgName>
          <desc>
            <address>
              <addrLine>Route de Saclay 91128 PALAISEAU CEDEX</addrLine>
              <country key="FR" />
            </address>
            <ref type="url">https://www.lix.polytechnique.fr/</ref>
          </desc>
          <listRelation>
            <relation active="#struct-300340" type="direct" />
            <relation name="UMR7161" active="#struct-441569" type="direct" />
          </listRelation>
        </org>
        <org type="institution" xml:id="struct-300340" status="VALID">
          <idno type="IdRef">027309320</idno>
          <idno type="ROR">https://ror.org/05hy3tk52</idno>
          <orgName>École polytechnique</orgName>
          <orgName type="acronym">X</orgName>
          <date type="start">1794-03-11</date>
          <desc>
            <address>
              <addrLine>École polytechnique, 91128 Palaiseau Cedex</addrLine>
              <country key="FR" />
            </address>
            <ref type="url">https://www.polytechnique.edu/</ref>
          </desc>
        </org>
        <org type="regroupinstitution" xml:id="struct-441569" status="VALID">
          <idno type="IdRef">02636817X</idno>
          <idno type="ISNI">0000000122597504</idno>
          <idno type="ROR">https://ror.org/02feahw73</idno>
          <orgName>Centre National de la Recherche Scientifique</orgName>
          <orgName type="acronym">CNRS</orgName>
          <date type="start">1939-10-19</date>
          <desc>
            <address>
              <country key="FR" />
            </address>
            <ref type="url">https://www.cnrs.fr/</ref>
          </desc>
        </org>
        <org type="laboratory" xml:id="struct-118511" status="VALID">
          <idno type="RNSR">200818248E</idno>
          <idno type="ROR">https://ror.org/0315e5x55</idno>
          <orgName>Inria Saclay - Ile de France</orgName>
          <desc>
            <address>
              <addrLine>1 rue Honoré d'Estienne d'OrvesBâtiment Alan TuringCampus de l'École Polytechnique91120 Palaiseau</addrLine>
              <country key="FR" />
            </address>
            <ref type="url">http://www.inria.fr/centre/saclay</ref>
          </desc>
          <listRelation>
            <relation active="#struct-300009" type="direct" />
          </listRelation>
        </org>
        <org type="institution" xml:id="struct-300009" status="VALID">
          <idno type="ROR">https://ror.org/02kvxyf05</idno>
          <orgName>Institut National de Recherche en Informatique et en Automatique</orgName>
          <orgName type="acronym">Inria</orgName>
          <desc>
            <address>
              <addrLine>Domaine de VoluceauRocquencourt - BP 10578153 Le Chesnay Cedex</addrLine>
              <country key="FR" />
            </address>
            <ref type="url">http://www.inria.fr/en/</ref>
          </desc>
        </org>
      </listOrg>
    </back>
  <teiCorpus>
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Speeding up RDF aggregate discovery through sampling</title>
				<funder ref="#_34EZTtJ">
					<orgName type="full">unknown</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher />
				<availability status="unknown"><licence /></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Ioana</forename><surname>Manolescu</surname></persName>
							<email>ioana.manolescu@inria.fr</email>
						</author>
						<author>
							<persName><forename type="first">Mirjana</forename><surname>Mazuran</surname></persName>
							<email>mirjana.mazuran@inria.fr</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="laboratory" key="lab1">Inria and LIX (</orgName>
								<orgName type="laboratory" key="lab2">UMR 7161</orgName>
								<orgName type="institution">Ecole polytechnique)</orgName>
								<address>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="laboratory" key="lab1">Inria and LIX (</orgName>
								<orgName type="laboratory" key="lab2">UMR 7161</orgName>
								<orgName type="institution">Ecole polytechnique)</orgName>
								<address>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Speeding up RDF aggregate discovery through sampling</title>
					</analytic>
					<monogr>
						<imprint>
							<date />
						</imprint>
					</monogr>
					<idno type="MD5">ED04B8E30B34B81C2F3CE9FB22C0351C</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-04-12T14:45+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid" />
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div><p>RDF graphs can be large and complex; finding out interesting information within them is challenging. One easy method for users to discover such graphs is to be shown interesting aggregates (under the form of two-dimensional graphs, i.e., bar charts), where interestingness is evaluated through statistics criteria. <software ContextAttributes="used">Dagger</software> <ref type="bibr" target="#b4">[5]</ref> pioneered this approach, however its is quite inefficient, in particular due to the need to evaluate numerous, expensive aggregation queries. In this work, we describe <software ContextAttributes="used">Dagger +</software> , which builds upon <software ContextAttributes="used">Dagger</software> and leverages sampling to speed up the evaluation of potentially interesting aggregates. We show that <software ContextAttributes="used">Dagger +</software> achieves very significant execution time reductions, while reaching results very close to those of the original, less efficient system.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div><head n="1">INTRODUCTION</head><p>RDF graphs are oftentimes large and complex; first-time users have a hard time to understand them. Exploration methods investigated in the past are based on keyword search, or on RDF summaries, which give users a first idea of a graph's content and structure. A different method of exploring RDF graphs was introduced in <software ContextAttributes="used">Dagger</software> <ref type="bibr" target="#b4">[5]</ref>, based on aggregation. Starting from an RDF graph, a set of agregate queries are automatically identified and evaluated, the most interesting ones (in a sense to be outlined shortly below) are chosen, and shown to human users as two-dimensional plots, in particular, bar charts. Figure <ref type="figure" target="#fig_0">1</ref> shows two examples. Above, we see the distribution of the number of ingredients appearing in food recipes in an RDF version of the foodista.com Web site, going from 1 to 25 with a peak at 8; we consider this distribution interesting as it has a clearly identified peak and quite a narrow interval. The graph below shows the distribution of Nobel prizes between female (left) and male (right) recipients; we find this interesting as it is very unbalanced.</p><p>As these examples illustrate, in <software>Dagger</software> + , we consider an aggregate query interesting if its result set has a high variance (second statistical moment). Other criteria can be considered, e.g., we have experimented also with the third statistical moment (skewness); more generally, while an RDF graph may have many interesting features, we seek to find aggregates over the graph having the highest variance. The running time of <software ContextAttributes="used">Dagger</software> was quite high: it took hours to identify the 10 most interesting aggregates on a dataset of 20 million triples. In this paper, we show how to speed it up, in particular through novel sampling techniques.</p><p>The remainder of this article is organized as follows. Section 2 introduces the state of the art. Section 3 describes the main concepts and algorithms of <software ContextAttributes="used">Dagger</software> <ref type="bibr" target="#b4">[5]</ref>, together with a set of improvements we brought through re-engineering. Then, Section 4 presents our performance-enhancing sampling technique.</p></div>
<div><head n="2">STATE OF THE ART</head><p>The problem of data exploration <ref type="bibr" target="#b7">[8]</ref> has received much attention; the automatic extraction of interesting aggregates is just one among many proposed techniques. Multidimensional data is particularly interesting in this respect, however, most works assume a fixed relational schema, which is not available for RDF graphs. More recent works <ref type="bibr" target="#b1">[2]</ref>, consider graphs, but (unlike <software ContextAttributes="used">Dagger</software>) assume a very regular and simple structure.</p><p>In <ref type="bibr" target="#b8">[9]</ref> the authors show how to automatically extract the top-k insights from multi-dimensional relational data, with fixed dimensions and measures. An insight is an observation derived from aggregation in multiple steps; it is considered interesting when it is remarkably different from others, or it exhibits a rising or falling trend. SeeDB <ref type="bibr" target="#b9">[10]</ref> recommends visualizations in high-dimensional relational data by means of a phased execution framework. The focus is to detect the visualizations with a large deviation with respect to a reference (e.g. another dataset, historical data or the rest of the data) from a database with a snowflake schema. In <ref type="bibr" target="#b5">[6]</ref>, multi-structural databases are proposed; their schema (i.e. possible dimensions) is known and three analytical operations are defined to: (i) determine how data is distributed across a particular set of dimensions, (ii) compare two sets of data with respect to given dimensions and (iii) separate the data into cohesive groups with respect to the known dimensions.</p><p>In contrast, Dagger (and <software>Dagger</software> + ) start directly from RDF, and, lacking schema information, automatically derives dimensions and measures that are good candidates to produce insights.</p><p>There is no universally accepted definition of interestingness; frequently, something unexpected (which differs from a reference) is considered interesting. The reference might be known a-priori, come from historical data, or be the average behavior. So far we have experimented with variance, skewness and kurtosis; we are also working to use the entropy. Many different RDF visualizations techniques can be used, e.g., <ref type="bibr" target="#b0">[1]</ref>.</p></div>
<div><head n="3">DAGGER OVERVIEW</head><p>We consider three pairwise disjoint sets: the set of URIs U, the set of literals L, and the set of blank nodes B. An RDF graph G is a finite set of triples of the form (s, p, o), called subject, property and object, such that s ∈ (U ∪ B), p ∈ U and o ∈ (U ∪ B ∪ L). The RDF property rdf:type is used to attach types (i.e. classes) to an RDF resource, which can have zero, one or several types. G can have an ontology stating relationships between its classes and properties, e.g., any UndegraduateStudent is a Student; its presence may lead to implicit triples, which are part of G even if they may not appear explicitly. A graph containing all the triples which may be derived from it is said to be saturated. Without loss of generality, we consider that our input graph is saturated.</p><p><software>Dagger</software> identifies unidimensional aggregate queries to be evaluated in an RDF graph G. However, unlike a traditional relational data warehouse, an RDF graph comes without identified set of facts; nor are dimensions and measures known in advance. Therefore, <software ContextAttributes="used">Dagger</software> must enumerate candidates for each of these roles.</p><p>A set of candidate facts (c f , in short) is a set of G resources which are deemed interesting for the analysis. <software>Dagger</software> considers as c f (i) all the resources of a given class C, e.g., all the Students; (ii) all the resources having a certain set P of properties, e.g., all those having title and author. A simple way to pick such a property set is to compute the support of the properties in G and select property sets whose support is above a certain threshold.</p><p>A candidate dimension (denoted d) is used for grouping the candidate facts. <software ContextAttributes="used">Dagger</software> supports as candidate dimensions (i) properties present on at least a certain fraction t t hr es of resources from c f ; (ii) derived properties, computed by <software ContextAttributes="used">Dagger</software> in order to find potentially interesting insights. The derived properties supported in <ref type="bibr" target="#b4">[5]</ref> are count(p), where p is a property that some c f resources have. For instance, if resources of type Student are stated to takeCourse, <software ContextAttributes="used">Dagger</software> derives the property takeCourse#. Further, <software ContextAttributes="used">Dagger</software> will consider a candidate dimension only the number of distinct values of this property on the c f resources is smaller than t dist × |c f | for a certain ratio 0 &lt; t dist &lt; 1.</p><p>A candidate measure (denoted m) is something to be evaluated or measured for each candidate fact. <software>Dagger</software> considers candidate measures among the (original or derived) properties of candidate facts whose support is above t t hr esh . Dimension-measure combinations such that one is a property a and the other is the count a# of this property are excluded.</p><p>An aggregation function ⊕ is chosen among min, max, avg, sum, count; the first four are considered only if the measure is numeric. Given that RDF data is often untyped or only partially typed, <software>Dagger</software> implements a type detection mechanism by trying to convert the property values to different types.</p><p>A <software>Dagger</software> aggregate aдд is a tuple (c f , d, m, ⊕). To specify how interesting an aggregate is, let f (V ) be a function which inputs a set of numerical values V and returns a number. Given f , the interestingness of aдд is computed as:</p><p>• let d 1 , d 2 , . . . be the distinct values that d may take for a resource in c f ; • for each d i , let c f i be set of c f resources for which d takes the value d i ; observe that the c f i sets may overlap, as a resource with more than one value for d belongs to several such sets. For instance, students can be grouped by the courses they take, and each student takes many courses; • for each c f i , let M i be the set of m values of c f i resources, and</p><formula xml:id="formula_0">m i = ⊕(M i ); • the interestingness of aдд is f ({m 1 , m 2 , . . .}).</formula><p>The problem considered by <software>Dagger</software> is: given a graph G, a set of value thresholds, function f and an integer k, find the k most interesting aggregates. Architecture. <software ContextAttributes="used">Dagger</software> leverages the robust query evaluation capabilities of an RDBMS to store the RDF graph, enumerate and evaluate candidate aggregates. SQL queries are used to: determine the resources part of a candidate fact sets; evaluate the suitability of their properties as dimensions, respectively, measures; compute and aggregate the group measures m i . The remaining operations, e.g., the computation of the interestingness score function, are done in Java. Aggregate recommendation cost. The most expensive computation steps are: (i) finding the candidate dimensions and (ii) evaluating the aggregation operations. Indeed, when looking for candidate dimensions, several queries are issued over c f (e.g., find all distinct properties, count the number of subject that have each property, find the values of the derived properties, etc.). Moreover, many candidate aggregates are generated, also leading to a high number of potentially expensive SQL queries.</p></div>
<div><head n="4">DAGGER + : SPEEDING UP DAGGER</head><p>A set of re-engineering changes were brought to <software ContextAttributes="used">Dagger</software> since the original demonstration. In particular, it has been ported on top of <software ContextAttributes="used">OntoSQL</software> (https://ontosql.inria.fr), a Java-based platform developed at Inria, providing efficient RDF storage, saturation, and query processing algorithms <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b3">4]</ref>. <software ContextAttributes="used">OntoSQL</software> encodes spaceconsuming URIs and literals into compact integers, together with a dictionary table which allows going from one to the other. For a given class c, all triples of the form x type c are stored in a single-column table t c holding the codes of the subjects x; for each property p other than type, a table t p stores (s code, o code) pairs for each (s, p, o) triple in G. This re-engineering has lead to a very significant reduction in <software ContextAttributes="used">Dagger</software>'s running time, e.g., on a 20 million triples graph, from several hours to 20 minutes.</p><p>Further, we adapted an optimization previously proposed in <ref type="bibr" target="#b9">[10]</ref>: we evaluate all candidate aggregates that share both dimension and measure by a single SQL query. In a relational context, aggregates can be evaluated together as soon as they have the same dimension (even if the measures are different) because one relational tuple usually contains all the attributes used in the different measures. In contrast, RDF candidate facts need to be joined with the t d table corresponding to the property d chosen as dimension, and with the t m table for the property chosen as measure; distinct measures require distinct joins, thus sharing is more limited. This is not due to the storage model, but to RDF heterogeneity: the candidate facts having the measure property m 1 may be different from those having property m 2 . This forces evaluating (d, m 1 ) aggregates separately from (d, m 2 ) ones.</p><p>Below, we focus on two novel optimization techniques we applied subsequently: using an RDF graph summary to speed up candidate dimension enumeration (Section 4.1), and using sampling to accelerate candidate dimension enumeration, aggregate evaluation and ranking (Section 4.2).</p></div>
<div><head n="4.1">Summary-based dimension enumeration</head><p>RDFQuotient <ref type="bibr" target="#b6">[7]</ref> is a structural RDF graph summarization tool based on graph quotients. Given an equivalence relation over graph nodes, the summary contains one node for each equivalence class in the original graph. Moreover, each edge n a -→ m in the original graph leads to an edge rep(n) a -→ rep(m) in the summary, where rep(n) is the summary representative of node n. A particular equivalence relation groups the nodes by their set of types. <software ContextAttributes="used">Dagger</software> + uses it to find: (i) all the types, (ii) for each type, the number of resources of that type, and (iii) the set of possible properties these resources might have. These questions can be answered exactly directly from the RDFQuotient reducing dimension enumeration time.</p></div>
<div><head n="4.2">Sampling-based aggregate selection</head><p>We introduced two sampling strategies to trade some accuracy in aggregate selection for running time:</p><p>• CFSampling: the c f is sampled (draw n 1 samples of size n 2 ), and candidate dimensions and measures are found for each sample independently. For each of the n 1 samples, candidate aggregates are generated, and their interestingness is evaluated on the sample. • ESampling: candidate dimensions and measures are computed on the whole c f as in <software>Dagger</software>. Then, n 1 samples of size n 2 are drawn from the c f , and the candidate aggregates are evaluated on the samples.</p><p>With CFSampling, the aggregates recommended for different sample may be different, e.g., certain properties might be found to be frequent in some sample but not in all of them. After the evaluation, a ranked list of aggregates is obtained for each sample. In ESampling, instead, the set of aggregates is unique as it is derived directly from the original data. However, given that all the aggregates are evaluated on samples, it also yields a ranked list of aggregates for each sample.</p><p>To be able to compare the results found without sampling with those found through sampling, we need to reconcile the results found on different samples into a single ranked list. We can do this by taking (i) the union or (ii) the intersection of the lists obtained from all the samples. Then, we re-rank the aggregates according to a estimation of their global interestingness measure (based on their interestingness on each sample), e.g., through pooled variance; at the end of this process, we obtain a unique ranked list of candidate aggregates.</p></div>
<div><head n="5">EXPERIMENTAL RESULTS</head><p>We measure the run time performances and to test the accuracy of the results obtained with sampling techniques. We used a 2,7 GHz Intel Core i7 with 16 GB of RAM. We describe experiments on the articles from the DBLP dataset 1 ; we use 20.132.491 triples describing information about 888.183 distinct articles. <software ContextAttributes="created">Dagger</software> + without sampling. First, we evaluate how much the use of the summary, and the shared evaluation, improve performance. Figure <ref type="figure" target="#fig_1">2</ref> shows the two main components (finding dimensions and aggregate evaluation), as well as a third, very small bar representing the other operations. Note that the property analysis which allows to select candidate dimensions also enables to select candidate measures (thus candidate measure selection time is negligible and wrapped under "Other").</p><p>Without any optimization ("NoSummary, NoShared" bar in Figure <ref type="figure" target="#fig_1">2</ref>), 21% of the time is spent looking for dimensions, while 78% of the time goes to evaluating aggregates. Summary use introduces a modest performance improvement, while shared aggregate evaluation has a much more significant result (see the "NoSummary, Shared" and "Summary, Shared" bars). Here, 1 http://www.rdfhdt.org/datasets/ <software ContextAttributes="created">Dagger</software> + generates a total of 371 candidate aggregates; without shared evaluation, each of them is evaluated as one query, however, with shared evaluation, only 131 queries are executed as this is the number of distinct pairs of dimension and measure.</p><p>Sampling. We measure the running time and the accuracy of the results by varying 3 parameters: (i) the sampling strategy (CFSampling or ESampling), (ii) the number of samples (2, 3, 4 or 5); and (iii) the sample size, as a ratio of the candidate fact set size (from 1% to 10% of the number of distinct CF resources). Figure <ref type="figure" target="#fig_2">3</ref> shows the running times: one plot for each number of samples (from top to bottom, 2, 3, 4, 5), each of which varies the strategy and the sample size. Ten runs are averaged for each parameter combinations (different samples are drawn in each run).</p><p>Figure <ref type="figure" target="#fig_2">3</ref> shows that ESampling is slower than CFSampling, as the former looks for candidate dimensions on the whole candidate fact set, whereas the latter does this on smaller-size samples. ESampling enumerates all the candidate aggregates also found without sampling, while CFSampling might enumerate a different set of aggregates: some properties that are overall frequent (infrequent) might be found infrequent (frequent) in a specific sample, and thus not be considered (considered) as candidate dimensions and measures. However, even though ESampling enumerates all the no-sampling candidate aggregates, it evaluates them on samples, and may end up considering them interesting (uninteresting) differently from the way they are on the complete CF.</p><p>To evaluate the accuracy of the results obtained through sampling, we compare the Top-5, Top-10 and Top-20 aggregates found without sampling, with those found through sampling. The ranked list of aggregates found with sampling is built by taking the union of all those found across the samples and reranking them according to the interestingness measure (in our experiments we use the pooled variance to rank all the results).    Aggregates whose interestingness is zero are not considered. Notice that we do not break ties, that is: if we search e.g. the Top-5 most interesting aggregates, but find that the sixth element in the list has the same interestingness value as the fifth, we also include it in the Top-5, as we did not find a meaningful way to break such ties. When no sampling is used, Top-5 returned 5 aggregates, respectively, Top-10 returned 11 while the Top-20 returned 20. We compute the accuracy as the percentage of aggregates in the sampling result, that are also in the result without sampling. Table <ref type="table" target="#tab_1">1</ref> shows the precision of CFSampling while Table <ref type="table" target="#tab_2">2</ref> shows that of ESampling. In 57% of the cases the accuracy obtained using ESampling is higher; on average, the two accuracy values differ by 6%. The accuracy is quite low when searching for the the Top-5 aggregates; in contrast, both Top-10 and Top-20 can be well approximated (accuracy above 80% for the Top-20 even with few samples). In general, the bigger the samples, the better the accuracy, however, results show situations where the Top-10 and Top-20 have better accuracy with a lower number of samples; there is a 10% difference in accuracy on average, i.e. the top-Ks differ by 2/3 aggregates. This does not mean that such aggregates were not found though but they have been ranked differently. Clearly, the accuracy increases with K (the amount of top aggregates) and with the size of the samples. The increase in the number of samples does not significantly improve accuracy.</p></div>
<div><head n="6">CONCLUSION</head><p>Automatic selection of interesting aggregates in an RDF graph is challenging, as candidate dimensions and measures must be "guessed" from the data, and candidate aggregates must be evaluated to assess their interestingness. After re-engineering <software ContextAttributes="created">Dagger</software> <ref type="bibr" target="#b4">[5]</ref> to exploit an existing efficient RDF platform, we have shown that sharing work and (to a lesser extent) using a graph summary can reduce its running time by a factor of 2. Our main focus has been on sampling, which, for Top-10 and Top-20 search, achieves good accuracy (above 70%) while reducing running time by another factor of 2. Overall, CFSampling appears the most interesting strategy. Our current work stretches in several directions: (i) generalizing <software ContextAttributes="created">Dagger</software> to more complex dimension and measure selection, (ii) adopt more interestingness metrics, (iii) introduce new types of derived properties, e.g., extract meaningful keywords from textual properties to be used as potential dimensions and/or measures.</p></div><figure xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Sample interesting aggregates.</figDesc><graphic coords="2,53.80,553.65,176.22,87.67" type="bitmap" /></figure>
<figure xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Impact of summary and sharing.</figDesc><graphic coords="4,53.80,495.00,140.40,108.30" type="bitmap" /></figure>
<figure xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Running times with sampling.</figDesc><graphic coords="4,309.94,83.69,228.95,291.65" type="bitmap" /></figure>
<figure xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Accuracy of results (%) with respect to running times (sec).</figDesc><graphic coords="5,87.52,83.68,418.00,152.00" type="bitmap" /></figure>
<figure xml:id="fig_4"><head>Figure 4</head><label>4</label><figDesc>plots the accuracy with respect to the running times. Each line of graphs represents the Top-5, Top-10 and Top-20 for a different number of samples; red x's indicate CFsampling, while green +'s indicate ESampling, for different sample dimensions.</figDesc></figure>
<figure type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>Accuracy of results with CFSampling.</figDesc><table><row><cell cols="3">#samples Top-K 1%</cell><cell>3%</cell><cell>5%</cell><cell>7%</cell><cell>9% 10%</cell></row><row><cell /><cell>Top5</cell><cell cols="4">40% 36% 24% 32% 28% 32%</cell></row><row><cell>2</cell><cell cols="5">Top10 49% 55% 63% 57% 63% 71%</cell></row><row><cell /><cell cols="5">Top20 65% 69% 81% 84% 89% 93%</cell></row><row><cell /><cell>Top5</cell><cell cols="4">28% 28% 32% 24% 16% 28%</cell></row><row><cell>3</cell><cell cols="5">Top10 45% 68% 71% 60% 59% 72%</cell></row><row><cell /><cell cols="5">Top20 67% 76% 75% 83% 83% 87%</cell></row><row><cell /><cell>Top5</cell><cell cols="4">36% 16% 12% 24% 24% 20%</cell></row><row><cell>4</cell><cell cols="5">Top10 49% 55% 27% 41% 60% 53%</cell></row><row><cell /><cell cols="5">Top20 70% 71% 66% 73% 87% 84%</cell></row><row><cell /><cell>Top5</cell><cell cols="4">36% 20% 12% 24% 20% 24%</cell></row><row><cell>5</cell><cell cols="5">Top10 50% 49% 38% 45% 52% 60%</cell></row><row><cell /><cell cols="5">Top20 68% 63% 68% 77% 80% 88%</cell></row></table></figure>
<figure type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>Accuracy of results with ESampling.</figDesc><table /></figure>
		</body>
		<back>

			<div type="funding">
<div><p>* <rs type="person">M. Mazuran</rs> is supported by the <rs type="programName">H2020 research program</rs> under grant nr. <rs type="grantNumber">800192</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_34EZTtJ">
					<idno type="grant-number">800192</idno>
					<orgName type="program" subtype="full">H2020 research program</orgName>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">LODeX: A Tool for Visual Querying Linked Open Data</title>
		<author>
			<persName><forename type="first">Fabio</forename><surname>Benedetti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sonia</forename><surname>Bergamaschi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Laura</forename><surname>Po</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ISWC 2015 Posters &amp; Demonstrations</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Using entropy metrics for pruning very large graph cubes</title>
		<author>
			<persName><forename type="first">D</forename><surname>Bleco</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Kotidis</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
	<note type="report_type">Information Systems</note>
	<note>To appear</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Optimizing Reformulationbased Query Answering in RDF</title>
		<author>
			<persName><forename type="first">D</forename><surname>Bursztyn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Goasdoué</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Manolescu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EDBT</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Teaching an RDBMS about ontological constraints</title>
		<author>
			<persName><forename type="first">D</forename><surname>Bursztyn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Goasdoué</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Manolescu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PVLDB</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page">12</biblScope>
			<date type="published" when="2016">2016. 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Dagger: Digging for Interesting Aggregates in RDF Graphs</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Diao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Manolescu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Shang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ISWC Posters &amp; Demonstrations Track</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Multi-structural databases</title>
		<author>
			<persName><forename type="first">R</forename><surname>Fagin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">V</forename><surname>Guha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Novak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Sivakumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Tomkins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">PODS. ACM</title>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="184" to="195" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Incremental structural summarization of RDF graphs (demo)</title>
		<author>
			<persName><forename type="first">François</forename><surname>Goasdoué</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pawel</forename><surname>Guzewicz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ioana</forename><surname>Manolescu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EDBT</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Overview of Data Exploration Techniques</title>
		<author>
			<persName><forename type="first">S</forename><surname>Idreos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Papaemmanouil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Chaudhuri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGMOD</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="277" to="281" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Extracting Top-K Insights from Multi-dimensional Data</title>
		<author>
			<persName><forename type="first">B</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">L</forename><surname>Yiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGMOD. ACM</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1509" to="1524" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">SEEDB: Efficient Data-Driven Visualization Recommendations to Support Visual Analytics</title>
		<author>
			<persName><forename type="first">M</forename><surname>Vartak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Rahman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Madden</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">G</forename><surname>Parameswaran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Polyzotis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PVLDB</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">13</biblScope>
			<biblScope unit="page" from="2182" to="2193" />
			<date type="published" when="2015">2015. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</teiCorpus></text>
</TEI>