<?xml version='1.0' encoding='utf-8'?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" version="1.1" xsi:schemaLocation="http://www.tei-c.org/ns/1.0 http://api.archives-ouvertes.fr/documents/aofr-sword.xsd">
  <teiHeader>
    <fileDesc>
      <titleStmt>
        <title>HAL TEI export of hal-04388942</title>
      </titleStmt>
      <publicationStmt>
        <distributor>CCSD</distributor>
        <availability status="restricted">
          <licence target="http://creativecommons.org/licenses/by/">Attribution</licence>
        </availability>
        <date when="2024-04-23T16:40:19+02:00" />
      </publicationStmt>
      <sourceDesc>
        <p part="N">HAL API platform</p>
      </sourceDesc>
    </fileDesc>
  </teiHeader>
  <text>
    <body>
      <listBibl>
        <biblFull>
          <titleStmt>
            <title xml:lang="en">Adaptation of AI Explanations to Users' Roles</title>
            <author role="aut">
              <persName>
                <forename type="first">Julien</forename>
                <surname>Delaunay</surname>
              </persName>
              <email type="md5">512742de0b1f906df783de3e83a80b2b</email>
              <email type="domain">irisa.fr</email>
              <idno type="idhal" notation="string">julien-delaunay</idno>
              <idno type="idhal" notation="numeric">1236016</idno>
              <idno type="halauthorid" notation="string">2114548-1236016</idno>
              <idno type="ORCID">https://orcid.org/0000-0001-6824-5010</idno>
              <idno type="GOOGLE SCHOLAR">https://scholar.google.fr/citations?user=6XitihwAAAAJ</idno>
              <affiliation ref="#struct-491653" />
            </author>
            <author role="aut">
              <persName>
                <forename type="first">Christine</forename>
                <surname>Largouët</surname>
              </persName>
              <email type="md5">ab4039b1556f486db20e8bc0aeafa384</email>
              <email type="domain">agrocampus-ouest.fr</email>
              <idno type="idhal" notation="string">christine-largouet</idno>
              <idno type="idhal" notation="numeric">1706</idno>
              <idno type="halauthorid" notation="string">13671-1706</idno>
              <idno type="ORCID">https://orcid.org/0000-0003-2739-5850</idno>
              <idno type="IDREF">https://www.idref.fr/082571090</idno>
              <affiliation ref="#struct-491653" />
            </author>
            <author role="aut">
              <persName>
                <forename type="first">Luis</forename>
                <surname>Galárraga</surname>
              </persName>
              <idno type="idhal" notation="numeric">1263076</idno>
              <idno type="halauthorid" notation="string">935990-1263076</idno>
              <idno type="ORCID">https://orcid.org/0000-0002-0241-5379</idno>
              <affiliation ref="#struct-491653" />
            </author>
            <author role="aut">
              <persName>
                <forename type="first">Niels</forename>
                <forename type="middle">Van</forename>
                <surname>Berkel</surname>
              </persName>
              <email type="md5">74e250fe7e64d0ab1f19c27a4e02bd35</email>
              <email type="domain">cs.aau.dk</email>
              <idno type="idhal" notation="numeric">1310802</idno>
              <idno type="halauthorid" notation="string">1825365-1310802</idno>
              <affiliation ref="#struct-300821" />
            </author>
            <editor role="depositor">
              <persName>
                <forename>Luis</forename>
                <surname>Galárraga</surname>
              </persName>
              <email type="md5">2ab89542c7290c9a3428e0e968ba9bcd</email>
              <email type="domain">inria.fr</email>
            </editor>
          </titleStmt>
          <editionStmt>
            <edition n="v1" type="current">
              <date type="whenSubmitted">2024-01-11 17:06:33</date>
              <date type="whenModified">2024-01-23 14:42:23</date>
              <date type="whenReleased">2024-01-12 09:06:03</date>
              <date type="whenProduced">2023-04-23</date>
              <date type="whenEndEmbargoed">2024-01-11</date>
              <ref type="file" target="https://inria.hal.science/hal-04388942/document">
                <date notBefore="2024-01-11" />
              </ref>
              <ref type="file" subtype="author" n="1" target="https://inria.hal.science/hal-04388942/file/chi2023f.pdf">
                <date notBefore="2024-01-11" />
              </ref>
            </edition>
            <respStmt>
              <resp>contributor</resp>
              <name key="329432">
                <persName>
                  <forename>Luis</forename>
                  <surname>Galárraga</surname>
                </persName>
                <email type="md5">2ab89542c7290c9a3428e0e968ba9bcd</email>
                <email type="domain">inria.fr</email>
              </name>
            </respStmt>
          </editionStmt>
          <publicationStmt>
            <distributor>CCSD</distributor>
            <idno type="halId">hal-04388942</idno>
            <idno type="halUri">https://inria.hal.science/hal-04388942</idno>
            <idno type="halBibtex">delaunay:hal-04388942</idno>
            <idno type="halRefHtml">&lt;i&gt;HCXAI 2023 - Workshop on Human-Centered Explainable AI&lt;/i&gt;, Apr 2023, Hamburg, Germany. pp.1-7</idno>
            <idno type="halRef">HCXAI 2023 - Workshop on Human-Centered Explainable AI, Apr 2023, Hamburg, Germany. pp.1-7</idno>
            <availability status="restricted">
              <licence target="http://creativecommons.org/licenses/by/">Attribution</licence>
            </availability>
          </publicationStmt>
          <seriesStmt>
            <idno type="stamp" n="UNIV-RENNES1">Université de Rennes 1</idno>
            <idno type="stamp" n="CNRS">CNRS - Centre national de la recherche scientifique</idno>
            <idno type="stamp" n="INRIA">INRIA - Institut National de Recherche en Informatique et en Automatique</idno>
            <idno type="stamp" n="UNIV-UBS">Université de Bretagne Sud</idno>
            <idno type="stamp" n="INSA-RENNES">Institut National des Sciences Appliquées de Rennes</idno>
            <idno type="stamp" n="INRIA-RENNES">INRIA Rennes - Bretagne Atlantique</idno>
            <idno type="stamp" n="IRISA">Irisa</idno>
            <idno type="stamp" n="IRISA_SET">IRISA_SET</idno>
            <idno type="stamp" n="INRIA_TEST">INRIA - Institut National de Recherche en Informatique et en Automatique</idno>
            <idno type="stamp" n="TESTALAIN1">TESTALAIN1</idno>
            <idno type="stamp" n="CENTRALESUPELEC">Ecole CentraleSupélec</idno>
            <idno type="stamp" n="INRIA2">INRIA 2</idno>
            <idno type="stamp" n="UR1-HAL">Publications labos UR1 dans HAL-Rennes 1</idno>
            <idno type="stamp" n="UR1-MATH-STIC">UR1 - publications Maths-STIC</idno>
            <idno type="stamp" n="UR1-UFR-ISTIC">UFR ISTIC Informatique et électronique</idno>
            <idno type="stamp" n="TEST-UR-CSS">TEST Université de Rennes CSS</idno>
            <idno type="stamp" n="UNIV-RENNES">Université de Rennes</idno>
            <idno type="stamp" n="INRIA-RENGRE">INRIA-RENGRE</idno>
            <idno type="stamp" n="UR1-MATH-NUM">Pôle UnivRennes - Mathématiques - Numérique </idno>
            <idno type="stamp" n="INSTITUT-AGRO-RENNES-ANGERS-UMR-IRISA">Institut Agro Rennes-Angers - UMR IRISA</idno>
          </seriesStmt>
          <notesStmt>
            <note type="audience" n="2">International</note>
            <note type="invited" n="0">No</note>
            <note type="popular" n="0">No</note>
            <note type="peer" n="1">Yes</note>
            <note type="proceedings" n="0">No</note>
          </notesStmt>
          <sourceDesc>
            <biblStruct>
              <analytic>
                <title xml:lang="en">Adaptation of AI Explanations to Users' Roles</title>
                <author role="aut">
                  <persName>
                    <forename type="first">Julien</forename>
                    <surname>Delaunay</surname>
                  </persName>
                  <email type="md5">512742de0b1f906df783de3e83a80b2b</email>
                  <email type="domain">irisa.fr</email>
                  <idno type="idhal" notation="string">julien-delaunay</idno>
                  <idno type="idhal" notation="numeric">1236016</idno>
                  <idno type="halauthorid" notation="string">2114548-1236016</idno>
                  <idno type="ORCID">https://orcid.org/0000-0001-6824-5010</idno>
                  <idno type="GOOGLE SCHOLAR">https://scholar.google.fr/citations?user=6XitihwAAAAJ</idno>
                  <affiliation ref="#struct-491653" />
                </author>
                <author role="aut">
                  <persName>
                    <forename type="first">Christine</forename>
                    <surname>Largouët</surname>
                  </persName>
                  <email type="md5">ab4039b1556f486db20e8bc0aeafa384</email>
                  <email type="domain">agrocampus-ouest.fr</email>
                  <idno type="idhal" notation="string">christine-largouet</idno>
                  <idno type="idhal" notation="numeric">1706</idno>
                  <idno type="halauthorid" notation="string">13671-1706</idno>
                  <idno type="ORCID">https://orcid.org/0000-0003-2739-5850</idno>
                  <idno type="IDREF">https://www.idref.fr/082571090</idno>
                  <affiliation ref="#struct-491653" />
                </author>
                <author role="aut">
                  <persName>
                    <forename type="first">Luis</forename>
                    <surname>Galárraga</surname>
                  </persName>
                  <idno type="idhal" notation="numeric">1263076</idno>
                  <idno type="halauthorid" notation="string">935990-1263076</idno>
                  <idno type="ORCID">https://orcid.org/0000-0002-0241-5379</idno>
                  <affiliation ref="#struct-491653" />
                </author>
                <author role="aut">
                  <persName>
                    <forename type="first">Niels</forename>
                    <forename type="middle">Van</forename>
                    <surname>Berkel</surname>
                  </persName>
                  <email type="md5">74e250fe7e64d0ab1f19c27a4e02bd35</email>
                  <email type="domain">cs.aau.dk</email>
                  <idno type="idhal" notation="numeric">1310802</idno>
                  <idno type="halauthorid" notation="string">1825365-1310802</idno>
                  <affiliation ref="#struct-300821" />
                </author>
              </analytic>
              <monogr>
                <meeting>
                  <title>HCXAI 2023 - Workshop on Human-Centered Explainable AI</title>
                  <date type="start">2023-04-23</date>
                  <date type="end">2023-04-28</date>
                  <settlement>Hamburg</settlement>
                  <country key="DE">Germany</country>
                </meeting>
                <imprint>
                  <biblScope unit="pp">1-7</biblScope>
                  <date type="datePub">2023</date>
                </imprint>
              </monogr>
            </biblStruct>
          </sourceDesc>
          <profileDesc>
            <langUsage>
              <language ident="en">English</language>
            </langUsage>
            <textClass>
              <keywords scheme="author">
                <term xml:lang="en">Explainability</term>
                <term xml:lang="en">Interpretability</term>
                <term xml:lang="en">User Study</term>
              </keywords>
              <classCode scheme="halDomain" n="info.info-hc">Computer Science [cs]/Human-Computer Interaction [cs.HC]</classCode>
              <classCode scheme="halDomain" n="info.info-ai">Computer Science [cs]/Artificial Intelligence [cs.AI]</classCode>
              <classCode scheme="halTypology" n="COMM">Conference papers</classCode>
              <classCode scheme="halOldTypology" n="COMM">Conference papers</classCode>
              <classCode scheme="halTreeTypology" n="COMM">Conference papers</classCode>
            </textClass>
            <abstract xml:lang="en">
              <p>Surrogate explanations approximate a complex model by training a simpler model over an interpretable space. Among these simpler models, we identify three kinds of surrogate methods: (a) feature-attribution, (b) example-based, and (c) rule-based explanations. Each surrogate approximates the complex model differently, and we hypothesise that this can impact how users interpret the explanation. Despite the numerous calls for introducing explanations for all, no prior work has compared the impact of these surrogates on specific user roles (e.g., domain expert, developer). In this article, we outline a study design to assess the impact of these three surrogate techniques across different user roles.</p>
            </abstract>
          </profileDesc>
        </biblFull>
      </listBibl>
    </body>
    <back>
      <listOrg type="structures">
        <org type="researchteam" xml:id="struct-491653" status="VALID">
          <idno type="RNSR">201622044W</idno>
          <orgName>Large Scale Collaborative Data Mining</orgName>
          <orgName type="acronym">LACODAM</orgName>
          <desc>
            <address>
              <addrLine>Campus de Beaulieu 35042 Rennes cedex</addrLine>
              <country key="FR" />
            </address>
            <ref type="url">https://www.inria.fr/equipes/lacodam</ref>
          </desc>
          <listRelation>
            <relation active="#struct-419153" type="direct" />
            <relation active="#struct-300009" type="indirect" />
            <relation active="#struct-491231" type="direct" />
            <relation active="#struct-490899" type="indirect" />
            <relation active="#struct-105160" type="indirect" />
            <relation active="#struct-117606" type="indirect" />
            <relation active="#struct-301232" type="indirect" />
            <relation active="#struct-172265" type="indirect" />
            <relation active="#struct-247362" type="indirect" />
            <relation active="#struct-411575" type="indirect" />
            <relation name="UMR6074" active="#struct-441569" type="indirect" />
            <relation active="#struct-481355" type="indirect" />
            <relation active="#struct-302102" type="indirect" />
          </listRelation>
        </org>
        <org type="institution" xml:id="struct-300821" status="VALID">
          <idno type="ROR">https://ror.org/04m5j1k67</idno>
          <orgName>Aalborg University [Denmark]</orgName>
          <orgName type="acronym">AAU</orgName>
          <desc>
            <address>
              <addrLine>Fredrik Bajers Vej 5, P.O. Box 159, DK - 9100 Aalborg, Denmark</addrLine>
              <country key="DK" />
            </address>
            <ref type="url">http://www.en.aau.dk/</ref>
          </desc>
        </org>
        <org type="laboratory" xml:id="struct-419153" status="VALID">
          <idno type="RNSR">198018249C</idno>
          <idno type="ROR">https://ror.org/04040yw90</idno>
          <orgName>Inria Rennes – Bretagne Atlantique</orgName>
          <desc>
            <address>
              <addrLine>Campus de beaulieu35042 Rennes cedex</addrLine>
              <country key="FR" />
            </address>
            <ref type="url">http://www.inria.fr/centre/rennes</ref>
          </desc>
          <listRelation>
            <relation active="#struct-300009" type="direct" />
          </listRelation>
        </org>
        <org type="institution" xml:id="struct-300009" status="VALID">
          <idno type="ROR">https://ror.org/02kvxyf05</idno>
          <orgName>Institut National de Recherche en Informatique et en Automatique</orgName>
          <orgName type="acronym">Inria</orgName>
          <desc>
            <address>
              <addrLine>Domaine de VoluceauRocquencourt - BP 10578153 Le Chesnay Cedex</addrLine>
              <country key="FR" />
            </address>
            <ref type="url">http://www.inria.fr/en/</ref>
          </desc>
        </org>
        <org type="department" xml:id="struct-491231" status="VALID">
          <orgName>GESTION DES DONNÉES ET DE LA CONNAISSANCE</orgName>
          <orgName type="acronym">IRISA-D7</orgName>
          <desc>
            <address>
              <country key="FR" />
            </address>
            <ref type="url">https://www.irisa.fr/fr/departements/d7-gestion-donnees-connaissance</ref>
          </desc>
          <listRelation>
            <relation active="#struct-490899" type="direct" />
            <relation active="#struct-105160" type="indirect" />
            <relation active="#struct-117606" type="indirect" />
            <relation active="#struct-301232" type="indirect" />
            <relation active="#struct-172265" type="indirect" />
            <relation active="#struct-247362" type="indirect" />
            <relation active="#struct-300009" type="indirect" />
            <relation active="#struct-411575" type="indirect" />
            <relation name="UMR6074" active="#struct-441569" type="indirect" />
            <relation active="#struct-481355" type="indirect" />
            <relation active="#struct-302102" type="indirect" />
          </listRelation>
        </org>
        <org type="laboratory" xml:id="struct-490899" status="VALID">
          <idno type="IdRef">026386909</idno>
          <idno type="ISNI">0000 0001 2298 7270</idno>
          <idno type="RNSR">200012163A</idno>
          <idno type="ROR">https://ror.org/00myn0z94</idno>
          <orgName>Institut de Recherche en Informatique et Systèmes Aléatoires</orgName>
          <orgName type="acronym">IRISA</orgName>
          <date type="start">2017-01-01</date>
          <desc>
            <address>
              <addrLine>Avenue du général LeclercCampus de Beaulieu 35042 RENNES CEDEX</addrLine>
              <country key="FR" />
            </address>
            <ref type="url">http://www.irisa.fr</ref>
          </desc>
          <listRelation>
            <relation active="#struct-105160" type="direct" />
            <relation active="#struct-117606" type="direct" />
            <relation active="#struct-301232" type="indirect" />
            <relation active="#struct-172265" type="direct" />
            <relation active="#struct-247362" type="direct" />
            <relation active="#struct-300009" type="direct" />
            <relation active="#struct-411575" type="direct" />
            <relation name="UMR6074" active="#struct-441569" type="direct" />
            <relation active="#struct-481355" type="direct" />
            <relation active="#struct-302102" type="indirect" />
          </listRelation>
        </org>
        <org type="institution" xml:id="struct-105160" status="VALID">
          <idno type="ROR">https://ror.org/015m7wh34</idno>
          <orgName>Université de Rennes</orgName>
          <orgName type="acronym">UR</orgName>
          <desc>
            <address>
              <addrLine>Campus de Beaulieu, 263 avenue Général Leclerc, CS 74205, 35042 RENNES CEDEX</addrLine>
              <country key="FR" />
            </address>
            <ref type="url">https://www.univ-rennes.fr/</ref>
          </desc>
        </org>
        <org type="institution" xml:id="struct-117606" status="VALID">
          <idno type="ROR">https://ror.org/04xaa4j22</idno>
          <orgName>Institut National des Sciences Appliquées - Rennes</orgName>
          <orgName type="acronym">INSA Rennes</orgName>
          <desc>
            <address>
              <addrLine>20, avenue des Buttes de Coësmes - CS 70839 - 35708 Rennes cedex 7</addrLine>
              <country key="FR" />
            </address>
            <ref type="url">http://www.insa-rennes.fr/</ref>
          </desc>
          <listRelation>
            <relation active="#struct-301232" type="direct" />
          </listRelation>
        </org>
        <org type="regroupinstitution" xml:id="struct-301232" status="VALID">
          <idno type="IdRef">162105150</idno>
          <orgName>Institut National des Sciences Appliquées</orgName>
          <orgName type="acronym">INSA</orgName>
          <desc>
            <address>
              <country key="FR" />
            </address>
          </desc>
        </org>
        <org type="institution" xml:id="struct-172265" status="VALID">
          <idno type="ROR">https://ror.org/04ed7fw48</idno>
          <orgName>Université de Bretagne Sud</orgName>
          <orgName type="acronym">UBS</orgName>
          <desc>
            <address>
              <addrLine>BP 92116 - 56321 Lorient cedex</addrLine>
              <country key="FR" />
            </address>
            <ref type="url">http://www.univ-ubs.fr/</ref>
          </desc>
        </org>
        <org type="institution" xml:id="struct-247362" status="VALID">
          <idno type="ROR">https://ror.org/03rxtdc22</idno>
          <orgName>École normale supérieure - Rennes</orgName>
          <orgName type="acronym">ENS Rennes</orgName>
          <desc>
            <address>
              <addrLine>Campus de Ker Lann - avenue Robert Schuman - 35170 Bruz</addrLine>
              <country key="FR" />
            </address>
            <ref type="url">http://www.ens-rennes.fr</ref>
          </desc>
        </org>
        <org type="institution" xml:id="struct-411575" status="VALID">
          <idno type="IdRef">184443237</idno>
          <idno type="ROR">https://ror.org/019tcpt25</idno>
          <orgName>CentraleSupélec</orgName>
          <desc>
            <address>
              <addrLine>3, rue Joliot Curie,Plateau de Moulon,91192 GIF-SUR-YVETTE Cedex</addrLine>
              <country key="FR" />
            </address>
            <ref type="url">http://www.centralesupelec.fr</ref>
          </desc>
        </org>
        <org type="regroupinstitution" xml:id="struct-441569" status="VALID">
          <idno type="IdRef">02636817X</idno>
          <idno type="ISNI">0000000122597504</idno>
          <idno type="ROR">https://ror.org/02feahw73</idno>
          <orgName>Centre National de la Recherche Scientifique</orgName>
          <orgName type="acronym">CNRS</orgName>
          <date type="start">1939-10-19</date>
          <desc>
            <address>
              <country key="FR" />
            </address>
            <ref type="url">https://www.cnrs.fr/</ref>
          </desc>
        </org>
        <org type="institution" xml:id="struct-481355" status="VALID">
          <idno type="IdRef">202743233</idno>
          <idno type="ROR">https://ror.org/030hj3061</idno>
          <orgName>IMT Atlantique</orgName>
          <orgName type="acronym">IMT Atlantique</orgName>
          <date type="start">2017-01-01</date>
          <desc>
            <address>
              <addrLine>Campus Brest : Technopôle Brest-Iroise CS 8381829238 BREST Cedex 3 -Campus Nantes : 4, rue Alfred Kastler- La chantrerie 44300 NANTES -Campus Rennes :  2 Rue de la Châtaigneraie, 35510 CESSON SEVIGNE</addrLine>
              <country key="FR" />
            </address>
            <ref type="url">https://www.imt-atlantique.fr</ref>
          </desc>
          <listRelation>
            <relation active="#struct-302102" type="direct" />
          </listRelation>
        </org>
        <org type="regroupinstitution" xml:id="struct-302102" status="VALID">
          <idno type="ROR">https://ror.org/025vp2923</idno>
          <orgName>Institut Mines-Télécom [Paris]</orgName>
          <orgName type="acronym">IMT</orgName>
          <date type="start">2012-03-01</date>
          <desc>
            <address>
              <addrLine>37-39 Rue Dareau, 75014 Paris</addrLine>
              <country key="FR" />
            </address>
            <ref type="url">http://www.mines-telecom.fr/</ref>
          </desc>
        </org>
      </listOrg>
    </back>
  <teiCorpus>
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Adaptation of AI Explanations to Users' Roles</title>
			</titleStmt>
			<publicationStmt>
				<publisher />
				<availability status="unknown"><licence /></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Julien</forename><surname>Delaunay</surname></persName>
							<email>julien.delaunay@inria.fr</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Inria</orgName>
								<orgName type="institution" key="instit2">IRISA Rennes</orgName>
								<address>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Christine</forename><surname>Largouet</surname></persName>
							<email>christine.largouet@irisa.fr</email>
							<affiliation key="aff1">
								<orgName type="department">Institut Agro</orgName>
								<orgName type="institution">IRISA Rennes</orgName>
								<address>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Luis</forename><surname>Galarraga</surname></persName>
							<email>luis.galarraga@inria.fr</email>
							<affiliation key="aff2">
								<orgName type="institution" key="instit1">Inria</orgName>
								<orgName type="institution" key="instit2">IRISA Rennes</orgName>
								<address>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Niels</forename><surname>Van Berkel</surname></persName>
							<email>nielsvanberkel@cs.aau.dk</email>
							<affiliation key="aff3">
								<orgName type="institution">Aalborg University Aalborg</orgName>
								<address>
									<country key="DK">Danemark</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Adaptation of AI Explanations to Users' Roles</title>
					</analytic>
					<monogr>
						<imprint>
							<date />
						</imprint>
					</monogr>
					<idno type="MD5">AD51CE844681639C5C0D7475DCBC7117</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-04-12T14:49+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid" />
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Explainability</term>
					<term>Interpretability</term>
					<term>User Study CCS Concepts</term>
					<term>Human-centered computing → Human computer interaction (HCI)</term>
					<term>User studies</term>
				</keywords>
			</textClass>
			<abstract>
<div><p>Surrogate explanations approximate a complex model by training a simpler model over an interpretable space. Among these simpler models, we identify three kinds of surrogate methods: (a) feature-attribution, (b) example-based, and (c) rule-based explanations. Each surrogate approximates the complex model differently, and we hypothesise that this can impact how users interpret the explanation. Despite the numerous calls for introducing explanations for all, no prior work has compared the impact of these surrogates on specific user roles (e.g., domain expert, developer). In this article, we outline a study design to assess the impact of these three surrogate techniques across different user roles.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div><head>Introduction</head><p>Machine Learning (ML) models are increasingly used, spanning from recommendation systems for entertainment applications to decision support for critical tasks such as law <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b25">26]</ref> and medicine <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b16">17]</ref>. These algorithms' efficiency has increased at the cost of opaqueness and bias <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b28">29]</ref>. An increasing focus is placed on transparency and explanations to uncover and mitigate the biases and errors introduced by ML algorithms. Among these explanation methods, surrogate-based-model-explanations (for now on surrogate explanations) are the most frequently used <ref type="bibr" target="#b15">[16]</ref>. The surrogate methods train a proxy to imitate the classifier's outcomes. This proxy is selected for its simple design, highly transparent, and ease of understanding. In their survey, Bodria et al. <ref type="bibr" target="#b5">[6]</ref> grouped the surrogate explanations into three categories: (a) feature-attribution, (b) rules, and (c) example-based explanations. Each of these has a different aim, presented first in this paper, ultimately impacting how the explanation is generated and presented to the user. While many researchers have pointed out the need for user studies to evaluate novel XAI methods <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b9">10]</ref>, relatively few studies have been conducted. Adadi et al. <ref type="bibr" target="#b1">[2]</ref> highlighted that in 2019, from a total of 381 XAI papers, only 5% emphasised users in evaluating XAI methods. Furthermore, although various user roles are involved in the application of ML models (e.g., developers, end-users), evaluations are primarily focused on developers as explanation methods are currently mostly used by developers <ref type="bibr" target="#b4">[5]</ref>. Researchers have proposed to create explanations adapted to users' roles, suggesting a total of three different roles: (a) developers, (b) domain experts, and (c) lay users <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b24">25]</ref>. However, users are more complex entities, and additional criteria may impact their experience with AI systems (e.g. level of trust in AI). We thus propose to conserve the original three roles as one of the multiple dimensions of user roles and present additional criteria. Finally, we introduce a methodology to conduct user studies comparing the impact of the surrogates depending on the context, task, and user role. These studies aim to help select the explanation methods adapted to user roles.</p><formula xml:id="formula_0">Instance x f o = 0, a = 18, mc = 1, bm = 'Low ′ , hc = 'N o ′ , (o = 30) Explanations Feature (f o = 0) → -6, attribution (bm ≥ 'Low ′ ) → -5 Rule If a ≤ 20 ∧ mc = 1 ⇒ non-obese Example bm = 'Sometimes ′ , hc = 'Y es ′ , (o = 70)</formula></div>
<div><head>Surrogate Explanations</head><p>Each of the three surrogate explanations methods differs in the way they approximate a black-box classifier <ref type="bibr" target="#b5">[6]</ref>. Therefore, before elaborating on adapting the surrogate to the user, we first clarify how these methods work and differ. We represent mathematical and graphical explanations for these three surrogates in Table <ref type="table" target="#tab_0">1</ref> and Figure <ref type="figure" target="#fig_1">1</ref>. Each of these explanations shows the main reason for the prediction made by a random forest classifier.</p><p>Feature attribution methods associate a weight to the input features to indicate a positive or negative impact on the final prediction. Therefore, Figure <ref type="figure" target="#fig_1">1a</ref> shows the explanations in a similar way to what is shown in LIME <ref type="bibr" target="#b22">[23]</ref> and SHAP <ref type="bibr" target="#b17">[18]</ref>, the methods the most commonly used to generate an explanation <ref type="bibr" target="#b15">[16]</ref>. Red and blue horizontal bars indicate respectively positive and negative impact. The final score and the vertical bar correspond to the final prediction. Explanations from Figure <ref type="figure" target="#fig_1">1a</ref> and Table <ref type="table" target="#tab_0">1</ref> indicate that the user is less prone to develop obesity due to the absence of obesity antecedents in their family and low consumption of food between meals.</p><p>Rule-based surrogates provide the minimum requirements for a given outcome <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b23">24]</ref>. These requirements take the form of 'if-then' rules that represent the conditions for a classifier to make a given prediction. These methods are commonly represented as in Table <ref type="table" target="#tab_0">1</ref>, however, Figure <ref type="figure" target="#fig_1">1b</ref> depicts similarly to <ref type="bibr" target="#b19">[20]</ref>, the increasing classifier's confidence in predicting non-obese as the conditions of the rule (i.e., age and monitoring calorie consumption) are met.</p><p>Example-based explanations present instances similar to the target with a comparable (prototype <ref type="bibr" target="#b12">[13]</ref>) or different  (counterfactual <ref type="bibr" target="#b8">[9]</ref>) classifier's reaction. To the best of our knowledge, no graphic illustration exists for counterfactuals, leading us to develop our own interpretation as shown in Figure <ref type="figure" target="#fig_1">1c</ref>. Thus, Figure <ref type="figure" target="#fig_1">1c</ref> shows the change in the AI's outcome when modifying a feature value. The counterfactual from Table <ref type="table" target="#tab_0">1</ref> and Figure <ref type="figure" target="#fig_1">1c</ref> shows that increasing both the consumption of high-caloric food and intake of food between meals would have changed the prediction.</p><p>Due to a lack of surrogate explanations comparison, XAI users are presently unable to indicate why they might use one type of proxy rather than another. However, the choice of the surrogate and its representation may impact the users (e.g., trust, understanding) <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b27">28]</ref>. We hence argue that preferring one type of proxy over another should be driven by criteria and situations rather than for functional reasons. We next present different user roles to guide researchers and actors in investigating the impact of selecting a surrogate and representation depending on user roles.</p></div>
<div><head>HOW TO MEASURE THE IMPACT OF EXPLANATIONS ON USERS?</head></div>
<div><head>Intentional measurements</head><p>Trust. Cahour and Forzy's scale <ref type="bibr" target="#b6">[7]</ref>. <ref type="bibr" target="#b14">[15]</ref>.</p></div>
<div><head>Satisfaction. Hoffman et al.'s questionnaire</head></div>
<div><head>Understanding. Madsen and</head><p>Gregor's questionnaire <ref type="bibr" target="#b18">[19]</ref>.</p></div>
<div><head>Behavioural measurements</head><p>Trust. The users have the option to modify their prediction after seeing the AI's prediction.</p><p>Satisfaction. The time mandatory to solve the simple task or predict. </p></div>
<div><head>Understanding. The users have to indicate which factors impact the most toward the prediction</head></div>
<div><head>User Roles</head><p>Most existing research has focused on three types of roles <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b24">25]</ref>: (a) developers that create or assess AI systems; (b) domain experts, persons with knowledge or authority in a particular area; and (c) lay users, individuals to whom the AI decision is applied (e.g., bank client). Yet, we argue that users and usage scenarios are more complex than those three well-defined categories. Instead, users of AI systems are multi-dimensional (e.g., roles, goals, trust in AI), and various scenarios affect the suitability of different explanation methods (e.g., data types, explanation representation). We thus propose four additional aspects to consider when selecting explanations adapted to users:</p><p>• The motivation to compute the explanation (e.g., increasing performance or trust in the system) is a key criterion for determining the appropriate model.</p><p>• The trust in AI systems may differ among the users as not all programmers have blind faith in the systems they code while lay people may place excessive trust in it.</p><p>• The challenges of representing data types such as sound or time series is one of the reasons why few explanation methods exist for these data types <ref type="bibr" target="#b5">[6]</ref>. As such, the data type influences the choice of the surrogate.</p><p>• Selecting one explanation representation over another (e.g., Figure <ref type="figure" target="#fig_1">1</ref> rather than Table <ref type="table" target="#tab_0">1</ref>) is crucial since it has been widely accepted that representations impact how users perceived AI systems <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b21">22]</ref>.</p><p>Evaluating how each dimension of the user roles and usage scenarios impacts the perception of surrogate explanation would allow associating surrogate methods adapted to users. We thus elaborate on our evaluation proposal to compare the impact of the three explanations surrogates on various users' roles.</p></div>
<div><head>Methodology</head><p>Based on various recommendations <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b27">28]</ref>, we outline in this section (i) diverse metrics to measure both user behavioural and perceived impact of an explanation surrogate, and (ii) a roadmap for conducting generic and replicable user studies for a given surrogate and representation. Perception and Behavioural. Van der Waa et al. highlighted the importance of employing mixed metrics to conduct XAI user studies <ref type="bibr" target="#b27">[28]</ref>. We also emphasise differentiating between perceived and behavioural measurements, as the user's perception may differ from their actual behaviour or decision-making. Therefore, we propose combining questionnaires measuring self-reported perception and simple tasks to gauge performance. Table <ref type="table" target="#tab_1">2</ref> summarises possible metrics and questionnaires to measure both the perceived and behavioural users' (a) understanding, (b) trust, and (c) satisfaction. From these multi-axes measurements, users can envision using one explanation method more than another.</p><p>Roadmap. Figure <ref type="figure" target="#fig_2">2</ref> illustrates an experimental protocol to conduct user studies evaluating the impact of a chosen explanation method and representation for one user role.</p><p>In the initial steps, we advise introducing the domain and the objective of the experiments. Then, to reduce the possibility of biases led by a short or long training round <ref type="bibr" target="#b27">[28]</ref>, an example round defines the user's task and the details of the explanation. Following, participants complete the actual study tasks. This can be repeated multiple times to obtain more reliable results. Participants are asked to predict using the same information as the system. Afterwards, participants have access to the AI prediction and its associated explanation. This approach allows for assessing the behavioural understanding, trust, and satisfaction as defined in Table <ref type="table" target="#tab_1">2</ref>. Finally, in the final round, we measure the perceived impact of the explanation through several questionnaires as described in Table <ref type="table" target="#tab_1">2</ref>.</p><p>By running this experiment for distinct (a) user profiles, (b) explanation surrogates, and (c) representations, researchers and actors may gain insight into which explanation and representation are the more suitable for a specific user based on various criteria.</p></div>
<div><head>Future Work</head><p>In this paper, we proposed considering users as more complex than the three original roles but as a multi-axes complexity scale. Comparing the impact of the three surrogate categories over the different aspects of users would benefit the ML sub-community of XAI by allowing them to manage and carefully select the appropriate proxy. Conversely, the HCI sub-community would profit from the roadmap we introduced due to the possibility of conducting generic and replicable user studies. Currently, we launched our experiments on tabular data, with 250 crowdworkers, three surrogates and two representations. Finally, we seek to conduct our investigation with computer scientists from different research laboratories, specialists either in HCI or ML, and domain experts in a relevant domain (e.g., healthcare).</p></div><figure xml:id="fig_0"><head /><label /><figDesc>(a) Feature-attribution explanation. (b) Rule-based explanation.(c) Counterfactual explanation.</figDesc></figure>
<figure xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Graphical representation of three different explanation proxies for a given instance predicted as non-obese by a classifier.</figDesc><graphic coords="4,522.46,113.46,176.42,94.64" type="bitmap" /></figure>
<figure xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Plan for user study evaluating the impact of a given explanation on users. The tasks are repeated n times, where n is the number of instances predicted by the user. Elements in green are behavioural measurements while in blue are self-reported.</figDesc><graphic coords="5,35.46,129.53,129.59,292.87" type="bitmap" /></figure>
<figure type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Explanations for a</figDesc><table><row><cell>classifier C computing the risk of</cell></row><row><cell>obesity o ∈ [0, 100] with the</cell></row><row><cell>outcome of 'non-obese' if o ≤ 50.</cell></row><row><cell>The attributes consist of the</cell></row><row><cell>patient's family's obesity</cell></row><row><cell>antecedents (fo), age (a),</cell></row><row><cell>monitoring calorie consumption</cell></row><row><cell>(mc), consumption of food between</cell></row><row><cell>meals (bm), and high-caloric food</cell></row><row><cell>(hc).</cell></row></table></figure>
<figure type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Metrics to measure user intent and behaviour.</figDesc><table /></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Persistent Anti-Muslim Bias in Large Language Models</title>
		<author>
			<persName><forename type="first">Abubakar</forename><surname>Abid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maheen</forename><surname>Farooqi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Zou</surname></persName>
		</author>
		<idno type="DOI">10.1145/3461702.3462624</idno>
		<ptr target="https://doi.org/10.1145/3461702.3462624" />
	</analytic>
	<monogr>
		<title level="m">Proc. AIES. ACM</title>
		<meeting>AIES. ACM</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Peeking Inside the Black-Box: A Survey on Explainable Artificial Intelligence (XAI)</title>
		<author>
			<persName><forename type="first">Amina</forename><surname>Adadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohammed</forename><surname>Berrada</surname></persName>
		</author>
		<idno type="DOI">10.1109/ACCESS.2018.2870052</idno>
		<ptr target="http://dx.doi.org/10.1109/ACCESS.2018.2870052" />
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="52138" to="52160" />
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Explainable Agents and Robots: Results from a Systematic Literature Review</title>
		<author>
			<persName><forename type="first">Sule</forename><surname>Anjomshoae</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amro</forename><surname>Najjar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Davide</forename><surname>Calvaresi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kary</forename><surname>Främling</surname></persName>
		</author>
		<ptr target="http://dl.acm.org/citation.cfm?id=3331806" />
	</analytic>
	<monogr>
		<title level="m">Proc. AAMAS. International Foundation for Autonomous Agents and Multiagent Systems</title>
		<meeting>AAMAS. International Foundation for Autonomous Agents and Multiagent Systems</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Thirty years of Artificial Intelligence and Law: overviews</title>
		<author>
			<persName><forename type="first">Michał</forename><surname>Araszkiewicz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Trevor</forename><surname>Bench-Capon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Enrico</forename><surname>Francesconi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marc</forename><surname>Lauritsen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Antonino</forename><surname>Rotolo</surname></persName>
		</author>
		<idno type="DOI">10.1007/s10506-022-09324-9</idno>
		<ptr target="https://doi.org/10.1007/s10506-022-09324-9" />
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence and Law</title>
		<imprint>
			<date type="published" when="2022-08-06">2022. 06 Aug 2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Explainable machine learning in deployment</title>
		<author>
			<persName><forename type="first">Umang</forename><surname>Bhatt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alice</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shubham</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adrian</forename><surname>Weller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ankur</forename><surname>Taly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yunhan</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joydeep</forename><surname>Ghosh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruchir</forename><surname>Puri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">F</forename><surname>José</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Moura</surname></persName>
		</author>
		<author>
			<persName><surname>Eckersley</surname></persName>
		</author>
		<idno type="DOI">10.1145/3351095.3375624</idno>
		<ptr target="http://dx.doi.org/10.1145/3351095.3375624" />
	</analytic>
	<monogr>
		<title level="m">Proc. on Fairness, Accountability, and Transparency (FAT)</title>
		<meeting>on Fairness, Accountability, and Transparency (FAT)</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Benchmarking and Survey of Explanation Methods for Black Box Models</title>
		<author>
			<persName><forename type="first">Francesco</forename><surname>Bodria</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fosca</forename><surname>Giannotti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Riccardo</forename><surname>Guidotti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Francesca</forename><surname>Naretto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dino</forename><surname>Pedreschi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Salvatore</forename><surname>Rinzivillo</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2102.13076" />
	</analytic>
	<monogr>
		<title level="j">CoRR</title>
		<imprint>
			<date type="published" when="2021">2021. 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Does projection into use improve trust and exploration? An example with a cruise control system</title>
		<author>
			<persName><forename type="first">Béatrice</forename><surname>Cahour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jean-François</forename><surname>Forzy</surname></persName>
		</author>
		<ptr target="https://www.sciencedirect.com/science/article/pii/S0925753509000587" />
	</analytic>
	<monogr>
		<title level="j">Safety Science</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1260" to="1270" />
			<date type="published" when="2009">2009. 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Explaining Decision-Making Algorithms through UI: Strategies to Help Non-Expert Stakeholders</title>
		<author>
			<persName><forename type="first">Ruotong</forename><surname>Hao Fei Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zheng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fiona O'</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Terrance</forename><surname>Connell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">Maxwell</forename><surname>Gray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haiyi</forename><surname>Harper</surname></persName>
		</author>
		<author>
			<persName><surname>Zhu</surname></persName>
		</author>
		<idno type="DOI">10.1145/3290605.3300789</idno>
		<ptr target="https://doi.org/10.1145/3290605.3300789" />
	</analytic>
	<monogr>
		<title level="m">Proc. CHI. ACM</title>
		<meeting>CHI. ACM</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">When Should We Use Linear Explanations?</title>
		<author>
			<persName><forename type="first">Julien</forename><surname>Delaunay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luis</forename><surname>Galárraga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christine</forename><surname>Largouët</surname></persName>
		</author>
		<idno type="DOI">10.1145/3511808.3557489</idno>
		<ptr target="https://doi.org/10.1145/3511808.3557489" />
	</analytic>
	<monogr>
		<title level="m">Proc. CIKM. ACM</title>
		<meeting>CIKM. ACM</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Towards A Rigorous Science of Interpretable Machine Learning</title>
		<author>
			<persName><forename type="first">Finale</forename><surname>Doshi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">-</forename><surname>Velez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Been</forename><surname>Kim</surname></persName>
		</author>
		<idno>arXiv:</idno>
		<ptr target="https://arxiv.org/abs/1702.08608" />
	</analytic>
	<monogr>
		<title level="m">Machine Learning</title>
		<imprint>
			<date type="published" when="2017">2017. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Dermatologist-level classification of skin cancer with deep neural networks</title>
		<author>
			<persName><forename type="first">Andre</forename><surname>Esteva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brett</forename><surname>Kuprel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roberto</forename><forename type="middle">A</forename><surname>Novoa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Justin</forename><surname>Ko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Susan</forename><forename type="middle">M</forename><surname>Swetter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Helen</forename><forename type="middle">M</forename><surname>Blau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Thrun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">nature</title>
		<imprint>
			<biblScope unit="volume">542</biblScope>
			<biblScope unit="page" from="115" to="118" />
			<date type="published" when="2017">2017. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Local Rule-Based Explanations of Black Box Decision Systems</title>
		<author>
			<persName><forename type="first">Riccardo</forename><surname>Guidotti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anna</forename><surname>Monreale</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Salvatore</forename><surname>Ruggieri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dino</forename><surname>Pedreschi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Franco</forename><surname>Turini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fosca</forename><surname>Giannotti</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/1805.10820" />
	</analytic>
	<monogr>
		<title level="j">CoRR</title>
		<imprint>
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">VCNet: A self-explaining model for realistic counterfactual generation</title>
		<author>
			<persName><forename type="first">Victor</forename><surname>Guyomard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Françoise</forename><surname>Fessant</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Guyet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tassadit</forename><surname>Bouadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexandre</forename><surname>Termier</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2212.10847</idno>
		<idno>CoRR abs/2212.10847</idno>
		<ptr target="https://doi.org/10.48550/arXiv.2212.10847" />
		<imprint>
			<date type="published" when="2022">2022. 2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Who wants what and how: a Mapping Function for Explainable Artificial Intelligence</title>
		<author>
			<persName><forename type="first">Maryam</forename><surname>Hashemi</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2302.03180</idno>
		<idno>CoRR abs/2302.03180</idno>
		<ptr target="http://dx.doi.org/10.48550/arXiv.2302.03180" />
		<imprint>
			<date type="published" when="2023">2023. 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Metrics for Explainable AI: Challenges and Prospects</title>
		<author>
			<persName><forename type="first">Robert</forename><forename type="middle">R</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shane</forename><forename type="middle">T</forename><surname>Mueller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gary</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jordan</forename><surname>Litman</surname></persName>
		</author>
		<idno>CoRR abs/1812.04608</idno>
		<ptr target="http://arxiv.org/abs/1812.04608" />
		<imprint>
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Trends in Explainable AI (XAI) Literature</title>
		<author>
			<persName><forename type="first">Alon</forename><surname>Jacovi</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2301.05433</idno>
		<idno>CoRR abs/2301.05433</idno>
		<ptr target="http://dx.doi.org/10.48550/arXiv.2301.05433" />
		<imprint>
			<date type="published" when="2023">2023. 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Interpretability methods of machine learning algorithms with applications in breast cancer diagnosis</title>
		<author>
			<persName><forename type="first">P</forename><surname>Karatza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Dalakleidi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Athanasiou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">S</forename><surname>Nikita</surname></persName>
		</author>
		<idno type="DOI">10.1109/EMBC46164.2021.9630556</idno>
		<ptr target="http://dx.doi.org/10.1109/EMBC46164.2021.9630556" />
	</analytic>
	<monogr>
		<title level="m">Proc. Engineering in Medicine &amp; Biology Society (EMBC)</title>
		<meeting>Engineering in Medicine &amp; Biology Society (EMBC)</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">A Unified Approach to Interpreting Model Predictions</title>
		<author>
			<persName><forename type="first">M</forename><surname>Scott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Su-In</forename><surname>Lundberg</surname></persName>
		</author>
		<author>
			<persName><surname>Lee</surname></persName>
		</author>
		<ptr target="https://proceedings.neurips.cc/paper/2017/hash/8a20a8621978632d76c43dfd28b67767-Abstract.html" />
	</analytic>
	<monogr>
		<title level="m">Proc. NeuIPS</title>
		<meeting>NeuIPS</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Measuring Human-Computer Trust</title>
		<author>
			<persName><forename type="first">Maria</forename><surname>Madsen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shirley</forename><forename type="middle">D</forename><surname>Gregor</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Interprtable machine learning: A guide for making black box models explainable</title>
		<author>
			<persName><forename type="first">Christoph</forename><surname>Molnar</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Weapons of Math Destruction: How Big Data Increases Inequality and Threatens Democracy</title>
		<author>
			<persName><forename type="first">O'</forename><surname>Cathy</surname></persName>
		</author>
		<author>
			<persName><surname>Neil</surname></persName>
		</author>
		<idno type="DOI">10.5860/crl.78.3.403</idno>
		<ptr target="https://doi.org/10.5860/crl.78.3.403" />
	</analytic>
	<monogr>
		<title level="j">Coll. Res. Libr</title>
		<imprint>
			<biblScope unit="volume">78</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="403" to="404" />
			<date type="published" when="2017">2017. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Manipulating and Measuring Model Interpretability</title>
		<author>
			<persName><forename type="first">Forough</forename><surname>Poursabzi-Sangdeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><forename type="middle">G</forename><surname>Goldstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jake</forename><forename type="middle">M</forename><surname>Hofman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jennifer</forename><forename type="middle">Wortman</forename><surname>Vaughan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hanna</forename><forename type="middle">M</forename><surname>Wallach</surname></persName>
		</author>
		<idno type="DOI">10.1145/3411764.3445315</idno>
		<ptr target="https://doi.org/10.1145/3411764.3445315" />
	</analytic>
	<monogr>
		<title level="m">Proc. CHI. ACM</title>
		<meeting>CHI. ACM</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Explaining the Predictions of Any Classifier</title>
		<author>
			<persName><forename type="first">Marco</forename><surname>Túlio Ribeiro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sameer</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carlos</forename><surname>Guestrin</surname></persName>
		</author>
		<idno type="DOI">10.1145/2939672.2939778</idno>
		<ptr target="https://doi.org/10.1145/2939672.2939778" />
	</analytic>
	<monogr>
		<title level="m">Proc. SIGKDD. ACM</title>
		<meeting>SIGKDD. ACM</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note>Why Should I Trust You?</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Anchors: High-Precision Model-Agnostic Explanations</title>
		<author>
			<persName><forename type="first">Marco</forename><surname>Túlio Ribeiro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sameer</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carlos</forename><surname>Guestrin</surname></persName>
		</author>
		<ptr target="https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/16982" />
	</analytic>
	<monogr>
		<title level="m">Proc. AAAI. AAAI Press</title>
		<meeting>AAAI. AAAI Press</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Can we do better explanations? A proposal of user-centered explainable AI</title>
		<author>
			<persName><forename type="first">Mireia</forename><surname>Ribera</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Àgata</forename><surname>Lapedriza</surname></persName>
		</author>
		<ptr target="http://ceur-ws.org/Vol-2327/IUI19WS-ExSS2019-12.pdf" />
	</analytic>
	<monogr>
		<title level="m">Proc. IUI Workshops</title>
		<title level="s">CEUR Workshop Proceedings). CEUR</title>
		<meeting>IUI Workshops</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Unsupervised law article mining based on deep pre-trained language representation models with application to the Italian civil code</title>
		<author>
			<persName><forename type="first">Andrea</forename><surname>Tagarelli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrea</forename><surname>Simeri</surname></persName>
		</author>
		<idno type="DOI">10.1007/s10506-021-09301-8</idno>
		<ptr target="https://doi.org/10.1007/s10506-021-09301-8" />
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence and Law</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="417" to="473" />
			<date type="published" when="2022-09-01">2022. 01 Sep 2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Effect of Information Presentation on Fairness Perceptions of Machine Learning Predictors</title>
		<author>
			<persName><forename type="first">Niels</forename><surname>Van Berkel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jorge</forename><surname>Goncalves</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Russo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Simo</forename><surname>Hosio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mikael</forename><forename type="middle">B</forename><surname>Skov</surname></persName>
		</author>
		<idno type="DOI">10.1145/3411764.3445365</idno>
		<ptr target="http://dx.doi.org/10.1145/3411764.3445365" />
	</analytic>
	<monogr>
		<title level="m">Proc. CHI. ACM</title>
		<meeting>CHI. ACM</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Evaluating XAI: A comparison of rule-based and example-based explanations</title>
		<author>
			<persName><forename type="first">Elisabeth</forename><surname>Jasper Van Der Waa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anita</forename><forename type="middle">H M</forename><surname>Nieuwburg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><forename type="middle">A</forename><surname>Cremers</surname></persName>
		</author>
		<author>
			<persName><surname>Neerincx</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.artint.2020.103404</idno>
		<ptr target="https://doi.org/10.1016/j.artint.2020.103404" />
	</analytic>
	<monogr>
		<title level="j">Artif. Intell</title>
		<imprint>
			<biblScope unit="volume">291</biblScope>
			<biblScope unit="page">103404</biblScope>
			<date type="published" when="2021">2021. 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Failure of chatbot Tay was evil, ugliness and uselessness in its nature or do we judge it through cognitive shortcuts and biases</title>
		<author>
			<persName><forename type="first">Tomás</forename><surname>Zemcík</surname></persName>
		</author>
		<idno type="DOI">10.1007/s00146-020-01053-4</idno>
		<ptr target="https://doi.org/10.1007/s00146-020-01053-4" />
	</analytic>
	<monogr>
		<title level="j">AI Soc</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="361" to="367" />
			<date type="published" when="2021">2021. 2021</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</teiCorpus></text>
</TEI>