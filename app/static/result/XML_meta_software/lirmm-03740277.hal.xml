<?xml version="1.0" encoding="utf-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:hal="http://hal.archives-ouvertes.fr/" version="1.1" xsi:schemaLocation="http://www.tei-c.org/ns/1.0 http://api.archives-ouvertes.fr/documents/aofr-sword.xsd">
  <teiHeader>
    <fileDesc>
      <titleStmt>
        <title>HAL TEI export of lirmm-03740277</title>
      </titleStmt>
      <publicationStmt>
        <distributor>CCSD</distributor>
        <availability status="restricted">
          <licence target="http://creativecommons.org/licenses/by/4.0/">Distributed under a Creative Commons Attribution 4.0 International License</licence>
        </availability>
        <date when="2024-04-29T11:49:54+02:00"/>
      </publicationStmt>
      <sourceDesc>
        <p part="N">HAL API platform</p>
      </sourceDesc>
    </fileDesc>
  </teiHeader>
  <text>
    <body>
      <listBibl>
        <biblFull>
          <titleStmt>
            <title xml:lang="en">Large-scale Knowledge Distillation with Elastic Heterogeneous Computing Resources</title>
            <author role="aut">
              <persName>
                <forename type="first">Ji</forename>
                <surname>Liu</surname>
              </persName>
              <email type="md5">5d0ed92f5d94bad6f1d4ad63b663c80a</email>
              <email type="domain">inria.fr</email>
              <idno type="idhal" notation="numeric">958433</idno>
              <idno type="halauthorid" notation="string">787622-958433</idno>
              <idno type="ORCID">https://orcid.org/0000-0003-4710-5697</idno>
              <affiliation ref="#struct-510362"/>
            </author>
            <author role="aut">
              <persName>
                <forename type="first">Daxiang</forename>
                <surname>Dong</surname>
              </persName>
              <idno type="halauthorid">2560035-0</idno>
              <affiliation ref="#struct-510362"/>
            </author>
            <author role="aut">
              <persName>
                <forename type="first">Xi</forename>
                <surname>Wang</surname>
              </persName>
              <idno type="halauthorid">853298-0</idno>
              <affiliation ref="#struct-510362"/>
            </author>
            <author role="aut">
              <persName>
                <forename type="first">An</forename>
                <surname>Qin</surname>
              </persName>
              <idno type="halauthorid">995904-0</idno>
              <affiliation ref="#struct-510362"/>
            </author>
            <author role="aut">
              <persName>
                <forename type="first">Xingjian</forename>
                <surname>Li</surname>
              </persName>
              <idno type="halauthorid">2560036-0</idno>
              <affiliation ref="#struct-510362"/>
            </author>
            <author role="aut">
              <persName>
                <forename type="first">Patrick</forename>
                <surname>Valduriez</surname>
              </persName>
              <email type="md5">b7903099e0d3ee0b492cd1c7a982e35b</email>
              <email type="domain">inria.fr</email>
              <idno type="idhal" notation="string">patrick-valduriez</idno>
              <idno type="idhal" notation="numeric">172604</idno>
              <idno type="halauthorid" notation="string">22529-172604</idno>
              <idno type="ORCID">https://orcid.org/0000-0001-6506-7538</idno>
              <idno type="GOOGLE SCHOLAR">https://scholar.google.fr/citations?user=Vj0m2A0AAAAJ&amp;hl=fr</idno>
              <idno type="IDREF">https://www.idref.fr/028314417</idno>
              <affiliation ref="#struct-1100621"/>
            </author>
            <author role="aut">
              <persName>
                <forename type="first">Dejing</forename>
                <surname>Dou</surname>
              </persName>
              <idno type="halauthorid">2421623-0</idno>
              <affiliation ref="#struct-510362"/>
            </author>
            <author role="aut">
              <persName>
                <forename type="first">Dianhai</forename>
                <surname>Yu</surname>
              </persName>
              <idno type="halauthorid">2560037-0</idno>
              <affiliation ref="#struct-510362"/>
            </author>
            <editor role="depositor">
              <persName>
                <forename>Isabelle</forename>
                <surname>Gouat</surname>
              </persName>
              <email type="md5">01a8910ec35817770bca127295d8d38a</email>
              <email type="domain">lirmm.fr</email>
            </editor>
          </titleStmt>
          <editionStmt>
            <edition n="v1" type="current">
              <date type="whenSubmitted">2022-07-29 11:03:58</date>
              <date type="whenModified">2023-11-07 03:25:31</date>
              <date type="whenReleased">2022-07-29 11:06:40</date>
              <date type="whenProduced">2023</date>
              <ref type="externalLink" target="http://arxiv.org/pdf/2207.06667"/>
            </edition>
            <respStmt>
              <resp>contributor</resp>
              <name key="102079">
                <persName>
                  <forename>Isabelle</forename>
                  <surname>Gouat</surname>
                </persName>
                <email type="md5">01a8910ec35817770bca127295d8d38a</email>
                <email type="domain">lirmm.fr</email>
              </name>
            </respStmt>
          </editionStmt>
          <publicationStmt>
            <distributor>CCSD</distributor>
            <idno type="halId">lirmm-03740277</idno>
            <idno type="halUri">https://hal-lirmm.ccsd.cnrs.fr/lirmm-03740277</idno>
            <idno type="halBibtex">liu:lirmm-03740277</idno>
            <idno type="halRefHtml">&lt;i&gt;Concurrency and Computation: Practice and Experience&lt;/i&gt;, 2023, 35 (26), pp.e7272. &lt;a target="_blank" href="https://dx.doi.org/10.1002/cpe.7272"&gt;&amp;#x27E8;10.1002/cpe.7272&amp;#x27E9;&lt;/a&gt;</idno>
            <idno type="halRef">Concurrency and Computation: Practice and Experience, 2023, 35 (26), pp.e7272. &amp;#x27E8;10.1002/cpe.7272&amp;#x27E9;</idno>
          </publicationStmt>
          <seriesStmt>
            <idno type="stamp" n="CNRS">CNRS - Centre national de la recherche scientifique</idno>
            <idno type="stamp" n="INRIA">INRIA - Institut National de Recherche en Informatique et en Automatique</idno>
            <idno type="stamp" n="INRIA-SOPHIA">INRIA Sophia Antipolis - Méditerranée</idno>
            <idno type="stamp" n="INRIASO">INRIA-SOPHIA</idno>
            <idno type="stamp" n="INRIA_TEST">INRIA - Institut National de Recherche en Informatique et en Automatique</idno>
            <idno type="stamp" n="TESTALAIN1">TESTALAIN1</idno>
            <idno type="stamp" n="ZENITH" corresp="LIRMM">Scientific Data Management</idno>
            <idno type="stamp" n="LIRMM">Laboratoire d'Informatique de Robotique et de Microélectronique de Montpellier</idno>
            <idno type="stamp" n="INRIA2">INRIA 2</idno>
            <idno type="stamp" n="UNIV-MONTPELLIER">Université de Montpellier</idno>
            <idno type="stamp" n="UM-2015-2021" corresp="UNIV-MONTPELLIER">Université de Montpellier (2015-2021)</idno>
            <idno type="stamp" n="UM-EPE" corresp="UNIV-MONTPELLIER">Université de Montpellier - EPE</idno>
            <idno type="stamp" n="IA">Intelligence Artificielle</idno>
          </seriesStmt>
          <notesStmt>
            <note type="audience" n="2">International</note>
            <note type="popular" n="0">No</note>
            <note type="peer" n="1">Yes</note>
          </notesStmt>
          <sourceDesc>
            <biblStruct>
              <analytic>
                <title xml:lang="en">Large-scale Knowledge Distillation with Elastic Heterogeneous Computing Resources</title>
                <author role="aut">
                  <persName>
                    <forename type="first">Ji</forename>
                    <surname>Liu</surname>
                  </persName>
                  <email type="md5">5d0ed92f5d94bad6f1d4ad63b663c80a</email>
                  <email type="domain">inria.fr</email>
                  <idno type="idhal" notation="numeric">958433</idno>
                  <idno type="halauthorid" notation="string">787622-958433</idno>
                  <idno type="ORCID">https://orcid.org/0000-0003-4710-5697</idno>
                  <affiliation ref="#struct-510362"/>
                </author>
                <author role="aut">
                  <persName>
                    <forename type="first">Daxiang</forename>
                    <surname>Dong</surname>
                  </persName>
                  <idno type="halauthorid">2560035-0</idno>
                  <affiliation ref="#struct-510362"/>
                </author>
                <author role="aut">
                  <persName>
                    <forename type="first">Xi</forename>
                    <surname>Wang</surname>
                  </persName>
                  <idno type="halauthorid">853298-0</idno>
                  <affiliation ref="#struct-510362"/>
                </author>
                <author role="aut">
                  <persName>
                    <forename type="first">An</forename>
                    <surname>Qin</surname>
                  </persName>
                  <idno type="halauthorid">995904-0</idno>
                  <affiliation ref="#struct-510362"/>
                </author>
                <author role="aut">
                  <persName>
                    <forename type="first">Xingjian</forename>
                    <surname>Li</surname>
                  </persName>
                  <idno type="halauthorid">2560036-0</idno>
                  <affiliation ref="#struct-510362"/>
                </author>
                <author role="aut">
                  <persName>
                    <forename type="first">Patrick</forename>
                    <surname>Valduriez</surname>
                  </persName>
                  <email type="md5">b7903099e0d3ee0b492cd1c7a982e35b</email>
                  <email type="domain">inria.fr</email>
                  <idno type="idhal" notation="string">patrick-valduriez</idno>
                  <idno type="idhal" notation="numeric">172604</idno>
                  <idno type="halauthorid" notation="string">22529-172604</idno>
                  <idno type="ORCID">https://orcid.org/0000-0001-6506-7538</idno>
                  <idno type="GOOGLE SCHOLAR">https://scholar.google.fr/citations?user=Vj0m2A0AAAAJ&amp;hl=fr</idno>
                  <idno type="IDREF">https://www.idref.fr/028314417</idno>
                  <affiliation ref="#struct-1100621"/>
                </author>
                <author role="aut">
                  <persName>
                    <forename type="first">Dejing</forename>
                    <surname>Dou</surname>
                  </persName>
                  <idno type="halauthorid">2421623-0</idno>
                  <affiliation ref="#struct-510362"/>
                </author>
                <author role="aut">
                  <persName>
                    <forename type="first">Dianhai</forename>
                    <surname>Yu</surname>
                  </persName>
                  <idno type="halauthorid">2560037-0</idno>
                  <affiliation ref="#struct-510362"/>
                </author>
              </analytic>
              <monogr>
                <idno type="halJournalId" status="VALID">12070</idno>
                <idno type="issn">1532-0626</idno>
                <idno type="eissn">1532-0634</idno>
                <title level="j">Concurrency and Computation: Practice and Experience</title>
                <imprint>
                  <publisher>Wiley</publisher>
                  <biblScope unit="volume">35</biblScope>
                  <biblScope unit="issue">26</biblScope>
                  <biblScope unit="pp">e7272</biblScope>
                  <date type="datePub">2023</date>
                  <date type="dateEpub">2022-08-28</date>
                </imprint>
              </monogr>
              <idno type="arxiv">2207.06667</idno>
              <idno type="doi">10.1002/cpe.7272</idno>
            </biblStruct>
          </sourceDesc>
          <profileDesc>
            <langUsage>
              <language ident="en">English</language>
            </langUsage>
            <textClass>
              <keywords scheme="author">
                <term xml:lang="en">Knowledge distillation</term>
                <term xml:lang="en">Distributed computing</term>
                <term xml:lang="en">Deep neural network</term>
              </keywords>
              <classCode scheme="halDomain" n="info.info-ai">Computer Science [cs]/Artificial Intelligence [cs.AI]</classCode>
              <classCode scheme="halDomain" n="info.info-dc">Computer Science [cs]/Distributed, Parallel, and Cluster Computing [cs.DC]</classCode>
              <classCode scheme="halDomain" n="info.info-lg">Computer Science [cs]/Machine Learning [cs.LG]</classCode>
              <classCode scheme="halTypology" n="ART">Journal articles</classCode>
              <classCode scheme="halOldTypology" n="ART">Journal articles</classCode>
              <classCode scheme="halTreeTypology" n="ART">Journal articles</classCode>
            </textClass>
            <abstract xml:lang="en">
              <p>Although more layers and more parameters generally improve the accuracy of the models, such big models generally have high computational complexity and require big memory, which exceed the capacity of small devices for inference and incurs long training time. In addition, it is difficult to afford long training time and inference time of big models even in high performance servers, as well. As an efficient approach to compress a large deep model (a teacher model) to a compact model (a student model), knowledge distillation emerges as a promising approach to deal with the big models. Existing knowledge distillation methods cannot exploit the elastic available computing resources and correspond to low efficiency. In this paper, we propose an Elastic Deep Learning framework for knowledge Distillation, i.e., EDL-Dist. The advantages of EDL-Dist are three-fold. First, the inference and the training process is separated. Second, elastic available computing resources can be utilized to improve the efficiency. Third, fault-tolerance of the training and inference processes is sup- ported. We take extensive experimentation to show that the throughput of EDL-Dist is up to 3.125 times faster than the baseline method (online knowledge distillation) while the accuracy is similar or higher.</p>
            </abstract>
          </profileDesc>
        </biblFull>
      </listBibl>
    </body>
    <back>
      <listOrg type="structures">
        <org type="institution" xml:id="struct-510362" status="VALID">
          <orgName>Baidu Research</orgName>
          <desc>
            <address>
              <addrLine>Baidu Technology Park, No. 10 Xibeiwang East Road, Haidian District, Beijing, China</addrLine>
              <country key="CN"/>
            </address>
            <ref type="url">http://research.baidu.com/</ref>
          </desc>
        </org>
        <org type="researchteam" xml:id="struct-1100621" status="VALID">
          <idno type="RNSR">201121208J</idno>
          <orgName>Scientific Data Management</orgName>
          <orgName type="acronym">ZENITH</orgName>
          <date type="start">2022-01-01</date>
          <desc>
            <address>
              <addrLine>LIRMM, 161 rue Ada, 34000 Montpellier</addrLine>
              <country key="FR"/>
            </address>
            <ref type="url">https://team.inria.fr/zenith/</ref>
          </desc>
          <listRelation>
            <relation active="#struct-34586" type="direct"/>
            <relation active="#struct-300009" type="indirect"/>
            <relation active="#struct-1100620" type="direct"/>
            <relation name="UMR5506" active="#struct-441569" type="indirect"/>
            <relation name="UMR5506" active="#struct-1100589" type="indirect"/>
          </listRelation>
        </org>
        <org type="laboratory" xml:id="struct-34586" status="VALID">
          <idno type="RNSR">198318250R</idno>
          <idno type="ROR">https://ror.org/01nzkaw91</idno>
          <orgName>Inria Sophia Antipolis - Méditerranée</orgName>
          <orgName type="acronym">CRISAM</orgName>
          <desc>
            <address>
              <addrLine>2004 route des Lucioles BP 93 06902 Sophia Antipolis</addrLine>
              <country key="FR"/>
            </address>
            <ref type="url">http://www.inria.fr/centre/sophia/</ref>
          </desc>
          <listRelation>
            <relation active="#struct-300009" type="direct"/>
          </listRelation>
        </org>
        <org type="institution" xml:id="struct-300009" status="VALID">
          <idno type="ROR">https://ror.org/02kvxyf05</idno>
          <orgName>Institut National de Recherche en Informatique et en Automatique</orgName>
          <orgName type="acronym">Inria</orgName>
          <desc>
            <address>
              <addrLine>Domaine de VoluceauRocquencourt - BP 10578153 Le Chesnay Cedex</addrLine>
              <country key="FR"/>
            </address>
            <ref type="url">http://www.inria.fr/en/</ref>
          </desc>
        </org>
        <org type="laboratory" xml:id="struct-1100620" status="VALID">
          <idno type="IdRef">139590827</idno>
          <idno type="ISNI">0000000405990488</idno>
          <idno type="RNSR">199111950H</idno>
          <idno type="ROR">https://ror.org/013yean28</idno>
          <orgName>Laboratoire d'Informatique de Robotique et de Microélectronique de Montpellier</orgName>
          <orgName type="acronym">LIRMM</orgName>
          <date type="start">2022-01-01</date>
          <desc>
            <address>
              <addrLine>161 rue Ada - 34095 Montpellier</addrLine>
              <country key="FR"/>
            </address>
            <ref type="url">https://www.lirmm.fr</ref>
          </desc>
          <listRelation>
            <relation name="UMR5506" active="#struct-441569" type="direct"/>
            <relation name="UMR5506" active="#struct-1100589" type="direct"/>
          </listRelation>
        </org>
        <org type="regroupinstitution" xml:id="struct-441569" status="VALID">
          <idno type="IdRef">02636817X</idno>
          <idno type="ISNI">0000000122597504</idno>
          <idno type="ROR">https://ror.org/02feahw73</idno>
          <orgName>Centre National de la Recherche Scientifique</orgName>
          <orgName type="acronym">CNRS</orgName>
          <date type="start">1939-10-19</date>
          <desc>
            <address>
              <country key="FR"/>
            </address>
            <ref type="url">https://www.cnrs.fr/</ref>
          </desc>
        </org>
        <org type="regroupinstitution" xml:id="struct-1100589" status="VALID">
          <idno type="ROR">https://ror.org/051escj72</idno>
          <orgName>Université de Montpellier</orgName>
          <orgName type="acronym">UM</orgName>
          <date type="start">2022-01-01</date>
          <desc>
            <address>
              <addrLine>163 rue Auguste Broussonnet - 34090 Montpellier</addrLine>
              <country key="FR"/>
            </address>
            <ref type="url">http://www.umontpellier.fr/</ref>
          </desc>
        </org>
      </listOrg>
    </back>
  </text>
</TEI>