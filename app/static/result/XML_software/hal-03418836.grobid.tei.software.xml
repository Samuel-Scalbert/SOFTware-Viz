<TEI xmlns="http://www.tei-c.org/ns/1.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xml:space="preserve" xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Provenance-and machine learning-based recommendation of parameter values in scientific workflows</title>
				<funder>
					<orgName type="full">Brazilian research agencies CNPq, FAPERJ</orgName>
				</funder>
				<funder>
					<orgName type="full">CNPq</orgName>
				</funder>
				<funder ref="#_82TxVxz">
					<orgName type="full">CAPES (Finance Code</orgName>
				</funder>
				<funder>
					<orgName type="full">FAPERJ</orgName>
				</funder>
				<funder ref="#_vE7H2B6">
					<orgName type="full">CAPES</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher />
				<availability status="unknown"><licence /></availability>
				<date type="published" when="2021-07-05">5 July 2021</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Daniel</forename><forename type="middle">Silva</forename><surname>Junior</surname></persName>
							<email>danieljunior@id.uff.br</email>
							<affiliation key="aff0">
								<orgName type="department">Institute of Computing</orgName>
								<orgName type="institution">Universidade Federal Fluminense</orgName>
								<address>
									<settlement>Niteroi</settlement>
									<region>RJ</region>
									<country key="BR">Brazil</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Esther</forename><surname>Pacitti</surname></persName>
							<affiliation key="aff1">
								<orgName type="laboratory" key="lab1">Inria</orgName>
								<orgName type="laboratory" key="lab2">LIRMM</orgName>
								<orgName type="institution" key="instit1">CNRS</orgName>
								<orgName type="institution" key="instit2">University of Montpellier</orgName>
								<address>
									<settlement>Montpellier</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Aline</forename><surname>Paes</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Computing</orgName>
								<orgName type="institution">Universidade Federal Fluminense</orgName>
								<address>
									<settlement>Niteroi</settlement>
									<region>RJ</region>
									<country key="BR">Brazil</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Daniel</forename><surname>De Oliveira</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Computing</orgName>
								<orgName type="institution">Universidade Federal Fluminense</orgName>
								<address>
									<settlement>Niteroi</settlement>
									<region>RJ</region>
									<country key="BR">Brazil</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Claudio</forename><surname>Ardagna</surname></persName>
						</author>
						<title level="a" type="main">Provenance-and machine learning-based recommendation of parameter values in scientific workflows</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2021-07-05">5 July 2021</date>
						</imprint>
					</monogr>
					<idno type="MD5">C184DD3C0FDE518A275B26230E55A562</idno>
					<idno type="DOI">10.7717/peerj-cs.606</idno>
					<note type="submission">Submitted 11 November 2020 Accepted 31 May 2021</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-04-12T14:52+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid" />
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Subjects Data Mining and Machine Learning</term>
					<term>Data Science</term>
					<term>Databases Scientific workflows</term>
					<term>Recommender systems</term>
					<term>Machine Learning</term>
					<term>Preference Learning</term>
				</keywords>
			</textClass>
			<abstract>
<div><p>Scientific Workflows (SWfs) have revolutionized how scientists in various domains of science conduct their experiments. The management of SWfs is performed by complex tools that provide support for workflow composition, monitoring, execution, capturing, and storage of the data generated during execution. In some cases, they also provide components to ease the visualization and analysis of the generated data. During the workflow's composition phase, programs must be selected to perform the activities defined in the workflow specification. These programs often require additional parameters that serve to adjust the program's behavior according to the experiment's goals. Consequently, workflows commonly have many parameters to be manually configured, encompassing even more than one hundred in many cases. Wrongly parameters' values choosing can lead to crash workflows executions or provide undesired results. As the execution of data-and computeintensive workflows is commonly performed in a high-performance computing environment e.g., (a cluster, a supercomputer, or a public cloud), an unsuccessful execution configures a waste of time and resources. In this article, we present FReeP-Feature Recommender from Preferences, a parameter value recommendation method that is designed to suggest values for workflow parameters, taking into account past user preferences. FReeP is based on Machine Learning techniques, particularly in Preference Learning. FReeP is composed of three algorithms, where two of them aim at recommending the value for one parameter at a time, and the third makes recommendations for n parameters at once. The experimental results obtained with provenance data from two broadly used workflows showed FReeP usefulness in the recommendation of values for one parameter. Furthermore, the results indicate the potential of FReeP to recommend values for n parameters in scientific workflows.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div><head>INTRODUCTION</head><p>Scientific experiments are the basis for evolution in several areas of human knowledge <ref type="bibr" target="#b11">(De Oliveira, Liu &amp; Pacitti, 2019;</ref><ref type="bibr" target="#b50">Mattoso et al., 2010;</ref><ref type="bibr" target="#b36">Hey &amp; Trefethen, 2020;</ref><ref type="bibr" target="#b35">Hey, Gannon &amp; Pinkelman, 2012)</ref>. Based on observations of open problems in their research areas, scientists formulate hypotheses to explain and solve those problems <ref type="bibr" target="#b28">(Gonçalves &amp; Porto, 2015)</ref>. Such hypothesis may be confirmed or refuted, and also can lead to new hypotheses. For a long time, scientific experiments were manually conducted by scientists, including instrumentation, configuration and management of the environment, annotation and analysis of results. Despite the advances obtained with this approach, time and resources were wasted since a small misconfiguration of the parameters of the experiment could compromise the whole experiment. The analysis of errors in the results was also far from trivial <ref type="bibr" target="#b11">(De Oliveira, Liu &amp; Pacitti, 2019)</ref>.</p><p>The evolution in computer science field allowed for the development of technologies that provided useful support for scientists in their experiments. One of these technologies is Scientific Workflows <ref type="bibr" target="#b11">(De Oliveira, Liu &amp; Pacitti, 2019;</ref><ref type="bibr" target="#b17">Deelman et al., 2005)</ref>. A scientific workflow (named workflow henceforth) is an abstraction that represents each step of the experiment expressed as an activity, which has input data and relationships (i.e., data dependencies) with other activities, according to the stages of the experiment <ref type="bibr" target="#b80">(Zhao &amp; Ioan Raicu, 2008)</ref>.</p><p>Several workflows commonly require the execution of multiple data-intensive operations as loading, transformation, and aggregation <ref type="bibr" target="#b50">(Mattoso et al., 2010)</ref>. Multiple computational paradigms can be used for the design and execution of workflows, e.g., shell and Python <software ContextAttributes="used">scripts</software> <ref type="bibr" target="#b49">(Marozzo, Talia &amp; Trunfio, 2013)</ref>, Big Data frameworks (e.g., <software ContextAttributes="used">Hadoop</software> and <software ContextAttributes="used">Spark</software>) <ref type="bibr">(Guedes et al., 2020b)</ref>, but they are usually managed by complex engines named Workflow Management Systems (WfMS). A key feature that a WfMS must address is the efficient and automatic management of parallel processing activities in High Performance Computing (HPC) environments <ref type="bibr" target="#b58">(Ogasawara et al., 2011)</ref>. Besides managing the execution of the workflow in HPC environments, WfMSs are also responsible for capturing, structuring and recording metadata associated to all the data generated during the execution: input data, intermediate data, and the final results. These metadata is well-known as provenance <ref type="bibr" target="#b20">(Freire et al., 2008)</ref>. Based on provenance data, it is possible to analyze the results obtained and to foster the reproducibility of the experiment, which is essential to prove the veracity of a produced result.</p><p>In this article, the concept of an experiment is seen as encompassing the concept of a workflow, and not as a synonym. A workflow may be seen as a controlled action of the experiment. Hence, the workflow is defined as one of the trials conducted in the context of an experiment. In each trial, the scientist needs to define the parameter values for each activity of the workflow. It is not unusual that a simple workflow has more than 100 parameters to set. Setting up these parameters may be simple for an expert, but not so simple for non-expert users. Although WfMSs represent a step forward by providing the necessary infrastructure to manage workflow executions, they provide a little help (or even no help at all) on defining parameter values for a specific workflow execution. A good parameters values tune in a workflow execution is crucial not only for the quality of the results but also influences if a workflow will execute or not (avoiding unnecessary execution crashes). A poor choice of parameters values can cause failures, which leads to a waste of execution time. Failures caused by poor choices of parameter values are even more severe when workflows are executing in HPC environments that follow a pay-as-you-go model, e.g., clouds, since they can increase the overall financial cost. This way, if the WfMS could "learn" from previous successfully executions of the workflow and recommend parameter values for scientists, some failures could be avoided. This recommendation is especially useful for non-expert users. Let us take as an example a scenario where an expert user has modeled a workflow and executed several trials of the same workflow varying the parameter values. If a non-expert scientist wants to execute the same workflow with a new set of parameter values and input data, but does not know how to set the values of some of the parameters, one can benefit from parameter values used on previous executions of the same (or similar) workflow. The advantage of the WfMS is provenance data already contains the parameter values used on previous (successful) executions and can be a rich resource to be used for recommendation. Thus, this article hypothesis is that by adopting an approach to recommend the parameters values of workflows in a WfMS, we can increase the probability that the execution of workflow will be completed. As a consequence, the financial cost associated with execution failures is reduced.</p><p>In this article, we propose a method named FReeP-Feature Recommender From Preferences, which aims at recommending values for parameters of workflow activities. The proposed approach is able to recommend parameter values in two ways: (i) a single parameter value at a time, and (ii) multiple parameter values at once. The proposed approach relies on user preferences, defined for a subset of workflow parameters, together with the provenance of the workflow. It is essential to highlight that user preferences are fundamental to explore experiment variations in a scientific scenario. Furthermore, for our approach, user preferences help prune search space and consider user restrictions, making personalized recommendations. The idea of combining user preferences and provenance is novel and allows for producing a personalized recommendation for scientists. FReeP is based on Machine Learning algorithms <ref type="bibr" target="#b52">(Mitchell, 2015)</ref>, particularly, Preference Learning <ref type="bibr" target="#b22">(Fürnkranz &amp; Hüllermeier, 2011)</ref>, and Recommender Systems <ref type="bibr" target="#b63">(Ricci, Rokach &amp; Shapira, 2011)</ref>. We evaluated FReeP using real workflow traces (considered as benchmarks): Montage <ref type="bibr" target="#b37">(Hoffa et al., 2008)</ref> from astronomy domain and <software ContextAttributes="used">SciPhy</software> <ref type="bibr" target="#b56">(Ocaña et al., 2011)</ref> from bioinformatics domain. Results indicate the potential of the proposed approach. This article is an extension of the conference paper "FReeP: towards parameter recommendation in scientific workflows using preference learning" <ref type="bibr" target="#b65">(Silva Junior et al., 2018)</ref> published in the Proceedings of the 2018 Brazilian Symposium on Databases (SBBD). This extended version provides new empirical shreds of evidence regarding several workflow case studies as well as a broader discussion on related work and experiments.</p><p>This article is organized in five sections besides this introduction. "Background" section details the theoretical concepts used in the proposal development. "FReeP-Feature Recommender from Preferences" section presents the algorithm developed for the problem of parameters value recommendation using user preferences. "Experimental Evaluation" section shows the results of the experimental evaluation of the approach in three different scenarios. Then, "Related Work" section presents a literature review with papers that have addressed solutions to problems related to the recommendation applied to workflows and the Machine Learning model hyperparameter recommendation. Lastly, "Conclusion" section brings conclusions about this article and points out future work.</p></div>
<div><head>BACKGROUND</head><p>This section presents key concepts for understanding the approach presented in this article to recommend values for parameters in workflows based on users' preferences and previous executions. Initially, it is explained about scientific experiments. Following, the concepts related to Recommender Systems are presented. Next, the concept of Preference Learning is presented. This section also brings a Borda Count overview, a non-common voting schema that is used to decide which values to suggest to the user.</p></div>
<div><head>Scientific experiment</head><p>A scientific experiment arises from the observation of some phenomena and questions raised from the observation. The next step is the hypotheses formulation aiming at developing possible answers to those questions. Then, it is necessary to test the hypothesis to verify if an output produced is a possible solution. The whole process includes many iterations of refinement, consisting, for example, of testing the hypothesis under distinct conditions, until it is possible to have enough elements to support it.</p><p>The scientific experiment life-cycle proposed by Mattoso et al. ( <ref type="formula">2010</ref>) is divided into three major phases: composition, execution and analysis. The composition phase is where the experiment is designed and structured. Execution is the phase where all the necessary instrumentation for the accomplishment of the experiment must be finished. Instrumentation means the definition of input data, parameters to be used at each stage of the experiment, and monitoring mechanisms. Finally, the analysis phase is when the data generated by the composition and execution phases are studied to understand the obtained results. The approach presented in this article focus on the Execution phase.</p></div>
<div><head>Scientific workflows</head><p>Scientific workflows have become a de facto standard for modeling in silico experiments <ref type="bibr" target="#b81">(Zhou et al., 2018)</ref>. A Workflow is an abstraction that represents the steps of an experiment and the dataflow through each of these steps. A workflow is formally defined as a directed acyclic graph W(A,Dep). The nodes A ¼ fa 1 ; a 2 ; . . . ; a n g are the activities and the edges Dep represent the data dependencies among activities in A. Thus, given a i :amp: mid; (1 ≤ i ≤ n), the set P = {p 1 , p 2 , …, p m } represents the possible input parameters for activity a i that defines the behavior of a i . Therefore, a workflow can be represented as a graph where the vertices act as experiment steps and the edges are the relations, or the dataflow between the steps.</p><p>A workflow can also be categorized according to the level of abstraction into conceptual or concrete. A conceptual workflow represents the highest level of abstraction, where the experiment is defined in terms of steps and dataflow between them. This definition does not explain how each step of the experiment will execute. The concrete workflow is an abstraction where the activities are represented by the computer programs that will execute them. The execution of an activity of the workflow is called an activation (De <ref type="bibr">Oliveira et al., 2010b)</ref>, and each activation invokes a program that has its parameters defined. However, managing this execution, which involves setting the correct parameter values for each program, capturing the intermediate data and execution results, becomes a challenge. It was with this in mind, and with the help of the composition of the experiment in the workflow format, that Workflow Management Systems (WfMS), such as <software ContextAttributes="used">Kepler</software> <ref type="bibr" target="#b2">(Altintas et al., 2006)</ref>, <software ContextAttributes="used">Pegasus</software> <ref type="bibr" target="#b17">(Deelman et al., 2005)</ref> and <software ContextAttributes="used">SciCumulus</software> <ref type="bibr">(De Oliveira et al., 2010b)</ref> emerged.</p><p>In special, <software ContextAttributes="used">SciCumulus</software> is a key component of the proposed approach since it provides a framework for parallel workflows to benefit from FReeP. Also, data used in the experiments presented in this article are retrieved from previous executions of several workflows in <software ContextAttributes="used">SciCumulus</software>. It is worth noticing that other WfMSs such as <software ContextAttributes="used">Pegasus</software> and <software ContextAttributes="used">Kepler</software> could also benefit from FReeP as long as they provide necessary provenance data for recommendation. <software ContextAttributes="used">SciCumulus</software> architecture is modularized to foster maintainability and ease the development of new features. <software ContextAttributes="used">SciCumulus</software> is open-source and can be obtained at https://github.com/UFFeScience/<software ContextAttributes="used">SciCumulus</software>/. The system is developed using MPI library (a de facto standard library specification for message-passing), so <software ContextAttributes="used">SciCumulus</software> is a distributed application, i.e., each <software ContextAttributes="used">SciCumulus</software> module has multiple instances created on the machines of the distributed environment (which are different processes and each process has multiple threads) that communicate, triggering functions for sending and receiving messages between these processes. According to <ref type="bibr" target="#b32">Guerine et al. (2019)</ref>, <software ContextAttributes="used">SciCumulus</software> has four main modules: (i) SCSetup, (ii) SCStarter, (iii) SCCore, and (iv) SCQP (<software ContextAttributes="used">SciCumulus Query Processor</software>). The first step towards executing a workflow in <software ContextAttributes="used">SciCumulus</software> is to define the workflow specification and the parameters values to be consumed. This is performed using the SCSetup module. The user has to inform the structure of the workflow, which programs are associated to which activities, etc. When the metadata related to the experiment is loaded into the <software ContextAttributes="used">SciCumulus</software> database, the user can start executing the workflow. Since <software ContextAttributes="used">SciCumulus</software> was developed focusing on supporting the execution of workflows in clouds, instantiating the environment was a top priority. The SCSetup module queries the provenance database to retrieve prospective provenance and creates the virtual machines (in the cloud) or reserve machines (in a cluster). The SCStarter copies and invokes an instance of SCCore in each machine of the environment, and since SCCore is a MPI-based application it runs in all machines simultaneously and follows a Master/Worker architecture (similar to <software ContextAttributes="used">Hadoop</software> and <software ContextAttributes="used">Spark</software>). The <software ContextAttributes="used">SCCore-Master</software> (SCCore 0 ) schedules the activations for several workers and each worker has a specific ID (SCCore 1 , SCCore 2 , etc.). When a worker is idle, it sends a message for the SCCore 0 (Master) and request more activations to execute. The SCCore 0 defines at runtime the best activation to send following a specific cost model. The SCQP component allows for users to submit queries to the provenance database for runtime or post-mortem analysis. For more information about <software ContextAttributes="used">SciCumulus</software> please refer to <ref type="bibr" target="#b13">(De Oliveira et al., 2012;</ref><ref type="bibr">De Oliveira et al., 2010a;</ref><ref type="bibr" target="#b32">Guerine et al., 2019;</ref><ref type="bibr" target="#b66">Silva et al., 2020;</ref><ref type="bibr">Guedes et al., 2020a;</ref><ref type="bibr" target="#b15">De Oliveira et al., 2013)</ref>.</p><p>An workflow activation has input data, and generates intermediate and output data. WfMS has to collect all metadata associated to the execution in order to foster reproducibility. This metadata is called provenance <ref type="bibr" target="#b20">(Freire et al., 2008)</ref>. According to <ref type="bibr" target="#b26">Goble (2002)</ref>, the provenance must verify data quality, path audit, assignment verification, and information querying. Data quality check is also related to verifying the reliability of workflow generated data. Path audit is the ability to follow the steps taken at each stage of the experiment that generated a given result. The assignment verification is linked to the ability to know who is responsible for the data generated. Lastly, an information query is essential to analyze the data generated by the experiment's execution. Especially for workflows, provenance can be classified as prospective (p-prov) and retrospective (r-prov) <ref type="bibr" target="#b20">(Freire et al., 2008)</ref>. p-prov represents the specification of the workflow that will be executed. It corresponds to the steps to be followed to achieve a result. r-prov is given by executed activities and information about the environment used to produce a data product, consisting of a structured and detailed history of the execution of the workflow.</p><p>Provenance is fundamental for the scientific experiment analysis phase. It allows for verifying what caused an activation to fail or generated an unexpected result, or in the case of success, what were the steps and parameters used until the result. Another advantage of provenance is the reproducibility of an experiment, which is essential for the validation of the results obtained by third parties. Considering the provenance benefits in scientific experiments, it was necessary to define a model of representation of provenance <ref type="bibr" target="#b6">(Bose, Foster &amp; Moreau, 2006)</ref>. The standard W3C model is PROV <ref type="bibr" target="#b24">(Gil et al., 2013)</ref>. PROV is a generic data model and is based on three basic components and their links, being the components: Entity, Agent and Activity. The provenance and provenance data model are essential concepts because FReeP operation relies on provenance to recommend parameter values. Also, to extract provenance data to use in FReeP it is necessary to understand the provenance data model used.</p></div>
<div><head>Recommender systems</head><p>FReeP is a personalized Recommender system (RS) <ref type="bibr" target="#b62">(Resnick &amp; Varian, 1997)</ref> aiming at suggesting the most relevant parameters to the user to perform a task, based on their preferences.There are three essential elements for the development of a recommender system: Users, Items, and Transactions. The Users are the target audience of the recommender system with their characteristics and goals. Items are the recommendation objects and Transactions are records that hold a tuple (user, interaction), where the interaction encompasses the actions that the user performed when using the recommender system. These interactions are generally user feedbacks, which may be interpreted as their preferences.</p><p>A recommender task can be defined as: given the elements Items, Users and Transactions, find the most useful items for each user. According to <ref type="bibr" target="#b0">Adomavicius &amp; Tuzhilin (2005)</ref>, a recommender system must satisfy the equation 8u 2 U; i 0 u ¼ arg max i2I Fðu; iÞ, where U represents the users, I represents the items and F is a utility function that calculates the utility of an item i in I for a u in U user. In case the tuple (u, i) is not defined in the entire search space, the recommender system can extrapolate the F function.</p><p>The utility function varies according to the approach followed by the recommender system. Thus, recommender systems are categorized according to the different strategies used to define the utility function. The most common approaches to recommender systems are: Content Based, Collaborative Filtering and Hybrids. Figure <ref type="figure">1</ref> provides a taxonomy related types of recommender systems for this work.</p><p>In Collaborative Filtering Recommender Systems, a recommendation is based on other users' experience with items in the system domain. The idea is related to the human behavior of, at times, giving credit to another person's opinion about what should be done in a given situation. The Neighborhood Based subtype strictly follows the principle that users with similar profiles have similar preferences. The Model-Based subtype generates a hypothesis from the data and use it to make recommendations instantly. Although widely adopted, Collaborative Filtering only uses collective information, limiting novel discoveries in scientific experiment procedures.</p><p>Content-based Recommender Systems make recommendations similar to items that the user has already expressed a positive rating in the past. To determine the similarity degree between items, this approach is highly dependent on extracting their characteristics. However, each scenario needs the right item representation to give satisfactory results.</p><p>In scientific experiments, it can be challenging to find an optimal item representation.</p><p>Finally, Hybrid Recommender Systems arise out of an attempt to minimize the weaknesses that traditional recommendation techniques have when used individually. Also, it is expected that a hybrid strategy can aggregate the strengths of the techniques used together. There are several methods of combining recommendation techniques in creating a hybrid recommender system, including: Weighting approaches that provides a score for each recommendation item, Switching, which allows for selecting different types of recommending strategies, Mixing, to make more than one recommentation at a time, Feature Combination, to put together both Content-Based and Collaborative Filtering strategies, Cascade, that first filters the candidate items for the recommendation, followed by refining these candidates, looking for the best alternatives, Feature Augmentationand Meta-Level, which chain a series of recommendations one after another <ref type="bibr" target="#b8">(Burke, 2002)</ref>.</p><p>FReeP is as a Cascade Hybrid Recommender System because the content of user preferences is used to prune the search space followed by a collaborative strategy to give the final recommendations.</p></div>
<div><head>Preference learning</head><p>User preferences play a crucial role in recommender systems <ref type="bibr" target="#b73">(Viappiani &amp; Boutilier, 2009)</ref>. From an Artificial Intelligence perspective, a preference is a problem restriction that allows for some degree of relaxation. <ref type="bibr" target="#b22">Fürnkranz &amp; Hüllermeier (2011)</ref> refers to Learning Preferences as "inducing preference models from empirical data". In several scenarios, the empirical data is implicitly defined, for example, when the user's preference is expressed by clicking on the most interesting products, instead of effectively buying one of them or stating that one is preferable over another.</p><p>A Preference Learning task consists of learning a predictive function that, given a set of items where preferences are already known, predicts preferences for a new set of items. The most common way of representing preferences is through binary relationships. For example, a tuple (x i &gt; x j ) &gt; would mean a preference for the value i over j for the attribute x.</p><p>The main task within Preference Learning area is Learning to Rank as commonly it is necessary to have an ordering of the preferences. The task is divided into three categories: Label Ranking <ref type="bibr" target="#b72">(Vembu &amp; Gärtner, 2011)</ref>, Instance Ranking <ref type="bibr" target="#b3">(Bergeron et al., 2008)</ref> and Object Ranking <ref type="bibr" target="#b55">(Nie et al., 2005)</ref>. In Label ranking a ranker makes an ordering of the set of classes of a problem for each instance of the problem. In cases where the classes of a problem are naturally ordered, the instance ranking task is more suitable, as it orders the instances of a problem according to their classes. The instances belonging to the "highest" classes precede the instances that belong to the "lower" classes. In object ranking an instance is not related to a class. This task's objective is, given a subset of items referring to the total set of items, to produce a ranking of the objects in that subset-for example, the ranking of web pages by a search engine.</p><p>Pairwise Label Ranking <ref type="bibr" target="#b21">(Fürnkranz &amp; Hüllermeier, 2003;</ref><ref type="bibr" target="#b39">Hüllermeier et al., 2008)</ref> (PLR) relates each instance with a preference type a &gt; b, representing that a is preferable to b. Then, a binary classification task is assembled where each example a, b is annotated with a is a is preferable over b and 0, otherwise. Then, a classifier M a, b is trained over such dataset to learn how to make the preference predictions which returns 1 as a prediction that a is preferable to b and 0 otherwise. Instead of using a single classifier that makes predictions between m classes, given a set L of m classes, there will be m(m -1)/2 binary classifiers, where a classifier M i, j only predicts between classes i, j in L. Then, the strategy defined by PLR uses the prediction of each classifier as a vote and uses a voting system that defines an ordered list of preferences. Next, we give more details about how FReeP tackles the voting problem.</p></div>
<div><head>Borda count</head><p>Voting Theory <ref type="bibr" target="#b69">(Taylor &amp; Pacelli, 2008</ref>) is an area of Mathematics aimed at the study of voting systems. In an election between two elements, it is fair to follow the majority criterion, that is, the winning candidate is the one that has obtained more than half of the votes. However, elections involving more than two candidates require a more robust system. Preferential Voting <ref type="bibr" target="#b43">(Karvonen, 2004)</ref> and Borda Count <ref type="bibr" target="#b19">(Emerson, 2013)</ref> are two voting schemas concerning the scenarios where there are more than two candidates. In Preferential Voting, voters elicit a list of the most preferred to the least preferred candidate. The elected candidate is the one most often chosen as the most preferred by voters.</p><p>Borda Count is a voting system in which voters draw up a list of candidates arranged according to their preference. Then, each position in the user's preference list gets a score. In a list of n candidates, the candidate in the i-th position on the list receives the score ni. To determine the winner, the final score is the sum of each candidate's scores for each voter, and the candidate with the highest score is the elected one. Figure <ref type="figure">2</ref> depicts an example of Borda Count. There are four candidates: A, B, C and D, and five vote ballots. The lines in each ballot represent the preference positions occupied by each candidate. As there are four candidates, the candidate preferred by a voter receives three points. The score for the candidate D is computed as follows: 1 voter elected the candidate D as the preferred candidate, then 1 * 3 = 3 points; 2 voters elected the candidate D as the second most preferred candidate, then 2 * 2 = 4 points; 2 voters elected the candidate D as the third most preferred candidate, then 2 * 1 = 2 points; 0 voters elected the candidate D as the least preferred, then 0 * 0 = 0 points. Finally, candidate D total score = 3 + 4 + 2 + 0 = 9.</p><p>Voting algorithms are used together with recommender systems to choose which items the users have liked best to make a good recommendation. <ref type="bibr" target="#b60">Rani, Shokeen &amp; Mullick (2017)</ref> proposed a recommendation algorithm based on clustering and a voting schema that after clustering and selecting the target user's cluster, uses the Borda Count to select the most popular items in the cluster to be recommended. Similarly, <ref type="bibr" target="#b46">Lestari, Adji &amp; Permanasari (2018)</ref> compares Borda Count and the Copeland Score Al-Sharrah (2010) in a recommendation system based on Collaborative Filtering. Still using the Borda Count, <ref type="bibr" target="#b68">Tang &amp; Tong (2016)</ref> proposes the BordaRank. The method consists of using the Borda Count method directly in the sparse matrix of evaluations, without predictions, to make a recommendation. </p></div>
<div><head>FREEP-FEATURE RECOMMENDER FROM PREFERENCES</head><p>Figure <ref type="figure" target="#fig_0">3</ref> depicts a synthetic workflow, where one can see four activities represented by colored circles where activities 1, 2, and 3 have one parameter each. To execute the workflow, it is required to define values for parameters 1, 2, and 3. Given a scenario where a user has not defined values for all parameters, FReeP targets at helping the user to define values for the missing parameters. For this, FReeP divides the problem into two sub-tasks: (1) recommendation for only one parameter at a time;</p><p>(2) recommendation for n parameters at once. The second task is more challenging than the first as parameters of different activities may present some data dependencies.</p><p>Taking into account user preferences, FReeP suggests parameter values that maximize a probability to make the workflow execute flawlessly until its end. FReeP receives a user preferences set to yield the personalized recommendations. The recommendations are the output of a model induced by a Machine Learning technique. FReeP is a hybrid recommendation technique as it incorporates aspects of both Collaborative Filtering and Content-Based concepts.</p><p>The way FReeP tackles the recommendation task is presented in three versions. In the first two versions, the algorithm aims at recommending a value for only one parameter at a time. While the naive version assumes that all parameters have a discrete domain, the enhanced second version is an extension of the first one that is able to deal with cases where a parameter has a continuous domain. The third version targets at recommending values for n &gt; 1 parameters at a time.</p><p>Next, we start by presenting the naive version of the method that makes the recommendation for a single parameter at a time. Then, we follow to the improved version with enhancements that improve the performance and allows for working with parameters in the continuous domain. Finally, a generic version of the algorithm is presented, aiming at making the recommendation of values for multiple parameters at a time.</p></div>
<div><head>Discrete domain parameter value recommendation</head><p>Given a provenance database D, a parameter y ∈ Y, where Y is the workflow parameters set, and a preferences or restrictions set P defined by the user, where p i ∈ P (y i , val k ), FReeP one parameter approach aims at solving the problem of recommending a r value for y, so that the P preferences together with the r recommendation to y maximize the chances of the workflow activation to run to the end. Figure <ref type="figure" target="#fig_1">4</ref> presents an architecture overview of FReeP's naive version. The algorithm receives as input the provenance database, a target workflow and user preferences. User preferences are also input as this article assumes that the user already has a subset of parameters for which has already defined values to use. In this naive version, the user preferences are only allowed in the form a = b, where a is a parameter, and b is a desired value to a.</p><p>Based on the user's preferences, it would be possible to query the provenance database from which the experiment came from to retrieve records that could assist in the search for other parameters values that had no preferences defined. However, FReeP is based on a model generation that generalizes the provenance database, removing the user's need to perform this query yet providing results that the query would not be able to return.</p><p>To obtain a recommendation from FReeP's naive version, seven steps are required: partitions generation, horizontal filter, vertical filter, hypothesis generation, predictions, aggregation, and, finally election-based recommendation. Algorithm 1 shows the proposed algorithm to perform the parameter recommendation, considering the preferences for a subset or all other workflow execution parameters.</p><p>The algorithm input data are: target parameter for which the algorithm should make the recommendation, y; user preferences set, such as a list of key-values, where the key is a workflow parameter and value is the user's preference for that parameter, P; provenance database, D.</p><p>The storage of provenance data for an experiment may vary from one WfMS to another. For example, <software ContextAttributes="created">SciCumulus</software>, which uses a provenance representation derived from PROV, stores provenance in a relational database. Using <software ContextAttributes="created">SciCumulus</software> example, it is trivial for the user responsible for the experiment to elaborate a SQL query that returns the provenance data related to the parameters used in each activity in a key-value representation. The key-value representation can be easily stored in a csv format file, which is the required format expected as provenance dataset in FReeP implementation. Thus, converting provenance data to the csv format is up to the user. Still, regarding the provenance data, the records present in the algorithm input data containing information about the parameters must be related only to executions that were successfully concluded, that is, there was no failure that resulted in the execution abortion. The inclusion of components to query and transform provenance data and force successful executions parameters selection would require implementations for each type of WfMS, which is out of the scope of this article. The initial step, partitions_generation, builds partitioning rules set based on the user's preferences. Initially, the preference set parameters P are used to generate a powerset. This first step returns all generated powerset as a partitions ruleset. Figure <ref type="figure">5</ref> shows an example of how this first step works, with some parameters from <software ContextAttributes="created">SciPhy</software> workflow.</p><p>Then, FReeP initializes an iteration over the partitioning rules generated by the previous step. Iteration begins selecting only the records that follow the user's preferences contained in the current ruleset, named in the algorithm as horizontal_filter. Figure <ref type="figure">6</ref> uses the partitions presented in Fig. <ref type="figure">5</ref> to show how the horizontal_filter step works. Subsequently, in the vertical_filter step, there is a parameter removal that aims at keeping only the recommendation target parameter, the parameters present in the current set of partitioning rules, and those that are neither the recommendation target parameter nor are present in any of the original user preferences. The last parameters mentioned remain because, in a next step, they can help to build a more consistent model. Thus, let PW be all workflow parameters set; PP the workflow parameters for which preference values have been defined; PA the parameters present in the partitioning rules of an iteration over the partitioning rules and PV = (PW -PP) ∪(PP ∩ PA) ∪ {y} ; the output from vertical_filter is the data from horizontal_filter for parameters in PV. The chain comprising the partitions generation and the horizontal and vertical filters is crucial to minimize the Cold Start problem <ref type="bibr" target="#b47">(Lika, Kolomvatsos &amp; Hadjiefthymiades, 2014)</ref>.</p></div>
<div><head>Current Partition Rule</head><p>[num_aligns] Cold Start is caused by the lack of ideal operating conditions for an algorithm, specifically in the recommender systems. This problem occurs, for example, when there are few users for the neighborhood definition with a similar user profile or lack of ratings for enough items. FReeP can also be affected by Cold Start problem. If only all preferences were used at one time for partitioning the provenance data, in some cases, it could be observed that the resulting partition would be empty. This is because there could be an absence of any of the user's preferences in the provenance data. Therefore, generating multiple partitions with subsets of preferences decreases the chance of obtaining only empty partitions. However, in the worst case where none of the user's preferences are present in the workflow provenance, FReeP will not perform properly, thus failing to make any recommendations.</p><formula xml:id="formula_0">num_aligns</formula><p>After the partitions generation and horizontal and vertical filters are discovered, there is a filtered data set that follows part of the user's preferences. These provenance data that will generate the Machine Learning model have numerical and categorical domain parameters. However, traditional Machine Learning models generally work with numerical data because the generation of these models, in most cases, involves many numerical calculations. Therefore, it is necessary to codify these categorical parameters to a numerical representation. The technique used here to encode categorical domain parameters to numerical representation is One-Hot encoding <ref type="bibr" target="#b9">(Coates &amp; Ng, 2011)</ref>. This technique consists of creating a new binary attribute, that is, the domain of this new attribute is 0 or 1, for each different attribute value present in dataset.</p><p>The encoded provenance data allows building Machine Learning models to make predictions for the target parameter under the step hypothesis_generation. The model generated has the parameter y as class variable, and the other parameters present in vertical_filter step output data are the attributes used to generalize the hypothesis. The model can be a classifier, where the model's prediction is a single recommendation value, or a ranker, where its prediction is an ordered list of values, of the value most suitable for the recommendation to the least suitable.</p><p>With a model created, we can use it to recommend the value for the target parameter. This step is represented in FReeP as recommended, and the recommendation of parameter y is made from the user's preferences. It is important to emphasize that the model's training data may contain parameters that the user did not specify any preference. In this case, an attribute of the instance submitted for the hypothesis does not have a defined value. To clarify the problem, let PW be all workflow parameters set, PP the parameters of workflow for which preference values have been defined; PA the parameters present in the partition rules of an iteration over the partitioning rules; and PV = (PW -PP) ∪ (PP ∩ PA) ∪ {y}, there may be parameters p ∈ PV | p ∉ PP, and for those parameters p there are no values defined a priori. To handle this problem, the average values present in the provenance data are used to fill in the numerical attributes' values and the most frequent values in the provenance date for the categorical attributes.</p><p>All predictions generated by recommend step, which is within the iteration over the partitioning rules, are stored. The last algorithm step, elect_recommendation, uses all of these predictions as votes to define which value should be recommended for the target parameter. When an algorithm instance is setup to return a classifier type model in hypothesis_generation step, the most voted value is elected as the recommendation. On the other hand, when an algorithm instance is setup to return a ranker type model in hypothesis_generation step, the strategy is Borda Count. The use of the Borda Count strategy seeks to take advantage of the list of lists form that the saved votes acquire when using the ranker model. This list of lists format occurs because the ranker prediction is a list, and since there are as many predictions as partitioning rules, the storage of these predictions takes the list of lists format.</p></div>
<div><head>Discrete and continuous domain parameter value recommendation</head><p>The naive version of FReeP allowed evaluating the algorithm's proposal. The proposal showed relevant results after initial tests (presented in next section), so efforts were focused on improving its performance and utility. In particular, the following problems have been identified: (1) User has some restriction to set his/her parameters preferences; (2) The categorical domain parameters when used as a class variable (parameters for recommendation) are treated as well as they are present in the input data; (3) Machine Learning models used can only learn when the class (parameter) variable has a discrete domain; (4) All partitions generated by workflow parameters powerset present in user preferences are used as partitioning rules for the algorithm.</p><p>Regarding problem 1, in Algorithm 1, the user was limited to define his preferences with the equality operator. Depending on the user's preferences, the equality operator is not enough. With this in mind, the Enhanced FReeP allows for the user to have access to the relational operators: ==,&gt;,&gt;=,&lt;,&lt;= and != to define his/her preferences. In addition, two logical operators are also supported in setting preferences: | and &amp;. Preferences with combination of supported operators is also allowed, for example: (a &gt; 10) | (at &lt; 5).</p><p>However, by allowing users to define their preferences in this way we create a problem when setting up the instances for recommendation step. As seen, PW represents all workflow parameters set, PP are workflow parameters that preference values have been set; PA the parameters present in the partitioning rules of an iteration over the partition rules; and PV = (PW -PP) ∪(PP ∩ PA) ∪ {y}. Thus, there may be parameters p ∈ PV | p ∉ PP, and for those parameters p, there are no values defined a priori. This enhanced version of the proposal allows the user's preferences to be expressed in a more relaxed way, demanding to create the instances used in the step recommendation that include a range (or set of values). To handle this isse, all possible instances from preference values combinations were generated. In case the preference is related to a numerical domain parameter and is defined in terms of values range, like a ≤ 10.5, FReeP uses all values present in the source provenance database that follows the preference restriction. It is important to note that for both numerical and categorical parameters, the combination of possible values are those present in the provenance database and that respect the user's preferences. Then, predictions are made for a set of instances using the model learned during the training phase.</p><p>Regarding problem 2, the provenance database, in general, present attributes with numerical and categorical domains. It is FReeP responsibility to convert categorical values into numerical representation due to restrictions related to the nature of the training algorithms of the Machine Learning models, e.g., Support Vector Machines (SVM) <ref type="bibr" target="#b74">(Wang, 2005)</ref>.</p><p>This pre-processing step was included in Algorithm 2 as classes_preprocessing step. The preprocessing consists in exchanging each distinct categorical value for a distinct integer. Note that the encoding of the parameter used as a class variable in the model generation is different from the encoding applied to the parameters used as attributes represented by the step preprocessing.</p><p>Concerning problem 3, by using classifiers to handle a continuous domain class variable degrades the performance results. Performance degradation happens because the numerical class variables are considered as categorical. For continuous numerical domain class variables, the Machine Learning models suggested are Regressors <ref type="bibr" target="#b54">(Myers &amp; Myers, 1990)</ref>. In this way, the Enhanced FReeP checks the parameter y domain, which is the recommendation target parameter, represented as model_select step in Algorithm 2.</p><p>To analyze problem 4, it is important to note that after converting categorical attributes One-Hot encoding in preprocessing step, the provenance database will have a considerable increase in the number of attributes. Also, after categorical attributes encoding in preprocessing step, the parameters extracted from the user's preferences, are also encoded for partitions_generation step. In Algorithm 1, the partitioning rules powerset is calculated on all attributes derived from the original parameters after One-Hot encoding. If FReeP uses the powerset generated from the parameters present in the user's preferences set as partitioning rules (in the partitions_generation step), it can be very costly. Thus, using the powerset makes the complexity of the algorithm becomes exponential according to the parameters present in the user's preferences set. Alternatives to select the best partitioning rules and handle the exponential cost are represented in Algorithm 2 as optimized_partitions_generation step. The two strategies proposed here are based on Principal Components Analysis (PCA) <ref type="bibr" target="#b23">(Garthwaite et al., 2002)</ref> and the Analysis of variance (ANOVA) <ref type="bibr" target="#b25">(Girden, 1992)</ref> statistical metric.</p><p>The strategy based on PCA consists of extracting x principal components from all provenance database, pca D , and for each pt ∈ partitions, pca i pt , which are pt partition principal components. Then, the norms are calculated ||pca Dpca i pt ||, and from that n partitioning rules are selected that generated pca i pt such that ||pca Dpca i pt || resulted in the lowest calculated values. Note that both x and n are defined parameters when executing the algorithm. In summary, the PCA strategy will select the partitions where the main components extracted are the closest to the principal components of the original provenance dataset.</p><p>ANOVA strategy seeks the n partitioning rules that best represent D, selecting those that generate partitions where the data variance is closest to D data variance. In short, original data variance and data variance for each partition are calculated using the ANOVA metric, then partitions with most similar variance to the original provenance data are selected. Here, the n rules are defined in terms of the data percentage required to represent the entire data set, and that parameter must also be defined in algorithm execution. Using PCA or ANOVA partitioning strategies means that the partitioning rules used by FReeP can be reduced, depending on the associated parameters that need to be defined.</p></div>
<div><head>Recommendation for n Parameters at a time</head><p>Algorithms 1 and 2 aim at producing single parameter recommendation at a time. However, in a real usage scenario of scientific workflows, the WfMS will probably need to recommend more than one parameter at a time. A naive alternative to handle this problem is to execute Algorithm 2 for each of the target parameters, always adding the last recommendation to the user's preference set. This alternative assumes that the parameters to be recommended are independent random variables. One way to implement this strategy is by using a classifiers chain <ref type="bibr" target="#b61">(Read et al., 2011)</ref>.</p><p>Nevertheless, this naive approach neglects that the order in which the target parameters are used during algorithm interactions can influence the produced recommendations. The influence is due to parameter dependencies that can be found between two (or more) workflow activities (e.g., two activities consume a parameter produced by a third activity of the workflow). In Fig. <ref type="figure" target="#fig_0">3</ref>, the circles represent the activities of workflow, so activities 2 and 3 are preceded by activity 1 (e.g., they consume the output of activity 1). Using this example, we can see that it is possible that there is a dependency relationship between the parameters param2 and param3 with the parameter param1. In this case, the values of param2 and param3 parameters can be influenced by parameter param1 value.</p><p>In order to deal with this problem, FReeP leverages the Classifiers Chains Set <ref type="bibr" target="#b61">(Read et al., 2011)</ref> concept. This technique allows for estimating the joint probability distribution of random variables based on a Classifiers Chains Set. In this case, the random variables are the parameters for which values are to be recommended, and the joint probability distribution concerns the possible dependencies between these parameters. The Classifiers Chains and Classifiers Chains Set are techniques from Multi-label Classification <ref type="bibr" target="#b70">(Tsoumakas &amp; Katakis, 2007</ref>) Machine Learning task.</p><p>Figure <ref type="figure" target="#fig_3">8</ref> depicts an architecture overview for the proposed algorithm named as Generic FReeP that recommends n parameters simultaneously. The architecture presented in Fig. <ref type="figure" target="#fig_3">8</ref> shows that the solution developed to make n parameter recommendations at a time is a packaging of FReeP algorithm to one parameter. This final approach is divided into five steps: identification of parameters for the recommendation, generation of ordered sequences of these parameters, iteration over each of the sequences generated with the addition of each recommendation from FReeP to the user preferences set, separation of recommendations by parameter and finally the choice of value recommendation for each target parameters. The formalization can be seen in Algorithm 3.</p><p>The first step parameters_extractor extracts the workflow parameters that are not present in the users' preferences and will be the targets of the recommendations. Thus, all other parameters that are not in the user's preferences will have recommendation values.</p><p>Lines 4 and 5 of the algorithm comprise the initialization of the variable responsible for storing the different recommendations for each parameter during the algorithm execution. Then, the list of all parameters that will be recommended is used for generating different ordering of these parameters, indicated by sequence_generators step. For example, let w be a workflow with 4 p parameters and let u be an user with pr 1 and pr 3 preferences for the p 1 and p 3 parameters respectively. The parameters to be recommended are p 2 and p 4 , in this case two possible orderings are: {p 2 , p 4 } and {p 4 , p 2 }. Note that the number of sorts used in the algorithm are not all possible sorts, in fact N of the possible sorts are selected at random.</p><p>Then, the algorithm initializes an iteration over each of the sorts generated by the step sequence_generators. Another nested iteration over each parameter present in the current order also begins. An intuitive explanation of the algorithm between lines 9 and 13 is that each current sequence parameter is used together with the user's preferences for its recommendation. At the end of the recommendation of one of the ordering parameters, the recommendation is incorporated into the preferences set used in the recommendation of the next ordering parameter. In this iteration, the recommendations are grouped by parameter to facilitate the election of the recommended value for each target parameter. The step of iterating over the generated sequences, always adding the last recommendation to the set of preferences, is the Classifiers Chains concept. To deal with the dependency between the workflow parameters that can influence a parameter value recommendation, the step that generates multiple sequences of parameters, combined with the Classifiers Chains, is the Classifiers Chains Set concept.</p><p>Finally, to choose the recommendation for each target parameter, a vote is taken on lines 15 and 16. The most_voted procedure makes the majority election that defines the target parameter recommendation value. This section presented three algorithms that are part of the FReep approach developed for the parameter recommendation problem in </p></div>
<div><head>EXPERIMENTAL EVALUATION</head><p>This section presents the experimental evaluation of all versions of FReeP. First, we present the workflows used as case studies namely <software ContextAttributes="created">SciPhy</software> <ref type="bibr" target="#b56">(Ocaña et al., 2011)</ref> and Montage <ref type="bibr" target="#b40">(Jacob et al., 2009)</ref>. Following we present the experimental and environment setups. Finally, we discuss the results.</p></div>
<div><head>Case studies</head><p>In this article, we consider two workflows from bioinformatics and astronomy domains, namely <software ContextAttributes="created">SciPhy</software> <ref type="bibr" target="#b56">(Ocaña et al., 2011)</ref> and Montage <ref type="bibr" target="#b40">(Jacob et al., 2009)</ref>, respectively. <software ContextAttributes="created">SciPhy</software> is a phylogenetic analysis workflow that generates phylogenetic trees (a tree-based representation of the evolutionary relationships among organisms) from input DNA, RNA and aminoacid sequences. <software ContextAttributes="created">SciPhy</software> has four major activities as presented in Fig. <ref type="figure" target="#fig_5">9A:</ref> (i) sequence alignment, (ii) alignment conversion, (iii) evolutionary model election and (iv) tree generation. <software ContextAttributes="created">SciPhy</software> has been used in scientific gateways such as <software ContextAttributes="created">BioInfoPortal</software> <ref type="bibr" target="#b57">(Ocaña et al., 2020)</ref>. <software ContextAttributes="created">SciPhy</software> is a CPU-intensive workflow, bacause many of its activities (especially the evolutionary model election) commonly execute for several hours depending on the input data and the chosen execution environment.</p><p>Montage <ref type="bibr" target="#b40">(Jacob et al., 2009</ref>) is a well-known astronomy workflow that assembles astronomical images into mosaics by using FITS (Flexible Image Transport System) files. Those files include a coordinate system and the image size, rotation, and WCS (World Coordinate System) map projection. Figure <ref type="figure" target="#fig_5">9B</ref> shows the montage activities: (i) <software ContextAttributes="created">ListFITS</software>, is gathered from real executions of scientific workflows on the grid and in the cloud from the <software ContextAttributes="created">Pegasus</software>' team in <software ContextAttributes="created">ISI</software> at the University of Southern California. The <software ContextAttributes="created">SciPhy</software> executions consumed from 200 up to 500 fasta files downloaded from RefSeq database. The Montage executions consumed from 50 up to 100 FIT files obtained from the "Two Micron All-Sky Survey"<ref type="foot" target="#foot_4">1</ref> . In the case of <software ContextAttributes="created">SciPhy</software>, the executions were performed by 3 different users (one expert and 2 undergraduate students). In the case of Montage (the executions in <software ContextAttributes="created">SciCumulus</software> were performed by an undergraduate student and the ones downloaded from the Workflow Generator site were performed by experts). Table <ref type="table" target="#tab_5">1</ref> summarizes the main characteristics of the datasets. The Total Records column shows the number of past executions of each workflow. Each dataset record can be used as an example for generating Machine Learning models during the algorithm's execution. As seen, the <software ContextAttributes="created">SciPhy</software> dataset is relatively small compared to Montage. The column Total Attributes shows how many activity parameters are considered in each workflow execution. Both workflows have the same number of categorical domain parameters, as presented in the column Categorical Attributes. Montage has more numeric domain parameters than <software ContextAttributes="created">SciPhy</software>, as shown in the Numerical Attributes column.</p><p>Statistics on the <software ContextAttributes="created">SciPhy</software> numerical attributes are shown in Table <ref type="table" target="#tab_6">2</ref>. This table presents the minimum and maximum values of each attribute, in addition to the standard deviation. The attribute prob1 (probability of a given evolutive relationship is valid) has the highest standard deviation, and its range of values is the largest among all attributes. The prob2 attribute (probability of a given evolutive relationship is valid) has both a range of values and the standard deviation similar to prob1. The standard deviation of the values of num_aligns (total number of alignments in a given data file) is very small, while the attribute length (maximum sequence length in a specific data file) has a high standard deviation, considering its values range.</p><p>The Montage numerical attributes, shown in Table <ref type="table" target="#tab_7">3</ref>, in most of the cases, have smaller standard deviation than the <software ContextAttributes="created">SciPhy</software>. On average, Montage attributes also have a smaller values range than <software ContextAttributes="created">SciPhy</software> dataset attributes. Also, in Montage dataset, the crota2 attribute (a float value that represents an image rotation on sky) has the largest values range and the  </p></div>
<div><head>Discrete domain recommendation evaluation</head><p>This experiment was modeled to evaluate FReeP's algorithm key concepts using the naive version presented in Algorithm 1, that was developed to recommend one discrete domain  parameter at a time. This experiment aims at evaluating and comparing the performance of FReeP when its hypothesis_generation step instantiates either a single classifier or a ranker. The ranker tested as a model was implemented using the Pairwise Label Ranking technique. K Nearest Neighbors <ref type="bibr" target="#b44">(Keller, Gray &amp; Givens, 1985)</ref> classifier is used as the classifier of this ranker implementation. The k parameter of K Nearest Neighbors classifier was set as 3, 5, 7 for both the ranker and classifier. The choice of k ∈ {3,5,7} is because small datasets are used, and thus k values greater than 7 do not return any neighbors in the experiments.</p><p>Experiment 1. Algorithm 1 evaluation script</p><p>1. The algorithm is instantiated with the classifier or ranker and a recommendation target workflow parameter.</p><p>2. The provenance database is divided into k parts to follow a K-Fold Cross Validation procedure <ref type="bibr" target="#b45">(Kohavi, 1995)</ref>. At each step, the procedure takes k -1 parts to train the model and the 1 remaining part to make the predictions. In this experiment, k = 5.</p><p>3. Each workflow parameter is used as recommendation target parameter.</p><p>4. Each provenance record in test data is used to retrieve target parameter real value.</p><p>5. Parameters that are not the recommendation target are used as preferences, with values from current test record.</p><p>6. Then, algorithm performs recommendation and both the result and the value present in the test record for the recommendation target parameter are stored.</p><p>7. Precision and recall values are calculated based on all K-Fold Cross Validation iterations.</p></div>
<div><head>Results</head><p>Experiment 1 results are presented and analyzed based on the values of precision and recall, in addition to the execution time. Figure <ref type="figure">11</ref> shows that Algorithm 1 execution with <software ContextAttributes="created">Sciphy</software> provenance database, using both the classifier and the ranker. Only KNN classifier with k = 3 gives a precision greater than 50%. Also, a high standard deviation is noticed. Even with unsatisfactory performance, Fig. <ref type="figure">12</ref> shows that KNN classifier presented better recall results than those for precision, both in absolute values terms and standard deviation, which had a slight decrease. In contrast, the ranker recall was even worse with the precision results and still present a very high standard deviation. Figure <ref type="figure" target="#fig_0">13</ref> shows the execution time, in seconds, to obtain the experiment's recommendations for <software ContextAttributes="created">SciPhy</software>. The execution time of ranker is much more significant when compared to the time spent by the classifier. This behavior can be explained by the fact that the technique used to generate the ranker creates multiple binary classifiers. Another point to note is that the execution time standard deviation from ranker is also very high. It is important to note that when FReeP uses KNN, it is memory-based, since each recommendation needs to be loaded into main memory.</p><p>Analyzing Fig. <ref type="figure" target="#fig_1">14</ref> (Montage) one can conclude that with the use of k = 3 for the classifier and for the ranker produces relevant results. The precision for this case reached 80%, and the standard deviation was considerably smaller compared to the precision results with <software ContextAttributes="created">Sciphy</software> dataset in Fig. <ref type="figure">11</ref>. For k ∈ {5,7}, the same results behavior was observed, considerably below those expected. Considering the precision, Fig. <ref type="figure" target="#fig_9">15</ref> shows that the results for k = 3 were the best for both the classifier and for ranker, although for this case they did not reach 80% (although it is close). It can be noted that the standard deviation was smaller when compared to the standard deviations found for precision. One interesting point about the execution time of the experiment with Montage presented in Fig. <ref type="figure" target="#fig_10">16</ref> is that for k ∈ {3,7} the ranker spent less time than the classifier. This behavior can be explained because the ranker, despite being generated by a process where several classifiers are built, relies on binary classifiers. When used alone, the classifier needs to handle all class variables values, in this case, parameter recommendation values, at once. However, it is also important to note that the standard deviation for ranker is much higher than for the classifier.</p><p>In general, it was possible to notice that the use of ranker did not bring encouraging results. In all cases, ranker precision and recall were lower than those presented by the classifier. Besides, the standard deviation of ranker in the execution time spent results was also very high. Another point to be noted is that the best precision and recall results were obtained with the data from Montage workflow. These results may be linked to the fact that the Montage dataset has more records than the <software>Sciphy</software> dataset.</p></div>
<div><head>Discrete and continuous domain recommendation evaluation</head><p>Experiment 1 was modified to evaluate the Algorithm 2 performance, yielding Experiment 2. Algorithm 2 was executed with variations in the choice of classifiers and regressors, partitions strategies, and records percentage from provenance database. All values per algorithm parameter are presented in Table <ref type="table" target="#tab_8">4</ref>. Experiment 2. Algorithm 2 evaluation script 1. Algorithm 2 is instantiated with a classifier or regressor, a partitioning strategy, percentage data to be returned by partitioning strategy, and a target workflow parameter.</p><p>2. Provenance database is divided using K-Fold Cross Validation, k = 5</p><p>3. Each provenance record on test data is used to retrieve the target parameter's real value.</p><p>4. A random number x between 2 and parameters number present in provenance database is chosen to simulated preference number used in recommending target parameter.</p></div>
<div><head>5.</head><p>x parameters are chosen from the remaining test record to be used as preferences.</p><p>6. Algorithm performs recommendation, and both result and test record value for the target parameter are stored.</p><p>7. Precision and recall, or MSE values are calculated based on all K-Fold Cross Validation iterations.  </p></div>
<div><head>Results</head><p>Experiment 2 results are presented using precision, recall, and execution time for categorical domain parameters recommendations, while numerical domain parameters recommendations are evaluated using MSE and the execution time. Based on the results obtained in Experiment 1, only classifiers were used as Machine Learning models in Experiment 2, i.e., we do not consider rankers.</p><p>The first observation when analyzing the precision data in Fig. <ref type="figure">17</ref> is that ANOVA partitioning strategy obtained better results than PCA. ANOVA partitioning strategy precision in absolute values is generally more significant, and variation in precision for each attribute considered for recommendation is lower than PCA strategy. The classifiers have very similar performance for all percentages of partitions in the ANOVA strategy. On the other hand, the variation in the percentages of elements per partition also reflects a more significant variation in results between the different classifiers. The Multi Layer Perceptron (MLP) classifier, which was trained using the Stochastic Descending Gradient <ref type="bibr" target="#b7">(Bottou, 2010)</ref> with a single hidden layer, presents the worst results except in the setup that it follows the PCA partitioning strategy with a percentage of 70% elements in the partitioning. The MLP model performance degradation may be related to the fact that the numerical attributes are not normalized before algorithm execution.</p><p>Recall results, in Fig. <ref type="figure" target="#fig_3">18</ref> were very similar to precision results in absolute values. A difference is the smallest variation, in general, of recall results for each attribute used in the recommendation experiment. The Multi Layer Perceptron classifier presented a behavior similar to the precision results, with a degradation in the setup that includes ANOVA partitioning with 70% of the elements in the partitioning.  execution time using different classifiers for each attribute is also much smaller and stable for ANOVA strategy than for PCA, regardless of element partition percentage. Analyzing precision, recall, and execution time spent data jointly, ANOVA partitioning strategy showed the best recommendation performance for the categorical domain parameters of the <software ContextAttributes="created">Sciphy</software> provenance database. Going further, the element partition percentage generated by the strategy has no significant impact on the results. Another interesting point is that a simpler classifier like KNN presented results very similar to those obtained by a more complex classifier like SVM.</p><p>Figure <ref type="figure" target="#fig_13">20A</ref> brings the data from results obtained for the numerical domain parameter <software ContextAttributes="created">Sciphy</software> provenance database. The data shows zero MSE in all cases, except for the use of Multi Layer Perceptron in the regression. This result can be explained by the small database and the few different values for each numerical domain parameter. Small values difference per parameter suggests that the regressors have no work to generate a result equal to what is already present in the database.</p><p>Looking at Fig. <ref type="figure" target="#fig_13">20B</ref>, one can notice that, similar to the categorical domain parameters results, the execution time of ANOVA partitioning strategy is much less than the time used by the PCA strategy. Another similar point with categorical domain parameter results is the smaller and more stable ANOVA strategy results variation.</p><p>From all results obtained in the Experiment 2 using <software ContextAttributes="created">Sciphy</software> provenance database, it can be noticed that the ANOVA partitioning strategy had the best performance. Further precision, recall, and MSE results, for the Algorithm 2 setup with ANOVA partitioning strategy also proved to be the one that performed the recommendations in the shortest time, generally in half the time that the PCA partitioning strategy. Note that the recommendation time can be treated as training time since the proposed algorithm has a memory-based approach. Finally, the choice of the generated partition size and the classifier or regressor used have no significant impact on the final result unless the classifier or regressor is based on Multi Layer Perceptron with the same parametrization used in this article. Analyzing Fig. <ref type="figure">21</ref>, precision results obtained with categorical domain parameters from Montage workflow provenance database is observed that in almost all the experiment setup variations evaluated, maximum performance is reached. As seen in Table <ref type="table" target="#tab_5">1</ref>, the Montage workflow provenance database used in the experiments has only two categorical domain parameters. The small variation in possible values in the database is an explanation for the precision results. The recall results in Fig. <ref type="figure">22</ref> are similar to the precision ones.</p><p>Concerning the results about the experiment time with categorical domain parameters from the Montage provenance database, presented in Fig. <ref type="figure" target="#fig_0">23</ref>, one can see that the KNN classifier, k = 3, with PCA partitioning strategy was the most time-consuming. On the other hand, with the same PCA partitioning strategy, the Multi Layer Perceptron classifier used less time, but with a wide variation in recommendation times for different parameters. The ANOVA partitioning strategy continued to be a partitioning strategy that delivers the fattest recommendations. Still analyzing ANOVA partitioning strategy results,  <ref type="figure" target="#fig_15">24A</ref> show that, in general, the MSE was very close to zero for all cases, except in algorithm setup using PCA partitioning strategy with 30% elements in the generated partition and the regressor implemented by Multi Layer Perceptron. The MSE and its variation were very close to zero.</p><p>Regarding the execution time of Experiment 2 for numerical domain parameters recommendations for Montage data, Fig. <ref type="figure" target="#fig_15">24B</ref> indicates the same behavior shown by results with <software ContextAttributes="created">SciPhy</software> provenance database. Using ANOVA partitioning strategy and KNR regressors with k ∈ {5,7} as setup for Algorithm 2 produced the fastest recommendations.</p><p>The experiment execution time of Montage provenance database was much greater than the time used with the data from the workflow <software>Sciphy</software>. The explanation is the difference in the database size. Another observation is that the ANOVA partitioning strategy produces the fastest recommendations. Another point is that the percentage of the elements in partitioning generated by each partitioning strategy has no impact on the algorithm performance. Finally, it was possible to notice that the more robust classifiers and regressors had their performance exceeded by simpler models in some cases for the data used.</p></div>
<div><head>Generic FReeP recommendation evaluation</head><p>A third experiment was modeled to evaluate Algorithm 3 performance. As in Experiment 2, different variations, following Table <ref type="table" target="#tab_8">4</ref> values, were used in algorithm execution. Precision, recall, and MSE are also the metrics used to evaluate the recommendations made by each algorithm instance.</p><p>Experiment 3. Algorithm 3 evaluation script 1. n Records from the provenance database were chosen as random examples.</p><p>2. m ≥ 2 random parameters were chosen for each example record as preferences, and their values are the same as those present in the example record.</p><p>3. Algorithm 3 was instantiated with a classifier or a regressor, a partitioning strategy, the partitions percentage to be returned by the partitioning strategy, and the selected m preferences.</p><p>4. Each returned recommendation is separated into numeric and categorical and is stored.</p><p>5. Precision and recall values were calculated for categorical recommendations and Mean Square Error (MSE) for numerical recommendations.</p></div>
<div><head>Results</head><p>Results showed here were obtained by fixing parameter n = 10 in Experiment 3, and using only <software ContextAttributes="created">SciPhy</software> provenance database. Based on Experiment 2 results, it was decided to use the ANOVA partitioning strategy with 50% recovering elements from the provenance database. This choice is because the ANOVA partitioning strategy was the one that obtained the best results in previous experiment. As the percentage of data recovered by the strategy was not an impacting factor in the results, an intermediate percentage used in the previous experiment is selected. In addition, only KNN, with k ∈ {5,7}, and SVM were kept as classifiers, whereas only KNR, with k ∈ {5,7}, and SVR was chosen as regressors. These choices are supported by, in general, are the ones that present the best precision, recall, and MSE results in Experiment 2. Table <ref type="table" target="#tab_9">5</ref> presents the results obtained with the Algorithm 3 instance variations. Each row in the table represents an Algorithm 3 instance setup. The column that draws the most attention is the Failures. What happens is that, for some cases, the algorithm was not able to carry out the recommendation together and therefore did not return any recommendations. It is important to remember that each algorithm setup was tested on a set with 10 records extracted randomly from the database. The random record selection process can select records in which parameter values can be present only in the selected record. For this experiment, the selected examples are removed from the dataset, and therefore there is no other record that allows the correct execution of the algorithm. Analyzing Table <ref type="table" target="#tab_9">5</ref> results, focusing on the column Failures and taking into account that 10 records were chosen for each setup, it is possible to verify that in most cases, the algorithm was not able to make recommendations. However, considering only the recommendations made, it can be seen that the algorithm had satisfactory results for the precision and recall metrics. The values presented for the MSE metric were mostly satisfactory, differing only in the configurations of lines 4 and 7, both using the regressor KNR with k = 5. Another point to note is that the algorithm had more problems to make recommendations when the SVM classifier was used. Furthermore, it is possible to note that algorithm setups with more sophisticated Machine Learning models such as SVM and SVR do not add performance to the algorithm, specifically for <software ContextAttributes="created">Sciphy</software> provenance dataset used.</p></div>
<div><head>RELATED WORK</head><p>Previous literature works had already relied on recommender systems to support scientific workflows. Moreover, hyperparameter tuning methods also have similar goals as paramater recommendation. Hyperparameters are variables that cannot be estimated directly from data, and, as a result, it is the user's task to explore and define those values. Hyperparameter Optimization (HPO) is a research area that emerged to assist users in adjusting the hyperparameters of Machine Learning models in a non-ad-hoc manner <ref type="bibr" target="#b77">(Yang &amp; Shami, 2020)</ref>. The well-defined processes resulting from research in the area may speed up the experimentation process and allow for reproducibility and fair comparison between models. Among the different methods of HPO, we can mention Decision Theory, Bayesian Optimization, Multi-fidelity Optimization, and Metaheuristic Algorithms.</p><p>Among the Decision Theory methods, the most used are Grid Search <ref type="bibr" target="#b4">(Bergstra et al., 2011)</ref> and Random Search <ref type="bibr" target="#b5">(Bergstra &amp; Bengio, 2012)</ref>. For both strategies, the user defines a list of values to be experimented for each hyperparameter. In Grid Search, the search for optimum values is given by experimenting the predefined values for the entire cartesian product. Random Search selects a sample for the hyperparameters to improve the execution time of the whole process. While the exponential search space of Grid Search may be impossible to complain, in Random Search there is the possibility that an optimal combination will not be explored. Also, the common problem between both approaches is that the dependencies between the hyperparameters are not taken into account. FReeP considers the possible dependencies between parameters by following the concept of classifier chains.</p><p>The Bayesian Optimization <ref type="bibr" target="#b18">(Eggensperger et al., 2013)</ref> method optimizes the search space exploration using information from the previously tested hyperparameters to prune the non-promising combinations test. Despite using a surrogate model, the Bayesian optimization method still requires that the target model evaluation direct the search for the optimal hyperparameters. In a scenario of scientific workflows, it is very costly from the economical and runtime perspective to run an experiment, even more so to only evaluate a combination of parameter values. FReeP does not require any new workflow execution to recommend which values to use as it uses only data from past executions.</p><p>Multi-fidelity Algorithms <ref type="bibr" target="#b79">(Zhang et al., 2016)</ref> also have the premise of balancing the time spent to search for hyperparameters. This kind of algorithm is based on successively evaluating hyperparameters in a subset search space. Those strategies follow similar motivations as the partitions generation of FReeP. However, in a scenario of scientific workflows, the Multi-fidelity algorithms still require workflow execution to evaluate combination quality.</p><p>The Metaheuristics Algorithms <ref type="bibr" target="#b27">(Gogna &amp; Tayal, 2013)</ref>, based on the evolution of populations, use different forms of combinations of pre-existing populations in the hope of generating better populations at each generation. For hyperparameters tuning, hyperparameters with missing values are the population. Still, FReeP does not require any new execution of the workflow a priori to evaluate a recommendation given by the algorithm.</p><p>In general, the works that seek to assist scientists with some type of recommendation involving scientific workflow are focused on the composition phase. Zhou et al. ( <ref type="formula">2018</ref>) uses a graph-based clustering technique to recommend workflows that can be reused in the composition of a developing workflow. De <ref type="bibr" target="#b12">Oliveira et al. (2008)</ref> uses workflow provenance to extract connection patterns between components in order to make recommendations of new components for a workflow in composition. For each new component used in the composition of workflow, new components are recommended. <ref type="bibr" target="#b33">Halioui, Valtchev &amp; Diallo (2016)</ref>, uses Natural Language Processing combined with specific ontologies in the field of Bioinformatics to extract concrete workflows from works in the literature. After the reconstruction of concrete workflows, tool combinations patterns, its parameters, and input data used in these workflows are extracted. All this data extracted can be used as assistance for composing new ones workflows that solve problems related to the mined workflows.</p><p>Yet concerned with assistance during the workflow composition phase, <ref type="bibr" target="#b53">Mohan, Ebrahimi &amp; Lu (2015)</ref> proposes the use of Folksonomy <ref type="bibr" target="#b29">(Gruber, 2007)</ref> to enrich the data used for the recommendation of others workflows similar to a workflow under development. A design workflow tool was developed that allows free specification tags to be used in each component, making it possible to use not only the recommendation strategy through the workflow syntax, but also component semantics. <ref type="bibr" target="#b67">Soomro, Munir &amp; McClatchey (2015)</ref> uses domain ontologies as a knowledge base to incorporate semantics into the recommendation process. A hybrid recommender system was developed using ontologies to improve the already known recommendation strategy based on the extraction of standards from other workflows. Zeng, He &amp; Van der Aalst (2011) uses data and control dependencies between activities, stored in the workflow provenance to build a causality table and another weights table. Subsequently, a Petri network <ref type="bibr" target="#b82">(Zhou &amp; Venkatesh, 1999</ref>) is used to recommend other components for the composition of workflow.</p><p>recommendation algorithm capable of making value recommendations for one or multiple parameters of a scientific workflow, taking into account the user's preferences.</p></div>
<div><head>FINAL REMARKS</head><p>The precision and recall results obtained from the experiments suggest that FReeP is useful in recommending missing parameter values, decreasing the probability that failures will abort scientific experiments performed in High-Performance Computing environments. These results show a high-reliability degree, especially in the recommendation for one workflow parameter due to the number of experimental iterations performed to obtain the evaluations. The low availability of data for the experiments of the recommendation for n parameters impacts the reliability of the results obtained in this scenario. However, the results presented for the n parameters recommendation show that the approach is promising.</p><p>FReeP has a number of characteristics pointing out its contribution in saving runtime and financial resources when executing scientific experiments. First, FReeP can be executed on standard hardware, such as that used in the experiments presented in this article, without the need for an HPC environment. Besides, FReeP does not require any further execution of the scientific workflow to assess the recommendation's quality as it uses provenance data. This characteristic of not requiring an instance of the scientific experiment to be performed is the huge difference and advantage compared with Hyperparameter Optimization strategies widely used in the Machine Learning models tuning.</p><p>In FReeP, all training data are collected and each tuple represents a different execution of the workflow. This data gathering process can nevertheless be time-consuming. However, one aspect that is expected is that the recommendation process will be performed once and a series of executions of the same workflow is repeated a significant number of (varying the known parameter). In addition, in many research groups there is already a database containing the provenance <ref type="bibr" target="#b20">(Freire et al., 2008)</ref> that can be used to recommend parameter values for non-expert users, i.e., the scientists will not need to effectively execute the workflow to train the model since provenance data is already available. Public provenance repositories such as <software ContextAttributes="created">ProvStore</software> (https://openprovenance.org/ store/) <ref type="bibr" target="#b38">(Huynh &amp; Moreau, 2015)</ref> can be used as input for FReeP. For example, <software ContextAttributes="created">ProvStore</software> contains 1,136 documents (each one associated with a workflow execution) of several different real workflows uploaded by research groups around the world.</p><p>From the perspective of runtime, when using the ANOVA partitioning strategy, in the experimental evaluation with the provenance data from the <software>Sciphy</software> workflow, the average time spent on the recommendations is about only 4 minutes. In comparison, the average time of execution of the workflow <software ContextAttributes="created">Sciphy</software> extracted from the provenance data used is about 17 h and 32 min. Still taking into account the use of the ANOVA partitioning strategy, in the experimental evaluation with the Montage workflow provenance data, the average time spent on the recommendation is about 1 h and 30 min. In contrast, the average execution time of a workflow experiment Montage extracted from the provenance data used was about 2 h and 3 min.</p><p>Although it is more evident the lower relation between the experiment's execution time and the recommendation time when analyzing the data from the <software>Sciphy</software> workflow, it is essential to emphasize that more robust hardware is not necessary to execute the recommendation process. Yet, future improvements in FReeP includes employing parallelism techniques to further decrease the recommendation time.</p></div>
<div><head>CONCLUSION</head><p>The scientific process involves observing phenomena from different areas, formulating hypotheses, testing, and refining them. Arguably, this is an arduous job for the scientist in charge of the process. With the advances in computational resources, there is a growing concern about helping scientists in scientific experimentation. A significant step towards a more robust aid was the adoption of scientific workflows as a model for representing scientific experiments and Scientific Workflow Management Systems to support the management of experiment executions.</p><p>Computational execution of the experiments represented as scientific workflows relies on the use of computer programs that play the role of each stage of the experiment. In addition to input data, these programs often need additional configuration parameters to be adjusted to simulate the experiment's conditions. The scientist responsible for the experiment ends up developing an intuition about the sets of parameters that lead to satisfactory results. However, another scientist who runs the same experiment will not have the same experience, which may lead him/her to define a set of parameters that will not result in a successful experiment.</p><p>Several proposals in the literature have aimed at supporting the composition phase of the experiments, but recommending parameter values for the experiment execution phase is still an open field. This article presented FReeP: Feature Recommender From Preferences, an algorithm for recommending values for parameters in scientific workflows considering the user's preferences. The goal was to allow a new user to express their preferences of values for a subset of workflow parameters and recommend values for the parameters that had no preference defined. FReeP has three versions, all of them relying on Machine Learning techniques. Two approaches focused on the value recommendation for one parameter at a time. The third instance addresses recommending values for all the other parameters of a workflow for which a user preference was not defined.</p><p>The proposed algorithm proved to be useful for recommending one parameter, indicating a path for the recommendation of n parameters. Nevertheless, there are some limitations. FReeP, as a memory-based algorithm, faces scalability issues as its implementation can consume a lot of computational resources. Yet, the recommendations of FReeP are limited to the existence of examples on the provenance dataset. This means that the algorithm cannot make any "default" recommendations if there are no examples for the algorithm's execution or recommend values that are not present in the provenance dataset. Also, the recommendation algorithm may have a longer processing time than the experiment itself. Another point is that all the instances have the same weight during the recommendation process. The algorithm does not consider the user's expertise that performed the previous execution to adjust an example's weight. Still, the algorithm considers only the set of parameters of the workflow; however, a set of parameters may be more or less relevant according to the input data. Additionally, the recommendation algorithm may end up recommending a set of values present in the provenance base that causes a workflow execution failure.</p><p>Based on those limitations, there are some proposals for future work. First proposal is parallelizing the processing of the generated partitions, which should decrease the time spent on the recommendation. In addition, evaluating FReeP on data from other domains and evaluating the tradeoff between the recommendation time and the algorithm execution time. Also, associating weights with examples from the provenance dataset according to the user's profile. Lastly, using instances from the provenance dataset that failed to execute the workflow as a constraint to improve the recommendations' results.</p></div><figure xml:id="fig_0"><head>Figure 3 A</head><label>3</label><figDesc>Figure3A synthetic workflow: circles represent activities, arrows between the circles represent the link between activities (data dependencies), and the labels for each circle represent the configuration parameters for each activity.Full-size  DOI: 10.7717/peerj-cs.606/fig-3</figDesc></figure>
<figure xml:id="fig_1"><head>Figure 4</head><label>4</label><figDesc>Figure 4 FReeP architecture overview. Full-size  DOI: 10.7717/peerj-cs.606/fig-4</figDesc></figure>
<figure xml:id="fig_2"><head /><label /><figDesc>Figure 7 uses data from the examples in Figs. 5 and 6 to show how the vertical_filter step works.</figDesc></figure>
<figure xml:id="fig_3"><head>Figure 8</head><label>8</label><figDesc>Figure 8 Generic FReeP architecture overview. Full-size  DOI: 10.7717/peerj-cs.606/fig-8</figDesc><graphic coords="19,33.85,87.70,538.41,161.58" type="bitmap" /></figure>
<figure xml:id="fig_4"><head>P</head><label /><figDesc>: recommendation target parameter D : fðparam; valÞjparam is a workflow parameter; valis the preference value for paramg D : ffðparam 1 1 ; val 1 1 Þ; …; ðparam l 1 ; val l 1 Þ; …ðparam m l ; val m l Þgjl is the workflow parameters number; m is the provenance dataset lengthg N :number of random sequences orders to be generated 1: procedure Generic FReeP(P, D, N) 2: target_parameters ← parameters_extractor(P, D) 3: votes ← ø 4: for each param ∈ target_parameters do 5: votes ← votes ∪ {(param, []) } 6: ordered_sequences ← sequence_generator(target_parameters, N) 7: for each sequence ∈ ordered_sequences do 8: preferences_tmp ← P 9: for each param ∈ sequence do 10: recommendation ← FReeP(param, preferences_tmp, D) 11: votes[param] ← votes[param] ∪ recommendation 12: new_preference ← generate_preference(param, recommendation) 13: preferences_tmp ← preferences_tmp ∪ new_preference 14: response ← ø 15: for each (param, values) ∈ votes do 16: response[param] most_voted(values) 17: return response Silva Junior et al. (2021), PeerJ Comput. Sci., DOI 10.7717/peerj-cs.606 19/46workflows. The proposals covered two main scenarios for parameters value recommendation (single and multiple parameter at a time).</figDesc></figure>
<figure xml:id="fig_5"><head>Figure 9</head><label>9</label><figDesc>Figure 9 The abstract specification of (a) SciPhy and (b) Montage. Full-size  DOI: 10.7717/peerj-cs.606/fig-9</figDesc><graphic coords="21,186.86,87.70,388.86,237.94" type="bitmap" /></figure>
<figure xml:id="fig_6"><head /><label /><figDesc>largest standard deviation. The dec (an optional float value that represents Dec for region statistics) and crval2 (a float value that represents Axis 2 sky reference value in Montage workflow) attributes have close statistics and are the attributes with the smallest data range and the smallest Montage data standard deviation. In Fig. 10, it is possible to check the correlation between the different attributes in the datasets. It is notable in both Figs. 10A and 10B that the attributes (i.e., workflow parameters) present a weak correlation. All those statistics are relevant to understand the results obtained by the experiments performed from each version of FReeP algorithm.</figDesc></figure>
<figure xml:id="fig_7"><head>Figure 10</head><label>10</label><figDesc>Figure 10 Datasets attributes correlation matrices. Full-size  DOI: 10.7717/peerj-cs.606/fig-10</figDesc><graphic coords="24,33.85,247.47,538.41,242.14" type="bitmap" /></figure>
<figure xml:id="fig_8"><head>Figure 11 46 Figure 13 Figure 14</head><label>11461314</label><figDesc>Figure 11 Precision results with SciPhy data.</figDesc><graphic coords="26,186.86,87.71,299.17,306.54" type="bitmap" /></figure>
<figure xml:id="fig_9"><head>Figure 15</head><label>15</label><figDesc>Figure 15 Recall results with Montage data. Full-size  DOI: 10.7717/peerj-cs.606/fig-15</figDesc></figure>
<figure xml:id="fig_10"><head>Figure 16</head><label>16</label><figDesc>Figure 16 Experiment recommendation execution time with Montage data. Full-size  DOI: 10.7717/peerj-cs.606/fig-16</figDesc></figure>
<figure xml:id="fig_11"><head>Figure 17 46 Figure 19</head><label>174619</label><figDesc>Figure 17 Precision results with Sciphy data. Full-size  DOI: 10.7717/peerj-cs.606/fig-17</figDesc></figure>
<figure xml:id="fig_12"><head>Figure 18 Figure 19</head><label>1819</label><figDesc>Figure 18 Recall results with Sciphy data. Full-size  DOI: 10.7717/peerj-cs.606/fig-18</figDesc></figure>
<figure xml:id="fig_13"><head>Figure 20</head><label>20</label><figDesc>Figure 20 MSE results and recommendation execution time with Sciphy data. Full-size  DOI: 10.7717/peerj-cs.606/fig-20</figDesc><graphic coords="32,33.85,87.70,537.17,289.70" type="bitmap" /></figure>
<figure xml:id="fig_14"><head>Figure 21 46 Figure 22 Figure 23</head><label>21462223</label><figDesc>Figure 21 Precision results with Montage data. Full-size  DOI: 10.7717/peerj-cs.606/fig-21</figDesc></figure>
<figure xml:id="fig_15"><head>Figure 24</head><label>24</label><figDesc>Figure 24 MSE results and recommendation execution time with Montage data. Full-size  DOI: 10.7717/peerj-cs.606/fig-24</figDesc><graphic coords="35,33.85,87.70,537.17,233.18" type="bitmap" /></figure>
<figure type="table" xml:id="tab_1"><head /><label /><figDesc>Figure2Votes example that each candidate received in voters preference order.</figDesc><table><row><cell>Voter 1</cell><cell>Voter 2</cell><cell>Voter 3</cell><cell>Voter 4</cell><cell>Voter 5</cell></row><row><cell>Candidate 1: A</cell><cell>Candidate 1: C</cell><cell>Candidate 1: D</cell><cell>Candidate 1: B</cell><cell>Candidate 1: C</cell></row><row><cell>Candidate 2: C</cell><cell>Candidate 2: B</cell><cell>Candidate 2: C</cell><cell>Candidate 2: D</cell><cell>Candidate 2: D</cell></row><row><cell>Candidate 3: D</cell><cell>Candidate 3: D</cell><cell>Candidate 3: B</cell><cell>Candidate 3: C</cell><cell>Candidate 3: B</cell></row><row><cell>Candidate 4: B</cell><cell>Candidate 4: A</cell><cell>Candidate 4: A</cell><cell>Candidate 4: A</cell><cell>Candidate 4: A</cell></row></table><note><p>Full-size  DOI: 10.7717/peerj-cs.606/fig-2 Silva Junior et al. (2021), PeerJ Comput. Sci., DOI 10.7717/peerj-cs.606 9/46</p></note></figure>
<figure type="table" xml:id="tab_3"><head /><label /><figDesc>Example of FReeP's horizontal filter using one partitioning rule for the Sciphy provenance dataset. Full-size  DOI: 10.7717/peerj-cs.606/fig-6</figDesc><table><row><cell /><cell /><cell cols="2">Provenance dataset</cell><cell /><cell /><cell /></row><row><cell cols="3">num_aligns length model1</cell><cell>prob1</cell><cell>model2</cell><cell>prob2</cell><cell /></row><row><cell>10.0</cell><cell cols="5">854.0 WAG+I+F 4634.242459 WAG+I+F 4634.242459</cell><cell /></row><row><cell>11.0</cell><cell cols="5">339.0 WAG+I+F 2012.681247 WAG+I 2052.864650</cell><cell /></row><row><cell>10.0</cell><cell cols="5">854.0 WAG+I+F 4634.242459 WAG+I+F 4634.242459</cell><cell /></row><row><cell>partitions</cell><cell /><cell /><cell /><cell /><cell /><cell /><cell>num_aligns length model1</cell><cell>prob1</cell><cell>model2</cell><cell>prob2</cell></row><row><cell>[ [num_aligns], [model1],</cell><cell>Iteration 1</cell><cell cols="2">Current Partition rule [num_aligns]</cell><cell cols="2">Preferences Selection num_aligns == 10.0</cell><cell>Horizontal Filter</cell><cell>10.0</cell><cell>854.0 WAG+I+F 4634.242459 WAG+I+F 4634.242459</cell></row><row><cell>[num_aligns,</cell><cell /><cell /><cell /><cell /><cell /><cell /><cell>10.0</cell><cell>854.0 WAG+I+F 4634.242459 WAG+I+F 4634.242459</cell></row><row><cell>model1] ]</cell><cell /><cell /><cell /><cell /><cell /><cell /></row><row><cell>Preferences num_aligns == 10.0 model1 == 'WAG' Figure 6 Silva</cell><cell cols="3">Parameters in Preferences [num_aligns, model1] Workflow Parameters [num_aligns, length, model1, prob1, model2, prob2] Target Parameter y = model2</cell><cell>-</cell><cell>[num_aligns] [length,prob1,model2,prob2]</cell><cell>∪ ∪</cell><cell>length model1 854.0 WAG+I+F 4634.242459 WAG+I+F 4634.242459 prob1 model2 prob2 854.0 WAG+I+F 4634.242459 WAG+I+F 4634.242459 [num_aligns, length, 10.0 10.0 prob1, model2, prob2] Vertical Filter num_aligns length 10.0 854.0 4634.242459 WAG+I+F 4634.242459 prob1 model2 prob2 10.0 854.0 4634.242459 WAG+I+F 4634.242459 Provenance dataset after Horizontal Filter</cell></row></table><note><p>⊂ Figure 7 FReeP's vertical filter step. Full-size  DOI: 10.7717/peerj-cs.606/fig-7 Junior et al. (2021), PeerJ Comput. Sci., DOI 10.7717/peerj-cs.606 13/46</p></note></figure>
<figure type="table" xml:id="tab_5"><head>Table 1</head><label>1</label><figDesc>Dataset characteristics.</figDesc><table><row><cell>Dataset</cell><cell>Total records</cell><cell>Total attributes</cell><cell>Categorical attributes</cell><cell>Numerical attributes</cell></row><row><cell>Sciphy</cell><cell>376</cell><cell>6</cell><cell>2</cell><cell>4</cell></row><row><cell>Montage</cell><cell>1,565</cell><cell>8</cell><cell>2</cell><cell>6</cell></row></table></figure>
<figure type="table" xml:id="tab_6"><head>Table 2</head><label>2</label><figDesc>SciPhy dataset statistics.</figDesc><table><row><cell>Parameter</cell><cell>Minimum value</cell><cell>Maximum value</cell><cell>Standard deviation</cell></row><row><cell>num_aligns</cell><cell>9.00</cell><cell>11.00</cell><cell>0.21</cell></row><row><cell>length</cell><cell>85.00</cell><cell>1,039.00</cell><cell>169.90</cell></row><row><cell>prob1</cell><cell>634.67</cell><cell>5,753.52</cell><cell>1,103.43</cell></row><row><cell>prob2</cell><cell>635.87</cell><cell>5,795.28</cell><cell>1,101.76</cell></row></table></figure>
<figure type="table" xml:id="tab_7"><head>Table 3</head><label>3</label><figDesc>Montage dataset statistics.</figDesc><table><row><cell>Parameter</cell><cell>Minimum value</cell><cell>Maximum value</cell><cell>Standard deviation</cell></row><row><cell>cntr</cell><cell>0.00</cell><cell>134.00</cell><cell>35.34</cell></row><row><cell>ra</cell><cell>83.12</cell><cell>323.90</cell><cell>91.13</cell></row><row><cell>dec</cell><cell>-27.17</cell><cell>28.85</cell><cell>17.90</cell></row><row><cell>crval1</cell><cell>83.12</cell><cell>323.90</cell><cell>91.13</cell></row><row><cell>crval2</cell><cell>-27.17</cell><cell>28.85</cell><cell>17.90</cell></row><row><cell>crota2</cell><cell>0.00</cell><cell>360.00</cell><cell>178.64</cell></row></table><note><p><p><ref type="bibr" target="#b14">Silva Junior et al. (2021)</ref></p>, PeerJ Comput. Sci., DOI 10.7717/peerj-cs.606</p></note></figure>
<figure type="table" xml:id="tab_8"><head>Table 4</head><label>4</label><figDesc>Algorithm 2 values per parameter used in Experiment 2.</figDesc><table><row><cell>Classifiers</cell><cell>Regressors</cell><cell>Partition strategy</cell><cell>Percentage</cell></row><row><cell>KNN</cell><cell>Linear Regression</cell><cell>PCA</cell><cell>30</cell></row><row><cell>SVM</cell><cell>KNR</cell><cell>ANOVA</cell><cell>50</cell></row><row><cell>Multi-Layer Perceptron</cell><cell>SVR</cell><cell /><cell>70</cell></row><row><cell /><cell>Multi-Layer Perceptron</cell><cell /><cell /></row></table><note><p>Silva Junior et al. (2021), PeerJ Comput. Sci., DOI 10.7717/peerj-cs.606 28/46</p></note></figure>
<figure type="table" xml:id="tab_9"><head>Table 5</head><label>5</label><figDesc>Experiment 3 results with Sciphy dataset.</figDesc><table><row><cell>Classifier</cell><cell>Regressor</cell><cell>Partitioning strategy</cell><cell>MSE</cell><cell>Precision</cell><cell>Recall</cell><cell>Failures</cell></row><row><cell>KNN 5</cell><cell>KNR 5</cell><cell>ANOVA 50</cell><cell>0.0</cell><cell>1.0</cell><cell>1.0</cell><cell>6</cell></row><row><cell>KNN 5</cell><cell>KNR 7</cell><cell>ANOVA 50</cell><cell>0.0</cell><cell>1.0</cell><cell>1.0</cell><cell>6</cell></row><row><cell>KNN 5</cell><cell>SVR</cell><cell>ANOVA 50</cell><cell>1.1075</cell><cell>1.0</cell><cell>1.0</cell><cell>6</cell></row><row><cell>KNN 7</cell><cell>KNR 5</cell><cell>ANOVA 50</cell><cell>4,279.2240</cell><cell>1.0</cell><cell>1.0</cell><cell>5</cell></row><row><cell>KNN 7</cell><cell>KNR 7</cell><cell>ANOVA 50</cell><cell>0.0</cell><cell>1.0</cell><cell>1.0</cell><cell>5</cell></row><row><cell>KNN 7</cell><cell>SVR</cell><cell>ANOVA 50</cell><cell>0.444</cell><cell>1.0</cell><cell>1.0</cell><cell>5</cell></row><row><cell>SVM</cell><cell>KNR 5</cell><cell>ANOVA 50</cell><cell>1,148.1876</cell><cell>0.75</cell><cell>0.75</cell><cell>6</cell></row><row><cell>SVM</cell><cell>KNR 7</cell><cell>ANOVA 50</cell><cell>0.0</cell><cell>1.0</cell><cell>1.0</cell><cell>7</cell></row><row><cell>SVM</cell><cell>SVR</cell><cell>ANOVA 50</cell><cell>0.0</cell><cell>1.0</cell><cell>1.0</cell><cell /></row></table></figure>
			<note place="foot" xml:id="foot_0"><p>Silva Junior et al. (2021), PeerJ Comput. Sci., DOI 10.7717/peerj-cs.606 3/46</p></note>
			<note place="foot" xml:id="foot_1"><p><ref type="bibr" target="#b14">Silva Junior et al. (2021)</ref>, PeerJ Comput. Sci., DOI 10.7717/peerj-cs.606</p></note>
			<note place="foot" xml:id="foot_2"><p>Silva Junior et al. (2021), PeerJ Comput. Sci., DOI 10.7717/peerj-cs.606 5/46</p></note>
			<note place="foot" xml:id="foot_3"><p>Silva Junior et al. (2021), PeerJ Comput. Sci., DOI 10.7717/peerj-cs.606 20/46</p></note>
			<note place="foot" n="1" xml:id="foot_4"><p>Data sources are available at http://irsa. ipac.caltech.edu. Silva Junior et al. (2021), PeerJ Comput. Sci., DOI 10.7717/peerj-cs.606</p></note>
			<note place="foot" xml:id="foot_5"><p>22/46</p></note>
			<note place="foot" xml:id="foot_6"><p>Silva Junior et al. (2021), PeerJ Comput. Sci., DOI 10.7717/peerj-cs.606 46/46</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>ACKNOWLEDGEMENTS</head><p>The authors would like to thank <rs type="person">Kary Ocaña</rs> for her explanations of the parameters of <software ContextAttributes="created">SciPhy</software> workflow.</p></div>
			</div>
			<div type="funding">
<div><head>Funding</head><p>This work was supported by the <rs type="funder">Brazilian research agencies CNPq, FAPERJ</rs>, and <rs type="funder">CAPES (Finance Code</rs> <rs type="grantNumber">001</rs>). The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</p></div>
<div><head>Grant Disclosures</head><p>The following grant information was disclosed by the authors: <rs type="funder">CNPq</rs>, <rs type="funder">FAPERJ</rs> and <rs type="funder">CAPES</rs>: Finance Code <rs type="grantNumber">001</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_82TxVxz">
					<idno type="grant-number">001</idno>
				</org>
				<org type="funding" xml:id="_vE7H2B6">
					<idno type="grant-number">001</idno>
				</org>
			</listOrg>

			<div type="availability">
<div><head>Data Availability</head><p>The following information was supplied regarding data availability:</p><p>All the code and data are available at https://github.com/MeLL-UFF/FReeP. The CSV files are available in the Supplemental Files.</p></div>
			</div>

			<div type="annex">
<div><p>which extracts compressed FITS files, (ii) Projection, which maps the astronomical positions into a Euclidean plane, (iii) SelectProjections, which joins the planes into a single mosaic file, and (iv) <software>CreateIncorrectedMosaic</software>, which creates an overlapping mosaic as an image. Programs (v) CalculateOverlap, (vi) ExtractDifferences, (vii) CalculateDifferences, (viii) FitPlane, and (ix) <software ContextAttributes="created">CreateMosaic</software> refine the image into the final mosaic. Montage is a data-intensive workflow, since one single execution of Montage can produce several GBs of data.</p></div>
<div><head>Experimental and environment setup</head><p>All FReeP algorithms presented in this article were implemented using the Python <software ContextAttributes="created">programming language</software>. FReeP implementation also benefits from <software ContextAttributes="created">Scikit-Learn</software> <ref type="bibr" target="#b59">(Pedregosa et al., 2011)</ref> to learn and evaluate the Machine Learning models, <software ContextAttributes="created">numpy</software> (Van der <ref type="bibr" target="#b71">Walt, Colbert &amp; Varoquaux, 2011)</ref>, a numerical data manipulation library; and <software ContextAttributes="created">pandas</software> <ref type="bibr" target="#b51">(McKinney, 2011)</ref>, which provides tabular data functionalities.</p><p>The machine specification where experiments were performed is a CPU Celeron (R) Dual-Core T3300 @ 2.00 GHz × 2 processor, 4GB DDR2 RAM and 132 GB HDD. To measure recommendations performance when the parameter is categorical, precision and recall are used as metrics. Precision and recall are metrics widely used for the quantitative assessment of recommender systems <ref type="bibr" target="#b34">(Herlocker et al., 2004;</ref><ref type="bibr" target="#b64">Schein et al., 2002)</ref>. Eq. ( <ref type="formula">1</ref>) defines precision and Eq. ( <ref type="formula">2</ref>) defines recall, following the recommender vocabulary, where TR is the correct recommendation set and R is all recommendations set. An intuitive explanation to precision is that it represents the most appropriate recommendations fraction. Still, recall represents the appropriate recommendation fraction that was made.</p><p>When the parameter to be recommended is numerical, the performance of FReeP is evaluated with Mean Square Error (MSE). The MSE formula is given by Eq. ( <ref type="formula">3</ref>) where n is the recommendations number, TV is the correct recommendation values set, and RV is the recommended values set.</p></div>
<div><head>DATASET</head><p>The datasets used are provenance data extracted from real executions of the workflows <software ContextAttributes="used">SciPhy</software> (all executions) using <software ContextAttributes="used">SciCumulus</software> Workflow Management System and Montage (part of the executions with <software ContextAttributes="used">SciCumulus</software>) and part of the execution data gathered at the Workflow Generator site (https://confluence.pegasus.isi.edu/display/pegasus/ WorkflowGenerator). This site provides instances of real workflow for evaluation of algorithms and systems on a range of workflow sizes. All data within these workflow traces In the context of helping less experienced users in the use of scientific workflows, <ref type="bibr" target="#b76">Wickramarachchi et al. (2018)</ref> and <ref type="bibr" target="#b48">Mallawaarachchi et al. (2018)</ref> show experiments that prove that SWfMS BioWorkflow <ref type="bibr" target="#b75">(Welivita et al., 2018)</ref> use is effective in increasing student engagement and learning in Bioinformatics.</p><p>Some works propose recommendation approaches that assist less experienced users in analysis of unknown domains, as is the case of <ref type="bibr" target="#b41">Kanchana et al. (2016)</ref> and <ref type="bibr" target="#b42">Kanchana et al. (2017)</ref>, where a chart recommendation system was developed and evolved based on the use of metadata from any domain data. The system uses Machine Learning and Rule-based components that are refined with user feedback on the usefulness of the recommended charts.</p><p>Most of the approaches that uses recommender system methods to support the scientific process are closely linked to the experiment's composition phase. The execution phase, where there is a need to adjust parameters, still lacks alternatives. Table <ref type="table">6</ref> compares related work with FReeP approach. In Table <ref type="table">6</ref> we show the name of the approach (column Approach), if it is focused on a specific domain or if its generic (column Domain), if it prunes the search space or considers the entire search space (column Search Space), if the approach considers dependencies among parameters (column Considers Dependencies), if it requires a new execution of the workflow or the application (column Requires Execution), and in which phase of the experiment life-cycle the approach is executed (column Life-cycle Phase). If there is no information about the analyzed characteristics in the paper we set as N/A (Not Available) in Table <ref type="table">6</ref>. This work proposes a hybrid </p></div>
<div><head>Supplemental Information</head><p>Supplemental information for this article can be found online at http://dx.doi.org/10.7717/ peerj-cs.606#supplemental-information.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Toward the next generation of recommender systems: a survey of the state-of-the-art and possible extensions</title>
		<author>
			<persName><forename type="first">G</forename><surname>Adomavicius</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Tuzhilin</surname></persName>
		</author>
		<idno type="DOI">10.1109/TKDE.2005.99</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Knowledge and Data Engineering</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="734" to="749" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Ranking using the copeland score: a comparison with the hasse diagram</title>
		<author>
			<persName><forename type="first">G</forename><surname>Al-Sharrah</surname></persName>
		</author>
		<idno type="DOI">10.1021/ci100064q</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Chemical Information and Modeling</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="785" to="791" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Introduction to scientific workflow management and the kepler system</title>
		<author>
			<persName><forename type="first">I</forename><surname>Altintas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Ludaescher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Klasky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Vouk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SC'06: Proceedings of the 2006 ACM/IEEE Conference on Supercomputing</title>
		<meeting><address><addrLine>Piscataway</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page">205</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Multiple instance ranking</title>
		<author>
			<persName><forename type="first">C</forename><surname>Bergeron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zaretzki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Breneman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">P</forename><surname>Bennett</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th International Conference on Machine Learning</title>
		<meeting>the 25th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="48" to="55" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Algorithms for hyper-parameter optimization</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Bergstra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Bardenet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Kégl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="page" from="2546" to="2554" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Random search for hyper-parameter optimization</title>
		<author>
			<persName><forename type="first">J</forename><surname>Bergstra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="281" to="305" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Report on the international provenance and annotation workshop: (ipaw'06) 3-5 May 2006</title>
		<author>
			<persName><forename type="first">R</forename><surname>Bose</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Foster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Moreau</surname></persName>
		</author>
		<idno type="DOI">10.1145/1168092.1168102</idno>
	</analytic>
	<monogr>
		<title level="j">ACM SIGMOD Record</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="51" to="53" />
			<date type="published" when="2006">2006</date>
			<pubPlace>Chicago</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Large-scale machine learning with stochastic gradient descent</title>
		<author>
			<persName><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of COMPSTAT'2010</title>
		<meeting>COMPSTAT'2010</meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="177" to="186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Hybrid recommender systems: survey and experiments</title>
		<author>
			<persName><forename type="first">R</forename><surname>Burke</surname></persName>
		</author>
		<idno type="DOI">10.1023/A:1021240730564</idno>
	</analytic>
	<monogr>
		<title level="j">User Modeling and User-Adapted Interaction</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="331" to="370" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">The importance of encoding versus training with sparse coding and vector quantization</title>
		<author>
			<persName><forename type="first">A</forename><surname>Coates</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th International Conference on Machine Learning (ICML-11)</title>
		<meeting>the 28th International Conference on Machine Learning (ICML-11)</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="921" to="928" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Scicumulus: a lightweight cloud middleware to explore many task computing paradigm in scientific workflows</title>
		<author>
			<persName><forename type="first">De</forename><surname>Oliveira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Ogasawara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Baião</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Mattoso</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">3rd International Conference on Cloud Computing</title>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="378" to="385" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Data-intensive workflow management: for clouds and data-intensive and scalable computing environments</title>
		<author>
			<persName><forename type="first">De</forename><surname>Oliveira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dcm</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Pacitti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Synthesis Lectures on Data Management</title>
		<meeting><address><addrLine>San Rafael</addrLine></address></meeting>
		<imprint>
			<publisher>Morgan &amp; Claypool Publishers</publisher>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Using provenance to improve workflow design</title>
		<author>
			<persName><forename type="first">De</forename><surname>Oliveira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">T</forename><surname>Murta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Werner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Mattoso</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Provenance and Annotation Workshop</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="136" to="143" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A provenance-based adaptive scheduling heuristic for parallel scientific workflows in clouds</title>
		<author>
			<persName><forename type="first">De</forename><surname>Oliveira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Ocaña</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kacs</forename><surname>Baião</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">A</forename><surname>Mattoso</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename></persName>
		</author>
		<idno type="DOI">10.1007/s10723-012-9227-2</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Grid Computing</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="521" to="552" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title />
		<author>
			<persName><forename type="first">Silva</forename><surname>Junior</surname></persName>
		</author>
		<idno type="DOI">10.7717/peerj-cs.606</idno>
	</analytic>
	<monogr>
		<title level="j">PeerJ Comput. Sci</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Performance evaluation of parallel strategies in public clouds: a study with phylogenomic workflows</title>
		<author>
			<persName><forename type="first">De</forename><surname>Oliveira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Ocaña</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kacs</forename><surname>Ogasawara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Dias</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gonçalves</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Baião</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Mattoso</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename></persName>
		</author>
		<idno type="DOI">10.1016/j.future.2012.12.019</idno>
	</analytic>
	<monogr>
		<title level="j">Future Generation Computer Systems</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1816" to="1825" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Scicumulus: a lightweight cloud middleware to explore many task computing paradigm in scientific workflows</title>
		<author>
			<persName><forename type="first">De</forename><surname>Oliveira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Ogasawara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Baião</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Mattoso</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2010 IEEE 3rd International Conference on Cloud Computing</title>
		<meeting><address><addrLine>Piscataway</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="378" to="385" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Pegasus: a framework for mapping complex scientific workflows onto distributed systems</title>
		<author>
			<persName><forename type="first">E</forename><surname>Deelman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M-H</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Blythe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Gil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Kesselman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Mehta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Vahi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Berriman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Good</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Laity</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Katz</surname></persName>
		</author>
		<idno type="DOI">10.1155/2005/128026</idno>
	</analytic>
	<monogr>
		<title level="j">Scientific Programming</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="219" to="237" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Towards an empirical foundation for assessing bayesian optimization of hyperparameters</title>
		<author>
			<persName><forename type="first">K</forename><surname>Eggensperger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Feurer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Hutter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bergstra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Snoek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Hoos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Leyton-Brown</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NIPS Workshop on Bayesian Optimization in Theory and Practice</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">The original Borda count and partial voting</title>
		<author>
			<persName><forename type="first">P</forename><surname>Emerson</surname></persName>
		</author>
		<idno type="DOI">10.1007/s00355-011-0603-9</idno>
	</analytic>
	<monogr>
		<title level="j">Social Choice and Welfare</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="353" to="358" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Provenance for computational tasks: a survey</title>
		<author>
			<persName><forename type="first">J</forename><surname>Freire</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Koop</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Santos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">T</forename><surname>Silva</surname></persName>
		</author>
		<idno type="DOI">10.1109/MCSE.2008.79</idno>
	</analytic>
	<monogr>
		<title level="j">Computing in Science &amp; Engineering</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="11" to="21" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Pairwise preference learning and ranking</title>
		<author>
			<persName><forename type="first">J</forename><surname>Fürnkranz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Hüllermeier</surname></persName>
		</author>
		<idno type="DOI">10.1109/MCSE.2008.79</idno>
	</analytic>
	<monogr>
		<title level="m">European Conference on Machine Learning</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="145" to="156" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Preference learning</title>
		<author>
			<persName><forename type="first">J</forename><surname>Fürnkranz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Hüllermeier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Encyclopedia of Machine Learning</title>
		<editor>
			<persName><forename type="first">C</forename><surname>Sammut</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><forename type="middle">I</forename><surname>Webb</surname></persName>
		</editor>
		<meeting><address><addrLine>Boston</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="789" to="795" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">H</forename><surname>Garthwaite</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">T</forename><surname>Jolliffe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Jolliffe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Jones</surname></persName>
		</author>
		<title level="m">Statistical inference</title>
		<meeting><address><addrLine>Oxford</addrLine></address></meeting>
		<imprint>
			<publisher>Oxford University Press on Demand</publisher>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<author>
			<persName><forename type="first">Y</forename><surname>Gil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Miles</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Belhajjame</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Deus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Garijo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Klyne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Missier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Soiland-Reyes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zednik</surname></persName>
		</author>
		<ptr target="https://global.oup.com/academic/product/statistical-inference-9780198572268?cc=br&amp;lang=en&amp;" />
		<title level="m">Prov model primer: W3C working group note</title>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="volume">30</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">ANOVA: repeated measures-number 84</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">R</forename><surname>Girden</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1992">1992</date>
			<publisher>Sage</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Position statement: musings on provenance, workflow and (semantic web) annotations for bioinformatics</title>
		<author>
			<persName><forename type="first">C</forename><surname>Goble</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Workshop on Data Derivation and Provenance</title>
		<meeting><address><addrLine>Chicago</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="volume">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Metaheuristics: review and application</title>
		<author>
			<persName><forename type="first">A</forename><surname>Gogna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Tayal</surname></persName>
		</author>
		<idno type="DOI">10.1080/0952813X.2013.782347</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental &amp; Theoretical Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="503" to="526" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Managing scientific hypotheses as data with support for predictive analytics</title>
		<author>
			<persName><forename type="first">B</forename><surname>Gonçalves</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Porto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computing in Science &amp; Engineering</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="35" to="43" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Ontology of folksonomy: a mash-up of apples and oranges</title>
		<author>
			<persName><forename type="first">T</forename><surname>Gruber</surname></persName>
		</author>
		<idno type="DOI">10.4018/jswis.2007010101</idno>
	</analytic>
	<monogr>
		<title level="j">International Journal on Semantic Web and Information Systems</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="11" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Provenance-based fault tolerance technique recommendation for cloud-based scientific workflows: a practical approach</title>
		<author>
			<persName><forename type="first">T</forename><surname>Guedes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">A</forename><surname>Jesus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kacs</forename><surname>Ocaña</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lma</forename><surname>Drummond</surname></persName>
		</author>
		<author>
			<persName><forename type="first">De</forename><surname>Oliveira D ; A</surname></persName>
		</author>
		<idno type="DOI">10.1007/s10586-019-02920-6</idno>
	</analytic>
	<monogr>
		<title level="j">Cluster Computing</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="123" to="148" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Capturing and analyzing provenance from spark-based scientific workflows with SAMbA-RaP</title>
		<author>
			<persName><forename type="first">T</forename><surname>Guedes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">B</forename><surname>Martins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mlf</forename><surname>Falci</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Silva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kacs</forename><surname>Ocaña</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mattoso</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bedo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">De</forename><surname>Oliveira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename></persName>
		</author>
		<idno type="DOI">10.1016/j.future.2020.05.031</idno>
	</analytic>
	<monogr>
		<title level="j">Future Generation Computer Systems</title>
		<imprint>
			<biblScope unit="volume">112</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="658" to="669" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">A provenance-based heuristic for preserving results confidentiality in cloud-based Silva Junior et al</title>
		<author>
			<persName><forename type="first">M</forename><surname>Guerine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">B</forename><surname>Stockinger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Rosseti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">G</forename><surname>Simonetti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kacs</forename><surname>Ocaña</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Plastino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">De</forename><surname>Oliveira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename></persName>
		</author>
		<idno type="DOI">10.1016/j.future.2019.01.051</idno>
		<idno>10.1016/j.future.2019.01.051</idno>
	</analytic>
	<monogr>
		<title level="j">Future Generation Computer Systems</title>
		<imprint>
			<biblScope unit="volume">97</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="697" to="713" />
			<date type="published" when="2019">2019. 2021</date>
		</imprint>
	</monogr>
	<note>PeerJ Comput. Sci.</note>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Towards an ontology-based recommender system for relevant bioinformatics workflows</title>
		<author>
			<persName><forename type="first">A</forename><surname>Halioui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Valtchev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">B</forename><surname>Diallo</surname></persName>
		</author>
		<idno type="DOI">10.1101/082776</idno>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Evaluating collaborative filtering recommender systems</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Herlocker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Konstan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">G</forename><surname>Terveen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">T</forename><surname>Riedl</surname></persName>
		</author>
		<idno type="DOI">10.1145/963770.963772</idno>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Information Systems</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="5" to="53" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">The future of data-intensive science</title>
		<author>
			<persName><forename type="first">T</forename><surname>Hey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Gannon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Pinkelman</surname></persName>
		</author>
		<idno type="DOI">10.1109/MC.2012.181</idno>
	</analytic>
	<monogr>
		<title level="j">Computer</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="81" to="82" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">The fourth paradigm 10 years on</title>
		<author>
			<persName><forename type="first">T</forename><surname>Hey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">E</forename><surname>Trefethen</surname></persName>
		</author>
		<idno type="DOI">10.1007/s00287-019-01215-9</idno>
	</analytic>
	<monogr>
		<title level="j">Informatik Spektrum</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="441" to="447" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">On the use of cloud computing for scientific workflows</title>
		<author>
			<persName><forename type="first">C</forename><surname>Hoffa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Mehta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Freeman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Deelman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Keahey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Berriman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Good</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2008 IEEE Fourth International Conference on eScience</title>
		<meeting><address><addrLine>Piscataway</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="640" to="645" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Provstore: a public provenance repository</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">D</forename><surname>Huynh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Moreau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Provenance and Annotation of Data and Processes</title>
		<editor>
			<persName><forename type="first">B</forename><surname>Ludäscher</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">B</forename><surname>Plale</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="275" to="277" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Label ranking by learning pairwise preferences</title>
		<author>
			<persName><forename type="first">E</forename><surname>Hüllermeier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Fürnkranz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Brinker</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.artint.2008.08.002</idno>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">172</biblScope>
			<biblScope unit="issue">16-17</biblScope>
			<biblScope unit="page" from="1897" to="1916" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Montage: a grid portal and software toolkit for science-grade astronomical image mosaicking</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Jacob</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Katz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">B</forename><surname>Berriman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Good</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Laity</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Deelman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Kesselman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M-H</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Prince</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Williams</surname></persName>
		</author>
		<idno type="DOI">10.1504/IJCSE.2009.026999</idno>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computational Science and Engineering</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="73" to="87" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Context aware recommendation for data visualization</title>
		<author>
			<persName><forename type="first">W</forename><surname>Kanchana</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Madushanka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Maduranga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Udayanga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Meedeniya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Perera</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2nd International Conference on Communication and Information Processing</title>
		<meeting>the 2nd International Conference on Communication and Information Processing</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="22" to="26" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Semiautomated recommendation platform for data visualization: Roopana</title>
		<author>
			<persName><forename type="first">W</forename><surname>Kanchana</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Madushanka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Maduranga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Udayanga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Meedeniya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Perera</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Moratuwa Engineering Research Conference (MERCon)</title>
		<meeting><address><addrLine>Piscataway</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2017">2017. 2017</date>
			<biblScope unit="page" from="117" to="122" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Preferential voting: incidence and effects</title>
		<author>
			<persName><forename type="first">L</forename><surname>Karvonen</surname></persName>
		</author>
		<idno type="DOI">10.1177/0192512104041283</idno>
	</analytic>
	<monogr>
		<title level="j">International Political Science Review</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="203" to="226" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">A fuzzy k-nearest neighbor algorithm</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Keller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Gray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Givens</surname></persName>
		</author>
		<idno type="DOI">10.1109/TSMC.1985.6313426</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Systems, Man, and Cybernetics</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="580" to="585" />
			<date type="published" when="1985">1985</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">A study of cross-validation and bootstrap for accuracy estimation and model selection</title>
		<author>
			<persName><forename type="first">R</forename><surname>Kohavi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14th international joint conference on Artificial intelligence</title>
		<meeting>the 14th international joint conference on Artificial intelligence<address><addrLine>Burlington</addrLine></address></meeting>
		<imprint>
			<publisher>Morgan Kaufmann Publishers Inc</publisher>
			<date type="published" when="1995">1995</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1137" to="1143" />
		</imprint>
	</monogr>
	<note>IJCAI'95)</note>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Performance comparison of rank aggregation using borda and copeland in recommender system</title>
		<author>
			<persName><forename type="first">S</forename><surname>Lestari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">B</forename><surname>Adji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">E</forename><surname>Permanasari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2018 International Workshop on Big Data and Information Security (IWBIS)</title>
		<meeting><address><addrLine>Piscataway</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="69" to="74" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Facing the cold start problem in recommender systems</title>
		<author>
			<persName><forename type="first">B</forename><surname>Lika</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Kolomvatsos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Hadjiefthymiades</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.eswa.2013.09.005</idno>
	</analytic>
	<monogr>
		<title level="j">Expert Systems with Applications</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="2065" to="2073" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Experiential learning in bioinformatics-learner support for complex workflow modelling and analysis</title>
		<author>
			<persName><forename type="first">V</forename><surname>Mallawaarachchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Wickaramarachchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Weliwita</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Perera</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Meedeniya</surname></persName>
		</author>
		<idno type="DOI">10.3991/ijet.v13i12.8608</idno>
	</analytic>
	<monogr>
		<title level="j">International Journal of Emerging Technologies in Learning</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page">19</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Scalable script-based data analysis workflows on clouds</title>
		<author>
			<persName><forename type="first">F</forename><surname>Marozzo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Talia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Trunfio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">WORKS</title>
		<imprint>
			<biblScope unit="page" from="124" to="133" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Towards supporting the life cycle of large-scale scientific experiments</title>
		<author>
			<persName><forename type="first">M</forename><surname>Mattoso</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Werner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">H</forename><surname>Travassos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Braganholo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Murta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Ogasawara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">De</forename><surname>Oliveira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Da</forename><surname>Cruz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sms</forename><surname>Martinho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename></persName>
		</author>
		<idno type="DOI">10.1504/IJBPIM.2010.033176</idno>
	</analytic>
	<monogr>
		<title level="j">International Journal of Business Process Integration and Management</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="79" to="92" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Pandas: a foundational python library for data analysis and statistics</title>
		<author>
			<persName><forename type="first">W</forename><surname>Mckinney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Python for High Performance and Scientific Computing</title>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title level="m" type="main">Machine learning</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">M</forename><surname>Mitchell</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015">2015</date>
			<publisher>McGraw-Hill Science/Engineering/Math</publisher>
			<pubPlace>Pennsylvania</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">A folksonomy-based social recommendation system for scientific workflow reuse</title>
		<author>
			<persName><forename type="first">A</forename><surname>Mohan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ebrahimi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2015 IEEE International Conference on Services Computing</title>
		<meeting><address><addrLine>Piscataway</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="704" to="711" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<monogr>
		<title level="m" type="main">Classical and modern regression with applications</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">H</forename><surname>Myers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">H</forename><surname>Myers</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1990">1990</date>
			<publisher>Duxbury Press</publisher>
			<biblScope unit="volume">2</biblScope>
			<pubPlace>Belmont, CA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Object-level ranking: bringing order to web objects</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J-R</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W-Y</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14th International Conference on World Wide Web</title>
		<meeting>the 14th International Conference on World Wide Web</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="567" to="574" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Sciphy: a cloud-based workflow for phylogenetic analysis of drug targets in protozoan genomes</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">A</forename><surname>Ocaña</surname></persName>
		</author>
		<author>
			<persName><forename type="first">De</forename><surname>Oliveira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Ogasawara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Dávila</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Lima</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Mattoso</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Brazilian Symposium on Bioinformatics</title>
		<meeting><address><addrLine>Berlin</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="66" to="70" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Bioinfoportal: a scientific gateway for integrating bioinformatics applications on the brazilian national high-performance computing network</title>
		<author>
			<persName><forename type="first">Kacs</forename><surname>Ocaña</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Galheigo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Osthoff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lmr</forename><surname>Gadelha</surname></persName>
		</author>
		<author>
			<persName><surname>Jr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Porto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ata</forename><surname>Gomes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">De</forename><surname>Oliveira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Vasconcelos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">T</forename></persName>
		</author>
		<idno type="DOI">10.1016/j.future.2020.01.030</idno>
	</analytic>
	<monogr>
		<title level="j">Future Generation Computer Systems</title>
		<imprint>
			<biblScope unit="volume">107</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="192" to="214" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">An algebraic approach for data-centric scientific workflows</title>
		<author>
			<persName><forename type="first">E</forename><surname>Ogasawara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">De</forename><surname>Oliveira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Valduriez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Dias</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Porto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Mattoso</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename></persName>
		</author>
		<idno type="DOI">10.14778/3402755.3402766</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the VLDB Endowment</title>
		<meeting>the VLDB Endowment</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="1328" to="1339" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Scikit-learn: machine learning in python</title>
		<author>
			<persName><forename type="first">F</forename><surname>Pedregosa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Varoquaux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gramfort</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Michel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Thirion</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Grisel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Blondel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Prettenhofer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Dubourg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2825" to="2830" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Recommendations using modified k-means clustering and voting theory</title>
		<author>
			<persName><forename type="first">P</forename><surname>Rani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Shokeen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Mullick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Science and Mobile Computing</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="143" to="148" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Classifier chains for multi-label classification</title>
		<author>
			<persName><forename type="first">J</forename><surname>Read</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Pfahringer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Holmes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Frank</surname></persName>
		</author>
		<idno type="DOI">10.1007/s10994-011-5256-5</idno>
	</analytic>
	<monogr>
		<title level="j">Machine Learning</title>
		<imprint>
			<biblScope unit="volume">85</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="333" to="359" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Recommender systems</title>
		<author>
			<persName><forename type="first">P</forename><surname>Resnick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">R</forename><surname>Varian</surname></persName>
		</author>
		<idno type="DOI">10.1145/245108.245121</idno>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="56" to="59" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Introduction to recommender systems handbook</title>
		<author>
			<persName><forename type="first">F</forename><surname>Ricci</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Rokach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Shapira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Recommender Systems Handbook</title>
		<editor>
			<persName><forename type="first">F</forename><surname>Ricci</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Rokach</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">B</forename><surname>Shapira</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><surname>Kantor</surname></persName>
		</editor>
		<meeting><address><addrLine>Boston</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="1" to="35" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Methods and metrics for cold-start recommendations</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">I</forename><surname>Schein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Popescul</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">H</forename><surname>Ungar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Pennock</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 25th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval<address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="253" to="260" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Freep: towards parameter recommendation in scientific workflows using preference learning</title>
		<author>
			<persName><forename type="first">Silva</forename><surname>Junior</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Paes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Pacitti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename></persName>
		</author>
		<author>
			<persName><forename type="first">De</forename><surname>Oliveira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">XXXIII Brazilian Symposium on Databases</title>
		<meeting><address><addrLine>Brazil</addrLine></address></meeting>
		<imprint>
			<publisher>Rio de Janeiro</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="211" to="216" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Adding domain data to code profiling tools to debug workflow parallel execution</title>
		<author>
			<persName><forename type="first">V</forename><surname>Silva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Neves</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Souza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alga</forename><surname>Coutinho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">De</forename><surname>Oliveira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Mattoso</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename></persName>
		</author>
		<idno type="DOI">10.1016/j.future.2018.05.078</idno>
	</analytic>
	<monogr>
		<title level="j">Future Generation Computer Systems</title>
		<imprint>
			<biblScope unit="volume">110</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="422" to="439" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Incorporating semantics in pattern-based scientific workflow recommender systems: improving the accuracy of recommendations</title>
		<author>
			<persName><forename type="first">K</forename><surname>Soomro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Munir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Mcclatchey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2015 Science and Information Conference (SAI)</title>
		<meeting><address><addrLine>Piscataway</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="565" to="571" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Bordarank: a ranking aggregation based approach to collaborative filtering</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Tong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE/ACIS 15th International Conference on Computer and Information Science (ICIS)</title>
		<meeting><address><addrLine>Piscataway</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2016">2016. 2016</date>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">D</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Pacelli</surname></persName>
		</author>
		<title level="m">Mathematics and politics: strategy, voting, power, and proof</title>
		<meeting><address><addrLine>Berlin</addrLine></address></meeting>
		<imprint>
			<publisher>Springer Science &amp; Business Media</publisher>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Multi-label classification: an overview</title>
		<author>
			<persName><forename type="first">G</forename><surname>Tsoumakas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Katakis</surname></persName>
		</author>
		<idno type="DOI">10.4018/jdwm.2007070101</idno>
	</analytic>
	<monogr>
		<title level="j">International Journal of Data Warehousing and Mining</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1" to="13" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">The numpy array: a structure for efficient numerical computation</title>
		<author>
			<persName><forename type="first">Walt</forename><forename type="middle">S</forename><surname>Van Der</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">C</forename><surname>Colbert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Varoquaux</surname></persName>
		</author>
		<idno type="DOI">10.1109/MCSE.2011.37</idno>
	</analytic>
	<monogr>
		<title level="j">Computing in Science &amp; Engineering</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="22" to="30" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<monogr>
		<title level="m" type="main">Label ranking algorithms: a survey</title>
		<author>
			<persName><forename type="first">S</forename><surname>Vembu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Gärtner</surname></persName>
		</author>
		<idno type="DOI">10.1109/MCSE.2011.37</idno>
		<imprint>
			<date type="published" when="2011">2011</date>
			<publisher>Springer</publisher>
			<biblScope unit="page" from="45" to="64" />
			<pubPlace>Berlin Heidelberg, Berlin, Heidelberg</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Regret-based optimal recommendation sets in conversational recommender systems</title>
		<author>
			<persName><forename type="first">P</forename><surname>Viappiani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Boutilier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the third ACM Conference on Recommender Systems</title>
		<meeting>the third ACM Conference on Recommender Systems</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="101" to="108" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<monogr>
		<title level="m" type="main">Support vector machines: theory and applications</title>
		<author>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005">2005</date>
			<publisher>Springer Science &amp; Business Media</publisher>
			<biblScope unit="volume">177</biblScope>
			<pubPlace>Berlin</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">Managing complex workflows in bioinformatics: an interactive toolkit with gpu acceleration</title>
		<author>
			<persName><forename type="first">A</forename><surname>Welivita</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Perera</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Meedeniya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Wickramarachchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Mallawaarachchi</surname></persName>
		</author>
		<idno type="DOI">10.1109/TNB.2018.2837122</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Nanobioscience</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="199" to="208" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">Enhanced student learning in proteomics-an interactive tool support for teaching workflows</title>
		<author>
			<persName><forename type="first">A</forename><surname>Wickramarachchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Mallawaarachchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Meedeniya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Perera</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Welivita</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2018 IEEE International Conference on Teaching, Assessment, and Learning for Engineering (TALE)</title>
		<meeting><address><addrLine>Piscataway</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="228" to="235" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">On hyperparameter optimization of machine learning algorithms: theory and practice</title>
		<author>
			<persName><forename type="first">L</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Shami</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.neucom.2020.07.061</idno>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">415</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="295" to="316" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main">A method to mine workflows from provenance for assisting scientific workflow composition</title>
		<author>
			<persName><forename type="first">R</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">M</forename><surname>Van Der Aalst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE World Congress on Services</title>
		<meeting><address><addrLine>Piscataway</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2011">2011. 2011</date>
			<biblScope unit="page" from="169" to="175" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">A new optimal sampling rule for multi-fidelity optimization via ordinal transformation</title>
		<author>
			<persName><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C-H</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2016 IEEE International Conference on Automation Science and Engineering (CASE)</title>
		<meeting><address><addrLine>Piscataway</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="670" to="674" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<analytic>
		<title level="a" type="main">Scientific workflow systems for 21st century, new bottle or new wine?</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ioan</forename><surname>Raicu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">F</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">EEE Congress on Services</title>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<analytic>
		<title level="a" type="main">Scientific workflow clustering and recommendation leveraging layer hierarchical analysis</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L-J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Gaaloul</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Ning</surname></persName>
		</author>
		<idno type="DOI">10.1109/TSC.2016.2542805</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Services Computing</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="169" to="183" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<monogr>
		<title level="m" type="main">Modeling, simulation, and control of flexible manufacturing systems: a Petri net approach</title>
		<author>
			<persName><forename type="first">M</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Venkatesh</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999">1999</date>
			<publisher>World Scientific</publisher>
			<biblScope unit="volume">6</biblScope>
			<pubPlace>Singapore</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>