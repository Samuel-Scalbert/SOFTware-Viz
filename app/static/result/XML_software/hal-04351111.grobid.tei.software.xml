<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="fr">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">constrained agents reach higher accuracy when tasks overlap</title>
				<funder ref="#_cj97G3c">
					<orgName type="full">Agence Nationale de la Recherche</orgName>
					<orgName type="abbreviated">ANR</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Andreas</forename><surname>Kalaitzakis</surname></persName>
							<email>andreas.kalaitzakis@inria.fr</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Univ. Grenoble Alpes</orgName>
								<orgName type="institution" key="instit2">Inria</orgName>
								<orgName type="institution" key="instit3">CNRS</orgName>
								<orgName type="institution" key="instit4">Grenoble INP</orgName>
								<orgName type="institution" key="instit5">LIG</orgName>
								<address>
									<postCode>F-38000</postCode>
									<settlement>Grenoble</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Univ. Grenoble Alpes</orgName>
								<orgName type="institution" key="instit2">Inria</orgName>
								<orgName type="institution" key="instit3">CNRS</orgName>
								<orgName type="institution" key="instit4">Grenoble INP</orgName>
								<orgName type="institution" key="instit5">LIG</orgName>
								<address>
									<postCode>F-38000</postCode>
									<settlement>Grenoble</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jérôme</forename><surname>Euzenat</surname></persName>
							<email>jerome.euzenat@inria.fr</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Univ. Grenoble Alpes</orgName>
								<orgName type="institution" key="instit2">Inria</orgName>
								<orgName type="institution" key="instit3">CNRS</orgName>
								<orgName type="institution" key="instit4">Grenoble INP</orgName>
								<orgName type="institution" key="instit5">LIG</orgName>
								<address>
									<postCode>F-38000</postCode>
									<settlement>Grenoble</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Univ. Grenoble Alpes</orgName>
								<orgName type="institution" key="instit2">Inria</orgName>
								<orgName type="institution" key="instit3">CNRS</orgName>
								<orgName type="institution" key="instit4">Grenoble INP</orgName>
								<orgName type="institution" key="instit5">LIG</orgName>
								<address>
									<postCode>F-38000</postCode>
									<settlement>Grenoble</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">constrained agents reach higher accuracy when tasks overlap</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">F0AFE427928699EF976970E67783325B</idno>
					<idno type="DOI">10.1007/978-3-031-43264-4_28</idno>
					<note type="submission">Submitted on 18 Dec 2023</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-04-12T14:53+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Cultural knowledge evolution</term>
					<term>Knowledge transfer</term>
					<term>Multi-tasking</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>de niveau recherche, publiés ou non, émanant des établissements d'enseignement et de recherche français ou étrangers, des laboratoires publics ou privés.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="fr">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Agents have been previously shown to improve their accuracy as a result of cultural knowledge evolution. The latter studies agents that evolve their knowledge representations, based on their perception and the feedback they receive from other agents. Recent work on cultural knowledge evolution focuses on agents tackling a single task: taking an abstract decision within an abstract domain. In <ref type="bibr" target="#b2">[3]</ref>, agents are forced to take identical decisions regarding a set of environment objects. Eventually, agents learn to agree over a single decision task, yet not necessarily on the same basis. For example, two agents may both decide to visit Barcelona. Agent α may base its decision on the temperature property, while agent β may base its decision on the ticket price property.</p><p>However, several tasks may exist. We build on previous works by introducing agents capable of taking abstract decisions within several domains. To do so, agents classify objects into ontology classes and associate these classes with different decisions for different tasks. We consider that realistic agents should not be able to develop ontologies containing all class descriptions. Thus, we limit the number of classes to be maintained within an agent's ontology. When this limit is reached, agents will try to forget knowledge that is not relevant to the tasks they favor. Deciding for different tasks may rely on a set of common properties. For example, the property temperature may be used in order to choose a destination (task 1). The same property may also be used to decide whether to wear a T-shirt (task 2). However, the property temperature may be completely irrelevant to choosing a movie (task 3). We assume that when this set is not empty, agents carrying several tasks may develop multi-purpose knowledge, i.e., knowledge that can be transferred among different tasks. Based on this, we formulate the following hypothesis: multi-tasking agents tackling tasks that rely on the same properties, are more accurate than multi-tasking agents tackling tasks that rely on different properties. We test this hypothesis by varying two parameters. The first parameter is the number of tasks assigned to each agent. The second parameter the number of common properties shared among the different tasks. Two variations of the second parameter are examined. Tasks either rely on the same properties, or rely on different ones. We then evaluate agent ontologies based on their contribution to promote successful interactions and provide accurate decisions. Based on this evaluation, the following is shown: when agents tackle tasks based on common properties, knowledge built by an agent while tackling one task, improves its accuracy on another task. We thus conclude that it is possible to transfer knowledge from one task to another.</p><p>After discussing related work in §2, preliminaries regarding the entities that constitute the environment as well as the notation that describes it, are introduced in §3. In §4, an outline of the experiment is provided, including how agents learn their initial ontologies, interact with each other and adapt when they disagree. Section 5 presents our hypothesis and the protocol used to test it. Results are presented in §6 and conclusions are provided in §7.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related work</head><p>It has been shown that referential games <ref type="bibr" target="#b8">[9]</ref> facilitate the establishment of communication protocols between communicating agents. <ref type="bibr" target="#b10">[11]</ref> argues that a communication protocol emerges when agents attempt to minimize the computational complexity of semantic interpretation. <ref type="bibr" target="#b6">[7]</ref> studies a framework where two agents develop a language in order to succeed in a referential game. <ref type="bibr" target="#b5">[6]</ref> shows that implicit cultural transmission leads to greater language compositionality. While our work relies on successfully communicating agents, our focus is on how this successful communication allows for better task completion. Different examples of multi-tasking agents exist in literature. Indicatively, multitask learning has been shown to significantly improve classification in a variety of areas, e.g., adversary robustness <ref type="bibr" target="#b9">[10]</ref>, visual interconceptual similarity <ref type="bibr" target="#b3">[4]</ref> and phenotype learning <ref type="bibr" target="#b4">[5]</ref>. Agents have also been used to study the impact of multi-task learning on emerging communication protocols. In <ref type="bibr" target="#b11">[12]</ref>, cooperative multi-agent reinforcement learning is considered. Our work is related to these works, since they consider agents that perform several tasks. However our focus is not on agents that improve their accuracy individually. Here we study agents that improve their accuracy through social transmission.</p><p>Social transmission among agents has been studied in <ref type="bibr" target="#b2">[3]</ref> and <ref type="bibr" target="#b12">[13]</ref>. In <ref type="bibr" target="#b12">[13]</ref>, the authors examine how concepts are organized and how their collective behavior can be established autonomously. In <ref type="bibr" target="#b2">[3]</ref>, a two-stage experiment is used, where agents first learn a classifier and then interact in pairs. Through an adaptation mechanism, it is shown that the agents achieve better knowledge, without adopting identical ontologies. We differentiate from these, by introducing memory-limited agents that tackle several tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experimental framework 3.1 Environment</head><p>Agents evolve in an environment populated by objects described by a set P of boolean properties. Objects are therefore described by the presence or absence of a property p ∈ P, denoted by p and ¬p respectively. Hence, there are 2 |P| object types, that are gathered in a set I.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Tasks</head><p>The term task refers to a piece of work, carried out by an agent. Here, we will concentrate on a set of decision tasks: making a decision about an object. There may be different tasks t ∈ T associated to a different set of possible decisions D t . Each object o can be considered with respect to any task t ∈ T . A function h * (o, t) → D t provides the correct, unknown to agents, decision for an object o with respect to a task t. For example, h * (tomato, coloring) will provide the decision red.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Agents</head><p>Agents are autonomous, co-existing entities, able to perceive and distinguish objects based on their properties. In this context, a population of multi-tasking agents A is assigned different subsets of T . To tackle these tasks, agents build and evolve private ontologies, expressed in ALC <ref type="bibr" target="#b1">[2]</ref>. Each agent α uses its ontology to compute a function h α (o, t) → D t which, given an object o and a task t, provides a decision h α (o, t). The right part of Figure <ref type="figure" target="#fig_0">1</ref> shows an example of a multi-task ontology constructed by an agent α. The bottom part represents the private ontology O α of agent α, allowing it to classify objects of the environment. The top part shows a set of decision ontologies, each one containing the valid decisions for a respective task t. An agent α learns at most one decision for an object o and a task t. Thus, each leaf of O α cannot be aligned more than once with the same decision ontology.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiment outline</head><p>In this paper, we examine if knowledge can be transferred from one task to another. To this end, a two-stage experiment is used. In the first stage, agents induce private ontologies based on randomly selected labeled examples. In the second stage, agents go through a fixed number of interactions. For each interaction, two randomly selected agents will have to decide with respect to an object o and a task t. When agents disagree, one of the two agents adapts its ontology. More details about how agents learn, are assigned tasks, interact, release resources and adapt their ontologies are presented in subsections 4.1, 4.2, 4.3, 4.4 and 4.5 respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Initial ontology induction</head><p>We approach multi-task learning as a problem of inducing an ontology capable of providing a decision for any task t ∈ T . Different algorithms may be used, affecting the final accuracy of agents. This paper does not examine how different learning algorithms impact the achieved accuracy. This paper examines how cultural evolution improves the accuracy of multi-tasking agents. Thus, details about the learning algorithm are omitted. A learning example can be seen in figure <ref type="figure" target="#fig_0">1</ref>. By the end of its initial ontology induction phase, the agent α is able to classify an object described by p 1 ⊓ p 2 but unable to decide about the task t 1 .</p><p>Object p1 p2 p3 p4 Task Decision  </p><formula xml:id="formula_0">o1 1 1 0 0 t1 d1 o2 1 0 0 1 t2 d1 o3 0 1 0 1 t1 d2 o4 0 0 1 0 t2 d2 o5 1 1 0 1 t1 d1 o6 1 1 0 0 t2 d1 o7 0 1 1 0 t1 d2 o8 1 0 1 1 t2 d2 =⇒ p1 d 2 t1 d 2 t2 o7 o4 o3</formula><formula xml:id="formula_1">d 3 ⊑ ⊑ ⊑ ⊕ ⊕ ⊕ D t2 d 1 d 2 d 3 ⊑ ⊑ ⊑ ⊕ ⊕ ⊕ O α ¬p 1 p 2 p 1 ⊓ ¬p 2 p 1 ⊓ p 2 ⊑ ⊑ ⊑ ⊑ ⊑ ⊑ ⊑ ⊑</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Task assignment</head><p>Agents are assigned with different subsets of T of the same size. The latter varies from 1 to |T | and remains constant for the duration of an experiment. Based on it, all possible task permutations of the same size are initially produced. Each permutation corresponding to a different subset of T , is then assigned to an even number of agents. Thus, the number of agents is always a multiple of the number of the different subsets of T .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Interaction</head><p>For each interaction, two randomly selected agents α and β are asked to provide a decision for an object o with respect to a task t. The agents provide their decisions based on the respective functions h α (o, t) and h β (o, t). If an agent is unable to provide a decision, then one decision is randomly selected. The agents will then disclose their decisions to each other. If h α (o, t) = h β (o, t), the agents agree and their interaction is considered as successful. On the contrary, their interaction ends as a failure. In this case, one of the two agents may adapt its ontology. In order to decide which agent will adapt, an evaluation set is randomly selected. It contains samples labeled with respect to the task t. The agents are evaluated against this set and a score is assigned to each one of them. The agent with the lowest score may adapt its ontology.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Resources release</head><p>When an agent's resources are exhausted, it tries to forget knowledge as follows (Figure <ref type="figure">2</ref>). Leaf nodes that satisfy the following criteria are removed: (a) they have the same immediate parent node (b) they are associated with the same decision regarding all tasks assigned to the agent. The process is repeated recursively, as long as leaf nodes satisfying (a) and (b) exist.</p><formula xml:id="formula_2">Dt 1 d1 d2 d3 ⊑ ⊑ ⊑ ⊕ ⊕ ⊕ Dt 2 d1 d2 d3 ⊑ ⊑ ⊑ ⊕ ⊕ ⊕ O α ¬p4 p1 p4 ⊓ ¬p1 p4 ⊓ p1 ⊑ ⊑ ⊑ ⊑ ⊑ ⊑ ⊑ ⊑ ⊑ =⇒ Dt 1 d1 d2 d3 ⊑ ⊑ ⊑ ⊕ ⊕ ⊕ Dt 2 d1 d2 d3 ⊑ ⊑ ⊑ ⊕ ⊕ ⊕ O α ¬p4 p4 ⊑ ⊑ ⊑ ⊑ ⊑ Fig. (2)</formula><p>Let an agent α assigned the task t2, with t2 relying on the property set Pt 2 . The property p1 / ∈ Pt 2 , thus p1 does not allow for distinguishing different decisions for the task t2. In this example, the agent has associated the same decision (in red), to both p4 ⊓ ¬p1 and p4 ⊓ p1. These two classes can be removed without any loss of accuracy with respect to t2. For the task t2, the parent node will now be associated with the decision d2 (red). For the task t1, the parent node will now be associated with one of two decisions previously associated with its former descendent nodes. Here, the decision d3 (gray) was randomly selected.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Adaptation</head><p>Our adaptation mechanism extends the one presented in <ref type="bibr" target="#b2">[3]</ref>. Based on it, an agent can either replace an existing decision or split a class into two sub-classes (Figure <ref type="figure" target="#fig_2">3</ref>). The agent does this on the basis of a property that distinguishes the current object from the objects classified by the class to be split. Only the decisions concerning the current task are affected. The first (claws ⊓ ¬poison) will be associated with the decision of the agent β. The second (claws⊓poison) will be associated with all decisions previously associated with the class claws.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Parameters</head><p>The experiment is executed under 6 setups. Each setup is run 20 times and its results are averaged. One run consists of 80000 interactions with each interaction taking place among two randomly selected agents. The total population of agents is 18. Their environment contains 64 different object types, each one perceivable through 6 different binary properties. The agents are initially trained with respect to 3 tasks. Taking 1 out of 4 decisions with respect to each task relies on 2 properties. These properties are either the same for all tasks, or different for each task. Agents induce an initial ontology based on a random 10 % of all existing labeled examples. The agents are assigned 1 to 3 tasks. Agent evaluation is based on 60% of all samples.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Measures</head><p>Success rate, as introduced in <ref type="bibr" target="#b2">[3]</ref> is defined as the proportion of successful interactions, over all performed interactions until the n th interaction. Task accuracy adapts the accuracy measure introduced in [3] to different tasks. It is defined as the proportion of object types for which a correct decision would be taken with respect to a task t, by an agent α on the n th iteration of the experiment.</p><formula xml:id="formula_3">tacc(α, n, t) = |{o ∈ I : h α n (o, t) = h * (o, t)}| |I|</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Results and discussion</head><p>We hypothesize that when tasks rely on common properties, it is possible for agents to build multi-purpose knowledge. To test this hypothesis, the accuracy of the following two populations was compared. The first consists of agents assigned up to 3 tasks for which all properties are shared. The second consists of agents assigned up to 3 tasks for which no properties are shared. improves their average accuracy. This improvement is higher when agents tackle tasks that rely on the same properties. On the one hand, when tasks rely on different properties, agents tackling 3 tasks are 9% more accurate than agents tackling 1 task. On the other hand, when tasks rely on common properties, agents tackling 3 tasks are 55% more accurate than agents tackling 1 task. This shows that agents tackling tasks relying on a common set of properties, may improve their accuracy on one task by carrying out another task. Results thus support our hypothesis.</p><p>Figure <ref type="figure">4b</ref> shows two things. First, agents tackling tasks that rely on the same properties achieve a higher accuracy on their best task, compared to agents tackling tasks that rely on different properties. This indicates that while the agents may abstain from some tasks, their ontologies contain multi-purpose knowledge, acquired during the initial ontoloy induction phase. This further supports our hypothesis. Second, when tasks rely on different properties, the effect of the number of tasks assigned to each agent on the accuracy for its best task, is statistically insignificant (p &gt; 0.05). This indicates that when tasks rely on different properties, learning to decide with respect to one task is not related to learning to decide with respect to a different task.</p><p>Figure <ref type="figure">4c</ref> shows that tackling less tasks or having tasks that rely on common properties improves the success rate. This is due to two reasons. The first is that the fewer the assigned tasks, the fewer are the decisions over which agents need to agree. The second is that the more tasks rely on common properties, the less non relevant knowledge may be present to an agent's initially induced ontology. Furthermore, while success rate improves over the course of the experiment, it does not converge to 1. This indicates that the final ontologies do not allow agents to reach consensus. This can be explained by the limitation of resources: agents may lack the resources required to learn to decide accurately for all assigned tasks and objects. As a result, they are able to decide accurately for different subsets of the existing object types at a given time. Thus, unless the different subsets coincide for all agents, consensus cannot be achieved. The latter is true even when agents interact over the same single task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Statistical analysis</head><p>Analysis of variance shows that the number of common properties among different tasks, has a statistically significant impact (p &lt; 0.05) on all measures. The number of assigned tasks has a statistically significant impact on (1) the success rate and (2) the average accuracy. When tasks rely on common properties, the latter has a statistically significant impact on the agents accuracy on their best task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>We hypothesize that agents tackling tasks that rely on common properties, benefit from the formation of multi-purpose knowledge. We test this hypothesis by introducing agents that learn and evolve ontologies with respect to several tasks. The experimental results support this hypothesis. On the one hand, it is shown that when agents tackle tasks that rely on common properties, knowledge is transfered from one task to another. On the other hand, when these tasks rely on different properties, tackling additional tasks does not affect the agents accuracy on their best task. Thus, deciding between tackling one or several tasks depends on the agents objective and the environment setup. The agent objective corresponds to whether they seek to optimize their accuracy on average or on their best task. The environment setup corresponds to whether the tasks depend on common properties or not. The experiments rely on minimal hypotheses about the environment, hence the results apply to a wide range of environment. These may serve as an insight on how agents evolve their knowledge within more complex environments. For example, one may consider environments where some tasks share properties, while other tasks are completely independent.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>F a ls e p3 d 1 t1 d 1 t2</head><label>1</label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. ( 1 )</head><label>1</label><figDesc>Fig. (1) Given a set of labeled examples, agents will induce a decision tree. The latter is subsequently transformed into an ontology. Each color represents a different decision.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>-Fig. ( 3 )</head><label>3</label><figDesc>Fig.<ref type="bibr" target="#b2">(3)</ref> The agent α will split the class claws into two sub-classes using the property poison. The first (claws ⊓ ¬poison) will be associated with the decision of the agent β. The second (claws⊓poison) will be associated with all decisions previously associated with the class claws.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 Fig. ( 4 )</head><label>44</label><figDesc>Fig. (4) (a) average accuracy, (b) accuracy on best task and (3) success rate for different number of assigned tasks and common properties.</figDesc></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p>This work has been partially supported by <rs type="funder">MIAI @ Grenoble Alpes</rs> (<rs type="grantNumber">ANR-19-P3IA-0003</rs>).</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_cj97G3c">
					<idno type="grant-number">ANR-19-P3IA-0003</idno>
				</org>
			</listOrg>

			<div type="availability">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Data availability</head><p>The cultural evolution simulator used for our experiments can be found in <ref type="bibr" target="#b0">[1]</ref>. Settings, results and the data analysis notebook are available in <ref type="bibr" target="#b7">[8]</ref>.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Lazy</forename><surname>Lavender</surname></persName>
		</author>
		<ptr target="https://gitlab.inria.fr/moex/lazylav." />
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m">The Description Logic Handbook: Theory, Implementation, and Applications</title>
		<editor>
			<persName><forename type="first">F</forename><surname>Baader</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><surname>Calvanese</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><surname>Mcguinness</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><surname>Nardi</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><forename type="middle">F</forename><surname>Patel-Schneider</surname></persName>
		</editor>
		<imprint>
			<publisher>Cambridge University Press</publisher>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Knowledge improvement and diversity under interaction-driven adaptation of learned ontologies</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Bourahla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Atencia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Euzenat</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 20 th ACM international conference on Autonomous Agents and Multi-Agent Systems (AAMAS)</title>
		<meeting>20 th ACM international conference on Autonomous Agents and Multi-Agent Systems (AAMAS)<address><addrLine>London, United King-</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="242" to="250" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Integrating concept ontology and multitask learning to achieve more effective classifier training for multilevel image annotation</title>
		<author>
			<persName><forename type="first">J</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Luo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="407" to="426" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Phenotypical ontology driven framework for multi-task learning</title>
		<author>
			<persName><forename type="first">M</forename><surname>Ghalwash</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Chakraporty</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Codella</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Sow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Health, Inference, and Learning</title>
		<meeting>the Conference on Health, Inference, and Learning<address><addrLine>New York, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="183" to="192" />
		</imprint>
	</monogr>
	<note>CHIL &apos;21</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Emergent linguistic phenomena in multi-agent communication games</title>
		<author>
			<persName><forename type="first">L</forename><surname>Harding Graesser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Kiela</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="3700" to="3710" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Emergence of language with multi-agent games: Learning to communicate with sequence of symbols</title>
		<author>
			<persName><forename type="first">S</forename><surname>Havrylov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Titov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">5th International Conference on Learning Representations (ICLR 17, workshop track)</title>
		<meeting><address><addrLine>Toulon, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><surname>Kalaitzakis</surname></persName>
		</author>
		<ptr target="https://sake.re/20230505-MTOA" />
		<title level="m">MTOA experiment description</title>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page">20230505</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">K</forename><surname>Lewis</surname></persName>
		</author>
		<title level="m">Convention: A Philosophical Study</title>
		<meeting><address><addrLine>Cambridge, MA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Wiley-Blackwell</publisher>
			<date type="published" when="1969">1969</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Multitask learning strengthens adversarial robustness</title>
		<author>
			<persName><forename type="first">C</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Nitin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Ray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Vondrick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision -ECCV 2020</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Vedaldi</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Bischof</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename><surname>Brox</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Frahm</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="158" to="174" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">What triggers the emergence of grammar?</title>
		<author>
			<persName><forename type="first">L</forename><surname>Steels</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AISB&apos;05: Proceedings of the Second International Symposium on the Emergence and Evolution of Linguistic Communication (EELC&apos;05)</title>
		<meeting><address><addrLine>Hatfield, United Kingdom</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="143" to="150" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Multi-lingual agents through multi-headed neural networks</title>
		<author>
			<persName><forename type="first">J</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Santos-Rodriguez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Anca</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Piechocki</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="volume">4</biblScope>
			<pubPlace>Tromsø, Norway</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Kmutual online ontology alignment</title>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Gasser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 1 st ACM international conference on Autonomous Agents and Multi-Agent Systems (AAMAS)</title>
		<meeting>1 st ACM international conference on Autonomous Agents and Multi-Agent Systems (AAMAS)<address><addrLine>Bologna, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
