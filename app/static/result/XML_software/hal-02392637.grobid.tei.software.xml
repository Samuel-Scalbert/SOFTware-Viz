<TEI xmlns="http://www.tei-c.org/ns/1.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xml:space="preserve" xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Location-Based Plant Species Prediction Using A CNN Model Trained On Several Kingdoms -Best Method Of GeoLifeCLEF 2019 Challenge</title>
			</titleStmt>
			<publicationStmt>
				<publisher />
				<availability status="unknown"><licence /></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Mathilde</forename><surname>Negri</surname></persName>
							<email>mathilde.negri@lirmm.fr</email>
							<affiliation key="aff2">
								<orgName type="institution">Université Paul Valéry</orgName>
								<address>
									<settlement>Montpellier</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="institution">Université de Montpellier</orgName>
								<address>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Maximilien</forename><surname>Servajean</surname></persName>
							<email>maximilien.servajean@lirmm.fr</email>
							<affiliation key="aff1">
								<orgName type="institution">LIRMM</orgName>
								<address>
									<settlement>Montpellier</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution">Université Paul Valéry</orgName>
								<address>
									<settlement>Montpellier</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Benjamin</forename><surname>Deneu</surname></persName>
							<email>benjamin.deneu@inria.fr</email>
							<affiliation key="aff0">
								<orgName type="institution">Inria</orgName>
								<address>
									<settlement>Montpellier</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution">Université Paul Valéry</orgName>
								<address>
									<settlement>Montpellier</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Alexis</forename><surname>Joly</surname></persName>
							<email>alexis.joly@inria.fr</email>
							<affiliation key="aff0">
								<orgName type="institution">Inria</orgName>
								<address>
									<settlement>Montpellier</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution">Université Paul Valéry</orgName>
								<address>
									<settlement>Montpellier</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Location-Based Plant Species Prediction Using A CNN Model Trained On Several Kingdoms -Best Method Of GeoLifeCLEF 2019 Challenge</title>
					</analytic>
					<monogr>
						<imprint>
							<date />
						</imprint>
					</monogr>
					<idno type="MD5">14B81137D5448E73FA2268958231043C</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-04-12T14:48+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid" />
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div><p>This technical report describes the model that achieved the best performance of the <software>GeoLifeCLEF</software> challenge, the objective of which was to evaluate methods for plant species prediction based on their geographical location. Our method is based on an adaptation of the Inception v3 architecture initially dedicated to the classification of RGB images. We modified the input layer of this architecture so as to process the spatialized environmental tensors as images with 77 distinct channels. Using this architecture, we did train several models that mainly differed in the used training data and in the predicted output classes. One of the main objective, in particular, was to compare the performance of a model trained with plant occurrences only to that obtained with a model trained on all available occurrences, including the species of other kingdoms. Our results show that the global model performs consistently better than the plant-specific model. This suggests that the convolutional neural network is able to capture some inter-dependencies among all species and that this information significantly improves the generalisation capacity of the model for any species.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div><head n="1">Introduction</head><p>Predicting a list of the most likely species present at a given location can be very useful. First, it could improve species identification processes and tools by reducing the list of candidate species observable at a given location (whether automated, semi-automated or based on classical field guides or flora). More generally, it could facilitate biodiversity inventories through the development of location-based recommendation services (typically on mobile phones) as well as the involvement of non-expert nature observers. Finally, it could be used for educational purposes through biodiversity discovery applications providing innovative features such as contextualized educational pathways.</p><p>This challenge is related to the problem of Species Distribution Modelling (SDM) in ecology. SDM goal is to predict the spatial distribution of a species over a territory <ref type="bibr" target="#b0">[1]</ref>, in our case we used spatial positions and also environmental data. SDM have become increasingly important in the last few decades for the study of biodiversity, the ecology of conservation, landscape management, preservation of rare and/or endangered species, measurement of human impact or climate change on species, etc.</p><p>Concretely, the objective of SDM is to infer the spatial distribution of a given species, and they are often based on a set of geolocalized occurrences of that species (collected by naturalists, field ecologists, nature observers, citizen sciences project, etc.).</p><p>Recently, SDM based on deep neural networks have begun to appear <ref type="bibr" target="#b1">[2]</ref>. These experiments have shown that they can have a good predictive power, potentially better than the models used conventionally in ecology such as MaxEnt <ref type="bibr" target="#b2">[3]</ref>. Deep neural networks can learn complex non-linear transformations in a wide variety of fields. In addition, they provide an opportunity to learn an area of environmental representation common to various species, which stabilizes predictions from one species to another and improves them globally. Finally, spatial patterns of environmental variables often contain useful information for species distribution, but are generally not considered in conventional models. On the contrary, convolutional neural networks effectively use this information and improve their predictions.</p><p>In this paper, we present a study to evaluate a convolutional neural network to determine the ecological preferences of species through ranges of environmental image patches provided as input (temperature, soil type, etc.) as part of the <software>GeoLifeCLEF</software> challenge.</p><p>-Section 2 gives an overview of the various data we used to build our model.</p><p>-Section 3 provides the detailed description of our model.</p><p>-Section 4 presents the results of the experiments and their analysis.</p></div>
<div><head n="2">Data</head></div>
<div><head n="2.1">Occurrences</head><p>The data set protocol is explained in the challenge protocol <ref type="bibr" target="#b3">[4]</ref>.</p><p>plantnet data set: composed of 2,367,145 plant species occurrences with uncertain identifications, because they come from the automatic identification of plant images, from the Pl@ntnet application. glc 18: Global Biodiversity Information Facility (GBIF) data set (same data set as last year challenge), it is composed of 291,392 occurrences of 3,336 plant species observed on French territory between 1835 and 2017.</p><p>trusted data set: a sample of plantnet data set without uncertainty.</p><p>no plant: 10,618,839 species occurrences from the GBIF database, of other kingdoms (such as mammals, birds, amphibians, insects, fungus etc.). We have removed occurrences that didn't match any environmental rasters, for example birds in the middle of the sea.</p><p>Then, we filter the database to get only plant species that were given by the challenge.</p><p>We used different methods to structure our train data set from each data set.</p><p>full noplant: we train our model with all the data (plantnet, glc 18 and no plant) we had including animal observations and species from other kingdoms.</p><p>full prediction: we only used the Pl@ntnet data set and glc 18 data set.</p><p>filter predictions: we try a random weighted selection scheme, the same as the one explained in the challenge notes for the test set. For each occurrence s i in our data set, we compute a weight w i which corresponds to the importance of this plant over an area of 2 kilometres. Then we did a random sampling on the z i number between 0 and the maximum weight, and we kept the occurrence only if z i &lt; w i . We did this sampling over 2 data set: the plantnet data set with uncertain identification set at 70%, we had a train set around 32,000 occurrences after sampling, and another with the data set pl trusted, we had around 27,000 occurrences after sampling.</p></div>
<div><head n="2.2">Environmental rasters</head><p>We have associated 33 rasters windows cropped into each corresponding global environmental rasters provided by the challenge as input features to each occurrence. <ref type="bibr" target="#b3">[4]</ref> An extraction protocol is given by the challenge. <ref type="foot" target="#foot_0">5</ref>These environmental rasters were constructed from various open data sets including Chelsea Climate, ESDB soil pedological data, Corine Land Cover 2012 soil occupation data, CGIAR-CSI evapotranspiration data, USGS Elevation data (Data available from the U.S. Geological Survey.) and BD Carthage hydrologic data. All these data try to best represent the environment where the plant is observed. We print them on a given area in the Figure <ref type="figure" target="#fig_0">1</ref>, we can see the diversity of information we have for one occurrence near Montpellier.</p><p>In the following, we generally denote to x X an occurrence, each x being associated to a spatial position p(x) in the spatial domain D, a species label y(x) and an environmental tensor g(x) of size 64x64x33. We denote as P the set of all spatial positions p covered by X. It is important to note that a given spatial position p 0 ∈ P usually corresponds to several occurrences x j ∈ X, p(x j ) = p 0 observed at that location. In the training set, up to several hundreds of occurrences can be located in the same place.</p><p>The environmental data provided <ref type="bibr" target="#b3">[4]</ref> is composed of tensors of 64x64X33 pixels. The corresponding 64x64 pixel matrices can be processed as classical image channels provided as CNN input. Most of them are continuous variables such as average temperature, altitude or distance to water as we can see them in the Figure <ref type="figure" target="#fig_0">1</ref>. Thus, the corresponding 64x64 pixel matrices can be processed as classical image channels provided as CNN inputs. Some of the variables are ordinal type (such as ESDB v2), they can be considered as additional channels of the CNN in the sense that the order of pixel values is not significant. For categorical variables like the Corine Land Cover soil type variable provided within <software ContextAttributes="used">GeoLifeCLEF</software>. This variable can take up to 48 different categorical values, but 3 of them are not used therefore we have kept 45 categorical variables. The order of these values has no meaning. Consequently, we preferred unstacking the corresponding channel into 45 different binary channels, then concatenate it with the other 32 tensors. Thus, instead of having a tensor of 64x64X33 pixels, we do have a tensor of 64x64x77 pixels.</p></div>
<div><head n="3">Convolutional Neural Network</head><p>It has been previously shown in <ref type="bibr" target="#b1">[2]</ref> that Convolutional Neural Networks (CNN) may reach better predictive performance than classical models used in ecology.</p><p>Our model attempts to predict the most likely species to be observed based on environmental features learned. Our structure is very different from last year challenge <ref type="bibr" target="#b4">[5]</ref>. We used an Inception V3 convolutional neural network <ref type="bibr" target="#b5">[6]</ref>, it is made up of symmetric and asymmetric building blocks, including convolutions, average pooling, max pooling, concatenates, dropouts, and fully connected layers. In addition to this model, we added a first layer of 77 layers, to match the size of the environmental raster and a dropout to avoid over fitting.</p><p>For the last layer we used a softmax and a cross entropy loss. The softmax layer is computed as:</p><formula xml:id="formula_0">p j = e hj K k=1 e h k<label>(1)</label></formula><p>where y k are the scores inferred by the net for each class, and K the number of different classes that means the number of species we trained our model with, the softmax activation for a class y j depends on all the scores in y.</p><p>Then we used a cross entropy loss <ref type="bibr" target="#b6">[7]</ref>:</p><formula xml:id="formula_1">Loss = - K k=1 y k log(p k )<label>(2)</label></formula><p>with y k a binary indicator if class label k is the correct classification for the observation and p k the probability of the observation is of class k.</p><p>Learning set up and parameters: all our experiments were conducted using <software>PyTorch</software> deep learning framework 4 and were run on a single computing node equipped with 4 Nvidia GTX 1080 ti GPU. We used the Stochastic Gradient Descent optimization algorithm with a learning rate of 0.1, a momentum of 0.9 and a batch size of 300. We trained our model over multiple epochs, then to export our result we took the epoch where the model gets the highest Top 1 score in our validation set. For our best runs (full noplant predictions and full predictions) we trained only over 20 epochs due to the number of data and for the two other runs we trained our model over 180 epochs.</p></div>
<div><head n="4">Result</head><p>For <software ContextAttributes="used">GeoLifeCLEF</software> 2019 they decided that the main evaluation criteria will be the accuracy based on the first 30 answers, also called Top 30, i.e. the function scoring 1 when the right specie is in the 30 first answers, and 0 if not. And as a  For this challenge we submitted 4 different runs. We can see the global result in Figure <ref type="figure" target="#fig_1">2</ref> and Table <ref type="table" target="#tab_0">1</ref>.</p><p>-The first one: full noplant predictions is a CNN trained with every data set (plantnet, no plant, glc 18). We used <software>pl@ntnet</software> database without any filters (2,367,145 plant species occurrences), train and test occurrences from last year's challenge (file GLC 2018.csv) and occurrences from other kingdoms (such as mammals, birds, amphibians, insects, fungus etc.) from the GBIF database (file noPlant.csv). There are 34,375 different classes, so this CNN has a larger last layer output, but for the test we let it choose only the plant classes which are provided by the challenge. This method showed the best result with a Top 30 of 0.1769 and a MRR of 0.031. -The second submission, full predictions is a CNN trained with plantnet data set and the data set of last year challenge. This means that we only have plants to train our model, we have 3,859 classes. It is the 5 th submission of the challenge, after SaraSi models with a top 30 of 0.1364. -The two other submissions were not as good (plcomplete predictions and inception glc19 filter predictions), we sampled our train set as explained in the challenge protocol for the test set. Therefore, we have reduced our data, our model didn't capture as much information as the other models.</p><p>In this case, it seems that the more data available to the CNN, the better the results. It seems that our model is learning from the species from another kingdoms that live in the same area. Indeed, our model train with more than only plant occurrences showed a better result for predicting plants. Here, the CNN has more classes but can classify plants even better. We can deduct from this that our CNN network not only captures environmental information but also, the interaction between different species, we can imagine that it can also learn from the information of the species that live around the plants and perhaps from the ecological niche of an occurrence.</p></div>
<div><head n="5">Conclusion</head><p>This paper describes our participation in <software>GeoLifeCLEF</software> challenge to evaluate location-based species prediction models. We compared Convolutional Neural Network trained with different data sets. The main conclusion of our study is that the convolutional neural network model is the most efficient model and it can learn information not only from environmental rasters but also from interaction between species of other kingdoms. Indeed, it achieved the best performance of the whole <software ContextAttributes="used">GeoLifeCLEF</software> challenge when we trained our model with other kingdom observations.</p><p>In future work, we will attempt to better understand what information the CNN does capture from different data sets and how it could be improved.</p></div><figure xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Environmental rasters</figDesc><graphic coords="5,134.77,115.82,345.81,363.10" type="bitmap" /></figure>
<figure xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Top30 accuracy score of every participant of GeoLifeCLEF 2019</figDesc><graphic coords="8,134.77,115.83,414.99,262.83" type="bitmap" /></figure>
<figure type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>Table of Result of GeoLifeCLEF 2019 challenge</figDesc><table><row><cell cols="2">Rank runId top30 runName</cell><cell>participant</cell></row><row><cell>1</cell><cell>27007 0.1769 full noplant predictions</cell><cell>LIRMM</cell></row><row><cell>2</cell><cell>27086 0.1687 RUN2 GRINNELL FULL INITIAL</cell><cell>SaraSi</cell></row><row><cell>3</cell><cell>27087 0.1653 RUN3 GRINNELL TRANS</cell><cell>SaraSi</cell></row><row><cell>4</cell><cell>27088 0.1646 RUN1 GRINNELL TESTSPECIES INITIAL</cell><cell>SaraSi</cell></row><row><cell>5</cell><cell>27006 0.1364 full predictions</cell><cell>LIRMM</cell></row><row><cell>6</cell><cell>26997 0.1342 submit xgb spatial 4x4 all</cell><cell>SSN CSE</cell></row><row><cell>7</cell><cell>26996 0.1288 submit xgb spatial allnoclc</cell><cell>SSN CSE</cell></row><row><cell>8</cell><cell>27013 0.1273 submit xgb dep3 1</cell><cell>SSN CSE</cell></row><row><cell>9</cell><cell>27069 0.1268 submission sel 4x4</cell><cell>SSN CSE</cell></row><row><cell>10</cell><cell>27012 0.1263 submit xgb 4x4 all dep3</cell><cell>SSN CSE</cell></row><row><cell>11</cell><cell>27070 0.1227 submission sel 1</cell><cell>SSN CSE</cell></row><row><cell>12</cell><cell>27064 0.1198 submission1x1</cell><cell>SSN CSE</cell></row><row><cell>13</cell><cell>27067 0.1135 submission4x4</cell><cell>SSN CSE</cell></row><row><cell>14</cell><cell>27124 0.1135 Lot Of Lof 2</cell><cell>Lot of Lof</cell></row><row><cell>15</cell><cell>27089 0.1110 RUN4 ELTON TRANS</cell><cell>SaraSi</cell></row><row><cell>16</cell><cell cols="2">27082 0.1090 RUN0 ELTON FULL INITIAL TESTSPECIES SaraSi</cell></row><row><cell>17</cell><cell>26988 0.1063 submit xgb spatial</cell><cell>SSN CSE</cell></row><row><cell>18</cell><cell>27123 0.0984 Lot Of Lof 3</cell><cell>Lot of Lof</cell></row><row><cell>19</cell><cell>27063 0.0864 Lot Of Lof 1</cell><cell>Lot of Lof</cell></row><row><cell>20</cell><cell>26875 0.0844 submission</cell><cell>SSN CSE</cell></row><row><cell>21</cell><cell>27102 0.0834 rfspatial</cell><cell>SSN CSE</cell></row><row><cell>22</cell><cell>26821 0.0570 submit</cell><cell>SSN CSE</cell></row><row><cell>23</cell><cell>27004 0.0470 plcomplete predictions</cell><cell>LIRMM</cell></row><row><cell>24</cell><cell>27005 0.0465 inception glc19 filter predictions</cell><cell>LIRMM</cell></row><row><cell>25</cell><cell>26968 0.0205 run 14</cell><cell>sergiu atodiresei</cell></row><row><cell>26</cell><cell>26964 0.0191 run 10</cell><cell>sergiu atodiresei</cell></row><row><cell>27</cell><cell>26961 0.0190 run 7</cell><cell>sergiu atodiresei</cell></row><row><cell>28</cell><cell>26971 0.0184 run 17</cell><cell>sergiu atodiresei</cell></row><row><cell>29</cell><cell>26967 0.0180 run 13</cell><cell>sergiu atodiresei</cell></row><row><cell>30</cell><cell>26960 0.0168 run 6</cell><cell>sergiu atodiresei</cell></row><row><cell>31</cell><cell>27062 0.0159 run 20</cell><cell>sergiu atodiresei</cell></row><row><cell>32</cell><cell>26958 0.0146 run 3</cell><cell>sergiu atodiresei</cell></row><row><cell>33</cell><cell>26970 0.0102 run 16</cell><cell>sergiu atodiresei</cell></row><row><cell>34</cell><cell>26969 0.0099 run 15</cell><cell>sergiu atodiresei</cell></row><row><cell>35</cell><cell>26972 0.0089 run 18</cell><cell>sergiu atodiresei</cell></row><row><cell>36</cell><cell>26963 0.0079 run 9</cell><cell>sergiu atodiresei</cell></row><row><cell>37</cell><cell>26965 0.0068 run 11</cell><cell>sergiu atodiresei</cell></row><row><cell>38</cell><cell>26926 0.0067 run 4</cell><cell>sergiu atodiresei</cell></row><row><cell>39</cell><cell>26973 0.0064 run 19</cell><cell>sergiu atodiresei</cell></row><row><cell>40</cell><cell>26959 0.0063 run 5</cell><cell>sergiu atodiresei</cell></row><row><cell>41</cell><cell>26962 0.0062 run 8</cell><cell>sergiu atodiresei</cell></row><row><cell>42</cell><cell>26957 0.0061 run 2</cell><cell>sergiu atodiresei</cell></row><row><cell>43</cell><cell>26966 0.0058 run 12</cell><cell>sergiu atodiresei</cell></row><row><cell>44</cell><cell>26956 0.0058 run 1</cell><cell>sergiu atodiresei</cell></row></table></figure>
			<note place="foot" n="5" xml:id="foot_0"><p>http://www.github.com/maximiliense/GLC19</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Mechanistic niche modelling: combining physiological and spatial data to predict species' ranges</title>
		<author>
			<persName><forename type="first">M</forename><surname>Kearney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Porter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ecology Letters</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="334" to="350" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">A deep learning approach to species distribution modelling</title>
		<author>
			<persName><forename type="first">C</forename><surname>Botella</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Joly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Bonnet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Monestiez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Munoz</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Maximum entropy modeling of species geographic distributions</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Phillips</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">P</forename><surname>Anderson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Schapire</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ecological Modelling</title>
		<imprint>
			<biblScope unit="volume">190</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="231" to="259" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Overview of geolifeclef 2019: plant species prediction using environment and animal occurrences</title>
		<author>
			<persName><forename type="first">C</forename><surname>Botella</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Servajean</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Bonnet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Joly</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CLEF working notes</title>
		<imprint>
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Location-based species recommendation using co-occurrences and environment-GeoLifeCLEF 2018 challenge</title>
		<author>
			<persName><forename type="first">B</forename><surname>Deneu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Servajean</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Botella</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Joly</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CLEF: Conference and Labs of the Evaluation Forum</title>
		<meeting><address><addrLine>Avignon, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018-09">September 2018</date>
		</imprint>
	</monogr>
	<note>CEUR Workshop Proceedings</note>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Rethinking the inception architecture for computer vision</title>
		<author>
			<persName><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wojna</surname></persName>
		</author>
		<idno>CoRR abs/1512.00567</idno>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A tutorial on the crossentropy method</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">T</forename><surname>De Boer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Kroese</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mannor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">Y</forename><surname>Rubinstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annals of Operations Research</title>
		<imprint>
			<biblScope unit="volume">134</biblScope>
			<biblScope unit="page" from="19" to="67" />
			<date type="published" when="2005-02">Feb 2005</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>