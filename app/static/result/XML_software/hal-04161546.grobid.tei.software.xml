<TEI xmlns="http://www.tei-c.org/ns/1.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xml:space="preserve" xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">ProvLight: Efficient Workflow Provenance Capture on the Edge-to-Cloud Continuum</title>
				<funder>
					<orgName type="full">FAPERJ</orgName>
				</funder>
				<funder ref="#_CtBjUYq">
					<orgName type="full">Agence Nationale de la Recherche</orgName>
					<orgName type="abbreviated">ANR</orgName>
				</funder>
				<funder>
					<orgName type="full">CNPq</orgName>
				</funder>
				<funder>
					<orgName type="full">Universities</orgName>
				</funder>
				<funder>
					<orgName type="full">HPC-BigData Inria Challenge (IPL)</orgName>
				</funder>
				<funder ref="#_BRZFTXR">
					<orgName type="full">Office of Science of the U.S. Department of Energy</orgName>
				</funder>
				<funder>
					<orgName type="full">HPDaSc</orgName>
				</funder>
				<funder>
					<orgName type="full">Inria</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher />
				<availability status="unknown"><licence /></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Daniel</forename><surname>Rosendo</surname></persName>
							<email>daniel.rosendo@inria.fr</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">University of Rennes</orgName>
								<orgName type="institution" key="instit2">Inria</orgName>
								<orgName type="institution" key="instit3">CNRS</orgName>
								<orgName type="institution" key="instit4">IRISA -Rennes</orgName>
								<address>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Marta</forename><surname>Mattoso</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Federal University of Rio de Janeiro</orgName>
								<address>
									<country key="BR">Brazil</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Alexandru</forename><surname>Costan</surname></persName>
							<email>alexandru.costan@inria.fr</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">University of Rennes</orgName>
								<orgName type="institution" key="instit2">Inria</orgName>
								<orgName type="institution" key="instit3">CNRS</orgName>
								<orgName type="institution" key="instit4">IRISA -Rennes</orgName>
								<address>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Renan</forename><surname>Souza</surname></persName>
							<email>souzar@ornl.gov</email>
							<affiliation key="aff2">
								<orgName type="laboratory">Oak Ridge National Laboratory</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Débora</forename><surname>Pina</surname></persName>
							<email>dbpina@cos.ufrj.br</email>
							<affiliation key="aff1">
								<orgName type="institution">Federal University of Rio de Janeiro</orgName>
								<address>
									<country key="BR">Brazil</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Patrick</forename><surname>Valduriez</surname></persName>
							<email>patrick.valduriez@inria.fr</email>
							<affiliation key="aff3">
								<orgName type="institution" key="instit1">University of Montpellier</orgName>
								<orgName type="institution" key="instit2">Inria</orgName>
								<orgName type="institution" key="instit3">CNRS</orgName>
								<orgName type="institution" key="instit4">LIRMM -Montpellier</orgName>
								<address>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Gabriel</forename><surname>Antoniu</surname></persName>
							<email>gabriel.antoniu@inria.fr</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">University of Rennes</orgName>
								<orgName type="institution" key="instit2">Inria</orgName>
								<orgName type="institution" key="instit3">CNRS</orgName>
								<orgName type="institution" key="instit4">IRISA -Rennes</orgName>
								<address>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">ProvLight: Efficient Workflow Provenance Capture on the Edge-to-Cloud Continuum</title>
					</analytic>
					<monogr>
						<imprint>
							<date />
						</imprint>
					</monogr>
					<idno type="MD5">3BAA0D53661D6BDF9CE7DD0370E76586</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-04-12T14:50+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid" />
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Provenance</term>
					<term>Lineage</term>
					<term>Workflows</term>
					<term>Edge</term>
					<term>IoT</term>
					<term>Computing Continuum</term>
				</keywords>
			</textClass>
			<abstract>
<div><p>Modern scientific workflows require hybrid infrastructures combining numerous decentralized resources on the IoT/Edge interconnected to Cloud/HPC systems (aka the Computing Continuum) to enable their optimized execution. Understanding and optimizing the performance of such complex Edgeto-Cloud workflows is challenging. Capturing the provenance of key performance indicators, with their related data and processes, may assist in understanding and optimizing workflow executions. However, the capture overhead can be prohibitive, particularly in resource-constrained devices, such as the ones on the IoT/Edge.</p><p>To address this challenge, based on a performance analysis of existing systems, we propose ProvLight, a tool to enable efficient provenance capture on the IoT/Edge. We leverage simplified data models, data compression and grouping, and lightweight transmission protocols to reduce overheads. We further integrate <software>ProvLight</software> into the <software ContextAttributes="created">E2Clab</software> framework to enable workflow provenance capture across the Edge-to-Cloud Continuum. This integration makes <software ContextAttributes="created">E2Clab</software> a promising platform for the performance optimization of applications through reproducible experiments.</p><p>We validate <software ContextAttributes="created">ProvLight</software> at a large scale with synthetic workloads on 64 real-life IoT/Edge devices in the FIT IoT LAB testbed. Evaluations show that <software ContextAttributes="created">ProvLight</software> outperforms state-of-the-art systems like <software ContextAttributes="created">ProvLake</software> and <software ContextAttributes="created">DfAnalyzer</software> in resource-constrained devices. <software ContextAttributes="created">ProvLight</software> is 26-37x faster to capture and transmit provenance data; uses 5-7x less CPU; 2x less memory; transmits 2x less data; and consumes 2-2.5x less energy. <software ContextAttributes="created">ProvLight</software> [1] and <software ContextAttributes="created">E2Clab</software> <ref type="bibr" target="#b1">[2]</ref> are available as open-source tools.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div><head>I. INTRODUCTION</head><p>Data processing and Artificial Intelligence (AI) workflows can no longer rely on traditional approaches (due to resource usage, latency, and privacy constraints) <ref type="bibr" target="#b2">[3]</ref> that send all data to centralized and distant Cloud datacenters for processing or AI model training <ref type="bibr" target="#b3">[4]</ref>. Instead, they need to leverage hybrid (decentralized) approaches that take advantage of the numerous resources close to the data generation sites (i.e., on the edge of the network) to promptly extract insights <ref type="bibr" target="#b4">[5]</ref> and satisfy the ultra-low latency requirements of applications.</p><p>This hybrid approach contributes to the emergence of the Computing Continuum <ref type="bibr" target="#b5">[6]</ref> (or the Edge-to-Cloud Continuum or the Transcontinuum). It seamlessly combines resources and services at the center of the network (e.g., in Cloud datacenters), at its edge, and in-transit, along the data path. Typically, data is first generated and preprocessed (e.g., model training with local data) on IoT/Edge devices. Then, data is transferred to (HPC-enabled) Clouds for Big Data analytics, AI model training, and global simulations. For instance, in Federated Learning (FL) model training, a central Cloud server collects data (model updates) from multiple decentralized Edge devices, then it generates a single accurate global inference model.</p><p>Due to the complexity incurred by application deployments on such highly distributed and heterogeneous Edge-to-Cloud infrastructures, realizing the Computing Continuum vision in practice is challenging. Deploying, analyzing, and reproducing performance trade-offs and optimizing large-scale, real-life applications on such infrastructures is difficult <ref type="bibr" target="#b2">[3]</ref>. It requires configuring a myriad of system-specific parameters (e.g., from AI and Big Data systems) and reconciling many requirements or constraints in terms of energy consumption, network efficiency, and hardware resource usage, to cite a few <ref type="bibr" target="#b6">[7]</ref>. In recent works, these challenges have been mainly explored by systems like <software ContextAttributes="created">Pegasus</software> <ref type="bibr" target="#b7">[8]</ref>, <software ContextAttributes="created">E2Clab</software> <ref type="bibr" target="#b8">[9]</ref>, Delta <ref type="bibr" target="#b9">[10]</ref>.</p><p>The process of understanding, optimizing, and reproducing complex Edge-to-Cloud workflows may be assisted by provenance data capture. "Provenance data" refer to a record trail that accounts for the origin of a piece of data together with descriptions of the computational processes that assist in explaining how and why it was generated <ref type="bibr" target="#b10">[11]</ref>. Capturing provenance data during workflow execution helps users in tracking inputs, outputs, and processing history, allowing them to steer workflows precisely <ref type="bibr" target="#b11">[12]</ref>.</p><p>For instance, considering a Federated Learning model training workflow executed on distributed devices on the Edge, the captured data during model training helps answer questions like: (i) What are the elapsed time and the training loss in the latest epoch for each hyperparameter combination? <ref type="bibr" target="#b12">[13]</ref>, <ref type="bibr" target="#b13">[14]</ref> or (ii) Retrieve the hyperparameters which obtained the 3 best accuracy values for model m? <ref type="bibr" target="#b13">[14]</ref>, <ref type="bibr" target="#b14">[15]</ref>. Answering such queries helps to analyze hyperparameter values related to the training stages and to adjust them for better-quality results.</p></div>
<div><head>A. Challenges and Novelty</head><p>Overhead in provenance systems is a critical problem that must be assessed <ref type="bibr" target="#b15">[16]</ref>. Many other contributions in provenance systems evaluate the overhead, such as <ref type="bibr" target="#b16">[17]</ref>, <ref type="bibr" target="#b17">[18]</ref>. Overhead is even more critical in edge devices because of resource constraints and power consumption. For this reason, we decided to focus on evaluating overhead in our work. In <ref type="bibr" target="#b18">[19]</ref>, leading database researchers discussed the challenges of deploying services considering disaggregation and high heterogeneity of resources in hybrid cloud infrastructures. In <ref type="bibr" target="#b19">[20]</ref>, the authors describe challenges related to capturing provenance on the Edge-to-Cloud Continuum.</p><p>The main state-of-the-art provenance systems were designed to run on Cloud/HPC infrastructures. We highlight that we have not found in the literature reference systems tailored for IoT/Edge devices. Therefore, this work refers to systems well-known for their low provenance capture overhead in Cloud/HPC, such as <software ContextAttributes="created">DfAnalyzer</software> <ref type="bibr" target="#b17">[18]</ref>, <software ContextAttributes="created">ProvLake</software> <ref type="bibr" target="#b16">[17]</ref>, and PROV-IO <ref type="bibr" target="#b20">[21]</ref>. We also include <software ContextAttributes="created">Komadu</software> <ref type="bibr" target="#b21">[22]</ref> in our analysis, as it is also compared within the aforementioned works.</p><p>Enabling provenance data capture with low overhead in resource-constrained IoT/Edge devices cannot be easily achieved by existing provenance systems, calling for practical solutions beyond the state-of-the-art. For instance, it requires the design and development of novel capture approaches focusing on the hardware limitations of IoT/Edge devices, as proposed in this work.</p></div>
<div><head>B. Contributions</head><p>We make the following contributions: 1) The first research question we aim to answer is: How Do the Existing Provenance Systems Perform in IoT/Edge Devices? We address this research question by providing an experimental evaluation of existing provenance systems along with a detailed discussion in Section III. 2) As our experiments concluded that the state-of-the-art systems present high overheads to capture provenance data in IoT/Edge devices, we propose a novel workflow provenance data capture approach tailored for resource-limited IoT/Edge devices, that addresses the limitations found in the state of the art (Section IV).</p><p><software ContextAttributes="created">ProvLight</software> is an open-source implementation of this approach (available at <ref type="bibr" target="#b0">[1]</ref>), following the W3C PROV-DM recommendations. 3) An integration of <software ContextAttributes="created">ProvLight</software> within the <software ContextAttributes="created">E2Clab</software> automatic deployment and performance optimization framework. This enables provenance data capture across the Computing Continuum for hybrid workflows deployed on both IoT/Edge and Cloud/HPC infrastructures. To the best of our knowledge, this enhanced version of <software ContextAttributes="created">E2Clab</software> is the first framework to support the end-toend provenance data capture of complex workflows Fig. <ref type="figure">1</ref>: PROV-DM: The W3C PROV Data Model <ref type="bibr" target="#b27">[28]</ref>.</p><p>executed on the Edge-to-Cloud Continuum (Section V). This integration with E<software ContextAttributes="created">2Clab</software> is an open-source tool available at <ref type="bibr" target="#b1">[2]</ref>. We highlight that, <software ContextAttributes="created">ProvLight</software> may be easily integrated into other deployment and performance optimization systems/frameworks. 4) A large-scale experimental validation of <software ContextAttributes="created">ProvLight</software> with synthetic workloads on 64 real-life IoT devices (from the FIT IoT LAB <ref type="bibr" target="#b22">[23]</ref> testbed) and Cloud resources (from the Grid'5000 <ref type="bibr" target="#b23">[24]</ref> testbed). Experimental evaluations show that <software ContextAttributes="created">ProvLight</software> outperforms (i.e., lower capture overhead) <software ContextAttributes="created">DfAnalyzer</software> and <software ContextAttributes="created">ProvLake</software> systems in terms of capture time, CPU and memory usage, network usage, and power consumption (Section VI).</p></div>
<div><head>II. BACKGROUND</head><p>This work focuses on provenance systems leveraging the user-defined capture approach <ref type="bibr" target="#b24">[25]</ref>, <ref type="bibr" target="#b25">[26]</ref>. This approach allows users to define what to capture by workflow script instrumentation through capture libraries. We highlight that script instrumentation (e.g., adding logging calls) is a common practice in distributed systems, particularly to assist debugging. In provenance capture, many other approaches rely on script instrumentation <ref type="bibr" target="#b16">[17]</ref>, <ref type="bibr" target="#b25">[26]</ref>, <ref type="bibr" target="#b26">[27]</ref>. A good practice to promote data interoperability is that such libraries should follow provenance specifications like the PROV-DM recommendation, as an example. Finally, the provenance capture of Edge-to-Cloud workflows is a new topic that requires automatic deployment tools like <software ContextAttributes="created">E2Clab</software>.</p></div>
<div><head>A. PROV-DM: The PROV Data Model</head><p>PROV <ref type="bibr" target="#b28">[29]</ref> is a specification to interchange provenance information. PROV-DM <ref type="bibr" target="#b27">[28]</ref> is the data model for the W3C provenance family of specifications. It aims to promote data interoperability from provenance management systems. Provenance systems such as <software ContextAttributes="created">DfAnalyzer</software> <ref type="bibr" target="#b17">[18]</ref>, <software ContextAttributes="created">ProvLake</software> <ref type="bibr" target="#b16">[17]</ref>, PROV-IO <ref type="bibr" target="#b20">[21]</ref>, <software ContextAttributes="created">Komadu</software> <ref type="bibr" target="#b21">[22]</ref>, among many others, follow the PROV-DM model.</p><p>Figure <ref type="figure">1</ref> illustrates the core elements of PROV-DM and their relationships. PROV-DM provides an abstract representation of provenance data derivations. Briefly described, the core elements are: (i) Agent: refers to tools invoked on behalf of users (e.g., software); (ii) Activity: refers to tasks (e.g., processing steps); and (i) Entity: refers to data objects (e.g., files, input parameters, etc.). Our capture approach also follows the PROV-DM recommendation.</p><p>B. Capturing Provenance for Edge-to-Cloud Workflows 1) Edge-to-Cloud Computing Continuum: Edge infrastructures refer to computing and storage resources located where the data originated. They consist of numerous smart devices sensing "what" is happening in the environment and generating potentially huge data streams at potentially high rates <ref type="bibr" target="#b2">[3]</ref>. The Edge computing paradigm aims to push intelligence to those devices and extract value from data in real-time to improve response times while preserving privacy and security (critical data is analyzed locally).</p><p>Cloud infrastructures provide virtually "unlimited" computing and storage resources used essentially for backup and data analytics for global insight extraction in centralized data centers. Data is first ingested at high rates through dedicated systems (e.g., <software ContextAttributes="created">Apache Kafka</software> <ref type="bibr" target="#b29">[30]</ref>) and analyzed by Big Data processing frameworks (e.g., Spark <ref type="bibr" target="#b30">[31]</ref>). They perform stream and batch analytics on vast historical data, AI model training, and complex simulations. The goal is to help understand "why" the phenomena sensed at the Edge are happening.</p><p>2) Federated Learning Training Use Case: To illustrate an Edge-to-Cloud application workflow, we refer to Federated Learning model training. Federated Learning <ref type="bibr" target="#b31">[32]</ref> is a collaborative machine learning paradigm that trains a centralized model on decentralized and private data.</p><p>The Federated Learning architecture is composed of a central server (typically deployed on the Cloud) and various devices (deployed on the Edge). Edge devices first download a global model from the cloud server and train it for several epochs with their local data. After multiple rounds of model updates, the results are sent to the cloud server for global model aggregation. This training loop continues until the global model achieves the desired accuracy <ref type="bibr" target="#b32">[33]</ref>.</p><p>Capturing provenance data of Federated Learning model training at runtime helps scientists to track model training inputs (e.g., hyperparameters), outputs (e.g., accuracy), and processing history (e.g., training epochs). In this context, captured data from each training epoch may refer to the hyperparameters (input data) followed by the respective accuracy obtained from the training (output data). The goal is to allow users to answer queries like the ones presented in Section I). Analyzing hyperparameters along the model training allows for adapting the training data and fine-tuning the model. Provenance data traces also help in the interpretation and reproducibility of the training results <ref type="bibr" target="#b13">[14]</ref>, <ref type="bibr" target="#b33">[34]</ref>.</p></div>
<div><head>C. E2Clab: Reproducible Edge-to-Cloud Experiments</head><p><software ContextAttributes="created">E2Clab</software> <ref type="bibr" target="#b34">[35]</ref> is an open-source framework (available at <ref type="bibr" target="#b1">[2]</ref>) that allows researchers to reproduce the application behavior in a controlled environment to understand and to optimize performance <ref type="bibr" target="#b8">[9]</ref>. It sits on top of EnOSlib <ref type="bibr" target="#b35">[36]</ref> and implements a rigorous methodology (illustrated in Figure <ref type="figure">2</ref>) for designing Software, algorithms Dataset Fig. <ref type="figure">2</ref>: <software ContextAttributes="created">E2Clab</software> experiment methodology <ref type="bibr" target="#b34">[35]</ref>.</p><p>experiments with real-world workloads on the Edge-to-Cloud Computing Continuum. Section V details how we extend <software ContextAttributes="created">E2Clab</software> to enable provenance data capture of Edge-to-Cloud workflows. Figure <ref type="figure" target="#fig_4">4</ref> illustrates the extended architecture.</p><p>High-level features provided by <software ContextAttributes="created">E2Clab</software> are (i) reproducible experiments; (ii) mapping application parts (executed on Edge, Fog, and Cloud/HPC) and physical testbeds; (iii) experiment variation and transparent scaling of scenarios; (iv) defining Edge-to-Cloud network constraints; (v) automatic experiment deployment, execution, and monitoring (e.g., on various testbeds like Grid'5000 <ref type="bibr" target="#b23">[24]</ref>, Chameleon <ref type="bibr" target="#b36">[37]</ref>, and FIT IoT LAB <ref type="bibr" target="#b22">[23]</ref>); (vi) workflow optimization.</p></div>
<div><head>III. PROVENANCE SYSTEMS IN IOT/EDGE</head><p>In the literature, to the best of our knowledge, we have not found provenance data capture tools tailored for IoT/Edge devices. Capturing provenance data in such devices requires using tools designed for Cloud/HPC resources. Therefore, in this section, we assess their overhead for capturing data in resource-limited computing resources.</p><p>A. Experimental Setup a) Selected provenance systems.: Due to the limitations of the PROV-IO and <software ContextAttributes="created">Komadu</software> systems, shown in Table <ref type="table" target="#tab_3">IV</ref>, they were excluded from our performance analysis. We choose <software ContextAttributes="created">ProvLake</software> and <software ContextAttributes="created">DfAnalyzer</software> because we have access to their data capture components as open-source software. Since we are limited to testing with the open-source version of these systems, we cannot experiment with features that might deliver lower overhead but are not open-source. For instance, <software ContextAttributes="created">ProvLake</software> reports being able to use a different communication protocol other than HTTP 1.1 for machine learning provenance capture with low overhead in an HPC environment <ref type="bibr" target="#b13">[14]</ref>, but this system version is not available as open-source.  The main analyzed metric is the capture time overhead, which refers to the relative difference of the workflow execution time with and without data capture. We repeat the experiment 10 times for each provenance system and for each synthetic workload and report the mean followed by the 95% confidence interval.</p><p>c) Overhead levels.: In the literature, the reference to low overhead or negligible overhead, in terms of provenance capture time in Cloud/HPC environments, differs between application domains. For instance: &lt;2% for blockchains <ref type="bibr" target="#b37">[38]</ref>;</p><p>4% for I/O-centric workflows <ref type="bibr" target="#b20">[21]</ref>; 4% for AI model training <ref type="bibr" target="#b12">[13]</ref>; 12% for security applications <ref type="bibr" target="#b38">[39]</ref>; to cite a few. Regarding provenance capture on resource-limited IoT/Edge devices, prohibitive overhead levels may vary depending on the application use case. For instance, in latency-sensitive applications such as autonomous vehicles <ref type="bibr" target="#b39">[40]</ref>, real-time monitoring in smart energy grids <ref type="bibr" target="#b40">[41]</ref>, and virtual and augmented reality <ref type="bibr" target="#b41">[42]</ref>, to cite a few, a &gt; 3% processing time overhead is considered high (i.e., enough to exceed the acceptable latency thresholds) as it can introduce delays that disrupt the realtime nature of the application, leading to inaccuracies, missed targets, or compromised safety.</p><p>d) Synthetic workload.: We use a synthetic workload to evaluate the provenance capture overhead because doing it in real workloads is much more complicated, costly, and may not make sense for the real application. The reason is that we cannot precisely control and isolate variables such as elapsed time, number of tasks, and number of attributes. A similar situation happens when scientists need to rely on simulations instead of real phenomena to test and evaluate their hypotheses. Unfortunately, there are no well-established benchmarks in the community to evaluate overhead in provenance systems. Therefore, like related work <ref type="bibr" target="#b16">[17]</ref>, <ref type="bibr" target="#b17">[18]</ref>, we decided to focus our analysis on synthetic workload configurations. Such configurations are based on real-life workloads <ref type="bibr" target="#b42">[43]</ref>- <ref type="bibr" target="#b44">[45]</ref>, and we refined the configuration space of our workloads with preliminary experiments on real-life edge devices.</p><p>Table <ref type="table" target="#tab_0">I</ref> presents the 8 synthetic workload configurations used to analyze the data capture overhead. We chose these values to cover combinations of application characteristics. The idea of these configurations is to mimic the characteristics of the various real-life workloads that IoT/Edge devices typically execute, such as AI model training (e.g., the Federated Learning use case we presented earlier), image pre-processing, and sensor data aggregation, among others. Such workloads are composed of various tasks (number of tasks), each one with a different number of attributes (attributes per task) and with different processing times (task duration).</p><p>We consider workloads with 5 chained transformations, which is an approximate number of transformations in many applications. In the Federated Learning application, for example, one of the transformations is model training, which has many epoch executions. We consider each epoch execution as a task of the model training transformation and each epoch has associated features (considered input attributes) and performance metrics (considered output attributes) <ref type="bibr" target="#b13">[14]</ref>. Other transformations include data preparation and the evaluation of the trained model. To generate our synthetic workload, we consider 100 tasks. In the Federated Learning example, it would represent a training with 100 epochs. For each task, we represent applications that manipulate a few (about 10) or more (about 100) attributes per task. Besides, to represent various classes of applications, we also consider four different task duration: shorter (e.g., 0.5 or 1 seconds) and longer (e.g., 3.5 or 5 seconds).</p><p>We run preliminary experiments to refine the synthetic workload configurations. We observe that there is no significant impact on the capture overhead when varying the number of tasks from 10, 50 to 100. In addition, since the data capture and transmission is measured per task, mainly variations in the number of attributes per task (amount of data transmitted) and task duration (data capture frequency) impact the capture time overhead (calculated as the relative difference). e) Hardware.: Each workload configuration runs on a single A8-M3 <ref type="bibr" target="#b45">[46]</ref> IoT device (ARM Cortex-A8 microprocessor, 600Mhz, 256MB; radio: 802.15.4, 2.4 GHz; power: 3.7V LiPo battery, 650 mAh) available at the FIT IoT LAB testbed <ref type="bibr" target="#b22">[23]</ref>. We instrument the synthetic workloads (code available at <ref type="bibr" target="#b46">[47]</ref>) with the capture libraries provided by <software ContextAttributes="created">ProvLake</software> and <software ContextAttributes="created">DfAnalyzer</software> systems. The libraries transmit the data to the provenance system running on a remote Cloud/HPC server <ref type="bibr" target="#b47">[48]</ref> (Intel Xeon Gold 5220, 2.20GHz, 18 cores; 96GB RAM; Ethernet) available at the Grid'5000 <ref type="bibr" target="#b23">[24]</ref> testbed.</p></div>
<div><head>B. Overhead Analysis</head><p>Table <ref type="table" target="#tab_1">II</ref> presents the capture time overhead of <software ContextAttributes="created">ProvLake</software> and <software ContextAttributes="created">DfAnalyzer</software> in IoT/Edge devices, and Table <ref type="table" target="#tab_2">III</ref> shows the analysis of a feature provided by <software ContextAttributes="created">ProvLake</software>, which consists of grouping the captured data, i.e., messages, before transmitting them to the server, i.e., provenance system. In addition, we analyze how low-bandwidth networks may impact such data grouping strategy.</p><p>Results in Table <ref type="table" target="#tab_1">II</ref> show that both systems present high overhead (&gt;39%) for tasks with a duration of 0.5 seconds. For the remaining task duration, the overhead is still high (&gt;3%). Varying the number of attributes per task from 10 to 100 slightly increases the overhead.</p><p>Regarding Table <ref type="table" target="#tab_2">III</ref>, we observe low overhead (&lt;3%) when grouping 50 messages for a task duration of 0.5 seconds, and grouping from 20 messages for a task duration of 1 second, for 1Gbit bandwidth. While for 25Kbit bandwidth, we observe high overhead (&gt;43%) for all workloads.  </p></div>
<div><head>C. Design-level Limitations of Existing Systems</head><p>Table <ref type="table" target="#tab_3">IV</ref> presents the takeaways of our performance analysis and exposes the main limitations of the existing provenance systems. In summary, the evaluation shows that the existing systems present high overheads (&gt;3%) when capturing on IoT/Edge devices.</p><p><software ContextAttributes="created">ProvLake</software> and <software ContextAttributes="created">DfAnalyzer</software> rely on HTTP over TCP, instead of IoT-based messaging and transmission protocols such as MQTT <ref type="bibr" target="#b48">[49]</ref>, CoAP <ref type="bibr" target="#b49">[50]</ref>, AMQP <ref type="bibr" target="#b50">[51]</ref>, UDP <ref type="bibr" target="#b51">[52]</ref>, RPL <ref type="bibr" target="#b52">[53]</ref>, to cite a few. In resource-constrained devices, they make a relevant impact on performance, resource usage, and power consumption, as explored by existing works <ref type="bibr" target="#b53">[54]</ref>- <ref type="bibr" target="#b55">[56]</ref>.</p><p>The experiment results reinforce the need for capture approaches tailored to the constraints imposed by IoT devices. In addition, simplified data models to represent the provenance data help to reduce overheads.</p></div>
<div><head>IV. PROVLIGHT DESIGN</head><p>This section introduces <software ContextAttributes="created">ProvLight</software>, a tool <ref type="bibr" target="#b0">[1]</ref> for the efficient provenance data capture of Edge-to-Cloud workflows. Prov-Light is designed to capture provenance in IoT/Edge devices with low overhead in terms of capture time, CPU and memory usage, network usage, and power consumption.</p><p>Subsection IV-A presents the <software>ProvLight</software> provenance model. Next, the architectural details are given in Subsection IV-B, while Subsection IV-C describes its implementation. </p></div>
<div><head>PROV-IO</head><p>Does not send the captured data over the network to another machine hosting the provenance system. Instead, it periodically dumps the in-memory provenance graph to disk. This approach is not suitable for IoT/Edge devices.</p></div>
<div><head>Komadu</head><p><software>Komadu</software> does not follow a clear separation between a client library and a backend provenance server. Therefore, the capture and the processing of the captured information run in the same machine. This approach is not suitable for capturing on IoT/Edge devices.</p></div>
<div><head>A. Data Exchange Model</head><p><software ContextAttributes="created">ProvLight</software> provenance data exchange model follows the W3C PROV-DM <ref type="bibr" target="#b27">[28]</ref> recommendation. The goal is to have a data exchange schema (domain-agnostic PROV modeling) for capturing data in the IoT/Edge and making sure these captured data are compatible with W3C PROV-based workflow provenance systems, such as <software ContextAttributes="created">ProvLake</software>, <software ContextAttributes="created">DfAnalyzer</software>, PROV-IO, among many others. Table V describes <software ContextAttributes="created">ProvLight</software> classes and their relationships and maps them to PROV-DM core elements.</p><p>The main classes of our model are Workflow, Task, and Data. These classes are derived from the Agent, Activity, and Entity PROV-DM types, respectively. <software>ProvLight</software> classes aim to provide a simplified abstraction allowing users to track workflow (Workflow class), input and output parameters (Data class), and processing history (Task class).</p><p>The Workflow class may be used to refer to the application workflow (e.g., Federated Learning training). The Task class refers to the tasks executed in the workflow (e.g., each epoch or model update of the model training). Finally, the Data class represents the input data attributes and values (e.g., hyperparameters of the learning algorithm) or the output attributes (e.g., training time and loss of each epoch).</p><p>To represent PROV-DM relationships, we use the id attribute of each class. We link the Task and Data classes with the workflow they belong to (wasAssociatedWith and <software>wasAttributedTo</software>, respectively). The links between a Task and its respective Data inputs and the generated outputs are represented by the used and wasGeneratedBy relationships, respectively. The dependencies attribute in the Task class links tasks (wasInformedBy) with dependencies (e.g., task B starts after task A ends). Finally, the derivations attribute in the Data class links (wasDerivedFrom) chained data (e.g., data D A was used in task A to generate data D B ).  Defining such relations aims to provide users with the data processing history: Where did the data come from? How was the data transformed? and Who acted upon it? For instance, capturing provenance data of Federated Learning model training workflows may help users to interpret results. Tracking model training at runtime and fine-tuning hyperparameters is helpful, especially when the training process takes a long time.</p></div>
<div><head>B. Architecture</head><p>Figure <ref type="figure" target="#fig_2">3</ref> presents the <software ContextAttributes="created">ProvLight</software> architecture. It follows a client/server model where the server receives the captured data from clients and then translates it and sends it to provenance systems. We highlight that <software ContextAttributes="created">ProvLight</software> may integrate with existing provenance systems like <software ContextAttributes="created">DfAnalyzer</software>, <software ContextAttributes="created">ProvLake</software>, and PROV<software ContextAttributes="created">-IO</software>, among others (e.g., through their APIs and <software ContextAttributes="created">ProvLight</software> data translator), as a solution for capturing data of workflows running on IoT/Edge devices, as illustrated in Figure <ref type="figure" target="#fig_2">3</ref>. Table VI summarizes how the <software ContextAttributes="created">ProvLight</software> architecture design differs from the systems analyzed in Section III. This integration may be achieved by using: 1) Server: The <software ContextAttributes="created">ProvLight</software> server is composed of a broker and a provenance data translator. Both may be parallelized to scale the data capture for scenarios with various IoT/Edge devices. We describe the main roles of each one.</p><p>(i) Broker: refers to an MQTT-SN broker (MQTT for Sensor Networks <ref type="bibr" target="#b56">[57]</ref>). During workflow execution, clients subscribe to the broker and then start to transmit the captured data. Next, this data is forwarded to the provenance data translator, which is subscribed to the broker.</p><p>(ii) Provenance Data Translator: translates the captured data to the respective format used by the provenance system. The provenance data translator may be extended, by users, to translate to a particular data model of a provenance system. After translating, it sends the data to the provenance system service (e.g., typically available at an ip:port). It allows seamless integration with existing systems.</p><p>2) <software ContextAttributes="created">Client</software>: The <software ContextAttributes="created">ProvLight</software> client aims to efficiently capture provenance data on resource-limited devices. <software ContextAttributes="created">ProvLight</software> provides a client library that follows the W3C PROV-DM provenance model (as presented in Table <ref type="table" target="#tab_4">V</ref>). This library allows users to instrument their workflow code to decide what data to capture. A client is configured to transmit, at runtime, the captured data to the remote broker (e.g., ip:port). This allows users to track workflow execution at runtime (e.g., started and finished tasks, input and output data, etc.) through provenance systems supporting data ingestion at runtime.</p></div>
<div><head>C. Implementation 1) Server:</head><p>The Broker is implemented based on the <software ContextAttributes="created">Eclipse</software> RSMB server <ref type="bibr" target="#b57">[58]</ref> (Really Small Message Broker). RSMB builds on top of Mosquitto <ref type="bibr" target="#b58">[59]</ref> and implements the MQTT-SN protocol.</p><p>The Provenance Data Translator is a Python <software ContextAttributes="created">service</software> that may be extended to translate captured data (from the <software ContextAttributes="created">ProvLight</software> data format) to a particular provenance system (e.g., <software ContextAttributes="created">DfAnalyzer</software>, <software ContextAttributes="created">ProvLake</software>, <software ContextAttributes="created">Komadu</software>, etc.). In our repository <ref type="bibr" target="#b0">[1]</ref>, we provide an implementation showing how to translate from the <software ContextAttributes="created">ProvLight</software> data format to <software ContextAttributes="created">DfAnalyzer</software>. Such translation is possible since the aforementioned systems follow the W3C PROV-DM provenance model. For the translator-to-broker communication, we use the MQTT-SN Python client library <ref type="bibr" target="#b59">[60]</ref> based on <software ContextAttributes="created">Eclipse</software> RSMB. Finally, for the translator-to-provenancesystem communication, users are free to use any Python <software ContextAttributes="created">library</software> compatible with the provenance system (e.g., Requests <ref type="bibr" target="#b60">[61]</ref>).</p><p>2) <software>Client</software>: The <software ContextAttributes="created">ProvLight</software> client library is implemented in Python and provides a series of features targeting resourcelimited IoT/Edge devices:</p><p>• provenance data representation: simplified classes for provenance modeling that allow users to represent workflows, data derivations (e.g., input/output data from tasks) and tasks (e.g., status, dependencies, data derivations); • payload compression: compresses the bytes in captured data before transmitting over the network; and</p><p>• data capture grouping: allow users to optionally group data just from ended tasks, so users may still track at workflow runtime the tasks that have already started. As shown later in the evaluation section, grouping and compressing captured data help reduce capture time overhead, especially in IoT/Edge devices.</p><p>How to capture provenance data from the workflows? Listing 1 illustrates an example of application code instrumentation with the <software>ProvLight</software> library highlighted in blue color. Lines 6, 7, and 23 instantiate the workflow, start, and finalize it, respectively. Line 16 instantiates a task, linking it to the workflow, input data derivation, and dependent task. Lines 18 and 21 capture data from the initialization and finalization of the task. Before starting a task, line 17 instantiates Data and adds it as input data (line 18) to the task. Following the same logic, line 20 instantiates and adds the output data from the task. We highlight that the begin() and end() methods of Workflow and Task transmit the captured data over the network to the broker. Finally, line 19 is where the workflow task runs.</p></div>
<div><head>V. PROVENANCE CAPTURE OF EDGE-TO-CLOUD WORKFLOWS</head><p>This section presents the integration of <software ContextAttributes="created">ProvLight</software> as a key system in the <software ContextAttributes="created">E2Clab</software> <ref type="bibr" target="#b34">[35]</ref> framework for reproducible experimentation across the Edge-to-Cloud Continuum. This integration allows users to capture end-to-end provenance data of Edge-to-Cloud workflows. Figure <ref type="figure" target="#fig_4">4</ref> shows the extended <software ContextAttributes="created">E2Clab</software> architecture with the new components in the red color.</p></div>
<div><head>A. Provenance Manager</head><p>We design a new manager named Provenance Manager. Figure <ref type="figure" target="#fig_4">4</ref> illustrates the integrated view of the two main elements that compose the Provenance Manager:</p><p>(i) <software>ProvLight</software>: to efficiently capture provenance data of workflows running on IoT devices. It also allows users to capture provenance in Cloud/HPC environments. <software ContextAttributes="created">ProvLight</software> translates the captured data to the <software ContextAttributes="created">DfAnalyzer</software> data model.</p><p>(ii) <software>DfAnalyzer</software>: to store and query provenance captured by <software ContextAttributes="created">ProvLight</software> during workflow runtime (e.g., compare provenance of multiple workflow evaluations to understand how they impact on performance). Furthermore, it allows users to visualize dataflow specifications (i.e., data attributes of each dataset).</p><p>In addition to the characteristics of the provenance systems analyzed in Table <ref type="table" target="#tab_3">IV</ref>, and due to <software ContextAttributes="created">ProvLake</software> being proprietary within IBM, while <software ContextAttributes="created">DfAnalyzer</software> is open source <ref type="bibr" target="#b61">[62]</ref>, in this work we decide to use <software ContextAttributes="created">DfAnalyzer</software>. As the data capture component of <software ContextAttributes="created">DfAnalyzer</software> presents high overhead, we just use its data analysis and storage components. Finally, the Provenance Manager could replace <software ContextAttributes="created">DfAnalyzer</software> with other provenance systems (e.g., PROV-IO, <software ContextAttributes="created">Komadu</software>, etc.). It requires extending <software ContextAttributes="created">ProvLight</software> to translate the provenance data to the data model of the provenance system and using their APIs.</p></div>
<div><head>B. Provenance Capture</head><p>Through the <software>E2Clab</software> framework, users may easily enable provenance data capture across the Edge-to-Cloud continuum through simple configuration files, as illustrated in Listing 2. Listing 2 refers to the <software ContextAttributes="created">E2Clab</software> layers services.yaml configuration file used to setup the experimental environment (e.g., testbeds, services that compose workflows, etc.). Lines 2 and 3 request resources from Grid'5000 and FIT IoT LAB testbeds, respectively. Line 8 requests a single server (e.g., Federated Learning server) on the Cloud layer; while line 11 requests 64 clients (e.g., to train the model with their local data) on the Edge layer. Finally, line 4 setups the provenance data capture (the ProvenanceManager service). After that, users may instrument their application code to capture data, as presented in Listing 1.</p><p>The ProvenanceManager service starts a Docker <ref type="bibr" target="#b62">[63]</ref> container with the <software ContextAttributes="created">DfAnalyzer</software> provenance system and a <software ContextAttributes="created">ProvLight</software> container allowing clients to send their provenance data. <software ContextAttributes="created">Df-Analyze</software> exhibits at workflow runtime the captured data on its Web interface. The ProvenanceManager service may be easily plugged into other provenance systems by just using their Docker images and extending the provenance data translator. </p></div>
<div><head>VI. EVALUATION</head><p>We aim to answer the following research questions: how does <software>ProvLight</software> perform in IoT/Edge devices? while initially targeting resource-constrained Edge devices, can <software ContextAttributes="created">ProvLight</software> be efficiently used also in the Cloud? We answer these questions in subsections A-D and E, respectively, by comparing <software ContextAttributes="created">ProvLight</software> against <software ContextAttributes="created">ProvLake</software> and <software ContextAttributes="created">DfAnalyzer</software>.</p><p>The main performance metric is the capture overhead in terms of: (i) data capture time; (ii) CPU and memory usage; (iii) network usage; and (iv) power consumption. The experimental setup is the same as presented in Subsection III-A, with synthetic workloads generated based on the Federated Learning use case. The deployment is shown in Figure <ref type="figure" target="#fig_5">5</ref>. Results in Figure <ref type="figure" target="#fig_11">6</ref> are the mean of 10 runs with their 95% confidence interval.</p></div>
<div><head>A. Capture Time Overhead</head><p>Table VII presents the capture time overhead comparison for the 8 synthetic workloads. In summary, <software ContextAttributes="created">ProvLight</software> presents low capture overhead (&lt;3%) for all workloads analyzed. Regarding tasks with a duration of 3.5 seconds or more, the capture overhead of <software ContextAttributes="created">ProvLight</software> is below 0.5%. Varying the number of attributes per task from 10 to 100 does not significantly increase the capture time. We highlight that <software ContextAttributes="created">ProvLight</software> is about 37x and 26x faster than <software ContextAttributes="created">ProvLake</software> and <software ContextAttributes="created">DfAnalyzer</software>, respectively.  Similarly to Table <ref type="table" target="#tab_2">III</ref>, Table VIII zooms our analysis in order to understand the impact of bandwidth variations and the grouping strategy on the data capture time. Results show that, differently from <software ContextAttributes="created">ProvLake</software>, <software ContextAttributes="created">ProvLight</software> presents low capture time overhead in low-bandwidth scenarios for task durations of 0.5 and 1 second. We highlight that, especially in lowbandwidth scenarios (25Kbit), the <software ContextAttributes="created">ProvLight</software> grouping strategy presents low overhead (&lt;2%), while <software ContextAttributes="created">ProvLake</software> presents high overhead (&gt;43%), see Table <ref type="table" target="#tab_2">III</ref>.</p><p>Scalability analysis. Table <ref type="table" target="#tab_8">IX</ref> presents the capture time overhead of <software ContextAttributes="created">ProvLight</software> when scaling the number of IoT/Edge devices and considering 100 tasks of 0.5s each and 100 attributes per task. We scale the scenario with 8, 16, 32, and 64 devices capturing provenance data in parallel and sending the data to the cloud server. As illustrated in Figure <ref type="figure" target="#fig_5">5</ref>, each client sends its data to its respective topic in the Broker and we parallelized the number of translators accordingly. Lastly, provenance systems (i.e., <software ContextAttributes="created">DfAnalyzer</software> in our case) can handle parallel requests and store the provenance data in a database system (e.g., <software ContextAttributes="created">MonetDB</software> <ref type="bibr" target="#b63">[64]</ref> used in <software ContextAttributes="created">DfAnalyzer</software>). Results show that by scaling up to 64 devices, the capture overhead is low (&lt;3%) and does not significantly impact the capture time. This is expected because devices (clients) asynchronously publish their messages to their respective topics in the MQTT-SN Broker. For 8 and 64 devices, the capture time overhead is 1.54% and 1.57%, respectively.   </p></div>
<div><head>B. CPU and Memory Overhead</head></div>
<div><head>C. Network Usage Overhead</head><p>As presented in Figure <ref type="figure" target="#fig_11">6c</ref>, <software ContextAttributes="created">ProvLight</software> transmits about 2x less data than <software ContextAttributes="created">ProvLake</software> and <software ContextAttributes="created">DfAnalyzer</software>. <software ContextAttributes="created">ProvLight</software> network usage is around 3.7 KB/sec during data capture. The application layer protocol used in <software ContextAttributes="created">ProvLight</software> (e.g., MQTT-SN), which compresses captured data before transmitting it, especially for tasks with many attributes per task (e.g., 100 in this case), explains such difference (2x less data) when compared to the other capture approaches.</p></div>
<div><head>D. Power Consumption Overhead</head><p>Finally, results in Figure <ref type="figure" target="#fig_11">6d</ref> (error bar omitted because we use the maximum power consumption for capturing provenance data) show that <software ContextAttributes="created">ProvLight</software> power consumption overhead is 2.1x and 2.6x less than <software ContextAttributes="created">ProvLake</software> and <software ContextAttributes="created">Dfanalyzer</software>. We highlight that <software ContextAttributes="created">ProvLight</software> overhead is 2.58% (considered low, &lt;3%), against 5.46% (<software ContextAttributes="created">ProvLake</software>) and 6.8% (<software ContextAttributes="created">DfAnalyzer</software>). The power consumption (in watts) for capturing and transmitting the data is on average 1.43W, 1.47W, and 1.49W for <software ContextAttributes="created">ProvLight</software>, <software ContextAttributes="created">ProvLake</software>, and <software ContextAttributes="created">DfAnalyzer</software>, respectively.</p></div>
<div><head>E. Performance in Cloud Servers</head><p>We compare the capture time overhead of <software ContextAttributes="created">ProvLight</software> against <software ContextAttributes="created">ProvLake</software> and <software ContextAttributes="created">DfAnalyzer</software> in Cloud servers (i.e., data capture on a server <ref type="bibr" target="#b47">[48]</ref> available in Grid'5000). Experiment results in Table <ref type="table" target="#tab_9">X</ref> show that the three approaches present low capture overhead (&lt;3%) for all task durations. Similarly to IoT/Edge devices, <software ContextAttributes="created">ProvLight</software> also outperforms <software ContextAttributes="created">ProvLake</software> and <software ContextAttributes="created">DfAnalyzer</software> in Cloud servers. <software ContextAttributes="created">ProvLight</software> is 7x and 5x faster than <software ContextAttributes="created">ProvLake</software> and <software ContextAttributes="created">DfAnalyzer</software>, respectively. <software ContextAttributes="created">ProvLight</software> capture time overhead is very low (&lt;0.25%) for all task durations.     </p></div>
<div><head>VII. DISCUSSION</head><p>The integration of <software>ProvLight</software> as a key system within the <software ContextAttributes="created">E2Clab</software> framework exhibits a series of features that make <software ContextAttributes="created">E2Clab</software> a promising platform for future performance optimization of applications on the Edge-to-Cloud Continuum through efficient provenance capture and reproducible experiments.</p></div>
<div><head>A. ProvLight Design Choices Impact on Performance</head><p>As presented in Table <ref type="table" target="#tab_5">VI</ref>, the combination of <software ContextAttributes="created">ProvLight</software> design choices on the server and client sides contributed to the low capture overhead. The <software ContextAttributes="created">ProvLight</software> client library keeps the connection to the remote server open while capturing data (i.e., when capturing data from different tasks, the connection is reused). Additionally, the library is based on the publish/subscribe asynchronous communication model and it uses MQTT-SN (application layer protocol) over UDP (transport layer protocol) instead of HTTP over TCP. Despite TCP being more reliable (e.g., uses acknowledgment messages for data delivery), the <software ContextAttributes="created">ProvLight</software> client sends data using QoS level 2, which guarantees that each message is received exactly once by the recipient. Such design choices help to reduce connection overheads while data transmission handshakes/acknowledgments require less bandwidth.</p><p>Another important feature is that <software>ProvLight</software> compresses data (using binary format) before transmitting. Through preliminary experiments, we analyzed the performance trade-offs of compressing the data on the IoT/Edge devices to make sure it is worth adding that feature. The time required to compress data (e.g., tasks with 100 attributes) on the edge device is negligible, around 0.001s on average.</p><p>Our analysis considered low-bandwidth scenarios and also the data grouping strategy, resulting in fewer and larger messages to reduce the number of transmissions. We also observe that the overhead of decompressing and translating such data on the Cloud server is negligible, around 0.005s.</p><p>Data communication is key to performance efficiency in IoT/Edge workloads, especially for low bandwidth networks. <software ContextAttributes="created">ProvLight</software> design choices such as simplified capture library for provenance data exchange (see Table <ref type="table" target="#tab_4">V</ref>), asynchronous MQTT-SN over UDP, data grouping, and data compression, explain the positive effects on performance and costs (e.g., lower overheads in terms of data capture time, and CPU, memory, network usage, and energy consumption).</p><p>In summary, the lightweight asynchronous protocol (MQTT-SN over UDP) has a major impact on the capture time overhead, energy consumption, and CPU and network usage. Our simplified data model has a major impact on memory consumption, and it helps to reduce even more the capture time overhead and CPU usage by 1.7% and 1.4%, respectively.</p></div>
<div><head>B. Impact of ProvLight on Real-life Use-Cases</head><p>To illustrate how real-life use cases could benefit from <software ContextAttributes="created">ProvLight</software> and its integration in the <software ContextAttributes="created">E2Clab</software> framework, we consider the training of Neural Networks presented in <ref type="bibr" target="#b14">[15]</ref> and <ref type="bibr" target="#b12">[13]</ref>. In these articles, the authors use the storage and query components of <software ContextAttributes="created">DfAnalyzer</software> to store captured data during model training executed on Cloud/HPC infrastructure and then query the data. They demonstrate how provenance data may be used to answer queries like the ones we presented in Section I.</p><p>Since modern AI workflows are being executed on hybrid infrastructures, we may instantiate this use-case (Neural Network training on the Cloud/HPC) to the context of hybrid Edge-to-Cloud Federated Learning Neural Network training. In this hybrid context, the model is now trained on various resource-limited Edge devices. Thanks to the efficient capture approach of <software>ProvLight</software>, users may still track the model training by capturing provenance data. Without <software ContextAttributes="created">ProvLight</software>, capturing provenance data of this use-case on the IoT/Edge is prohibitive due to the high overheads imposed by the existing approaches, as presented in Section III.</p><p>Finally, thanks to the <software>E2Clab</software> framework, users may easily set up the Federated Learning Neural Network training and deploy it on distributed Edge devices (to train the model) and on the Cloud server (to update the global model). Furthermore, the <software ContextAttributes="created">E2Clab</software> Provenance Manager allows users to store data captured with <software ContextAttributes="created">ProvLight</software> and query them using <software ContextAttributes="created">DfAnalyzer</software>. Therefore, through the <software ContextAttributes="created">E2Clab</software> Provenance Manager, users may answer the same queries mentioned earlier. We highlight that this Neural Network use case is just one example from various that could benefit from this work.</p></div>
<div><head>C. Integration with Existing Systems</head><p><software>ProvLight</software> is designed to be easily integrated with existing provenance systems (e.g., <software ContextAttributes="created">ProvLake</software>, <software ContextAttributes="created">DfAnalyzer</software>, PROV-IO, among others) and workflow management systems and deployment frameworks (e.g., <software ContextAttributes="created">Pegasus</software>, <software ContextAttributes="created">E2Clab</software>, among others). Such integration would enable these systems to capture provenance data (with low capture overheads) in IoT/Edge devices.</p><p>As presented in Subsection IV-B, this is possible thanks to the <software>ProvLight</software> provenance data translator. It translates from the <software ContextAttributes="created">ProvLight</software> data format to the data format of the target system. This requires users to extend the <software ContextAttributes="created">ProvLight</software> translator. In this work, we demonstrate in Section V: (i) the integration of <software ContextAttributes="created">ProvLight</software> with the open-source <software ContextAttributes="created">DfAnalyzer</software> provenance system as a solution for provenance capture on the IoT/Edge; and then (ii) we integrate this capture solution within the <software ContextAttributes="created">E2Clab</software> framework (the Provenance Manager) to enable provenance capture of Edge-to-Cloud workflows.</p></div>
<div><head>D. Reproducibility and Artifact Availability</head><p>The experimental evaluations presented in this work follow a rigorous methodology <ref type="bibr" target="#b34">[35]</ref> to support reproducible Edgeto-Cloud experiments on large-scale testbeds (e.g., Grid'5000 and FIT IoT LAB used in our experiments). This guided us to systematically define the experimental environment (e.g., computing resources, services/systems, network, and application execution) through well-structured configuration files. The experiment artifacts and results are available at <ref type="bibr" target="#b46">[47]</ref>.</p></div>
<div><head>VIII. RELATED WORK</head><p>Tanaka et al. <ref type="bibr" target="#b7">[8]</ref> extend the <software ContextAttributes="created">Pegasus</software> <ref type="bibr" target="#b64">[65]</ref> Workflow Management System to support Edge-to-Cloud workflows. The paper explores performance trade-offs in managing and executing Edge-to-Cloud workloads. <software ContextAttributes="created">Pegasus</software> provides provenance data collection capabilities to capture performance metrics during workflow execution. We highlight that <software ContextAttributes="created">Pegasus</software> (and other systems like <software ContextAttributes="created">Kepler</software> <ref type="bibr" target="#b65">[66]</ref>, <software ContextAttributes="created">Taverna</software> <ref type="bibr" target="#b66">[67]</ref>, etc.) explores the predefined provenance capture approach. <software ContextAttributes="created">Pegasus</software> automatically logs provenance data about the local execution of the application codes, such as launching them and capturing the exit status and runtime information <ref type="bibr" target="#b67">[68]</ref>. While <software ContextAttributes="created">ProvLight</software> and the systems we compared with (see Table <ref type="table" target="#tab_3">IV</ref>) explore the userdefined capture approach, i.e., the user defines what to capture by workflow code instrumentation. Furthermore, unlike Prov-Light, <software ContextAttributes="created">Pegasus</software> does not explore IoT/Edge protocols to transfer the captured data nor provides features like simplified data models and compressing and grouping messages. This may result in higher overheads compared to <software ContextAttributes="created">ProvLight</software>, as presented in Section III. Finally, the authors do not analyze the energy consumption of their capture approach.</p><p>A provenance collection framework for the IoT/Edge devices is proposed in <ref type="bibr" target="#b68">[69]</ref>. The proposed framework follows PROV-DM recommendations and provides provenance collection capabilities for IoT/Edge devices. Unlike our work, the authors do not validate their approach on real-life Edge devices. Also, no performance evaluations are presented to understand capture overheads.</p><p>Genoma, a distributed provenance-as-a-service system across IoT/Edge devices and Cloud servers, is proposed in <ref type="bibr" target="#b69">[70]</ref>. Genoma transmits provenance data to the Cloud using the MQTT protocol. Data is transmitted based on storage availability on the Edge device and the frequency of data communication. The authors do not evaluate the performance of Genoma. Capture overheads regarding capture time, network usage, energy consumption, and CPU and memory usage are left for future work. In contrast, <software ContextAttributes="created">ProvLight</software> is evaluated on all the metrics mentioned above.</p></div>
<div><head>IX. CONCLUSION</head><p>The integration of <software>ProvLight</software> within <software ContextAttributes="created">E2Clab</software> makes the latter, to the best of our knowledge, the first framework to support the end-to-end provenance capture of Edge-to-Cloud workflows with low overheads across the Computing Continuum. <software ContextAttributes="created">Prov-Light</software> and <software ContextAttributes="created">E2Clab</software> are available as open-source tools. In future work, we will enable the provenance capture of workflows developed in C/C++ (not only in Python) and secure the data transmission from the Edge devices to the provenance system.</p></div><figure xml:id="fig_1"><head>b)</head><label /><figDesc>Performance metrics.:</figDesc></figure>
<figure xml:id="fig_2"><head>Fig. 3 :</head><label>3</label><figDesc>Fig. 3: ProvLight Architecture.</figDesc></figure>
<figure xml:id="fig_3"><head>1 15 d a t a i d += 1 16 t</head><label>1516</label><figDesc>from p r o v l i g h t i m p o r t Workflow , Task , D a t a 2 a t t r i b u t e s = 100 3 c h a i n e d t r a n s f o r m a t i o n s = 5 4 n u m b e r o f t a s k s = 100 5 # A p p l i c a t i o n Workflow 6 w o r k f l o w = Workflow ( 1 ) 7 w o r k f l o w . b e g i n ( ) 8 # T a s k s and d a t a d e r i v a t i o n s 9 d a t a i d = 0 10 p r e v i o u s t a s k = [ ] 11 i n d a t a = { ' i n ' : [ 1 f o r i n r a n g e ( a t t r i b u t e s ) ]} 12 o u t d a t a = { ' o u t ' : [ 2 f o r i n r a n g e ( a t t r i b u t e s ) ]} 13 f o r t r a n s f i d i n r a n g e ( c h a i n e d t r a n s f o r m a t i o n s ) : 14 f o r t a s k i d i n r a n g e ( i n t ( n u m b e r o f t a s k s / c h a i n e d t r a n s f o r m a t i o n s ) ) : a s k = Task ( t r a n s f i d -t a s k i d , workflow , t r a n s f i d , d e p e n d e n c i e s = p r e v i o u s t a s k ) 17 d a t a i n = D a t a ( i n { d a t a i d } , w o r k f l o w . i d , i n d a t a ) 18 t a s k . b e g i n ( [ d a t a i n ] ) 19 # ### ADD YOUR TASK HERE #### 20 d a t a o u t = D a t a ( o u t { d a t a i d } , w o r k f l o w . i d , o u t d a t a ) 21 t a s k . end ( [ d a t a o u t ] ) 22 p r e v i o u s t a s k = [ t a s k . i d ] 23 w o r k f l o w . end ( ) Listing 1: ProvLight: user-defined provenance capture.</figDesc></figure>
<figure xml:id="fig_4"><head>Fig. 4 :</head><label>4</label><figDesc>Fig. 4: Extended E2Clab: Provenance Data Manager.</figDesc></figure>
<figure xml:id="fig_5"><head>Fig. 5 :</head><label>5</label><figDesc>Fig. 5: Experimental setup.</figDesc></figure>
<figure xml:id="fig_6"><head>Figures</head><label /><figDesc>Figures 6a and 6b present the CPU and memory overhead for capturing provenance data with ProvLake, DfAnalyzer, and ProvLight (from left to right). Regarding the CPU overhead,</figDesc></figure>
<figure xml:id="fig_11"><head>Fig. 6 :</head><label>6</label><figDesc>Fig.6: Provenance data capture overhead with respect to: CPU, memory, network usage, and power consumption.</figDesc><graphic coords="10,433.39,50.54,131.51,98.63" type="bitmap" /></figure>
<figure type="table" xml:id="tab_0"><head>TABLE I :</head><label>I</label><figDesc>Synthetic workload configurations.</figDesc><table /></figure>
<figure type="table" xml:id="tab_1"><head>TABLE II :</head><label>II</label><figDesc>Capture overhead of ProvLake and DfAnalyzer.</figDesc><table><row><cell /><cell>overhead</cell><cell>low</cell><cell>high</cell><cell /><cell /></row><row><cell /><cell>level</cell><cell>3%</cell><cell>&gt;3%</cell><cell /><cell /></row><row><cell>attributes per task</cell><cell>Provenance System</cell><cell /><cell cols="2">Capture Overhead (%)</cell><cell /></row><row><cell>10</cell><cell>ProvLake</cell><cell>56.9% ±0.08</cell><cell>29.9% ±0.29</cell><cell>8.56% ±0.01</cell><cell>6.02% ±0.01</cell></row><row><cell>10</cell><cell>DfAnalyzer</cell><cell>39.8% ±0.06</cell><cell>21.2% ±0.34</cell><cell>6.12% ±0.07</cell><cell>4.26% ±0.01</cell></row><row><cell>100</cell><cell>ProvLake</cell><cell>57.3% ±0.10</cell><cell>30.1% ±0.41</cell><cell>8.57% ±0.01</cell><cell>6.04% ±0.04</cell></row><row><cell>100</cell><cell>DfAnalyzer</cell><cell>40.5% ±0.20</cell><cell>21.3% ±0.06</cell><cell>6.12% ±0.01</cell><cell>4.31% ±0.01</cell></row><row><cell /><cell>task dur. (s)</cell><cell>0.5</cell><cell>1</cell><cell>3.5</cell><cell>5</cell></row></table></figure>
<figure type="table" xml:id="tab_2"><head>TABLE III :</head><label>III</label><figDesc>ProvLake: impact of bandwidth and grouping strategy on the capture overhead.</figDesc><table><row><cell cols="3"># of messages grouped Bandwidth 1Gbit</cell><cell cols="2">Bandwidth 25Kbit</cell></row><row><cell>0</cell><cell>57.3% ±0.10</cell><cell>30.1% ±0.27</cell><cell>321% ±1.05</cell><cell>161% ±1.14</cell></row><row><cell>10</cell><cell>6.83% ±0.02</cell><cell>3.58% ±0.20</cell><cell>102.5% ±3.89</cell><cell>49.8% ±2.92</cell></row><row><cell>20</cell><cell>3.87% ±0.01</cell><cell>1.99% ±0.01</cell><cell>100.8% ±3.78</cell><cell>51.16% ±1.03</cell></row><row><cell>50</cell><cell>2.37% ±0.01</cell><cell>1.24% ±0.01</cell><cell>95.04% ±0.10</cell><cell>43.23% ±0.28</cell></row><row><cell>task duration (s)</cell><cell>0.5</cell><cell>1</cell><cell>0.5</cell><cell>1</cell></row></table></figure>
<figure type="table" xml:id="tab_3"><head>TABLE IV :</head><label>IV</label><figDesc>Limitations of existing provenance systems.</figDesc><table><row><cell>System</cell><cell>Limitation</cell></row><row><cell>DfAnalyzer</cell><cell>Presents high (&gt;3%) capture overhead for all synthetic workloads.</cell></row><row><cell /><cell>Presents high (&gt;3%) overhead for all work-</cell></row><row><cell /><cell>loads. However, ProvLake allows grouping</cell></row><row><cell>ProvLake</cell><cell>captured data to reduce transmission fre-quency, enabling lower overhead, but it still</cell></row><row><cell /><cell>suffers high overhead in low bandwidth net-</cell></row><row><cell /><cell>works.</cell></row></table></figure>
<figure type="table" xml:id="tab_4"><head>TABLE V :</head><label>V</label><figDesc>The ProvLight provenance data exchange model follows PROV-DM.</figDesc><table><row><cell>PROV-DM</cell><cell>ProvLight</cell><cell>ProvLight</cell><cell /><cell cols="2">ProvLight Attribute Description</cell><cell>ProvLight</cell></row><row><cell>Type</cell><cell>Class</cell><cell cols="2">Class Attributes</cell><cell cols="2">and PROV-DM Relationships</cell><cell>Class Description</cell></row><row><cell>Agent</cell><cell>Workflow</cell><cell>id</cell><cell /><cell>Workflow id.</cell><cell>Refers to application workflows.</cell></row><row><cell /><cell /><cell>id</cell><cell /><cell>Task id.</cell></row><row><cell /><cell /><cell>workflow</cell><cell /><cell cols="2">Links tasks with the workflow they belong to (wasAssociatedWith).</cell><cell>Represents the processing</cell></row><row><cell>Activity</cell><cell>Task</cell><cell>dependencies data</cell><cell /><cell cols="2">Dependencies between tasks (wasInformedBy). Data used (used) and generated (wasGeneratedBy) by a task.</cell><cell>steps of tasks (and their dependencies) that compose</cell></row><row><cell /><cell /><cell>time</cell><cell /><cell cols="2">Task start and end time.</cell><cell>workflows.</cell></row><row><cell /><cell /><cell>status</cell><cell /><cell cols="2">Task status: running or finished.</cell></row><row><cell>Entity</cell><cell>Data</cell><cell>id workflow id derivations attributes</cell><cell /><cell cols="2">Data id. Links data with the workflow they belong to (wasAttributedTo). Links chained data (wasDerivedFrom). Data attributes and values.</cell><cell>Represents data derivations along the workflow execution.</cell></row><row><cell>Server</cell><cell /><cell>broker translator</cell><cell cols="2">Client library</cell><cell>IoT/Edge device</cell></row><row><cell /><cell cols="2">HPC/Cloud</cell><cell /><cell cols="2">IoT/Edge</cell></row><row><cell cols="2">Provenance</cell><cell /><cell /><cell cols="2">Provlight</cell></row><row><cell cols="2">Systems</cell><cell /><cell /><cell cols="2">Client</cell></row><row><cell /><cell /><cell cols="2">ProvLight</cell><cell cols="2">Library</cell></row><row><cell cols="2">ProvLake</cell><cell cols="2">Server</cell><cell /></row><row><cell cols="2">DfAnalyzer</cell><cell cols="2">services</cell><cell /></row><row><cell cols="2">PROV-IO</cell><cell /><cell /><cell /></row><row><cell cols="2">Komadu …</cell><cell>Provenance data translator</cell><cell>broker</cell><cell /><cell>…</cell></row><row><cell>others</cell><cell /><cell /><cell /><cell /></row></table></figure>
<figure type="table" xml:id="tab_5"><head>TABLE VI :</head><label>VI</label><figDesc>How does ProvLight differ from state-of-the-art systems in terms of data capture?</figDesc><table><row><cell /><cell>ProvLight</cell><cell>DfAnalyzer</cell><cell>ProvLake</cell></row><row><cell>application layer protocol</cell><cell>MQTT-SN QoS 2: Exactly once</cell><cell>HTTP 1.1</cell><cell>HTTP 1.1</cell></row><row><cell>transport layer protocol</cell><cell>UDP</cell><cell>TCP</cell><cell>TCP</cell></row><row><cell>Communication</cell><cell>Publish/</cell><cell>Request/</cell><cell>Request/</cell></row><row><cell>model</cell><cell>Subscribe</cell><cell>Response</cell><cell>Response</cell></row><row><cell>Server side</cell><cell>MQTT-SN Broker</cell><cell>HTTP Server</cell><cell>HTTP Server</cell></row><row><cell /><cell>provenance data</cell><cell /><cell /></row><row><cell>Client side features</cell><cell>representation &amp; payload compression &amp;</cell><cell>N/A</cell><cell>grouping data captured</cell></row><row><cell /><cell>grouping data captured</cell><cell /><cell /></row><row><cell>Provenance data model</cell><cell>PROV-DM</cell><cell>PROV-DM</cell><cell>PROV-DM</cell></row><row><cell>Capture library language</cell><cell>Python</cell><cell>Python, C++</cell><cell>Python</cell></row></table></figure>
<figure type="table" xml:id="tab_6"><head>TABLE VII :</head><label>VII</label><figDesc>ProvLight: capture overhead in IoT/Edge devices. Refer to Table II to compare with DfAnalyzer and ProvLake.</figDesc><table><row><cell>Attributes per task</cell><cell /><cell cols="2">Capture Overhead (%)</cell><cell /></row><row><cell>10</cell><cell>1.45% ±0.01</cell><cell>1.02% ±0.01</cell><cell>0.31% ±0.01</cell><cell>0.23% ±0.01</cell></row><row><cell>100</cell><cell>1.54% ±0.01</cell><cell>1.11% ±0.01</cell><cell>0.37% ±0.01</cell><cell>0.29% ±0.01</cell></row><row><cell>task duration (s)</cell><cell>0.5</cell><cell>1</cell><cell>3.5</cell><cell>5</cell></row></table></figure>
<figure type="table" xml:id="tab_7"><head>TABLE VIII :</head><label>VIII</label><figDesc>ProvLight: impact of bandwidth and grouping strategy on the capture overhead. Refer to TableIIIto compare with ProvLake.</figDesc><table><row><cell cols="3"># of messages grouped Bandwidth 1Gbit</cell><cell cols="2">Bandwidth 25Kbit</cell></row><row><cell>0</cell><cell>1.54% ±0.01</cell><cell>1.10% ±0.01</cell><cell>1.56% ±0.01</cell><cell>1.04% ±0.01</cell></row><row><cell>10</cell><cell>1.37% ±0.01</cell><cell>0.75% ±0.01</cell><cell>1.37% ±0.01</cell><cell>0.74% ±0.01</cell></row><row><cell>20</cell><cell>1.32% ±0.01</cell><cell>0.72% ±0.01</cell><cell>1.34% ±0.01</cell><cell>0.73% ±0.01</cell></row><row><cell>50</cell><cell>1.31% ±0.01</cell><cell>0.72% ±0.01</cell><cell>1.31% ±0.01</cell><cell>0.72% ±0.01</cell></row><row><cell>task duration (s)</cell><cell>0.5</cell><cell>1</cell><cell>0.5</cell><cell>1</cell></row></table></figure>
<figure type="table" xml:id="tab_8"><head>TABLE IX :</head><label>IX</label><figDesc>ProvLight scalability analysis.</figDesc><table><row><cell>System</cell><cell /><cell cols="2">Capture Overhead (%)</cell><cell /></row><row><cell>ProvLight</cell><cell>1.54% ±0.01</cell><cell>1.54% ±0.01</cell><cell>1.56% ±0.01</cell><cell>1.57% ±0.02</cell></row><row><cell># of devices</cell><cell>8</cell><cell>16</cell><cell>32</cell><cell>64</cell></row></table></figure>
<figure type="table" xml:id="tab_9"><head>TABLE X :</head><label>X</label><figDesc>Capture overhead in Cloud servers.</figDesc><table><row><cell /><cell>System</cell><cell /><cell cols="2">Capture Overhead (%)</cell><cell /></row><row><cell>100</cell><cell>ProvLake</cell><cell>1.71% ±0.03</cell><cell>0.92% ±0.01</cell><cell>0.34% ±0.01</cell><cell>0.26% ±0.01</cell></row><row><cell>attributes per task</cell><cell>DfAnalyzer</cell><cell>1.17% ±0.02</cell><cell>0.63% ±0.01</cell><cell>0.25% ±0.01</cell><cell>0.21% ±0.01</cell></row><row><cell /><cell>ProvLight</cell><cell>0.24% ±0.01</cell><cell>0.17% ±0.01</cell><cell>0.12% ±0.01</cell><cell>0.11% ±0.01</cell></row><row><cell /><cell>task duration (s)</cell><cell>0.5</cell><cell>1</cell><cell>3.5</cell><cell>5</cell></row><row><cell cols="6">ProvLight uses 7x and 5x less CPU than ProvLake and</cell></row><row><cell cols="6">DfAnalyzer, respectively. Capturing with ProvLight, the CPU</cell></row><row><cell cols="6">overhead is low (&lt;3%), and CPU usage varies between 1.7%</cell></row><row><cell cols="6">and 2%. Regarding the memory overhead, ProvLight memory</cell></row><row><cell cols="6">usage is &lt;4%. It uses about 2x less memory than ProvLake</cell></row><row><cell cols="2">and DfAnalyzer.</cell><cell /><cell /><cell /><cell /></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>ACKNOWLEDGMENTS</head><p>This work was funded by <rs type="funder">Inria</rs> through the <rs type="funder">HPC-BigData Inria Challenge (IPL)</rs>, by the <rs type="funder">French ANR OverFlow</rs> project (<rs type="grantNumber">ANR-15-CE25-0003</rs>), and the <rs type="funder">HPDaSc</rs> associate team with <rs type="person">Brazil</rs>. <rs type="person">Marta Mattoso</rs> and <rs type="person">Débora Pina</rs> are funded by <rs type="funder">CNPq</rs> and <rs type="funder">FAPERJ</rs><rs type="person">. Renan</rs> is at the <rs type="institution">Oak Ridge Leadership Computing Facility</rs> at the <rs type="institution">Oak Ridge National Laboratory</rs>, which is supported by the <rs type="funder">Office of Science of the U.S. Department of Energy</rs> under Contract No. <rs type="grantNumber">DE-AC05-00OR22725</rs>. Experiments presented in this paper were carried out using the Grid'5000 and <rs type="institution">FIT IoT LAB</rs> testbeds, supported by a scientific interest group hosted by several <rs type="funder">Universities</rs> and organizations.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_CtBjUYq">
					<idno type="grant-number">ANR-15-CE25-0003</idno>
				</org>
				<org type="funding" xml:id="_BRZFTXR">
					<idno type="grant-number">DE-AC05-00OR22725</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<ptr target="https://gitlab.inria.fr/provlight/provlight" />
		<title level="m">Provlight tool: Provenance capture for iot/edge devices</title>
		<imprint>
			<date type="published" when="2023-01">2023, jan</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">E2clab source code</title>
		<ptr target="https://gitlab.inria.fr/E2Clab/e2clab" />
		<imprint>
			<date type="published" when="2019-01">2019. jan</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Distributed intelligence on the Edge-to-Cloud Continuum: A systematic literature review</title>
		<author>
			<persName><forename type="first">D</forename><surname>Rosendo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Costan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Valduriez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Antoniu</surname></persName>
		</author>
		<ptr target="https://hal.archives-ouvertes.fr/hal-03654722" />
	</analytic>
	<monogr>
		<title level="j">Journal of Parallel and Distributed Computing</title>
		<imprint>
			<biblScope unit="volume">166</biblScope>
			<biblScope unit="page" from="71" to="94" />
			<date type="published" when="2022-08">Aug. 2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Edge intelligence: The confluence of edge computing and artificial intelligence</title>
		<author>
			<persName><forename type="first">S</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Dustdar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">Y</forename><surname>Zomaya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Internet of Things Journal</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="7457" to="7469" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Big data and extremescale computing: Pathways to convergence -toward a shaping strategy for a future software and data ecosystem for scientific inquiry</title>
		<author>
			<persName><forename type="first">M</forename><surname>Asch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Moore</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Badia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Beck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Beckman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Bidot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Bodin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Cappello</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Choudhary</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>De Supinski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The International Journal of High Performance Computing Applications</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="435" to="479" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<ptr target="https://www.etp4hpc.eu/sra.html" />
		<title level="m">Etp4hpc strategic research agenda</title>
		<imprint>
			<date type="published" when="2020-04-29">April 29, 2020</date>
		</imprint>
	</monogr>
	<note>ETP4HPC</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Combining heuristics to optimize and scale the placement of iot applications in the fog</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Etchevers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Letondeur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Lebre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Coupaye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Desprez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE/ACM 11th International Conference on Utility and Cloud Computing (UCC)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2018">2018. 2018</date>
			<biblScope unit="page" from="153" to="163" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Automating edge-to-cloud workflows for science: Traversing the edge-to-cloud continuum with pegasus</title>
		<author>
			<persName><forename type="first">R</forename><surname>Tanaka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Papadimitriou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">C</forename><surname>Viswanath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Lyons</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Thareja</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Esquivel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Deelman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2022 22nd IEEE International Symposium on Cluster, Cloud and Internet Computing (CCGrid)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="826" to="833" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Reproducible Performance Optimization of Complex Applications on the Edge-to-Cloud Continuum</title>
		<author>
			<persName><forename type="first">D</forename><surname>Rosendo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Costan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Antoniu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Simonin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-C</forename><surname>Lombardo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Joly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Valduriez</surname></persName>
		</author>
		<ptr target="https://hal.archives-ouvertes.fr/hal-03310540" />
	</analytic>
	<monogr>
		<title level="m">Cluster 2021 -IEEE International Conference on Cluster Computing</title>
		<meeting><address><addrLine>Portland, OR, United States</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2021-09">Sep. 2021</date>
			<biblScope unit="page" from="23" to="34" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Coding the computing continuum: Fluid function execution in heterogeneous computing environments</title>
		<author>
			<persName><forename type="first">R</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Baughman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Chard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Babuji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Foster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Chard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2021 IEEE International Parallel and Distributed Processing Symposium Workshops (IPDPSW)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="66" to="75" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Encyclopedia of database systems</title>
		<author>
			<persName><forename type="first">L</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">T</forename><surname>Özsu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
			<publisher>Springer</publisher>
			<biblScope unit="volume">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Keeping track of user steering actions in dynamic workflows</title>
		<author>
			<persName><forename type="first">R</forename><surname>Souza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Silva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Camata</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">L G A</forename><surname>Coutinho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Valduriez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mattoso</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Future Generation Computer Systems</title>
		<imprint>
			<biblScope unit="volume">99</biblScope>
			<biblScope unit="page" from="624" to="643" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Capturing provenance to improve the model training of pinns: first handon experiences with grid5000</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Silva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Pina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Kunstmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Oliveira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Valduriez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">L</forename><surname>Coutinho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mattoso</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CILAMCE-PANACM 2021-Proceedings of the joint XLII Ibero-Latin-American Congress on Computational Methods in Engineering and III Pan-American Congress on Computational Mechanics</title>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="1" to="7" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Workflow provenance in the lifecycle of scientific machine learning</title>
		<author>
			<persName><forename type="first">R</forename><surname>Souza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">G</forename><surname>Azevedo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Lourenc ¸o</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Soares</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Thiago</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Brandão</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Civitarese</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Brazil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Moreno</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Valduriez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mattoso</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Cerqueira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A S</forename><surname>Netto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Concurrency and Computation: Practice and Experience</title>
		<imprint>
			<biblScope unit="volume">6544</biblScope>
			<biblScope unit="page" from="1" to="21" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Provenance supporting hyperparameter analysis in deep neural networks</title>
		<author>
			<persName><forename type="first">D</forename><surname>Pina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Kunstmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Oliveira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Valduriez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mattoso</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Provenance and Annotation of Data and Processes: 8th and 9th International Provenance and Annotation Workshop, IPAW 2020+ IPAW 2021</title>
		<meeting><address><addrLine>Virtual Event</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2021">July 19-22, 2021. 2021</date>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="20" to="38" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A survey on provenance: What for? what form? what from?</title>
		<author>
			<persName><forename type="first">M</forename><surname>Herschel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Diestelkämper</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Ben Lahmar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The VLDB Journal</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="881" to="906" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Efficient runtime capture of multiworkflow data using provenance</title>
		<author>
			<persName><forename type="first">R</forename><surname>Souza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Azevedo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Thiago</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Soares</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Nery</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Netto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Vital</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Cerqueira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Valduriez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mattoso</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2019 15th International Conference on eScience (eScience)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="359" to="368" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Dfanalyzer: runtime dataflow analysis tool for computational science and engineering applications</title>
		<author>
			<persName><forename type="first">V</forename><surname>Silva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Campos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Guedes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Camata</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Oliveira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">L</forename><surname>Coutinho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Valduriez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mattoso</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SoftwareX</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page">100592</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">The next 5 years: what opportunities should the database community seize to maximize its impact?</title>
		<author>
			<persName><forename type="first">M</forename><surname>Balazinska</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Chaudhuri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ailamaki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Freire</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Krishnamurthy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Stonebraker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 ACM SIGMOD International Conference on Management of Data</title>
		<meeting>the 2020 ACM SIGMOD International Conference on Management of Data</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="411" to="414" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">F</forename><surname>Da Silva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Badia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Bala</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Bard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P.-T</forename><surname>Bremer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Buckley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Caino-Lores</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Chard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Goble</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Jha</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2304.00019</idno>
		<title level="m">Workflows community summit 2022: A roadmap revolution</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Prov-io: An i/ocentric provenance framework for scientific data on hpc systems</title>
		<author>
			<persName><forename type="first">R</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Byna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 31st International Symposium on High-Performance Parallel and Distributed Computing</title>
		<meeting>the 31st International Symposium on High-Performance Parallel and Distributed Computing</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="213" to="226" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">An approach to standalone provenance systems for big social provenance data</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Tas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Baeth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Aktas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2016 12th International Conference on Semantics, Knowledge and Grids (SKG)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="9" to="16" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Fit iot-lab: A large scale open experimental iot testbed</title>
		<author>
			<persName><forename type="first">C</forename><surname>Adjih</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Baccelli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Fleury</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Harter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Mitton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Noel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Pissard-Gibollet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Saint-Marcel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Schreiner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Vandaele</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2015 IEEE 2nd World Forum on Internet of Things (WF-IoT)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="459" to="464" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Grid'5000: A Large Scale And Highly Reconfigurable Experimental Grid Testbed</title>
		<author>
			<persName><forename type="first">R</forename><surname>Bolze</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Cappello</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Caron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Dayde</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Desprez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Jeannot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Jégou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lanteri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Leduc</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Melab</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Mornet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Namyst</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Primet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Quétier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Richard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E.-G</forename><surname>Talbi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Touche</surname></persName>
		</author>
		<ptr target="https://hal.inria.fr/hal-00684943" />
	</analytic>
	<monogr>
		<title level="j">International Journal of High Performance Computing Applications</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="481" to="494" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Proml: A decentralised platform for provenance management of machine learning software systems</title>
		<author>
			<persName><forename type="first">N</forename><surname>Khoi Tran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Sabir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Babar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Abolhasan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lipman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Software Architecture: 16th European Conference, ECSA 2022</title>
		<meeting><address><addrLine>Prague, Czech Republic</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2022">September 19-23, 2022. 2022</date>
			<biblScope unit="page" from="49" to="65" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Active provenance for data-intensive workflows: engaging users and developers</title>
		<author>
			<persName><forename type="first">A</forename><surname>Spinuso</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Atkinson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Magnoni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2019 15th International Conference on eScience (eScience)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="560" to="569" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Survey on the analysis of user interactions and visualization provenance</title>
		<author>
			<persName><forename type="first">K</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ottley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Walchshofer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Streit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wenskovitch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics Forum</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="757" to="783" />
			<date type="published" when="2020">2020</date>
			<publisher>Wiley Online Library</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Prov-dm: The prov data model</title>
		<author>
			<persName><forename type="first">K</forename><surname>Belhajjame</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>B'far</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Cheney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Coppens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Cresswell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Gil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Groth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Klyne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Lebo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Mccusker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">W3C Recommendation</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="15" to="16" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">The w3c prov family of specifications for modelling provenance metadata</title>
		<author>
			<persName><forename type="first">P</forename><surname>Missier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Belhajjame</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Cheney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 16th International Conference on Extending Database Technology</title>
		<meeting>the 16th International Conference on Extending Database Technology</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="773" to="776" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<author>
			<persName><forename type="first">N</forename><surname>Garg</surname></persName>
		</author>
		<title level="m">Apache kafka</title>
		<meeting><address><addrLine>Birmingham, UK</addrLine></address></meeting>
		<imprint>
			<publisher>Packt Publishing</publisher>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Spark: Cluster Computing with Working Sets</title>
		<author>
			<persName><forename type="first">M</forename><surname>Zaharia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Chowdhury</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Franklin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Shenker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Stoica</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2Nd USENIX Conference on Hot Topics in Cloud Computing, ser. HotCloud'10</title>
		<meeting>the 2Nd USENIX Conference on Hot Topics in Cloud Computing, ser. HotCloud'10<address><addrLine>Berkeley, CA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>USENIX Association</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="10" to="10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Communication-efficient learning of deep networks from decentralized data</title>
		<author>
			<persName><forename type="first">B</forename><surname>Mcmahan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Moore</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Ramage</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Hampson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">A</forename><surname>Arcas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Artificial intelligence and statistics</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1273" to="1282" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Edgefed: Optimized federated learning based on edge computing</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="209" to="191" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Provenance supporting hyperparameter analysis in deep neural networks</title>
		<author>
			<persName><forename type="first">D</forename><surname>Pina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Kunstmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Oliveira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Valduriez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mattoso</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Provenance and Annotation of Data and Processes</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="20" to="38" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">E2Clab: Exploring the Computing Continuum through Repeatable, Replicable and Reproducible Edge-to-Cloud Experiments</title>
		<author>
			<persName><forename type="first">D</forename><surname>Rosendo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Silva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Simonin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Costan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Antoniu</surname></persName>
		</author>
		<ptr target="https://hal.archives-ouvertes.fr/hal-02916032" />
	</analytic>
	<monogr>
		<title level="m">Cluster 2020 -IEEE International Conference on Cluster Computing</title>
		<meeting><address><addrLine>Kobe, Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020-09">Sep. 2020</date>
			<biblScope unit="page" from="1" to="11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">EnosLib: A Library for Experiment-Driven Research in Distributed Computing</title>
		<author>
			<persName><forename type="first">R.-A</forename><surname>Cherrueau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Delavergne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Van Kempen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Lebre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Pertin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Rojas Balderrama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Simonet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Simonin</surname></persName>
		</author>
		<ptr target="https://hal.inria.fr/hal-03324177" />
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Parallel and Distributed Systems</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1464" to="1477" />
			<date type="published" when="2022-06">Jun. 2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Lessons learned from the chameleon testbed</title>
		<author>
			<persName><forename type="first">K</forename><surname>Keahey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Anderson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Riteau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Ruth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Stanzione</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Cevik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Colleran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">S</forename><surname>Gunawi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Hammock</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2020 USENIX Annual Technical Conference (USENIX ATC 20)</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="219" to="233" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Lineagechain: a fine-grained, secure and efficient data provenance system for blockchains</title>
		<author>
			<persName><forename type="first">P</forename><surname>Ruan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">T A</forename><surname>Dinh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">C</forename><surname>Ooi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The VLDB Journal</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="3" to="24" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Runtime analysis of whole-system provenance</title>
		<author>
			<persName><forename type="first">T</forename><surname>Pasquier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Moyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bates</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Hermant</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Eyers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bacon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Seltzer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 ACM SIGSAC conference on computer and communications security</title>
		<meeting>the 2018 ACM SIGSAC conference on computer and communications security</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="1601" to="1616" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">The trade-offs between fog processing and communications in latency-sensitive vehicular fog computing</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">F</forename><surname>De Mendonc ¸a Junior</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Kokkinogenis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">L</forename><surname>Dias</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">M</forename><surname>Orey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Rossetti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pervasive and Mobile Computing</title>
		<imprint>
			<biblScope unit="volume">84</biblScope>
			<biblScope unit="page">101638</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Iot-enabled smart energy grid: Applications and challenges</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A A</forename><surname>Abir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Anwar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kayes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE access</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="50" to="961" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Edge-assisted rendering of 360 videos streamed to head-mounted virtual reality</title>
		<author>
			<persName><forename type="first">W.-C</forename><surname>Lo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-Y</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-H</forename><surname>Hsu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2018 IEEE International Symposium on Multimedia (ISM)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="44" to="51" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Federated learning for internet of things</title>
		<author>
			<persName><forename type="first">T</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Avestimehr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 19th ACM Conference on Embedded Networked Sensor Systems</title>
		<meeting>the 19th ACM Conference on Embedded Networked Sensor Systems</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="413" to="419" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Deep anomaly detection for time-series data in industrial iot: A communication-efficient on-device federated learning approach</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Garg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Hossain</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Internet of Things Journal</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="6348" to="6358" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">An on-device federated learning approach for cooperative model update between edge devices</title>
		<author>
			<persName><forename type="first">R</forename><surname>Ito</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Tsukada</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Matsutani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="92" to="986" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<ptr target="https://www.iot-lab.info/docs/boards/iot-lab-a8-m3/" />
		<title level="m">Iot-lab a8-m3 board</title>
		<imprint>
			<date type="published" when="2023-01-02">January 2, 2023</date>
		</imprint>
	</monogr>
	<note>IoT-LAB</note>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<ptr target="https://gitlab.inria.fr/E2Clab/examples/provenance-iot-edge" />
		<title level="m">Provenance capture iot/edge: experiment artifacts</title>
		<imprint>
			<date type="published" when="2023-01">2023, jan</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<author>
			<persName><surname>G5k</surname></persName>
		</author>
		<ptr target="https://www.grid5000.fr/w/Nancy:Hardware#gros" />
		<title level="m">Grid'5000: a large-scale and flexible testbed for experimentdriven research</title>
		<imprint>
			<date type="published" when="2023-01-02">January 2, 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<ptr target="https://mqtt.org/" />
		<title level="m">Mqtt: The standard for iot messaging</title>
		<imprint>
			<date type="published" when="2023-07">2023, jul</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<ptr target="https://datatracker.ietf.org/doc/html/rfc7252" />
		<title level="m">Coap: The constrained application protocol</title>
		<imprint>
			<date type="published" when="2023-07">2023, jul</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<title level="m" type="main">Amqp: Advanced message queuing protocol</title>
		<ptr target="http://docs.oasis-open.org/amqp/core/v1.0/os/amqp-core-overview-v1.0-os.html" />
		<imprint>
			<date type="published" when="2023-07">2023, jul</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<ptr target="https://datatracker.ietf.org/doc/html/rfc768" />
		<title level="m">Udp: User datagram protocol</title>
		<imprint>
			<date type="published" when="2023-07">2023, jul</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<ptr target="https://datatracker.ietf.org/doc/html/rfc6550" />
		<title level="m">Rpl: Ipv6 routing protocol for low-power and lossy networks</title>
		<imprint>
			<date type="published" when="2023-07">2023, jul</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Evaluating the performance of coap, mqtt, and http in vehicular scenarios</title>
		<author>
			<persName><forename type="first">R</forename><surname>Morabito</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Laaroussi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Jiménez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Standards for Communications and Networking</title>
		<imprint>
			<publisher>CSCN</publisher>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Comparison with http and mqtt in internet of things (iot)</title>
		<author>
			<persName><forename type="first">B</forename><surname>Wukkadada</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Wankhede</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Nambiar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Nair</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2018 International Conference on Inventive Research in Computing Applications (ICIRCA)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="249" to="253" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">A comparative evaluation of amqp, mqtt and http protocols using real-time public smart city data</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">B</forename><surname>Gemirter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">¸</forename></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">¸</forename><surname>Baydere</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2021 6th International Conference on Computer Science and Engineering (UBMK)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="542" to="547" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Mqtt for sensor networks (mqtt-sn) protocol specification</title>
		<author>
			<persName><forename type="first">A</forename><surname>Stanford-Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">L</forename><surname>Truong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International business machines (IBM) Corporation version</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1" to="28" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
		<ptr target="https://github.com/eclipse/mosquitto.rsmb" />
		<title level="m">Rsmb: Really small message broker</title>
		<imprint>
			<date type="published" when="2013-01">2013, jan</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<monogr>
		<ptr target="https://github.com/eclipse/mosquitto" />
		<title level="m">Eclipse mosquitto: An open source mqtt broker</title>
		<imprint>
			<date type="published" when="2017-01">2017, jan</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<monogr>
		<ptr target="https://github.com/luanguimaraesla/mqttsn" />
		<title level="m">Python client for mqtt-sn brokers</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<monogr>
		<ptr target="https://github.com/psf/requests" />
		<title level="m">Requests: Http for humans</title>
		<imprint>
			<date type="published" when="2018-01">2018, jan</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<monogr>
		<ptr target="https://gitlab.com/ssvitor/dataflowanalyzer" />
		<title level="m">Dfanalyzer tool</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<monogr>
		<author>
			<persName><surname>Docker</surname></persName>
		</author>
		<ptr target="https://www.docker.com/" />
		<title level="m">What is in a docker container?</title>
		<imprint>
			<date type="published" when="2023-01-02">January 2, 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Monetdb/x100: Hyperpipelining query execution</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">A</forename><surname>Boncz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zukowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Nes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cidr</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="225" to="237" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Pegasus, a workflow management system for science automation</title>
		<author>
			<persName><forename type="first">E</forename><surname>Deelman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Vahi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Juve</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Rynge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Callaghan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Maechling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Mayani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">F</forename><surname>Da Silva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Livny</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Future Generation Computer Systems</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="page" from="17" to="35" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Scientific workflow management and the kepler system</title>
		<author>
			<persName><forename type="first">B</forename><surname>Ludäscher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Altintas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Berkley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Higgins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Jaeger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">A</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Concurrency and computation: Practice and experience</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1039" to="1065" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Taverna: lessons in creating a workflow environment for the life sciences</title>
		<author>
			<persName><forename type="first">T</forename><surname>Oinn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Greenwood</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Addis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">N</forename><surname>Alpdemir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ferris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Glover</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Goble</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Goderis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Hull</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Marvin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Concurrency and computation: Practice and experience</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1067" to="1100" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Managing large-scale workflow execution from resource provisioning to provenance tracking: The cybershake example</title>
		<author>
			<persName><forename type="first">E</forename><surname>Deelman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Callaghan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Field</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Francoeur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">H</forename><surname>Jordan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Kesselman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Maechling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Second IEEE International Conference on e-Science and Grid Computing (e-Science'06)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2006">2006. 2006</date>
			<biblScope unit="page" from="14" to="14" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Towards a provenance collection framework for internet of things devices</title>
		<author>
			<persName><forename type="first">E</forename><surname>Nwafor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Campbell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Bloom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 IEEE SmartWorld, Ubiquitous Intelligence &amp; Computing, Advanced &amp; Trusted Computed, Scalable Computing &amp; Communications, Cloud &amp; Big Data Computing, Internet of People and Smart City Innovation</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Genoma: Distributed provenance as a service for iot-based systems</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">C</forename><surname>Narendra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Shukla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Nayak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Jagadish</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Kalkur</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2019 IEEE 5th World Forum on Internet of Things (WF-IoT)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="755" to="760" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>