<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Private Protocols for U -Statistics in the Local Model and Beyond</title>
				<funder>
					<orgName type="full">The Alan Turing Institute</orgName>
				</funder>
				<funder ref="#_Juj5SQV">
					<orgName type="full">European Union</orgName>
				</funder>
				<funder ref="#_VFYg3Fq #_YYZgHJc">
					<orgName type="full">Agence Nationale de la Recherche</orgName>
					<orgName type="abbreviated">ANR</orgName>
				</funder>
				<funder>
					<orgName type="full">Alan Turing Institute</orgName>
				</funder>
				<funder ref="#_VWNTp2Y">
					<orgName type="full">Marie Curie</orgName>
				</funder>
				<funder ref="#_ujPqmGZ #_NTr3XXb">
					<orgName type="full">UK Government</orgName>
				</funder>
				<funder ref="#_EpYZZFX">
					<orgName type="full">CPER Nord-Pas de Calais/FEDER</orgName>
				</funder>
				<funder ref="#_f9Ks8mq #_f5YhnJ5">
					<orgName type="full">EPSRC</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">James</forename><surname>Bell</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">The Alan Turing Institute Inria Google Aalto University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Aurélien</forename><surname>Bellet</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">The Alan Turing Institute Inria Google Aalto University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Adrià</forename><surname>Gascón</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">The Alan Turing Institute Inria Google Aalto University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Tejas</forename><surname>Kulkarni</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">The Alan Turing Institute Inria Google Aalto University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Private Protocols for U -Statistics in the Local Model and Beyond</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">1807D22290585486EA0E9D72E0FDE7B1</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-04-12T14:45+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper, we study the problem of computing U -statistics of degree 2, i.e., quantities that come in the form of averages over pairs of data points, in the local model of differential privacy (LDP). The class of U -statistics covers many statistical estimates of interest, including Gini mean difference, Kendall's tau coefficient and Area under the ROC Curve (AUC), as well as empirical risk measures for machine learning problems such as ranking, clustering and metric learning. We first introduce an LDP protocol based on quantizing the data into bins and applying randomized response, which guarantees an -LDP estimate with a Mean Squared Error (MSE) of O(1/ √ n ) under regularity assumptions on the U -statistic or the data distribution. We then propose a specialized protocol for AUC based on a novel use of hierarchical histograms that achieves MSE of O(α 3 /n 2 ) for arbitrary data distribution. We also show that 2-party secure computation allows to design a protocol with MSE of O(1/n 2 ), without any assumption on the kernel function or data distribution and with total communication linear in the number of users n. Finally, we evaluate the performance of our protocols through experiments on synthetic and real datasets.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>The problem of collecting aggregate statistics from a set of n users in a way that individual contributions remain private even from the data analysts has recently attracted a lot of interest. In the popular local model of differential privacy (LDP) <ref type="bibr" target="#b16">(Duchi et al., 2013;</ref><ref type="bibr" target="#b27">Kairouz</ref> Proceedings of the 23 rd International Conference on Artificial Intelligence and Statistics (AISTATS) 2020, Palermo, Italy. PMLR: Volume 108. Copyright 2020 by the author(s). <ref type="bibr">et al., 2014)</ref>, users apply a local randomizer to their private input before sending it to an untrusted aggregator. In this context, most work has focused on computing quantities that are separable across individual users, such as sums and histograms (see <ref type="bibr" target="#b2">Bassily and Smith, 2015;</ref><ref type="bibr" target="#b41">Wang et al., 2017;</ref><ref type="bibr" target="#b30">Kulkarni et al., 2019;</ref><ref type="bibr" target="#b13">Cormode et al., 2018;</ref><ref type="bibr">Bassily et al., 2017, and references therein)</ref>.</p><p>In this paper, we study the problem of privately computing U -statistics of degree 2, which generalize sample mean statistics to averages over pairs of data points. Let x 1 , . . . , x n be a set of n data points drawn i.i.d. from an unknown ditribution µ over a (discrete or continuous) domain X . The U -statistic of degree 2 with kernel f , given by U f,n = 2 n(n-1) i&lt;j f (x i , x j ), is an unbiased estimate of U f = E x,x ∼µ [f (x, x )] with minimum variance <ref type="bibr" target="#b25">(Hoeffding, 1948)</ref>. The class of U -statistics covers many statistical estimates of interest, including sample variance, Gini mean difference, Kendall's tau coefficient, Wilcoxon Mann-Whitney hypothesis test and Area under the ROC Curve (AUC) <ref type="bibr" target="#b32">(Lee, 1990;</ref><ref type="bibr" target="#b34">Mann and Whitney, 1947;</ref><ref type="bibr" target="#b21">Faivishevsky and Goldberger, 2008)</ref>. They are also commonly used as empirical risk measures for machine learning problems such as ranking, clustering and metric learning <ref type="bibr" target="#b29">(Kar et al., 2013;</ref><ref type="bibr" target="#b10">Clémençon et al., 2016)</ref>.</p><p>Interestingly, private estimation of U -statistics in the LDP model for arbitrary kernel functions f and data distributions µ cannot be straightforwardly addressed by resorting to standard local randomizers such as the Laplace mechanism or randomized response. Indeed, one cannot apply the local randomizer to the terms of the sum based on the sensitivity of f (as each term is shared across two users), and perturbing the inputs themselves can lead to large errors when passed through the (potentially discontinuous) function f . In this work, we design and analyze several protocols for computing U -statistics with privacy and utility guarantees. More precisely:</p><p>1. We introduce a generic LDP protocol based on quantizing the data into k bins and applying kary randomized response. We show that under an assumption on either the kernel function f or the data distribution µ, the aggregator can construct an -LDP estimate of U f,n with a Mean Squared Error (MSE) of O(1/ √ n ).</p><p>2. For the case of the AUC on a domain of size 2 α , whose kernel does not satisfy the regularity assumption required by our previous protocol, we design a specialized protocol based on hierarchical histograms that achieves MSE O(α 2 log(1/δ)/n 2 ) under ( , δ)-LDP and O(α 3 /n 2 ) under -LDP, for arbitrary data distribution.</p><p>3. Under a slight relaxation of the local model in which we allow pairs of users i and j to compute a randomized version of f (x i , x j ) with 2-party secure computation, we show that we can design a protocol with MSE of O(1/n 2 ), without any assumption on the kernel function or data distribution and with constant communication for each of the n users.</p><p>4. To evaluate the practical performance of the proposed protocols, we present some experiments on synthetic and real datasets for the task of computing AUC and Kendall's tau coefficient.</p><p>The paper is organized as follows. Section 2 gives some background on U -statistics and local differential privacy. In Section 3 we present a generic LDP protocol based on randomizing quantized inputs. Section 4 introduces a specialized LDP protocol for computing the Area under the ROC Curve (AUC). In Section 5, we introduce a generic protocol which operates in a slightly relaxed version of the LDP model where users can run secure 2-party computation. We present some numerical experiments in Section 6, and conclude with a discussion of our results and future work in Section 7.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">BACKGROUND</head><p>In this section, we introduce some background on Ustatistics and local differential privacy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">U -Statistics</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.1">Definition and Properties</head><p>Let µ be an (unknown) distribution over an input space X and f : X 2 → R be a pairwise function (assumed to be symmetric for simplicity) referred to as the kernel.</p><p>Given a sample S = {x i } n i=1 of n observations drawn from µ, we are interested in estimating the following population quantity:</p><formula xml:id="formula_0">U f = E X1,X2∼µ [f (X 1 , X 2 )].</formula><p>(1)</p><p>Definition 1 <ref type="bibr" target="#b25">(Hoeffding, 1948)</ref>. The U -statistic of degree 2 with kernel f is given by</p><formula xml:id="formula_1">U f,n = 2 n(n-1) i&lt;j f (x i , x j ).</formula><p>(2)</p><p>U f,n is an unbiased estimate of U f . Denoting by</p><formula xml:id="formula_2">ζ 1 = Var(f (x 1 , X 2 ) | x 1 )) and ζ 2 = Var(f (X 1 , X 2 ),</formula><p>its variance is given by <ref type="bibr" target="#b25">(Hoeffding, 1948;</ref><ref type="bibr" target="#b32">Lee, 1990)</ref>:</p><formula xml:id="formula_3">Var(U f,n ) = 2 n(n-1) (2(n -2)ζ 1 + ζ 2 ).<label>(3)</label></formula><p>The above variance is of O(1/n) and is optimal among all unbiased estimators of U f that can be computed from S. This incurs a complex dependence structure, as each data point appears in n-1 pairs. The statistical behavior of U -statistics can be investigated using linearization techniques <ref type="bibr" target="#b25">(Hoeffding, 1948)</ref> and decoupling methods (de la Pena and Giné, 1999), which provide tools to reduce their analysis to that of standard i.i.d. averages. One may refer to <ref type="bibr" target="#b32">(Lee, 1990)</ref> for asymptotic theory of U -statistics, to <ref type="bibr" target="#b38">(Van Der Vaart, 2000)</ref> (Chapter 12 therein) and (de la Pena and Giné, 1999) for nonasymptotic results, and to <ref type="bibr" target="#b11">(Clémençon et al., 2008</ref><ref type="bibr" target="#b10">(Clémençon et al., , 2016) )</ref> for an account of U -statistics in the context of machine learning and empirical risk minimization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.2">Motivating Examples</head><p>U -statistics are commonly used as point estimators of various global properties of distributions, as well as in statistical hypothesis testing <ref type="bibr" target="#b32">(Lee, 1990;</ref><ref type="bibr" target="#b34">Mann and Whitney, 1947;</ref><ref type="bibr" target="#b21">Faivishevsky and Goldberger, 2008)</ref>. They also come up as empirical risk measures in machine learning problems with pairwise loss functions such as bipartite ranking, metric learning and clustering. Below, we give some concrete examples of U -statistics of broad interest to motivate our private protocols.</p><p>Gini mean difference. This is a classic measure of dispersion which is often seen as more informative than the variance for some distributions <ref type="bibr" target="#b43">(Yitzhaki, 2003)</ref>. Letting X ⊂ R, it is defined as</p><formula xml:id="formula_4">G = 2 n(n-1) i&lt;j |x i -x j |,<label>(4)</label></formula><p>which is a U -statistic of degree 2 with kernel f (x i , x j ) = |x i -x j |. Gini coefficient, the most commonly used measure of inequality, is obtained by multiplying G by (n -1)/2 n i=1 x i . Remark 1. The variance of a sample, obtained by replacing the absolute difference by the squared difference in (4), is also a U -statistic. However we note that computing the variance can be achieved by computing two sums of locally computable variables (x i and x 2 i ), which can be done with existing LDP protocols.</p><p>Rényi-2 entropy. Also known as collision entropy, this provides a measure of entropy between Shannon's entropy and min entropy which is used in many applications involving discrete distributions (see <ref type="bibr">Acharya et al., 2015, and references therein)</ref>. It is given by</p><formula xml:id="formula_5">H 2 = -ln 2 n(n-1) i&lt;j I[x i = x j ] .</formula><p>(5)</p><p>The expression inside the log is a U -statistic of degree 2 with kernel f</p><formula xml:id="formula_6">(x i , x j ) = I[x i = x j ].</formula><p>Kendall's tau coefficient. This statistic measures the ordinal association between two variables and is often used as a test statistic to answer questions such as "does a higher salary make one happier?". In learning to rank applications, it is used to evaluate the extent to which a predicted ranking correlates with the (humangenerated) gold standard (see e.g., <ref type="bibr" target="#b26">Joachims, 2002;</ref><ref type="bibr" target="#b31">Lapata, 2006)</ref>. Formally, assuming continuous variables for simplicity, let X ⊂ R 2 and S = {x i = (y i , z i )} n i=1 . For any i &lt; j, the pairs x i = (y i , z i ) and x j = (y j , z j ) are said be concordant if (y i &gt; y j ) ∧ (z i &gt; z j ) or (y i &lt; y j ) ∧ (z i &lt; z j ), and discordant otherwise. Let C and D be the number of concordant and discordant pairs in S. Kendall rank correlation coefficient is defined as:</p><formula xml:id="formula_7">τ = C -D C + D = 1 n 2 i&lt;j sign(y i -y j ) sign(z i -z j ),<label>(6)</label></formula><p>which is a U -statistic of degree 2 with kernel f (x i , x j ) = sign(y i -y j ) sign(z i -z j ). 1</p><p>Area under the ROC curve (AUC). In binary classification with class imbalance, the Receiver Operating Characteristic (ROC) gives the true positive rate with respect to the false positive rate of a predictor at each possible decision threshold. The AUC is a popular summary of the ROC curve which gives a single, threshold-independent measure of the classifier goodness: it corresponds to the probability that the predictor assigns a higher score to a randomly chosen positive point than to a randomly chosen negative one. AUCs are widely used as performance metrics in machine learning <ref type="bibr" target="#b6">(Bradley, 1997;</ref><ref type="bibr" target="#b24">Herschtal and Raskutti, 2004)</ref>, and have also been recently studied as fairness measures <ref type="bibr" target="#b28">(Kallus and Zhou, 2019;</ref><ref type="bibr" target="#b39">Vogel et al., 2020)</ref>. Formally, let X ⊂ R × {-1, 1} and S = {x i = (s i , y i )} n i=1 where for each data point i, s i ∈ R is the score assigned to point i and y i ∈ {-1, 1} is its label. For convenience, let S + = {s i : y i = 1} and S -= {s i :</p><formula xml:id="formula_8">y i = -1} and let n + = |S + | and n -= |S -|. The AUC is given by AU C = 1 n + n - si∈S + sj ∈S -I[s i &gt; s j ],<label>(7)</label></formula><p>where</p><formula xml:id="formula_9">I[σ] is an indicator variable outputting 1 if the predicate σ is true and 0 otherwise. Up to a n 2 /n + n - factor, it is easy to see that AU C is a U -statistic of degree 2 with kernel f (x i , x j ) = I[s i &gt; s j ∧ y i &gt; y j ] + I[s i &lt; s j ∧ y i &lt; y j ].</formula><p>1 One can easily modify the kernel to account for ties.</p><p>Machine learning with pairwise losses. Many machine learning problems involve loss functions that operate on pairs of points <ref type="bibr" target="#b29">(Kar et al., 2013;</ref><ref type="bibr" target="#b10">Clémençon et al., 2016)</ref>. This is the case for instance in metric learning <ref type="bibr" target="#b4">(Bellet et al., 2015)</ref>, bipartite ranking <ref type="bibr" target="#b11">(Clémençon et al., 2008)</ref> and clustering <ref type="bibr" target="#b9">(Clémençon, 2014)</ref>. Empirical risk minimization problems have therefore the following generic form:</p><formula xml:id="formula_10">min θ∈Θ 2 n(n-1) i&lt;j θ (x i , x j ),<label>(8)</label></formula><p>where θ ∈ Θ are model parameters. The objective function in (8), as well as its gradient, are U -statistics of degree 2 with kernels θ and ∇ θ θ respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Local Differential Privacy</head><p>The classic centralized model of differential privacy assumed the presence of a trusted aggregator which processes the private information of individuals and releases a perturbed version of the result. The local model instead captures the setting where individuals do not trust the aggregator and randomize their input locally before sharing it. This model has received wide industrial adoption <ref type="bibr" target="#b19">(Erlingsson et al., 2014;</ref><ref type="bibr" target="#b22">Fanti et al., 2016;</ref><ref type="bibr">Differential Privacy Team, Apple, 2017;</ref><ref type="bibr" target="#b15">Ding et al., 2017)</ref>.</p><p>Definition 2 <ref type="bibr" target="#b16">(Duchi et al., 2013)</ref>. A local randomizer R is ( , δ)-locally differentially private (LDP) if for all x, x ∈ X and all possible output O in the range of R:</p><formula xml:id="formula_11">P r[R(x) = O] ≤ e P r[R(x ) = O] + δ.</formula><p>The special case δ = 0 is called pure -LDP.</p><p>Most work in LDP aims to compute quantities that are separable across individual inputs, such as sums and histograms (see <ref type="bibr" target="#b2">Bassily and Smith, 2015;</ref><ref type="bibr" target="#b41">Wang et al., 2017;</ref><ref type="bibr" target="#b30">Kulkarni et al., 2019;</ref><ref type="bibr" target="#b13">Cormode et al., 2018;</ref><ref type="bibr">Bassily et al., 2017, and references therein)</ref>. In contrast, our goal is to design LDP protocols for computing Ustatistics, where each term involves a pair of inputs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">GENERIC LDP PROTOCOL FROM QUANTIZATION</head><p>Discrete inputs. We first consider the case of discrete inputs taking one of k values. The possible values of the kernel function can be written as a matrix A ∈ R k×k where A ij = f (i, j). In this case, we can set the local randomizer R to be k-ary randomized response to generate a perturbed version R(x i ) of each input x i . Let e i denote the vector of length k with a one in the i-th position and 0 elsewhere. For each perturbed input in one-hot encoding form e R(xi) we can deduce an unbiased estimate of e xi . As the discrete U -statistic is Algorithm 1: LDP algorithm based on quantization and private histograms Public Parameters: Privacy budget , quantization scheme π, number of bins k.</p><p>Input:</p><formula xml:id="formula_12">(x i ∈ X ) i∈[n] Output: Estimate U f,n of U f 1 for each user i ∈ [n] do 2 Form quantized input π(x i ) ∈ [k] 3 For β = k/(k + e -1), generate xi ∈ [k] s.t. P (x i = i) = 1 -β for i = π(x i ), β/k for i = π(x i ),<label>(9)</label></formula><p>4</p><p>Send xi to the aggregator 5 end 6 Return U f,n computed from x1 , . . . , xn and β a linear function of each of these vectors, computing it on these unbiased estimates gives an unbiased estimate U f,n which can be written as:</p><formula xml:id="formula_13">U f,n = 1 n 2 1≤i&lt;j≤n f A (R(x i ), R(x j )),</formula><p>and is itself a U -statistic with kernel f A given by</p><formula xml:id="formula_14">f A (R(x 1 ), R(x 2 )) = (1-β) -2 (e R(x1) -b) T A(e R(x2) -b),</formula><p>where 1 -β is the probability of returning the true input in k-ary randomized response (see Eq. 9) and b is the vector of length k with every entry β/k. Details and analysis of this process, leveraging Hoeffding's decomposition of U -statistics <ref type="bibr" target="#b25">(Hoeffding, 1948;</ref><ref type="bibr" target="#b32">Lee, 1990)</ref>, can be found in Section A.1 of the supplementary material. The resulting bounds on the variance of U f,n are summarized in the following theorem.</p><formula xml:id="formula_15">Theorem 1. If f (x, x ) ∈ [0, 1] for all x, x , then Var( U f,n ) ≤ 1 n(1 -β) 2 + (1 + β) 2 2n(n -1)(1 -β) 4 .</formula><p>In order to achieve -LDP with a fixed k this becomes,</p><formula xml:id="formula_16">Var( U f,n ) ≈ (1 + k/ ) 2 n + (1 + k/ ) 4 2n 2 ≈ k 2 n 2 ,</formula><p>Continuous inputs. For U -statistics on discrete domains, e.g. Renyi-2 entropy, the above strategy can be applied directly. Possibly more importantly however, this then leads to a natural protocol for the continuous case. In this protocol (see Algorithm 1), the local randomizer proceeds by quantizing the input into k bins (for instance using simple or randomized rounding) before applying the previous procedure.</p><p>There are two sources of error in this protocol. The first one is due to the randomization needed to satisfy LDP in the quantized domain as bounded in Theorem 1.</p><p>The second source of error is due to quantization. In order to control this error in a nontrivial way, we rely on an assumption on the kernel function (namely, that it is Lipschitz) or the data distribution (namely, that it has Lipschitz density). Under these assumptions and using an appropriate variant of the kernel function on the quantized domain, we show that we can bound the error with respect to the original domain by a term in O(1/k 2 ) (see Section A.2 of the supplementary material). This leads to the following result.</p><p>Theorem 2. For simplicity, assume bounded domain X = [0, 1] and kernel values f (x, y) ∈ [0, 1] for all x, y ∈ X . Let π correspond to simple rounding, &gt; 0, k ≥ 1 and β = k/(k + e -1). Then Algorithm 1 satisfies -LDP. Furthermore:</p><formula xml:id="formula_17">• If f is L f -Lipschitz in each of its arguments, then MSE( U f,n ) is less than or equal to 1 n(1 -β) 2 + (1 + β) 2 2n(n -1)(1 -β) 4 + L 2 f 2k 2 . • If dµ/dλ is L µ -Lipschitz w.r.t. some measure λ, then MSE( U f,n ) is less than or equal to 1 n(1 -β) 2 + (1 + β) 2 2n(n -1)(1 -β) 4 + 4L 2 µ k 2 + 4L 4 µ k 4 .</formula><p>Remark 2. The use of simple rounding is not optimal in many situations. In the case of sum, and possibly of the Gini coefficient, it would be more accurate if randomized rounding were used instead of simple rounding. We leave this investigation for later work.</p><p>Setting k so as to balance the quantization and estimation errors leads to the following corollary. Corollary 1. Under the conditions of Theorem 2, for ≤ 1 and large enough n,</p><formula xml:id="formula_18">taking k = n 1/4 √ L leads to MSE( U f,n ) = O(L/ √ n ),</formula><p>where L corresponds to L f or L µ depending on the assumption. This result gives concrete error bounds for U -statistics whose kernel is Lipschitz, for arbitrary data distributions. One important example is the Gini mean difference, whose corresponding kernel f (x i , x j ) = |x i -x j | is 1-Lipschitz. On the other hand, for U -statistics with non-Lipschitz kernels, the data distribution must be sufficiently smooth (if not, it is easy to construct cases that make the algorithm fail).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">LOCALLY PRIVATE AUC</head><p>In this section, we describe an algorithm for computing AUC (7), whose kernel is discontinuous and therefore non-Lipschitz. We assume X to be an ordered domain of size d, that is with each datum in [0..d -1]. Note that all data is in practice discrete when represented in finite precision, so this is general. For simplicity of presentation we will assume that (i) d = 2 α for some integer α, and (ii) that the classes of the data, the y i , are public.</p><p>Our solution for computing AUC in the local model relies on a hierarchical histogram construction that has been considered in previous works for private collection of high-dimensional data <ref type="bibr" target="#b8">(Chan et al., 2012)</ref>, heavy hitters <ref type="bibr" target="#b1">(Bassily et al., 2017)</ref>, and range queries <ref type="bibr" target="#b30">(Kulkarni et al., 2019)</ref>. A hierarchical histogram is essentially a tree data structure on top of a histogram where each internal node is labelled with the sum of the values in the interval covered by it (see Figure <ref type="figure" target="#fig_0">1</ref>). That allows to answer any range query about u by checking the value associated with O(log |u|) nodes in the tree. We first define an exact version of such hierarchical histograms and explain how to compute AUC from one.</p><p>Notation on trees. We represent a binary tree h of depth α with integer node labels as a total mapping from a prefix-closed set of binary strings of length at most α to the integers. We refer to the i-th node in level l of the tree by the binary representation of i padded to length l from the left with zeros. With this notation, h λ is the label of the root node, as we use λ to denote the empty string, h 0 (resp. h 1 ) is the integer label of the left (resp. right) child of the root of h, and in general h p is the label of the node at path p from the root, i.e. the label of the node reached by following left or right children from the root according to the value of p (0 indicates left and 1 indicates right). Let b i be the i-th node in the bottom level. For two binary strings p, p ∈ {0, 1} * we denote the prefix relation by Algorithm. We use hierarchical histograms to compute AUC as follows. Let S + and S -be the samples of the positive and negative classes from which we Figure <ref type="figure">2</ref>: Our algorithm can be seen as a breath-first traversal of a tree, where at each level some nodes are selected for their subtrees to be explored further.</p><p>want to estimate AUC. Let h + and h -be hierarchical histograms for S + and S -. Note that h + λ = n + and h - λ = n -. We can now define the unnormalized AUC, denoted UAUC, over hierarchical histograms recursively by letting UAUC(h + , h -, p) be 0, if p is a leaf, and otherwise setting:</p><formula xml:id="formula_19">UAUC(h + , h -, p) = h + p•1 h - p•0 + i∈{0,1} UAUC(h + , h -, p•i) .</formula><p>Thus we have AUC(S + , S -) = AUC(h</p><formula xml:id="formula_20">+ , h -, λ) = 1 n + n -UAUC(h + , h -, λ).</formula><p>The above definition naturally leads to an algorithm that proceeds by traversing the trees h + , h -top-down from the root λ, accumulating the products of counts from h + , h -at nodes that correspond to entries in h + that are bigger than entries in h -. We now define a differentially private analogue. Later we will describe an efficient frequency oracle which can be used to compute an LDP estimate ĥ of a hierarchical histogram h of n values in a domain of size 2 α . This will provide the following necessary properties (i) ĥ is unbiased, (ii) Var( ĥ) ≤ v, with v defined as Cnα for some small constant C (iii) the ĥp are pairwise independent and (iv) Each level of ĥ is independent of the other levels.</p><p>Our private algorithm for computing an estimate of UAUC is then defined in terms of parameters n + and n -, v + and v -(bounding the variance of ĥ+ and ĥrespectively), and a &gt; 1 is a small number depending on n + , n -, α and C.</p><p>For a symbol ℵ we write ℵ ± to simultaneously refer to ℵ + and ℵ -. Let h± p = max( ĥ± p , √ av ± /2), i.e. h+ p = max( ĥ+ p , √ av + /2) and hp = max( ĥp , √ av -/2), and</p><formula xml:id="formula_21">let τ = a √ v -v + .</formula><p>Our private estimate is defined as follows. If p is a leaf then UAUC( ĥ+ , ĥ-, p) is 0, else if h+ p hp &lt; τ then it is given by</p><formula xml:id="formula_22">1 2 i∈{0,1} ĥ+ p•i i∈{0,1} ĥ- p•i .</formula><p>Otherwise, it is given recursively by</p><formula xml:id="formula_23">ĥ+ p•1 ĥ- p•0 + i∈{0,1} UAUC( ĥ+ , ĥ-, p • i) . (<label>10</label></formula><formula xml:id="formula_24">)</formula><p>As before, this definition leads to an algorithm. Note that the only difference with its non-private analogue is that this procedure does not recurse into subtrees whose contribution to the UAUC is upper bounded sufficiently tightly. More concretely, the server starts by querying ĥ+ , ĥat the root, namely with p = λ. If p is a leaf then we return 0 as the AUC. Otherwise, the algorithm checks whether h+ p hp &lt; τ . If so, then the algorithm concludes that there is not much to gain in exploring the subtrees rooted at p•0 and p•1, and returns</p><formula xml:id="formula_25">1 2 i∈0,1 ĥ+ p•i i∈0,1</formula><p>ĥp•i as an estimate of 1 2 h + p h - p . This estimate might seem equivalent to 1 2 ĥ+ p ĥp , but takes the previous form for a technical reason that is made clear in the proof. In this case we call p a discarded node. On the other hand, if h+ p hp ≥ τ , the algorithm proceeds as its non-private analogue, accumulating the contribution to the UAUC from the direct subtrees of p and recursing into nodes p • 0 and p • 1. In this case we refer to p as a recursed node. Thus every node p ∈ {0, 1} ≤α will be either recursed, a leaf or there will be a discarded node p such that p p. This is depicted in Figure <ref type="figure">2</ref>.</p><p>Analysis. Note that our algorithm has two sources of error: (i) the one incurred by discarding nodes and (ii) the error in estimating the contribution to the UAUC of the recursed nodes. The threshold τ is carefully chosen to balance these two errors.</p><p>Let R m be the set of nodes recursed on at level m. Our accuracy proof starts by bounding the expected value of |R m | (see Lemma 4 in Section B.1 of the supplementary) by a quantity B that is independent of m. We now describe a central argument to our accuracy proof, stated in the next theorem. Let E R m be the contribution to the error by nodes in R m . Then, the total contribution to the error by recursed nodes is</p><formula xml:id="formula_26">E R = m∈[α] E R m . A useful identity is E(E R 2 ) = m∈[α] E(E R m 2 ), as we can bound E(E R m 2</formula><p>), for any m, in terms of B (see detailed proof in the supplementary).</p><p>Note that this identity follows from E(E R m E R m ) = 0, with m &gt; m. The latter would hold if errors E R m and E R m were independent, since our frequency oracle is unbiased. However, errors at a given level are not independent of previous levels. However E(E R m E R m ) = 0 because the conditional expectation of E R m with respect to the answers of the frequency oracles up to level m is 0 i.e. E R 1 , . . . , E R m is a martingale difference sequence. The idea of conditioning on previous levels is used several times in our proofs, also to bound the error due to discarded nodes.</p><p>Next, we state our accuracy result, which is proven in detail in Section B.1 of the supplementary. Our proof tracks constants: this is important for practical purposes, and we show empirically in Section D.1 that our bound is in fact quite tight.</p><p>Theorem 3. If α ≤ √ n and the following holds:</p><p>1. E( ĥ± p -h ± p ) = 0 i.e. frequency estimates are unbiased.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">E(( ĥ±</head><formula xml:id="formula_27">p -h ± p ) 2 ) ≤ v ± i.e. MSE of frequency estima- tor is bounded by v ± = Cn ± α.</formula><p>3. For distinct p, p ∈ {0, 1} ≤α with |p| = |p |, ĥ± p and ĥ± p are independent i.e. the frequency estimates are pairwise independent.</p><p>4. For all m ≤ log(d), the lists ( ĥ± p ) p∈{0,1} ≤m and ( ĥ± p ) p∈{0,1} &gt;m are independent of each other.</p><p>Then, MSE( UAUC) is given by</p><formula xml:id="formula_28">Cn -n + α 2 2n + (4a + 1) min(n -, n + ) + 21 √ 2nCα √ a -1</formula><p>Instantiating ĥ. So far, Theorem 3 does not yield a complete algorithm as it does not specify an algorithm for computing estimates ĥ of a hierarchical histogram that satisfy the conditions of Theorem 3. In Section B.2 of the supplementary, we show how to instantiate such an algorithm in a communication-efficient manner by combining ideas from <ref type="bibr" target="#b1">Bassily et al. (2017)</ref>, in particular the use of the Hadamard transform, with an modified version of the protocol from <ref type="bibr" target="#b30">Kulkarni et al. (2019)</ref>. This leads to the following result. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">GENERIC PROTOCOLS FROM 2PC</head><p>So far, we have proposed a specialized LDP protocol for AUC, and a generic LDP protocol which requires some assumption on the kernel function or the data distribution to guarantee nontrivial error bounds. We conjecture that no LDP protocol can guarantee nontrivial error for arbitrary kernels and distributions, but we leave this as an open question for future work.</p><p>In this section, we slightly relax the model of LDP by allowing pairs of users i and j to compute a randomized version f (x i , x j ) of their kernel value f (x i , x j ) with 2-party secure computation (2PC). This gives rise to a computational differential privacy (CDP) model <ref type="bibr" target="#b35">Mironov et al. (2009)</ref>. Unsurprisingly, we show that in this model we can match the MSE of O( ln(1/δ) n 2 ) for computing regular (univariate) averages in the ( , δ)-LDP model by using advanced composition results <ref type="bibr" target="#b18">(Dwork et al., 2010)</ref>. However, such a protocol requires O(n 2 ) communication as all pairs of users need to compute f (x i , x j ) via 2PC, and does not satisfy pure -DP.</p><p>Proposed protocol. To address these limitations, we propose that the aggregator asks only a (random) subset of pairs of users (i, j) to submit their randomized kernel value f (x i , x j ). The idea is to trade-off between the error due to privacy (which increases as more pairs are used, due to budget splitting) and the subsampling error (for not averaging over all pairs). Given a positive integer P (which should be thought of as a small constant independent of n) and assuming n to be even for simplicity, we propose the following protocol:</p><p>1. Subsampling: The aggregator samples P independent permutations σ 1 , . . . , σ P ∈ S n of the set of users {1, . . . , n}. This defines a set of P n/2 pairs P = (σ p (2i -1, 2i)) p∈[P ],1≤i≤N/2 .</p><p>2. Perturbation: For each pair of users (i, j) ∈ P, users compute f (x i , x j ) via 2PC and sends it to the aggregator.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Aggregation:</head><p>The aggregator computes an estimate of U f as a function of { f (x i , x j )} (i,j)∈P .</p><p>Analysis. We have the following result for the Laplace mechanism applied to real-valued kernel functions (the extension to randomized response for discrete-valued kernels is straightforward). The proof relies on an exact characterization of the subsampling error by leveraging results on the variance of incomplete U -statistics <ref type="bibr" target="#b5">(Blom, 1976)</ref>, see Section C.1 of the supplementary for details.</p><p>Theorem 5 (2PC subsampling protocol with Laplace mechanism). Let &gt; 0, P ≥ 1 and assume that the kernel f has values in [0, 1]. Consider our subsampling protocol above with f (x i , x j ) = f (x i , x j ) + η ij where η ij ∼ Lap(P/ ), and the estimate computed as U f,n = 2 P n (i,j)∈P f (x i , x j ). Then the protocol satisfies -CDP, has a total communication cost of O(P n) and</p><formula xml:id="formula_29">MSE( U f,n ) = 2 P n 2(P -1) 1 - 1 n -1 ζ 1 + 1 + P -1 n -1 ζ 2 + 2P n 2 ,</formula><p>where ζ 1 and ζ 2 are defined as in (3).</p><p>The MSE in Theorem 5 is of O( 1 P n + P n 2 ). Remarkably, this shows that the O(1/n) variance of the estimate that uses all pairs is preserved when subsampling only O(n) pairs. This is made possible by the strong dependence structure in the O(n 2 ) terms of the original U -statistic.</p><p>As expected, P rules a trade-off between the errors due to subsampling and to privacy: the larger P , the smaller the former but the larger the latter (as each user must split its budget across P pairs). The optimal value of P depends on the kernel function and the data distribution (through ζ 1 and ζ 2 ) on the one hand, and the privacy budget on the other hand. This trade-off, along with the optimality of the proposed subsampling schemes, are discussed in more details Section C.1 of the supplementary material. In practice and as illustrated in our experiments, P can be set to a small constant.</p><p>Implementing 2PC. Securely computing the randomized kernel value f (x i , x j ) can be done efficiently for many kernel functions and local randomizers of interest, as the number of parties involved is limited to 2. We assume semi-honest parties (see <ref type="bibr" target="#b23">Goldreich, 2004</ref>, for a definition of this threat model). A suitable 2PC technique in this application are garbled circuits <ref type="bibr" target="#b42">(Yao, 1986;</ref><ref type="bibr" target="#b33">Lindell and Pinkas, 2009;</ref><ref type="bibr" target="#b20">Evans et al., 2018)</ref>, which are well-suited to compute Boolean comparisons as required in several of the kernels mentioned in Section 2.1.2. The circuits for computing the kernels can then be extended with output perturbation following ideas from <ref type="bibr" target="#b17">Dwork et al. (2006)</ref> and <ref type="bibr" target="#b7">Champion et al. (2019)</ref>. We refer to Section C.2 of the supplement for details on design and complexity.</p><p>Remark 3 (Beyond 2PC). One could further relax the model to allow multi-party secure computation with more than two parties, e.g. by extending the garbled circuit computing the kernel with secure aggregation over the P n pairs before performing output perturbation. This would recover the utility of centralized DP at the cost of much more computation and quadratic communication, which is not practical, as well as robustness. More interesting trade-offs may be achieved by securely aggregating small subsets of pairs. We leave the careful analysis of such extensions to future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">EXPERIMENTS</head><p>AUC. We use the Diabetes dataset <ref type="bibr" target="#b37">(Strack et al., 2014)</ref> for the binary classification task of determining whether a patient will be readmitted in the next 30 days after being discharged. We train a logistic regression model s which is used to score data points in [0, 1], and apply our protocol to privately compute AUC on the test set. Patients readmitted before 30 days form the positive class. Class sizes are shown in Figure <ref type="figure">3</ref>. Class information is not considered sensitive, as opposed to the score s(x) on private user data s(x), which includes detailed medical information. Figure <ref type="figure">3</ref> shows the standard error achieved by our protocol for different values of the domain size d. For each value of d we run our protocol with inputs s(fp(s(x i ), d)), where fp The plot shows that the protocol is quite robust to the choice of d, and that increasing beyond 2 does not improve results significantly. Recall that the error of our AUC protocol depends on the size of the smallest class, which is quite small here (only 693 examples).</p><p>Kendall's tau. We use the Tripadvisor dataset <ref type="bibr" target="#b40">(Wang, 2010)</ref>. The dataset consists of discrete user ratings (from scale -1 to 5) for hotels in San Francisco over many service quality metrics such as room service, location, room cleanliness, front desk service etc. After discarding the records with missing values, we have over 246K records. Let x i = (y i , z i ) be ratings given by user i to the room (y i ) and the cleanliness (z i ). The goal is to privately estimate the Kendall's tau coefficient (KTC) between these two variables, whose true value is 0.58. We compare the privacy-utility trade-off of our randomized response protocol (Algorithm 1 without quantization, since inputs can take only 6 × 6 = 36 values), our 2PC protocol based on subsampling, and the 2PC protocol that computes all pairs and relies on advanced composition (for which we set δ = 1e -8 ). The 2PC primitive to compute f (x i , x j ) is simulated. The results shown in Figure <ref type="figure" target="#fig_3">4</ref> show that the 2PC protocol with all pairs performs worst due to composition. The randomized response protocol performs slightly better, thanks to the small domain size. Finally, our 2PC protocol with subsampling achieves the lowest error by roughly an order of magnitude in high privacy regimes ( ≤ 2) while keeping the communication cost linear in n. As predicted by our analysis, P = 1 is best in high privacy regimes, where the error due to privacy dominates the subsampling error. We also see that P &gt; 1 can be used to reduce the overall error in low privacy regimes (for = 10 one can use an even larger P to match the error of the randomized response protocol).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">CONCLUDING REMARKS</head><p>In this paper, we tackled the problem of computing U -statistics from private user data, covering many statistical quantities of broad interest which were not addressed by previous private protocols.</p><p>Relative merits of our protocols. Our three protocols are largely complementary, insofar as each of them is well-suited to specific situations. Our first protocol (quantization followed by randomized response) can gracefully handle cases where the kernel is Lipschitz or the data is discrete in a small domain. It may also work well for non-Lipschitz kernels when quantizing data into few bins does not lose too much information (e.g., when the data distribution is smooth enough). As the latter hypothesis is difficult to assess in advance, we argue that there can exist specialized protocols that work well for non-Lipschitz kernels on continuous data or large discrete domains. Our second protocol illustrates this for the case of AUC: we leverage a hierarchical histogram structure to scale much better with the number of bins than the first protocol (see Section D for experiments comparing these two protocols). Finally, if one is willing to slightly relax the LDP model to allow pairwise communication among users, and if the kernel can be computed efficiently via 2PC, our third protocol is expected to perform best in terms of accuracy.</p><p>Extension to higher degrees. While we focused on pairwise U -statistics, our ideas can be extended to higher degrees. A prominent example is the Volume Under the ROC Surface, the generalization of the AUC to multi-partite ranking <ref type="bibr" target="#b12">(Clémençon et al., 2013)</ref>.</p><p>Future work. A promising direction for future work is to develop private multi-party algorithms for learning with pairwise losses <ref type="bibr" target="#b29">(Kar et al., 2013;</ref><ref type="bibr" target="#b10">Clémençon et al., 2016)</ref> by combining private stochastic gradient descent for standard empirical risk minimization <ref type="bibr" target="#b3">(Bassily et al., 2014;</ref><ref type="bibr" target="#b36">Shokri and Shmatikov, 2015)</ref> and our protocols to compute the gradient estimates.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Hierarchical histogram h for multiset {0, 1, 2, 2, 3} over the domain {0, 1, 2, 3}.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>p p, and their concatenation as p • p . Definition 3. Let S = {s 1 , . . . , s n } be a multiset, with s i ∈ [0..d -1]. A hierarchical histogram of S is a total mapping h : {0, 1} ≤log(d) → Z defined as h(b) = |{s ∈ S | ∃b ∈ {0, 1} * : b • b = b s }|. For simplicity, we denote h(b) by h b .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Theorem 4 .</head><label>4</label><figDesc>There is a one-round non-interactive protocol for computing AUC in the local model with MSE bounded by O(α 2 log(1/δ)/n 2 ) under ( , δ)-LDP and O(α 3 /n 2 ) under -LDP. Every user submits one bit, and the server does O(nlog(d)) computation and requires O(log(d)) additional reconstruction space.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 3 :Figure 4 :</head><label>34</label><figDesc>Figure 3: Mean and std. dev. (over 20 runs) of the absolute error of our AUC protocol on the scores of a logistic regression model trained on a Diabetes dataset.</figDesc></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><p>Acknowledgments J. B. was supported by <rs type="funder">The Alan Turing Institute</rs> underthe <rs type="funder">EPSRC</rs> grant <rs type="grantNumber">EP/N510129/1</rs>, and the <rs type="funder">UK Government</rs>'s <rs type="programName">Defence &amp; Security Programme</rs> in support of the <rs type="funder">Alan Turing Institute</rs>. A. B. was supported by grants <rs type="grantNumber">ANR-16-CE23-0016-01</rs> and <rs type="grantNumber">ANR-18-CE23-0018-03</rs>, by the <rs type="funder">European Union</rs>'s <rs type="programName">Horizon 2020 Research and Innovation Program</rs> under Grant Agreement No. <rs type="grantNumber">825081</rs> <rs type="projectName">COMPRISE</rs> and by a grant from <rs type="funder">CPER Nord-Pas de Calais/FEDER</rs> <rs type="programName">DATA Advanced data science</rs> and technologies 2015-2020. A. B. thanks <rs type="person">Jan Ramon</rs> for useful discussions. Work partly done when A. G. was at <rs type="institution">The Alan Turing Institute and Warwick University</rs>, and supported by <rs type="funder">The Alan Turing Institute</rs> under the <rs type="funder">EPSRC</rs> grant <rs type="grantNumber">EP/N510129/1</rs>, and the <rs type="funder">UK Government</rs>'s <rs type="programName">Defence &amp; Security Programme</rs> in support of the <rs type="funder">Alan Turing Institute</rs>. T. K. thanks <rs type="person">Graham Cormode</rs> for arranging a trip to <rs type="institution">Inria Lille</rs>. His visit was supported by <rs type="funder">Marie Curie</rs> Grant <rs type="grantNumber">618202</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_f9Ks8mq">
					<idno type="grant-number">EP/N510129/1</idno>
				</org>
				<org type="funding" xml:id="_ujPqmGZ">
					<orgName type="program" subtype="full">Defence &amp; Security Programme</orgName>
				</org>
				<org type="funding" xml:id="_VFYg3Fq">
					<idno type="grant-number">ANR-16-CE23-0016-01</idno>
				</org>
				<org type="funding" xml:id="_YYZgHJc">
					<idno type="grant-number">ANR-18-CE23-0018-03</idno>
				</org>
				<org type="funded-project" xml:id="_Juj5SQV">
					<idno type="grant-number">825081</idno>
					<orgName type="project" subtype="full">COMPRISE</orgName>
					<orgName type="program" subtype="full">Horizon 2020 Research and Innovation Program</orgName>
				</org>
				<org type="funding" xml:id="_EpYZZFX">
					<orgName type="program" subtype="full">DATA Advanced data science</orgName>
				</org>
				<org type="funding" xml:id="_f5YhnJ5">
					<idno type="grant-number">EP/N510129/1</idno>
				</org>
				<org type="funding" xml:id="_NTr3XXb">
					<orgName type="program" subtype="full">Defence &amp; Security Programme</orgName>
				</org>
				<org type="funding" xml:id="_VWNTp2Y">
					<idno type="grant-number">618202</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">The Complexity of Estimating Rényi Entropy</title>
		<author>
			<persName><forename type="first">J</forename><surname>Acharya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Orlitsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">T</forename><surname>Suresh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Tyagi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SODA</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Practical locally private heavy hitters</title>
		<author>
			<persName><forename type="first">R</forename><surname>Bassily</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Nissim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Stemmer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">G</forename><surname>Thakurta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Local, private, efficient protocols for succinct histograms</title>
		<author>
			<persName><forename type="first">R</forename><surname>Bassily</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">STOC</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Private Empirical Risk Minimization: Efficient Algorithms and Tight Error Bounds</title>
		<author>
			<persName><forename type="first">R</forename><surname>Bassily</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">D</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Thakurta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">FOCS</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Metric Learning</title>
		<author>
			<persName><forename type="first">A</forename><surname>Bellet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Habrard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sebban</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015">2015</date>
			<publisher>Morgan &amp; Claypool Publishers</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Some properties of incomplete Ustatistics</title>
		<author>
			<persName><forename type="first">G</forename><surname>Blom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biometrika</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="573" to="580" />
			<date type="published" when="1976">1976</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">The use of the area under the ROC curve in the evaluation of machine learning algorithms</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">P</forename><surname>Bradley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1145" to="1159" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Securely sampling biased coins with applications to differential privacy</title>
		<author>
			<persName><forename type="first">J</forename><surname>Champion</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Shelat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ullman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IACR Cryptology ePrint Archive</title>
		<imprint>
			<biblScope unit="page">823</biblScope>
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Privacypreserving stream aggregation with fault tolerance</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">H</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Song</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Financial Cryptography</title>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">A statistical view of clustering performance through the theory of U-processes</title>
		<author>
			<persName><forename type="first">S</forename><surname>Clémençon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Multivariate Analysis</title>
		<imprint>
			<biblScope unit="volume">124</biblScope>
			<biblScope unit="page" from="42" to="56" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Scalingup Empirical Risk Minimization: Optimization of Incomplete U-statistics</title>
		<author>
			<persName><forename type="first">S</forename><surname>Clémençon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bellet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Colin</forename></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="165" to="202" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Ranking and empirical risk minimization of Ustatistics</title>
		<author>
			<persName><forename type="first">S</forename><surname>Clémençon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Lugosi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Vayatis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Annals of Statistics</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="844" to="874" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Ranking data with ordinal labels: Optimality and pairwise aggregation</title>
		<author>
			<persName><forename type="first">S</forename><surname>Clémençon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Robbiano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Vayatis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine Learning</title>
		<imprint>
			<biblScope unit="volume">91</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="67" to="104" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Marginal release under local differential privacy</title>
		<author>
			<persName><forename type="first">G</forename><surname>Cormode</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kulkarni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Srivastava</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGMOD</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<author>
			<persName><forename type="first">V</forename><surname>De La Pena</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Giné</surname></persName>
		</author>
		<title level="m">Decoupling: from Dependence to Independence</title>
		<meeting><address><addrLine>Apple</addrLine></address></meeting>
		<imprint>
			<publisher>Springer. Differential Privacy Team</publisher>
			<date type="published" when="1999">1999. 2017</date>
		</imprint>
	</monogr>
	<note>Learning with privacy at scale</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Collecting telemetry data privately</title>
		<author>
			<persName><forename type="first">B</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kulkarni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yekhanin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Local privacy and statistical minimax rates</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Duchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Wainwright</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">FOCS</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Our data, ourselves: Privacy via distributed noise generation</title>
		<author>
			<persName><forename type="first">C</forename><surname>Dwork</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Kenthapadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Mcsherry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Mironov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Naor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EUROCRYPT</title>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Boosting and Differential Privacy</title>
		<author>
			<persName><forename type="first">C</forename><surname>Dwork</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">N</forename><surname>Rothblum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Vadhan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">FOCS</title>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Rappor: Randomized aggregatable privacy-preserving ordinal response</title>
		<author>
			<persName><forename type="first">U</forename><surname>Erlingsson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Pihur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Korolova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CCS</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">A pragmatic introduction to secure multi-party computation</title>
		<author>
			<persName><forename type="first">D</forename><surname>Evans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Kolesnikov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Rosulek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Foundations and Trends in Privacy and Security</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">2-3</biblScope>
			<biblScope unit="page" from="70" to="246" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">ICA based on a Smooth Estimation of the Differential Entropy</title>
		<author>
			<persName><forename type="first">L</forename><surname>Faivishevsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Goldberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Building a RAPPOR with the unknown: Privacy-preserving learning of associations and data dictionaries</title>
		<author>
			<persName><forename type="first">G</forename><surname>Fanti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Pihur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ú</forename><surname>Erlingsson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">PoPETs</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<author>
			<persName><forename type="first">O</forename><surname>Goldreich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Foundations of Cryptography</title>
		<imprint>
			<publisher>Cambridge University Press</publisher>
			<date type="published" when="2004">2004</date>
			<biblScope unit="volume">2</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Optimising area under the ROC curve using gradient descent</title>
		<author>
			<persName><forename type="first">A</forename><surname>Herschtal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Raskutti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">A class of statistics with asymptotically normal distribution</title>
		<author>
			<persName><forename type="first">W</forename><surname>Hoeffding</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annals of Mathematics and Statistics</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="293" to="325" />
			<date type="published" when="1948">1948</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Optimizing search engines using clickthrough data</title>
		<author>
			<persName><forename type="first">T</forename><surname>Joachims</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD</title>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Extremal mechanisms for local differential privacy</title>
		<author>
			<persName><forename type="first">P</forename><surname>Kairouz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Oh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Viswanath</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">The Fairness of Risk Scores Beyond Classification: Bipartite Ranking and the xAUC Metric</title>
		<author>
			<persName><forename type="first">N</forename><surname>Kallus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">On the Generalization Ability of Online Learning Algorithms for Pairwise Loss Functions</title>
		<author>
			<persName><forename type="first">P</forename><surname>Kar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">K</forename><surname>Sriperumbudur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Karnick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Answering range queries under local differential privacy</title>
		<author>
			<persName><forename type="first">T</forename><surname>Kulkarni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Cormode</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Srivastava</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGMOD</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Automatic Evaluation of Information Ordering: Kendall&apos;s Tau</title>
		<author>
			<persName><forename type="first">M</forename><surname>Lapata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="471" to="484" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">U -statistics: Theory and practice</title>
		<author>
			<persName><forename type="first">A</forename><surname>Lee</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1990">1990</date>
			<publisher>Marcel Dekker, Inc</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">A proof of security of yao&apos;s protocol for two-party computation</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Lindell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Pinkas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Cryptology</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="161" to="188" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">On a Test of Whether one of Two Random Variables is Stochastically Larger than the Other</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">B</forename><surname>Mann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">R</forename><surname>Whitney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annals of Mathematical Statistics</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="50" to="60" />
			<date type="published" when="1947">1947</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Computational Differential Privacy</title>
		<author>
			<persName><forename type="first">I</forename><surname>Mironov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Pandey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Reingold</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">P</forename><surname>Vadhan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
			<publisher>CRYPTO</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Privacypreserving deep learning</title>
		<author>
			<persName><forename type="first">R</forename><surname>Shokri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Shmatikov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CCS</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<author>
			<persName><forename type="first">B</forename><surname>Strack</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Deshazo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Gennings</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Olmo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ventura</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">J</forename><surname>Cios</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">N</forename><surname>Clore</surname></persName>
		</author>
		<ptr target="https://archive.ics.uci.edu/ml/datasets/diabetes+130-us+hospitals+for+years+1999-2008" />
		<title level="m">Diabetes data</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Asymptotic Statistics</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">W</forename><surname>Van Der Vaart</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000">2000</date>
			<publisher>Cambridge University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Learning Fair Scoring Functions: Fairness Definitions, Algorithms and Generalization Bounds for Bipartite Ranking</title>
		<author>
			<persName><forename type="first">R</forename><surname>Vogel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bellet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Clémençon</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2002.08159</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<ptr target="http://www.preflib.org/data/combinatorial/trip/" />
		<title level="m">Trip advisor data</title>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Locally differentially private protocols for frequency estimation</title>
		<author>
			<persName><forename type="first">T</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Blocki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Jha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">USENIX Security Symposium</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">How to generate and exchange secrets</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Yao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">FOCS</title>
		<imprint>
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
	<note>extended abstract</note>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Gini&apos;s Mean Difference: A Superior Measure of Variability for Non-Normal Distributions</title>
		<author>
			<persName><forename type="first">S</forename><surname>Yitzhaki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Metron International Journal of Statistics</title>
		<imprint>
			<biblScope unit="volume">61</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="285" to="316" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
