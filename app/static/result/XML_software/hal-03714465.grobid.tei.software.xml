<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">High-Dimensional Private Empirical Risk Minimization by Greedy Coordinate Descent</title>
				<funder>
					<orgName type="full">Inria Exploratory Action FLAMED</orgName>
				</funder>
				<funder ref="#_ueWP5Gu">
					<orgName type="full">Agence Nationale de la Recherche</orgName>
					<orgName type="abbreviated">ANR</orgName>
				</funder>
				<funder ref="#_uFjA9Jg #_6yrM8KC #_nBxkBZD #_t3uteHA">
					<orgName type="full">unknown</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Paul</forename><surname>Mangold</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Aurélien</forename><surname>Bellet</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Joseph</forename><surname>Salmon</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Marc</forename><surname>Tommasi</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Univ. Lille</orgName>
								<orgName type="institution" key="instit2">Inria</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="laboratory">UMR 9189</orgName>
								<orgName type="institution" key="instit1">CNRS</orgName>
								<orgName type="institution" key="instit2">Centrale Lille -CRIStAL</orgName>
								<address>
									<postCode>F-59000</postCode>
									<settlement>Lille</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="institution" key="instit1">Univ. Lille</orgName>
								<orgName type="institution" key="instit2">Inria</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="institution" key="instit1">CNRS</orgName>
								<orgName type="institution" key="instit2">Centrale Lille</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff4">
								<orgName type="laboratory">IMAG</orgName>
								<orgName type="institution">UMR 9189 -CRIStAL</orgName>
								<address>
									<postCode>F-59000</postCode>
									<settlement>Lille</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff5">
								<orgName type="institution">Univ Montpellier</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff6">
								<orgName type="institution">CNRS</orgName>
								<address>
									<settlement>Montpellier</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff7">
								<orgName type="institution" key="instit1">Institut Universitaire de France (IUF) Univ. Lille</orgName>
								<orgName type="institution" key="instit2">CNRS</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff8">
								<orgName type="institution" key="instit1">Inria</orgName>
								<orgName type="institution" key="instit2">Centrale Lille</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff9">
								<orgName type="institution">UMR</orgName>
								<address>
									<addrLine>9189 -CRIStAL</addrLine>
									<postCode>F-59000</postCode>
									<settlement>Lille</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">High-Dimensional Private Empirical Risk Minimization by Greedy Coordinate Descent</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">F34C0019FA0A49840A0908CD662A0E24</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-04-12T14:52+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper, we study differentially private empirical risk minimization (DP-ERM). It has been shown that the worst-case utility of DP-ERM reduces polynomially as the dimension increases. This is a major obstacle to privately learning large machine learning models. In high dimension, it is common for some model's parameters to carry more information than others. To exploit this, we propose a differentially private greedy coordinate descent (DP-GCD) algorithm. At each iteration, DP-GCD privately performs a coordinate-wise gradient step along the gradients' (approximately) greatest entry. We show theoretically that DP-GCD can achieve a logarithmic dependence on the dimension for a wide range of problems by naturally exploiting their structural properties (such as quasi-sparse solutions). We illustrate this behavior numerically, both on synthetic and real datasets.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Machine Learning (ML) crucially relies on data, which can be sensitive or confidential. Unfortunately, trained models are prone to leaking information about specific training points <ref type="bibr" target="#b42">(Shokri et al., 2017)</ref>. A standard approach for training models while provably controlling the amount of leakage is to solve an empirical risk minimization (ERM) problem under differential privacy (DP) constraints <ref type="bibr" target="#b9">(Chaudhuri et al., 2011)</ref>. In this work, we consider the generic problem formulation:</p><formula xml:id="formula_0">w * ∈ arg min w∈R p f (w) = 1 n n i=1 (w; d i ) ,<label>(1)</label></formula><p>where D = (d 1 , . . . , d n ) is a dataset of n samples drawn from a universe X , and (•, d) : R p → R is a loss function which is convex and smooth for all d ∈ D.</p><p>The DP constraint in DP-ERM induces a trade-off between the precision of the solution (utility) and privacy. <ref type="bibr" target="#b6">Bassily et al. (2014)</ref> proved lower bounds on utility under a fixed DP budget. These lower bounds scale polynomially with the dimension p. Since machine learning models are often high-dimensional (e.g., n ≈ p or even n p), this is a massive drawback for the use of DP-ERM.</p><p>To go beyond this negative result, one has to leverage the fact that high-dimensional problems often exhibit some structure. In particular, some parameters are typically more significant than others: it is notably (but not only) the case when models are sparse, which is often desired in high dimension <ref type="bibr" target="#b47">(Tibshirani, 1996)</ref>. Private learning algorithms could thus be designed to exploit this by focusing on the most significant parameters of the problem. Several works have tried to exploit such high-dimensional problems' structure to reduce the dependence on the dimension, e.g., from polynomial to logarithmic. <ref type="bibr" target="#b44">Talwar et al. (2015)</ref>, <ref type="bibr" target="#b4">Bassily et al. (2021)</ref>, and <ref type="bibr" target="#b1">Asi et al. (2021)</ref> proposed a DP Frank-Wolfe algorithm (DP-FW) that exploits the solution's sparsity. However, their algorithm only works on 1constrained DP-ERM, restricting its range of application. For sparse linear regression, <ref type="bibr" target="#b29">Kifer et al. (2012)</ref> proposed to first identify some support and then solve the DP-ERM problem on the restricted support. Unfortunately, their approach requires implicit knowledge of the solution's sparsity. Finally, <ref type="bibr" target="#b26">Kairouz et al. (2021)</ref> and <ref type="bibr" target="#b57">Zhou et al. (2021)</ref> used public data to estimate lower-dimensional subspaces, where the gradient can be computed at a reduced privacy cost. A key limitation is that such public data set, from the same domain as the private data, is typically not available in many learning scenarios involving sensitive data.</p><p>In this work, we propose a private algorithm that does not have these pitfalls: the differentially private greedy coordinate descent algorithm (DP-GCD). At each iteration, DP-GCD privately determines the gradient's greatest coordinate, and performs a gradient step in its direction. It focuses on the most useful parameters, avoiding wasting privacy budget on updating non-significant ones. Our algorithm works on any smooth, unconstrained DP-ERM problem. We also propose a proximal version to tackle non-smooth regularizers. Crucially, DP-GCD is adaptive to the sparsity of the solution, and is able to ignore small (but non-zero) parameters, improving utility even on non-sparse problems.</p><p>Formally, we show that DP-GCD reduces the dependence on the dimension from √ p or p to log(p) for a wide range of unconstrained problems. This is the first algorithm to obtain such gains without relying on 1 or 0 constraints. In fact, DP-GCD's utility naturally depends on 1 -norm quantities (i.e., distance from initialization to optimal or strong-convexity parameter) and spans two different regimes. When these 1 -norm quantities are O(1) as assumed in DP-FW, DP-GCD attains O(log(p)/n 2/3 2/3 ) and O(log(p)/n 2 2 ) utility on convex and strongly-convex problems respectively, outperforming existing DP-FW algorithms without solving a constrained problem. In the second regime, when the 2 -norm counterpart of the above quantities are O(1) as assumed for DP-SGD and its variants, we show that DP-GCD adapts to the problem's underlying structure. Specifically, it is able to interpolate between logarithmic and polynomial dependence on the dimension. In addition to these general utility results, we prove that for strongly convex problems with quasi-sparse solutions (including but not limited to sparse problems), DP-GCD converges to a good approximate solution in few iterations. This improves utility in the 2 -norm setting, replacing the polynomial dependence on the ambient space's dimension by the quasi-sparsity level of the solution. We evaluate both our algorithms numerically on real and synthetic datasets, validating our theoretical observations. Our contributions can be summarized as follows:</p><p>1. We propose differentially private greedy coordinate descent (DP-GCD), a method that performs updates along the (approximately) greatest entry of the gradient. We formally establish its privacy guarantees, and derive high probability utility upper bounds.</p><p>2. We prove that DP-GCD exploits structural properties of the problem (e.g., quasi-sparse solutions) to improve utility. Importantly, DP-GCD does not require prior knowledge of this structure to exploit it.</p><p>3. We empirically validate our theoretical results on a variety of synthetic and real datasets, showing that DP-GCD outperforms existing private algorithms on highdimensional problems with quasi-sparse solutions.</p><p>The rest of the paper is organized as follows. First, we discuss related work in more details in Section 2, and present the relevant mathematical background in Section 3. Section 4 then introduces DP-GCD, and formally analyzes its privacy and utility. We validate our theoretical results numerically in Section 5. Finally, we conclude and discuss the limitations of our results in Section 6.  <ref type="bibr" target="#b21">Hardt et al., 2016;</ref><ref type="bibr" target="#b2">Bassily et al., 2020)</ref> to show that in some regimes, the population risk is the same as in non-private SCO. <ref type="bibr" target="#b17">Feldman et al. (2020)</ref> and <ref type="bibr" target="#b53">Wang et al. (2022)</ref> then developed efficient (linear-time) algorithm to solve this problem. In all of the above work, the utility upper bounds scale polynomially in p, which is not suitable in high dimension.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head><p>In contrast, our approach provably achieves logarithmic dependence on the dimension for some problems.</p><p>DP-ML in high dimension. Several approaches have been explored to reduce the dependence on the dimension. One option is to consider 1 -constrained problems. For DP-ERM, <ref type="bibr" target="#b44">Talwar et al. (2015)</ref> and <ref type="bibr" target="#b45">Talwar et al. (2016)</ref> used a differentially private Frank-Wolfe algorithm (DP-FW) <ref type="bibr" target="#b19">(Frank and Wolfe, 1956;</ref><ref type="bibr" target="#b23">Jaggi, 2013)</ref> to achieve utility that scales logarithmically with the dimension. <ref type="bibr" target="#b1">Asi et al. (2021)</ref> and <ref type="bibr" target="#b4">Bassily et al. (2021)</ref> proposed stochastic DP-FW algorithms, extending the above results to DP-SCO. For more general domains (e.g., polytopes), <ref type="bibr" target="#b28">Kasiviswanathan and Jin (2016)</ref> randomly project the data on a smaller-dimensional space, and lift the result back onto the original space. The dependence in the dimension is encoded by the Gaussian width of the domain, again leading to O(log p) error for the 1 ball or the simplex. <ref type="bibr" target="#b51">Wang et al. (2017)</ref> derived a faster mirror descent algorithm for DP-ERM whose utility also depends on the Gaussian width of the domain. Our approach matches the O(log p) dependence of the above methods when key quantities are bounded in 1 norm, but can also achieve such gains for more general problems, e.g., when the problem has a quasi-sparse solution. <ref type="bibr" target="#b29">Kifer et al. (2012)</ref> previously leveraged the solution sparsity for the specific problem of sparse linear regression: they first identify some support, and then solve DP-ERM on this restricted support. Similarly, <ref type="bibr" target="#b52">Wang and Gu (2019)</ref> and <ref type="bibr" target="#b22">Hu et al. (2022)</ref> proposed hard thresholding-based algorithms for DP-ERM and DP-SCO under sparsity ( 0 norm) constraints. Both approaches achieve an error of O(log p) but rely either on prior knowledge on the solution's sparsity, or on the tuning of an additional hyperparameter. In contrast, our approach automatically adapts to the sparsity and works also when solutions are only quasi-sparse. Finally, <ref type="bibr" target="#b26">Kairouz et al. (2021)</ref> and <ref type="bibr" target="#b57">Zhou et al. (2021)</ref> estimate lowerdimensional gradient subspaces using public data. This reduces noise addition, but in practice, public data is only rarely available.</p><p>Coordinate descent. CD algorithms have a long history in optimization (see <ref type="bibr" target="#b54">Wright, 2015;</ref><ref type="bibr" target="#b41">Shi et al., 2017</ref>, for detailed reviews on CD). Most approaches have focused on randomized or cyclic choices of coordinates <ref type="bibr" target="#b48">(Tseng, 2001;</ref><ref type="bibr" target="#b35">Nesterov, 2012)</ref>, with proximal and parallel variants <ref type="bibr" target="#b39">(Richtárik and Takáč, 2014;</ref><ref type="bibr" target="#b18">Fercoq and Richtárik, 2014;</ref><ref type="bibr" target="#b20">Hanzely et al., 2018)</ref>, sometimes applied to the dual problem <ref type="bibr" target="#b40">(Shalev-Shwartz and Zhang, 2013)</ref>. In this work, our focus is on greedy coordinate descent methods, which update the coordinate with greatest gradient entry <ref type="bibr" target="#b30">(Luo and Tseng, 1992;</ref><ref type="bibr" target="#b49">Tseng and Yun, 2009;</ref><ref type="bibr" target="#b11">Dhillon et al., 2011)</ref>. <ref type="bibr" target="#b36">Nutini et al. (2015)</ref> showed improved convergence rates for smooth, strongly-convex functions, by measuring strong convexity in the 1 -norm. Our work builds upon these results to design and analyze the first private greedy CD approach. Although techniques such as fast nearest-neighbor schemes have been proposed to compute the (approximate) greedy update more efficiently <ref type="bibr" target="#b11">(Dhillon et al., 2011;</ref><ref type="bibr" target="#b36">Nutini et al., 2015;</ref><ref type="bibr" target="#b27">Karimireddy et al., 2019)</ref>, greedy CD methods are often slower (in wall-clock time) than their randomized or cyclic counterparts <ref type="bibr" target="#b32">(Massias et al., 2017)</ref>. However, in the private setting we consider, the main focus is not on computing time but on achieving the best privacy-utility trade-off. This gives a distinct advantage to greedy CD, as it provides a way to perform the (approximately) most useful coordinate update under a given privacy budget instead of wasting budget on updating random (potentially useless) coordinates. The analysis of proximal extensions of greedy CD for composite problems with non-smooth parts is known to be challenging even in the non-private setting. <ref type="bibr" target="#b27">Karimireddy et al. (2019)</ref> proved convergence rates only for 1 -and box-regularized problems, using a modified greedy CD algorithm. In this work, we propose and empirically evaluate a proximal extension of our DP-GCD algorithm with formal privacy guarantees, but leave its utility analysis for future work; see the discussion in Section 6.</p><p>Private coordinate descent. Differentially Private Coordinate Descent (DP-CD) was recently studied by <ref type="bibr" target="#b31">Mangold et al. (2022)</ref>, who analyzed its utility and derived corresponding lower bounds. They showed that DP-CD can exploit coordinate-wise regularity assumptions to use larger step-sizes, outperforming DP-SGD when gradient coordinates are imbalanced. Our DP-GCD also shares this property. <ref type="bibr" target="#b10">Damaskinos et al. (2021)</ref> proposed a dual coordinate descent algorithm for generalized linear models. Private CD has also been used by <ref type="bibr" target="#b7">Bellet et al. (2018)</ref> in a decentralized setting. All these works use random selection, which fails to exploit key problem's properties such as quasi-sparsity, and thus suffer a polynomial dependence on the dimension p. In contrast, our private greedy selection rule focuses on the most useful coordinates, thereby reducing the dependence on p to only logarithmic in such settings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">PRELIMINARIES</head><p>In this section, we introduce important technical notions that will be used throughout the paper.</p><p>Norms. We start by defining two conjugate norms that will allow to keep track of coordinate-wise quantities. Let M = diag(M 1 , . . . , M p ) with M 1 , . . . , M p &gt; 0, and</p><formula xml:id="formula_1">w M,1 = p j=1 M 1 2 j |w j | , w M -1 ,∞ = max j∈[p] M -1 2 j |w j | .</formula><p>When M is the identity matrix I, • M,1 is the standard</p><formula xml:id="formula_2">1 -norm and • M -1 ,∞ is the ∞ -norm. We also define the Euclidean dot product u, v = p j=1 u i v i and cor- responding norms • M,2 = •, M • 1 2 and • M -1 ,2 = •, M -1 • 1 2</formula><p>. Similarly, we recover the standard 2 -norm when M = I.</p><p>Regularity assumptions. We recall classical regularity assumptions along with ones specific to the coordinatewise setting. We denote by ∇f the gradient of a differentiable function f , and by ∇ j f its j-th coordinate. We denote by e j the j-th vector of R p 's standard basis.</p><p>(Strong)-convexity. For q ∈ {1, 2}, a differentiable function f : R p → R is µ M,q -strongly-convex w.r.t. the norm</p><formula xml:id="formula_3">• M,q if for all v, w ∈ R p , f (w) ≥ f (v) + ∇f (v), w - v + µ M,q<label>2</label></formula><p>wv 2 M,q . The case M 1,q = • • • = M p,q = 1 recovers standard µ I,q -strong convexity w.r.t. the q -norm. When µ M,q = 0, the function is just said to be convex.</p><formula xml:id="formula_4">Component Lipschitzness. A function f : R p → R is L-component-Lipschitz for L = (L 1 , . . . , L p ) with L 1 , . . . , L p &gt; 0 if for w ∈ R p , t ∈ R and j ∈ [p], |f (w + te j ) -f (w)| ≤ L j |t|. For q ∈ {1, 2}, f is Λ q - Lipschitz w.r.t. • q if for v, w ∈ R p , |f (v) -f (w)| ≤ Λ q v -w q . Component smoothness. A differentiable function f : R p → R is M -component-smooth for M 1 , . . . , M p &gt; 0 if for v, w ∈ R p , f (w) ≤ f (v) + ∇f (v), w -v + 1 2 w - v 2 M,2 . When M 1 = • • • = M p = β, f is said to be β- smooth.</formula><p>Component-wise regularity assumptions are not restrictive: for q ∈ {1, 2}, Λ q -Lipschitzness w.r.t. • q implies (Λ q , . . . , Λ q )-component-Lipschitzness and β-smoothness implies (β, . . . , β)-component-smoothness. Yet, the actual component-wise constants of a function can be much lower than what can be deduced from their global counterparts. In the following of this paper, we will use </p><formula xml:id="formula_5">M min = min j∈[p] M j , M max = max j∈[p] M j ,</formula><formula xml:id="formula_6">Pr [A(D) ∈ S] ≤ e • Pr [A(D ) ∈ S] + δ .</formula><p>In this paper, we consider the classic central model of DP, where a trusted curator has access to the raw dataset and releases a model trained on this dataset<ref type="foot" target="#foot_0">2</ref> .</p><p>A common principle for releasing a private estimate of a function h : D → R p is to perturb it with noise. To ensure privacy, the noise is scaled with the sensitivity ∆ q (h) = sup D∼D h(D)h(D ) q of h, with q = 1 for Laplace, and q = 2 for Gaussian mechanism. In coordinate descent methods, we release coordinate-wise gradients. The j-th coordinate of a loss function's gradient</p><formula xml:id="formula_7">∇ j : R p → R has sensitivity ∆ 1 (∇ j f ) = ∆ 2 (∇ j f ) (∇ j f is a scalar).</formula><p>For L-component-Lipschitz losses, these sensitivities are upper bounded by 2L j <ref type="bibr" target="#b31">(Mangold et al., 2022)</ref>.</p><p>In our algorithm, we will also need to compute the index of the gradient's maximal entry privately. To this end, we use the report-noisy-argmax mechanism <ref type="bibr" target="#b15">(Dwork and Roth, 2013)</ref>. This mechanism perturbs each entry of a vector with Laplace noise, calibrated to its coordinate-wise sensitivities, and releases the index of a maximal entry of this noisy vector. Revealing only this index allows to greatly reduce the noise, in comparison to releasing the full gradient. This will be the cornerstone of our greedy algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">PRIVATE GREEDY CD</head><p>In this section, we present our main contribution: the differentially private greedy coordinate descent algorithm (DP-GCD). As described in Section 4.1, DP-GCD updates only one coordinate per iteration, which is selected greedily as the (approximately) largest entry of the gradient so as to maximize the improvement in utility at each iteration. We establish privacy (Section 4.2) and utility (Section 4.3) guarantees for DP-GCD. We further show in Section 4.4 that DP-GCD enjoys improved utility for high-dimensional problems with a quasi-sparse solution (i.e., with a fraction of the parameters dominating the others). We then provide a proximal extension of DP-GCD to non-smooth problems (Section 4.5) and conclude with a discussion of DP-GCD's computational complexity in Section 4.6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">The Algorithm</head><p>At each iteration, DP-GCD (Algorithm 1) updates the parameter with the greatest gradient value (rescaled by the inverse square root of the coordinate-wise smoothness constant). This corresponds to the Gauss-Southwell-Lipschitz rule <ref type="bibr" target="#b36">(Nutini et al., 2015)</ref>. To guarantee privacy, this selection is done using the report-noisy-max mechanism <ref type="bibr" target="#b15">(Dwork and Roth, 2013)</ref> with noise scales λ j along j-th entry (j ∈ [p]). DP-GCD then performs a gradient step with step size γ j &gt; 0 along this direction. The gradient is privatized using the Laplace mechanism <ref type="bibr" target="#b15">(Dwork and Roth, 2013)</ref> with scale λ j .</p><p>Remark 4.1 (Sparsity of iterates). When initialized at w 0 = 0, DP-GCD generates sparse iterates. Since it chooses its updates greedily, this gives a screening ability to the algorithm <ref type="bibr" target="#b16">(Fang et al., 2020)</ref>. We discuss the implications of this property in Section 4.4, where we show that DP-GCD's utility is improved when the problem's solution is (quasi-)sparse.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Privacy Guarantees</head><p>The privacy guarantees of DP-GCD depends on the noise scales λ j and λ j . In Theorem 4.2, we describe how to set these values so as to ensure that DP-GCD is ( , δ)differentially private.</p><formula xml:id="formula_8">Theorem 4.2. Let , δ ∈ (0, 1]. Algorithm 1 with λ j = λ j = 8Lj n T log(1/δ) is ( , δ)-DP. Sketch of Proof. (Detailed proof in Appendix A) Let = / 16T log(1/δ).</formula><p>At an iteration t, data is accessed twice. First, to compute the index j t of the coordinate to update. It is obtained as the index of the largest noisy entry of f 's gradient, with noise Lap(λ j ). By the report-noisy-argmax mechanism, j t is -DP. Second, to compute the gradient's j t 's entry, which is released with noise Lap(λ j ).The Algorithm 1 DP-GCD: Differentially Private Greedy Coordinate Descent 1: Input: initial w 0 ∈ R p , iteration count T &gt; 0, ∀j ∈ [p], noise scales λ j , λ j , step sizes γ j &gt; 0. 2: for t = 0 to T -1 do 3:</p><formula xml:id="formula_9">j t = arg max j ∈[p] |∇ j f (w t )+χ t j | √ M j</formula><p>, with χ t j ∼ Lap(λ j ). Choose j t using report-noisy-max.</p><p>4:</p><formula xml:id="formula_10">w t+1 = w t -γ jt (∇ jt f (w t ) + η t jt )e jt , with η t jt ∼ Lap(λ jt ).</formula><p>Update the chosen coordinate.</p><p>5: return w T .</p><p>Laplace mechanism ensures that this computation is also -DP. Algorithm 1 is thus the 2T -fold composition of -DP mechanisms, and the result follows from DP's advanced composition theorem <ref type="bibr" target="#b15">(Dwork and Roth, 2013)</ref>.</p><p>Remark 4.3. The assumption ∈ (0, 1] is only used to give a closed-form expression for the noise scales λ, λ's.</p><p>In practice, we tune them numerically to obtain the desired value of &gt; 0 by the advanced composition theorem (see eq. ( <ref type="formula" target="#formula_3">2</ref>) in Appendix A), removing the assumption ≤ 1.</p><p>Computing the greedy update requires injecting Laplace noise that scales with the coordinate-wise Lipschitz constants L 1 , . . . , L p of the loss. These constants are typically smaller than their global counterpart. This allows DP-GCD to inject less noise on smaller-scaled coordinates.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Utility Guarantees</head><p>We now prove utility upper bounds for DP-GCD. We show that in favorable settings (see discussion below), DP-GCD decreases the dependence on the dimension from polynomial to logarithmic. Theorem 4.4 gives asymptotic utility upper bounds, where O ignores non-significant logarithmic terms. Complete non-asymptotic results can be found in Appendix B. Theorem 4.4. Let , δ ∈ (0, 1]. Assume (•; d) is a convex and L-component-Lipschitz loss function for all d ∈ X , and f is M -component-smooth. Define W * the set of minimizers of f , and f * the minimum of f . Let w priv ∈ R p be the output of Algorithm 1 with step sizes γ j = 1/M j , and noise scales λ 1 , . . . , λ p , λ 1 , . . . , λ p set as in Theorem 4.2 (with T chosen below) to ensure ( , δ)-DP. Then, the following holds for any ζ ∈ (0, 1]:</p><formula xml:id="formula_11">1. When f is convex, we define the quantity R M,1 = max w∈R p max w * ∈W * w -w * M,1 | f (w) ≤ f (w 0 ) . Assume the initial optimality gap is f (w 0 ) -f * ≥ 16L max T log(1/δ) log(2T p/ζ)/M min n , and set T = O(n 2/3 2/3 R 2/3 M,1 M 1/3 min /L 2/3 max log(1/δ) 1/3 ). Then with probability at least 1 -ζ, f (w priv ) -f * = O R 4/3 M,1 L 2/3 max log(1/δ) log(p/ζ) n 2/3 2/3 M 1/3 min . 2. When f is µ M,1 -strongly convex w.r.t. • M,1 , set T = O 1 µ M,1 log( Mminµ M,1 n (f (w 0 )-f (w * )) Lmax log(1/δ) log(2p/ζ) ) . Then with probability at least 1 -ζ, f (w priv ) -f * = O L 2 max log(1/δ) log(2p/µ M ζ) M min µ 2 M,1 n 2 2</formula><p>. Sketch of Proof. (Detailed proof in Appendix B). We start by proving a noisy "descent lemma". Since f is smooth, we have</p><formula xml:id="formula_12">f (w t+1 ) ≤ f (w t ) -1 2Mj ∇ j f (w t ) 2 + 1 2Mj (η t j ) 2 . The greedy selection of j gives that -1 Mj (∇ j f (w t ) + χ j ) 2 ≤ -∇f (w t ) + χ 2 M -1 ,∞ .</formula><p>We then use the inequality (a + b) 2 ≤ 2a 2 + 2b 2 for a, b ∈ R, and convexity arguments to prove the lemma. When f is convex, we have</p><formula xml:id="formula_13">f (w t+1 ) -f (w * ) ≤ f (w t ) -f (w * ) - (f (w t ) -f (w * )) 2 8 w t -w * 2 M,1 + |η t j | 2 2M j + |χ t j | 2 2M j + |χ t j * | 2 4M j * .</formula><p>There, we observe that, at each iteration, either (i) w t is far enough from the optimum, and the value of the objective decreases with high probability, either (ii) w t is close to the optimum, then all future iterates remain in a ball whose radius depends on the scale of the noise. We prove this key property rigorously in Appendix B.3.2.</p><p>When f is µ M,1 -strongly-convex w.r.t. • M,1 , we obtain</p><formula xml:id="formula_14">f (w t+1 ) -f (w * ) ≤ 1 - µ M,1 4 (f (w t ) -f (w * )) + |η t j | 2 2M j + |χ t j | 2 2M j + |χ t j * | 2 4M j * ,</formula><p>and the result follows by induction. In both settings, we use Chernoff bounds to obtain a high-probability result.</p><p>Remark 4.5. The lower bound on f (w 0 )f * in Theorem 4.4 is a standard assumption in the analysis of inexact coordinate descent methods: it ensures that sufficient decrease is possible despite the noise. A similar assumption is made by <ref type="bibr" target="#b46">Tappenden et al. (2016)</ref>, see Theorem 5.1 therein.</p><p>Discussion of the utility bounds. One of the key properties of DP-GCD is that its utility is dictated by 1 -norm quantities (R M,1 and µ M,1 ). Remarkably, this arises without enforcing any 1 constraint in the problem, which is in stark contrast with private Frank-Wolfe algorithms (DP-FW) that require such constraints <ref type="bibr" target="#b44">(Talwar et al., 2015;</ref><ref type="bibr" target="#b1">Asi et al., 2021;</ref><ref type="bibr" target="#b4">Bassily et al., 2021)</ref>. To better grasp the implications of this, we discuss our results in two regimes considered in previous work (see Section 2): (i) when these 1 -norm quantities are bounded (similarly to DP-FW algorithms), and (ii) when their 2 -norm counterparts are bounded (similarly to DP-SGD-style algorithms).</p><p>Bounded in 1 -norm. When R M,1 and µ M,1 are O(1), as assumed in prior work on DP-FW <ref type="bibr" target="#b44">(Talwar et al., 2015;</ref><ref type="bibr" target="#b1">Asi et al., 2021;</ref><ref type="bibr" target="#b4">Bassily et al., 2021)</ref>, DP-GCD's dependence on the dimension is logarithmic. For convex objectives, its utility is O(log(p)/n 2/3 2/3 ), matching that of DP-FW and known lower bounds <ref type="bibr" target="#b44">(Talwar et al., 2015)</ref>. For stronglyconvex problems, DP-GCD is the first algorithm to achieve a O(log(p)/n 2 2 ) utility. Indeed, the only competing result in this setting, due to <ref type="bibr" target="#b1">Asi et al. (2021)</ref>, obtains a worse utility of O(log(p) 4/3 /n 4/3 4/3 ) by using an impractical reduction of DP-FW to the convex case. DP-GCD outperforms this prior result without suffering the extra complexity due to the reduction.</p><p>Bounded in 2 -norm. Consider R M,2 and µ M,2 , the 2norm counterparts of R M,1 and µ M,1 . Assume that R M,2 and µ M,2 are both O(1), as considered in DP-SGD and its variants <ref type="bibr" target="#b6">(Bassily et al., 2014;</ref><ref type="bibr" target="#b51">Wang et al., 2017)</ref>. We compare these quantities using the following inequalities (see <ref type="bibr" target="#b43">Stich et al., 2017;</ref><ref type="bibr" target="#b36">Nutini et al., 2015)</ref>:</p><formula xml:id="formula_15">R 2 M,2 ≤ R 2 M,1 ≤ pR 2 M,2 , 1 p µ M,2 ≤ µ M,1 ≤ µ M,2 .</formula><p>In the best case of these inequalities, the O(log p) utility bounds of the bounded 1 norm regime are preserved in the bounded 2 scenario. In the worst case, the utility of DP-GCD becomes O(p 2/3 /n 2/3 2/3 ) and O(p 2 /n 2 2 ) for convex and strongly-convex objectives respectively. These worst-case results match DP-FW's utility in the convex setting (see e.g., <ref type="bibr" target="#b1">Asi et al. (2021)</ref>), but they do not match DP-SGD's utility. However, this sheds light on an interesting phenomenon: DP-GCD interpolates between 1 -and 2norm regimes. Indeed, it lies somewhere between the two extreme cases we just described, depending on how the 1and 2 -norm constants compare. Most interestingly, it does so without a priori knowledge of the problem or explicit constraint on the domain. Whether there exists an algorithm that yields optimal utility in all regimes is an interesting open question.</p><p>Coordinate-wise regularity. Due to its use of coordinate-wise step sizes, DP-GCD can adapt to coordinate-wise imbalance of the objective in the same way as its randomized counterpart, DP-CD, where coordinates are chosen uniformly at random <ref type="bibr" target="#b31">(Mangold et al., 2022)</ref>. This adaptivity notably appears in Theorem 4.4 through the measurement of R M,1 and µ M,1 relatively to the scaled norm • M,1 (as defined in Section 3). We refer to <ref type="bibr" target="#b31">(Mangold et al., 2022)</ref> for detailed discussion of these quantities and the associated gains compared to full gradient methods like DP-SGD.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Better Utility on Quasi-Sparse Problems</head><p>In addition to the general utility results presented above, we now exhibit a specific setting where DP-GCD performs especially well, namely strongly-convex problems whose solutions are dominated by a few parameters. We call such vectors quasi-sparse.</p><p>Definition 4.6 ((α, τ )-quasi-sparsity). A vector w ∈ R p is (α, τ )-quasi-sparse if it has at most τ entries superior to α (in modulus). When α = 0, the vector is called τ -sparse.</p><p>Note that any vector in R p is (0, p)-quasi-sparse, and for any τ there exists α &gt; 0 such that the vector is (α, τ )quasi-sparse. In fact, α and τ are linked, and τ (α) can be seen as a function of α. Of course, quasi-sparsity will only yield meaningful improvements when α and τ are small simultaneously.</p><p>We now state the main result of this section, which shows that DP-GCD (initialized with w 0 = 0) converges to a good approximate solution in few iterations for problems with quasi-sparse solutions. </p><formula xml:id="formula_16">f (w T ) -f * ≤ T t=1 1 - µ M,2 4(τ + min(t, s)) (f (w 0 ) -f * ) + O (T + τ )(p -τ )α 2 + L 2 max T (T + τ ) M min µ M,2 n 2 2 . Setting T = s+τ µ M,2 log((f (w 0 ) -f * )M min µ M,2 n 2 2 /L 2 ), and assuming α 2 = O L 2 max (s + τ )/M min µ 2 M,2 pn 2 2 , we obtain that with probability at least 1 -ζ, f (w T ) -f * = O L 2 max M min (s + τ ) 2 log(2p/ζ) µ M,2 n 2 2 .</formula><p>Here, strong convexity is measured in 2 norm but the dependence on the dimension is reduced from p, the ambient space dimension, to (s + τ ) 2 , the effective dimension of the space where the optimization actually takes place.</p><p>For high-dimensional sparse problems, the latter is typically much smaller and yields a large improvement in utility. Note that it is not necessary for the solution to be perfectly sparse: it suffices that most of its mass is concentrated in a fraction of the coordinates. Notably, when</p><formula xml:id="formula_17">α 2 = O(L 2 max T /M min µ M,2 pn 2 2</formula><p>), the lack of sparsity is smaller than the noise, and does not affect the rate. It generalizes the results by <ref type="bibr" target="#b16">Fang et al. (2020)</ref> for non-private and sparse settings, that we recover when α = 0 and → +∞.</p><p>In practice, the assumption over the iterates' sparsity is often met with s p. In the non-private setting, greedy coordinate descent is known to focus on coordinates that are non-zero in the solution <ref type="bibr" target="#b32">(Massias et al., 2017)</ref>: this keeps iterates' sparsity close to the one of the solution. Furthermore, due to privacy constraints, DP-GCD will often run for T p iterations. This is especially true in highdimensional problems, where the amount of noise required to guarantee privacy does not allow many iterations (cf. experiments in Section 5).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Proximal DP-GCD</head><p>In Section 4.4, we proved that DP-GCD's utility is improved when problem's solution is (quasi-)sparse. This motivates us to consider problems with sparsity-inducing regularization, such as the 1 norm of w <ref type="bibr" target="#b47">(Tibshirani, 1996)</ref>. To tackle such non-smooth terms, we propose a proximal version of DP-GCD (for which the same privacy guarantees hold), building upon the multiple greedy rules that have been proposed for the nonsmooth setting (see e.g., <ref type="bibr" target="#b49">Tseng and Yun, 2009;</ref><ref type="bibr" target="#b36">Nutini et al., 2015)</ref>. We describe this extension in Appendix C, and study it numerically in Section 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6">Computational Cost</head><p>Each iteration of DP-GCD requires computing a full gradient, but only uses one of its coordinates. In non-private optimization, one would generally be better off performing the full update to avoid wasting computation. This is not the case when gradients are private. Indeed, using the full gradient requires privatizing p coordinates, even when only a few of them may be needed. Conversely, the report noisy max mechanism <ref type="bibr" target="#b15">(Dwork and Roth, 2013)</ref> allows to select these entries without paying the full privacy cost of dimension. Hence, the greedy updates of DP-GCD reduce the noise needed at the cost of more computation.</p><p>In practice, the higher computational cost of each iteration may not always translate in a significantly larger cost overall: as shown by our theoretical results, DP-GCD is able to exploit the quasi-sparsity of the solution to progress fast and only a handful of iterations may be needed to reach a good private solution. In contrast, most updates of classic private optimization algorithms (like DP-SGD) may not be worth doing, and lead to unnecessary injection of noise. We illustrate this phenomenon numerically in Section 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">EXPERIMENTS</head><p>In this section, we evaluate the practical performance of DP-GCD on linear models using the logistic and squared loss with 1 and 2 regularization. We compare DP-GCD to two competitors: differentially private stochastic gradient descent (DP-SGD) with batch size 1 <ref type="bibr" target="#b6">(Bassily et al., 2014;</ref><ref type="bibr" target="#b0">Abadi et al., 2016)</ref>, and differentially private randomized coordinate descent (DP-CD) <ref type="bibr" target="#b31">(Mangold et al., 2022)</ref>. The code is available online<ref type="foot" target="#foot_1">3</ref> and in the supplementary.</p><p>Datasets. The first two datasets, coined log1 and log2, are synthetic. We generate a design matrix X ∈ R 1,000×100 with unit-variance, normally-distributed columns. Labels are computed as y = Xw (true) + ε, where ε is normally-distributed noise and w (true) is drawn from a log-normal distribution of parameters µ = 0 and σ = 1 or 2 respectively. This makes w (true) quasi-sparse. The square dataset is generated similarly, with X ∈ R 1,000×1,000 and w (true) having only 10 non-zero values. The california dataset can be downloaded from scikit-learn <ref type="bibr" target="#b38">(Pedregosa et al., 2011)</ref> while mtp, madelon and dorothea are available in the OpenML repository <ref type="bibr" target="#b50">(Vanschoren et al., 2014)</ref>; see summary in Table 1. We discuss the levels of (quasi)-sparsity of each problem's solution in Appendix D.</p><p>Algorithmic setup. (Privacy.) For each algorithm, the tightest noise scales are computed numerically to guarantee a suitable privacy level of (1, 1/n 2 )-DP, where n is the number of records in the dataset. For DP-CD and DP-SGD, we privatize the gradients with the Gaussian mechanism <ref type="bibr" target="#b15">(Dwork and Roth, 2013)</ref>, and account for privacy tightly using Rényi differential privacy (RDP) <ref type="bibr" target="#b33">(Mironov, 2017)</ref>. For DP-SGD, we use RDP amplification for the subsampled Gaussian mechanism <ref type="bibr" target="#b34">(Mironov et al., 2019)</ref>.</p><p>(Hyperparameters.) For DP-SGD, we use constant step sizes and standard gradient clipping <ref type="bibr" target="#b0">(Abadi et al., 2016)</ref>. For DP-GCD and DP-CD, we set the step sizes to η j = γ Mj , and adapt the coordinate-wise clipping thresholds from one hyperparameter, as proposed by <ref type="bibr" target="#b31">Mangold et al. (2022)</ref>. For each algorithm, we thus tune two hyperparameters: one step-size and one clipping threshold; see also Appendix D.</p><p>(Plots.) In all experiments, we plot the relative error to the non-private optimal objective value for the best set of hyperparameters (averaged over 5 runs), as a function of the number of passes on the data. Each pass corresponds to p iterations of DP-CD, n iterations of DP-SGD and 1 iteration of DP-GCD. This guarantees the same amount of computation for each algorithm, for each x-axis tick.</p><p>DP-GCD exploits problem structure. In the higherdimensional datasets square and dorothea, where p ≥ n, DP-GCD is the only algorithm that manages to do multiple iterations and to decrease the objective value (see <ref type="bibr">Figures 1e and 1g)</ref>. In both problems, solutions are sparse due Passes on data</p><formula xml:id="formula_18">5 × 10 -1 6 × 10 -1 7 × 10 -1 8 × 10 -1 (a) log1 Logistic + L2 (λ = 1e-3) 0 10 20</formula><p>Passes on data</p><formula xml:id="formula_19">3 × 10 -1 4 × 10 -1 6 × 10 -1 (b) log2 Logistic + L2 (λ = 1e-3) 0 10 20</formula><p>Passes on data</p><formula xml:id="formula_20">10 -1 6 × 10 -2 7 × 10 -2 8 × 10 -2 9 × 10 -2 (c) mtp LS + L2 (λ = 5e-8) 0 10 20</formula><p>Passes on data</p><formula xml:id="formula_21">4 × 10 -2 5 × 10 -2 (d) madelon Logistic + L2 (λ = 1)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Relative Error to</head><p>Non-Private Opt. Passes on data</p><formula xml:id="formula_22">10 -4 10 -3 10 -2 10 -1 (f) california LASSO (λ = 0.1) 0 1 2 3</formula><p>Passes on data</p><formula xml:id="formula_23">6 × 10 -1 7 × 10 -1 8 × 10 -1 (g) dorothea Logistic + L1 (λ = 0.01) 0 5 10</formula><p>Passes on data</p><formula xml:id="formula_24">10 -4 10 -3 10 -2 DP-CD DP-SGD DP-GCD (h) madelon Logistic + L1 (λ = 0.05)</formula><p>Figure <ref type="figure">1</ref>: Relative error (min/mean/max over 5 runs) to non-private optimal for DP-GCD (our approach) versus DP-CD and DP-SGD. On the x-axis, 1 tick represents a full access to the data: p iterations of DP-CD, n iterations of DP-SGD and 1 iteration of DP-GCD. Number of iterations, clipping thresholds and step sizes are tuned simultaneously for each algorithm.</p><p>to the 1 regularization. This shows that DP-GCD's greedy selection of updates can exploit this property to find relevant non-zero coefficients (see Table <ref type="table" target="#tab_2">3</ref> in Appendix D), even when this selection is noisy. The lower-dimensional datasets log1, log2 and madelon (where p &lt; n) are still too high dimensional (relatively to n) for DP-SGD and DP-CD to make significant progress. In contrast, DP-GCD exploits the fact that solutions are quasi-sparse to find good approximate solutions quickly (see Figures <ref type="figure">1a,  1b, 1d, 1e, 1g</ref> and<ref type="figure">1h</ref>). On the low-dimensional dataset california, DP-GCD is roughly on par with DP-SGD and DP-CD (see Figure <ref type="figure">1f</ref>). This is due to the additional noise term introduced by the greedy selection rule: in such setting, the lower number of iterations does not compensate for this as much as in higher-dimensional problems. A similar phenomenon arise in mtp (Figure <ref type="figure">1c</ref>), whose solution is not imbalanced enough for DP-GCD to be superior to its competitors.</p><p>Computational complexity. As discussed in Section 4.6, one iteration of DP-GCD requires a full pass on the data. This is as costly as p iterations of DP-CD or n iterations of DP-SGD. Nonetheless, on many problems, DP-GCD requires just as many passes on the data as DP-CD and DP-SGD (Figures <ref type="figure">1a</ref> and<ref type="figure">1c to 1f</ref>). When more computation is required, it also provides significantly better solutions than DP-CD and DP-SGD (Figure <ref type="figure">1b</ref>). This is in line with our theoretical results from Section 4.4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">CONCLUSION AND DISCUSSION</head><p>We proposed DP-GCD, a greedy coordinate descent algorithm for DP-ERM. In favorable settings, DP-GCD achieves utility guarantees of O(log(p)/n 2/3 2/3 ) and O(log(p)/n 2 2 ) for convex and strongly-convex objectives. It is the first algorithm to achieve such rates without solving an 1 -constrained problem. Instead, we show that DP-GCD depends on 1 -norm quantities and automatically adapts to the structure of the problem. Specifically, DP-GCD interpolates between logarithmic and polynomial dependence on the dimension, depending on the problem. Thus, DP-GCD constitutes a step towards the design of an algorithm that adjusts to the appropriate p structure of a problem (see <ref type="bibr" target="#b4">Bassily et al., 2021;</ref><ref type="bibr" target="#b1">Asi et al., 2021)</ref>.</p><p>We also showed that DP-GCD adapts to the quasi-sparsity of the problem, without requiring a priori knowledge about it. In such problems, it converges to a good approximate solution in few iterations. This improves utility, and reduces the polynomial dependence on the dimension to a polyno-mial dependence on the (much smaller) quasi-sparsity level of the solution.</p><p>We also proposed and evaluated a proximal variant of DP-GCD, allowing non-smooth, sparsity-inducing regularization. While it is not covered by our utility guarantees, we note that the only existing analysis of such variants in the non-private setting is the one of <ref type="bibr" target="#b27">Karimireddy et al. (2019)</ref> for 1 and box constraints. Their proof relies on an alternation between good (that provably progress) and bad steps (that do not increase the objective), which does not transfer to the private setting. Extending such results to DP-ERM is an exciting direction for future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A PROOF OF PRIVACY</head><formula xml:id="formula_25">Theorem 4.2. Let , δ ∈ (0, 1]. Algorithm 1 with λ j = λ j = 8Lj n T log(1/δ) is ( , δ)-DP.</formula><p>Proof. In each iteration of Algorithm 1, the data is accessed twice: once to choose the coordinate and once to compute the private gradient. In total, data is thus queried 2T times.</p><p>Let λ j = λ j = 2Lj n . For j ∈ [p], the gradient's j-th entry has sensitivity 2L j . Thus, by the report noisy max mechanism <ref type="bibr" target="#b15">(Dwork and Roth, 2013)</ref>, the greedy choice of j is -DP. By the Laplace mechanism <ref type="bibr" target="#b15">(Dwork and Roth, 2013)</ref>, computing the corresponding gradient coordinate is also -DP.</p><p>The advanced composition theorem for differential privacy thus ensures that the 2T -fold composition of these mechanisms is ( , δ)-DP for δ &gt; 0 and</p><formula xml:id="formula_26">= 4T log(1/δ) + 2T (exp( ) -1) ,<label>(2)</label></formula><p>where we recall that = </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B PROOF OF UTILITY</head><p>In this section, we prove Theorem 4.4 and Theorem 4.7, giving utility upper bounds for DP-GCD. We obtain these highprobability results through a careful examination of the properties of DP-GCD's iterates, and obtain high-probability results by using concentration inequalities (see Appendix B.1).</p><p>In Appendix B.2, we prove a general descent lemma, which implies that iterates of DP-GCD converge (with high probability) to a neighborhood of the optimum. This property is proven rigorously in Appendix B.3.2, and we give the utility results for general convex functions in Appendix B.3.3. Under the additional assumption that the objective is strongly convex, we prove better utility bounds in Appendix B.4. These bounds follow from a key lemma (see Appendix B.4.1), which implies linear convergence to a neighborhood of the optimum. We then use this result in two settings, obtaining two different rates: first in a general setting (in Appendix B.4.2), then under the additional assumption that the problem's solution is quasi-sparse (in Appendix B.4.3).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.1 Concentration Lemma</head><p>To prove high-probability utility results, we first bound (in Lemma B.1) the probability for a sum of squared Laplacian variables to exceed a given threshold. Lemma B.1. Let K &gt; 0 and λ 1 , . . . , λ K &gt; 0. Define X k ∼ Lap(λ k ) and λ max = max k∈[K] λ k . For any β &gt; 0, it holds that</p><formula xml:id="formula_27">Pr K k=1 X 2 k ≥ β ≤ 2 K exp - √ β 2λ max .<label>(3)</label></formula><p>Proof. We first remark that (</p><formula xml:id="formula_28">K k=1 |X k |) 2 = K k=1 K k =1 |X k ||X k | ≥ K k=1 X 2 k . Therefore Pr K k=1 X 2 k ≥ a 2 ≤ Pr K k=1 |X k | 2 ≥ a 2 = Pr K k=1 |X k | ≥ a .<label>(4)</label></formula><p>Chernoff's inequality now gives, for any γ &gt; 0,</p><formula xml:id="formula_29">Pr K k=1 |X k | ≥ a ≤ exp(-γa)E exp(γ K k=1 |X k |) .<label>(5)</label></formula><p>By the properties of the exponential and the X k 's independence, we can rewrite the inequality as</p><formula xml:id="formula_30">Pr K k=1 |X k | ≥ a ≤ exp(-γa)E K k=1 exp γ|X k | = exp(-γa) K k=1 E exp γ|X k | .<label>(6)</label></formula><p>We can now compute the expectation of exp(</p><formula xml:id="formula_31">γ|X k |) for k ∈ [K], E exp γ|X k | = 1 2λ k +∞ -∞ exp(γ|x|) exp(- |x| λ k )dx = 1 λ k +∞ 0 exp (γ - 1 λ k )x dx .<label>(7)</label></formula><p>We choose γ = 1/2λ max , such that γ ≤ 1/2λ k for all k ∈ [K] and obtain</p><formula xml:id="formula_32">E exp γ|X k | = 1 λ k 1 1 λ k -γ = 1 1 -γλ k ≤ 2 . (<label>8</label></formula><formula xml:id="formula_33">)</formula><p>Plugging everything together, we have proved that</p><formula xml:id="formula_34">Pr K k=1 X 2 k ≥ a 2 ≤ Pr K k=1 |X k | ≥ a ≤ 2 K exp(- a 2λ max ) ,<label>(9)</label></formula><p>and taking a = √ β gives the result.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.2 Descent Lemma</head><p>We now prove a noisy descent lemma for DP-GCD (Lemma B.2). This lemma bounds the suboptimality f (w t+1 )f (w * ) at time t + 1 as a function of the suboptimality f (w t )f (w * ) at time t, of the gradient's largest entry and of the noise. At this point, we remark that when the gradient is large enough, it is very probable that 1 8 ∇f</p><formula xml:id="formula_35">(w t ) 2 M -1 ,∞ ≥ 1 2Mj |η t j | 2 + 1 2Mj |χ t j | 2 + 1 4M j * |χ t j * | 2 :</formula><p>this implies that the value of the objective function decreases with high probability, even under the presence of noise. This observation will be crucial for proving utility for general convex functions. Lemma B.2. Let t ≥ 0 and w t , w t+1 ∈ R p two consecutive iterates of Algorithm 1, with γ j = 1/M j and λ j , λ j chosen as in Theorem 4.2 to ensure , δ-DP. We denote by j ∈ [p] the coordinate chosen at this step t, and by j * = arg max j∈[p] |∇ j f (w t )|/ M j the coordinate that would have been chosen without noise. The following inequality holds</p><formula xml:id="formula_36">f (w t+1 ) -f (w * ) ≤ f (w t ) -f (w * ) - 1 8 ∇f (w t ) 2 M -1 ,∞ + 1 2M j |η t j | 2 + 1 2M j |χ t j | 2 + 1 4M j * |χ t j * | 2 . (<label>10</label></formula><formula xml:id="formula_37">)</formula><p>Proof. The smoothness of f gives a first inequality</p><formula xml:id="formula_38">f (w t+1 ) ≤ f (w t ) + ∇f (w t ), w t+1 -w t + 1 2 w t+1 -w t 2 M (11) = f (w t ) - 1 M j ∇ j f (w t )(∇ j f (w t ) + η t j ) + 1 2M j (∇ j f (w t ) + η t j ) 2 (12) = f (w t ) - 1 M j ∇ j f (w t ) 2 - 1 M j ∇ j f (w t )η t j + 1 2M j (∇ j f (w t )) 2 + 1 M j ∇ j f (w t )η t j + 1 2M j (η t j ) 2 (13) = f (w t ) - 1 2M j ∇ j f (w t ) 2 + 1 2M j (η t j ) 2 . (<label>14</label></formula><formula xml:id="formula_39">)</formula><p>We will make the noisy gradient appear, so as to use the noisy greedy rule. To do so, we remark that the classical inequality</p><formula xml:id="formula_40">(a + b) 2 ≤ 2a 2 + 2b 2 for any a, b ∈ R implies that -a 2 ≤ -1 2 (a + b) 2 + b 2 . Applied with a = ∇ j f (w t )/ M j and b = χ t j / M j , this results in - 1 2M j ∇ j f (w t ) 2 ≤ - 1 4M j (∇ j f (w t ) + χ t j ) 2 + 1 2M j (χ t j ) 2 . (<label>15</label></formula><formula xml:id="formula_41">)</formula><p>And, by the noisy greedy rule, 1 √</p><formula xml:id="formula_42">M j * |∇ j * f (w t ) + χ t j * | ≤ 1 √ Mj |∇ j f (w t ) + χ t j |.</formula><p>We replace in (15) and use the inequality</p><formula xml:id="formula_43">-a 2 ≤ -1 2 (a + b) 2 + b 2 with a = (∇ j * f (w t ) + χ j * )/ M j * and b = -χ j * / M j * to obtain - 1 2M j ∇ j f (w t ) 2 ≤ - 1 4M j * (∇ j * f (w t ) + χ t j * ) 2 + 1 2M j (χ t j ) 2 (16) ≤ - 1 8M j * (∇ j * f (w t )) 2 + 1 4M j * (χ t j * ) 2 + 1 2M j (χ t j ) 2 . (<label>17</label></formula><formula xml:id="formula_44">)</formula><p>The result follows from ( <ref type="formula" target="#formula_38">14</ref>) and 1</p><formula xml:id="formula_45">M j * (∇ j * f (w t )) 2 = ∇f (w t ) 2 M -1 ,∞ .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.3 Utility for General Convex Functions</head><p>In this section, we derive an upper bound on the utility of DP-GCD for convex objective functions. First, we use convexity of f to upper bound the decrease described in Lemma B.2. This gives Lemma B.3 in Appendix B.3.1, where the suboptimality gap f (w t+1 )f (w * ) at time t + 1 is upper bound by a function of the suboptimality gap f (w t )f (w * ) at time t and the noise injected in step t. The novelty of our analysis lies in Lemma B.4, where examine the decrease of the objective. Specifically, we show that either (i) f (w t ) is far from its minimum, and the suboptimality gap decreases with high probability, either (ii) f (w t ) is close to its minimum, then all future iterates of DP-GCD will remain in a ball whose radius is determined by the variance of the noise. This observation is essential for proving the utility results stated in Section 4.3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.3.1 Descent Lemma for Convex Functions</head><p>Lemma B.3. Under the hypotheses of Lemma B.2, for a convex objective function f , we have</p><formula xml:id="formula_46">f (w t+1 ) -f (w * ) ≤ f (w t ) -f (w * ) - (f (w t ) -f (w * )) 2 8 w t -w * 2 M,1 + 1 2M j |η t j | 2 + 1 2M j |χ t j | 2 + 1 4M j * |χ t j * | 2 . (<label>18</label></formula><formula xml:id="formula_47">)</formula><p>Proof. Since f is convex, it holds that</p><formula xml:id="formula_48">f (w * ) ≥ f (w t ) + ∇f (w t ), w * -w t .<label>(19)</label></formula><p>After reorganizing the terms, we can upper bound them using Hölder's inequality</p><formula xml:id="formula_49">f (w t ) -f (w * ) ≤ ∇f (w t ), w t -w * (20) ≤ ∇f (w t ) M -1 ,∞ w t -w * M,1 ,<label>(21)</label></formula><p>where the second inequality holds since • M,1 and • M -1 ,∞ are conjugate norms. We now divide (21) by w tw * M,1 , square it and reorganize to get -∇f</p><formula xml:id="formula_50">(w t ) 2 M -1 ,∞ ≤ -(f (w t )-f (w * )) 2 w t -w * 2 M,1</formula><p>. Replacing in Lemma B.2 gives the result.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.3.2 Key Lemma on the Behavior of DP-GCD's Iterates</head><p>Now that we have an inequality in the form of Lemma B.3, we prove that iterates of DP-GCD converge to a vicinity of the optimum. In the general lemma below, think of ξ t as f (w t )f (w * ) and of β as the variance of the term. This result will be combined with Lemma B.1 to obtain high-probability bounds.</p><p>Lemma B.4. Let {c t } t≥0 and {ξ t } t≥0 be two sequences of positive values that satisfy, for all t ≥ 0,</p><formula xml:id="formula_51">ξ t+1 ≤ ξ t - ξ 2 t c t + β,<label>(22)</label></formula><p>such that if ξ t ≤ ξ 0 then c t ≤ c 0 . Assume that β ≤ c 0 and ξ 0 ≥ 2 √ βc 0 . Then:</p><p>1. For all t &gt; 0, c t ≤ c 0 , and there exists t</p><formula xml:id="formula_52">* &gt; 0 such that ξ t+1 ≤ ξ t if t &lt; t * and ξ t ≤ 2 √ βc 0 if t ≥ t * . 2. For all t ≥ 1, ξ t ≤ c0 t + 2 √ βc 0 . Proof. 1. Assume that for t ≥ 0, √ βc 0 ≤ ξ t ≤ ξ 0 . Then, ξ t+1 ≤ ξ t - ξ 2 t c t + β ≤ ξ t - √ βc 0 2 c 0 + β = ξ t ,<label>(23)</label></formula><p>where the second inequality comes from ξ t ≥ √ βc 0 and ξ t ≤ ξ 0 (which implies c t ≤ c 0 ). We now define the following value t * , which defines the point of rupture between two regimes for ξ t :</p><formula xml:id="formula_53">t * = min t ≥ 0 ξ t ≤ βc 0 . (<label>24</label></formula><formula xml:id="formula_54">)</formula><p>Let t &lt; t * , assume that ξ t ≤ ξ 0 , then (23) holds, that is ξ t+1 ≤ ξ t ≤ ξ 0 . By induction, it follows that for all t &lt; t * , ξ t+1 ≤ ξ t ≤ ξ 0 and c t ≤ c 0 .</p><p>Remark now that ξ t * ≤ √ βc 0 , we prove by induction that ξ t stays under 2 √ βc 0 for t ≥ t * . Assume that for t ≥ t * , ξ t ≤ 2 √ βc 0 . Then, there are two possibilities. If ξ t ≤ √ βc 0 , then</p><formula xml:id="formula_55">ξ t+1 ≤ ξ t - ξ 2 t c t + β ≤ βc 0 + β ≤ 2 βc 0 ,<label>(25)</label></formula><p>and ξ t+1 ≤ 2 √ βc 0 . Otherwise, √ βc 0 ≤ ξ t ≤ 2 √ βc 0 ≤ ξ 0 and (23) holds, which gives ξ t+1 ≤ ξ t ≤ 2 √ βc 0 . We proved that for t ≥ t * , ξ t ≤ 2 √ βc 0 , which concludes the proof of the first part of the lemma.</p><p>2. We start by proving this statement for 0 &lt; t &lt; t * -1. Define ω = 2u c0 and u = √ βc 0 . The assumption on ξ t implies, by the first part of the lemma, ξ t+1 ≤ ξ t -</p><formula xml:id="formula_56">ξ 2 t ct + β ≤ ξ t - ξ 2 t c0 + β, which can be rewritten ξ t+1 -u ≤ (1 -ω)(ξ t -u) - (ξ t -u) 2 c 0 ,<label>(26)</label></formula><p>since</p><formula xml:id="formula_57">(1 -ω)(ξ t -u) -(ξt-u) 2 c0 = ξ t -ωξ t -u + ωu - ξ 2 t c0 -2ξtu c0 -u 2 c0 = ξ t - ξ 2 t c0 -u + ωu -u 2 c0 , and ωu -u 2 c0 = u 2 c0 = β. Since t &lt; t * -1, ξ t+1 -u &gt; 0 and ξ t -u &gt; 0, we can thus divide (26) by (ξ t+1 -u)(ξ t -u) to obtain 1 ξ t -u ≤ 1 -ω ξ t+1 -u - ξ t -u (ξ t+1 -u)c 0 ≤ 1 -ω ξ t+1 -u - 1 c 0 ≤ 1 ξ t+1 -u - 1 c 0 ,<label>(27)</label></formula><p>where the second inequality comes from ξ t+1u ≤ ξ tu from the first part of the lemma. By applying this inequality recursively and taking the inverse of the result, we obtain the desired resuld ξ</p><formula xml:id="formula_58">t ≤ c0 t + √ βc 0 ≤ c0 t + 2 √ βc 0 for all 0 &lt; t &lt; t * .</formula><p>For t ≥ t * , we have already proved that ξ t ≤ 2 √ βc 0 ≤ c0 t + 2 √ βc 0 , which concludes our proof.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.3.3 Convex Utility Result</head><p>Theorem 4.4. (Convex Case) Let , δ ∈ (0, 1]. Assume (•; d) is a convex and L-component-Lipschitz loss function for all d ∈ X , and f is M -component-smooth. Define W * the set of minimizers of f , and f * the minimum of f . Let w priv ∈ R p be the output of Algorithm 1 with step sizes γ j = 1/M j , and noise scales λ 1 , . . . , λ p , λ 1 , . . . , λ p set as in Theorem 4.2 (with T chosen below) to ensure ( , δ)-DP. Then, the following holds for ζ ∈ (0, 1]:</p><formula xml:id="formula_59">f (w priv ) -f (w * ) ≤ 8R 2 M T + 32R 2 M β ,<label>(28)</label></formula><formula xml:id="formula_60">where β = 2λ 2 max Mmin log( 8T p ζ ) 2 , and R M = max w∈R p min w * ∈W * w -w * M,1 | f (w) ≤ f (w 0 ) . If we set T = n 2 2 R 2 M Mmin 2 7 L 2 max log(1/δ) 1/3 , then with probability at least 1 -ζ, f (w T ) -f (w 0 ) = O R 4/3 M L 2/3 max log(p/ζ) M 1/3 min n 2/3 2/3 . (<label>29</label></formula><formula xml:id="formula_61">)</formula><p>Proof. Let ξ t = f (w t )f (w * ). We upper bound the following probability by the union bound, and the fact that for t ≥ 0, the events E t j : "coordinate j is updated at step t" for j ∈ [p] partition the probability space:</p><formula xml:id="formula_62">Pr ∃t, ξ t+1 ≥ ξ t - ξ 2 t 8 w t -w * 2 M,1 + β ≤ T -1 t=0 Pr ξ t+1 ≥ ξ t - ξ 2 t 8 w t -w * 2 M,1 + β (30) = T -1 t=0 p j=1 Pr ξ t+1 ≥ ξ t - ξ 2 t 8 w t -w * 2 M,1 + β ∧ E t j . (<label>31</label></formula><formula xml:id="formula_63">) Lemma B.3 gives ξ t+1 ≤ ξ t - ξ 2 t 8 w t -w * 2 M,1 + 1 2Mj |η t j | 2 + 1 2Mj |χ t j | 2 + 1 4M j * |χ t j * | 2 .</formula><p>We thus have the following upper bound:</p><formula xml:id="formula_64">Pr ∃t, ξ t+1 ≥ ξ t - 1 8 w t -w * 2 M,1 ξ 2 t + β ≤ T -1 t=0 p j=1 Pr |η t j | 2 2Mj + |χ t j | 2 2Mj + |χ t j * | 2 4M j * ≥ β (32) ≤ T -1 t=0 p j=1 Pr |η t j | 2 + |χ t j | 2 + |χ t j * | 2 ≥ 2M min β . (33) By Lemma B.1 with X 1 = η t j ∼ Lap(λ j ), X 2 = χ t j ∼ Lap(λ j ) and X 3 = χ t j * ∼ Lap(λ j * ), it holds that Pr |η t j | 2 + |χ t j | 2 + |χ t j * | 2 ≥ 2M min β ≤ 8 exp - √ 2M min β 2λ max = ζ T p ,<label>(34)</label></formula><p>where the last equality comes from β = We now prove a link between f 's largest gradient entry and the suboptimality gap, under the assumption that there exists a unique minimizer w * of f that is (α, τ )-quasi-sparse. Note that this assumption is not restrictive in general as any vector in R p is (0, p)-quasi-sparse, and for any τ there exists α &gt; 0 such that the vector is (α, τ )-quasi-sparse. We will denote by W τ,α ⊆ R p the set of (α, τ )-quasi-sparse vectors of R p :</p><formula xml:id="formula_65">W τ,α = {w ∈ R p | |{j ∈ [p] | |w j | ≥ α}| ≤ τ } . (<label>38</label></formula><formula xml:id="formula_66">)</formula><p>When α = 0, we simply write W τ = W τ,0 , that is the set of τ -sparse vectors. We also define the associated thresholding operator π α , that puts to 0 the coordinates that are smaller than α, "projecting" vectors from W τ,α to W τ , i.e., for w ∈ R p , π α (w) = 0 if |w j | ≤ α , w j otherwise .</p><p>(</p><formula xml:id="formula_67">)<label>39</label></formula><p>where D = (d 1 , . . . , d n ) is a dataset of n samples drawn from a universe X , : R p × X → R is a loss function which is convex and smooth in w, and ψ : R p → R is a convex regularizer which is separable (i.e., ψ(w) = p j=1 ψ j (w j )) and typically nonsmooth (e.g., 1 -norm).</p><p>Algorithm 2 DP-GCD (Proximal Version): Private Proximal Greedy CD 1: Input: initial w 0 ∈ R p , iteration count T &gt; 0, ∀j ∈ [p], noise scales λ j , λ j , step sizes γ j &gt; 0. 2: for t = 0 to T -1 do 3: Select j t by the noisy GS-s, GS-r or GS-q rule. 4: w t+1 = w t + (prox γ j ψ j (w tγ j (∇ j f (w t ) + η t jt ))w t j )e j , η t jt ∼ Lap(λ jt ). 5: return w T . Runtime. Finally, we report the runtime of DP-GCD, in comparison with DP-CD and DP-SGD in Figure <ref type="figure">4</ref>, that is the counterpart of Figure <ref type="figure">1</ref>, except with runtime on the x-axis. These results confirm the fact that DP-GCD can be efficient, although its iterations are expensive to compute. Indeed, in imbalanced problems, the small number of iterations of DP-GCD enables it to run faster than DP-SGD, and in roughly the same time as DP-CD, while improving utility.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>Proceedings of the 26 th International Conference on Artificial Intelligence and Statistics (AISTATS) 2023, Valencia, Spain. PMLR: Volume 206. Copyright 2023 by the author(s).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>and their Lipschitz counterparts L min and L max . Differential privacy (DP). Let D be a set of datasets and F a set of possible outcomes. Two datasets D, D ∈ D are said neighboring (denoted by D ∼ D ) if they differ on at most one element. Definition 3.1 (Differential Privacy, Dwork 2006). A randomized algorithm A : D → F is ( , δ)-differentially private if, for all neighboring datasets D, D ∈ D and all S ⊆ F in the range of A:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Theorem 4. 7 (</head><label>7</label><figDesc>Proof in Appendix B.4.3). Consider f satisfying the hypotheses of Theorem 4.4, with Algorithm 1 initialized at w 0 = 0. We denote its output w T , and assume that its iterates remain s-sparse for some s ≤ p. Assume that f is µ M,2 -strongly-convex w.r.t. • M,2 , and that the (unique) solution of problem (1) is (α, τ )-quasi-sparse for some α, τ ≥ 0. Let 0 ≤ T ≤ pτ and ζ ∈ [0, 1]. Then with probability at least 1ζ:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>j ∈ [p]. When ≤ 1, we can give a simpler expression (see Corollary 3.21 of Dwork and Roth, 2013): with = /4 T log(1/δ), Algorithm 1 is ( , δ)-DP for λ j = λ j = 8L j T log(1/δ)/n .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>2λ 2 max</head><label>2</label><figDesc>Mmin log( 8T p ζ ) 2 . We have proved thatPr ∃t, ξ t+1 ≥ ξ tour Lemma B.4, with ξ t = f (w t )f (w * ); c 0 = 8R 2 M and c t = 8 w tw * 2 M,1 for t &gt; 0; and β = 2λ 2 max Mmin log( 8T p ζ ) 2. These values satisfies the assumptions of Lemma B.4 since, by the definition of R M , it holds that c t ≤ c 0 whenever ξ t ≤ ξ 0 (i.e., f(w t )f (w * ) ≤ f (w 0 )f (w * )). Additionally, f (w 0 )f (w * ) ≥ 32R 2 M β, therefore f (w 0 )f (w * ) ≥ 2 √ βc 0 , and β ≤ c 0 .We obtain the result, with probability at least 1ζ:f (w t )f (w 0 ) log(1/δ) 1/3 , we obtain that, with probability at least 1ζ, f (w t )f (w 0 ) ≤ 64R</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>Number of records and features in each dataset.</figDesc><table><row><cell></cell><cell></cell><cell cols="2">log1, log2 square</cell><cell>mtp</cell><cell cols="3">dorothea california madelon</cell></row><row><cell></cell><cell>Records</cell><cell>1, 000</cell><cell>1, 000</cell><cell>4, 450</cell><cell>800</cell><cell>20, 640</cell><cell>2, 600</cell></row><row><cell></cell><cell>Features</cell><cell>100</cell><cell>1, 000</cell><cell>202</cell><cell>88, 119</cell><cell>8</cell><cell>501</cell></row><row><cell>Relative Error to Non-Private Opt.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>0</cell><cell>10</cell><cell>20</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 :</head><label>3</label><figDesc>Coordinates correctly/incorrectly identified as non-zeros by each algorithm, and relative suboptimality gap (f (w priv )f * )/f * (averaged over 5 runs).</figDesc><table><row><cell>square</cell><cell>california</cell><cell>dorothea</cell><cell>madelon</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 :</head><label>4</label><figDesc>Selected hyperparameters for every dataset and algorithm.</figDesc><table><row><cell>Dataset</cell><cell>Loss</cell><cell cols="4">Algorithm Passes on data Clipping threshold Step size</cell></row><row><cell cols="3">california LeastSquares + L1 DP-CD</cell><cell>5.0</cell><cell>2.02e+01</cell><cell>1.00e+00</cell></row><row><cell>square</cell><cell cols="2">LeastSquares + L1 DP-CD</cell><cell>0.01</cell><cell>9.10e+03</cell><cell>1.00e+01</cell></row><row><cell>mtp</cell><cell cols="2">LeastSquares + L2 DP-CD</cell><cell>3.0</cell><cell>2.02e+01</cell><cell>2.15e-02</cell></row><row><cell>madelon</cell><cell>Logistic + L1</cell><cell>DP-CD</cell><cell>0.1</cell><cell>7.91e+00</cell><cell>2.15e+00</cell></row><row><cell>log1</cell><cell>Logistic + L2</cell><cell>DP-CD</cell><cell>10.0</cell><cell>1.84e-01</cell><cell>1.00e+00</cell></row><row><cell>log2</cell><cell>Logistic + L2</cell><cell>DP-CD</cell><cell>1.0</cell><cell>7.54e-01</cell><cell>2.15e+00</cell></row><row><cell>madelon</cell><cell>Logistic + L2</cell><cell>DP-CD</cell><cell>10.0</cell><cell>1.21e+00</cell><cell>1.00e-01</cell></row><row><cell>dorothea</cell><cell>Logistic + L1</cell><cell>DP-CD</cell><cell>3.0</cell><cell>4.50e-02</cell><cell>4.64e+00</cell></row><row><cell cols="3">california LeastSquares + L1 DP-SGD</cell><cell>20.0</cell><cell>1.26e+01</cell><cell>2.15e-05</cell></row><row><cell>square</cell><cell cols="2">LeastSquares + L1 DP-SGD</cell><cell>0.01</cell><cell>4.94e+00</cell><cell>1.00e-04</cell></row><row><cell>mtp</cell><cell cols="2">LeastSquares + L2 DP-SGD</cell><cell>20.0</cell><cell>1.26e+01</cell><cell>2.15e-05</cell></row><row><cell>madelon</cell><cell>Logistic + L1</cell><cell>DP-SGD</cell><cell>10.0</cell><cell>6.87e-03</cell><cell>1.00e+00</cell></row><row><cell>log1</cell><cell>Logistic + L2</cell><cell>DP-SGD</cell><cell>20.0</cell><cell>1.84e-01</cell><cell>4.64e-04</cell></row><row><cell>log2</cell><cell>Logistic + L2</cell><cell>DP-SGD</cell><cell>20.0</cell><cell>1.84e-01</cell><cell>4.64e-04</cell></row><row><cell>madelon</cell><cell>Logistic + L2</cell><cell>DP-SGD</cell><cell>20.0</cell><cell>1.84e-01</cell><cell>1.00e-04</cell></row><row><cell>dorothea</cell><cell>Logistic + L1</cell><cell>DP-SGD</cell><cell>0.001</cell><cell>1.00e-04</cell><cell>1.00e-06</cell></row><row><cell cols="3">california LeastSquares + L1 DP-GCD</cell><cell>4</cell><cell>5.18e+01</cell><cell>1.00e+00</cell></row><row><cell>square</cell><cell>LeastSquares + L1</cell><cell></cell><cell>2</cell><cell>1.46e+04</cell><cell>2.15e+00</cell></row><row><cell>mtp</cell><cell cols="2">LeastSquares + L2 DP-GCD</cell><cell>7</cell><cell>2.02e+01</cell><cell>4.64e-01</cell></row><row><cell>madelon</cell><cell>Logistic + L1</cell><cell>DP-GCD</cell><cell>1</cell><cell>7.91e+00</cell><cell>2.15e+00</cell></row><row><cell>log1</cell><cell>Logistic + L2</cell><cell>DP-GCD</cell><cell>10</cell><cell>3.09e+00</cell><cell>2.15e+00</cell></row><row><cell>log2</cell><cell>Logistic + L2</cell><cell>DP-GCD</cell><cell>20</cell><cell>1.93e+00</cell><cell>4.64e-01</cell></row><row><cell>madelon</cell><cell>Logistic + L2</cell><cell>DP-GCD</cell><cell>10</cell><cell>7.91e+00</cell><cell>1.00e+00</cell></row><row><cell>dorothea</cell><cell>Logistic + L1</cell><cell>DP-GCD</cell><cell>2</cell><cell>1.26e+01</cell><cell>2.15e+00</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_0"><p>In fact, our privacy guarantees hold even if all intermediate iterates are released (not just the final model).</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_1"><p>https://gitlab.inria.fr/pmangold1/ greedy-coordinate-descent</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>ACKNOWLEDGMENTS</head><p>The authors would like to thank the anonymous reviewers who provided useful feedback on previous versions of this work, which helped to improve the paper. This work was supported by the <rs type="funder">Inria Exploratory Action FLAMED</rs> and by the <rs type="funder">French National Research Agency (ANR)</rs> through grant <rs type="grantNumber">ANR-20-CE23-0015</rs> (Project <rs type="projectName">PRIDE</rs>), <rs type="grantNumber">ANR-20-CHIA-0001-01</rs> (<rs type="projectName">Chaire IA CaMeLOt</rs>) and <rs type="grantNumber">ANR 22-PECY-0002</rs> <rs type="projectName">IPOP</rs> (<rs type="projectName">Interdisciplinary Project on Privacy)</rs> project of the <rs type="projectName">Cybersecurity PEPR</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funded-project" xml:id="_ueWP5Gu">
					<idno type="grant-number">ANR-20-CE23-0015</idno>
					<orgName type="project" subtype="full">PRIDE</orgName>
				</org>
				<org type="funded-project" xml:id="_uFjA9Jg">
					<idno type="grant-number">ANR-20-CHIA-0001-01</idno>
					<orgName type="project" subtype="full">Chaire IA CaMeLOt</orgName>
				</org>
				<org type="funded-project" xml:id="_6yrM8KC">
					<idno type="grant-number">ANR 22-PECY-0002</idno>
					<orgName type="project" subtype="full">IPOP</orgName>
				</org>
				<org type="funded-project" xml:id="_nBxkBZD">
					<orgName type="project" subtype="full">Interdisciplinary Project on Privacy)</orgName>
				</org>
				<org type="funded-project" xml:id="_t3uteHA">
					<orgName type="project" subtype="full">Cybersecurity PEPR</orgName>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Importantly, restricting a function to τ -sparse vectors changes its strong-convexity parameter. Let τ ≥ 0 and q ∈ {1, 2}, we say a function is µ (τ ) M,q -strongly-convex when restricted to τ -sparse vectors if for all τ -sparse vectors v, w ∈ W τ ,</p><p>Remark that when τ ≥ p, we recover the usual strong-convexity parameters. The parameters w.r.t. 1 -and 2 -norms can be compared using the following inequality <ref type="bibr" target="#b16">(Fang et al., 2020)</ref>, for all τ ≥ 0,</p><p>We are ready to prove Lemma B.5.</p><p>Lemma B.5. Let f : R p → R be a function that is M -component-smooth, and µ</p><p>M,1 -strongly-convex w.r.t. • M,1 when restricted to τ -sparse vectors, for τ ≥ 0. Assume that the unique minimizer w * of f is (τ, α)-quasi-sparse, for α, τ ≥ 0. Let w t ∈ R p be a t-sparse vector for some t ≥ 0. Then we have</p><p>Proof. Let w t ∈ R p be a t-sparse vector. Remark that w * is (α, τ )-quasi-sparse, meaning that π α (w * ) is τ -sparse. The union of w t and π α (w * )'s supports (supp(w t ) and supp(π α (w * ))) thus satisfies | supp(w) ∪ supp(π α (w * ))| ≤ t + τ . As the function f is µ</p><p>M,1 -strongly-convex with respect to • M,1 and t + τ sparse vector,</p><p>Since π α : W τ,α → W τ,0 is surjective, minimizing this equation for w ∈ W τ,α on both sides gives</p><p>≥ f (w t )sup</p><p>The second term corresponds to the conjugate of the function <ref type="bibr" target="#b8">(Boyd and Vandenberghe, 2004</ref>). This gives</p><p>Finally, w * is the minimizer of f (which is convex), thus ∇f (w * ) = 0. The smoothness of f gives, for any</p><p>where the second inequality comes from π α (w * ) ∈ W τ , since w * ∈ W τ,α . It remains to observe that π α (w * )-w * 2 M,2 ≤ M max (pτ )α 2 to get the result.</p><p>Corollary B.6. For τ -sparse vectors, we have α = 0 and thus (pτ )α = 0. Lemma B.5 can thus be simplified as</p><p>When vectors are not sparse (τ = p), we recover the inequality </p><p>), then with probability at least</p><p>Proof. When f is µ M,1 -strongly-convex w.r.t. the norm • M,1 , Corollary B.6 with τ = p and α = 0 (which holds for any vector) yields</p><p>We replace this in Lemma B.2 to obtain</p><p>Analogously to the proof of Theorem 4.4, we define</p><p>we have, with probability at least</p><p>which is the desired result.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.4.3 Better Utility for Quasi-Sparse Solutions</head><p>Theorem 4.7. Consider f satisfying the hypotheses of Theorem 4.4, with Algorithm 1 initialized at w 0 = 0. We denote its output w T , and assume that its iterates remain s-sparse for some s ≤ p. Assume that, for all τ ≥ 0, f is µ</p><p>M,1strongly-convex w.r.t. • M,1 for τ -sparse vectors and µ M,2 -strongly-convex w.r.t. • M,2 , and that the (unique) solution of problem (1) is (α, τ )-quasi-sparse for some α, τ ≥ 0. Let T ≥ 0, ζ ∈ [0, 1], and β = 2λ 2 max Mmin log(T P/ζ) 2 . Then for all t ≤ T we have that, with probability at least 1ζ:</p><p>Proof. First, we remark that at each iteration, we change only one coordinate. Therefore, after t iterations, the iterate w t is at most t-sparse. Since all iterates are also s-sparse, it is min(s, t)-sparse. Additionally, we assumed that w * is (τ, α)-almost-sparse. Therefore, Lemma B.5 yields</p><p>and Lemma B.2 becomes</p><p>Then by Chernoff's equality, we obtain (similarly to the proof of Theorem 4.4 for the convex case) that with probability at least 1ζ, for T ≥ 0,</p><p>, we can further upper bound µ</p><p>M,1 , and 1 -</p><p>which allows to simplify the above expression to</p><p>where the second inequality follows from µ</p><p>min(s,T )+τ and µ</p><p>M,1 ≤ µ M,2 . We have proven inequalities (57) and (58) of the theorem.</p><p>When α 2 = O L 2 max (s + τ )/M min µ 2 M,2 pn 2 2 , the two additive terms of (66) are O((s + τ )β/µ M,2 ). Since min(s, T ) + τ ≤ s + τ , we choose T = s+τ µ M,2 log((f (w 0 )f * )M min µ M,2 n 2 2 /L 2 ) to balance all the terms and obtain the result.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C GREEDY COORDINATE DESCENT FOR COMPOSITE PROBLEMS</head><p>Consider the problem of privately approximating</p><p>We propose a proximal greedy algorithm to solve (67), see Algorithm 2. The proximal operator is the following (we refer to <ref type="bibr" target="#b37">Parikh and Boyd, 2014</ref>, for a detailed discussion on proximal operator and related algorithms):</p><p>The same privacy guarantees as for the smooth DP-GCD algorithm hold since, privacy-wise, the proximal step is a postprocessing step. We also adapt the greedy selection rule to incorporate the non-smooth term. We can use one of the following three rules</p><p>These rules are commonly considered in the non-private GCD literature (see e.g., <ref type="bibr" target="#b49">Tseng and Yun, 2009;</ref><ref type="bibr" target="#b41">Shi et al., 2017;</ref><ref type="bibr" target="#b27">Karimireddy et al., 2019)</ref>, except for the noise η t j and the rescaling in the GS-s and GS-r rules.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D EXPERIMENTAL DETAILS</head><p>In this section, we provide more information about the experiments, such as details on implementation, datasets and the hyperparameter grid we use for each algorithm. We then give the full results on our L1-regularized, non-smooth, problems, with the three greedy rules (as opposed to Section 5 where we only plotted results for the GS-r rule). Finally, we provide runtime plots.</p><p>Code and setup. The algorithms are implemented in C++ for efficiency, together with a Python wrapper for simple use.</p><p>It is provided as supplementary. Experiments are run on a computer with a Intel (R) Xeon(R) Silver 4114 CPU @ 2.20GHz and 64GB of RAM, and took about 10 hours in total to run (this includes all hyperparameter tuning).</p><p>Datasets. The datasets we use are described in Table <ref type="table">1</ref>. In Figure <ref type="figure">2</ref>, we plot the histograms of the absolute value of each problem solution's parameters. The purple line indicates the value of α that ensures that the parameters of the solution are (α, 5)-quasi-sparse. Note the logarithmic scale on the y-axis. On the log1, log2, madelon, square, california and dorothea datasets, the solutions are very imbalanced. In these problems, a very limited number of parameters stand out, and DP-GCD is able to exploit this property. This illustrates the results from Section 4.4, since DP-GCD can exploit this structure even in quasi-sparse problems, where α is non zero. Conversely, the mtp solution is more balanced: the structural properties of this dataset are not strong enough for DP-GCD to outperform its competitors.</p><p>Hyperparameters. On all datasets, we use the same hyperparameter grid. For each algorithm, we choose between roughly the same number of hyperparameters. The number of passes on data represents p iterations of DP-CD, n iterations of DP-SGD, and 1 iteration of DP-GCD. The complete grid is described in Table <ref type="table">2</ref>, and the chosen hyperparameters for each problem and algorithm are given in Table <ref type="table">4</ref>. Recovery of the support. In Table <ref type="table">3</ref>, we report the number of coordinates that are correctly/incorrectly identified as non-zero on 1 regularized problems. Contrary to DP-SGD and DP-CD, DP-GCD never incorrectly identifies a coordinate as non-zero. Additionally, the suboptimality gap is lower for DP-GCD: its updates thus lead to better solutions.</p><p>Additional experiments on proximal DP-GCD. In Figure <ref type="figure">3</ref>, we show the results of the proximal DP-GCD algorithm, after tuning the hyperparameters with the grid described above for each of the GS-s, GS-r and GS-q rules.</p><p>The three rules seem to behave qualitatively the same on square, dorothea and madelon, our three high-dimensional non-smooth problems. There, most coordinates are chosen about one time. Thus, as described by <ref type="bibr" target="#b27">Karimireddy et al. (2019)</ref>, all the steps are "good" steps (along their terminology): and on such good steps, the three rules coincide. On the lower-dimensional dataset california, coordinates can be chosen more than one time, and "bad" steps are likely to happen. On these steps, the three rules differ.  Figure <ref type="figure">3</ref>: Relative error to non-private optimal for DP-CD, proximal DP-GCD (with GS-r, GS-s and GS-q rules) and DP-SGD on different problems. On the x-axis, 1 tick represents a full access to the data: p iterations of DP-CD, n iterations of DP-SGD and 1 iteration of DP-GCD. Number of iterations, clipping thresholds and step sizes are tuned simultaneously for each algorithm. We report min/mean/max values over 5 runs.</p><p>Relative Error to Non-Private Opt.  </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Deep Learning with Differential Privacy</title>
		<author>
			<persName><forename type="first">M</forename><surname>Abadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">B</forename><surname>Mcmahan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Mironov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Talwar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security. CCS &apos;16</title>
		<meeting>the 2016 ACM SIGSAC Conference on Computer and Communications Security. CCS &apos;16<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2016-10">Oct. 2016</date>
			<biblScope unit="page" from="308" to="318" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Private Stochastic Convex Optimization: Optimal Rates in 1 Geometry</title>
		<author>
			<persName><forename type="first">H</forename><surname>Asi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Feldman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Koren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Talwar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Stability of Stochastic Gradient Descent on Nonsmooth Convex Losses</title>
		<author>
			<persName><forename type="first">R</forename><surname>Bassily</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Feldman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Guzmán</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Talwar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Private Stochastic Convex Optimization with Optimal Rates</title>
		<author>
			<persName><forename type="first">R</forename><surname>Bassily</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Feldman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Talwar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">Guha</forename><surname>Thakurta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Non-Euclidean Differentially Private Stochastic Convex Optimization</title>
		<author>
			<persName><surname>Curran Associates</surname></persName>
		</author>
		<author>
			<persName><surname>Inc</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Bassily</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Guzman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Nandi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Thirty Fourth Conference on Learning Theory</title>
		<meeting>Thirty Fourth Conference on Learning Theory</meeting>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="474" to="499" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Algorithmic Stability for Adaptive Data Analysis</title>
		<author>
			<persName><forename type="first">R</forename><surname>Bassily</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Nissim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Steinke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Stemmer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ullman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Forty-Eighth Annual ACM Symposium on Theory of Computing. STOC &apos;16</title>
		<meeting>the Forty-Eighth Annual ACM Symposium on Theory of Computing. STOC &apos;16<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2016-06">June 2016</date>
			<biblScope unit="page" from="1046" to="1059" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Differentially Private Empirical Risk Minimization: Efficient Algorithms and Tight Error Bounds</title>
		<author>
			<persName><forename type="first">R</forename><surname>Bassily</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Thakurta</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1405.7085</idno>
		<imprint>
			<date type="published" when="2014-10">Oct. 2014</date>
		</imprint>
	</monogr>
	<note>cs, stat</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Personalized and Private Peer-to-Peer Machine Learning</title>
		<author>
			<persName><forename type="first">A</forename><surname>Bellet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Guerraoui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Taziki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Tommasi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Artificial Intelligence and Statistics</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2018-03">Mar. 2018</date>
			<biblScope unit="page" from="473" to="481" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">P</forename><surname>Boyd</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Vandenberghe</surname></persName>
		</author>
		<title level="m">Convex Optimization</title>
		<meeting><address><addrLine>Cambridge, UK ; New York</addrLine></address></meeting>
		<imprint>
			<publisher>Cambridge University Press</publisher>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Differentially Private Empirical Risk Minimization</title>
		<author>
			<persName><forename type="first">K</forename><surname>Chaudhuri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Monteleoni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">D</forename><surname>Sarwate</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">29</biblScope>
			<biblScope unit="page" from="1069" to="1109" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Differentially Private Stochastic Coordinate Descent</title>
		<author>
			<persName><forename type="first">G</forename><surname>Damaskinos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Mendler-Dünner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Guerraoui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Papandreou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Parnell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2021-05">May 2021</date>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="7176" to="7184" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Nearest Neighbor Based Greedy Coordinate Descent</title>
		<author>
			<persName><forename type="first">I</forename><surname>Dhillon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Ravikumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Tewari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Curran</forename><surname>Associates</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Inc</forename></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Differential Privacy</title>
		<author>
			<persName><forename type="first">C</forename><surname>Dwork</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Automata, Languages and Programming</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">M</forename><surname>Bugliesi</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">B</forename><surname>Preneel</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">V</forename><surname>Sassone</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">I</forename><surname>Wegener</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin, Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="1" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Preserving Statistical Validity in Adaptive Data Analysis</title>
		<author>
			<persName><forename type="first">C</forename><surname>Dwork</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Feldman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hardt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Pitassi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Reingold</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">L</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Forty-Seventh Annual ACM Symposium on Theory of Computing. STOC &apos;15</title>
		<meeting>the Forty-Seventh Annual ACM Symposium on Theory of Computing. STOC &apos;15<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2015-06">June 2015</date>
			<biblScope unit="page" from="117" to="126" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">The Algorithmic Foundations of Differential Privacy</title>
		<author>
			<persName><forename type="first">C</forename><surname>Dwork</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Foundations and Trends® in Theoretical Computer Science</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">3-4</biblScope>
			<biblScope unit="page" from="211" to="407" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Greed Meets Sparsity: Understanding and Improving Greedy Coordinate Descent for Sparse Optimization</title>
		<author>
			<persName><forename type="first">H</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Friedlander</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics</title>
		<meeting>the Twenty Third International Conference on Artificial Intelligence and Statistics</meeting>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2020-06">June 2020</date>
			<biblScope unit="page" from="434" to="444" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Private Stochastic Convex Optimization: Optimal Rates in Linear Time</title>
		<author>
			<persName><forename type="first">V</forename><surname>Feldman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Koren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Talwar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 52nd Annual ACM SIGACT Symposium on Theory of Computing</title>
		<meeting>the 52nd Annual ACM SIGACT Symposium on Theory of Computing<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2020-06">June 2020</date>
			<biblScope unit="page" from="439" to="449" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Accelerated, Parallel and Proximal Coordinate Descent</title>
		<author>
			<persName><forename type="first">O</forename><surname>Fercoq</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Richtárik</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1312.5799</idno>
		<imprint>
			<date type="published" when="2014-03">Mar. 2014</date>
		</imprint>
	</monogr>
	<note>cs, math, stat</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">An Algorithm for Quadratic Programming</title>
		<author>
			<persName><forename type="first">M</forename><surname>Frank</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Wolfe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Naval Research Logistics Quarterly</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">1-2</biblScope>
			<biblScope unit="page" from="95" to="110" />
			<date type="published" when="1956-03">Mar. 1956</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">SEGA: Variance Reduction via Gradient Sketching</title>
		<author>
			<persName><forename type="first">F</forename><surname>Hanzely</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Mishchenko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Richtarik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 32nd International Conference on Neural Information Processing Systems. NIPS&apos;18</title>
		<meeting>the 32nd International Conference on Neural Information Processing Systems. NIPS&apos;18<address><addrLine>Red Hook, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Curran Associates Inc</publisher>
			<date type="published" when="2018-12">Dec. 2018</date>
			<biblScope unit="page" from="2086" to="2097" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Train Faster, Generalize Better: Stability of Stochastic Gradient Descent</title>
		<author>
			<persName><forename type="first">M</forename><surname>Hardt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Recht</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Singer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of The 33rd International Conference on Machine Learning</title>
		<meeting>The 33rd International Conference on Machine Learning</meeting>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2016-06">June 2016</date>
			<biblScope unit="page" from="1225" to="1234" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">High Dimensional Differentially Private Stochastic Optimization with Heavy-tailed Data</title>
		<author>
			<persName><forename type="first">L</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 41st ACM SIGMOD-SIGACT-SIGAI Symposium on Principles of Database Systems. PODS &apos;22</title>
		<meeting>the 41st ACM SIGMOD-SIGACT-SIGAI Symposium on Principles of Database Systems. PODS &apos;22<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2022-06">June 2022</date>
			<biblScope unit="page" from="227" to="236" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Revisiting Frank-Wolfe: Projection-Free Sparse Convex Optimization</title>
		<author>
			<persName><forename type="first">M</forename><surname>Jaggi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2013-02">Feb. 2013</date>
			<biblScope unit="page" from="427" to="435" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Accelerating Stochastic Gradient Descent Using Predictive Variance Reduction</title>
		<author>
			<persName><forename type="first">R</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>
			<persName><forename type="first">C</forename><forename type="middle">J C</forename><surname>Burges</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Bottou</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Welling</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Z</forename><surname>Ghahramani</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K</forename><forename type="middle">Q</forename><surname>Weinberger</surname></persName>
		</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="volume">26</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">A New Analysis of Differential Privacy&amp;#x2019;s Generalization Guarantees</title>
		<author>
			<persName><forename type="first">C</forename><surname>Jung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Ligett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Neel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sharifi-Malvajerdi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Shenfeld</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 53rd Annual ACM SIGACT Symposium on Theory of Computing</title>
		<meeting>the 53rd Annual ACM SIGACT Symposium on Theory of Computing<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2021-06">June 2021</date>
		</imprint>
	</monogr>
	<note>Invited Paper</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Nearly) Dimension Independent Private ERM with AdaGrad Rates via Publicly Estimated Subspaces</title>
		<author>
			<persName><forename type="first">P</forename><surname>Kairouz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Diaz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Rush</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Thakurta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Thirty Fourth Conference on Learning Theory</title>
		<meeting>Thirty Fourth Conference on Learning Theory</meeting>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2021-07">July 2021</date>
			<biblScope unit="page" from="2717" to="2746" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Efficient Greedy Coordinate Descent for Composite Problems</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">P</forename><surname>Karimireddy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Koloskova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">U</forename><surname>Stich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Jaggi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The 22nd International Con-ference on Artificial Intelligence and Statistics</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2019-04">Apr. 2019</date>
			<biblScope unit="page" from="2887" to="2896" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Efficient Private Empirical Risk Minimization for High-dimensional Learning</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">P</forename><surname>Kasiviswanathan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Jin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page">10</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Private Convex Empirical Risk Minimization and High-dimensional Regression</title>
		<author>
			<persName><forename type="first">D</forename><surname>Kifer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Thakurta</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page">40</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">On the Convergence of the Coordinate Descent Method for Convex Differentiable Minimization</title>
		<author>
			<persName><forename type="first">Z.-Q</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Tseng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Optimization Theory and Applications</title>
		<imprint>
			<biblScope unit="volume">72</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="7" to="35" />
			<date type="published" when="1992-01">Jan. 1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Differentially Private Coordinate Descent for Composite Empirical Risk Minimization</title>
		<author>
			<persName><forename type="first">P</forename><surname>Mangold</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bellet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Salmon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Tommasi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">From safe screening rules to working sets for faster Lasso-type solvers</title>
		<author>
			<persName><forename type="first">M</forename><surname>Massias</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gramfort</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Salmon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS-OPT</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Renyi Differential Privacy</title>
		<author>
			<persName><forename type="first">I</forename><surname>Mironov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE 30th Computer Security Foundations Symposium (CSF)</title>
		<imprint>
			<date type="published" when="2017-08">Aug. 2017. 2017</date>
			<biblScope unit="page" from="263" to="275" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Rényi Differential Privacy of the Sampled Gaussian Mechanism</title>
		<author>
			<persName><forename type="first">I</forename><surname>Mironov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Talwar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1908.10530</idno>
		<imprint>
			<date type="published" when="2019-08">Aug. 2019</date>
		</imprint>
	</monogr>
	<note>cs, stat</note>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Efficiency of Coordinate Descent Methods on Huge-Scale Optimization Problems</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Nesterov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Journal on Optimization</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="341" to="362" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Coordinate Descent Converges Faster with the Gauss-Southwell Rule Than Random Selection</title>
		<author>
			<persName><forename type="first">J</forename><surname>Nutini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Schmidt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Laradji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Friedlander</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Koepke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2015-06">June 2015</date>
			<biblScope unit="page" from="1632" to="1641" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Proximal Algorithms</title>
		<author>
			<persName><forename type="first">N</forename><surname>Parikh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Boyd</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Foundations and Trends in Optimization</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="127" to="239" />
			<date type="published" when="2014-01">Jan. 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Scikit-Learn: Machine Learning in Python</title>
		<author>
			<persName><forename type="first">F</forename><surname>Pedregosa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Varoquaux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gramfort</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Michel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Thirion</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Grisel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Blondel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Prettenhofer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Dubourg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Vanderplas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Passos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Cournapeau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">MACHINE LEARNING IN PYTHON</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Iteration Complexity of Randomized Block-Coordinate Descent Methods for Minimizing a Composite Function</title>
		<author>
			<persName><forename type="first">P</forename><surname>Richtárik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Takáč</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Mathematical Programming</title>
		<imprint>
			<date type="published" when="2014-04">Apr. 2014</date>
			<biblScope unit="volume">144</biblScope>
			<biblScope unit="page" from="1" to="38" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Stochastic Dual Coordinate Ascent Methods for Regularized Loss</title>
		<author>
			<persName><forename type="first">S</forename><surname>Shalev-Shwartz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="567" to="599" />
			<date type="published" when="2013-02">Feb. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">A Primer on Coordinate Descent Algorithms</title>
		<author>
			<persName><forename type="first">H.-J</forename><forename type="middle">M</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Yin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1610.00040</idno>
		<imprint>
			<date type="published" when="2017-01">Jan. 2017</date>
		</imprint>
	</monogr>
	<note>math, stat</note>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Membership Inference Attacks Against Machine Learning Models</title>
		<author>
			<persName><forename type="first">R</forename><surname>Shokri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Stronati</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Shmatikov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 IEEE Symposium on Security and Privacy (SP)</title>
		<imprint>
			<date type="published" when="2017-05">May 2017</date>
			<biblScope unit="page" from="3" to="18" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Approximate Steepest Coordinate Descent</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">U</forename><surname>Stich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Raj</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Jaggi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 34th International Conference on Machine Learning</title>
		<meeting>the 34th International Conference on Machine Learning</meeting>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2017-07">July 2017</date>
			<biblScope unit="page" from="3251" to="3259" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Nearly Optimal Private LASSO</title>
		<author>
			<persName><forename type="first">K</forename><surname>Talwar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">Guha</forename><surname>Thakurta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">Private Empirical Risk Minimization Beyond the Worst Case: The Effect of the Constraint Set Geometry</title>
		<author>
			<persName><forename type="first">K</forename><surname>Talwar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Thakurta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1411.5417</idno>
		<idno>arXiv: 1411.5417</idno>
		<imprint>
			<date type="published" when="2016-11">Nov. 2016</date>
		</imprint>
	</monogr>
	<note>cs, stat</note>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Inexact Coordinate Descent: Complexity and Preconditioning</title>
		<author>
			<persName><forename type="first">R</forename><surname>Tappenden</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Richtárik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gondzio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Optimization Theory and Applications</title>
		<imprint>
			<biblScope unit="volume">170</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="144" to="176" />
			<date type="published" when="2016-07">July 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Regression Shrinkage and Selection Via the Lasso</title>
		<author>
			<persName><forename type="first">R</forename><surname>Tibshirani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Royal Statistical Society: Series B (Methodological)</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="267" to="288" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Convergence of a Block Coordinate Descent Method for Nondifferentiable Minimization</title>
		<author>
			<persName><forename type="first">P</forename><surname>Tseng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Optimization Theory and Applications</title>
		<imprint>
			<biblScope unit="volume">109</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="475" to="494" />
			<date type="published" when="2001-06">June 2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">A Coordinate Gradient Descent Method for Nonsmooth Separable Minimization</title>
		<author>
			<persName><forename type="first">P</forename><surname>Tseng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mathematical Programming</title>
		<imprint>
			<biblScope unit="volume">117</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="387" to="423" />
			<date type="published" when="2009-03">Mar. 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">OpenML: Networked Science in Machine Learning</title>
		<author>
			<persName><forename type="first">J</forename><surname>Vanschoren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">N</forename><surname>Rijnvan Rijn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Bischl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Torgo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM SIGKDD Explorations Newsletter</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="49" to="60" />
			<date type="published" when="2014-06">June 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Differentially Private Empirical Risk Minimization Revisited: Faster and More General</title>
		<author>
			<persName><forename type="first">D</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>
			<persName><forename type="first">I</forename><surname>Guyon</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">U</forename><forename type="middle">V</forename><surname>Luxburg</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Bengio</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Wallach</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Fergus</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Vishwanathan</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Garnett</surname></persName>
		</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">30</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Differentially private iterative gradient hard thresholding for sparse learning</title>
		<author>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Gu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th International Joint Conference on Artificial Intelligence. IJCAI&apos;19</title>
		<meeting>the 28th International Joint Conference on Artificial Intelligence. IJCAI&apos;19<address><addrLine>Macao, China</addrLine></address></meeting>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2019-08">Aug. 2019</date>
			<biblScope unit="page" from="3740" to="3747" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Differentially Private SGD with Non-Smooth Losses</title>
		<author>
			<persName><forename type="first">P</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied and Computational Harmonic Analysis</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="page" from="306" to="336" />
			<date type="published" when="2022-01">Jan. 2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Coordinate Descent Algorithms</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Wright</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mathematical Programming</title>
		<imprint>
			<biblScope unit="volume">151</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="3" to="34" />
			<date type="published" when="2015-06">June 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Bolt-on Differential Privacy for Scalable Stochastic Gradient Descent-based Analytics</title>
		<author>
			<persName><forename type="first">X</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Chaudhuri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Jha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Naughton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 ACM International Conference on Management of Data. SIGMOD &apos;17</title>
		<meeting>the 2017 ACM International Conference on Management of Data. SIGMOD &apos;17<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2017-05">May 2017</date>
			<biblScope unit="page" from="1307" to="1322" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">A Proximal Stochastic Gradient Method with Progressive Variance Reduction</title>
		<author>
			<persName><forename type="first">L</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Journal on Optimization</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="2057" to="2075" />
			<date type="published" when="2014-01">Jan. 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
		<title level="m" type="main">Bypassing the Ambiant Dimension: Private SGD with Gradient Subspace Identification</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">S</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Banerjee</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page">28</biblScope>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
