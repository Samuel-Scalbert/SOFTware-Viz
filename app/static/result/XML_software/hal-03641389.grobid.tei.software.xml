<TEI xmlns="http://www.tei-c.org/ns/1.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xml:space="preserve" xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">LifeCLEF 2022 Teaser: An Evaluation of Machine-Learning Based Species Identification and Species Distribution Prediction</title>
				<funder>
					<orgName type="full">DigitAG</orgName>
				</funder>
				<funder ref="#_R254UDC">
					<orgName type="full">European Union</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher />
				<availability status="unknown"><licence /></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Alexis</forename><surname>Joly</surname></persName>
							<email>alexis.joly@inria.fr</email>
							<affiliation key="aff0">
								<orgName type="laboratory" key="lab1">Inria</orgName>
								<orgName type="laboratory" key="lab2">LIRMM</orgName>
								<orgName type="institution" key="instit1">Univ Montpellier</orgName>
								<orgName type="institution" key="instit2">CNRS</orgName>
								<address>
									<settlement>Montpellier</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Hervé</forename><surname>Goëau</surname></persName>
							<idno type="ORCID">0000-0003-3296-3795</idno>
							<affiliation key="aff1">
								<orgName type="laboratory">CIRAD</orgName>
								<orgName type="institution">UMR AMAP</orgName>
								<address>
									<settlement>Montpellier, Occitanie</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Stefan</forename><surname>Kahl</surname></persName>
							<idno type="ORCID">0000-0002-2411-8877</idno>
							<affiliation key="aff5">
								<orgName type="laboratory" key="lab1">KLYCCB</orgName>
								<orgName type="laboratory" key="lab2">Cornell Lab of Ornithology</orgName>
								<orgName type="institution">Cornell University</orgName>
								<address>
									<settlement>Ithaca</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Lukáš</forename><surname>Picek</surname></persName>
							<idno type="ORCID">0000-0002-6041-9722</idno>
							<affiliation key="aff9">
								<orgName type="department" key="dep1">Department of Cybernetics</orgName>
								<orgName type="department" key="dep2">FAV</orgName>
								<orgName type="institution">University of West Bohemia</orgName>
								<address>
									<settlement>Plzen</settlement>
									<country>Czechia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Titouan</forename><surname>Lorieul</surname></persName>
							<idno type="ORCID">0000-0001-5228-9238</idno>
							<affiliation key="aff0">
								<orgName type="laboratory" key="lab1">Inria</orgName>
								<orgName type="laboratory" key="lab2">LIRMM</orgName>
								<orgName type="institution" key="instit1">Univ Montpellier</orgName>
								<orgName type="institution" key="instit2">CNRS</orgName>
								<address>
									<settlement>Montpellier</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Elijah</forename><surname>Cole</surname></persName>
							<idno type="ORCID">0000-0001-6623-0966</idno>
							<affiliation key="aff8">
								<orgName type="department">Department of Computing and Mathematical Sciences</orgName>
								<address>
									<settlement>Caltech, Pasadena</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Benjamin</forename><surname>Deneu</surname></persName>
							<idno type="ORCID">0000-0003-0640-5706</idno>
							<affiliation key="aff0">
								<orgName type="laboratory" key="lab1">Inria</orgName>
								<orgName type="laboratory" key="lab2">LIRMM</orgName>
								<orgName type="institution" key="instit1">Univ Montpellier</orgName>
								<orgName type="institution" key="instit2">CNRS</orgName>
								<address>
									<settlement>Montpellier</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Maximilien</forename><surname>Servajean</surname></persName>
							<idno type="ORCID">0000-0002-9426-2583</idno>
							<affiliation key="aff6">
								<orgName type="department">AMIS</orgName>
								<orgName type="laboratory">LIRMM</orgName>
								<orgName type="institution" key="instit1">Univ Paul Valéry Montpellier</orgName>
								<orgName type="institution" key="instit2">University Montpellier</orgName>
								<orgName type="institution" key="instit3">CNRS</orgName>
								<address>
									<settlement>Montpellier</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Andrew</forename><surname>Durso</surname></persName>
							<idno type="ORCID">0000-0002-3008-7763</idno>
							<affiliation key="aff10">
								<orgName type="department">Department of Biological Sciences</orgName>
								<orgName type="institution">Florida Gulf Coast University</orgName>
								<address>
									<settlement>Fort Myers</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Isabelle</forename><surname>Bolon</surname></persName>
							<idno type="ORCID">0000-0001-5940-2731</idno>
							<affiliation key="aff7">
								<orgName type="department">Department of Community Health and Medicine</orgName>
								<orgName type="laboratory">ISG</orgName>
								<orgName type="institution">UNIGE</orgName>
								<address>
									<settlement>Geneva</settlement>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Hervé</forename><surname>Glotin</surname></persName>
							<idno type="ORCID">0000-0001-7338-8518</idno>
							<affiliation key="aff2">
								<orgName type="department">LIS</orgName>
								<orgName type="institution" key="instit1">Univ. Toulon</orgName>
								<orgName type="institution" key="instit2">Aix Marseille Univ</orgName>
								<orgName type="institution" key="instit3">CNRS</orgName>
								<orgName type="institution" key="instit4">DYNI Team</orgName>
								<address>
									<settlement>Marseille</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Robert</forename><surname>Planqué</surname></persName>
							<idno type="ORCID">0000-0002-0489-5425</idno>
							<affiliation key="aff3">
								<orgName type="institution">Xeno-canto Foundation</orgName>
								<address>
									<settlement>Amsterdam</settlement>
									<country key="NL">The Netherlands</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Willem-Pier</forename><surname>Vellinga</surname></persName>
							<idno type="ORCID">0000-0003-3886-5088</idno>
							<affiliation key="aff3">
								<orgName type="institution">Xeno-canto Foundation</orgName>
								<address>
									<settlement>Amsterdam</settlement>
									<country key="NL">The Netherlands</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Holger</forename><surname>Klinck</surname></persName>
							<idno type="ORCID">0000-0003-3886-5088</idno>
							<affiliation key="aff5">
								<orgName type="laboratory" key="lab1">KLYCCB</orgName>
								<orgName type="laboratory" key="lab2">Cornell Lab of Ornithology</orgName>
								<orgName type="institution">Cornell University</orgName>
								<address>
									<settlement>Ithaca</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Tom</forename><surname>Denton</surname></persName>
							<affiliation key="aff11">
								<orgName type="institution">Google LLC</orgName>
								<address>
									<settlement>San Francisco</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Ivan</forename><surname>Eggel</surname></persName>
							<affiliation key="aff4">
								<orgName type="institution">HES-SO</orgName>
								<address>
									<settlement>Sierre</settlement>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Pierre</forename><surname>Bonnet</surname></persName>
							<idno type="ORCID">0000-0002-2828-4389</idno>
							<affiliation key="aff1">
								<orgName type="laboratory">CIRAD</orgName>
								<orgName type="institution">UMR AMAP</orgName>
								<address>
									<settlement>Montpellier, Occitanie</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Henning</forename><surname>Müller</surname></persName>
							<idno type="ORCID">0000-0001-6800-9878</idno>
							<affiliation key="aff4">
								<orgName type="institution">HES-SO</orgName>
								<address>
									<settlement>Sierre</settlement>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Milan</forename><surname>Šulc</surname></persName>
							<idno type="ORCID">0000-0002-6321-0131</idno>
							<affiliation key="aff12">
								<orgName type="department">Department of Cybernetics</orgName>
								<orgName type="institution" key="instit1">FEE</orgName>
								<orgName type="institution" key="instit2">CTU in Prague</orgName>
								<address>
									<settlement>Prague</settlement>
									<country key="CZ">Czech Republic</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">LifeCLEF 2022 Teaser: An Evaluation of Machine-Learning Based Species Identification and Species Distribution Prediction</title>
					</analytic>
					<monogr>
						<imprint>
							<date />
						</imprint>
					</monogr>
					<idno type="MD5">C8C6A7F17BDB523564C5C8045DA7009D</idno>
					<idno type="DOI">10.1007/978-3-030-99739-7_49</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-04-12T14:54+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid" />
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div><p>Building accurate knowledge of the identity, the geographic distribution and the evolution of species is essential for the sustainable development of humanity, as well as for biodiversity conservation. However, the difficulty of identifying plants, animals and fungi is hindering the aggregation of new data and knowledge. Identifying and naming living organisms is almost impossible for the general public and is often difficult even for professionals and naturalists. Bridging this gap is a key step towards enabling effective biodiversity monitoring systems. The LifeCLEF campaign, presented in this paper, has been promoting and evaluating advances in this domain since 2011. The 2022 edition proposes five data-oriented challenges related to the identification and</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div><p>prediction of biodiversity: (i) <software>PlantCLEF</software>: very large-scale plant identification, (ii) BirdCLEF: bird species recognition in audio soundscapes, (iii) <software ContextAttributes="created">GeoLifeCLEF</software>: remote sensing based prediction of species, (iv) <software ContextAttributes="created">SnakeCLEF</software>: Snake Species Identification in Medically Important scenarios, and (v) FungiCLEF: Fungi recognition from images and metadata.</p></div>
<div><head n="1">LifeCLEF Lab Overview</head><p>Accurately identifying organisms observed in the wild is an essential step in ecological studies. Unfortunately, observing and identifying living organisms requires high levels of expertise. For instance, vascular plants alone account for more than 300,000 different species and the distinctions between them can be quite subtle. The world-wide shortage shortage of trained taxonomists and curators capable of identifying organisms has come to be known as the taxonomic impediment. Since the Rio Conference of 1992, it has been recognized as one of the major obstacles to the global implementation of the Convention on Biological Diversity<ref type="foot" target="#foot_0">1</ref> . In 2004, Gaston and O'Neill <ref type="bibr" target="#b6">[7]</ref> discussed the potential of automated approaches for species identification. They suggested that, if the scientific community were able to (i) produce large training datasets, (ii) precisely evaluate error rates, (iii) scale up automated approaches, and (iv) detect novel species, then it would be possible to develop a generic automated species identification system that would open up new vistas for research in biology and related fields.</p><p>Since the publication of <ref type="bibr" target="#b6">[7]</ref>, automated species identification has been studied in many contexts <ref type="bibr">[6,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b35">36]</ref>. This area continues to expand rapidly, particularly due to advances in deep learning <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b31">[32]</ref><ref type="bibr" target="#b32">[33]</ref><ref type="bibr" target="#b33">[34]</ref><ref type="bibr" target="#b34">[35]</ref>. In order to measure progress in a sustainable and repeatable way, the LifeCLEF<ref type="foot" target="#foot_1">2</ref> research platform was created in 2014 as a continuation and extension of the plant identification task that had been run within the ImageCLEF lab<ref type="foot" target="#foot_2">3</ref> since 2011 <ref type="bibr" target="#b9">[10]</ref><ref type="bibr" target="#b10">[11]</ref><ref type="bibr" target="#b11">[12]</ref>. Since 2014, LifeCLEF expanded the challenge by considering animals in addition to plants, and including audio and video content in addition to images <ref type="bibr" target="#b13">[14]</ref><ref type="bibr" target="#b14">[15]</ref><ref type="bibr" target="#b15">[16]</ref><ref type="bibr" target="#b16">[17]</ref><ref type="bibr" target="#b17">[18]</ref><ref type="bibr" target="#b18">[19]</ref><ref type="bibr" target="#b19">[20]</ref><ref type="bibr" target="#b20">[21]</ref>. About 100-500 research groups annually register to LifeCLEF in order to either download the data, register to the mailing list or benefit from the shared evaluation tools. The number of participants who finally crossed the finish line by submitting runs was respectively: 22 in 2014, 18 in 2015, 17 in 2016, 18 in 2017, 13 in 2018, 16 in 2019, 16 in 2020, 1,022 in 2021 (including the 1,004 participants of the BirdCLEF Kaggle challenge). The 2022 edition proposes five data-oriented challenges: three in the continuity of the 2021 edition (BirdCLEF, <software ContextAttributes="created">GeoLifeCLEF</software> and SnakeCLEF), one new challenge related to fungi recognition with a focus on the combination of visual information with meta-data and on edible vs. poisonous species (FungiCLEF), and a considerable expansion of the <software ContextAttributes="created">PlantCLEF</software> challenge towards the identification of the world's flora (about 300K species). In the following sections, we describe for each of the five challenges the motivation, the used data collection and the evaluated task.</p></div>
<div><head n="2">PlantCLEF Challenge: Identify the World's Flora</head><p>Motivation: It is estimated that there are more than 300,000 species of vascular plants in the world. Increasing our knowledge of these species is of paramount importance for the development of human civilization (agriculture, construction, pharmacopoeia, etc.), especially in the context of the biodiversity crisis <ref type="bibr" target="#b21">[22]</ref>. However, the burden of systematic plant identification by human experts strongly penalizes the aggregation of new data and knowledge. Since then, automatic identification has made considerable progress in recent years as highlighted during all previous editions of <software ContextAttributes="used">PlantCLEF</software>. Deep learning techniques now seem mature enough to address the ultimate but realistic problem of global identification of plant biodiversity in spite of many problems that the data may present (a huge number of classes, very strongly unbalanced classes, partially erroneous identifications, duplications, variable visual quality, diversity of visual contents such as photos or herbarium sheets, etc.).</p><p>Data Collection: the training dataset that will be used this year can be distinguished in 2 main categories: labeled and unlabeled (i.e. with or without species labels provided and checked by humans). The labeled training dataset will be based on a dataset of more than 5M images covering more than 290k plant species based on a web crawl with <software ContextAttributes="used">Google</software> and <software ContextAttributes="used">Bing</software> search engines and the Encyclopedia of Life webportal. All datasets provided in previous editions of <software ContextAttributes="used">PlantCLEF</software> can also be used and the use of external data will be encouraged, notably via the <software ContextAttributes="used">gbif-dl</software><ref type="foot" target="#foot_3">4</ref> package which facilitates the download of media data from the world's largest biodiversity database (GBIF<ref type="foot" target="#foot_4">5</ref> ) by wrapping its public API. The unlabeled training dataset will be based on more than 9 million pictures coming from the <software ContextAttributes="used">Pl@ntNet</software> platform <ref type="bibr" target="#b3">[4]</ref> (associated with a pseudo-label but without human verification). Finally, the test set will be a set of tens of thousands pictures verified by world class experts related to various regions of the world and taxonomic groups.</p><p>Task Description: the task will be evaluated as a plant species retrieval task based on multi-image plant observations from the test set. The goal will be to retrieve the correct plant species among the top results of a ranked list of species returned by the evaluated system. The participants will first have access to the training set and a few months later, they will be provided with the whole test set. Semi-supervised or unsupervised approaches will be strongly encouraged and a starter package with a pre-trained model based on this type of method exploiting the unlabeled training dataset will be provided.</p></div>
<div><head n="3">BirdCLEF Challenge: Bird Species Identification in Soundscape Recordings</head><p>Motivation: Recognizing bird sounds in complex soundscapes is an important sampling tool that often helps to reduce the limitations of point counts<ref type="foot" target="#foot_5">6</ref> . In the future, archives of recorded soundscapes will become increasingly valuable as the habitats in which they were recorded will be lost in the near future. It is imperative to develop new technologies that can cope with the increasing amount of audio data and that can help to accelerate the process of species diversity assessments. In the past few years, deep learning approaches have transformed the field of automated soundscape analysis. Yet, when training data is sparse, detection systems struggle with the recognition of rare species. The goal of this competition is to establish training and test datasets that can serve as real-world applicable evaluation scenarios for endangered habitats and help the scientific community to advance their conservation efforts through automated bird sound recognition.</p></div>
<div><head>Data Collection:</head><p>We will build on the experience from previous editions and adjust the overall task to encourage participants to focus on few-shot learning and task-specific model designs. We will select training and test data to suit this demand. As for previous years, Xeno-canto will be the primary source for training data, expertly annotated soundscape recordings will be used for testing. We will focus on bird species for which there is limited training data, but we will also include common species so that participants can train good recognition systems. In search of suitable test data, we will consider different data sources with varying complexity (call density, chorus, signal-to-noise ratio, anthropophony), and quality (mono and stereo recordings). We also want to focus on very specific real-world use cases (e.g., conservation efforts in Hawaii) and frame the competition based on the demand of the particular use case. Additionally, we are considering including unlabeled data to encourage self-supervised learning regimes.</p><p>Task Description: The competition will be held on Kaggle and the evaluation mode will resemble the 2021 test mode (i.e., hidden test data, code competition). We will use established metrics like F1 score and LwLRAP which reflect use cases for which precision is key and also allow organizers to assess system performance independent of fine-tuned confidence thresholds. Participants will be asked to return a list of species for short audio segments extracted from labeled soundscape data. In the past, we used 5-second segments, and we will consider increasing the duration of these context windows to better reflect the overall ground truth label distribution. However, the overall structure of the task will remain unchanged, as it provides a well-established base that has resulted in significant participation in past editions (e.g., 1,004 participants and 9,307 submissions in 2021). Again, we will strive to keep the dataset size reasonably small (&lt;50 GB) and easy to process, and we will also provide introductory code repositories and write-ups to lower the entry level of the competition.</p></div>
<div><head n="4">GeoLifeCLEF Challenge: Species Prediction Based on Occurrence Data, Environmental Data and Remote Sensing Data</head><p>Motivation: Automatically predicting the list of species that are the most likely to be observed at a given location is useful for many scenarios in biodiversity conservation, ecotourism, land management, etc. First of all, it allows improve species identification tools by reducing the list of candidate species that are observable at a given location (be they automated, semi-automated or based on classical field guides or flora). More generally, it facilitates biodiversity inventories through the development of location-based recommendation services (typically on mobile phones), it favours the involvement of non-expert nature observers, as well as accelerate the annotation or validation of species observed by non-experts to produce high quality datasets. Last but not least, it might serve educational purposes thanks to biodiversity discovery applications providing functionalities such as contextualized educational pathways.</p></div>
<div><head>Data Collection:</head><p>The <software>GeoLifeCLEF</software> dataset (already used in 2020 and 2021) contains about 2 million observations of around 30 thousand plant and animal species. Each observation is paired with very high-resolution covariates (aerial imagery, land cover, altitude) and environmental rasters (bioclimatic variables, soil type, etc.). The dataset took months to build in its raw format (∼850 GB) and we reformatted it in a more convenient and memory efficient format (∼100 GB). Indeed, it has not yet been used to its full potential due (i) to the computing power required to train models on it, and, (ii) to the complexity and the wide variety of challenges of the tackled task. In 2021, the challenge focused on measuring the efficiency of remote sensing imagery to predict the presence of species at a given location. In 2022, the objective is to make this competition more realistic by changing the evaluation protocol: the models will be evaluated on new presence/absence observation data. This means that the 2022 challenge will tackle two main issues in species presence prediction: (i) taking into consideration the sampling bias due to the presence-only nature of the training observation data, and, (ii) predicting relevant sets of species present at the given location.</p><p>Task Description: Given the test set of locations (i.e. geo-coordinates) and corresponding high-resolution and environmental covariates, the goal of the task will be to return for each location a ranked list of species sorted according to the likelihood that they might have been observed at that location. The metric used will be a multi-label metric such as mean average precision (mAP).</p></div>
<div><head n="5">SnakeCLEF Challenge: Automated Snake Species Identification with Country-Level Focus</head><p>Motivation: Developing a robust system for identifying snake species from photographs is an important goal in biodiversity and global health. With over half a million of deaths and disability from venomous snakebite annually, understanding the global distribution of more than 3,900 snake species and differentiating them from images (particularly images of low quality) will significantly improve epidemiology data and treatment outcomes. From previous editions, we learned that "machines" are capable of accurate recognition (Macro F 1c &gt;90%, Accuracy ∼95%) even in the scenarios with long-tailed class distributions and ∼800 species. Thus, testing over real Medically Important Scenarios and integrating information on species toxicity is the next step to provide a more reliable "machine" prediction.</p></div>
<div><head>Data Collection:</head><p>The dataset used in previous editions <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b28">29]</ref> will be extended with new and rare species as well as with images from countries with no or just a few samples, reducing the uneven species distributions across all the countries included in the data. For testing, we tailored two sets, one for a machine evaluation and the second for the HUMAN vs AI comparison. The <software ContextAttributes="used">SnakeCLEF</software> 2022 dataset covers 1,000 snake species on more than 500,000 images and from approximately 200 countries -adding 224 new species. In addition, we include: (i) snake species toxicity level, allowing us to research methods for lowering the possibility of medically-critical mis-prediction, i.e., confusion of venomous species with nonvenomous. (ii) country-species mapping file describing species-country presence based on the The Reptile Database and allowing better worldwide regularization.</p><p>Task Description: Given the set of images and corresponding geographic locality information, the goal of the task is to return for each image a ranked list of species sorted according to the likelihood that they are in the image and might have been observed at that location and minimising the venomous/nonvenomous confusion.</p></div>
<div><head n="6">FungiCLEF Challenge: Fungi Recognition from Images and Metadata</head><p>Motivation: Automatic recognition of fungi species assists mycologists, citizen scientists and nature enthusiasts in species identification in the wild. Its availability supports the collection of valuable biodiversity data. In practice, species identification typically does not depend solely on the visual observation of the specimen but also on other information available to the observer -such as habitat, substrate, location and time. Thanks to rich metadata, precise annotations, and baselines available to all competitors, the challenge provides a benchmark for image recognition with the use of additional information. Moreover, similarly to <software>SnakeCLEF</software>, the toxicity of a mushroom can be crucial for the decision of a mushroom picker. The task will explore the decision process beyond the commonly assumed 0/1 cost function.</p></div>
<div><head>Data Collection:</head><p>The challenge dataset is based on the DF20 dataset <ref type="bibr" target="#b27">[28]</ref> Task Description: Given the set of images and corresponding metadata, the goal of the task is to return for each image a ranked list of species sorted according to the likelihood of the species appearing in the image. A baseline procedure to include meta-data in the decision problem, as well as pre-trained baseline image classifiers, will be provided as part of the task description to all participants.</p></div>
<div><head n="7">Timeline and Registration Instructions</head><p>All information about the timeline and participation in the challenges is provided on the LifeCLEF 2022 web pages <ref type="bibr" target="#b2">[3]</ref>. The challenges themselves are ran on the AIcrowd platform <ref type="bibr" target="#b0">[1]</ref> and the Kaggle platform <ref type="bibr" target="#b1">[2]</ref> for the registration, the submission of runs, the display of the leaderboard, etc.</p></div>
<div><head n="8">Conclusions and Perspectives</head><p>To fully reach its objective, an evaluation campaign such as LifeCLEF requires a long-term research effort so as to (i) encourage non-incremental contributions, (ii) measure consistent performance gaps, (iii) progressively scale-up the problem and (iv) enable the emergence of a strong community. The 2022 edition of the lab supports this vision and also includes the following innovations:</p><p>-A new task on fungi recognition from images and metadata.</p><p>-A widening of the plant task at the scale of the world flora (100K-300K species). -The inclusion of new data for the bird task with a focus on unsupervised training, stereo audio recordings and concrete conservation use cases. -The inclusion of presence-absence test data for the <software>GeoLifeCLEF</software> challenge.</p><p>-The evaluation of decision problems for poisonous and venomous species identification represents a task beyond 0/1 cost function, not represented in computer vision benchmarks.</p></div><figure type="table" xml:id="tab_0"><head /><label /><figDesc>, contains 295,938 training images belonging to 1,604 species observed mostly in Denmark. All training samples passed an expert validation process, guaranteeing high quality labels. Rich observation metadata about habitat, substrate, time, location, EXIF etc. are provided. The challenge comes with two different test sets: (i) The first is unique in its annotation process, as all test images belong to physical samples sent for DNA sequencing. (ii) The second, with approximately 60k images, covers the whole year and includes observations collected across all substrate and habitat types.</figDesc><table /></figure>
			<note place="foot" n="1" xml:id="foot_0"><p>https://www.cbd.int/.</p></note>
			<note place="foot" n="2" xml:id="foot_1"><p>http://www.lifeclef.org/.</p></note>
			<note place="foot" n="3" xml:id="foot_2"><p>http://www.imageclef.org/.</p></note>
			<note place="foot" n="4" xml:id="foot_3"><p>https://github.com/plantnet/gbif-dl.</p></note>
			<note place="foot" n="5" xml:id="foot_4"><p>https://www.gbif.org/.</p></note>
			<note place="foot" n="6" xml:id="foot_5"><p>e.g. some species might be oversampled or undersampled.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><p>Acknowledgements. This project has received funding from the <rs type="funder">European Union</rs>'s <rs type="programName">Horizon 2020 research and innovation programme</rs> under grant agreement No • <rs type="grantNumber">863463</rs> (<rs type="projectName">Cos4Cloud</rs> project), and the support of #<rs type="funder">DigitAG</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funded-project" xml:id="_R254UDC">
					<idno type="grant-number">863463</idno>
					<orgName type="project" subtype="full">Cos4Cloud</orgName>
					<orgName type="program" subtype="full">Horizon 2020 research and innovation programme</orgName>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title />
		<author>
			<persName><surname>Aicrowd</surname></persName>
		</author>
		<ptr target="https://www.aicrowd.com/" />
		<imprint />
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<ptr target="https://www.kaggle.com/" />
		<title level="m">Kaggle</title>
		<imprint />
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title />
		<author>
			<persName><surname>Lifeclef</surname></persName>
		</author>
		<ptr target="https://www.imageclef.org/LifeCLEF2022" />
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Pl@ntnet app in the era of deep learning</title>
		<author>
			<persName><forename type="first">A</forename><surname>Affouard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Goeau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Bonnet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Lombardo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Joly</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">5th International Conference on Learning Representations (ICLR 2017)</title>
		<meeting><address><addrLine>Toulon, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017-04">April 2017. 2017</date>
			<biblScope unit="page" from="24" to="26" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Plant Identification: Experts vs. Machines in the Era of Deep Learning</title>
		<author>
			<persName><forename type="first">H</forename><surname>Goëau</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-319-76445-0_8</idno>
		<ptr target="https://doi.org/10.1007/978-3-319-76445-0" />
	</analytic>
	<monogr>
		<title level="m">Multimedia Tools and Applications for Environmental &amp; Biodiversity Informatics</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Joly</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Vrochidis</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K</forename><surname>Karatzas</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Karppinen</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><surname>Bonnet</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="131" to="149" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Sensor network for the monitoring of ecosystem: Bird species recognition</title>
		<author>
			<persName><forename type="first">J</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Ee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Roe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="DOI">10.1109/ISSNIP.2007.4496859</idno>
		<ptr target="https://doi.org/10.1109/ISSNIP.2007.4496859" />
	</analytic>
	<monogr>
		<title level="m">Intelligent Sensors, Sensor Networks and Information</title>
		<imprint>
			<date type="published" when="2007">2007. 2007</date>
		</imprint>
	</monogr>
	<note>ISSNIP 2007. 3rd International Conference on</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Automated species identification: why not?</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">J</forename><surname>Gaston</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>O'neill</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Philos. Trans. Royal Soc. London B: Biol. Sci</title>
		<imprint>
			<biblScope unit="volume">359</biblScope>
			<biblScope unit="issue">1444</biblScope>
			<biblScope unit="page" from="655" to="667" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Plant identification using deep neural networks via optimization of transfer learning parameters</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Ghazi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Yanikoglu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Aptoula</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">235</biblScope>
			<biblScope unit="page" from="228" to="235" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<author>
			<persName><forename type="first">H</forename><surname>Glotin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Dugan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Halkias</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sueur</surname></persName>
		</author>
		<ptr target="http://sabiod.org/ICML4B2013book.pdf" />
		<title level="m">Proceeding 1st workshop on Machine Learning for Bioacoustics -ICML4B. ICML</title>
		<meeting>eeding 1st workshop on Machine Learning for Bioacoustics -ICML4B. ICML<address><addrLine>Atlanta USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">The imageclef 2013 plant identification task</title>
		<author>
			<persName><forename type="first">H</forename><surname>Goëau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CLEF: Conference and Labs of the Evaluation Forum</title>
		<meeting><address><addrLine>Valencia, Spain. Valencia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013-09">Sep. 2013. 2013</date>
		</imprint>
	</monogr>
	<note>CLEF task Overview 2013</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">The imageclef 2011 plant images classification task</title>
		<author>
			<persName><forename type="first">H</forename><surname>Goëau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CLEF: Conference and Labs of the Evaluation Forum</title>
		<meeting><address><addrLine>Amsterdam, Netherlands</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011-09">Sep. 2011. 2011</date>
		</imprint>
	</monogr>
	<note>CLEF task Overview 2011</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Imageclef 2012 plant images identification task</title>
		<author>
			<persName><forename type="first">H</forename><surname>Goëau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CLEF: Conference and Labs of the Evaluation Forum</title>
		<meeting><address><addrLine>Rome, Italy; Rome</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012-09">Sep. 2012. 2012</date>
		</imprint>
	</monogr>
	<note>CLEF Task Overview 2012</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Interactive plant identification based on social image data</title>
		<author>
			<persName><forename type="first">A</forename><surname>Joly</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ecol. Inf</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="22" to="34" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Overview of LifeCLEF 2018: a large-scale evaluation of species identification and recommendation algorithms in the era of ai</title>
		<author>
			<persName><forename type="first">A</forename><surname>Joly</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CLEF: Cross-Language Evaluation Forum for European Languages. Experimental IR Meets Multilinguality, Multimodality, and Interaction</title>
		<editor>
			<persName><forename type="first">G</forename><forename type="middle">J</forename><surname>Jones</surname></persName>
		</editor>
		<meeting><address><addrLine>Avigon, France</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2018-09">Sep 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Overview of LifeCLEF 2019: Identification of Amazonian Plants, South &amp; North American Birds, and Niche Prediction</title>
		<author>
			<persName><forename type="first">A</forename><surname>Joly</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-28577-7_29</idno>
		<ptr target="https://hal.umontpellier.fr/hal-02281455" />
	</analytic>
	<monogr>
		<title level="m">CLEF 2019 -Conference and Labs of the Evaluation Forum. Experimental IR Meets Multilinguality, Multimodality, and Interaction</title>
		<editor>
			<persName><forename type="first">F</forename><surname>Crestani</surname></persName>
		</editor>
		<meeting><address><addrLine>Lugano, Switzerland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019-09">Sep 2019</date>
			<biblScope unit="page" from="387" to="401" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">LifeCLEF 2016: Multimedia Life Species Identification Challenges</title>
		<author>
			<persName><forename type="first">A</forename><surname>Joly</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-319-44564-9_26</idno>
		<ptr target="https://hal.archives-ouvertes.fr/hal-01373781" />
	</analytic>
	<monogr>
		<title level="m">CLEF: Cross-Language Evaluation Forum. Experimental IR Meets Multilinguality, Multimodality, and Interaction</title>
		<editor>
			<persName><forename type="first">N</forename><surname>Fuhr</surname></persName>
		</editor>
		<meeting><address><addrLine>Évora, Portugal</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016-09">Sep 2016</date>
			<biblScope unit="page" from="286" to="310" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">LifeCLEF 2017 Lab Overview: Multimedia Species Identification Challenges</title>
		<author>
			<persName><forename type="first">A</forename><surname>Joly</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-319-65813-1_24</idno>
		<ptr target="https://hal.archives-ouvertes.fr/hal-01629191" />
	</analytic>
	<monogr>
		<title level="m">CLEF: Cross-Language Evaluation Forum. Experimental IR Meets Multilinguality, Multimodality, and Interaction</title>
		<editor>
			<persName><forename type="first">G</forename><forename type="middle">J</forename><surname>Jones</surname></persName>
		</editor>
		<meeting><address><addrLine>Dublin, Ireland</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2017-09">Sep 2017</date>
			<biblScope unit="page" from="255" to="274" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">LifeCLEF 2014: Multimedia Life Species Identification Challenges</title>
		<author>
			<persName><forename type="first">A</forename><surname>Joly</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-319-11382-1_20</idno>
		<ptr target="https://hal.inria.fr/hal-01075770" />
	</analytic>
	<monogr>
		<title level="m">CLEF: Cross-Language Evaluation Forum. Information Access Evaluation. Multilinguality, Multimodality, and Interaction</title>
		<meeting><address><addrLine>Sheffield, United Kingdom</addrLine></address></meeting>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2014-09">Sep 2014</date>
			<biblScope unit="page" from="229" to="249" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Lifeclef 2015: multimedia life species identification challenges</title>
		<author>
			<persName><forename type="first">A</forename><surname>Joly</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Experimental IR Meets Multilinguality, Multimodality, and Interaction</title>
		<imprint>
			<publisher>Springe, Chem</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="462" to="483" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Overview of lifeclef 2020: a system-oriented evaluation of automated species identification and species distribution prediction</title>
		<author>
			<persName><forename type="first">A</forename><surname>Joly</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference of the Cross-Language Evaluation Forum for European Languages</title>
		<imprint>
			<publisher>Springer, Chem</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="342" to="363" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Overview of lifeclef 2021: an evaluation of machine-learning based species identification and species distribution prediction</title>
		<author>
			<persName><forename type="first">A</forename><surname>Joly</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference of the Cross-Language Evaluation Forum for European Languages</title>
		<imprint>
			<publisher>Springer, Chem</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="371" to="393" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Species coextinctions and the biodiversity crisis</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">P</forename><surname>Koh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">R</forename><surname>Dunn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">S</forename><surname>Sodhi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">K</forename><surname>Colwell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">C</forename><surname>Proctor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">S</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">305</biblScope>
			<biblScope unit="issue">5690</biblScope>
			<biblScope unit="page" from="1632" to="1634" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Contour matching for a fish recognition and migration-monitoring system</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">B</forename><surname>Schoenberger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Shiozawa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Zhan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Optics East</title>
		<imprint>
			<publisher>International Society for Optics and Photonics</publisher>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="37" to="48" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Multi-organ plant classification based on convolutional and recurrent neural networks</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">S</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Remagnino</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="4287" to="4301" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<ptr target="http://sabiod.org/nips4b" />
		<title level="m">NIPS International Conference on Neural Information Processing Scaled for Bioacoustics, from Neurons to Big Data</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">A deep active learning system for species identification and counting in camera trap images</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Norouzzadeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Morris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Beery</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Jojic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Clune</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Methods Ecol. Evol</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="150" to="161" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Overview of the snakeclef 2020: Automatic snake species identification challenge</title>
		<author>
			<persName><forename type="first">L</forename><surname>Picek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ruiz De Castañeda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Durso</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">M</forename><surname>Sharada</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CLEF: Conference and Labs of the Evaluation Forum</title>
		<meeting><address><addrLine>Thessaloniki, Greece</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020-09">Sep. 2020. 2020</date>
		</imprint>
	</monogr>
	<note>CLEF task overview 2020</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Danish fungi 2020 -not just another image recognition dataset</title>
		<author>
			<persName><forename type="first">L</forename><surname>Picek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sulc</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Matas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Heilmann-Clausen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Jeppesen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Laessøe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Frøslev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)</title>
		<meeting>the IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Overview of SnakeCLEF 2021: Automatic snake species identification with country-level focus</title>
		<author>
			<persName><forename type="first">L</forename><surname>Picek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Durso</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ruiz De Castañeda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Bolon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Working Notes of CLEF 2021 -Conference and Labs of the Evaluation Forum</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">A toolbox for animal call recognition</title>
		<author>
			<persName><forename type="first">M</forename><surname>Towsey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Planitz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Nantes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wimmer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Roe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioacoustics</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="107" to="125" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Automated species recognition of antbirds in a Mexican rainforest using hidden Markov models</title>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">M</forename><surname>Trifa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">N</forename><surname>Kirschel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">E</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">E</forename><surname>Vallejo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Acoust. Soc. Am</title>
		<imprint>
			<biblScope unit="volume">123</biblScope>
			<biblScope unit="page">2424</biblScope>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">The inaturalist species classification and detection dataset</title>
		<author>
			<persName><forename type="first">G</forename><surname>Van Horn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Mac Aodha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Shepard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Adam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Belongie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CVPR</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">A new method to control error rates in automated species identification with deep learning algorithms</title>
		<author>
			<persName><forename type="first">S</forename><surname>Villon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Mouillot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Chaumont</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Subsol</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Claverie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Villéger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sci. Reports</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="13" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Machine learning for image based species identification</title>
		<author>
			<persName><forename type="first">J</forename><surname>Wäldchen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Mäder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Methods Ecol. Evol</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2216" to="2225" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Automated plant species identification-trends and future directions</title>
		<author>
			<persName><forename type="first">J</forename><surname>Wäldchen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Rzanny</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Seeland</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Mäder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS Comput. Biol</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">1005993</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Automated identification of animal species in camera trap images</title>
		<author>
			<persName><forename type="first">X</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Kays</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">A</forename><surname>Jansen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Huang</surname></persName>
		</author>
		<idno type="DOI">10.1186/1687-5281-2013-52</idno>
		<ptr target="https://doi.org/10.1186/1687-5281-2013-52Viewpublicationstats" />
	</analytic>
	<monogr>
		<title level="j">EURASIP J. Image Video Process</title>
		<imprint>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="10" />
			<date type="published" when="2013">2013. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>