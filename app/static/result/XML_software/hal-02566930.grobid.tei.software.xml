<TEI xmlns="http://www.tei-c.org/ns/1.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xml:space="preserve" xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Skill Rating for Multiplayer Games Introducing Hypernode Graphs and their Spectral Theory</title>
			</titleStmt>
			<publicationStmt>
				<publisher />
				<availability status="unknown"><licence /></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Thomas</forename><surname>Ricatte</surname></persName>
							<email>thomas@ricatte.fr</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Université de Lille</orgName>
								<orgName type="institution" key="instit2">Inria Lille Nord Europe</orgName>
								<address>
									<addrLine>40, Av. Halley</addrLine>
									<postCode>59650</postCode>
									<settlement>Villeneuve d'Ascq</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Rémi</forename><surname>Gilleron</surname></persName>
							<email>remi.gilleron@univ-lille.fr</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Université de Lille</orgName>
								<orgName type="institution" key="instit2">Inria Lille Nord Europe</orgName>
								<address>
									<addrLine>40, Av. Halley</addrLine>
									<postCode>59650</postCode>
									<settlement>Villeneuve d'Ascq</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Marc</forename><surname>Tommasi</surname></persName>
							<email>marc.tommasi@univ-lille.fr</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Université de Lille</orgName>
								<orgName type="institution" key="instit2">Inria Lille Nord Europe</orgName>
								<address>
									<addrLine>40, Av. Halley</addrLine>
									<postCode>59650</postCode>
									<settlement>Villeneuve d'Ascq</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">David</forename><surname>Blei</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Université de Lille</orgName>
								<orgName type="institution" key="instit2">Inria Lille Nord Europe</orgName>
								<address>
									<addrLine>40, Av. Halley</addrLine>
									<postCode>59650</postCode>
									<settlement>Villeneuve d'Ascq</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Skill Rating for Multiplayer Games Introducing Hypernode Graphs and their Spectral Theory</title>
					</analytic>
					<monogr>
						<imprint>
							<date />
						</imprint>
					</monogr>
					<idno type="MD5">B3AF0D456D10B0B9D2E9C01DBA2E498E</idno>
					<note type="submission">Submitted 12/13; Revised 3/20;</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-04-12T14:51+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid" />
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Hypergraphs</term>
					<term>Graph Laplacians</term>
					<term>Graph Kernels</term>
					<term>Spectral Learning</term>
					<term>Semisupervised Learning</term>
					<term>Multiplayer Games</term>
					<term>Skill Rating Algorithms</term>
				</keywords>
			</textClass>
			<abstract>
<div><p>We consider the skill rating problem for multiplayer games, that is how to infer player skills from game outcomes in multiplayer games. We formulate the problem as a minimization problem arg min s s T ∆s where ∆ is a positive semidefinite matrix and s a real-valued function, of which some entries are the skill values to be inferred and other entries are constrained by the game outcomes. We leverage graph-based semi-supervised learning (SSL) algorithms for this problem. We apply our algorithms on several data sets of multiplayer games and obtain very promising results compared to Elo Duelling (see <ref type="bibr" target="#b5">Elo, 1978)</ref> and <software ContextAttributes="used">TrueSkill</software> (see <ref type="bibr" target="#b7">Herbrich et al., 2006)</ref>. As we leverage graph-based SSL algorithms and because games can be seen as relations between sets of players, we then generalize the approach. For this aim, we introduce a new finite model, called hypernode graph, defined to be a set of weighted binary relations between sets of nodes. We define Laplacians of hypernode graphs. Then, we show that the skill rating problem for multiplayer games can be formulated as arg min s s T ∆s where ∆ is the Laplacian of a hypernode graph constructed from a set of games. From a fundamental perspective, we show that hypernode graph Laplacians are symmetric positive semidefinite matrices with constant functions in their null space. We show that problems on hypernode graphs can not be solved with graph constructions and graph kernels. We relate hypernode graphs to signed graphs showing that positive relations between groups can lead to negative relations between individuals.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div><head n="1.">Introduction</head><p>We consider the skill rating problem for multiplayer games such as team sports and online games. We consider games between two teams where each team is composed of an arbitrary number of players. We assume, as in <ref type="bibr" target="#b7">Herbrich et al. (2006)</ref>, that the skill of a team is a weighted sum of the player skills. The problem is to infer individual player skills from a limited number of game outcomes. The skills can then be used for match-making, skill ranking or outcome prediction for new games.</p><p>Given a set of players and a set of games between teams of players, we model the player skills and the game outcomes by real-valued functions. We show that the skill rating problem is equivalent to solving a minimization problem arg min s s T ∆s where ∆ is a positive </p><formula xml:id="formula_0">G =    √ 2 2 √ 2 2 √ 2 - √ 2 - √ 2 0 1 0 0 -1 -1 1 0 0 √ 3 3 0 0 - √ 3 3   </formula><p>Figure <ref type="figure">1</ref>: Left: a hypernode graph h with three hyperedges h blue = {{1, 2, 3}, {4, 5}}, h black = {{4, 5}, {1, 6}} and h red = {{3}, {6}} where a hyperedge is represented by a rectangle and nodes in a hypernode are connected to the same side of the rectangle. Right : a gradient G of h which values are square root of the weights and are positive for one hypernode and negative for the other. The matrix G can be seen as an alternative definition of the hypernode graph h.</p><p>semidefinite matrix and some entries of s are constrained by the game outcomes. In order to solve this problem, we propose two algorithms. The first one is the semi-supervised learning (SSL) algorithm presented in <ref type="bibr">Zhu et al. (2003)</ref> originally designed for graph-based SSL. The second one, also inspired from graph-based SSL, is to use a regression support vector machine using the Moore-Penrose pseudoinverse ∆ † of the matrix ∆ as a kernel.</p><p>In the experiments, we consider real data sets of multiplayer games (double tennis and online games) and apply our method in a batch setting. We get very competitive results with specialized algorithms such as Elo duelling (see <ref type="bibr" target="#b5">Elo, 1978)</ref> and <software ContextAttributes="used">TrueSkill</software> (see <ref type="bibr" target="#b7">Herbrich et al., 2006)</ref>.</p><p>The above minimization problem can be solved by graph-based SSL algorithms because its formulation is similar to the case of graphs where ∆ is a graph Laplacian. Here, the positive semidefinite matrix ∆ expresses conditions on the players skills based on the game outcomes, where each game can be considered as a binary relation between two sets of players. Driven by these remarks, we introduce hypernode graphs as a finite model for relations between sets and we show that our matrix ∆ is the Laplacian of such an hypernode graph.</p><p>We define a hypernode graph to be a set of hyperedges. A hyperedge is a pair of disjoint hypernodes, where a hypernode is a set of nodes. Every node of a hypernode is given a non negative real-valued weight. Roughly speaking, a hypernode models a group, a hyperedge models a relation between two groups, and individual weights correspond to the contribution of each individual to the relation between the two groups. An example of hypernode graph is shown in Figure <ref type="figure">1</ref>. Hypernode graphs generalize over graphs because there is a one to one correspondence between undirected graphs and hypernode graphs in which all hypernodes are singleton sets.</p><p>We consider real-valued node functions over hypernode graphs and we assume an additive model where the hypernode valuation is the linear combination of its node valuations. We assume that connected hypernodes tend to have similar values. For real-valued node functions over discrete structures, the gradient is a discrete derivative that allows to mea-sure such a similarity. Therefore, we define a gradient for hypernode graphs and we denote by G the gradient matrix of a hypernode graph h. An example is shown in Figure <ref type="figure">1</ref>. We define the Laplacian ∆ of h to be ∆ = G T G. Then, the quantity f T ∆f measures the smoothness of a real-valued node function f on the hypernode graph h. In other words, f T ∆f is small when connected hypernodes have close values. Then, we show that a set of multiplayer games can be modeled by a hypernode graph and that our algorithm for the skill rating problem is finding a real-valued node function s minimizing Ω(s) = s T ∆s, where ∆ is the Laplacian of the constructed hypernode graph, under constraints on the s-values for game outcomes.</p><p>One question raised by the introduction of our new framework is whether problems on hypernode graphs can be solved using graphs. Indeed, for hypergraphs (a generalization of graphs where a hyperedge is a set of nodes), it has been proved in <ref type="bibr" target="#b1">Agarwal et al. (2006)</ref> that the hypergraph Laplacians introduced at this time (other hypergraph Laplacians have been defined since (see <ref type="bibr" target="#b4">Chan et al., 2018</ref>, and references within)), do not extend graph Laplacians because learning based on a hypergraph Laplacian can be proved equivalent to learning on a graph Laplacian using an adequate graph construction (such as clique expansion or star expansion). This is not the case for hypernode graphs. Indeed, we show that no graph construction allows to define a set of smooth functions over the graph equal to the set of smooth functions over a given hypernode graph. Thus, we state that hypernode graph Laplacians strictly generalize over graph Laplacians.</p><p>It can be noted that the class of hypernode graph Laplacians strictly contains the class of graph Laplacians and also contains the class of graph kernels (the Moore-Penrose pseudoinverse of a graph Laplacian). A convex linear combination of graph kernels (used in multiple graph kernel learning as in <ref type="bibr" target="#b2">Argyriou et al. (2005)</ref>) is not, in general, a graph kernel but we prove that it is a hypernode graph kernel (the Moore-Penrose pseudoinverse of a hypernode graph Laplacian). We conjecture that the class of hypernode graph Laplacians is the smallest class closed by convex linear combinations which contains all graph kernels. We also show that, for every hypernode graph, we can construct a signed graph with adjacency matrix W and degree matrix D such that D-W is the Laplacian of the hypernode graph. This shows that positive relations between groups can lead to negative relations between individuals. Let us recall that, for arbitrary signed graphs, the matrix D -W can be indefinite. From a spectral theory perspective, hypernode graphs correspond to the class of signed graphs such that D -W is positive semidefinite introduced by <ref type="bibr" target="#b8">Koren et al. (2002)</ref> for the problem of drawing graphs. Last, we study how to define a distance between nodes in hypernode graphs and we leave open questions on connected components and random walks in hypernode graphs.</p></div>
<div><head n="2.">Skill Rating for Multiplayer Games</head><p>We consider competitive games between two teams where each team is composed of an arbitrary number of players. A first objective is to compute the skills of individual players from a batch of games with their outcomes. A second objective is to predict a game outcome for a new game. In this section, we show how to model a batch of games and to infer player skills that allow to predict game outcomes of new games.</p></div>
<div><head n="2.1">Skill Rating as an Optimization Problem</head><p>Let us consider a set of players P = {1, . . . , n} and a set of games Γ = {1, . . . , m} together with their respective game outcome. Each game is between two teams of an arbitrary number of players. Let us also consider that a player i contributes to a game γ with a positive real value c γ (i). Let us assume that each player has a skill s(i), we suppose an additive model as in <ref type="bibr" target="#b7">Herbrich et al. (2006)</ref> stating that the skill of a team is the weighted sum of the skills of the players in the team. More formally, given two teams of players A = {a 1 , a 2 , . . . , a } and B = {b 1 , b 2 , . . . , b k } playing game γ, then A is predicted to be the winner if</p><formula xml:id="formula_1">i=1 c γ (a i )s(a i ) &gt; k i=1 c γ (b i )s(b i ) .<label>(1)</label></formula><p>Equivalently, one can rewrite this inequality by introducing a positive real number o γ on the right hand side such that</p><formula xml:id="formula_2">i=1 c γ (a i )s(a i ) = o γ + k i=1 c γ (b i )s(b i ) ,<label>(2)</label></formula><p>where the real number o γ quantifies the game outcome. In the case of a draw, there is an equality between the team skills, thus the game outcome o γ is set to 0. Given a set of games with their respective outcome, the goal is to infer a skill rating function s ∈ R n that respects as much as possible Equation (2) for every game. We define the cost of a game γ with outcome o γ for a skill function s by</p><formula xml:id="formula_3">C γ (s) = i=1 c γ (a i )s(a i ) -o γ + k i=1 c γ (b i )s(b i ) 2 .</formula><p>Consequently, given a set of games Γ and the corresponding game outcomes, the goal is to find a skill rating function s * that minimizes the sum of the different costs:</p><formula xml:id="formula_4">s * = arg min s γ∈Γ C γ (s) .<label>(3)</label></formula><p>We now reformulate this problem as a SSL problem over a positive semidefinite matrix. For this, let us define the matrix G ∈ R m× (n+m) , where n is the number of players and m the number of games, as follows. Let γ ∈ Γ be a game between teams A and B where A is supposed to be the winner, the γ-th row of G models game γ and is defined by: for</p><formula xml:id="formula_5">1 ≤ i ≤ n, G γ,i = c γ (a i ) if a i ∈ A, G γ,i = -c γ (a i ) if a i ∈ B,</formula><p>and 0 otherwise (the player i is not involved in the game γ); and, for 1 ≤ γ ≤ m, G i,n+γ = -1 for γ = γ and 0 otherwise.</p><p>Then, it is easy to show that the skill rating problem (3) is equivalent to find a realvalued node function s ∈ R (n+m) solution of minimize s s T ∆s subject to for every game γ with outcome o γ , s(n</p><formula xml:id="formula_6">+ γ) = o γ (4)</formula><p>where ∆ = G T G. We can note that the matrix ∆ is positive semidefinite.</p></div>
<div><head n="2.2">Regularizing the Optimization Problem</head><p>When the number of games is small, player skills can be defined independently while satisfying the constraints and it will be irrelevant to compare them. In order to solve this issue, we introduce in Equation 4 a regularization term based on the standard deviation σ(s p ) of players skills where s p = (s(1), . . . , s(n)). This allows us to reduce the spread of the player skills and leads us to find a real valued node function s ∈ R (n+m) solution of minimize s s T ∆s + µσ(s p ) 2 subject to for every game γ with outcome o γ , s(n</p><formula xml:id="formula_7">+ γ) = o γ (5)</formula><p>where µ is a regularization parameter. That is, we control the spread of s p avoiding extreme values for players involved in a small number of games. In order to apply SSL algorithms over a positive semidefinite matrix, we propose to rewrite Problem 5.</p><p>First, let us recall that if s is the mean of the player skills vector s p , then, for all q ∈ R,</p><formula xml:id="formula_8">we have σ(s p ) 2 = 1 n n i=1 (s(i) -s) 2 ≤ 1 n n i=1 (s(i) -q) 2 . Thus, Problem 5 is equivalent to minimize s∈R (n+m) ,q∈R s T ∆s + µ n n i=1 (s(i) -q) 2 subject to for every game γ with outcome o γ , s(n + γ) = o γ (6)</formula><p>We now define the matrix n+m+1) . The first m rows of G µ are the rows of G with an additional null column. The last n rows of G µ are defined by, for every 1</p><formula xml:id="formula_9">G µ ∈ R (m+n)×(</formula><formula xml:id="formula_10">≤ i ≤ n, G µ,(m+i,i) = -µ n , G µ,(m+i,n+m+1) = µ n</formula><p>, and 0 otherwise. Note that the last n rows of G µ allow to compute µ n n i=1 (s(i) -q) 2 where s(n + m + 1) = q when computing s T G T µ G µ s. Thus Problem 6 is equivalent to finding a real-valued node function s ∈ R (n+m+1) solution of minimize</p><formula xml:id="formula_11">s s T ∆ µ s subject to for every game γ with outcome o γ , s(n + γ) = o γ<label>(7)</label></formula><p>where ∆ µ = G T µ G µ is positive semidefinite. Note that, assuming unitary contributions and a Gaussian distribution for skill ratings, we can prove that the value of µ/n should have the same order of magnitude than the average number of games played by a player. Indeed, this will allow us to obtain close expected values for the two terms s T ∆s and µσ(s p ) 2 . We follow this guideline in the experiments presented below.</p></div>
<div><head n="2.3">Inferring Skill Ratings and Predicting Game Outcomes</head><p>Problem 7 can be viewed as a SSL problem because the question is to predict player skills (values s(i) for 1 ≤ i ≤ n) from known outcomes (values s(n + γ) for 1 ≤ γ ≤ m). We propose two algorithms: H-ZGL: as the matrix ∆ µ is positive semidefinite, we can use the SSL algorithm presented in <ref type="bibr">Zhu et al. (2003)</ref>. This algorithm was originally designed for graphs and solves exactly Problem 7 by putting hard constraints on the outcome values. It should be noted that the algorithm is parameter free.</p><p>H-SVR: another approach to solve the SSL problem is to use a regression algorithm. For this, we consider the Moore-Penrose pseudoinverse ∆ † µ of the matrix ∆ µ , we train a regression support vector machine and predict player skills. The main parameter is the soft margin parameter.</p><p>Given the player skills, we can deduce team skills, and finally predict game outcomes for new games. For this, we suppose that we are given a training set Γ l of games with known outcomes together with a test set Γ u of games for which game outcomes are hidden. The goal is to predict game outcomes for the test set Γ u . We follow the following protocol.</p><p>Algorithm 1 Predicting game outcomes Input: a training set Γ l of games and a test set Γ u of games 1: Build, as described in Sections 2.1 and 2.2, the matrix ∆ µ using game set Γ l 2: Compute an optimal skill rating s * using H-ZGL or H-SVR for Problem 7 3: Compute the mean skill s among players in Γ l 4: for each game in Γ u do 5:</p><p>Assign skills given by s * to players involved in Γ l , and s otherwise 6:</p><p>Compare the team skills and predict the winner according to Equation <ref type="formula" target="#formula_1">1</ref>7: end for</p></div>
<div><head n="2.4">Experiments</head><p>In this section, we report experimental results for the inference of player skills and the prediction of game outcomes for different data sets in the batch setting described above. Note that other works have considered the online setting as in <ref type="bibr" target="#b7">Herbrich et al. (2006)</ref> or Elo <ref type="bibr">(1978)</ref>.</p></div>
<div><head>Tennis Doubles</head><p>We consider a data set of tennis doubles collected between January 2009 and September 2011 from ATP tournaments (World Tour, Challengers and Futures). Tennis doubles are played by two teams of two players. Each game has a winner (no draw is allowed). A game is played in two or three winning sets. The final score corresponds to the number of sets won by each team during the game. The data set Γ consists in 10028 games with n = 1834 players.</p><p>Along the experimental process, given a proportion ρ, we draw randomly a training set Γ l of size ρ% of the number of games in Γ. The remaining games define the test set Γ u . We present in Figure <ref type="figure">2</ref> several statistics related to this process on the Tennis data set. First, it can be noticed that many players have played a small number of games. Second, when the number of games in the training set is small, half of the players are involved in games in the test set. Therefore, the skill rating problem and the game outcome prediction problem become far more difficult to solve when few games are used for learning.</p><p>The experimental setting is defined as follows. Let ρ be a proportion varying from 10% to 90% by 10%. For every value of ρ, we repeat ten times: draw a random training set Γ l of size ρ% of the number of games in Γ; let the remaining games define the test set Γ u ; infer player skills and predict game outcomes following Algorithm 1. We set all player The experiments presented in this section use µ/n = 16. We report in Figure <ref type="figure" target="#fig_2">3</ref> prediction results using: Algorithm 1 with H-ZGL, Algorithm 1 with H-SVR, Elo Duelling, and Trueskill. 1 It can be noted that Elo Duelling performs poorly but Elo was designed for one against one games. It should be noted that we have done similar experiments for tennis singles. The results are not reported here but they show that Elo Duelling and <software ContextAttributes="used">TrueSkill</software> obtain similar results but are outperformed by H-ZGL and H-SVR. For the data set of tennis doubles, it must be noted that H-ZGL and H-SVR outperform <software ContextAttributes="used">TrueSkill</software> for a small number of training games. Also, H-ZGL outperforms <software ContextAttributes="used">TrueSkill</software> whatever is the number of training games. On this set of experiments H-ZGL outperforms H-SVR but it should be noted that H-ZGL is parameter free and that we use H-SVR with the default soft margin parameter value.</p></div>
<div><head>Xbox Title Halo2</head><p>The Halo2 data set was generated by Bungie Studio during the beta testing of the XBox title Halo2. It has been notably used in <ref type="bibr" target="#b7">Herbrich et al. (2006)</ref> to evaluate the performance of the <software ContextAttributes="used">TrueSkill</software> algorithm. We consider the Small Teams data set with n = 4992 players and 27536 games opposing up to 12 players in two teams which can have a different size. Each game can result in a draw or a win of one of the two teams. The proportion of draws is 22.8%. As reported in <ref type="bibr" target="#b7">Herbrich et al. (2006)</ref>, the prediction of draws is challenging and We consider the same experimental process. For the construction of the hypernode graph in Algorithm 1, we fix all players contributions in games to 1 and we again set the parameter value µ/n to 16. In the optimization problem (7), the game outcomes are set to 1 when the game has a winner and 0 otherwise because game scores vary depending on the type of game. The matrix ∆ µ has dimension n + 2 + 1 = 4995. We again compare the skill rating algorithms H-ZGL, H-SVR, Elo Duelling and <software ContextAttributes="used">TrueSkill</software>. The number of prediction errors over game outcomes is computed assuming that a draw can be regarded as half a win, half a loss as in <ref type="bibr" target="#b9">Lasek et al. (2013)</ref>. We present the experimental results in Figure <ref type="figure" target="#fig_3">4</ref>. For a proportion of 10% of games in the training set, H-ZGL, H-SVR and <software ContextAttributes="used">TrueSkill</software> give similar results while with larger training sets, our hypernode graph learning algorithms outperform <software ContextAttributes="used">TrueSkill</software>. Contrary to the previous experiment, H-SVR (with default parameter value) outperforms H-ZGL.</p></div>
<div><head n="3.">Hypernode Graphs</head><p>In the previous section, we consider the skill rating problem as a SSL problem and we express it as a minimization problem using a positive semidefinite matrix ∆ which expresses conditions on the players skills based on the game outcomes. This allows us to use graphbased SSL algorithms. As games can be considered as relations between sets of players, there is a discrete structure underlying the skill-rating problem. The existing discrete structure and the similarity with graph-based SSL motivate the work presented in this section. Indeed, we now introduce hypernode graphs as a finite model for relations between sets, we show that our matrix ∆ is the Laplacian of such an hypernode graph, and we show that Problem 7 expresses the smoothness of a real-valued node function over the hypernode graph with some constraints on node values. </p></div>
<div><head n="3.1">Introducing Hypernode Graphs</head><p>The following definition is our contribution to the modeling of binary relationships between sets of entities.</p><p>Definition 1 A hypernode graph h = (V, H) is a set of nodes V and a set of hyperedges H. Each hyperedge h ∈ H is an unordered pair {s h , t h } of two non empty and disjoint hypernodes (a hypernode is a subset of V ). Each hyperedge h ∈ H has a weight function w h mapping every node i in s h ∪ t h to a positive real number w h (i) (for i / ∈ s h ∪ t h , we define w h (i) = 0). Each weight function w h must satisfy the Equilibrium Condition defined by</p><formula xml:id="formula_12">i∈t h w h (i) = i∈s h w h (i) .<label>(8)</label></formula><p>We denote by n the number of nodes. We say that a node i belongs to a hyperedge h, that we denote by i ∈ h, if w h (i) = 0. We define the degree of a node i by deg(i) = h w h (i). The degree of a node is positive when it belongs to at least one hyperedge. We define the diagonal degree matrix by D = diag(deg(1), . . . , deg(n)).</p><p>An example of hypernode graph is shown in Figure <ref type="figure">1</ref>. The hyperedge h blue links the sets {1, 2, 3} and {4, 5}. The weights of h blue satisfy the Equilibrium condition:</p><formula xml:id="formula_13">1/2 + 1/2 + √ 2 = √ 2 + √ 2.</formula><p>The hyperedge h black links the sets {4, 5} and {1, 6} and satisfies the Equilibrium condition. The hyperedge h red links the two singletons {3} and {6} with equal weights, thus the hyperedge h red can be viewed as an edge with edge weight 1/3.</p><p>As noted in the previous example, when a hyperedge h is an unordered pair {{i}, {j}}, the Equilibrium Condition states that the weights w h (i) and w h (j) are equal. Therefore, every hypernode graph such that all hyperedges are unordered pairs of singleton nodes can be viewed as a graph with adjacency matrix W defined by W i,j = W j,i = w h (i) = w h (j) for every hyperedge {{i}, {j}}, and 0 otherwise. Conversely, every graph can be viewed as a hypernode graph where every hypernode is a singleton set.</p></div>
<div><head n="3.2">Laplacians and Kernels of Hypernode Graphs</head><p>We are interested in evaluating real-valued functions on nodes and on hypernodes. We assume a weighted linear model such that any real-valued node function f can be extended to a hypernode u of a hyperedge h by f (u) = i∈u f (i) w h (i). Moreover, we will consider an homophilic assumption stating that connected hypernodes tend to have similar values. In order to implement this assumption, we introduce a gradient for hypernode graphs by Definition 2 Let h = (V, H) be a hypernode graph and f be a real-valued node function, the (hypernode graph) unnormalized gradient of h is a linear application, denoted by grad, that maps every real-valued node function f into a real-valued hyperedge function grad(f ) defined, for every h = {s h , t h } in H, by</p><formula xml:id="formula_14">grad(f )(h) = f (t h ) -f (s h ) = i∈t h f (i) w h (i) - i∈s h f (i) w h (i) ,<label>(9)</label></formula><p>where an arbitrary orientation of the hyperedges has been chosen. We denote by G ∈ R p×n the matrix of grad. The square n × n real-valued matrix ∆ = G T G is defined to be the unnormalized Laplacian of the hypernode graph h.</p><p>As suggested by an anonymous reviewer, a hypernode graph could be defined by a gradient matrix as shown in Figure <ref type="figure">1</ref>.</p><p>It should be noted that the Laplacian ∆ does not depend on the arbitrary orientation of the hyperedges chosen for defining the gradient. Also, by definition, the Laplacian ∆ is positive semidefinite. Moreover, because of the definition of the additive model and because of the Equilibrium Condition 8, the gradient of every constant node function is the zero-valued hyperedge function. Consequently, we have 1 ∈ Null(∆) where Null(∆) is the null space of ∆. Last, it could be noted that, when the hypernode graph is a graph (all hypernodes are singleton sets), then the hypernode graph Laplacian is equal to the unnormalized graph Laplacian.</p><p>The Laplacian allows to define the smoothness of a real-valued node function f over a hypernode graph h to be Ω(f ) = f T ∆f .</p><p>Last, we define the hypernode graph kernel of a hypernode graph h to be the Moore-Penrose pseudoinverse ∆ † of the hypernode graph Laplacian ∆.</p><p>Because a hypernode graph Laplacian is positive semidefinite, we can leverage the spectral learning algorithms defined in Von Luxburg (2007), <ref type="bibr" target="#b15">Zhou et al. (2005), and</ref><ref type="bibr">Zhu et al. (2003)</ref> from graphs to hypernode graphs.</p></div>
<div><head n="3.3">Modeling the Skill Rating Problem with Hypernode Graphs</head><p>In this section, we show how to model a batch of games by a hypernode graph and how the problems ( <ref type="formula">4</ref>) and ( <ref type="formula" target="#formula_11">7</ref>) translate on the constructed hypernode graphs.</p><p>We consider a set of m games as in Section 2.1. The construction mimics the construction of the previous section with the additional trick to add a new node in order to satisfy the Equilibrium condition 8 for hyperedges. Indeed, we consider n + m + 1 nodes, n nodes for the players, m nodes for the outcomes and one lazy node. We can define, for every game γ a hyperedge h as follows.</p><p>1. The players of A define one of the two hypernodes of h, the weight of a player node i is defined to be c(i) 2 ;</p><p>2. do the same construction for the second team B;</p><p>3. add the outcome node associated with γ to the set of nodes of the losing team, its weight is set to 1;</p><p>4. add the lazy node to the set of nodes corresponding to the winning team, its weight is chosen in order to ensure the Equilibrium condition for the hyperedge h.</p><p>This defines the hypernode graph h = (V, H). Then, it is easy to show that Problem 4 is equivalent to minimizing s T ∆s where ∆ is the Laplacian of h with constraints for game outcomes and adding the additional constraint s(n + m + 1) = 0 for the lazy node.</p><p>For the regularization term, we define the hypernode graph h µ obtained from the hypernode graph h by adding a regularizer node and adding n hyperedges between every player node and the regularizer node R with (node) weights set to µ/n. Then, it is easy to show that Problem 7 is equivalent to minimizing s T ∆ µ s where ∆ µ is the Laplacian of h µ with constraints for game outcomes and adding the additional constraint s(n + m + 1) = 0 for the lazy node.</p><p>Then as said before, we can leverage graph-based SSL algorithms and consider, for instance, the algorithms H-ZGL and H-SVR of Section 2.3.</p></div>
<div><head n="3.4">The Class of Hypernode Graphs Laplacians</head><p>Proposition 3 The class of hypernode graph Laplacians is the class of symmetric positive semidefinite real-valued matrices M such that 1 ∈ Null(M ) (the null space of M ).</p><p>Proof As a consequence of Definition 2, every hypernode graph Laplacian M is a symmetric positive semidefinite real-valued matrix such that 1 ∈ Null(M ). Conversely, let us consider the following algorithm Algorithm 2 Construction of a hypernode graph Input: M ∈ R n×n symmetric positive semidefinite such that 1 ∈ Null(M )</p><formula xml:id="formula_15">1: Set V to {1, . . . , n}; set H to ∅ 2: Compute a square root decomposition M = G T G 3: for each row r of G do 4: Create a new hyperedge h = {s h , t h } with s h = t h = ∅ 5:</formula><p>for each node i ∈ V do 6:</p><formula xml:id="formula_16">Define w h (i) = r(i) 2 7: if r(i) &lt; 0 then Add i to s h else if r(i) &gt; 0 Add i to t h end if 8:</formula><p>end for</p></div>
<div><head>9:</head><p>Add h to H 10: end for 11: return The hypernode graph h = (V, H) From a square root decomposition G T G of M , for each line of G, we define a hyperedge h = {s h , t h } where nodes in s h (respectively in t h ) have positive (respectively negative) values in the line, and node weights are chosen to be squares of values in the line. Then, the Equilibrium condition 8 is satisfied because 1 ∈ Null(M ). And it is easy to check that G is a gradient matrix of h and, consequently, that M = G T G is the Laplacian of h.</p><p>As a consequence of Proposition 3, the class of hypernode graph Laplacians</p><p>• is closed under convex linear combination,</p><p>• is closed under pseudoinverse,</p><p>• and strictly contains the class of graph Laplacians and the class of graph kernels (a graph kernel is the Moore-Penrose pseudoinverse of a graph Laplacian).</p><p>Linear combinations of graph kernels have been used for SSL (see for instance <ref type="bibr" target="#b2">Argyriou et al., 2005)</ref>. Another consequence of Proposition 3 is that any convex linear combination of graph kernels is a hypernode graph kernel (but not necessarily a graph kernel). To conclude this section, we propose</p></div>
<div><head>Conjecture:</head><p>The class of hypernode graph Laplacians is the smallest class closed by convex linear combination which contains all graph kernels.</p><p>The main point is to prove that every hypernode graph Laplacian is a convex linear combination of graph kernels which is difficult because a graph kernel has no simple analytic form.</p></div>
<div><head n="3.5">Hypernode Graph Laplacians Strictly Generalize Graph Laplacians</head><p>As said above, the class of hypernode graph Laplacians strictly contains the class of graph Laplacians. But this does not allow us to claim that hypernode graph Laplacians provide a gain of expressiveness over graph Laplacians. Indeed, it could be the case that through a well chosen graph construction, the set of smooth functions f defined on hypernode graphs by f T ∆f = 0 could be made to coincide exactly with the set of smooth functions defined on graphs. The class of hypergraph Laplacians has been studied in that perspective of expressiveness. Indeed, it has been shown in <ref type="bibr" target="#b1">Agarwal et al. (2006)</ref> that hypergraph Laplacians such as the ∆ B from <ref type="bibr" target="#b3">Bolla (1993)</ref>, ∆ R from Rodríguez (2003) and ∆ ZHS from <ref type="bibr" target="#b16">Zhou et al. (2007)</ref> can be defined as (restrictions of) graph Laplacians using a graph construction such as the clique expansion (where each hyperedge is replaced by a clique graph with uniform weights) or the star expansion (where, for every hyperedge, a new node is added and is linked with all the nodes in the hyperedge).</p><p>While one can think of similar constructions for the case of hypernode graphs, we prove that there does not exist a (finite) graph expansion of a hypernode graph which defines the same set of smooth functions over the original set of nodes. The proof is based on the very simple hypernode graph h shown in Figure <ref type="figure" target="#fig_4">5</ref>. Note that a function is smooth over h if and only if it satisfies (f (1</p><formula xml:id="formula_17">) + f (2) -f (3) -f (4)) 2 = 0 . (C)</formula></div>
<div><head>We show that</head><p>Proposition 4 There do not exist a finite graph g whose node set contains {1, 2, 3, 4} and that satisfies the conditions:</p><p>1. All the smooth functions on g satisfy (C).</p><p>2. Any function that satisfy (C) can be extended to a smooth function on g.</p><p>Proof Let us define S = {1, 3} and denote by ∆ the Laplacian matrix of h. The indicator vector 1 S is in Null(∆) and, thus, define a smooth function on h. Let us consider a graph g e = (N e , E e ) whose nodeset N e contains the nodeset N = {1, 2, 3, 4} and that satisfies the two conditions presented in Proposition 4. We denote by ∆ e the Laplacian matrix of g e . Because of the second condition, the function 1 S can be extended to a smooth function f e on g e .</p><p>Since g e is a graph, we know that Null(∆ e ) is spanned by the indicator vectors of the connected components of g e (see for <ref type="bibr">instance Von Luxburg, 2007)</ref>. Since f e (1) = 1 S (1) = f e (2) = 1 S (2), 1 and 2 must be in different components in g e . Note that the same holds with f e (1) = f e (4), f e (3) = f e (2) and f e (3) = f e (4). By following a similar reasoning with S = {1, 4}, we eventually deduce that the four original nodes 1, 2, 3 and 4 must be in distinct components in g e .</p><p>Let us now consider the components C of g e that contains the node 1. As stated above, we have necessarily f e (2) = f e (3) = f e (4) = 0. The indicator function f e of C is smooth on g e but we have</p><formula xml:id="formula_18">(f e (1) + f e (2) -f e (3) -f e (4)) 2 = (1 + 0 -0 -0) 2 = 0 .</formula><p>Consequently, f e does not satisfy (C), which violates the first condition and concludes the proof.</p><p>The first condition in Proposition 4 ensures that smooth functions on g are related to smooth functions over the original hypernode graph h. The second condition in Proposition 4 ensures that smooth functions on the original hypernode graph can be defined from smooth functions over expanded finite graphs. The combination of these two conditions ensure that the problem of finding smooth functions on h can be rephrased as a graph problem (finding the smooth functions on g and compute their restrictions to {1, 2, 3, 4}). The fact that no graph g can satisfy both conditions at the same time for a simple hypernode graph h shows that smoothness properties over hypernode graphs can not be defined over undirected expanded graphs. </p><formula xml:id="formula_19">1 2 3 4 1 1 1 1 ∆ =     1 1 -1 -1 1 1 -1 -1 -1 -1 1 1 -1 -1 1 1    </formula><formula xml:id="formula_20">G = 1 1 -1 -1 0 0 -1 1 1 2 3 4 0.5 0.5 2 0.5 0.5 2 G = - √ 2 2 - √ 2 2 √ 2 0 - √ 2 2 - √ 2 2 0 √ 2</formula><p>Figure <ref type="figure">6</ref>: two L-equivalent hypernode graphs with their respective gradient which are square root of the Laplacian ∆ shown in Figure <ref type="figure">7</ref>.</p><formula xml:id="formula_21">∆ =     1 1 -1 -1 1 1 -1 -1 -1 -1 2 0 -1 -1 0 2     ; W =     0 -1 1 1 -1 0 1 1 1 1 0 0 1 1 0 0     ; D =     1 0 0 0 0 1 0 0 0 0 2 0 0 0 0 2     .</formula><p>Figure <ref type="figure">7</ref>: Laplacian matrix, pairwise weight matrix, and degree matrix for the two Lequivalent hypernode graphs shown in Figure <ref type="figure">6</ref>.</p><p>root decomposition is not unique, there are several hypernode graphs with the same Laplacian that we called L-equivalent. Examples of L-equivalent hypernode graphs are given in Figure <ref type="figure">6</ref>. In order to study the L-equivalent relation and to decide whether a hypernode graph is L-equivalent to a graph, we first show that hypernode graphs are related to signed graphs.</p><p>It is known that the Laplacian matrix ∆ of a graph can be written D -W where W is the adjacency matrix of the graph and D is the corresponding degree matrix. Let us consider a hypernode graph h with Laplacian ∆, we define the pairwise weight matrix W of h by W i,j = -∆ i,j if i = j, and 0 otherwise. Note that the pairwise weight matrix coincides with the classic adjacency matrix when the hypernode graph is a graph. Let us define the degree of a node i to be deg(i) = j∈V W i,j and let us denote by D the diagonal matrix of all deg(i). Then, because of the property 1 ∈ Null(M ) in Proposition 3, it is immediate that, for every i, ∆ i,i = j∈V W i,j . As a consequence, we have Proposition 5 Let h = (V, H) be a hypernode graph, let W be the pairwise weight matrix of h, and let D be the diagonal degree matrix of h. Then, the Laplacian of h is ∆ = D -W .</p><p>An example is shown in Figure <ref type="figure">7</ref>. As a consequence of the above proposition, we can leverage the pairwise weight matrix to characterize L-equivalent hypernode graphs by Proposition 6 Two hypernode graphs are L-equivalent if and only if they have the same pairwise weight matrix. Two L-equivalent hypernode graphs have the same degree matrix.</p><p>The pairwise weight matrix W contains in general negative weights and can be thus interpreted as the adjacency matrix of a signed graph. Therefore, we define the reduced signed graph of a hypernode graph h to be the signed graph g with adjacency matrix W . An example is shown in Figure <ref type="figure" target="#fig_5">8</ref>. Then, we can show that</p><p>• the reduced signed graph of a graph g (viewed as a hypernode graph) is the graph g,</p><p>• a hypernode graph h is L-equivalent to a graph if and only if its reduced signed graph is a graph,</p><p>• a signed graph with adjacency matrix W is the reduced signed graph of a hypernode graph if and only if the matrix D -W is positive semidefinite.</p><p>The definition of the pairwise weight matrix may seem ad hoc to mimic the definition of the Laplacian in the graph case. But, we can show that the pairwise weight matrix can be defined directly from the hypernode graph using the following formula ∀i = j, W i,j = h∈H P (h, i, j) w h (i) w h (j) ,</p><p>where P (h, i, j) = 1 if i and j belongs to two different ends of h, P (h, i, j) = -1 if i and j belongs to the same end of h, and 0 otherwise. The pairwise weight W i,j can be interpreted as a flow measure between node i and j in the hypergraph. It is computed as a sum over all the hyperedges involving nodes i and j. For every term in the sum, the quantity w h (i) can be viewed as the cost of entering the hyperedge h at node i, the quantity w h (j) as the cost of exiting the hyperedge h at node j, and P (h, i, j) as a sign depending whether i and j are in the same end or in different ends of the hyperedge.</p></div>
<div><head n="3.7">Defining a distance in Hypernode Graphs</head><p>We now study whether a distance can be defined between nodes of a hypernode graph. Let us consider a hypernode graph h = (V, H) with Laplacian ∆. Let ∆ † be the Moore-Penrose pseudo-inverse of ∆, let us define d by, for every i, j in V ,</p><formula xml:id="formula_23">d(i, j) = ∆ † i,i + ∆ † j,j -2∆ † i,j .<label>(11)</label></formula><p>Because ∆ † is symmetric positive semidefinite, we have Proposition 7 d defines a pseudometric on h: it is positive, symmetric and satisfies the triangle inequality (for all i, j, k the inequality d(i, j) ≤ d(i, k) + d(k, j) holds).</p><p>For the pseudometric d to be a distance, d should satisfy also the coincidence axiom: d(i, j) = 0 ⇒ i = j. This is not true in general as d(1, 2) = 0 for the hypernode graph in Figure <ref type="figure" target="#fig_4">5</ref>. The intuition is that the nodes 1 and 2 can not be distinguished because the smoothness condition is on the sum f (1) + f (2). Nevertheless we can show that Proposition 8 When Null(∆) = Span(1), d defines a metric (or distance) on h.</p><p>Let us recall that, in the graph case, Proposition 7 holds and that Proposition 8 holds when the graph is connected. By analogy with the case of graphs, the condition Null(∆) = Span(1) can be viewed as an algebraic definition of a connected hypergraph. So far, we have not found an alternative algorithmic definition of connected components in hypernode graphs.</p><p>Finally, let us note that, in the graph case, for connected graphs, both d and d 2 are metrics while, for hypernode graphs, d 2 does not satisfy the triangle inequality even if Null(∆) = Span <ref type="bibr" target="#b0">(1)</ref>. We provide in <ref type="bibr" target="#b12">Ricatte et al. (2015)</ref> a formulation of d 2 in terms of diffusion potentials but do not find an interpretation of d 2 using random walks in hypernode graphs.</p></div>
<div><head n="4.">Conclusion</head><p>We have introduced a new model and new algorithms to learn from binary relations between groups. We showed that our method obtained state-of-the-art results for skill rating in multiplayer games. We are convinced that our method could be successfully applied to other games where players have different roles (such as team sports like basketball, american football or baseball) by modeling roles with weights. From a machine learning perspective, we believe that this model will open the way to solving new learning problems in networks when relations between sets of nodes are meaningful. From a fundamental perspective, our model is a strict generalization of graphs. Many theoretical studies remain to be done on the spectral theory of hypernode graphs. Note that we leave open some questions such as finding a characterization of the class of hypernode graphs, finding an algorithmic definition of connected components, and how to interpret random walks and distances on hypernode graphs. Also the study of directed hypernode graphs remains to be done from a machine learning perspective.</p></div><figure xml:id="fig_1"><head /><label /><figDesc>Figure 2: [left] Distribution of the number of players against the number of played games;[right] Average percentage of players in Γ u which are involved in some game in Γ l</figDesc></figure>
<figure xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Predictive error for Double Tennis data set</figDesc></figure>
<figure xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Predictive error for Halo2 data set</figDesc></figure>
<figure xml:id="fig_4"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: A hypernode graph h and its Laplacian ∆</figDesc></figure>
<figure xml:id="fig_5"><head>Figure 8 :</head><label>8</label><figDesc>Figure 8: The reduced signed graph with adjacency matrix W of Figure 7 of the two Lequivalent hypernode graphs shown in Figure 6.</figDesc></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgments</head><p>The authors are very grateful to the referees for their constructive comments and to the Editor <rs type="person">David Blei</rs> for his unwavering support.</p></div>
			</div>			<div type="annex">
<div><p>Xiaojin Zhu, Zoubin Ghahramani, John Lafferty, et al. Semi-supervised learning using gaussian fields and harmonic functions. In Proceedings of the 20th International conference on Machine learning (ICML-03), pages <ref type="bibr">912-919, 2003.</ref> </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Parameters of Elo and TrueSkill are the default parameters of Hamilton</title>
		<author>
			<persName><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">8.33 and τ = 0.25 for TrueSkill)</title>
		<imprint>
			<date type="published" when="2012">2012. 2013. 2013. 2012</date>
		</imprint>
	</monogr>
	<note>) (K = 32 for Elo, µ0 = 25, β = 12.5</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Higher Order Learning with Graphs</title>
		<author>
			<persName><forename type="first">Sameer</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kristin</forename><surname>Branson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Serge</forename><surname>Belongie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd International conference on Machine learning (ICML-06)</title>
		<meeting>the 23rd International conference on Machine learning (ICML-06)</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="17" to="24" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Combining Graph Laplacians for Semi-Supervised Learning</title>
		<author>
			<persName><forename type="first">Andreas</forename><surname>Argyriou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><surname>Herbster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Massimiliano</forename><surname>Pontil</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 19th Annual Conference on Neural Information Processing Systems (NIPS-05)</title>
		<meeting>the 19th Annual Conference on Neural Information Processing Systems (NIPS-05)</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="67" to="74" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Spectra, euclidean representations and clusterings of hypergraphs</title>
		<author>
			<persName><forename type="first">Marianna</forename><surname>Bolla</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Discrete Mathematics</title>
		<imprint>
			<biblScope unit="volume">117</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="19" to="39" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Spectral properties of hypergraph laplacian and approximation algorithms</title>
		<author>
			<persName><forename type="first">T.-H</forename><surname>Hubert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Louis</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhihao</forename><surname>Anand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gavin</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chenzi</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the ACM (JACM)</title>
		<imprint>
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="issue">3 -15</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">The Rating of Chess Players, Past and Present</title>
		<author>
			<persName><forename type="first">Arpad</forename><surname>Emrick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elo</forename></persName>
		</author>
		<imprint>
			<date type="published" when="1978">1978</date>
			<publisher>Arco Publishing</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">PythonSkills: Implementation of the TrueSkill, Glicko and Elo Ranking Algorithms</title>
		<author>
			<persName><forename type="first">Scott</forename><surname>Hamilton</surname></persName>
		</author>
		<ptr target="https://pypi.python.org/pypi/skills" />
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">TrueSkill TM : A Bayesian Skill Rating System</title>
		<author>
			<persName><forename type="first">Ralf</forename><surname>Herbrich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tom</forename><surname>Minka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thore</forename><surname>Graepel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 20th Annual Conference on Neural Information Processing Systems (NIPS-06)</title>
		<meeting>the 20th Annual Conference on Neural Information Processing Systems (NIPS-06)</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="569" to="576" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">ACE: a fast multiscale eigenvectors computation for drawing huge graphs</title>
		<author>
			<persName><forename type="first">Yeruda</forename><surname>Koren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liran</forename><surname>Carmel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Harel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Symposium on Information Visualization (INFOVIS-02)</title>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="137" to="144" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">The predictive power of ranking systems in association football</title>
		<author>
			<persName><forename type="first">Jan</forename><surname>Lasek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zoltán</forename><surname>Szlávik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sandjai</forename><surname>Bhulai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Applied Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="27" to="46" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Python implementation of Elo: A rating system for chess tournaments</title>
		<author>
			<persName><forename type="first">Heungsub</forename><surname>Lee</surname></persName>
		</author>
		<ptr target="https://pypi.python.org/pypi/elo/0.1.dev,2013a" />
		<imprint />
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<author>
			<persName><forename type="first">Heungsub</forename><surname>Lee</surname></persName>
		</author>
		<ptr target="http://trueskill.org/,2013b" />
		<title level="m">Python implementation of TrueSkill: The video game rating system</title>
		<imprint />
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Hypernode Graphs for Learning from Binary Relations between Groups in Networks</title>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Ricatte</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rémi</forename><surname>Gilleron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marc</forename><surname>Tommasi</surname></persName>
		</author>
		<ptr target="https://hal.inria.fr/hal-01247103" />
		<imprint>
			<date type="published" when="2015-01">January 2015</date>
		</imprint>
		<respStmt>
			<orgName>INRIA Lille</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Research report</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">On the Laplacian spectrum and walk-regular hypergraphs</title>
		<author>
			<persName><surname>Ja Rodríguez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Linear and Multilinear Algebra</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="285" to="297" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">A tutorial on spectral clustering</title>
		<author>
			<persName><forename type="first">Ulrike</forename><surname>Von</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luxburg</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Statistics and computing</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="395" to="416" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Learning from labeled and unlabeled data on a directed graph</title>
		<author>
			<persName><forename type="first">Dengyong</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiayuan</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bernhard</forename><surname>Schölkopf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd International conference on Machine learning (ICML-05)</title>
		<meeting>the 22nd International conference on Machine learning (ICML-05)</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="1036" to="1043" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Learning with hypergraphs: Clustering, classification, and embedding</title>
		<author>
			<persName><forename type="first">Dengyong</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiayuan</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bernhard</forename><surname>Schölkopf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 20th Annual Conference on Neural Information Processing Systems (NIPS-06)</title>
		<meeting>the 20th Annual Conference on Neural Information Processing Systems (NIPS-06)</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="1601" to="1608" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>