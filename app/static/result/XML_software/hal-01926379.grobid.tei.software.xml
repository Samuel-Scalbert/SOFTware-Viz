<TEI xmlns="http://www.tei-c.org/ns/1.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xml:space="preserve" xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Bridging the Semantic Web and NoSQL Worlds: Generic SPARQL Query Translation and Application to MongoDB</title>
			</titleStmt>
			<publicationStmt>
				<publisher />
				<availability status="unknown"><licence /></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Franck</forename><surname>Michel</surname></persName>
							<email>franck.michel@cnrs.fr</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Université Côte d'Azur</orgName>
								<orgName type="institution" key="instit2">Inria</orgName>
								<orgName type="institution" key="instit3">CNRS</orgName>
								<address>
									<region>I3S</region>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Catherine</forename><surname>Faron-Zucker</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Université Côte d'Azur</orgName>
								<orgName type="institution" key="instit2">Inria</orgName>
								<orgName type="institution" key="instit3">CNRS</orgName>
								<address>
									<region>I3S</region>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Johan</forename><surname>Montagnat</surname></persName>
							<email>johan.montagnat@cnrs.fr</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Université Côte d'Azur</orgName>
								<orgName type="institution" key="instit2">Inria</orgName>
								<orgName type="institution" key="instit3">CNRS</orgName>
								<address>
									<region>I3S</region>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Bridging the Semantic Web and NoSQL Worlds: Generic SPARQL Query Translation and Application to MongoDB</title>
					</analytic>
					<monogr>
						<imprint>
							<date />
						</imprint>
					</monogr>
					<idno type="MD5">4F5330BE2AA4B3F360E5787BD42CC1BC</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-04-12T14:47+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid" />
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Query rewriting</term>
					<term>SPARQL</term>
					<term>RDF</term>
					<term>NoSQL</term>
					<term>xR2RML</term>
					<term>Linked Data</term>
				</keywords>
			</textClass>
			<abstract>
<div><p>RDF-based data integration is often hampered by the lack of methods to translate data locked in heterogeneous silos into RDF representations. In this paper, we tackle the challenge of bridging the gap between the Semantic Web and NoSQL worlds, by fostering the development of <software>SPARQL</software> interfaces to heterogeneous databases. To avoid defining yet another <software ContextAttributes="used">SPARQL</software> translation method for each and every database, we propose a two-phase method. Firstly, a <software ContextAttributes="used">SPARQL</software> query is translated into a pivot abstract query. This phase achieves as much of the translation process as possible regardless of the database. We show how optimizations at this abstract level can save subsequent work at the level of a target database query language. Secondly, the abstract query is translated into the query language of a target database, taking into account the specific database capabilities and constraints. We demonstrate the effectiveness of our method with the <software ContextAttributes="used">MongoDB</software> NoSQL document store, such that arbitrary <software ContextAttributes="used">MongoDB</software> documents can be aligned on existing domain ontologies and accessed with <software ContextAttributes="used">SPARQL</software>. Finally, we draw on a real-world use case to report experimental results with respect to the effectiveness and performance of our approach.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div><head n="1">Introduction</head><p>The Resource Description Framework (RDF) <ref type="bibr" target="#b10">[11]</ref> is increasingly adopted as the pivot format for integrating heterogeneous data sources. It offers a unified data model that allows building upon countless existing vocabularies and domain ontologies, while benefiting from Semantic Web's reasoning capabilities. It also allows leveraging the growing, world-scale knowledge base referred to as the Web of Data. Today, increasing amounts of RDF data are published on the Web, notably following the Linked Data principles <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b17">19]</ref>. These data often originate from heterogeneous silos that are inaccessible to data integration systems and search engines. Hence, a first step to enabling RDF-based data integration consists in translating legacy data from heterogeneous formats into RDF representations.</p><p>During the last fifteen years, much work has investigated how to translate common databases and data formats into RDF. Relational databases were primarily targeted <ref type="bibr" target="#b34">[36,</ref><ref type="bibr" target="#b32">34]</ref>, along with a handful of data formats such as XML <ref type="bibr" target="#b2">[3]</ref> and CSV <ref type="bibr" target="#b26">[28]</ref>. Meanwhile, the database landscape has significantly diversified with the adoption of various non-relational models. Initially designed as the core system of Big Data Web applications, NoSQL databases have gained momentum and are now increasingly adopted as general-purpose, commonplace databases. Today, companies and institutions store massive amounts of data in NoSQL instances. So far however, these data often remain inaccessible to RDF-based data integration systems, and consequently invisible to the Web of Data. although unleashing their data could potentially spur new integration opportunities and push the Web of Data forward.</p><p>The Semantic Web and NoSQL worlds build upon very different paradigms that are challenging to bridge over: whereas the former handles highly connected graphs along with the rich expressiveness of <software ContextAttributes="used">SPARQL</software>, the latter trades off query expressiveness for scalability and fast retrieval of denormalized data<ref type="foot" target="#foot_0">1</ref> . As a result of these discrepancies, bridging the gap between those two worlds is a challenging endeavor.</p><p>Two strategies generally apply when it comes to access non-RDF data as RDF. In the graph materialization strategy, the transformation is applied exhaustively to the database content, the resulting RDF graph is loaded into a triple store and accessed through a <software ContextAttributes="used">SPARQL</software> query engine <ref type="bibr" target="#b16">[18]</ref> or by dereferencing URIs (as Linked Data). On the one hand, this strategy easily supports further processing or analysis, since the graph is made available at once. On the other hand, the materialized RDF graph may rapidly become outdated if the pace of database updates is high. Running the transformation process periodically is a common workaround, but in the context of large data sets, the cost (in time, memory and CPU) of materializing and reloading the graph may become out of reach. To work out this issue, the query rewriting strategy aims to access heterogeneous databases as virtual RDF graphs. A query processor rewrites a <software ContextAttributes="used">SPARQL</software> query into the query language of the target database. The target database query is evaluated at run-time such that only relevant data are fetched from the database and translated into RDF triples. This strategy better scales to big data sets and guarantees data freshness, but entails overheads that may penalize performances if complex analysis is needed.</p><p>In previous works we defined a generic mapping language, xR2RML <ref type="bibr" target="#b23">[25]</ref>, that enables the translation of a broad scope of data sources into RDF. The mapping instructs how to translate each data item from its original format into RDF triples, by adapting to the multiplicity of query languages and data models. We applied xR2RML to the <software ContextAttributes="used">MongoDB</software> NoSQL document store<ref type="foot" target="#foot_1">2</ref> and we implemented the graph materialization strategy.</p><p>To cope with large and frequently updated data sets though, we wish to tackle the question of accessing such databases using the query rewriting strategy. Hence, to avoid defining yet another <software>SPARQL</software> translation method for each and every database, in this paper we investigate a general two-phase method. Firstly, given a set of xR2RML mappings, a SPARQL query is rewritten into a pivot abstract query. This phase achieves as much of the translation process as possible regardless of the database, and enforces early query optimizations. Secondly, the abstract query is translated into the target database query language, taking into account the specific database capabilities and constraints. We demonstrate the effectiveness of our method in the case of MongoDB, accessing arbitrary MongoDB documents with <software ContextAttributes="used">SPARQL</software>. We show that we can always rewrite an abstract query into a union of <software ContextAttributes="used">MongoDB</software> find queries that shall return all the documents required to answer the <software ContextAttributes="used">SPARQL</software> query.</p><p>The rest of this article is organized as follows. After a review of <software>SPARQL</software> query rewriting approaches in section 2, we quickly remind the principles and main features of the xR2RML mapping language in section 3. Then, in sections 4 and 5 we describe the two-phase method introduced above. In section 6, we describe a real-world use case and we report experimental results with respect to the effectiveness and performance of our approach. Finally, we discuss our solution and envision some perspectives in section 7, and we draw some conclusions in section 8.</p></div>
<div><head n="2">Related Works</head></div>
<div><head n="2.1">Rewriting SPARQL to SQL and XQuery</head><p>Since the early 2000's, various works have investigated methods to query legacy data sources with <software ContextAttributes="used">SPARQL</software>. Relational databases (RDB) have caught much attention, either in the context of RDB-backed RDF stores <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b33">35,</ref><ref type="bibr" target="#b13">14]</ref> or using arbitrary relational schemas <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b36">38,</ref><ref type="bibr" target="#b27">29,</ref><ref type="bibr" target="#b29">31,</ref><ref type="bibr" target="#b30">32]</ref>. These methods harness the ability of SQL to support joins, unions, nested queries and various string manipulation functions. Typically, a conjunction of two <software ContextAttributes="used">SPARQL</software> basic graph patterns (BGP) results in the inner join of their respective translations; their union results in a SQL UNION ALL clause; the <software ContextAttributes="used">SPARQL</software> OPTIONAL clause results in a left outer join, and a <software ContextAttributes="used">SPARQL</software> FILTER results in an encapsulating SQL SELECT WHERE clause.</p><p>Chebotko's algorithm <ref type="bibr" target="#b9">[10]</ref> focused on RDB-based triple stores. Priyatna et al. <ref type="bibr" target="#b27">[29]</ref> extended it to support custom R2RML mappings (the W3C recommendation of an RDB-to-RDF mapping language <ref type="bibr" target="#b11">[12]</ref>) while applying several query optimizations. Two limitations can be emphasized though: (i) R2RML mappings must have constant predicates, i.e. the predicate term of the generated RDF triples cannot be built from database values; (ii) Triple patterns are considered and translated independently of each other, even when they share <software ContextAttributes="used">SPARQL</software> variables. The resulting SQL query embeds unnecessary complexity that is taken care of later on, in the SQL query optimization step. Unbehauen et al. <ref type="bibr" target="#b36">[38]</ref> clear the first limitation by defining the concept of compatibility between the RDF terms of a <software ContextAttributes="used">SPARQL</software> triple pattern and R2RML mappings, which enables managing variable predicates. Furthermore, to address the second limitation, they pre-checking join constraints implied by shared variables in order to reduce the number of candidate mappings for each triple pattern. Yet again, two limitations can be noticed: (iii) References between R2RML mappings are not considered, hence joins implied by shared variables are dealt with but joins declared in the R2RML mapping graph are ignored. (iv) The rewriting process associates each part of a mapping to a set of columns, called column group, which enables filter, join and data type compatibility checks. This leverages SQL capabilities (CASE, CAST, string concatenation, etc.), making it hardly applicable out of the scope of SQL-based systems. In the three aforementioned approaches, the optimization is dependent on the target database language, and can hardly be generalized. In our attempt to rewrite <software ContextAttributes="used">SPARQL</software> queries in the general case, such optimization are performed earlier, regardless of the target database capabilities.</p><p>In a somewhat different approach, Rodríguez-Muro and Rezk <ref type="bibr" target="#b30">[32]</ref> extend the <software ContextAttributes="used">ontop</software> Ontology-Based Data Access (OBDA) system to support R2RML mappings. A <software ContextAttributes="used">SPARQL</software> query and an R2RML mapping graph are translated into a Datalog program. This formal representation is used to combine and apply optimization techniques from logic programming and SQL querying. The optimized program is then translated into an executable SQL query.</p><p>Other approaches investigated the querying of XML databases in a rather similar philosophy. For instance, <software ContextAttributes="used">SPARQL</software>2<software ContextAttributes="used">XQuery</software> <ref type="bibr" target="#b3">[4]</ref> relies on the ability of <software ContextAttributes="used">XQuery</software> to support joins, nested queries and complex filtering. Typically, a <software ContextAttributes="used">SPARQL</software> FILTER is translated into an encapsulating For-Let-Where <software ContextAttributes="used">XQuery</software> clause.</p><p>Finally, it occurs that the rich expressiveness of SQL and <software>XQuery</software> makes it possible to translate a <software ContextAttributes="used">SPARQL</software> 1.0 query into a single, possibly deeply nested, target query, whose semantics is provably strictly equivalent to that of the <software ContextAttributes="used">SPARQL</software> query. Commonly, query optimization issues are addressed at the level of the produced target query, or they may even be delegated to the target database optimization engine. Hence, the above reviewed methods are tailored to the expressiveness of the target query language, such that SQL or <software ContextAttributes="used">XQuery</software> specificities are woven into the translation method itself, which undermines the ability to use such methods beyond their initial scope.</p></div>
<div><head n="2.2">Rewriting SPARQL to NoSQL</head><p>To the best of our knowledge, little work has investigated how to perform RDFbased data integration over the NoSQL family of databases. An early work 3 has tackled the translation of <software ContextAttributes="used">CouchDB</software> 4 documents into RDF, but did not addressed <software ContextAttributes="used">SPARQL</software> rewriting. <software ContextAttributes="used">MongoGraph</software> 5 is an extension of the <software ContextAttributes="used">AllegroGraph</software> triple store to query arbitrary <software ContextAttributes="used">MongoDB</software> documents with <software ContextAttributes="used">SPARQL</software>. But very much like the Direct Mapping <ref type="bibr" target="#b0">[1]</ref> defined in the context of RDBs, both works come up with an ad-hoc ontology (e.g. each JSON field name is turned into a predicate) and hardly supports the reuse of existing ontologies. Tomaszuk proposed to use a <software ContextAttributes="used">MongoDB</software> database as an RDF triple store <ref type="bibr" target="#b35">[37]</ref>. In this context, the author devised a translation of <software ContextAttributes="used">SPARQL</software> queries into <software ContextAttributes="used">MongoDB</software> queries, that is however closely tied to the specific database schema and thus is unfit for arbitrary documents.</p><p>More in line with our work, Botoeva et al. proposed a generalization of the OBDA principles <ref type="bibr" target="#b28">[30]</ref> to <software ContextAttributes="used">MongoDB</software> <ref type="bibr" target="#b7">[8]</ref>. They describe a two-step rewriting process of <software ContextAttributes="used">SPARQL</software> queries into a <software ContextAttributes="used">MongoDB</software> aggregate pipeline. In section 7, we analyze in further details the relationship between their approach and ours. Interestingly, to the best of our knowledge, only one approach tackled the keyvalue store subset of NoSQL databases. Mugnier et al. <ref type="bibr" target="#b24">[26]</ref> define the NO-RL rule language that can express lightweight ontologies to be applied to key-value stores. Leveraging the formal semantics of NO-RL, they propose an algorithm to reformulate a query under a NO-RL ontology, but <software ContextAttributes="used">SPARQL</software> is not considered.</p><p>Finally, since NoSQL document stores are based on JSON, let us mention the JSON-LD syntax that is meant for the serialization of Linked Data in the JSON format. When applied to existing JSON documents, a JSON-LD profile can be considered as a lightweight method to interpret JSON data as RDF. Such a profile could be exploited by a <software>SPARQL</software> rewriting engine to enable the querying of document stores with <software ContextAttributes="used">SPARQL</software>. This approach would be limited though, since JSON-LD is not meant to describe rich mappings from JSON to RDF, but simply to interpret JSON as RDF. It lacks the expressiveness and flexibility required to align JSON documents with domain ontologies that may model data in a rather different manner. Besides, we do not want to define a method specifically tailored to <software ContextAttributes="used">MongoDB</software>; our point is to provide a generic rewriting method that can be applied to the concrete case of <software ContextAttributes="used">MongoDB</software> as well as various other databases.</p></div>
<div><head n="3">The xR2RML Mapping Language</head><p>The xR2RML mapping language <ref type="bibr" target="#b23">[25]</ref> intends to foster the translation of legacy data sources into RDF. It can describe the mapping of an extensible scope of databases to RDF, independently of any query language or data model. It is backward compatible with R2RML and relies on RML <ref type="bibr" target="#b12">[13]</ref> for the handling of various data formats. It can translate data with mixed embedded formats and generate RDF collections and containers.</p><p>An xR2RML mapping defines a logical source (property xrr:logicalSource) as the result of executing a query against an input database (xrr:query and rr:tableName). An optional iterator (value of property rml:iterator) can be applied to each query result, and a xrr:uniqueRef property can identify unique fields. Data from the logical source is mapped to RDF terms (literal, IRI, blank node) by term maps. There exists four types of term maps: a subject map generates the subject of RDF triples, predicate and object maps produce the predicate and object terms, and an optional graph map is used to name a target graph. Listing 1.1 depicts two mappings &lt;#Mbox&gt; and &lt;#Knows&gt;, each consisting of a subject map, a predicate map and an object map.</p><p>Term maps extract data from query results by evaluating xR2RML references whose syntax depends on the target database and is an implementation choice: typically, this may be a column name in case of a relational database, an XPath expression in case of an XML database, or a <software>JSONPath</software> When the evaluation of an xR2RML reference produces several RDF terms, the xR2RML processor creates one triple for each term. Alternatively, the rr:termType property of a term map can be used to group the terms in an RDF collection while specifying a language tag or data type. Besides, the default iteration model can be modified using nested term maps, notably useful to parse nested collections of values and generate appropriate triples.</p><p>xR2RML allows to model cross-references by means of referencing object maps that use values produced by the subject map of a parent mapping as the objects of triples produced by a child mapping. Properties rr:child and rr:parent specify the join condition between documents of both mappings. Running Example. To illustrate the description of our method, we define a running example that we shall use throughout this paper. Let us consider a <software>MongoDB</software> database with a collection people depicted in Listing 1.2: each JSON document provides the identifier, email addresses and contacts of a person; contacts are identified by their email addresses.</p><p>Let us now consider the xR2RML mapping graph in Listing 1.1, consisting of two mappings &lt;#Mbox&gt; and &lt;#Knows&gt;. The logical source of mappings &lt;#Mbox&gt;, { "id id id ": 105632 , "firstname firstname firstname ":" John " , "emails emails emails ":</p><p>[" john@foo . com " ," john@example . org "] , "contacts contacts contacts ": [" chris@example . org " , " alice@foo . com "] } { "id id id ": 327563 , "firstname firstname firstname ":" Alice " , "emails emails emails ":</p><p>[" alice@foo . com "] , "contacts contacts contacts ": [" john@foo . com "] } Listing 1.2. <software>MongoDB</software> collection "people" containing two documents respectively &lt;#Knows&gt;, is a <software ContextAttributes="used">MongoDB</software> query that retrieves documents having a non-null emails field, respectively a contacts array field with at least one element. Both subject maps use a template to build IRI terms by concatenating http://example.org/member/ with the value of JSON field id. Applied to the documents in Listing 1.2, the xR2RML mapping graph generates the following RDF triples:</p><p>&lt; http :// example . org / member /105632 &gt; foaf : mbox &lt; mailto : john@foo . com &gt; , &lt; mailto : john@example . org &gt;; foaf : knows &lt; http :// example . org / member /327563 &gt;.</p><p>&lt; http :// example . org / member /327563 &gt; foaf : mbox &lt; mailto : alice@foo . com &gt;; foaf : knows &lt; http :// example . org / member /105632 &gt;.</p><p>4 From <software ContextAttributes="used">SPARQL</software> to Abstract Queries Section 2 emphasized that <software ContextAttributes="used">SPARQL</software> rewriting methods for SQL or <software ContextAttributes="used">XQuery</software> rely on prior knowledge about the target query language expressiveness. This makes possible the semantics-preserving translation of a <software ContextAttributes="used">SPARQL</software> query into a single equivalent target query. In the general case however (beyond SQL and <software ContextAttributes="used">XQuery</software>), the target query language may not support joins, unions, sub-queries and/or filtering. To tackle this challenge, our method first enacts the databaseindependent steps of the rewriting process. To generate the abstract query, we rely on and extend the R2RML-based <software ContextAttributes="used">SPARQL</software> rewriting approaches reviewed in section 2, while taking care of avoiding the limitations highlighted. More specifically, we focus on rewriting a <software ContextAttributes="used">SPARQL</software> 1.0 graph pattern, whatever the query form (SELECT, ASK, DESCRIBE, etc.). The translation of a <software ContextAttributes="used">SPARQL</software> graph pattern into an abstract query consists of four steps, sketched in Fig. <ref type="figure" target="#fig_0">1</ref> and described in the next sub-sections. §4.1: A <software ContextAttributes="used">SPARQL</software> 1.0 graph pattern is rewritten into an abstract expression exhibiting operators of the abstract query language. §4.2: We identify candidate xR2RML mappings likely to generate RDF triples that match each triple pattern. §4.3: Each triple pattern is translated into a subquery according to the set of xR2RML mappings identified. A sub-query consists of operators of the abstract query language and atomic abstract queries. §4.4:</p><p>We enforce several optimizations on the resulting abstract query, e.g. self-joins or self-unions elimination. Our pivot abstract query language complies with the grammar depicted in Def. 1.</p><p>It derives from the syntax and semantics of <software ContextAttributes="used">SPARQL</software> <ref type="bibr" target="#b25">[27]</ref>: the language keeps the names of several <software ContextAttributes="used">SPARQL</software> operators (UNION, LIMIT, FILTER) and prefers the SQL terms INNER JOIN ON and LEFT OUTER JOIN ON to refer to join operations more explicitly. A notable difference with <software ContextAttributes="used">SPARQL</software> is that, in the tree representation of a query, the leaves of a <software ContextAttributes="used">SPARQL</software> query are triple patterns. Conversely, the leaves of an abstract query are Atomic Abstract Queries ( §4.3).</p><p>The INNER JOIN and LEFT OUTER JOIN operators stem from the join constraints implied by shared variables. Somehow, the second INNER JOIN in Def. 1, including the "AS child " and "AS parent" notations, is entailed by the join constraints expressed in xR2RML mappings using referencing object maps and properties rr:child and rr:parent. Notation v 1 ,... v n , in the join operators, stands for the set of <software ContextAttributes="used">SPARQL</software> variables on which the join is to be performed. Notation &lt;Ref&gt; stands for any valid xR2RML data element reference, i.e. a column name for a tabular data source, an XPath expression for an XML database, a <software ContextAttributes="used">JSONPath</software> expression for a NoSQL document store such as <software ContextAttributes="used">MongoDB</software> and <software ContextAttributes="used">CouchDB</software>, etc. The first query transformation step is implemented by function trans m depicted in Def. 2. It rewrites a well-designed <software ContextAttributes="used">SPARQL</software> graph pattern <ref type="bibr" target="#b25">[27]</ref> into an abstract query while making no assumption with respect to the target database query capabilities. It extends the algorithms proposed in <ref type="bibr" target="#b9">[10]</ref>, <ref type="bibr" target="#b36">[38]</ref> and <ref type="bibr" target="#b27">[29]</ref>.</p></div>
<div><head>Definition 2. Translation of a SPARQL query into an abstract query under xR2RML mappings (function transm).</head><p>Let m be an xR2RML mapping graph consisting of a set of xR2RML mappings. Let gp be a well-designed <software>SPARQL</software> graph pattern, f be a <software ContextAttributes="used">SPARQL</software> filter and l an integer limit value representing the maximum number of results. We denote by transm(gp, f, l) the translation, under m, of "gp FILTER f " into an abstract query that shall not return more than l results. We denote by transm(gp) the result of transm(gp, true, ∞). Function transm is defined recursively as follows:</p><p>if gp consists of a single triple pattern tp, transm(gp, f, l) = transTPm(tp, spar-qlCond(tp, f ), l) where transTPm translates a single triple pattern into an abstract query ( §4.3) and sparqlCond discriminates <software>SPARQL</software> filter conditions ( §4.1).</p><formula xml:id="formula_0">-if gp is (P LIMIT l'), transm(gp, f, l) = transm(gp, f, min(l, l')) -if gp is (P FILTER f '), transm(gp, f, l) = transm(P, f ∧ f ', ∞) FILTER spar- qlCond(P, f ∧ f ') LIMIT l -if gp is (P1 AND P2), transm(gp, f, l) = transm(P1, f, ∞) INNER JOIN transm(P2, f, ∞) ON var(P1) ∩ var(P2) LIMIT l -if gp is (P1 OPTIONAL P2), transm (gp, f, l) = transm(P1, f, ∞) LEFT OUTER JOIN transm(P2, f, ∞) ON var(P1) ∩ var(P2) LIMIT l -if gp is (P1 UNION P2), transm (gp, f, l) = transm (P1, f, l) UNION transm (P2, f, l) LIMIT l</formula><p>As a simplification, notations "FILTER true" and "LIMIT ∞" may be omitted.</p><p>Example The application of function trans m to the graph pattern gp 1 is as follows:</p><formula xml:id="formula_1">transm ( gp1 ) = transm ( gp1 , true , ∞) = transTPm ( tp1 , true , ∞) INNER INNER INNER JOIN JOIN JOIN transTPm ( tp2 , true , ∞) ON ON ON { var ( tp1 ) ∩ var ( tp2 )} LIMIT ∞ = transTPm ( tp1 ) INNER INNER INNER JOIN JOIN JOIN transTPm ( tp2 ) ON ON ON {? x }</formula><p>Dealing with <software>SPARQL</software> filters. <software ContextAttributes="used">SPARQL</software> rewriting methods reviewed in section 2 generally adopt a bottom-up approach where, typically, a <software ContextAttributes="used">SPARQL</software> FIL-TER translates into an encapsulating query (e.g. a SELECT-WHERE clause in the case of SQL). Thus, filters in the outer query do not contribute to the selectivity of inner-queries that may return large intermediate results. This flaw is commonly worked out in a subsequent SQL query optimization step, or by assuming that the underlying database engine can take care of this optimization.</p><p>In our context though, we cannot assume that the target query can be optimized nor that the database query engine is capable of doing it. We therefore consider <software>SPARQL</software> filters at the earliest stage: function trans m pushes <software ContextAttributes="used">SPARQL</software> filters down into the translation of each inner query in order to return only necessary intermediate results.</p><p>Let us consider a <software ContextAttributes="used">SPARQL</software> filter f as a conjunction of n conditions (n ≥ 1): C1 ∧ ... Cn. Function sparqlCond, formally defined in <ref type="bibr" target="#b20">[22]</ref>, discriminates between these conditions with regards to two criteria: (i) A condition C i is pushed into the translation of triple pattern tp if all variables of C i show up in tp, e.g. a condition involving variables ?x and ?y is pushed into the translation of tp only if tp involves at least ?x and ?y. (ii) A condition C i is part of the abstract FILTER operator if at least one variable of C i is shared by several triple patterns, e.g. if C i contains variable ?x, and variable ?x also shows up in two different triple patterns, then C i is in the condition of the abstract FILTER operator. Note that both criteria are not exclusive: a condition may simultaneously show up in the translation of a triple pattern and in the FILTER abstract operator. Example. <software ContextAttributes="used">SPARQL</software> query Q 2 , depicted in Listing 1.3, contains the graph pattern gp 2 that consists of three triple patterns tp 1 , tp 2 and tp 3 , and a filter consisting of the conjunction of two conditions c 1 and c 2 :</p><p>SELECT SELECT SELECT ? x WHERE WHERE WHERE { ? x foaf : mbox ? mbox . # tp1 ? y foaf : mbox &lt; mailto : john@foo . com &gt;. # tp2 ? x foaf : knows ? y .</p><p># tp3 FILTER FILTER FILTER { contains ( str (? mbox ) , " foo . com ") # c1 &amp;&amp; ? x != ? y } } # c2</p><p>Listing 1.3. <software>SPARQL</software> query Q2</p><p>Let us compute function sparqlCond for each triple pattern:</p><p>-tp 1 has two variables, ?x and ?mbox. No condition involves both variables, but c 1 involves ?mbox and has no other variable, thereby c 1 matches criterion (i) for tp 1 . Condition c 2 involves ?x but it also involves ?y that is not in tp 1 . Hence, c 2 does not match criterion (i) for tp 1 , and sparqlCond(tp1, c1 ∧ c2) = c1.</p><p>-tp 2 has one variable, ?y, and no condition involves only ?y. Hence, no condition can be pushed into the translation of tp 2 , denoted sparqlCond(tp2, c1 ∧ c2) = true.</p><p>-tp 3 has two variables ?x and ?y, and only condition c 2 involves them both. Hence, only c 2 matches criterion (i) for tp 3 and sparqlCond(tp3, c1 ∧ c2) = c2.</p><p>-Lastly, only condition c 2 involves variables shared by several triples patterns: ?x and ?y. Thus, only c 2 matches criterion (ii), which entails the generation of the abstract filter FILTER(c2).</p><p>As a result, gp 2 is rewritten into the following abstract query:</p><formula xml:id="formula_2">transm ( gp2 , c1 ∧ c2 ) = transTPm ( tp1 , c1 ) INNER INNER INNER JOIN JOIN JOIN transTPm ( tp2 , true ) ON ON ON {} INNER INNER INNER JOIN JOIN JOIN transTPm ( tp3 , c2 ) ON ON ON {? x ,? y } FILTER FILTER FILTER ( c2 )</formula><p>Dealing with the LIMIT solution modifier. Similar to the case of <software>SPARQL</software> filters, the common bottom-up approach of SQL rewriting methods consists in rewriting a LIMIT into an encapsulating query. Thus, again, sub-queries may return unnecessary large intermediate results. Therefore, function trans m pushes the LIMIT value down into the translation of each triple pattern using the limit argument l, initialized to ∞. During the parsing of the graph pattern by function trans m , the limit argument is updated according to the graph pattern encountered. Below, we elaborate on some of the situations tackled in Def. 2: -In a graph pattern P LIMIT l', the smallest limit is kept, hence the min(l, l') in trans m (gp, f, min(l, l')).</p><p>-In a graph pattern P FILTER f ', we cannot know in advance how many results will be filtered out by the FILTER clause. Consequently, we have to run the query with no limit and apply the filter afterward. Hence the ∞ argument in trans m (P, f ∧ f ', ∞) FILTER sparqlCond(...) LIMIT l.</p><p>-Similarly, in the case of an inner or left join, we cannot know in advance how many results will be returned. Consequently, the left and right queries alike are run with no limit first, the join is computed, and only then can we limit the number of results. Hence the ∞ argument in the expressions:</p><formula xml:id="formula_3">trans m (P 1 ,f,∞) ... INNER JOIN trans m (P 2 ,f,∞) ... LIMIT l.</formula><p>Dealing with other solution modifiers. For the sake of simplicity, we do not describe in further details the management of <software>SPARQL</software> solution modifiers OFFSET, ORDER BY and DISTINCT. Let us simply mention that they are managed in the very same way as the <software ContextAttributes="used">SPARQL</software> FILTER clause and LIMIT solution modifier, i.e. as additional parameters of the trans m and transTP m functions, and additional operators of the abstract query language.</p></div>
<div><head n="4.2">Binding xR2RML Mappings to Triple Patterns</head><p>An important step in the rewriting process consists in figuring out which of the mappings are good candidates to answer the <software ContextAttributes="used">SPARQL</software> query. More precisely, for each triple pattern tp of the <software ContextAttributes="used">SPARQL</software> graph pattern, we must figure out which mappings can possibly generate triples that match tp. We call this the triple pattern binding <ref type="foot" target="#foot_6">7</ref> , defined in Def. 3:</p><formula xml:id="formula_4">Definition 3. Triple Pattern Binding.</formula><p>Let m be an xR2RML mapping graph consisting of a set of xR2RML mappings, and tp be a triple pattern. A mapping M ∈ m is bound to tp if it is likely to produce triples that match tp. A triple pattern binding is a pair (tp, MSet) where MSet is the set of mappings of m that are bound to tp.</p><p>Function bind m (Def. 4) determines, for a graph pattern gp, the bindings of each triple pattern of gp. It takes into account join constraints implied by shared variables and by cross-references defined in the mapping (xR2RML referencingobject map), and the <software ContextAttributes="used">SPARQL</software> filter constraints whose unsatisfiability can be verified statically. This is achieved by means of two functions: compatible and reduce. These functions were introduced in <ref type="bibr" target="#b36">[38]</ref> but important details were left untold. Especially, the authors did not formally define what the compatibility between a term map and a triple pattern term means, and they did not investigate the compatibility between a term map and a <software ContextAttributes="used">SPARQL</software> filter. In this section we give a detailed insight into these functions. A formal definition is provided in <ref type="bibr" target="#b20">[22]</ref>. Definition 4. Binding xR2RML mappings to triple patterns (bind m ). Let m be a set of xR2RML mappings, gp be a well-designed graph pattern, and f be a <software ContextAttributes="used">SPARQL</software> filter. Let M.sub, M.pred and M.obj respectively denote the subject map, the predicate map and the object map of an xR2RML mapping M. We denote by bind m (gp, f ) the set of triple pattern bindings of "gp FILTER f " under m, and we denote by bind m (gp) the result of bind m (gp, true). Function bind m (gp, f ) is defined recursively as follows:</p><p>if gp consists of a single triple pattern tp, bind m (gp, f ) is the pair (tp, MSet)</p><p>where</p><formula xml:id="formula_5">MSet = {M | M ∈ m ∧ compatible(M.sub, tp.sub, f ) ∧ compati- ble(M.pred, tp.pred, f ) ∧ compatible(M.obj, tp.obj, f )}</formula><p>where compatible verifies the compatibility between a term map, a triple pattern term and a <software>SPARQL</software> filter</p><formula xml:id="formula_6">-if gp is (P1 AND P2), bind m (gp, f ) = reduce(bind m (P1, f ), bind m (P2, f )) ∪ reduce(bind m (P2, f ), bind m (P1, f ))</formula><p>where reduce utilizes dependencies between graph patterns to reduce their bindings</p><formula xml:id="formula_7">-if gp is (P1 OPTIONAL P2), bind m (gp, f ) = bind m (P1, f ) ∪ reduce(bind m (P2, f ), bind m (P1, f )) -if gp is (P1 UNION P2), bind m (gp, f ) = bind m (P1, f ) ∪ bind m (P2, f ) -if gp is (P FILTER f '), bind m (gp, f ) = bind m (P, f ∧ f ')</formula><p>Function compatible checks whether a term map is compatible with (i) a term of a triple pattern and (ii) a <software ContextAttributes="used">SPARQL</software> filter, so as to rule out incompatible associations. When the triple pattern term is constant (literal, IRI or blank node), incompatibilities may occur when its type does not mach the term map type (e.g. when the triple pattern term is a literal whereas the term map produces IRIs). Incompatibilities may also occur for literals when language tags or data types do not match. When the triple pattern term is a variable, incompatibilities may arise from unsatisfiable <software ContextAttributes="used">SPARQL</software> filters. These situations pertain to type constraints expressed using <software ContextAttributes="used">SPARQL</software> functions isIRI, <software ContextAttributes="used">isLiteral</software> or <software ContextAttributes="used">isBlank</software>, as well as language and data type constraints expressed using functions lang, langMatches and datatype. For instance, if variable ?v is associated with a term map that produces literals, the <software ContextAttributes="used">SPARQL</software> filter isIRI(?v) can never be satisfied, which ensures that the association is invalid. We provided a formal definition of function compatible in <ref type="bibr" target="#b21">[23]</ref>.</p><p>Function reduce uses the variables shared by two triple patterns to detect unsatisfiable join constraints, and accordingly to reduce the set of mappings bound to each triple pattern. For instance, let us consider two triple patterns tp 1 and tp 2 that have a shared variable ?v. Mapping M 1 is bound to tp 1 and mapping M 2 is bound to tp 2 . If the term map associated to ?v in M 1 generates literals whereas the term map associated to ?v in M 2 generates IRIs, we say that the term maps are incompatible. Consequently, function reduce rules out M 1 from the bindings of tp 1 and M 2 from the bindings of tp 2 . In other words, reduce(bind m (tp 1 ), bind m (tp 2 )) returns the reduced bindings of tp 1 such that the term maps associated to ?v in the bindings of tp 1 are compatible with the term maps associated to ?v in the bindings of tp 2 .</p><p>Running Example. Let us consider query Q 2 depicted in Listing 1.3. We first compute the triple pattern bindings for tp 1 , tp 2 and tp 3 independently. The constant predicate of tp 1 and tp 2 matches the constant predicate map of mapping &lt;#Mbox&gt;. The subject and object of tp 1 are both variables, and the constant object of tp 2 (&lt;mailto:john@foo.com&gt;) is compatible with the object map of &lt;#Mbox&gt;. Hence, &lt;#Mbox&gt; is bound to both triple patterns:</p><formula xml:id="formula_8">bindm(tp1, c1 ∧ c2) = (tp1, {&lt;#Mbox&gt;}) bindm(tp2, c1 ∧ c2) = (tp2, {&lt;#Mbox&gt;}) Likewise, we can show that &lt;#Knows&gt; is bound to tp 3 : bindm(tp3, c1 ∧ c2) = (tp3, {&lt;#Knows&gt;}).</formula><p>Let us consider the join constraint implied by variable ?y: ? y foaf : mbox &lt; mailto : john@foo . com &gt;. # tp2 ? x foaf : knows ? y .</p><p># tp3</p><p>?y is the subject in tp 2 that is bound to &lt;#Mbox&gt;, ?y is thereby associated to &lt;#Mbox&gt;'s subject map. ?y is also the object in tp 3 that is bound to &lt;#Knows&gt;, ?y is thereby associated to &lt;#Knows&gt;'s object map. Therefore, the expression reduce(bindm(tp2, c1 ∧ c2), bindm(tp3, c1 ∧ c2))</p><p>checks whether the subject map of &lt;#Mbox&gt; is compatible with the object map of &lt;#Knows&gt;. But since the object map of &lt;#Knows&gt; is a referencing object map whose parent is &lt;#Mbox&gt;, this amounts to check whether the subject map of &lt;#Mbox&gt; is compatible with itself, which is obvious. Consequently, the join constraint implied by variable ?y does not rule out any binding. Similarly, we can show that the join constraint implied by variable ?x, shared by tp 1 and tp 3 , does not rule out any binding. Lastly, the set of triple pattern bindings for the graph pattern of query Q 2 is as follows:</p><p>bindm(tp1 AND tp2 AND tp3, c1 ∧ c2) = (tp1,{&lt;#Mbox&gt;}), (tp2,{&lt;#Mbox&gt;}), (tp3,{&lt;#Knows&gt;})</p></div>
<div><head n="4.3">Translation of a SPARQL Triple Pattern</head><p>The last step of the rewriting towards the abstract query language consists in the translation of each triple pattern into an abstract query, under the set of xR2RML mappings bound to that triple pattern by function bind m . This is achieved by function transTP m defined in Def. 5, that may have to deal with various situations. Let m be an xR2RML mapping graph consisting of a set of xR2RML mappings, gp be a well-designed graph pattern, and tp a triple pattern of gp. Let l be the maximum number of query results, and f be a <software>SPARQL</software> filter expression. Let getBoundM m (gp, tp, f ) be the function that, given gp, tp and f, returns the set of mappings of m that are bound to tp in bind m (gp, f ). We denote by transTP m (tp, f, l) the translation, under getBoundM m (gp, tp, f ), of tp into an abstract query whose results can be translated into at most l RDF triples matching "tp FILTER f ". The resulting abstract query, denoted &lt;ResultQuery&gt; in the grammar below, is a union of per-mapping subqueries, where a subquery is either an Atomic Abstract Query or the inner join of two Atomic Abstract Queries. As a simplification, arguments f and l may be omitted when their values are "true" and ∞ respectively. Let us now give an insight into how transTP m deals with these situations. (1) The most simple situation is encountered when a simple triple pattern tp is bound with a single xR2RML mapping M . If M has a regular object map (not a referencing object map denoting a cross-reference), then tp translates into an atomic abstract query. We will define the concept of atomic abstract query further on in this section. At this point, let us just notice that it is an abstract query obtained by matching the terms of a triple pattern with their respective term maps in a mapping.</p><p>(2) If the mapping M denotes a cross-reference by means of a referencing object map, .i.e. it refers to another mapping for the generation of object terms, then the result of transTP m is the INNER JOIN of two atomic abstract queries, denoted:</p><formula xml:id="formula_9">&lt; AtomicQuery1 &gt; AS AS AS child INNER INNER INNER JOIN JOIN JOIN &lt; AtomicQuery2 &gt; AS AS AS parent ON ON ON child / childRef = parent / parentRef</formula><p>where childRef and parentRef denote the values of properties rr:child and rr:parent respectively.</p><p>(3) We have seen, in the definition of bind m , that several mappings may be bound to a single triple pattern tp, each one may produce a subset of the RDF triples that match tp. In such a situation, transTP m translates tp into a union of per-mapping atomic abstract queries.</p><p>Interestingly enough, we notice that INNER JOINs may be implied either by shared <software>SPARQL</software> variables (Def. 2) or cross-references denoted in the mappings (situation (2) described above). Similarly, UNIONs may arise either from the <software ContextAttributes="used">SPARQL</software> UNION operator (Def. 2) or the binding of several mappings to the same triple pattern (situation (3) described above).</p><p>Due to size constraints, we do not go through the full algorithm of transTP m in this paper, however the interested reader is referred to <ref type="bibr" target="#b20">[22]</ref> for a comprehensive description. Atomic Abstract Query. An atomic abstract query consists of four parts, denoted by {From, Project, Where, Limit}. We now describe these components and the way they are computed by function transTP m .</p><p>-From. The From part provides the concrete query that the abstract query relies on. It contains the logical source of an xR2RML mapping, that consists of the xrr:query or rr:tableName properties, an optional iterator (property rml:iterator) and the optional xrr:uniqueRef property. With the example of query Q 2 (Listing 1.3), the From part for tp 1 simply consists of the logical source of &lt;#Mbox&gt;: db.people.find({'emails':{$ne: null}}).</p><p>-Project. Traditionally, the projection part of a database query restricts the set of attributes that must be returned in the query response. In relational algebra, this is denoted by the projection operator π: π a1,...an (R) denotes the tuple obtained when the attributes of tuple R are restricted to the set {a 1 , ...a n }. Similarly, the Project part of an atomic abstract query is a set of xR2RML references. For each variable in the triple pattern, the xR2RML references in the term map matched with that variable are projected. In our running example, the subject and object of tp 1 are ?x and ?mbox1. They are matched with the subject and object maps of mapping &lt;#Mbox&gt;. Thus, the corresponding xR2RML references within these subject map and object map must be projected. Hence the Project part for tp 1 : {$.id AS ?x, $.emails.* AS ?mbox1}. Furthermore, the child and parent joined references of a referencing object map must be projected in order to accommodate databases that do not support joins. In the relational database case, these projections would be useless since the database can compute the join internally. But the abstract query must accommodate any target database, hence the systematic projection of joined references.</p><p>-Where. The Where part is a set of conditions about xR2RML references. They are produced by matching each term of a triple pattern tp with its corresponding term map in mapping M : the subject of tp is matched with M 's subject map, the predicate with M 's predicate map and the object with M 's object map. Additional conditions are entailed from the <software ContextAttributes="used">SPARQL</software> filter f. In <ref type="bibr" target="#b20">[22]</ref>, we show that three types of condition may be created: (i) a <software ContextAttributes="used">SPARQL</software> variable in the triple pattern is turned into a not-null condition on the xR2RML reference corresponding to that variable in the term map, denoted by isNotNull(&lt;xR2RML reference&gt;); (ii) A constant term in the triple pattern (IRI or literal) is turned into an equality condition on the xR2RML reference corresponding to that term in the term map, denoted by equals(&lt;xR2RML reference&gt;, value); (iii) A <software ContextAttributes="used">SPARQL</software> filter condition about a <software ContextAttributes="used">SPARQL</software> variable is turned into a filter condition, denoted by <software ContextAttributes="used">sparqlFilter</software>(&lt;xR2RML reference&gt;, f ). Running Example. In the case of query Q 2 (Listing 1.3), triple pattern tp 2 is matched with mapping &lt;#Mbox&gt;. It has the variable ?y in the subject position, which entails an isNotNull condition. It also has a constant term in the object position, which entails an equals condition. Finally, the Where part for tp 2 contains two conditions: isNotNull($.id) and equals($.emails.*, "john@foo.com").</p><p>When we put all the pieces together, we can rewrite the graph pattern gp 2 of <software>SPARQL</software> query Q 2 into the abstract query depicted in Listing 1.4.</p></div>
<div><head n="4.4">Abstract Query Optimization</head><p>At this point, the method we have exposed translates a <software>SPARQL</software> graph pattern into an effective abstract query, i.e. that preserves the semantics of the <software ContextAttributes="used">SPARQL</software> query. Yet, shortcomings such as unnecessary complexity or redundancy may lead to the generation of inefficient queries, and consequently yield poor performances. Although we may postpone the query optimization to the translation into a concrete query language, it is beneficial to figure out which optimizations can be done at the abstract query level first, and leave only database-specific optimizations to the subsequent stage.</p><p><software ContextAttributes="used">SPARQL</software>-to-SQL methods proposed various SQL query optimizations such as <ref type="bibr" target="#b37">[39,</ref><ref type="bibr" target="#b30">32,</ref><ref type="bibr" target="#b13">14]</ref>. In this section, we review some of these techniques, referring to the Listing 1.5. Optimization of transm(gp2) (Listing 1.4) by self-join elimination terminology defined in <ref type="bibr" target="#b37">[39]</ref>. We show how these optimizations can be adapted to fit in the context of our abstract query language. In particular, we show that our translation method implements some of these optimizations by construction.</p><p>In addition, we propose a new optimization, the Filter Propagation, that, to our knowledge, was not proposed in any <software>SPARQL</software>-to-SQL rewriting method.</p><p>Filter Optimization. In a naive approach, strings generated by R2RML templates are dealt with using an SQL comparison of the resulting strings rather than the database values used in the template. Typically, when the translation of an R2RML template relies on the SQL string concatenation, a <software>SPARQL</software> query can ben rewritten into something like this: In our approach, equality conditions apply to xR2RML references rather than on the template-generated values, hence the Filter Optimization is enforced by construction.</p><p>Filter pushing. As mentioned earlier, the translation of a <software>SPARQL</software> filter into an encapsulating SELECT WHERE clause lowers the selectivity of inner queries, and the query evaluation process may have to deal with unnecessarily large intermediate results. In our approach, Filter pushing is enforced by construction by the sparqlCond function: relevant <software ContextAttributes="used">SPARQL</software> conditions are pushed down, as much as possible, in the translation of individual triple patterns.</p><p>Self-Join Elimination. A self-join may occur when several mappings share the same logical source. This can lead to several triple patterns being translated into atomic abstract queries with the same From part. The Self-Join Elimination consists in merging the criteria of several atomic queries into a single equivalent query. In Listing 1.4, the atomic query in transTPm(tp2, true) and the second atomic query in transTPm(tp3, c2) have the same From part and project the same <software ContextAttributes="used">JSONPath</software> expression as variable ?y. Using joins commutativity, those two queries can be merged into a single one depicted in the third atomic abstract query in Listing 1.5 <ref type="foot" target="#foot_7">8</ref> .</p><p>Self-Union Elimination. A UNION operator can be created either due to the <software>SPARQL</software> UNION operator or during the translation of a triple pattern to which several mappings are bound (in function transT P m ). Analogously to the Self-Join Elimination, a union of several atomic abstract queries sharing the same logical source can be merged into a single query when they have the same From part.</p><p>Constant Projection. The Constant Projection optimization detects cases where the only projected variables in the <software ContextAttributes="used">SPARQL</software> query are matched with constant values in the bound mappings. In the relational database context, it has been referred to as the Projection Pushing optimization <ref type="bibr" target="#b37">[39]</ref>. Let us consider the example query below:</p><formula xml:id="formula_10">SELECT DISTINCT ? p WHERE {? s ? p ? o }.</formula><p>In a naive approach, all mappings are bound to the triple pattern ?s ?p ?o. Hence, the resulting abstract query is a union of the atomic queries derived from all the possible mappings. In other words, this query will materialize the whole database before it can provide an answer. Very frequently, xR2RML predicate maps are constant-valued: the predicate is not computed from a database value, on the contrary it is defined statically in the mapping. This is typically the case in our running example that has only constant predicate maps (values of property rr:predicate: foaf:knows and foaf:mbox (Listing 1.1). In such cases, given that the <software>SPARQL</software> query retrieves only DISTINCT values of the predicate variable ?p, no query needs to be run against the database at all: it is sufficient to collect the distinct constant values that variable ?p can be matched with. More generally, this optimization checks if the variables projected in the <software ContextAttributes="used">SPARQL</software> query are matched with constant term maps. If this is verified, the <software ContextAttributes="used">SPARQL</software> query is rewritten such that the values of the projected variables be provided as an inline solution sequence using the <software ContextAttributes="used">SPARQL</software> 1.1 VALUES clause. Using the mapping graph of our running example, we would rewrite the query in this way:</p><p>SELECT DISTINCT ? p WHERE { VALUES ? p ( foaf : mbox foaf : knows )}</p><p>Filter Propagation. We identified another type of optimization that was not implemented in the <software>SPARQL</software>-to-SQL context. This optimization applies to the inner join or left outer join of two atomic queries, and seeks to narrow down one of the joined queries by propagating filter conditions from the other query. In an inner join, if the two queries have shared variables, then equals and isNotNull AND ( &lt; exp1 &gt;, &lt; exp2 &gt;, ...)</p><p>→ $and and and :[ &lt; exp1 &gt;,&lt; exp2 &gt; ,...] OR ( &lt; exp1 &gt;, &lt; exp2 &gt;, ...) → $or or or :[ &lt; exp1 &gt;,&lt; exp2 &gt; ,...] WHERE ( &lt; JavaScript exp &gt;)</p><p>→ $where where where : ' &lt; JavaScript exp &gt; ' ELEMMATCH ( &lt; exp1 &gt;,&lt; exp2 &gt;...) → $elemMatch elemMatch elemMatch :{ &lt; exp1 &gt;,&lt; exp2 &gt;...} FIELD ( p1 ) ... FIELD ( pn )</p><p>→ " p1 . ... . pn ": SLICE ( &lt; exp &gt; , &lt; number &gt;)</p><p>→ &lt;exp &gt;:{$slice slice slice : &lt; number &gt;} COND ( equals ( v ))</p><p>→ $eq eq eq : v COND ( isNotNull ) → $exists exists exists :true true true , $ne ne ne :null null null EXISTS ( &lt; exp &gt;)</p><p>→ &lt;exp &gt;:{$exists exists exists :true true true } NOT_EXISTS ( &lt; exp &gt;)</p><p>→ &lt;exp &gt;:{$exists exists exists :false false false } COMPARE ( &lt; exp &gt; , &lt;op &gt; , &lt;v &gt;)</p><p>→ &lt;exp &gt;:{ &lt; op &gt;: &lt;v &gt;} NOT_SUPPORTED → ∅ UNION ( &lt; query1 &gt; , &lt; query2 &gt;...) Same semantics as OR , although OR is processed by the NoSQL engine whereas UNION is processed by the query processing engine Listing 1.6. Abstract representation of a <software>MongoDB</software> query and translation to a concrete query string. &lt;op&gt; stands for one of the <software ContextAttributes="used">MongoDB</software> comparison operators: $eq, $ne, $lt, $lte, $gt, $gte, $size and $regex.</p><p>conditions of one query on those shared variables can be propagated to the other query. In a left join, propagation can happen only from right to left query since null values must still be allowed in the right query.</p></div>
<div><head n="5">Application to the MongoDB NoSQL Database</head><p>In the previous section, we have exhibited an abstract query model and a method to translate a <software>SPARQL</software> graph pattern into an optimized abstract query, relying on the xR2RML mapping of a target database to RDF. We now want to illustrate the effort it takes to translate from the abstract query language towards a concrete query language with a somewhat different expressiveness.</p><p>To this end, we consider the <software>MongoDB</software> NoSQL database. Its JSON-based data model and its query language differ greatly from SQL-based systems for which many rewriting works have been proposed. Hence, we believe that it should provide an interesting illustration of our method. Besides, <software ContextAttributes="used">MongoDB</software> has become a popular NoSQL actor in recent years. It is provided as a service by major cloud service providers and tends to become common within the scientific community, suggesting that it is increasingly adopted as a commonplace database.</p><p>In this section, we first glance at the <software>MongoDB</software> query language, and we describe an abstract representation of <software ContextAttributes="used">MongoDB</software> queries (section 5.1). Then, we show that the translation from the abstract query language towards Mon-goDB is made challenging by the expressiveness discrepancy between the two languages (section 5.2) and we describe a complete method to achieve this. Finally, we summarize the whole <software ContextAttributes="used">SPARQL</software>-to-<software ContextAttributes="used">MongoDB</software> process orchestration, from the <software ContextAttributes="used">SPARQL</software> graph pattern translation until the generation of the RDF triples that match this graph pattern (section 5.3).</p></div>
<div><head n="5.1">The MongoDB Query Language</head><p><software>MongoDB</software> comes with a rich set of APIs to allow applications to query a database in an imperative way. In addition, the <software ContextAttributes="used">MongoDB</software> interactive interface defines a JSON-based declarative query language consisting of two query methods. The find method retrieves documents matching a set of conditions and returns a cursor to the matching documents. Optional modifiers amend the query to impose limits and sort orders. Alternatively, the aggregate method allows for the definition of processing pipelines: each document of a collection passes through each stage of a pipeline thereby creating a new collection. This allows for a richer expressiveness but comes with a higher resource consumption that entails less predictable performances. Thus, as a first approach, this work considers the find query method, hereafter called the <software ContextAttributes="used">MongoDB</software> query language.</p><p>The <software>MongoDB</software> find query method takes two arguments formatted as JSON documents. The first argument describes conditions about the documents to search for. Query operators are denoted by a heading '$' character. The optional projection argument specifies the fields of the matching documents to return. For instance, the query below matches all documents with a field "emails" and returns only the "id" field of each matching document. db . people . find ({" emails ": {$exists : true }} , {" id ": true })</p><p>The <software ContextAttributes="used">MongoDB</software> documentation provides a rich description of the find query that however lacks precision as to the formal semantics of some operators. Attempts were made to clarify this semantics while underlining some limitations and ambiguities: Botoeva et al. <ref type="bibr" target="#b6">[7]</ref> mainly focus on the aggregate query and ignore some of the operators we use in our translation, such as $where, $elemM atch, $regex and $size. On the other hand, Husson <ref type="bibr" target="#b18">[20]</ref> describes the find query, yet some restrictions on the operator $where are not formalized.</p><p>Hence, in <ref type="bibr" target="#b20">[22]</ref> we specified the grammar of the subset of the query language that we consider. We also defined an abstract representation of <software ContextAttributes="used">MongoDB</software> queries, that allows for handy manipulation during the query construction and optimization phases. Listing 1.6 details the constructs of this representation and their equivalent concrete query string, when relevant. The NOT SUPPORTED clause helps keep track of any location, within the query, where a condition cannot translate into an equivalent <software ContextAttributes="used">MongoDB</software> query element. It shall be used in the last rewriting and optimization phase.</p><p>Let us consider the following abstract representation of a <software>MongoDB</software> query (or "abstract <software ContextAttributes="used">MongoDB</software> query" for short):</p><p>AND ( COMPARE ( FIELD ( p ) FIELD (0) , $eq , 10) , FIELD ( q ) ELEMMATCH ( COND ( equals (" val ")) )</p><p>It matches all documents where "p" is an array field whose first element (at index 0) is 10, and "q" is an array field in which at least one element has value "val". Its concrete representation is:</p><p>$and : [ {" p .0": {$eq :10}} , {" q ": {$elemMatch : {$eq :" val "}}} ] To achieve a translation from the abstract query language towards the Mon-goDB query language, we must figure out which components of an abstract query have an equivalent <software>MongoDB</software> rewriting, and, conversely, which components shall be computed by the query-processing engine. Below, we analyze the possible situations.</p><p>-Inner and left outer joins. <software>MongoDB</software> find queries do not support joins. Consequently, there does not exist any <software ContextAttributes="used">MongoDB</software> query that would be equivalent to the INNER JOIN and LEFT OUTER JOIN operators. These operators need to be processed by the query-processing engine by joining the RDF triples generated for both sub-queries.</p><p>-UNION. The rewriting of the UNION operator depends on the graph patterns to which it applies. Let us consider the following <software>SPARQL</software> graph pattern, where tp n is any triple pattern: { tp1. tp2. } UNION { tp3. tp4. } Each member of the union translates into an INNER JOIN. Since joins cannot be processed within <software ContextAttributes="used">MongoDB</software>, the outer UNION operator cannot be processed within <software ContextAttributes="used">Mon-goDB</software> either. The issue occurs likewise as soon as one of the members is either an INNER JOIN or LEFT OUTER JOIN. Under some circumstances, a UNION operator may be translated into the <software ContextAttributes="used">MongoDB</software> $or operator. Yet, the Mon-goDB language definition imposes specific restrictions as to how operators can be nested. Consequently, in a first approach, we always shift the processing of the UNION abstract operator to the query-processing engine. Further works could attempt to characterize more specifically the situations where a UNION can be processed within <software ContextAttributes="used">MongoDB</software>.</p><p>-FILTER and LIMIT. In section 4, we showed that the FILTER and LIMIT <software>SPARQL</software> solution modifiers are pushed down into relevant atomic abstract queries (as <software ContextAttributes="used">sparqlFilter</software> conditions of the Where part or as the Limit part of an atomic query, respectively). When FILTER and LIMIT <software ContextAttributes="used">SPARQL</software> clauses cannot be pushed down in atomic queries, they end up as abstract operators with the same names, FILTER and LIMIT. The latter apply to abstract sub-queries made of UNION, INNER JOIN and/or LEFT OUTER JOIN operators. Hence, given that UNION and INNER/LEFT OUTER JOIN operators are not processed within <software ContextAttributes="used">MongoDB</software>, the FILTER and LIMIT operators cannot be processed within <software ContextAttributes="used">MongoDB</software> either.</p><p>Ultimately, it occurs that only the atomic abstract queries can be processed within <software ContextAttributes="used">MongoDB</software>, while other abstract operators shall be taken care of by the query-processing engine. More generally, the translation from the abstract query language towards <software ContextAttributes="used">MongoDB</software> consists of two steps depicted in Fig. <ref type="figure" target="#fig_4">2</ref>. In step 1 (detailed in section 5.2), the translation of each atomic abstract query towards <software ContextAttributes="used">MongoDB</software> amounts to translate projections of <software ContextAttributes="used">JSONPath</software> expressions (Project part) into <software ContextAttributes="used">MongoDB</software> projection arguments, and conditions on <software ContextAttributes="used">JSONPath</software> expressions (Where part) into equivalent abstract <software ContextAttributes="used">MongoDB</software> queries. Several shortcomings may appear at this stage, such as unnecessary complexity or untranslatable conditions. Thus, in step 2 (detailed in section 5.2) each abstract <software ContextAttributes="used">MongoDB</software> query is optimized and rewritten into valid, concrete <software ContextAttributes="used">MongoDB</software> queries.</p><p>In the current status of this work, we do not consider the translation of <software>SPARQL</software> filters (conditions <software ContextAttributes="used">sparqlFilter</software> ) for the sake of simplicity. <software ContextAttributes="used">SPARQL</software> 1.0 filters come with a broad set of conditional expressions including logical comparisons, literal manipulation expressions (string, numerical, boolean), XPath constructor functions, casting functions for additional data types of the RDF data model, and <software ContextAttributes="used">SPARQL</software> built-in functions (lang, langmatches, datatype, bound, sameTerm, isIRI, isURI, <software ContextAttributes="used">isBlank</software>, <software ContextAttributes="used">isLiteral</software>, regex ). Handling these expressions within the translation towards <software ContextAttributes="used">MongoDB</software> would yield a significant additional complexity without changing the translation principles though. Yet, an implementation should handle them for the sake of performance and completeness.</p><p>Translation of Projections and Conditions Two functions, named proj and trans, handle the translation of the Project and Where parts of an atomic abstract query respectively. Below, we illustrate their principles on an example. The interested reader shall find their formal definition in <ref type="bibr" target="#b20">[22]</ref>.</p><p>In Listing 1.5, the third atomic abstract query is as follows (the <software>sparqlFilter</software> condition has been omitted):</p><p>{From From From :</p><p>{" db . people . find ({ ' emails ':{$ne : null }})"} , Project Project Project : {$. emails .* , $. id AS AS AS ? y } , Where Where Where : {isNotNull isNotNull isNotNull ($. emails .*) , isNotNull isNotNull isNotNull ($. id ) , equals equals equals ($. emails .* ," john@foo . com ") }} Function proj converts the <software>JSONPath</software> expressions of the From part into a list of paths to be projected. In the example, expressions $.emails.* and $.id translate into their <software ContextAttributes="used">MongoDB</software> projection counterparts: "emails":true and "id":true. Later on, this abstract representation will be translated into an equivalent concrete query:</p><p>"emails": {$elemMatch: {$exists:true, $ne:null}}.</p><p>Similarly, condition isNotNull($.id) will be translated into: "id": {$exists:true, $ne:null}, and condition equals($.emails.*,"john@foo.com") will be translated into: "emails": {$elemMatch: {$eq:'john@foo.com'}}.</p><p>These conditions are used to augment the query of the From part, initially provided by the mapping's logical source. When we put all the pieces together, the atomic abstract query is translated into the concrete <software>MongoDB</software> query below, where all conditions are operands of an $and operator: db . people . find ( # Query argument { $and : [ {" emails ": {$ne : null }} , # from the From part {" emails ": {$elemMatch : {$exists : true ,$ne : null }}} , {" id ": {$exists : true ,$ne : null }} , {" emails ": {$elemMatch : {$eq : ' john@foo . com '}}} ] } , # Projection argument { " emails ": true , " id ": true } )</p><p>Optimization and Rewriting into Concrete <software>MongoDB</software> Queries In the previous section, function trans produces abstract <software ContextAttributes="used">MongoDB</software> queries that can be rewritten into concrete queries straightaway. Yet, this rewriting may be hindered by three potential issues:</p><p>(i) During the translation process, nested OR or AND clauses may be produced, as well as sibling WHERE clauses. Such unnecessary complexity may yield an underperforming query. (ii) It may not be possible to translate some <software>JSONPath</software> expressions into equivalent <software ContextAttributes="used">MongoDB</software> operators. This occurs with specific <software ContextAttributes="used">JSONPath</software> array slice notations, or in <software ContextAttributes="used">JSONPath</software> expressions assuming that the root document is an array field and not a document field (which is forbidden in <software ContextAttributes="used">MongoDB</software>). In such cases, a NOT SUPPORTED clause tracks the location of this failed translation. (iii) The <software ContextAttributes="used">MongoDB</software> $where operator passes a JavaScript expression or function to the query system. It provides greater flexibility than other operators, however it is valid only in the top-level query document: it cannot be used inside a nested query such as the $elemM atch operator. During the translation process though, function trans may nest a WHERE clause beneath other clauses, yielding an invalid query.</p><p>To take care of these issues, in <ref type="bibr" target="#b22">[24]</ref> we described a post-translation function rewrite, depicted by step 2 in Fig. <ref type="figure" target="#fig_4">2</ref>. First, a set of rewriting rules address issue (i) by flattening nested OR, nested AND and nested UNION clauses, and merging sibling WHERE clauses.</p><p>To address issue (ii), these rules remove NOT SUPPORTED clauses while ensuring that the resulting query returns a superset of the valid answers: all the correct answers are returned, along with possibly incorrect answers. In turn, the transformation of this superset into RDF triples shall produce all the triples that match the <software>SPARQL</software> query, in addition to triples that may not match the query. The latter are ruled out during the query evaluation process by running a late <software ContextAttributes="used">SPARQL</software> query evaluation.</p><p>A second set of rewriting rules address issue (iii) by "pulling up" WHERE clauses at the top-level query. This is notably achieved by replacing OR clauses with UNION clauses that have the same semantics but are processed differently. An OR clause represents the $or operator and is processed by <software>MongoDB</software>. Conversely, the UNION clause has no equivalent <software ContextAttributes="used">MongoDB</software> operator: it is processed outside of <software ContextAttributes="used">MongoDB</software> by the query processing engine. As a consequence, an abstract <software ContextAttributes="used">MongoDB</software> query may be rewritten into a union of valid, concrete <software ContextAttributes="used">MongoDB</software> queries.</p><p>Finally, Theorem 1 captures two key properties of the rewriting process. It has been proved in <ref type="bibr" target="#b20">[22]</ref>.</p><p>Theorem 1. Let C be an equality or not-null condition on a <software>JSONPath</software> expression. Let Q = (Q 1 ... Q n ) be the abstract <software ContextAttributes="used">MongoDB</software> query produced by trans(C).</p><formula xml:id="formula_11">Rewritability: It is always possible to rewrite Q into a query Q = union(Q 1 , ..., Q m ) such that ∀i ∈ [1, m] Q i is</formula><p>a valid <software>MongoDB</software> query, i.e. Q i does not contain any not supported clause, and a where clause only shows at the top-level of Q i . Completeness: Executing Q against the database retrieves all the documents matching condition C. If Q contains at least one not supported clause, then Q may retrieve additional documents that do not match condition C.</p><p>A corollary of Theorem 1 is that, using the xR2RML mapping of a <software>MongoDB</software> database to RDF, we can rewrite any <software ContextAttributes="used">SPARQL</software> 1.0 graph pattern into an abstract query whose atomic abstract queries are valid <software ContextAttributes="used">MongoDB</software> queries or unions of valid <software ContextAttributes="used">MongoDB</software> queries.</p></div>
<div><head n="5.3">Complete SPARQL-to-MongoDB Query Translation and Evaluation</head><p>Fig. <ref type="figure" target="#fig_5">3</ref> summarizes the whole <software ContextAttributes="used">SPARQL</software>-to-<software ContextAttributes="used">MongoDB</software> process orchestration, from the graph pattern translation to the subsequent <software ContextAttributes="used">MongoDB</software> queries evaluation and the production of RDF triples.</p><p>In step 1, function trans m (section 4.1) translates a <software>SPARQL</software> graph pattern into an abstract query under a set of xR2RML mappings denoted by m. It leverages function transTP m (section 4.3) to a triple pattern tp into an abstract query under the set of mappings bound to tp by function bind m (section 4.2). The resulting abstract query contains atomic abstract queries of the form {From, Project, Where, Limit}, combined with abstract operators INNER JOIN, LEFT OUTER JOIN, UNION, FILTER, LIMIT. The Project part of an atomic abstract query is a set of xR2RML references (i.e. <software ContextAttributes="used">JSONPath</software> expressions for <software ContextAttributes="used">MongoDB</software>) that must be projected. The Where part consists of isNotNull, equals and <software ContextAttributes="used">sparqlFilter</software> conditions on <software ContextAttributes="used">JSONPath</software> expressions. In step 2, function proj translates each projected <software ContextAttributes="used">JSONPath</software> expression into a <software ContextAttributes="used">MongoDB</software> projection argument, function trans translates each isNotNull and equals condition into an abstract representation of a <software ContextAttributes="used">MongoDB</software> query (section (section 5.2), and function rewrite (section 5.2) optimizes and rewrites this abstract representation into a concrete <software ContextAttributes="used">MongoDB</software> query or a union of concrete <software ContextAttributes="used">MongoDB</software> queries.</p><p>Two steps remain, that we have not described yet. In step 3, the concrete queries are executed against the database. In step 4, the result JSON documents are translated into RDF triples according to the xR2RML mappings, then the query processing engine evaluates the abstract query by computing the INNER/LEFT OUTER JOIN, UNION, FILTER and LIMIT operators. Finally, in case one atomic abstract query contained a NOT SUPPORTED clause, a late <software>SPARQL</software> evaluation is performed to rule out the RDF triples that do not match the query (as explained in section 5.2).</p></div>
<div><head n="6">Experimentation and Evaluation</head><p>To date, to our knowledge, the method proposed in this paper and the MongoDBenabled <software ContextAttributes="used">ontop</software> software <ref type="bibr" target="#b7">[8]</ref> are the only approaches meant to query arbitrary <software ContextAttributes="used">MongoDB</software> documents with <software ContextAttributes="used">SPARQL</software>. So far though, this <software ContextAttributes="used">ontop</software> version is not available for test, which hinders possible performance comparison. Additionally, no benchmark similar to the Berlin <software ContextAttributes="used">SPARQL</software> Benchmark for relational databases <ref type="bibr" target="#b5">[6]</ref> exists so far for querying NoSQL databases with <software ContextAttributes="used">SPARQL</software>.</p><p>Therefore, in this section, we describe a real-world use case that we used to build a test database, and we report experimental results with respect to the effectiveness and performance of our approach.</p></div>
<div><head n="6.1">Prototype Implementation</head><p><software>Morph</software>-xR2RML is the prototype implementation we developped to evaluate the effectiveness of the xR2RML mapping language and the <software ContextAttributes="used">SPARQL</software>-to-<software ContextAttributes="used">MongoDB</software> method proposed in this paper. It comes with connectors for the <software ContextAttributes="used">MySQL</software> and <software ContextAttributes="used">Postgres</software> relational databases, and for the <software ContextAttributes="used">MongoDB</software> document store. It can process an xR2RML mapping graph in either the data materialization or the query rewriting modes.</p><p><software ContextAttributes="used">Morph</software>-xR2RML is available on GitHub<ref type="foot" target="#foot_8">9</ref> under the <software ContextAttributes="used">Apache</software> 2.0 license, it is written in the <software ContextAttributes="used">Scala</software> programming language. It is based on and extends the <software ContextAttributes="used">Morph-</software>RDB <ref type="bibr" target="#b27">[29]</ref> R2RML implementation. We performed a substantial code refactoring in order to isolate any RDB-related code into a dedicated software module. As a result, our prototype is extensible by design: supporting a new type of database amounts to create a new software module that implements a given set of interfaces, thereby encapsulating and isolating any database-specific concerns from the rest of the project code. Following this approach, we developed a connector for the <software ContextAttributes="used">MongoDB</software> document store, to translate <software ContextAttributes="used">MongoDB</software> JSON documents into RDF and rewrite <software ContextAttributes="used">SPARQL</software> queries into <software ContextAttributes="used">MongoDB</software> queries.</p><p><software ContextAttributes="used">Morph</software>-xR2RML relies on several open-source Java APIs, the most salient ones are listed here. Jena<ref type="foot" target="#foot_9">10</ref> is a well known Java framework consisting of several APIs meant to build Semantic Web Data applications. We use the Jena RDF API that helps handle RDF triples and graphs. <software ContextAttributes="used">MongoDB</software> comes with a native Java API <ref type="foot" target="#foot_10">11</ref> that allows for imperative style querying only. The Jongo API <ref type="foot" target="#foot_11">12</ref> builds on top of it to translate a declarative <software ContextAttributes="used">MongoDB</software> query (a find query in our case) into imperative code. Lastly, Jayway JsonPath<ref type="foot" target="#foot_12">13</ref> is a Java implementation of the <software ContextAttributes="used">JSONPath</software> language.</p><p>The query rewriting experimentation we report in this section was conducted on a server equipped with a 3.0 GHz CPU with two physical cores, and 8 GB RAM. The <software>MongoDB</software> engine and the <software ContextAttributes="used">Morph-xR2</software>RML Java virtual machine alike were running on the same server. The Java virtual machine was allowed a maximum of 4 GB memory.</p></div>
<div><head n="6.2">Experimentation Database</head><p><software ContextAttributes="used">TAXREF</software> <ref type="bibr" target="#b14">[15]</ref> is the French national taxonomic register for fauna, flora and fungus, maintained and distributed by the French National Museum of Natural History (MNHN). It is a manually curated register of all the species inventoried in metropolitan France and overseas territories, organized as a hierarchy of over 485.000 scientific names (in version 9) that mark a national and international consensus. As an example, the listing below shows a JSON excerpt from <software ContextAttributes="used">TAXREF</software>'s Web service 14 , describing the common dolphin species (Delphinus delphis). Annotation "habitat":1 states that it lives in a marine habitat, annotation "rang":"ES" states that the taxon belongs to the "species" taxonomical rank. Annotation "fr":"P" characterizes one of its biogeographical statuses: it states that Delphinus delphis is present in mainland France.</p></div>
<div><head>{</head><p>" codeTaxon ":"60878" , " codeReference ":"60878" , " codeParent ":"191591" , " rang ":" ES " , " libelleNom ":" Delphinus delphis " , " libelleAuteur ":" Linnaeus , 1758" , " no mV e rn ac ul a ir e ":" Dauphin commun " , " n o m V e r n a c u l a i r e A n g l a ":" Common Dolphin " , " url ":" http :// inpn . mnhn . fr / espece / cd_nom /60878" , " habitat ":"1" , " fr ":" P " , (...) }</p><p>We are involved in an on-going collaboration with <software ContextAttributes="used">TAXREF</software> experts from MNHN, aimed to publish <software ContextAttributes="used">TAXREF</software> on the Web of Data as a SKOS thesaurus <ref type="bibr" target="#b8">[9]</ref>. In this context, we imported into a <software ContextAttributes="used">MongoDB</software> database the JSON representation of <software ContextAttributes="used">TAXREF</software> v9.0, wherein each of the 485.189 JSON documents accounts for one scientific name, may it be a taxon reference of synonymous name. Listing 1.7 exemplifies the SKOS modeling with taxon Delphinus delphis and its synonym Delphinus vulgaris. The taxon is represented as a SKOS concept (line 10). The skos:broader property models the relationships towards the parent taxon in the classification (line 13), i.e. genus Delphinus in this example. The taxon reference and synonymous names are represented as SKOS-XL labels (lines 23-33), referred to with properties skosxl:prefLabel and skosxl:altLabel respectively (lines <ref type="bibr" target="#b13">[14]</ref><ref type="bibr" target="#b14">[15]</ref>. The taxonomical rank, habitat and bio-geographical status are properties of the SKOS concept (lines 16-21), while the authorities and vernacular names are properties of SKOS labels (lines <ref type="bibr">25-27 and 31-33)</ref>.</p><p>Leveraging this existing database, we set up an experimentation of the SPARQLto-<software>MongoDB</software> query rewriting. In the next section, we shortly describe the xR2RML mappings designed for the experimentation. </p></div>
<div><head n="6.3">Experimentation xR2RML Mapping Graph</head><p>The xR2RML mapping graph designed to generate the <software ContextAttributes="used">TAXREF</software>-based SKOS thesaurus is provided in the xR2RML GitHub repository <ref type="foot" target="#foot_13">15</ref> . It consists of 90 mappings, a somewhat high number that spawns from the distance between the internal structure of <software ContextAttributes="used">TAXREF</software> JSON documents and the targeted SKOS modeling. We illustrate this distance with an example. Habitats are coded in <software ContextAttributes="used">TAXREF</software> with integer values, e.g. value '1' represents the marine habitat, '2' represents fresh water, etc. Translating the marine habitat into URI http://inpn.mnhn.fr/taxref/habitat#1 would be straightforward using a template that would append the value read from the database to http://inpn.mnhn.fr/taxref/habitat#. A single mapping would be sufficient to generate the triples related to all types of habitat. However, our modeling targets the generation of more meaningful URIs that cannot be generated by a template, e.g. http://inpn.mnhn.fr/taxref/habitat#Marine; instead, we must write a mapping whose query filters only taxa with habitat '1': Such a mapping must be written for each of the 8 habitat values. A similar situation is observed for the 48 taxonomical ranks and 30 bio-geographical statuses, that all comme with dedicated mappings.</p></div>
<div><head n="6.4">Experimentation Results</head><p>In section 5, we showed that atomic abstract queries can be translated into equivalent <software ContextAttributes="used">MongoDB</software> queries, but other operators of the abstract query language (INNER JOIN, LEFT OUTER JOIN, UNION) must be computed by the     query along with the corresponding triple pattern and semantics, the number of results it retrieves from the database, and the average time it took to process the query (the query processing spans the <software ContextAttributes="used">SPARQL</software> query rewriting, the query evaluation against <software ContextAttributes="used">MongoDB</software> and the RDF triples generation). For each query, 10 measures were performed: we report the average value and standard deviation. The last column gives the average processing time per query result, that converges towards 0.48ms. Figure <ref type="figure" target="#fig_6">4</ref> depicts the average query processing time (fourth column of Table <ref type="table" target="#tab_7">1</ref>) as a function of the number of results (blue line). Since <software ContextAttributes="used">Morph</software>-xR2RML relies on the Jongo API to process a <software ContextAttributes="used">MongoDB</software> query, we also measured the time needed by Jongo to parse the query, pass it on to <software ContextAttributes="used">MongoDB</software> and retrieve the results from <software ContextAttributes="used">MongoDB</software>. Red dots represent the measures when simply querying <software ContextAttributes="used">MongoDB</software> with Jongo, while blue dots represent the measures of the whole process executed by  The distance between the two lines gives an estimation of the overhead imposed by <software ContextAttributes="used">Morph</software>-xR2RML to rewrite the query and generate the triples. Figure <ref type="figure" target="#fig_2">5</ref> depicts this overhead. The confidence for Q0 and Q1, and to some extend for Q2, is very low as attested by the large error bars. Indeed, materializing a few triples is barely measurable (&lt;1ms for Q0, and in the order of 30ms for Q1), such that the measure is very sensitive to environment variations. Conversely, the confidence for Q3 to Q6 is quite high. Q3, Q4 and Q5 show a similar overhead of approximately 19%. Although we could expect the overhead percentage to be constant with higher numbers of results, it reaches 32% for Q6. A detailed analysis shows that the difference lies in the time needed to generate the RDF triples. Compared to Q5, the number of results in Q6 increases by 77% while the materialization time increases by 120%. The variable term in Q3, Q4 and Q5 is a blank node whereas it is a URI in Q6. A tentative explanation is that <software ContextAttributes="used">Morph</software>-xR2RML may be faster when producing blank nodes than when producing URIs, unless this difference lies in the Jena API on which <software ContextAttributes="used">Morph</software>-xR2RML relies to handle RDF triples. Further works should consider using more substantial databases to assess this difference with more precision. In any case, the processing performed by <software ContextAttributes="used">Morph</software>-xR2RML adds no more than a 30% overhead to the time needed to query the database and retrieve the results.</p><p>Yet, waiting 10 seconds to get 18000 results (query Q3) can be considered surprisingly long compared to native RDF triple stores. To investigate this question, we compared the time it takes to run a query (i) through the Jongo API (the case of <software ContextAttributes="used">Morph</software>-xR2RML) and (ii) directly through <software ContextAttributes="used">MongoDB</software>'s own Java API. The results are presented in Figure <ref type="figure" target="#fig_8">6</ref>. Surprisingly, they attest that, while Jongo is efficient for few results (in the order of 100), it entails a significant overhead for larger results: 116% overhead for query Q6 (i.e. using Jongo more than doubles the query time). Jongo's authors argue that the library is almost as fast as querying <software ContextAttributes="used">MongoDB</software> directly, under the assumption that the marshalling/unmarshalling of JSON documents is left to Jongo. <software ContextAttributes="used">Morph</software>-xR2RML retrieves JSON documents from Jongo as Java strings in order to evaluate them with <software ContextAttributes="used">JSONPath</software> expressions. It is likely that converting documents to strings and evaluating them with a third-party <software ContextAttributes="used">JSONPath</software> library significantly impairs performances. Further investigation should be conducted to figure this out more precisely, keeping in mind that solving this issue could approximately save a factor 2 during the processing of large result sets.</p></div>
<div><head>Impact of Query Optimizations</head><p>In this section, we measure the completion time of two example <software ContextAttributes="used">SPARQL</software> queries involving joins. Notably, we measure the gain obtained by performing optimizations at the level of the abstract query, namely the self-join elimination and the filter propagation. Additional example queries are reported in <ref type="bibr" target="#b20">[22]</ref> along with measures of the impact of the self-union elimination and the constant projection optimizations.</p><p>Join Query, Self-Join Elimination. <software>SPARQL</software> query Q 7 , depicted below, looks for taxa (variable ?t) that are present in the overseas collectivity of Saint-Pierre-et-Miquelon (http://sws.geonames.org/3424932/). The graph pattern matches 12,708 triples that yield a <software ContextAttributes="used">SPARQL</software> result set of 4,236 solutions. In a first step, Q 8 translates into the inner join of three atomic abstract queries, portrayed in Listing 1.9. The first atomic query retrieves 1 document from the database, while the second and third queries retrieve 257,965 documents each. Executed naively, the inner-most join computes the join of 257,965 triples with another 257,965 triples generated from the same database documents. With a smarter join ordering, the triple produced by the first atomic query is joined with the 257,965 triples of the second one to produce two triples (taxon 60585 has two synonyms), that, in turn, are joined with the 257,965 triples of the third query. Yet, two joins of 257,965 triples with one then two triples have to be performed. Some tests show that the time needed to complete this query is in the order of 4 minutes.</p><p>The Filter Propagation optimization leverages some situations where, within the join of two sub-queries, a condition on a variable shared by both subqueries can be propagated from one sub-query to the other. In the example, the two joins are performed on variable ?t. The first atomic query projects ?t as expression $.codeTaxon and has condition equals($.codeTaxon, 60585).</p><p>In the second and third queries, variable ?t is projected as $.codeReference. Therefore, the join condition can only be satisfied if expression $.codeReference returns the value 60585. In other words, we can propagate the condition on $.codeTaxon, equals($.codeTaxon, 60585) to the second and third queries as a condition on $.codeReference: equals($.codeReference, 60585). The optimized abstract query is pictured in Listing 1.10. The second and third queries now only yield two RDF triples. Finally, the execution of this query lasts 565ms in average, that is a gain factor in the order of 400.</p></div>
<div><head n="7">Discussion and Perspectives</head><p>In the case of <software>MongoDB</software>, the processing of joins is shifted to the query processing engine, and can ensue poor performances when joined sub-queries are not selective enough. Furthermore, real-world <software ContextAttributes="used">SPARQL</software> queries often contain substantial graph patterns with multiple joined triple patterns. It is therefore critical to be able to process joins efficiently. Thus, beyond the optimizations that we implemented at the abstract query level, query-plan optimization techniques shall be investigated to help answer the following questions:</p><p>-Can we rewrite a <software ContextAttributes="used">SPARQL</software> graph pattern in a way that facilitates the production of an efficient abstract query? -How to inject intermediate results into a subsequent query, as performed in the bind join optimization <ref type="bibr" target="#b15">[17]</ref>? -How to reorder joins considering the number of results of sub-queries, in a way similar to methods proposed by distributed query engines? <ref type="bibr" target="#b31">[33,</ref><ref type="bibr">16,</ref><ref type="bibr" target="#b19">21]</ref> -Can we perform lazy evaluation of joins by progressively materializing triples on each side of the join until the expected number of results is reached? This would typically resemble the method employed in the non-blocking evaluation of queries in the context of Triple Pattern Fragments <ref type="bibr" target="#b38">[40]</ref>.</p><p>Additionally, several leads could be investigated to overcome the limitations of the translation from the abstract query language to <software>MongoDB</software>.</p><p>-Our method generates the RDF triples resulting from each atomic queries and subsequently performs joins (INNER JOIN, LEFT OUTER JOIN). In some cases though, joins may rule out many of the triples that were just materialized. Hence, it should be studied when joins can be evaluated on the database documents. This would typically rule out unnecessary documents earlier in the process, thus saving the useless generation of RDF triples. -Our implementation of xR2RML for <software>MongoDB</software> relies on <software ContextAttributes="used">JSONPath</software> to extract data elements from <software ContextAttributes="used">MongoDB</software> results. In turn, the <software ContextAttributes="used">SPARQL</software> rewriting process must handle conditions on <software ContextAttributes="used">JSONPath</software> expressions. Consequently, we have to cope with the expressiveness discrepancy between <software ContextAttributes="used">SPARQL</software> and <software ContextAttributes="used">MongoDB</software>, and between <software ContextAttributes="used">JSONPath</software> and <software ContextAttributes="used">MongoDB</software> alike. While we must cope with the earlier (our goal is specifically to access heterogeneous databases with <software ContextAttributes="used">SPARQL</software>), the latter is somewhat more an implementation choice.</p><p>Hence, an investigation should figure out whether considering a restricted subset of <software>JSONPath</software> may produce a simpler solution while still enabling to address most mapping situations. -Beyond this, another promising lead is to determine what type of <software ContextAttributes="used">MongoDB</software> query should be used preferably: find or aggregate queries. We address this question in section 7, as part of a broader discussion about the similarities and discrepancies between our approach and that of <software ContextAttributes="used">ontop</software>'s authors.</p><p>Comparison with the <software ContextAttributes="used">MongoDB</software>-enabled <software ContextAttributes="used">ontop</software>. To the best of our knowledge, the only other approach meant to access arbitrary <software ContextAttributes="used">MongoDB</software> documents with <software ContextAttributes="used">SPARQL</software> has been proposed by the authors of <software ContextAttributes="used">ontop</software>, Botoeva et al. <ref type="bibr" target="#b7">[8]</ref>. This approach starts with deriving a set of type constraints (literal, object, array) from the mapping assertions, called the <software ContextAttributes="used">MongoDB</software> database schema. Then, a relational view over the database is defined with respect to that schema, notably by flattening array fields. A <software ContextAttributes="used">SPARQL</software> query is rewritten into relational algebra (RA) query, and RA expressions over the relational view are translated into <software ContextAttributes="used">MongoDB</software> aggregate queries. Similarly, we translate a <software ContextAttributes="used">SPARQL</software> query into an abstract representation (that is not relational algebra) under xR2RML mappings. To deal with the tree structure of JSON documents we use <software ContextAttributes="used">JSONPath</software> expressions. On the one hand, this avoids the definition of a relational view over the database, but this comes with additional complexity in the translation process, as translating conditions on <software ContextAttributes="used">JSONPath</software> expressions is not straightforward. On the other hand, the advantage of our method is that the query evaluation relies on existing database indexes, whereas in the case of Botoeva et al., the flattening step prevents from exploiting these indexes.</p><p>The mappings are quite similar in both approaches although xR2RML is more flexible: (i) class names (in triples ?x rdf:type A) and predicates can be built from database values whereas they are constant in the approach proposed by <ref type="bibr">Botoeva et al., and (ii)</ref> xR2RML allows to turn an array field into an RDF collection or container, while the latter approach only supports the multipletriples strategy.</p><p>Finally, the main differences pertain to the type of target query. Botoeva et al. produce <software ContextAttributes="used">MongoDB</software> aggregate queries, with the major advantage of ensuring a semantics-preserving <software ContextAttributes="used">SPARQL</software>-to-<software ContextAttributes="used">MongoDB</software> query translation, thus delegating the whole processing to <software ContextAttributes="used">MongoDB</software> and making the query translation simpler. In practice however, aggregate pipelines may perform poorly. To optimize them, an option suggested by the authors is to decompose the pipeline into smaller queries and have the query-processing engine perform the remaining steps. Our approach works the other way around: it produces less-expressive <software ContextAttributes="used">MongoDB</software> find queries, leaving much more work to the query-processing engine. Nevertheless, having the job done outside of the database engine allows to leverage extensive works about smart query optimizations <ref type="bibr" target="#b15">[17,</ref><ref type="bibr" target="#b31">33,</ref><ref type="bibr">16,</ref><ref type="bibr" target="#b19">21]</ref>, whereas this is not possible when the database performs an aggregate query in a black-box manner.</p><p>Typically though, in situations involving large joins, aggregate queries perform faster than find queries as they can leverage database indexes. In the future, it would be interesting to assess whether we could characterize mappings with respect to the type of query that shall perform best: single vs. multiple separate queries, find vs. aggregate, and figure out a balance between the two approaches.</p><p>Furthermore, unlike <software>ontop</software>, xR2RML allows for rich <software ContextAttributes="created">JSONPath</software> expressions to evaluate a JSON document and generate RDF terms. In this matter, further studies should figure out how to translate such expressions into aggregate queries.</p></div>
<div><head n="8">Conclusion</head><p>The method proposed in this paper aims at fostering the development of <software>SPARQL</software> interfaces to heterogeneous databases, as we believe this is a key to push the Web of Data forward. In particular, we think that this should help to bridge the gap between the Semantic Web and the NoSQL family of databases.</p><p>To achieve this goal without defining yet another <software>SPARQL</software> translation method for each and every database, we proposed a two-phase approach. First, we defined an abstract query language deriving from the syntax and semantics of <software ContextAttributes="created">SPARQL</software>. Utilizing the xR2RML mapping language and leveraging R2RMLbased <software ContextAttributes="created">SPARQL</software>-to-SQL works, we introduced a generic method to translate a <software ContextAttributes="created">SPARQL</software> 1.0 graph pattern into an abstract query. We showed how optimizations can be beneficially enforced at this abstract level, saving subsequent work at the level of a target database language. In a second phase, the abstract query is translated into the query language of a target database. To demonstrate the effectiveness of our approach, we applied it to the <software ContextAttributes="created">MongoDB</software> NoSQL document store. We devised a method to translate an abstract query into <software ContextAttributes="created">MongoDB</software> find queries, and we showed that this translation is challenged by the expressiveness discrepancy between <software ContextAttributes="created">SPARQL</software> and the <software ContextAttributes="created">MongoDB</software> query language.</p><p>Finally, we conducted an experimentation based on the real-world use case of a taxonomical reference stored in a <software>MongoDB</software> database. Utilizing a mapping of this database to a SKOS thesaurus, we first measured performances in the case of single <software ContextAttributes="used">SPARQL</software> triple patterns that translate into single <software ContextAttributes="used">MongoDB</software> queries. Then, we measured the performances of richer <software ContextAttributes="used">SPARQL</software> queries and we demonstrated the effectiveness of some of the optimizations performed at the level of the abstract query language. We underlined some limitations of the translation from the abstract query language to <software ContextAttributes="used">MongoDB</software>, that can impair performances. In section 7 we discuss several improvement leads that could be investigated.</p><p>From a broader perspective, we have shown that translating a <software>SPARQL</software> query into efficient concrete queries can be challenging when it comes to address data sources such as NoSQL databases. These systems are generally optimized for fast storage and retrieval of vast collections of documents. They favor scalability, high throughput and availability over consistency and query language expressiveness. As a consequence, they often come with denormalized data models where redundancy is common, and barely support joins. This is the case of other document stores such as <software ContextAttributes="used">CouchDB</software> that are designed in a way very similar to <software ContextAttributes="used">MongoDB</software>. Column family stores usually allow for a richer data model and provide a more expressive query language. But although their columnar data model makes them easily compared with relational systems, they often suffer the same limitations as document stores with respect to the limited support of joins. Key-value stores are designed for fast retrieval of data e.g. accessed by key. They are typically used to implement cache systems, for which a very simple query language (consisting essentially of put and retrieve by key operations) covers most use cases.</p><p>Consequently, it is likely that the hurdles we encountered with <software>MongoDB</software> will be encountered with other NoSQL databases alike. The situation may not be so much different for the last category of NoSQL databases, namely graph stores. By nature, their data models are closer to RDF. Still, whereas RDF predicates can be used with literal values as well as resources, graph databases such as Neo4J 16 manage literals (called node attributes) and other graph nodes in a very different way. As a result, querying a graph database with <software ContextAttributes="used">SPARQL</software> may be more challenging that it seems, and we believe that our two-phase approach may be relevant in this context too.</p></div><figure xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Translation of a SPARQL 1.0 graph pattern into an optimized abstract query</figDesc><graphic coords="9,134.77,115.84,345.82,91.62" type="bitmap" /></figure>
<figure xml:id="fig_1"><head>Definition 1 .</head><label>1</label><figDesc>Grammar of the Abstract Pivot Query Language &lt; AbstractQuery &gt; ::= &lt; AtomicQuery &gt; | &lt; Query &gt; | &lt; Query &gt; FILTER FILTER FILTER &lt; SPARQL filter &gt; | &lt; Query &gt; LIMIT LIMIT LIMIT &lt; integer &gt; &lt; Query &gt; ::= &lt; AbstractQuery &gt; INNER INNER INNER JOIN JOIN JOIN &lt; AbstractQuery &gt; ON ON ON { v1 ,... vn } | &lt; AbstractQuery &gt; AS AS AS child INNER INNER INNER JOIN JOIN JOIN &lt; AbstractQuery &gt; AS AS AS parent ON ON ON child / &lt; Ref &gt; = parent / &lt; Ref &gt; | &lt; AbstractQuery &gt; LEFT LEFT LEFT OUTER OUTER OUTER JOIN JOIN JOIN &lt; AbstractQuery &gt; ON ON ON { v1 ,... vn }| &lt; AbstractQuery &gt; UNION UNION UNION &lt; AbstractQuery &gt; &lt; AtomicQuery &gt; ::= { From , Project , Where , Limit }</figDesc></figure>
<figure xml:id="fig_2"><head>Definition 5 .</head><label>5</label><figDesc>Translation of a SPARQL Triple Pattern into Atomic Abstract Queries (function transTP m ).</figDesc></figure>
<figure xml:id="fig_3"><head>&lt;</head><label /><figDesc>ResultQuery &gt; ::= &lt; SubQuery &gt; (UNION UNION UNION &lt; SubQuery &gt;)* &lt; SubQuery &gt; ::= &lt; AtomicQuery &gt; | &lt; AtomicQuery &gt; AS AS AS child INNER INNER INNER JOIN JOIN JOIN &lt; AtomicQuery &gt; AS AS AS parent ON ON ON child / &lt; Ref &gt;= parent / &lt; Ref &gt;</figDesc></figure>
<figure xml:id="fig_4"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Translation of atomic abstract queries into concrete MongoDB queries</figDesc></figure>
<figure xml:id="fig_5"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Complete SPARQL-to-MongoDB Query Translation and Evaluation</figDesc><graphic coords="24,134.77,115.83,345.83,152.28" type="bitmap" /></figure>
<figure xml:id="fig_6"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Average query processing time as a function of the number of results. Dotted lines represent the linear regression lines of both series.</figDesc><graphic coords="31,134.77,115.83,345.83,191.31" type="bitmap" /></figure>
<figure xml:id="fig_7"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. Processing time overhead imposed by Morph-xR2RML, compared to a direct database query. The overhead comprises rewriting the SPARQL query and translating the MongoDB results into RDF triples</figDesc><graphic coords="31,134.77,358.62,345.83,197.27" type="bitmap" /></figure>
<figure xml:id="fig_8"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. Overhead of querying MongoDB through the Jongo API compared to a direct query through MongoDB's Java API</figDesc><graphic coords="32,134.77,115.83,345.83,193.44" type="bitmap" /></figure>
<figure type="table" xml:id="tab_0"><head /><label /><figDesc>6 expression in case of NoSQL document stores like MongoDB or CouchDB. xR2RML references are used with property xrr:reference whose value is a single xR2RML reference, and property rr:template whose value is a template string which may contain several references. In Listing 1.1, both subject maps use a template to build IRI terms by concatenating http://example.org/member/ with the value of the "id" JSON field.</figDesc><table /><note><p><p>&lt;# Mbox &gt; xrr xrr xrr :logicalSource logicalSource logicalSource [ xrr xrr xrr :query query query " db . people . find ({ ' emails ':{ $ne : null }})" ]; rr rr rr :subjectMap subjectMap subjectMap [ rr rr rr :template template template " http :// example . org / member /{ $ . id }" ]; rr rr rr :p r e d i c a t e O b j e c t M a p p r e d i c a t e O b j e c t M a p p r e d i c a t e O b j e c t M a p [ rr rr rr :predicate predicate predicate foaf : mbox ; rr rr rr :objectMap objectMap objectMap [ rr rr rr :template template template " mailto :{ $ . emails .*}"; rr rr rr :termType termType termType rr rr rr :IRI IRI IRI ] ]. &lt;# Knows &gt; xrr xrr xrr :logicalSource logicalSource logicalSource [ xrr xrr xrr :query query query " db . people . find ({ ' contacts ':{ $size : { $gte :1}}})" ]; rr rr rr :subjectMap subjectMap subjectMap [ rr rr rr :template template template " http :// example . org / member /{ $ . id }" ];</p>rr rr rr :p r e d i c a t e O b j e c t M a p p r e d i c a t e O b j e c t M a p p r e d i c a t e O b j e c t M a p [ rr rr rr :predicate predicate predicate foaf : knows ; rr rr rr :objectMap objectMap objectMap [ rr rr rr :p a r e n t Tr i p l e s M a p p a r e n t T r i p l e s M a p p a r e n t T r i p l e s M a p &lt;# Mbox &gt;; rr rr rr :joinCondition joinCondition joinCondition [ rr rr rr :child child child " $ . contacts .*"; rr rr rr :parent parent parent " $ . emails .*" ] ] ]. Listing 1.1. xR2RML example mapping graph</p></note></figure>
<figure type="table" xml:id="tab_1"><head /><label /><figDesc>. Let us give a first simple illustration. SPARQL query Q 1 contains a graph pattern gp 1 that consists of two triple patterns, tp 1 and tp 2 :</figDesc><table><row><cell>Q1 : SELECT SELECT SELECT ? x WHERE WHERE WHERE {</cell></row><row><cell>? x foaf : mbox ? mbox . # tp1</cell></row><row><cell>? x foaf : knows ? y . } # tp2</cell></row></table></figure>
<figure type="table" xml:id="tab_2"><head /><label /><figDesc>Project Project Project : {$. emails .* , $. id AS AS AS ? y } , Where Where Where : {isNotNull isNotNull isNotNull ($. emails .*) , isNotNull isNotNull isNotNull ($. id ) , sparqlFilter sparqlFilter sparqlFilter (? x != ? y )}} AS AS AS parent parent parent ON ON ON child child child /$. contacts .* = parent parent parent /$. emails .* Listing 1.4. Rewriting of the graph pattern gp2 of query Q2 (Listing 1.3) into an abstract query</figDesc><table><row><cell>trans trans transm ( gp2 ) =</cell><cell /></row><row><cell cols="2">transTP transTP transTPm ( tp1 , c1 ) INNER INNER INNER JOIN JOIN JOIN</cell></row><row><cell cols="2">transTP transTP transTPm ( tp2 , true ) ON ON ON {} INNER INNER INNER JOIN JOIN JOIN</cell></row><row><cell cols="2">transTP transTP transTPm ( tp3 , c2 ) ON ON ON {? x ,? y }</cell></row><row><cell cols="2">FILTER FILTER FILTER (? x != ? y )</cell></row><row><cell cols="2">transTP transTP transTPm ( tp1 , c1 ) =</cell></row><row><cell>{ From From From :</cell><cell>{" db . people . find ({ ' emails ': {$ne : null }})"} ,</cell></row><row><cell cols="2">Project Project Project : {$. id AS AS AS ?x , $. emails .* AS AS AS ? mbox1 } ,</cell></row><row><cell>Where Where Where :</cell><cell>{isNotNull isNotNull isNotNull ($. id ) , isNotNull isNotNull isNotNull ($. emails .*) ,</cell></row><row><cell /><cell>sparqlFilter sparqlFilter sparqlFilter ( contains ( str (? mbox1 ) ," foo . com "))}}</cell></row><row><cell cols="2">transTP transTP transTPm ( tp2 , true ) =</cell></row><row><cell>{ From From From :</cell><cell>{" db . people . find ({ ' emails ': {$ne : null }})"} ,</cell></row><row><cell cols="2">Project Project Project : {$. id AS AS AS ? y } ,</cell></row><row><cell>Where Where Where :</cell><cell>{isNotNull isNotNull isNotNull ($. id ) , equals equals equals ($. emails .* ," john@foo . com ")}}</cell></row><row><cell cols="2">transTP transTP transTPm ( tp3 , c2 ) =</cell></row><row><cell>{ From From From :</cell><cell>{" db . people . find ({ ' contacts ':{$size : {$gte :1}}})"} ,</cell></row><row><cell cols="2">Project Project Project : {$. id AS AS AS ?x , $. contacts .*} ,</cell></row><row><cell>Where Where Where :</cell><cell>{isNotNull isNotNull isNotNull ($. id ) , isNotNull isNotNull isNotNull ($. contacts .*) ,</cell></row><row><cell /><cell>sparqlFilter sparqlFilter sparqlFilter (? x != ? y )}} AS AS AS child child child</cell></row><row><cell>INNER INNER INNER JOIN JOIN JOIN</cell><cell /></row><row><cell>{ From From From :</cell><cell /></row></table><note><p>{" db . people . find ({ ' emails ':{$ne : null }})" } ,</p></note></figure>
<figure type="table" xml:id="tab_7"><head>Table 1 .</head><label>1</label><figDesc>Execution time of SPARQL queries with one triple pattern</figDesc><table><row><cell /><cell /><cell /><cell>Exec.</cell><cell>Exec.</cell></row><row><cell>Q. Id</cell><cell>Query semantics and SPARQL triple pattern</cell><cell>No. results</cell><cell>time ± std dev.</cell><cell>time per result</cell></row><row><cell /><cell /><cell /><cell>(ms)</cell><cell>(ms)</cell></row><row><cell>Q0</cell><cell>Find the reference name for taxon 60587 ?t skosxl:prefLabel &lt;http://inpn.mnhn.fr/taxref/label/60587&gt;</cell><cell>1</cell><cell>451 ± 36</cell><cell>451.00</cell></row><row><cell>Q1</cell><cell>Get synonyms of taxon 95372 &lt;http://inpn.mnhn.fr/taxref/9.0/taxon/95372&gt; skosxl:altLabel ?a</cell><cell>164</cell><cell>522 ± 14</cell><cell>3.18</cell></row><row><cell /><cell>Get all bio-geographical statuses in</cell><cell /><cell /><cell /></row><row><cell>Q2</cell><cell>St Pierre et Miquelon ?bgs dct:spatial</cell><cell>4835</cell><cell>4.056 ± 65</cell><cell>0.84</cell></row><row><cell /><cell>&lt;http://sws.geonames.org/3424932/&gt;</cell><cell /><cell /><cell /></row><row><cell>Q3</cell><cell>Get all bio-geographical statuses in Guadeloupe ?bgs dct:spatial &lt;http://sws.geonames.org/3579143/&gt;</cell><cell>17956</cell><cell>9665 ± 45</cell><cell>0.54</cell></row><row><cell /><cell>Get all bio-geographical statuses in</cell><cell /><cell /><cell /></row><row><cell>Q4</cell><cell>New Caledonia ?bgs dct:spatial</cell><cell>35703</cell><cell>17289 ± 78</cell><cell>0.48</cell></row><row><cell /><cell>&lt;http://sws.geonames.org/2139685/&gt;</cell><cell /><cell /><cell /></row><row><cell>Q5</cell><cell>Get bio-geographical statuses in mainland France ?bgs dct:spatial &lt;http://sws.geonames.org/3017382/&gt;</cell><cell>128018</cell><cell>61645 ± 671</cell><cell>0.48</cell></row><row><cell>Q6</cell><cell>Get all taxa (that are SKOS concepts) ?c a skos:Concept</cell><cell>227224</cell><cell>108508 ± 459</cell><cell>0.48</cell></row><row><cell cols="5">query-processing engine, i.e. Morph-xR2RML. Therefore, a first series of tests</cell></row><row><cell cols="5">aimed to assess the performance of Morph-xR2RML with a SPARQL query con-</cell></row><row><cell cols="5">sisting of a single triple pattern, bound to exactly one mapping and producing</cell></row><row><cell cols="5">a single MongoDB query (section 6.4). In a second series of tests, we measured</cell></row><row><cell cols="5">the completion time of SPARQL queries involving joins and/or unions, and we</cell></row><row><cell cols="5">compared them to the time needed for a single triple pattern. Furthermore,</cell></row><row><cell cols="5">we measured the gain obtained by performing optimizations at the level of the</cell></row><row><cell cols="2">abstract query (section 6.4).</cell><cell /><cell /><cell /></row><row><cell cols="5">Processing a Single Triple Pattern To measure the performance of Morph-</cell></row><row><cell cols="5">xR2RML in the case of a single triple pattern translated into a single MongoDB</cell></row></table></figure>
<figure type="table" xml:id="tab_8"><head>Table 1</head><label>1</label><figDesc /><table><row><cell>lists each</cell></row></table></figure>
<figure type="table" xml:id="tab_9"><head /><label /><figDesc>Executed separately, the first triple pattern would be bound to 15 mappings (one for each geographical location) and would yield 311,489 RDF triples; the second one would be bound to one mapping and would yield 4,835 triples, and the third one would be bound to 15 mapping and would yield 260,631 documents. Executed as such, query Q 7 completes in almost 10 minutes (600s).Listing 1.9. Rewriting of the graph pattern of query Q8. used to generate RDF triples matching the three triple patterns. This optimized query completes in 2,966ms in average, i.e. a 65% gain compared to the query with reduced bindings.Filter Propagation. SPARQL query Q 8 , pictured herebelow, retrieves the taxon (variable ?t) whose preferred label has a certain URI, alongside two of its alternate labels (variables ?a and ?b).</figDesc><table><row><cell cols="3">[{ Binding Binding Binding (? t skosxl : prefLabel http :// inpn . mnhn . fr / taxref / label /60585</cell></row><row><cell /><cell cols="2">-&gt; T M _ T a x o n _ P r e f L a b e l )</cell></row><row><cell>From From From</cell><cell cols="2">: db . taxrefv9 . find ( {</cell></row><row><cell /><cell /><cell>$where : ' this . codeTaxon == this . codeReference ' } )</cell></row><row><cell cols="3">Project Project Project : $. codeTaxon AS AS AS ? t</cell></row><row><cell cols="3">Where Where Where : isNotNull isNotNull isNotNull ($. codeTaxon ) , equals equals equals ($. codeTaxon , 60585) }</cell></row><row><cell cols="2">] INNER INNER INNER JOIN JOIN JOIN [</cell></row><row><cell cols="3">[{ Binding Binding Binding (? t skosxl : altLabel ? a -&gt; T M _ T a x o n _ A l t L a b e l )</cell></row><row><cell /><cell>From From From</cell><cell>: db . taxrefv9 . find ( {</cell></row><row><cell /><cell /><cell>$where : ' this . codeTaxon != this . codeReference ' } )</cell></row><row><cell /><cell cols="2">Project Project Project : $. codeReference AS AS AS ?t , $. codeTaxon AS AS AS ? a</cell></row><row><cell /><cell cols="2">Where Where Where : isNotNull isNotNull isNotNull ($. codeReference ) , isNotNull isNotNull isNotNull ($. codeTaxon ) }</cell></row><row><cell cols="3">] INNER INNER INNER JOIN JOIN JOIN [</cell></row><row><cell cols="3">{ Binding Binding Binding (? t skosxl : altLabel ? b -&gt; T M _ T a x o n _ A l t L a b e l )</cell></row><row><cell /><cell>From From From</cell><cell>: db . taxrefv9 . find ( {</cell></row><row><cell /><cell /><cell>$where : ' this . codeTaxon != this . codeReference ' } )</cell></row><row><cell /><cell cols="2">Project Project Project : $. codeReference AS AS AS ?t , $. codeTaxon AS AS AS ? b</cell></row><row><cell /><cell cols="2">Where Where Where : isNotNull isNotNull isNotNull ($. codeReference ) , isNotNull isNotNull isNotNull ($. codeTaxon ) }</cell></row><row><cell cols="2">] ON ON ON ? t</cell></row><row><cell>] ON ON ON ? t</cell><cell /></row><row><cell cols="3">SELECT SELECT SELECT * WHERE WHERE WHERE {</cell></row><row><cell cols="3">? t skosxl : prefLabel</cell></row><row><cell cols="3">&lt; http :// inpn . mnhn . fr / taxref / label /60585 &gt; .</cell></row><row><cell cols="3">? t skosxl : altLabel ? a .</cell></row><row><cell cols="3">? t skosxl : altLabel ? b .</cell></row><row><cell cols="3">FILTER FILTER FILTER (? a != ? b )</cell></row><row><cell>}</cell><cell /></row><row><cell cols="3">SELECT SELECT SELECT * WHERE WHERE WHERE {</cell></row><row><cell cols="3">? t taxrefprop : b ioGeoSt atusIn ? bgs .</cell><cell># tp1</cell></row><row><cell cols="3">? bgs dct : spatial</cell></row><row><cell cols="3">&lt; http :// sws . geonames . org /3424932/ &gt; .</cell><cell># tp2</cell></row><row><cell cols="3">? bgs dwc : o c c u r r e n c e S t a t u s taxrefbgs : P . # tp3</cell></row><row><cell>}</cell><cell /></row></table></figure>
<figure type="table" xml:id="tab_10"><head /><label /><figDesc>Listing 1.10. Rewriting of the graph pattern of query Q8 after enforcing the filter propagation optimization.</figDesc><table><row><cell cols="3">[{ Binding Binding Binding (? t skosxl : prefLabel http :// inpn . mnhn . fr / taxref / label /60585</cell></row><row><cell /><cell cols="2">-&gt; T M _ T a x o n _ P r e f L a b e l )</cell></row><row><cell>From From From</cell><cell cols="2">: db . taxrefv9 . find ( {</cell></row><row><cell /><cell /><cell>$where : ' this . codeTaxon == this . codeReference ' } )</cell></row><row><cell cols="3">Project Project Project : $. codeTaxon AS AS AS ? t</cell></row><row><cell cols="3">Where Where Where : isNotNull isNotNull isNotNull ($. codeTaxon ) , equals equals equals ($. codeTaxon , 60585) }</cell></row><row><cell cols="2">] INNER INNER INNER JOIN JOIN JOIN [</cell></row><row><cell cols="3">[{ Binding Binding Binding (? t skosxl : altLabel ? a -&gt; T M _ T a x o n _ A l t L a b e l )</cell></row><row><cell /><cell>From From From</cell><cell>: db . taxrefv9 . find ( {</cell></row><row><cell /><cell /><cell>$where : ' this . codeTaxon != this . codeReference ' } )</cell></row><row><cell /><cell cols="2">Project Project Project : $. codeReference AS AS AS ?t , $. codeTaxon AS AS AS ? a</cell></row><row><cell /><cell cols="2">Where Where Where : isNotNull isNotNull isNotNull ($. codeTaxon ) , equals equals equals ($. codeReference , 60585) }</cell></row><row><cell cols="3">] INNER INNER INNER JOIN JOIN JOIN [</cell></row><row><cell cols="3">{ Binding Binding Binding (? t skosxl : altLabel ? b -&gt; T M _ T a x o n _ A l t L a b e l )</cell></row><row><cell /><cell>From From From</cell><cell>: db . taxrefv9 . find ( {</cell></row><row><cell /><cell /><cell>$where : ' this . codeTaxon != this . codeReference ' } )</cell></row><row><cell /><cell cols="2">Project Project Project : $. codeReference AS AS AS ?t , $. codeTaxon AS AS AS ? b</cell></row><row><cell /><cell cols="2">Where Where Where : isNotNull isNotNull isNotNull ($. codeTaxon ) , equals equals equals ($. codeReference , 60585) }</cell></row><row><cell cols="2">] ON ON ON ? t</cell></row><row><cell>] ON ON ON ? t</cell><cell /></row></table></figure>
			<note place="foot" n="1" xml:id="foot_0"><p>We refer to key-value stores, document stores and column family stores but leave out graph stores that generally come with a richer query expressiveness.</p></note>
			<note place="foot" n="2" xml:id="foot_1"><p>https://www.mongodb.org/</p></note>
			<note place="foot" n="3" xml:id="foot_2"><p>https://github.com/agrueneberg/Sessel</p></note>
			<note place="foot" n="4" xml:id="foot_3"><p>http://couchdb.apache.org/</p></note>
			<note place="foot" n="5" xml:id="foot_4"><p>http://franz.com/agraph/support/documentation/4.7/mongo-interface.html</p></note>
			<note place="foot" n="6" xml:id="foot_5"><p>http://goessner.net/articles/JsonPath/</p></note>
			<note place="foot" n="7" xml:id="foot_6"><p>We adapt the triple pattern binding proposed by Unbehauen et al. in<ref type="bibr" target="#b36">[38]</ref>, and we assume that xR2RML mappings are normalized in the sense defined by<ref type="bibr" target="#b30">[32]</ref>, i.e. they contain exactly one predicate-object map with exactly one predicate map and one object map, and any rr:class property is replaced by an equivalent predicate-object map with a constant predicate rdf:type</p></note>
			<note place="foot" n="8" xml:id="foot_7"><p>Note that for a self-join elimination to be safe, additional conditions must be met, that we do not detail here.</p></note>
			<note place="foot" n="9" xml:id="foot_8"><p>https://github.com/frmichel/morph-xr2rml/</p></note>
			<note place="foot" n="10" xml:id="foot_9"><p>http://jena.apache.org/</p></note>
			<note place="foot" n="11" xml:id="foot_10"><p>https://mongodb.github.io/mongo-java-driver/</p></note>
			<note place="foot" n="12" xml:id="foot_11"><p>http://jongo.org/</p></note>
			<note place="foot" n="13" xml:id="foot_12"><p>https://github.com/json-path/JsonPath</p></note>
			<note place="foot" n="15" xml:id="foot_13"><p>xR2RML mapping graph for <software>TAXREF</software> v9: https://github.com/frmichel/morph-xr2rml/blob/master/morph-xr2rml-dist/example taxref/xr2rml taxref v9.ttl</p></note>
		</body>
		<back>
			<div type="annex">
<div><p>[ { Binding Binding Binding ( tp1 : ? t taxrefprop : bioGeo StatusIn ? bgs -&gt; TM_SBG_SPM )</p><p>From From From : db . taxrefv9 . find ({$where : ' this . codeTaxon == this . codeReference ' , 'spm ':{$ne : ' '} , ' spm ':{$ne : null }}) Project Project Project : $. codeTaxon AS AS AS ?t , $. codeTaxon AS AS AS ? bgs Where Where Where : isNotNull isNotNull isNotNull ($. Where Where Where : isNotNull isNotNull isNotNull ($. codeTaxon ) , equals equals equals ($. spm , P ) } Listing 1.8. Top: rewriting of the graph pattern of query Q7 after bindings reduction. Bottom: the same query after self-join elimination. Compared to the notation used in previous sections, each atomic abstract query contains heading lines providing the binding(s) of the triple pattern(s) that this atomic query accounts for, denoted by Binding(triple pattern -&gt; mapping name).</p><p>The binding reduction step (section 4.2) removes all but one mapping bound to the first and third triple patterns. The query now amounts to the join of three atomic abstract queries depicted in Listing 1.8 (top). The first and second atomic queries yield 4,835 RDF triples while the third query yields 4,236 triples. Under such reduced bindings, query Q 7 completes in 8.53s in average, the querying to <software>MongoDB</software> accounts for 47% of this total time, the generation of the RDF triples accounts for 11% and the processing of joins for 39%.</p><p>A closer look to the abstract query shows that it contains two self-joins that can be eliminated for the following reasons: (i) all three queries share the same From part (the logical source), (ii) they are joined on the ?bgs variable that is always projected from the same reference $.codeTaxon, and (iii) $.codeTaxon is declared as a unique identifier in at least one mapping bound to the three triple patterns (with property xrr:uniqueRef). This self-join elimination yields an optimized query that now consists of a single atomic query depicted in Listing 1.9 (bottom). Note that the Project and Where parts have been merged, and the three bindings now apply to this atomic query: the same <software>MongoDB</software> query is</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><surname>Arenas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bertails</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Prud'hommeaux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sequeda</surname></persName>
		</author>
		<title level="m">A Direct Mapping of Relational Data to RDF</title>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<author>
			<persName><forename type="first">T</forename><surname>Berners-Lee</surname></persName>
		</author>
		<ptr target="http://www.w3.org/DesignIssues/LinkedData.html" />
		<title level="m">Linked Data, in Design Issues of the WWW</title>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">The XML and Semantic Web Worlds: Technologies, Interoperability and Integra-tion: a Survey of the State of the Art</title>
		<author>
			<persName><forename type="first">N</forename><surname>Bikakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Tsinaraki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Gioldasis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Stavrakantonakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Christodoulakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Semantic Hyper/Multimedia Adaptation</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="319" to="360" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">The SPARQL2XQuery interoperability framework</title>
		<author>
			<persName><forename type="first">N</forename><surname>Bikakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Tsinaraki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Stavrakantonakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Gioldasis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Christodoulakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">World Wide Web</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="403" to="490" />
			<date type="published" when="2015-03">Mar 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">D2R server -Publishing Relational Databases on the Semantic Web</title>
		<author>
			<persName><forename type="first">C</forename><surname>Bizer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Cyganiak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceeding of the 5th International Semantic Web Conference (ISWC)</title>
		<meeting>eeding of the 5th International Semantic Web Conference (ISWC)</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">The Berlin SPARQL Benchmark</title>
		<author>
			<persName><forename type="first">C</forename><surname>Bizer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Schultz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal on Semantic Web and Information Systems</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1" to="24" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<author>
			<persName><forename type="first">E</forename><surname>Botoeva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Calvanese</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Cogrel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Rezk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Xiao</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/1603.09291v1" />
		<title level="m">A formal presentation of MongoDB (extended version)</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">OBDA beyond relational DBs: A study for MongoDB</title>
		<author>
			<persName><forename type="first">E</forename><surname>Botoeva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Calvanese</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Cogrel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Rezk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Xiao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 29th Int. Workshop on Description Logics</title>
		<meeting>the 29th Int. Workshop on Description Logics</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Towards a Shared Reference Thesaurus for Studies on History of Zoology, Archaeozoology and Conservation Biology</title>
		<author>
			<persName><forename type="first">C</forename><surname>Callou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Michel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Faron-Zucker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Montagnat</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Semantic Web For Scientific Heritage (SW4SH), ESWC workshops</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Semantics preserving SPARQL-to-SQL translation</title>
		<author>
			<persName><forename type="first">A</forename><surname>Chebotko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Fotouhi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Data &amp; Knowledge Engineering</title>
		<imprint>
			<biblScope unit="volume">68</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="973" to="1000" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">RDF 1.1 Concepts and Abstract Syntax</title>
		<author>
			<persName><forename type="first">R</forename><surname>Cyganiak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wood</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lanthaler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">W3C Recommendation</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">R2RML: RDB to RDF mapping language</title>
		<author>
			<persName><forename type="first">S</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sundara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Cyganiak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">W3C Recommendation</title>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">RML: A generic language for integrated RDF mappings of heterogeneous data</title>
		<author>
			<persName><forename type="first">A</forename><surname>Dimou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Vander Sande</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Colpaert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Verborgh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Mannens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Van De Walle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 7th Workshop on Linked Data on the Web</title>
		<meeting>the 7th Workshop on Linked Data on the Web</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A Complete Translation from SPARQL into Efficient SQL</title>
		<author>
			<persName><forename type="first">B</forename><surname>Elliott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Thomas-Ogbuji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">M</forename><surname>Ozsoyoglu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Database Engineering &amp; Applications Symposium</title>
		<meeting>the International Database Engineering &amp; Applications Symposium</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="31" to="42" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">TAXREF v9. 0, référentiel taxonomique pour la France: Méthodologie</title>
		<author>
			<persName><forename type="first">P</forename><surname>Gargominy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Tercerie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Régnier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Ramage</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Dupont</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Vandel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Daszkiewicz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Poncet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Schoelink</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Görlitz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SPLENDID: SPARQL Endpoint Federation Exploiting VOID Descriptions</title>
		<meeting><address><addrLine>Staab, S.</addrLine></address></meeting>
		<imprint>
			<publisher>Intl. Ws. COLD</publisher>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Optimizing Queries across Diverse Data Sources</title>
		<author>
			<persName><forename type="first">L</forename><surname>Haas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Kossmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Wimmers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd International Conference on Very Large Data Bases (VLDB 1997)</title>
		<meeting>the 23rd International Conference on Very Large Data Bases (VLDB 1997)</meeting>
		<imprint>
			<date type="published" when="1997">1997</date>
			<biblScope unit="page" from="276" to="285" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">SPARQL 1.1 Query Language</title>
		<author>
			<persName><forename type="first">S</forename><surname>Harris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Seaborne</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">W3C Recommendation</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Linked Data: Evolving the Web into a Global Data Space</title>
		<author>
			<persName><forename type="first">T</forename><surname>Heath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Bizer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011">2011</date>
			<publisher>Morgan &amp; Claypool</publisher>
		</imprint>
	</monogr>
	<note>1st edn.</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Une sémantique statique pour MongoDB</title>
		<author>
			<persName><forename type="first">A</forename><surname>Husson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">25th Journées Francophones des Langages Applicatifs</title>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="77" to="92" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Optimising SPARQL query processing in distributed knowledge graphs</title>
		<author>
			<persName><forename type="first">A</forename><surname>Macina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Montagnat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Corby</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Actes de la Conférence Gestion de Données -Principes, Technologies et Applications (BDA)</title>
		<meeting>s de la Conférence Gestion de Données -Principes, Technologies et Applications (BDA)<address><addrLine>Poitiers, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Integrating Heterogeneous Data Sources in the Web of Data</title>
		<author>
			<persName><forename type="first">F</forename><surname>Michel</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017-03">Mar 2017</date>
		</imprint>
		<respStmt>
			<orgName>Université Côte d'Azur</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.d. thesis</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">A Generic Mapping-Based Query Translation from SPARQL to Various Target Database Query Languages</title>
		<author>
			<persName><forename type="first">F</forename><surname>Michel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Faron-Zucker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Montagnat</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceeding of the 12th International Conference on Web Information Systems and Technologies (WebIST)</title>
		<meeting>eeding of the 12th International Conference on Web Information Systems and Technologies (WebIST)</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="147" to="158" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">A Mapping-based Method to Query MongoDB Documents with SPARQL</title>
		<author>
			<persName><forename type="first">F</forename><surname>Michel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Faron-Zucker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Montagnat</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th DEXA International Conference. LNCS</title>
		<meeting>the 27th DEXA International Conference. LNCS</meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="volume">9828</biblScope>
			<biblScope unit="page" from="52" to="67" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Translation of Heterogeneous Databases into RDF, and Application to the Construction of a SKOS Taxonomical Reference</title>
		<author>
			<persName><forename type="first">F</forename><surname>Michel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Faron-Zucker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Montagnat</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Revised Selected Papers of the 11th WebIST international conference</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="275" to="296" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Ontology-Mediated Queries for NOSQL Databases</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">L</forename><surname>Mugnier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">C</forename><surname>Rousset</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Ulliana</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 30th Conference on Artificial Intelligence</title>
		<meeting>the 30th Conference on Artificial Intelligence<address><addrLine>Phoenix, Arizona, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Semantics and Complexity of SPARQL</title>
		<author>
			<persName><forename type="first">J</forename><surname>Pérez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Arenas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Gutierrez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Database Systems</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1" to="45" />
			<date type="published" when="2009-08">Aug 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Metadata Vocabulary for Tabular Data</title>
		<author>
			<persName><forename type="first">R</forename><surname>Pollock</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tennison</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Kellogg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Herman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">W3C Recommendation</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Formalisation and Experiences of R2RMLbased SPARQL to SQL query translation using Morph</title>
		<author>
			<persName><forename type="first">F</forename><surname>Priyatna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Corcho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sequeda</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceeding of the World Wide Web Conference (WWW)</title>
		<meeting>eeding of the World Wide Web Conference (WWW)</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">High Performance Query Answering over DL-Lite Ontologies</title>
		<author>
			<persName><forename type="first">M</forename><surname>Rodrıguez-Muro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Calvanese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th Int. Conference on Principles of Knowledge Representation and Reasoning</title>
		<meeting>the 13th Int. Conference on Principles of Knowledge Representation and Reasoning<address><addrLine>KR</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012">2012. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Ontology-Based Data Access: Ontop of Databases</title>
		<author>
			<persName><forename type="first">M</forename><surname>Rodríguez-Muro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Kontchakov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zakharyaschev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Semantic Web -ISWC 2013</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="558" to="573" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Efficient SPARQL-to-SQL with R2RML mappings</title>
		<author>
			<persName><forename type="first">M</forename><surname>Rodríguez-Muro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Rezk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Web Semantics</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="141" to="169" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Fedx: Optimization techniques for federated query processing on Linked Data</title>
		<author>
			<persName><forename type="first">A</forename><surname>Schwarte</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Haase</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Hose</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Schenkel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Schmidt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th International Conference on Semantic Web (ISWC'11)</title>
		<meeting>the 10th International Conference on Semantic Web (ISWC'11)</meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="601" to="616" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Survey of directly mapping SQL databases to the Semantic Web</title>
		<author>
			<persName><forename type="first">J</forename><surname>Sequeda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">H</forename><surname>Tirmizi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Corcho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Miranker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Knowledge Eng. Review</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="445" to="486" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Ultrawrap: SPARQL execution on relational data</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">F</forename><surname>Sequeda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Miranker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Web Semantics</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Bringing Relational Databases into the Semantic Web: A survey</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">E</forename><surname>Spanos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Stavrou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Mitrou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Semantic Web Journal</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="169" to="209" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Document-oriented triplestore based on RDF/JSON</title>
		<author>
			<persName><forename type="first">D</forename><surname>Tomaszuk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Logic, philosophy and computer science</title>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="125" to="140" />
		</imprint>
		<respStmt>
			<orgName>University of Bialystok</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Accessing Relational Data on the Web with SparqlMap</title>
		<author>
			<persName><forename type="first">J</forename><surname>Unbehauen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Stadler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Auer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Semantic Technology</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="65" to="80" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Optimizing SPARQL-to-SQL Rewriting</title>
		<author>
			<persName><forename type="first">J</forename><surname>Unbehauen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Stadler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Auer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Information Integration and Web-based Applications &amp; Services (iiWAS'13)</title>
		<meeting>Information Integration and Web-based Applications &amp; Services (iiWAS'13)</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page">324</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Triple pattern fragments: a lowcost knowledge graph interface for the web</title>
		<author>
			<persName><forename type="first">R</forename><surname>Verborgh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Vander Sande</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Hartig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Van Herwegen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>De Vocht</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>De Meester</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Haesendonck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Colpaert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Web Semantics</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">38</biblScope>
			<biblScope unit="page" from="184" to="206" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>