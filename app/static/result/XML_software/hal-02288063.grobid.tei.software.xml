<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="fr">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Cauchy Multichannel Speech Enhancement with a Deep Speech Prior</title>
				<funder>
					<orgName type="full">French State agency</orgName>
				</funder>
				<funder ref="#_W7QQzSz">
					<orgName type="full">Agence Nationale de la Recherche</orgName>
					<orgName type="abbreviated">ANR</orgName>
				</funder>
				<funder ref="#_E2rTJMX">
					<orgName type="full">JSPS KAKENHI</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Mathieu</forename><surname>Fontaine</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Université de Lorraine</orgName>
								<orgName type="institution" key="instit2">CNRS</orgName>
								<orgName type="institution" key="instit3">Inria</orgName>
								<orgName type="institution" key="instit4">LORIA</orgName>
								<address>
									<settlement>Nancy</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Aditya</forename><forename type="middle">Arie</forename><surname>Nugraha</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">AIP</orgName>
								<orgName type="institution">RIKEN</orgName>
								<address>
									<settlement>Tokyo</settlement>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Roland</forename><surname>Badeau</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Télécom ParisTech</orgName>
								<orgName type="laboratory">LTCI</orgName>
								<orgName type="institution">Université Paris-Saclay</orgName>
								<address>
									<settlement>Paris</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Kazuyoshi</forename><surname>Yoshii</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">AIP</orgName>
								<orgName type="institution">RIKEN</orgName>
								<address>
									<settlement>Tokyo</settlement>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
							<affiliation key="aff4">
								<orgName type="department">Graduate School of Informatics</orgName>
								<orgName type="institution">Kyoto University</orgName>
								<address>
									<settlement>Kyoto</settlement>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Antoine</forename><surname>Liutkus</surname></persName>
							<affiliation key="aff3">
								<orgName type="institution" key="instit1">Inria</orgName>
								<orgName type="institution" key="instit2">LIRMM</orgName>
								<address>
									<settlement>Montpellier</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Cauchy Multichannel Speech Enhancement with a Deep Speech Prior</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">C8B6AA69CC7BA081F4529B84781A1459</idno>
					<idno type="DOI">10.23919/EUSIPCO.2019.8903091</idno>
					<note type="submission">Submitted on 16 Oct 2019</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-04-12T14:43+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Multichannel speech enhancement</term>
					<term>multivariate complex Cauchy distribution</term>
					<term>variational autoencoder</term>
					<term>nonnegative matrix factorization</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>de niveau recherche, publiés ou non, émanant des établissements d'enseignement et de recherche français ou étrangers, des laboratoires publics ou privés.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="fr">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>Multichannel speech enhancement aims to extract speech from an observed multichannel noisy signal <ref type="bibr" target="#b0">[1]</ref>. Usually, parametric models are used for the speech (target) signal, the additive noise, and the way both are captured by the microphones. The core feature of such models is to allow the reconstruction of the target signal from the noisy mixture, provided that the parameters are well estimated. The standard example is having sources parameterized by their spectrograms, and reconstructed through soft-masking (Wiener-like) strategies.</p><p>Deep neural networks (DNNs) have been increasingly used in this context <ref type="bibr" target="#b0">[1]</ref>- <ref type="bibr" target="#b3">[4]</ref>. Most approaches train denoising DNNs to estimate the model parameters, e.g., source spectrograms or the time-frequency mask of one or all of the sources. In this case, the training employs paired data consisting of noisy speech and clean speech. Although it has been shown that denoising DNNs could be robust to unseen environments <ref type="bibr" target="#b4">[5]</ref>, there is still a concern that they are not adaptive enough to unseen noises. This issue has recently been addressed by several studies on semi-supervised speech enhancement <ref type="bibr" target="#b5">[6]</ref>- <ref type="bibr" target="#b9">[10]</ref>. The core idea of these studies is to formulate a probabilistic generative model in which both speech spectrogram and noise spectrogram are modeled by latent variable models. The speech spectrogram model is trained as the decoder in the variational autoencoder (VAE) framework <ref type="bibr" target="#b10">[11]</ref>, while the noise spectrogram is modeled by a nonnegative matrix factorization (NMF) <ref type="bibr" target="#b11">[12]</ref> approach. The speech model is trained with clean speech only, thus independent from the actual noise that will be found in the observations at test time. Indeed, the core feature of this strategy is to let the noise parameters be estimated and adapted at test time, so that it is flexible and may achieve good denoising performance even in adversarial conditions not met at training time. In the case of multichannel enhancement <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b8">[9]</ref>, the spatial parameters are also estimated at test time.</p><p>Most of these methods <ref type="bibr" target="#b5">[6]</ref>- <ref type="bibr" target="#b8">[9]</ref> tackle such a whole estimation problem under a Gaussian probabilistic setting. Although it is convenient because it leads to straightforward inference methods, it has the drawback of being sensitive to initialization and prone to be trapped in a local minimum <ref type="bibr" target="#b12">[13]</ref>.</p><p>As opposed to their Gaussian counterpart, heavy-tailed probabilistic models allow for outcomes that are far away from the expected values <ref type="bibr" target="#b13">[14]</ref>, <ref type="bibr" target="#b14">[15]</ref>. From an inference perspective, this means that unlikely observations will not have a detrimental impact on the parameters, yielding robust estimation. Among them, non-Gaussian α-stable models are remarkable because they also satisfy the central limit theorem <ref type="bibr" target="#b15">[16]</ref>, which means that a sum of α-stable random vectors remains α-stable. This is an interesting feature in a context of speech enhancement where additive sources are combined to yield the observed mixture. Notwithstanding their attractive features, the main weakness of these distributions is the absence of a closed-form probability density function (PDF), except for α = 0.5 (the Lévy distribution), α = 1 (the Cauchy distribution), and α = 2 (the Gaussian distribution).</p><p>An option is to express an α-stable random variable as conditionally Gaussian <ref type="bibr" target="#b15">[16]</ref>. This may always be done in the scalar (single-channel) case and only in some cases for multichannel data. Put it simply, the trick is to write an α-stable random variable as a Gaussian variable with a covariance that is multiplied by a random impulse variable, distributed as a positive α 2 -stable random variable. This makes it possible to use the classical Gaussian methodology, provided that some specific method is found to estimate the impulse variables, notably some Markov chain Monte Carlo (MCMC) strategy <ref type="bibr" target="#b16">[17]</ref>- <ref type="bibr" target="#b18">[19]</ref>. However, the MCMC algorithm is often computationally demanding at test time, and <ref type="bibr" target="#b19">[20]</ref> proposes an approximation to construct filters without requiring the estimation of impulse variables. Still, this strategy does not provide any convenient cost function to use for parameter estimation, which is inconvenient in our case.</p><p>In line with the present study, combining a VAE and general α-stable distributions has recently been proposed in <ref type="bibr" target="#b9">[10]</ref>. It suffers from expensive MCMC schemes. A simplified approach undertaken in <ref type="bibr" target="#b20">[21]</ref> is to focus on the Cauchy α = 1 case, for which closed-form expressions of the likelihood are available. However, this study is limited to single-channel source separation based on low-rank source models.</p><p>In this paper, we go beyond related work in this respect and introduce a semi-supervised multichannel speech enhancement method that uses a VAE-based speech model and a low-rank noise model, that both parameterize Cauchy models for the sources. To the best of our knowledge, this is the first study that uses a computationally-tractable heavy-tailed model for multichannel sources unlike previous studies that use a heavytailed model for multichannel mixtures <ref type="bibr" target="#b21">[22]</ref>, <ref type="bibr" target="#b22">[23]</ref>. Additionally, we show how deep latent variable models may be combined with more classical low-rank models in this setting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. PROBABILISTIC FORMULATION</head><p>This section formulates a probabilistic model for the proposed Cauchy multichannel speech enhancement method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Multivariate Complex Cauchy Distribution</head><p>Let y be a complex random vector of dimension K. Then, y ∼ C C (y|µ, V) follows a circularly-symmetric multivariate complex Cauchy distribution iff. its probability density is</p><formula xml:id="formula_0">p µ,V (y) = A K,V 1 + (y -µ) H V -1 (y -µ) -K-1 2 ,<label>(1)</label></formula><p>where</p><formula xml:id="formula_1">A K,V = K k=1 K -k + 1 2 π -K det (V) -1<label>(2)</label></formula><p>and . H , V and µ in (1) respectively stand for the Hermitian transposition, the positive definite scatter matrix and the location parameter <ref type="bibr" target="#b23">[24]</ref>, <ref type="bibr" target="#b24">[25]</ref>. Similarly to the Gaussian distribution, a linear combination of Cauchy vectors remains a Cauchy vector. However, the tails of a Gaussian distribution are lighter than those of a Cauchy one (see Fig. <ref type="figure" target="#fig_0">1</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Spatial Model</head><p>We work in the short time Fourier transform (STFT) domain. Let f ∈ [1, F ] and t ∈ [1, T ] be the frequency bin and time frame indexes, respectively. Following the literature, we assume that the observed mixture signal is a linear combination of the sources. Considering speech and noise as the sources, the STFT of a K-channel noisy speech x ∈ C F ×T ×K is expressed for each time-frequency (TF) bin f t as where the speech x s f t ∈ C K and the noise x n f t ∈ C K are assumed to follow a Cauchy distribution:</p><formula xml:id="formula_2">x f t = x s f t + x n f t ,<label>(3)</label></formula><formula xml:id="formula_3">x s f t ∼ C C x s f t 0, a s f t R s f , x n f t ∼ C C x n f t 0, a n f t R n f ,<label>(4)</label></formula><p>with a s f t ∈ R + and a n f t ∈ R + are the sources' magnitudes, while R s f and R n f are the K × K positive definite spatial scatter matrices of the sources.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Source Models</head><p>While the scatter matrices R s f and R n f are left unconstrained, specific models are picked for the speech and noise magnitudes.</p><p>First, the F -dimensional vector a s t gathering the speech magnitudes a s f t for frame t is assumed to depend on lowdimensional latent variables written z t ∈ R D with D &lt; F . This mapping is given by a function called the decoder and written a s t = µ θ (z t ), parameterized by θ. Second, the noise magnitudes a n f t are modeled with a nonnegative matrix factorization (NMF) <ref type="bibr" target="#b25">[26]</ref> as follows:</p><formula xml:id="formula_4">a n f t = L l=1 w f l h lt for ∀f, t,<label>(5)</label></formula><p>where L is the number of basis vectors. At test time, the key idea becomes to use the observed mixture x to estimate the most likely latent vectors z t and NMF parameters w and h as well as the scatter matrices. They are then used in conjunction to âs t = µ θ (z t ) to separate the signals with the technique presented in section II-D.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Projection-Based Wiener Filter</head><p>The Cauchy model above resembles its Gaussian counterpart <ref type="bibr" target="#b26">[27]</ref>. Instead of scatter matrices, the Gaussian model has covariance matrices. The mixture covariance matrix is simply a linear combination of the source covariance matrices. In this case, given the model parameters, the multichannel Wiener filter can be used to extract the sources. Unfortunately, this linear combination between scatter matrices is usually not satisfied for the Cauchy model with K &gt; 1.</p><p>We therefore propose to project the observation vectors</p><formula xml:id="formula_5">x f t ∈ C K to the complex plane C. Let us consider M vectors u 1 , • • • , u M ∈ C K and let x mf t = u H m x f t for ∀m, f, t<label>(6)</label></formula><p>be the m th -projection of the observed signal x f t . As demonstrated in <ref type="bibr" target="#b27">[28]</ref>, the random variable x mf t is Cauchy distributed and the following posterior mean of the projected speech</p><formula xml:id="formula_6">xs mf t</formula><p>is tractable for all m, f, t:</p><formula xml:id="formula_7">xs mf t E u H m x s f t |x mf t , Ψ = v s mf t v mf t x mf t ,<label>(7)</label></formula><p>where</p><formula xml:id="formula_8">       v s mf t = a s f t u H m R s f u m , v n mf t = a n f t u H m R n f u m , v mf t = v s mf t + v n mf t 2 ,<label>(8)</label></formula><p>and Ψ a s f t , a n f t , R s f , R n f . We then deduce an estimator xs f t of x s f t by using U † , which is the pseudo-inverse of U [u 1 , . . . , u M ]</p><p>H ∈ C M ×K :</p><formula xml:id="formula_9">xs f t = U † xs 1f t , • • • , xs mf t T .<label>(9)</label></formula><p>An estimator xn f t of x n f t can be computed in a similar way. In this paper, in order to simplify the computation of ( <ref type="formula" target="#formula_9">9</ref>), the projector U is chosen to be unitary so that U † = U.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. PARAMETER ESTIMATION</head><p>This section explains how to estimate the parameters of the probabilistic model proposed in Section II.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Training Phase</head><p>To train the speech decoder model µ θ (z), we adopt the VAE framework <ref type="bibr" target="#b10">[11]</ref>. For training, two DNNs are considered:</p><p>• An encoder that inputs a s t and outputs two D-dimensional vectors written µ q φ (a s t ) and σ q φ (a s t ). Together, they define the distribution of the latent vectors: q φ (z t |a t ), defined as N (z t |µ q φ (a t ), Diag[σ q φ (a t )]) • A decoder that outputs two F -dimensional vectors written µ θ (z t ) and γ θ (z t ), that together describe the distribution of the speech magnitudes a s t given z, written p θ (a s t |z t ). We detail that distribution later. In any case, the model parameters θ and φ are jointly optimized by minimizing the negative log-likelihood (NLL):</p><formula xml:id="formula_10">-ln p θ (a s t ) = -ln zt q φ (z t |a s t ) q φ (z t |a s t ) p θ (a s t , z t )dz t ≤ -E q φ (zt|a s t ) ln p θ (a s t |z t )p θ (z t ) q φ (z t |a s t ) = -E q φ (zt|a s t ) [ln p θ (a s t |z t )]+KL[q φ (z t |a s t ) p θ (z t )] def = L mag + L reg ,<label>(10)</label></formula><p>where KL[q p] is the Kullback-Leibler (KL) divergence from p to q <ref type="bibr" target="#b28">[29]</ref>. The reparameterization trick <ref type="bibr" target="#b10">[11]</ref> is used to obtain z t given the encoder outputs µ q φ (a s t ) and σ q φ (a s t ). For training, the observed magnitudes from a clean speech dataset, a s f t , are assumed to follow a real Cauchy distribution</p><formula xml:id="formula_11">C R with location [µ θ (z t )] f ∈ R + and scale [γ θ (z t )] f ∈ R + : p θ (a s f t |z t ) = C R a s f t [µ θ (z t )] f , [γ θ (z t )] f . (<label>11</label></formula><formula xml:id="formula_12">)</formula><p>This complies with the α-spectrogram assumption for α = 1 <ref type="bibr" target="#b29">[30]</ref>. Thus, the magnitude reconstruction loss L mag , serving as a cost function for training the parameters θ, may be picked as the negative log-likelihood (NLL):</p><formula xml:id="formula_13">L mag c = 1 T F,T f,t=1 ln[γ θ (z t )] f + ln 1 + a s f t -[µ θ (z t )] f 2 γ 2 f t . (<label>12</label></formula><formula xml:id="formula_14">)</formula><p>Then, assuming a simple prior p θ (z t ) ∼ N (z t |0, I), the regularization term L reg <ref type="bibr" target="#b10">[11]</ref> is computed as</p><formula xml:id="formula_15">L reg = 1 2T D,T d,t=1 [µ q φ (a s t )] 2 d + [σ q φ (a s t )] 2 d -ln[σ q φ (a s t )] 2 d -1 .<label>(13)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Test Phase</head><p>As advocated above, the projected mixtures x mf t are considered as isotropic complex random variables. They are thus parameterized through a scale parameter √ v mf t and the negative log-likelihood is given by</p><formula xml:id="formula_16">D (v) c = M,F,T m,f,t=1 3 2 ln v mf t + |x mf t | 2 - 1 2 ln (v mf t ) ,<label>(14) where c</label></formula><p>= denotes equality up to a constant. At test time, the latent variables z t are initialized by sampling from q φ (z t | |x t |), i.e., by applying the encoder to the average of the mixture magnitude spectrogram over channels. This in turn provides an initial estimate µ θ (z t ) for the speech magnitude a s t . Then, the latent variables z t are updated by backpropagation with a gradient descent method to minimize the cost function <ref type="bibr" target="#b13">(14)</ref>. In this case, all parameters other than z t , including the decoder parameters, are kept fixed.</p><p>For estimating the noise parameters, we adopt a majorizationequalization (ME) strategy <ref type="bibr" target="#b25">[26]</ref> as in <ref type="bibr" target="#b20">[21]</ref>. Due to space constraints, we only provide here the multiplicative updates used for the parameters w and h as follows:</p><formula xml:id="formula_17">w f l ← 1 3 w f l mt h lt ψ n mf mt h lt ψ n mf ξ mf t ,<label>(15)</label></formula><formula xml:id="formula_18">h lt ← 1 3 h lt mf h f l ψ n mf mf w f l ψ n mf ξ mf t ,<label>(16)</label></formula><p>Fig. <ref type="figure">3</ref>: Performance comparison in terms of PESQ (left), STOI (middle), and SDR (right). Higher is better. The mean and the standard deviation are respectively shown in white and black fonts.</p><formula xml:id="formula_19">ψ n mf u H m R n f u m v n mf t v mf t ,<label>(17)</label></formula><formula xml:id="formula_20">ξ mf t 1 + |x mf t | 2 v mf t .<label>(18)</label></formula><p>Similarly for noise parameter estimation, we define the estimator vj f t = a j f t Rj f for j ∈ {s, n}, where a j f t is provided by the source models and Rj</p><formula xml:id="formula_21">f = m r j m ,f u m u H m . It leads to r j m f ← 1 3 r j f mt a j f t η j mm f t mt η j mm f t ξ mf t ,<label>(19)</label></formula><formula xml:id="formula_22">η j mm f t |u H m u m | 2 v j mf t v mf t .<label>(20)</label></formula><p>IV. EVALUATION</p><p>In this section, we compare the performance of three different systems on a 5-channel speech enhancement task. Each of them includes at least one multichannel nonnegative matrix factorization (MNMF) spectrogram model <ref type="bibr" target="#b30">[31]</ref>. The systems include: (1) Cauchy VAE-MNMF, that we propose above; (2) Gaussian VAE-MNMF, that is a system similar to ours, but based on a Gaussian model <ref type="bibr" target="#b8">[9]</ref>; and (3) Cauchy MNMF, that is a semi-supervised multichannel Cauchy NMF, where the speech magnitude is also modeled with an NMF with basis vectors trained on clean speech beforehand. The Gaussian VAE-MNMF system is provided by the authors <ref type="bibr" target="#b8">[9]</ref>.</p><p>The performance is measured by the signal-to-distortion ratio (SDR) provided by the BSS-Eval toolbox <ref type="bibr" target="#b31">[32]</ref>, the Perceptual Evaluation of Speech Quality (PESQ) score <ref type="bibr" target="#b32">[33]</ref>, and the Short-Time Objective Intelligibility (STOI) score <ref type="bibr" target="#b33">[34]</ref>. The SDR is computed on the enhanced 5-channel speech, while the PESQ and the STOI are computed on one of the channels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Experimental Conditions</head><p>We consider the simulated training, development, and test sets of the CHiME-4 corpus <ref type="bibr" target="#b4">[5]</ref> The evaluation is then done on 10% of the full test set, i.e., 132 randomly selected 5-channel noisy utterances (K = 5).</p><p>The STFT coefficients are extracted using a Hann window with a length of 1024 samples and an overlap of 75% (F = 513).</p><p>The encoder and the decoder of the speech VAE for the Cauchy VAE-MNMF is depicted in Fig. <ref type="figure" target="#fig_1">2</ref>. These DNNs are trained by backpropagation with the Adam update rule whose learning rate is fixed to 10 -3 <ref type="bibr" target="#b34">[35]</ref>. The update is done for every minibatch of 8192 frames from 32 randomly selected utterances. The gradient is normalized with threshold fixed to 1 <ref type="bibr" target="#b35">[36]</ref>. The weight normalization <ref type="bibr" target="#b36">[37]</ref> is also employed. The training is started with a warm-up technique <ref type="bibr" target="#b37">[38]</ref> for 100 epochs and stopped after 50 consecutive epochs that failed to obtain a better validation score. The latest model yielding the lowest error is kept. These DNNs are comparable in size to the ones used in the Gaussian VAE-MNMF.</p><p>For both VAE-MNMF methods, the latent variable dimension of the speech model is fixed to D = 32 and the number of bases of the noise model is fixed to L = 32. Similarly, for the Cauchy MNMF, the number of bases of both source models is fixed to L = 32. For the Cauchy MNMF and the Cauchy VAE-MNMF, the dimension of the projector U is fixed to M = 8. The NMF parameters are initialized randomly and the coefficients r j mf are initialized as 1. We consider 64 optimization iterations for the Cauchy MNMF and 50 for both VAE-MNMF methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Experimental Results</head><p>Fig. <ref type="figure">3</ref> shows that the Cauchy VAE-MNMF globally outperforms the Cauchy MNMF and the Gaussian VAE-MNMF. It provides an SDR improvement of 4.2 dB w.r.t. the Gaussian VAE-MNMF. We also observe that the standard deviation of the metrics is generally smaller for the Cauchy VAE-MNMF, suggesting that it has stronger robustness to noise.</p><p>As an illustration, we also displayed in Fig. <ref type="figure" target="#fig_4">4</ref> the logmagnitude spectrograms of estimated speech obtained with the Cauchy and the Gaussian VAE-MNMFs. We see that the one seems less robust against non-stationary noise.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. CONCLUSION</head><p>We proposed a speech enhancement system combining a nonnegative matrix factorization (NMF) model for the noise and a variational autoencoder (VAE) for speech, that is trained and used under heavy-tailed probabilistic models. We derived the whole training and inference strategy and gave the details of the corresponding algorithms.  In an evaluation on 5-channel mixtures from the CHiME-4 corpus, we found out that our proposed system achieves a significantly better performance than its Gaussian counterpart, yielding a 4 dB SDR improvement.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 :</head><label>1</label><figDesc>Fig. 1: Tails of unidimensional Cauchy and Gaussian PDF</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 :</head><label>2</label><figDesc>Fig.2:The encoder and decoder of the speech VAE. 'FC' represents a fully-connected layer whose size is shown inside the parentheses. The speech magnitude estimate is computed from the decoder output âs t = exp (ln µ t ).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>. All data are sampled at 16 kHz. We use 7138 single-channel clean speech signals of the training set for training the DNNs of the Cauchy VAE-MNMF and the speech basis vectors of the Cauchy MNMF. Moreover, we use 1640 single-channel clean speech signals from the development set as the validation set for the DNN training.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 4 :</head><label>4</label><figDesc>Fig. 4: Log-magnitude spectrograms of clean speech (topleft), corrupted speech (top-right), speech estimated with the Gaussian VAE-MNMF (bottom-left) and speech estimated with the Cauchy VAE-MNMF (bottom-right). The utterance is M05_447C020F_PED from the test set et05_ped_simu.</figDesc><graphic coords="6,73.79,127.31,103.75,61.87" type="bitmap" /></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>ACKNOWLEDGEMENT</head><p>We thank <rs type="person">S. Leglaive</rs> for providing the code of [9].</p></div>
			</div>
			<div type="funding">
<div><p>This work was partly supported by the research programme <rs type="projectName">KAMoulox</rs> (<rs type="grantNumber">ANR-15-CE38-0003-01</rs>) funded by <rs type="funder">ANR</rs>, the <rs type="funder">French State agency</rs> for research, and <rs type="funder">JSPS KAKENHI</rs> No. <rs type="grantNumber">19H04137</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funded-project" xml:id="_W7QQzSz">
					<idno type="grant-number">ANR-15-CE38-0003-01</idno>
					<orgName type="project" subtype="full">KAMoulox</orgName>
				</org>
				<org type="funding" xml:id="_E2rTJMX">
					<idno type="grant-number">19H04137</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m">Audio Source Separation and Speech Enhancement</title>
		<editor>
			<persName><forename type="first">E</forename><surname>Vincent</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename><surname>Virtanen</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Gannot</surname></persName>
		</editor>
		<imprint>
			<publisher>Wiley</publisher>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Multichannel audio source separation with deep neural networks</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Nugraha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Liutkus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Vincent</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE/ACM Trans. ASLP</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1652" to="1664" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A generic neural acoustic beamforming architecture for robust multi-channel speech processing</title>
		<author>
			<persName><forename type="first">J</forename><surname>Heymann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Drude</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Haeb-Umbach</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Speech &amp; Language</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="page" from="374" to="385" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Multichannel signal processing with deep neural networks for automatic speech recognition</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">N</forename><surname>Sainath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">W</forename><surname>Wilson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Narayanan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Variani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bacchiani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Shafran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Senior</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Chin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Misra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE/ACM Trans. ASLP</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="965" to="979" />
			<date type="published" when="2017-05">May 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">An analysis of environment, microphone and data simulation mismatches in robust speech recognition</title>
		<author>
			<persName><forename type="first">E</forename><surname>Vincent</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Watanabe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Nugraha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Barker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Marxer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Speech &amp; Language</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="page" from="535" to="557" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Statistical speech enhancement based on probabilistic integration of variational autoencoder and non-negative matrix factorization</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Bando</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mimura</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Itoyama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Yoshii</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kawahara</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE ICASSP</title>
		<meeting>IEEE ICASSP</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="716" to="720" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A variance modeling framework based on variational autoencoders for speech enhancement</title>
		<author>
			<persName><forename type="first">S</forename><surname>Leglaive</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Girin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Horaud</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE MLSP</title>
		<meeting>IEEE MLSP</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Bayesian multichannel speech enhancement with a deep speech prior</title>
		<author>
			<persName><forename type="first">K</forename><surname>Sekiguchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bando</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Yoshii</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kawahara</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. APSIPA</title>
		<meeting>APSIPA</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="1233" to="1239" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Semi-supervised multichannel speech enhancement with variational autoencoders and non-negative matrix factorization</title>
		<author>
			<persName><forename type="first">S</forename><surname>Leglaive</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Girin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Horaud</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE ICASSP</title>
		<meeting>IEEE ICASSP</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Speech enhancement with variational autoencoders and alpha-stable distributions</title>
		<author>
			<persName><forename type="first">S</forename><surname>Leglaive</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Liutkus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Girin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Horaud</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE ICASSP</title>
		<meeting>IEEE ICASSP</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Auto-encoding variational Bayes</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICLR</title>
		<meeting>ICLR</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Learning the parts of objects by nonnegative matrix factorization</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">D</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">S</forename><surname>Seung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">401</biblScope>
			<biblScope unit="issue">6755</biblScope>
			<biblScope unit="page" from="788" to="791" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">SVD based initialization: A head start for nonnegative matrix factorization</title>
		<author>
			<persName><forename type="first">C</forename><surname>Boutsidis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Gallopoulos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1350" to="1362" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Applications of &quot;Student&apos;s&quot; distribution</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Fisher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Metron</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="90" to="104" />
			<date type="published" when="1925">1925</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Speech enhancement in the DFT domain using Laplacian speech priors</title>
		<author>
			<persName><forename type="first">R</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Breithaupt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IWAENC</title>
		<meeting>IWAENC</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="87" to="90" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Stable non-Gaussian random processes: stochastic models with infinite variance</title>
		<author>
			<persName><forename type="first">G</forename><surname>Samoradnitsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Taqqu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1994">1994</date>
			<publisher>Chapman and Hall/CRC</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Alphastable multichannel audio source separation</title>
		<author>
			<persName><forename type="first">S</forename><surname>Leglaive</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Liutkus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Badeau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Richard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE ICASSP</title>
		<meeting>IEEE ICASSP</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="576" to="580" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Multichannel audio modeling with elliptically stable tensor decomposition</title>
		<author>
			<persName><forename type="first">M</forename><surname>Fontaine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F.-R</forename><surname>Stöter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Liutkus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Serizel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Badeau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. LVA/ICA</title>
		<meeting>LVA/ICA</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="13" to="23" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Alpha-stable low-rank plus residual decomposition for speech enhancement</title>
		<author>
			<persName><forename type="first">U</forename></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Erdogan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Leglaive</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Liutkus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Badeau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Richard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE ICASSP</title>
		<meeting>IEEE ICASSP</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Explaining the parameterized Wiener filter with alpha-stable processes</title>
		<author>
			<persName><forename type="first">M</forename><surname>Fontaine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Liutkus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Girin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Badeau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. WASPAA</title>
		<meeting>WASPAA</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Cauchy nonnegative matrix factorization</title>
		<author>
			<persName><forename type="first">A</forename><surname>Liutkus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Fitzgerald</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Badeau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. WASPAA</title>
		<meeting>WASPAA</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1" to="5" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Student&apos;s t multichannel nonnegative matrix factorization for blind source separation</title>
		<author>
			<persName><forename type="first">K</forename><surname>Kitamura</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bando</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Itoyama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Yoshii</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IWAENC</title>
		<meeting>IWAENC</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="1" to="5" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Generalized independent low-rank matrix analysis using heavy-tailed distributions for blind source separation</title>
		<author>
			<persName><forename type="first">D</forename><surname>Kitamura</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mogami</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Mitsui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Takamune</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Saruwatari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Ono</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Takahashi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Kondo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">EURASIP J. on Adv. in Signal Process</title>
		<imprint>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="25" />
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Indirect estimation of elliptical stable distributions</title>
		<author>
			<persName><forename type="first">M</forename><surname>Lombardi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Veredas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Statistics &amp; Data Analysis</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="2309" to="2324" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Multivariate stable distributions</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Press</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Multivariate Analysis</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="444" to="462" />
			<date type="published" when="1972">1972</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Algorithms for nonnegative matrix factorization with the β-divergence</title>
		<author>
			<persName><forename type="first">C</forename><surname>Févotte</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Idier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="2421" to="2456" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Under-determined reverberant audio source separation using a full-rank spatial covariance model</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">Q K</forename><surname>Duong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Vincent</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Gribonval</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. ASLP</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1830" to="1840" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Projection-based demixing of spatial audio</title>
		<author>
			<persName><forename type="first">D</forename><surname>Fitzgerald</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Liutkus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Badeau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE/ACM Trans. ASLP</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1556" to="1568" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">On information and sufficiency</title>
		<author>
			<persName><forename type="first">S</forename><surname>Kullback</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Leibler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ann. Math. Statist</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="79" to="86" />
			<date type="published" when="1951">1951</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Generalized Wiener filtering with fractional power spectrograms</title>
		<author>
			<persName><forename type="first">A</forename><surname>Liutkus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Badeau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE ICASSP</title>
		<meeting>IEEE ICASSP</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="266" to="270" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Multichannel nonnegative matrix factorization in convolutive mixtures for audio source separation</title>
		<author>
			<persName><forename type="first">A</forename><surname>Ozerov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Févotte</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. ASLP</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="550" to="563" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">First stereo audio source separation evaluation campaign: Data, algorithms and results</title>
		<author>
			<persName><forename type="first">E</forename><surname>Vincent</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Sawada</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Bofill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Makino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Rosca</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICA</title>
		<meeting>ICA</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="552" to="559" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<idno>P.862</idno>
		<title level="m">Perceptual evaluation of speech quality (PESQ): An objective method for end-to-end speech quality assessment of narrowband telephone networks and speech codecs</title>
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">An algorithm for intelligibility prediction of time-frequency weighted noisy speech</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">H</forename><surname>Taal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">C</forename><surname>Hendriks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Heusdens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Jensen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. ASLP</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="2125" to="2136" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICLR</title>
		<meeting>ICLR</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">On the difficulty of training recurrent neural networks</title>
		<author>
			<persName><forename type="first">R</forename><surname>Pascanu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICML</title>
		<meeting>ICML</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="1310" to="1318" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Weight normalization: A simple reparameterization to accelerate training of deep neural networks</title>
		<author>
			<persName><forename type="first">T</forename><surname>Salimans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. NIPS</title>
		<meeting>NIPS</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="901" to="909" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Ladder variational autoencoders</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">K</forename><surname>Sønderby</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Raiko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Maaløe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">K</forename><surname>Sønderby</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Winther</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. NIPS</title>
		<meeting>NIPS</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="3738" to="3746" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
