<TEI xmlns="http://www.tei-c.org/ns/1.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xml:space="preserve" xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Deep Species Distribution Modeling From Sentinel-2 Image Time-Series: A Global Scale Analysis on the Orchid Family</title>
				<funder ref="#_zVQMkfH">
					<orgName type="full">GENCI</orgName>
				</funder>
				<funder>
					<orgName type="full">CACTUS Fund</orgName>
				</funder>
				<funder>
					<orgName type="full">INRIA</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher />
				<availability status="unknown"><licence /></availability>
				<date type="published" when="2022-04-22">22 April 2022</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Miguel</forename><forename type="middle">Alfonso</forename><surname>Ortega-Huerta</surname></persName>
						</author>
						<author role="corresp">
							<persName><forename type="first">Joaquim</forename><surname>Estopinan</surname></persName>
							<email>joaquim.estopinan@inria.fr</email>
							<affiliation key="aff5">
								<orgName type="institution">INRIA</orgName>
								<address>
									<settlement>Montpellier</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
							<affiliation key="aff6">
								<orgName type="laboratory">LIRMM</orgName>
								<orgName type="institution" key="instit1">Univ Montpellier</orgName>
								<orgName type="institution" key="instit2">CNRS</orgName>
								<address>
									<settlement>Montpellier</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Maximilien</forename><surname>Servajean</surname></persName>
							<affiliation key="aff6">
								<orgName type="laboratory">LIRMM</orgName>
								<orgName type="institution" key="instit1">Univ Montpellier</orgName>
								<orgName type="institution" key="instit2">CNRS</orgName>
								<address>
									<settlement>Montpellier</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
							<affiliation key="aff7">
								<orgName type="laboratory">AMIS</orgName>
								<orgName type="institution">Université Paul Valéry Montpellier</orgName>
							</affiliation>
							<affiliation key="aff8">
								<orgName type="institution" key="instit1">Univ Montpellier</orgName>
								<orgName type="institution" key="instit2">CNRS</orgName>
								<address>
									<settlement>Montpellier</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Pierre</forename><surname>Bonnet</surname></persName>
							<affiliation key="aff9">
								<orgName type="laboratory" key="lab1">AMAP</orgName>
								<orgName type="laboratory" key="lab2">CIRAD</orgName>
								<orgName type="institution" key="instit1">Univ Montpellier</orgName>
								<orgName type="institution" key="instit2">CNRS</orgName>
								<orgName type="institution" key="instit3">INRAE</orgName>
								<orgName type="institution" key="instit4">IRD</orgName>
								<address>
									<settlement>Montpellier</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
							<affiliation key="aff10">
								<orgName type="laboratory">CIRAD</orgName>
								<orgName type="institution">UMR AMAP</orgName>
								<address>
									<settlement>Montpellier</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">François</forename><surname>Munoz</surname></persName>
							<affiliation key="aff11">
								<orgName type="laboratory">LIPHY</orgName>
								<orgName type="institution">Université Grenoble Alpes</orgName>
								<address>
									<settlement>Grenoble</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Alexis</forename><surname>Joly</surname></persName>
							<affiliation key="aff5">
								<orgName type="institution">INRIA</orgName>
								<address>
									<settlement>Montpellier</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
							<affiliation key="aff6">
								<orgName type="laboratory">LIRMM</orgName>
								<orgName type="institution" key="instit1">Univ Montpellier</orgName>
								<orgName type="institution" key="instit2">CNRS</orgName>
								<address>
									<settlement>Montpellier</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">VTT Technical Research Centre of Finland Ltd</orgName>
								<address>
									<country key="FI">Finland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">National Autonomous University of Mexico</orgName>
								<address>
									<country key="MX">Mexico</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="institution">Junshi XIA</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="institution">RIKEN</orgName>
								<address>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff4">
								<orgName type="department">Sergey Dudov</orgName>
								<orgName type="institution">Lomonosov Moscow State University</orgName>
								<address>
									<country key="RU">Russia</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Deep Species Distribution Modeling From Sentinel-2 Image Time-Series: A Global Scale Analysis on the Orchid Family</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2022-04-22">22 April 2022</date>
						</imprint>
					</monogr>
					<idno type="MD5">7B820F353633F0DB2AF312CF160608DA</idno>
					<idno type="DOI">10.3389/fpls.2022.839327</idno>
					<note type="submission">This article was submitted to Technical Advances in Plant Science, a section of the journal Frontiers in Plant Science Received: 19 December 2021 Accepted: 28 February 2022</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-04-12T14:49+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid" />
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>species distribution modeling</term>
					<term>deep learning</term>
					<term>image time-series</term>
					<term>Sentinel-2</term>
					<term>convolutional neural networks</term>
					<term>remote sensing</term>
					<term>macroecology</term>
					<term>data science Estopinan et al</term>
				</keywords>
			</textClass>
			<abstract />
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div><p>Species distribution models (SDMs) are widely used numerical tools that rely on correlations between geolocated presences (and possibly absences) and environmental predictors to model the ecological preferences of species. Recently, SDMs exploiting deep learning and remote sensing images have emerged and have demonstrated high predictive performance. In particular, it has been shown that one of the key advantages of these models (called deep-SDMs) is their ability to capture the spatial structure of the landscape, unlike prior models. In this paper, we examine whether the temporal dimension of remote sensing images can also be exploited by deep-SDMs. Indeed, satellites such as Sentinel-2 are now providing data with a high temporal revisit, and it is likely that the resulting time-series of images contain relevant information about the seasonal variations of the environment and vegetation. To confirm this hypothesis, we built a substantial and original dataset (called <software>DeepOrchidSeries</software>) aimed at modeling the distribution of orchids on a global scale based on Sentinel-2 image time series. It includes around 1 million occurrences of orchids worldwide, each being paired with a 12-month-long time series of high-resolution images (640 x 640 m RGB+IR patches centered on the geolocated observations). This ambitious dataset enabled us to train several deep-SDMs based on convolutional neural networks (CNNs) whose input was extended to include the temporal dimension. To quantify the contribution of the temporal dimension, we designed a novel interpretability methodology based on temporal permutation tests, temporal sampling, and temporal averaging. We show that the predictive performance of the model is greatly increased by the seasonality information contained in the temporal series. In particular, occurrence-poor species and diversity-rich regions are the ones that benefit the most from this improvement, revealing the importance of habitat's temporal dynamics to characterize species distribution.</p></div>
<div><head n="1.">INTRODUCTION 1.Context</head><p>Understanding and mapping species distributions is a major topic in conservation biology <ref type="bibr" target="#b56">(Pecl et al., 2017)</ref>. Species distribution models (SDMs) have recently become a key instrument: over the last 20 years, 6,000 peer-reviewed studies were found with this keyword according to <ref type="bibr" target="#b2">Araújo et al. (2019)</ref>. These statistical algorithms learn the correlations between species presence records (and possibly species absence records) and some environmental predictors provided. Under certain modeling assumptions <ref type="bibr" target="#b85">(Zurell et al., 2020)</ref>, they can estimate species distribution by generalizing learned habitat preferences over time and space <ref type="bibr" target="#b59">(Phillips and Dudík, 2008;</ref><ref type="bibr" target="#b75">Thuiller et al., 2009)</ref>. A major issue for the use of SDMs concerns the ecological relevance of the predictive variables used <ref type="bibr" target="#b29">(Fourcade et al., 2018)</ref>. Furthermore, collecting appropriate data at a large scale is usually very challenging. Global bio-climatic variables do not systematically provide enough information to draw conclusions on a species, presence. Many other factors like species dispersal capacities <ref type="bibr" target="#b51">(Monsimet et al., 2020)</ref> or shifts in land use actually come into play.</p><p>After having revolutionized computer vision, neural networks -and especially convolutional neural networks (CNNs) -are also increasingly recognized in ecology <ref type="bibr" target="#b79">(Williams et al., 2009;</ref><ref type="bibr" target="#b36">Heikkinen et al., 2012;</ref><ref type="bibr" target="#b9">Botella et al., 2018;</ref><ref type="bibr" target="#b12">Brodrick et al., 2019)</ref>. They allow identifying environmental patterns on images like tree crowns <ref type="bibr" target="#b20">(Csillik et al., 2018)</ref> or forest type limitations <ref type="bibr" target="#b78">(Wagner et al., 2019)</ref>. Local environment spatial structure has already been proven to add relevant information to SDMs involving convolutional layers <ref type="bibr" target="#b23">(Deneu et al., 2021b)</ref>.</p><p>In addition, remotely sensed data can grasp key features of vegetation functioning and thus convey relevant insights on species habitats <ref type="bibr" target="#b62">(Remm and Remm, 2009;</ref><ref type="bibr" target="#b0">Adhikari et al., 2012;</ref><ref type="bibr" target="#b35">He et al., 2015)</ref>. Unmanned Aerial Vehicles (UAVs) allow finer and finer-scale coverage at local, regional, or even country scale <ref type="bibr" target="#b44">(Kattenborn et al., 2020)</ref>. Thanks to such imagery, the nature and spatial structure of ecosystems can be characterized and learned in SDM training. RGB and IR image patches around species occurrences (or digitized geolocated presence of species) are thus added to the environmental predictors, so as to include information on vegetation and land-use heterogeneity around the occurrences <ref type="bibr">(Deneu et al., 2021a)</ref>.</p><p>Satellite missions like Copernicus Sentinel-2 (S2) <ref type="bibr" target="#b7">(Berger et al., 2012)</ref> now provide RGB and IR channels with fine spatial resolution and temporal revisit frequency worldwide (see <ref type="bibr">Section 2.1.1)</ref>, which can feed high-resolution, CNN-based SDM models. However, there is still much potential ahead for bringing together remote sensing and deep learning <ref type="bibr" target="#b14">(Camps-Valls et al., 2021)</ref>. Remote sensing datasets that are (i) readily available for deep learning applications and (ii) exploiting the spatial, spectral, and temporal dimensions of new satellite missions are still very few. For instance, among the twenty-three benchmark datasets implemented in <software ContextAttributes="used">TorchGeo</software> <ref type="bibr" target="#b71">(Stewart et al., 2021)</ref>, only two encompass a temporal dimension. There is then an opportunity to build RGB+IR image time series around occurrences spread worldwide. By sampling S2 data for a whole year, prominence is given to the seasonal evolutions of the plants, habitats. These time series are capturing the signature of ecosystems phenology and productivity. Our hypothesis is that this information can significantly help SDM predictions.</p></div>
<div><head n="1.2.">Contributions</head><p>This paper contribution is 2-folds: First, we built a substantial and original dataset pairing nearly 1 million geolocated occurrences of the Orchidaceae family with satellite image time series. This dataset and the associated method scripts, released as open data and code, should be useful for conservation biologists and SDM users in general. To our knowledge, no similar ready-to-use dataset is already available. Second, we designed interpretability tests of the deep SDMs trained on this dataset in order to measure the importance of seasonal landscape variability in characterizing species habitat and niche. Figure <ref type="figure" target="#fig_0">1</ref> provides the visual abstract of our method.</p></div>
<div><head n="2.">MATERIALS AND METHODS</head></div>
<div><head n="2.1.">DeepOrchidSeries Dataset</head></div>
<div><head n="2.1.1.">Raw Input Data Description</head></div>
<div><head>Orchid Occurrences Dataset</head><p>The Orchidaceae family is of great interest because of its diversity (about 28,000 species estimated) and its aesthetic attractiveness <ref type="bibr" target="#b17">(Chase et al., 2015)</ref>. Orchids are of major concern for ecologists due to the numerous threats they are facing: habitat destruction, climate change, pollution, and illegal harvesting for horticulture and tourism industries <ref type="bibr" target="#b80">(Wraith and Pickering, 2018)</ref>. They are also considered as a relevant proxy of their ecosystem's health <ref type="bibr" target="#b53">(Newman, 2009)</ref>. Moreover, orchids are found on all continents in a wide range of habitats and they are blooming at very different altitudes. Such a range or environmental amplitude is difficult to achieve with other families, making the orchid family an excellent candidate for the purpose of our study (i.e., to measure the importance of seasonal variability in characterizing species habitat and niche).</p><p>Rather than collecting a new set of orchid occurrences to build our image time-series dataset, we decided instead to reuse the one introduced by <ref type="bibr" target="#b84">Zizka et al. (2021)</ref>. Their objective was different from ours (i.e., estimating the conservation status of orchids) but the set of occurrences they collected from GBIF meets two main criteria of interest for our study: (i) global scale and (ii) suitable data quality, thanks to several data filtering and cleaning processes (including the use of the R package <software ContextAttributes="used">CoordinateCleaner</software> v. 2.0-9, <ref type="bibr" target="#b83">Zizka et al., 2019)</ref>. The complete process they use is summarized in the Supplementary Table <ref type="table" target="#tab_0">1</ref> of their paper <ref type="bibr" target="#b84">(Zizka et al., 2021)</ref>. Another benefit of reusing <ref type="bibr" target="#b84">(Zizka et al., 2021)</ref>'s occurrence data is to support the potential reuse of our deep-SDM for the automated assessment of the orchid's IUCN status. In the long term, this will improve the reproducibility and comparability of newly developed methods in this regard.</p><p>In total, the dataset contains 999,407 occurrences of 14,148 species with 70 records per species on average, 4 in median, and 3,537 species (25%) with more than 13 observations. The (heavily-tailed) distribution of the number of occurrences per species is shown in Figure <ref type="figure" target="#fig_1">2A</ref> (through a Next, we conducted experiments where the input temporal dimension was modified (randomized, averaged or sampled) so as to measure its contribution to model performance. Layer 3: the results are finally broken down into three main dimensions of analysis: species frequency in the dataset, bioregion, and species diversity in these bioregions. The analysis reveals that occurrence-poor species and diversity-rich regions are the ones that benefit the most from the improvement provided by the temporal information.</p></div>
<div><head>Lorenz curve)</head><p>. Figure <ref type="figure" target="#fig_1">2B</ref> represents the temporal distribution of the occurrences in the dataset. Half of the observations dated from 1997, one quarter from 2010. A total of 14.6% of the set (145,641 occurrences) came with no timestamp at all. The oldest occurrence was from 1901 as a result of the filtering process that got rid of data records older than 1900. Only observations with a position uncertainty higher than 100 km were discarded.</p><p>Perspectives and limits related to the use of such a large and imbalanced occurrence dataset will be discussed in the final Section 4.</p></div>
<div><head>Sentinel-2 Multispectral Images</head><p>Sentinel-2 multispectral data comes from two identical satellites in the same orbit but diametrically opposite to one another. Sentinel-2A was launched on 23 June 2015 and its counterpart Sentinel-2B on 7 March 2017. This satellite mission is part of the European Earth observation project Copernicus 1 , previously known as Global Monitoring for Environment and Security (GMES, <ref type="bibr" target="#b24">Drusch et al., 2012)</ref>. Thirteen channels from the visible to short-wave infrared are monitoring the planet, with 10, 20, or 60 m spatial resolution and a 5-day temporal revisit above any point on Earth. Additional satellites 2C and 2D are planned to ensure continuity in the coming years and the next generation of Sentinel-2 satellites are being prepared. We only kept four out of the thirteen channels, i.e., the three RGB channels and the Infrared (IR) channel (842 nm). These wavelengths are expected to convey the most relevant information about the environment <ref type="bibr" target="#b35">(He et al., 2015)</ref> and are also the finer in terms of spatial resolution (10 m). The smallest geographic units downloadable via the sentinelsat 2 <software ContextAttributes="used">API</software> are 109.8 km × 109.8 km square data tiles in WGS84/UTM projection. They were defined following a military grid splitting Earth planisphere. The field square from a given satellite orbit at a given sensing time interval does not always cover a whole tile so that several products must be merged and cropped to get an image of the whole tile.</p><p>Data products are made available to the user at two distinct levels: Top-of-Atmosphere (TOA or 2C) and Bottomof-Atmosphere (BOA or 2A). The important difference is the application of an atmospheric correction algorithm such as 1 https://www.copernicus.eu/en 2 https://sentinelsat.readthedocs.io/en/stable/ Sen2Cor <ref type="bibr" target="#b48">(Louis et al., 2016;</ref><ref type="bibr" target="#b40">Ientilucci and Adler-Golden, 2019)</ref>. Water vapor and other atmospheric components alter the satellite image caption with complex non-linear deformations. When and how atmospheric correction should be performed prior to exploiting remote sensing data depends on the desired information and thus the targeted application. About classification and change detection tasks, a recognized work from <ref type="bibr" target="#b69">Song et al. (2001)</ref> advises performing simple corrections only when multi-temporal data is used. Otherwise, having both training and test sets from the same relative scale proved to be sufficient: no significant performance gain would result from the addition of an atmospheric correction step. A more recent article estimating the relation between sea surface salinity and Sentinel-2 Imagery with a neural network and 2,700 points obtained better results with TOA than BOA imagery (Medina-Lopez, 2020). On their specific application, they found that the atmospheric correction entailed information loss due to alteration of actual multispectral relationships. They also observed that the time and computational resources spared by using the level 2C products were an important element to consider. Using L1C products time-series, <ref type="bibr" target="#b65">Rußwurm and Körner (2018)</ref> obtain state-of-theart land cover classification performances. Level 2A products are not readily available at the global scale and, when needed, atmospheric corrections have in this case to be applied by users. Considering the conclusions of previous surveys and the large size of the targeted data, we decided to work with TOA products. Moreover, the atmosphere information could be valuable for our application and we suggest that deep-SDMs are capable of correctly learning without this additional filter. </p></div>
<div><head n="2.1.2.">Dataset Construction</head><p>Figure <ref type="figure" target="#fig_2">3</ref> summarizes the workflow followed to obtain image time-series from a set of geolocated occurrences. The first step is to define the set of Sentinel-2 tiles containing all targeted occurrences, for which more details are provided in the Global scale processing paragraph. The second and third steps are used to define the patch size and the time sampling strategy, respectively. Our choices are presented in the two dedicated paragraphs hereafter. Finally, the last paragraph introduces our method to select the least cloudy S2 data.</p><p>We have furthermore considered only the four spectral bands available at 10 m resolution, but our workflow could be applied as well to bands at 20 m and 60 m resolution after a downsampling step. Sentinel-2 queries and downloads were made with the Scihub Copernicus <software ContextAttributes="used">API</software><ref type="foot" target="#foot_2">3</ref> . We then extracted the patches by parallelizing the processing by UTM zone to gain speed. Code and details are available at https://gitlab.inria.fr/jestopin/ sen2patch.</p></div>
<div><head>Global Scale Processing</head><p>The first step consists then in defining the minimal set of Sentinel-2 tiles containing all our orchid observations. The Sentinelsat python <software ContextAttributes="used">API</software> provides the option to query data by various geographical means, mainly, coordinates, polygons, tiles, or satellite orbits. However, querying the <software ContextAttributes="used">API</software> on an occurrence-by-occurrence basis for a dataset containing nearly one million occurrences is counterproductive. It is much more efficient to first download the tiles containing occurrences and then extract them locally (as shown in Figure <ref type="figure" target="#fig_4">4A</ref> for the histogram of the number of occurrences per tile). To do so, we implemented the following two steps:</p><p>• First, we created a dictionary linking each tile with its WGS84 geometry thanks to the Sentinel-2 Level-1C tiling grid provided by the ESA Sentinel-2 official portal<ref type="foot" target="#foot_3">4</ref> . • Then, an iterative process on all occurrences was implemented, testing each time if the new observation is included in the union of the already retained tiles set. If not, a tile containing the occurrence location is downloaded and added to the set.</p><p>The final tiles set map is given in Figure <ref type="figure" target="#fig_4">4C</ref>. It illustrates the full geographical scope of the dataset with 7,563 targeted tiles. A total of 50% of all land areas (Antarctica excluded) were included in the collected data. The color scale proportional to the number of observations per tile (with a log10-scale) further shows a geographic (or observation) bias in the occurrences set: Europe, south Australia, and New Zealand are gathering huge numbers of records.</p></div>
<div><head>Patch Size</head><p>The size of the patches associated with each occurrence is an important hyper-parameter to set. Patches should be large enough to contain the most relevant spatial information, but not too large to avoid introducing patterns that are too distant from the occurrence. They should also be large enough to compensate for the geographic imprecision of the occurrences (as shown in geolocation uncertainty distribution Supplementary Figure <ref type="figure" target="#fig_0">1</ref> and <ref type="bibr" target="#b81">Wüest et al., 2020)</ref>, but not too large to avoid computational issues. Considering all that constraints, our final choice was patches of size 640 m × 640 m (only powers of two were considered to optimize memory usage).  </p></div>
<div><head>Time Series Extent and Temporal Resolution</head><p>One of the main contributions of our study is to consider time series of satellite images rather than a single date image, with the objective of better characterizing the habitat of species. Two important parameters in this regard are the temporal extent of the series and its resolution. Here too, there is a compromise to be made. The extent and resolution must be high enough to capture important (spatio-)temporal patterns, but cannot be too high due to computational constraints. We finally chose a 1-year time series with a resolution of 1 month (i.e., twelve images, one per month). Such 12-month time series allow grasping the main seasonal variations of the environmental and ecological context including vegetation phenology, yearly weather variations as well as landscape annual variations linked to human activity (e.g., agriculture). Noticeably, such seasonal variations are often neglected in SDMs devised at a global scale. Figures <ref type="figure" target="#fig_5">5A,</ref><ref type="figure">B</ref> show significant seasonal changes that can largely help models to differentiate species habitats. In Figure <ref type="figure" target="#fig_5">5A</ref>, the tree cover greatly vary depending on the season and in Figure <ref type="figure" target="#fig_5">5B</ref> snow covers the field half of the year. What if we only had 1 month of data? Environmental contexts would be characterized very partially and wrong inferences could be done on species ecological preferences (imagine having only one image covered by snow for Figure <ref type="figure" target="#fig_5">5B</ref>). These examples illustrate the gain of ecologically relevant information when considering a 12-month image-series.</p><p>Another parameter to be set is the starting date of the time series. Ideally, it should be chosen so that the date of the occurrences is included in the 1-year period covered for the time series. There are various reasons in practice impeding a perfect match between the occurrences dates and the associated predictive data. To begin with, the Sentinel-2 satellite was launched only in 2015 so that older occurrences cannot be matched. Second, all occurrences do not come with a precise date, some having no date information at all. Third, some S2 tiles from the defined minimal set would have to be downloaded a huge number of times to inform all observations at different dates. Lastly, there is no simple and open access to data older than a rolling year on Copernicus Open Access Hub. Because of all that constraints, we finally chose a fixed period for all 12-month time series, with a starting date of 1 March 2020 and an ending date of 29 February 2021 (the choice of the recent period being linked to the temporal distribution of the number of occurrences, as shown in Figure <ref type="figure" target="#fig_1">2B</ref>).</p></div>
<div><head>Data Selection Based on Cloud Cover</head><p>Remote sensing data at RGB/IR channels are directly dependent on potential clouds covering the satellite's field of view. Fortunately, S2 products are including in their metadata the percentage of the scene view corrupted by cloud cover. Thereby when querying the Sentinelsat <software ContextAttributes="used">API</software> over a given area and time window, one can ask to only keep the less cloudy products. The wider the chosen time window is, the more likely an almost cloud-free product will be available within. Based on this metadata, we selected the least cloudy S2 products within each month in the targeted time window. With this selection process, we expect the large majority of time series to be cloudfree like Figures <ref type="figure" target="#fig_5">5A,</ref><ref type="figure">B</ref>. Figure <ref type="figure" target="#fig_6">6</ref> provides an overview of the cloud coverage distribution in selected products compared to all available products in the queried time window. When, despite our efforts to select the least cloudy products, the obtained satellite data around an occurrence present many cloudy frames, it could nonetheless be interpreted as a piece of information contributing to the species, ecological niche. Furthermore, in this case, the environment structure can still be captured from clear scenes at other dates of the time series (see for instance April, May, and November 2020 on Figure <ref type="figure" target="#fig_5">5C</ref>).</p></div>
<div><head n="2.2.">SDM Trained With Satellite Image Series</head><p>In this section, we describe the architecture and learning procedure of the deep-SDMs that we trained based on the <software>DeepOrchidSeries</software> dataset described above. Given an image time series as input, the model estimates orchids, relative probabilities of presence.</p></div>
<div><head n="2.2.1.">Model Definition and Training Procedure Model Architecture</head><p>The model used is an extended version of the Inception v3 <ref type="bibr" target="#b74">(Szegedy et al., 2016)</ref> CNN. Inception networks are appreciated because of their capacity to grasp patterns -here environmental patterns-at multiple scales. It has been shown by <ref type="bibr" target="#b23">Deneu et al. (2021b)</ref> that this architecture provides better species prediction performance than point neural networks, boosted trees, or random forests. We use this work to justify our choice of model. Nevertheless, testing other recent neural architectures specifically designed to deal with spatio-temporal data is an avenue to be exploited in the future, see the second perspective of the discussion. In particular, the performance gain was shown to be the most significant for rare species. In our context, the Inception v3 architecture was modified so as to accept not only RGB images but the full RGB+IR image time series. Our inputs are of size (N f , N x , N y ) with N f the number of features equal to 12 * 4 = 48 (12 months x 4 RGB+IR channels) and N x = N y = 64 (corresponding to 640 x 640 m quadrats at 10 m resolution). To speed up the training and regularize the model, batch normalization <ref type="bibr" target="#b41">(Ioffe and Szegedy, 2015)</ref> was applied on the convolutional layer activations, just before the nonlinear ReLu function. Dropout <ref type="bibr" target="#b70">(Srivastava et al., 2014)</ref> was finally used to prevent the network from overfitting (with a dropout probability of 0.5).</p></div>
<div><head>Model Loss</head><p>The models were trained using the LDAM loss (Label-Distribution-Aware Margin, <ref type="bibr" target="#b15">Cao et al., 2019)</ref> designed for strong class-imbalance multi-class classification problems. In our context, it allows pushing upward rare species performance without deteriorating predictions on common species. The LDAM loss is a label-distribution-aware function that leads the model to an optimized trade-off between per-class margins. When considering two species only, say one rare and one common, the decision boundary drawn by this loss will be slightly shifted toward the common species in order to let the benefit of the doubt to the rare species (refer to <ref type="bibr" target="#b15">Cao et al., 2019</ref> Figure <ref type="figure" target="#fig_0">1</ref> for a meaningful scheme). The LDAM loss has been shown to perform very well in many deep learning benchmarks involving both a strong imbalance between classes and a high inter-class ambiguity.</p></div>
<div><head>Training Procedure</head><p>The models were fitted using stochastic gradient descent on multi-GPU nodes from Jean Zay, an IDRIS supercomputer 5 . Convolutional and linear layers weights were initialized from a truncated normal continuous random variable. The deferred reweighting (DRW) training schedule associated with the LDAM loss was used. DRW is a vanilla empirical risk minimization (ERM) until a given epoch, here 65. Then, the training ends with a re-weighted loss and SGD steps with a re-normalized learning rate, both by batch species frequency. The learning rate was initialized to 0.1 and later decayed by a factor of ten at epochs 50 and 65. A trained model is approximately 600 MB.</p></div>
<div><head n="2.2.2.">Performance Evaluation of the Model Data Split</head><p>The <software ContextAttributes="used">DeepOrchidSeries</software> dataset was split into three parts: (i) Training set (90%), (ii) Validation set (5%), and (iii), Test set (5%). Following the recommendations of <ref type="bibr" target="#b63">Roberts et al. (2017)</ref>, the split was done using a spatial blocking strategy that enables a more robust estimation of the performance of the model. The spatial blocks were defined in the spherical coordinate system according to a 0.025 • grid, i.e., square blocks of 2.775 km at the equator. Splitting by block is important to impede the model from being validated or tested at locations very close to the training occurrences. In addition to the spatial blocking, we also used a stratified sampling strategy to ensure that any region of the world has a minimal number of blocks in the training set. We, therefore, used the WGSRPD level 2 regions <ref type="bibr" target="#b13">(Brummitt et al., 2001)</ref>. Within each region, we randomly sampled 90% of the blocks present and assign them to the training set. The remaining blocks were assigned to either the validation set or the test set (at random). Validation and test occurrences from species that were not in the training set were removed. Table <ref type="table" target="#tab_0">1</ref> provides the number of occurrences and species in each set.</p></div>
<div><head>Evaluation Metrics</head><p>Our model being trained with a multi-class classification loss on presence-only data, its output is a categorical probability distribution of the form η s (x) = P(Y = s|X = x) where x is the input tensor (i.e., an RGB+IR image time-series), Y the observed species and η s (x) is the estimated probability that the observed species is s conditionally to x. Because the output is a categorical probability distribution, we have that the sum of probabilities over all species is equal to one ( m s=1 η s (x) = 1). To evaluate the model, we chose not to use pseudo-absences because of the bias induced by such methods <ref type="bibr" target="#b60">(Phillips et al., 2009;</ref><ref type="bibr" target="#b10">Botella et al., 2020)</ref>. Instead, we used a set-valued metric <ref type="bibr" target="#b18">(Chzhen et al., 2021)</ref> to assess the quality of the species assemblage predicted by the model for a given input. Specifically, we chose the commonly used top-k accuracy as suggested in <ref type="bibr" target="#b11">Botella et al. (2019)</ref>. It measures the success rate of the model when it returns the top-k most probable species for any input x. More formally</p><formula xml:id="formula_0">A k = n i=1 A k (i) n (<label>1</label></formula><formula xml:id="formula_1">)</formula><p>where n is the number of occurrences in the test set (or validation set) and</p><formula xml:id="formula_2">A k (i) = 1 if η y i (x i ) ≥ ηk (x i ) 0 otherwise</formula><p>with y i the true species label of occurrence x i and ηk (x i ) the outputs of the model re-ordered in decreasing order of probabilities.</p><p>Because of the high-class imbalance of our dataset, a shortcoming of this metric applied on all test occurrences taken together (or micro-average, <ref type="bibr" target="#b68">Sokolova and Lapalme, 2009)</ref> is that it gives far too much importance to the most frequent species over the less frequent ones. To compensate for this imbalance, it is preferable to use the macro-average version of this metric <ref type="bibr" target="#b68">(Sokolova and Lapalme, 2009)</ref> consisting of first calculating the score of each species and then averaging the scores over all species. More formally, the macro-average top-k accuracy can be defined as</p><formula xml:id="formula_3">MSA k = l s=1 SA k,s l (<label>2</label></formula><formula xml:id="formula_4">)</formula><p>where l is the number of species in the test and SA k,s is the top-k accuracy for species s defined as</p><formula xml:id="formula_5">SA k,s = y i =s A k (i) n s<label>(3)</label></formula><p>with n s the number of occurrences of species s in the test set.</p><p>During the training phase of the model, the macro-average topk accuracy (MSA k ) is computed on the validation set every two epochs for k = 30. The model selected in the end is the one with the highest value.</p><p>To analyze the performance of the model according to the number of occurrences available in the training set, we also measured the macro-average accuracy on subsets of species categorized by a range of their number of occurrences. If we denote as N s the number of occurrences of a species s in the training set, we can define as S I = {s| N s ∈ I, n s &gt; 0} the set of species in the test set having a number of training occurrences in a given interval I. The macro-average accuracy for a given interval I is then defined as</p><formula xml:id="formula_6">MSA k,I = s∈S I SA k,s |S I |<label>(4)</label></formula><p>Another batch of experiences will focus on performances per geographic region. Spatial units are taken from the World Geographical Scheme for Recording Plant Distributions book <ref type="bibr" target="#b13">(Brummitt et al., 2001)</ref>. The level 3 division defines the botanical countries that we exploit. Performance per region r is denoted as RA k,r and is defined as the micro-average top-k accuracy computed only on the occurrences encompassed in r:</p><formula xml:id="formula_7">RA k,r = x i ∈r A k (i) n r<label>(5)</label></formula><p>where n r is the number of test occurrences in r. Regions with n r fewer than 50 occurrences were excluded as statistically insignificant. Further, performance per region is compared with region's species diversity. Therefore, we computed the diversity index q D r of each region r according to the definition of <ref type="bibr" target="#b39">Hill (1973)</ref> and <ref type="bibr" target="#b43">Jost (2006)</ref>. It is a quantitative measure of biodiversity combining, in a given region, species richness with species relative prevalence. The term prevalence is used instead of abundance to account for the observation bias in our data. Species richness corresponds to the number of distinct species observed (denoted L r ). Species relative prevalence is the share of species occurrences compared to all region's observations: p s,r equals n s,r n r , with n s,r the number of test occurrences from species s in r. The general expression of the region's diversity index is</p><formula xml:id="formula_8">q D r =          L r s=1 p q s,r 1 1-q if q = 1 exp -L r s=1 p s,r ln(p s,r ) if q = 1 (6)</formula><p>where q is a parameter weighting the trade-off between the importance granted to species richness (small value) vs. relative prevalence (big value). 0 D r results in regional species richness and 1 D r is the exponential of the Shannon entropy <ref type="bibr" target="#b67">(Shannon, 1948)</ref>. Performance per region is then averaged per category I on the diversity index and written as MRA k,I .</p><p>In the literature, the majority of studies involving species diversity use it as a response variable. They are focusing on its potential drivers like bio-climatic variables, topographic heterogeneity, or forest structure <ref type="bibr" target="#b76">(Thuiller et al., 2006;</ref><ref type="bibr" target="#b34">Hakkenberg et al., 2016)</ref>. Here, we exploit species diversity as an explanatory variable possibly explaining our model performances. In a similar manner, <ref type="bibr" target="#b25">Emerson and Kolm (2005)</ref> defended that species diversity is a driver of speciation and <ref type="bibr" target="#b21">(Dawud et al., 2016)</ref> examined its influence on soil carbon stocks among others.</p></div>
<div><head n="2.2.3.">Interpretability Experiments: Quantifying the Contribution of Temporal Information</head><p>We designed several tests to analyze to what extent the trained model uses the temporal information contained in the image time series. The general principle is to transform the input data in order to suppress some information and to retrain a new model based on this transformed data. The comparison of the model deprived of information with the original model then allows quantifying the importance of the suppressed information. Figure <ref type="figure" target="#fig_8">7</ref> gives a comprehensive overview of the procedure detailed hereafter:</p><p>M Original time-series. This is the default original model where the input image time series are kept unchanged (stacked in chronological order). Here, the model can learn from the temporal dynamics present in the series. The filters learned by the Inception v3 model are themselves ordered feature maps time series of 12 months and are likely to capture spatio-temporal redundancies in the input data (e.g., seasonal variations of the environment or phenological patterns).</p><p>M 1 Random permutation. In this model, the 12 images of the original time series are randomly shuffled so that the model can no longer base its predictions on the actual temporal sequencing <ref type="bibr" target="#b32">(Garnot et al., 2019)</ref>. All input variance and spatial information remain nonetheless in the input. The filters learned by the Inception v3 model can neither be specialized by month nor can the model differentiate relations between months input. It actually learns from the block of 12 months considering them all equally. This procedure is comparable to the variable importance technique where a given input variable is randomized across samples to test how the model performs without its contribution. However, here, we do not randomize a given feature across samples, but features order independently for each sample. M 2 Temporal averaging. In this model, the input image series are reduced to the mean over the 12 months replicated twelve times. Only the first moment of the distribution over the time dimension is kept and the model only "sees" a mean landscape averaged along the year. The objective here is to test to what extent a simple temporal averaging is sufficient to sum up most of the temporal variation. Each month contributes equally to the mean and the result is blurry. The variance between months has been totally removed. Ecological gradients of the different patch elements are reduced to their sum divided by twelve.</p><p>M 3 Temporal sampling. In this model, the input image series are reduced to only 1 month picked at random and replicated twelve times. The neural network is being provided with only a twelfth of the predictive data and is deprived of any temporal information.</p><p>Please notice that for each of the cases (M 1 , M 2 , and M 3 ), the data transformation is applied once on the whole dataset (including training, validation, and test set) before the model is trained and evaluated. Model M 1 being deprived only of the months, order information, its comparison with Model M can be interpreted as a statistical test of the hypothesis that the composition of species depends on the existence of months specific features, in particular the ones resulting from yearly seasonality cycles. The comparison between M and M 3 can be interpreted as a test of the hypothesis that the species composition does or does not depend on any temporal variability. Model M 2 can be seen as an intermediate scheme where the temporal variability is summarized only by the mean of the distribution. Accordingly, the comparison between M 1 and M 2 allows assessing how useful statistical moments of a higher order than the mean are for characterizing the temporal variability.</p><p>To compare the performances of two different models, say M and M i with i ∈ {1, 2, 3}, for a given species s in the test set, we set a metric down called relative performance change of M i compared to M, defined as</p><formula xml:id="formula_9">S k,s (M, M i ) = SA k,s (M) -SA k,s (M i ) SA k,s (M)<label>(7)</label></formula><p>where SA k,s is the top-k accuracy of species s (see Equation <ref type="formula" target="#formula_5">3</ref>).</p><p>In the same manner that we defined the macro-average accuracy per category I on the species training set's number of occurrences, we can now consider the mean relative performance change per category between two models:</p><formula xml:id="formula_10">MS k,I (M, M i ) = s∈S I S k,s (M, M i ) |S I | (8) Relative region performance change R k,r (M, M i ) is also calculated as RA k,r (M)-RA k,r (M i ) RA k,r (M)</formula><p>. This measure is averaged per category I on the diversity index as well and is represented by MR k,I (M, M i ).</p><p>When computing S k,s (M, M i ) (resp. R k,r (M, M i )) between M and M i models for a given species s (resp. a given region r), it is beforehand necessary to make sure that the denominator, SA k,s (M) (resp. RA k,r (M)), is not null. It can sometimes be when the model M fails to predict the correct label for all s occurrences (resp. all occurrences in r). In this case, no performance change can be calculated since it is already null. Species s (resp. region r) is then removed from the calculation of the mean performance change by categories on species training set number of occurrences (resp. on regions diversity index). This is why there is a drop of support between Figure <ref type="figure" target="#fig_10">9</ref> (resp. Figure <ref type="figure" target="#fig_11">10</ref>) left and right graphs, i.e., there are fewer species (resp. regions) encompassed in the categories, as indicated on the horizontal axis. This effect is a lot more important on the support of the species mean performance change than on the region's one. To sum up, relative performance change cannot be calculated for species or regions having already the lowest possible score with the whole temporal information. They are in that case discarded from the mean performance change calculation. The image time-series A (black legend) corresponds to the original data, i.e., to the images stacked in chronological order. The image series B 1 (green legend) is obtained by randomly permuting the original time series. The image series B 2 (red legend) is made of 1 month picked at random and replicated N times. The image series B 3 (blue legend) is constructed by averaging the 12 images of the original time series and replicating the resulting mean image N times. Please note that the same legend's colors will be used in the figures of the paper presenting the results of these experiments.</p></div>
<div><head n="3.">RESULTS</head></div>
<div><head n="3.1.">Model Validation and Performance</head><p>The top-30 and macro-average top-30 accuracy of the four models (M, M 1 , M 2 , and M 3 ) are presented on Figure <ref type="figure" target="#fig_9">8</ref> (at each epoch of the training phase for the validation set and on the test set for the final selected model). Due to the long-tail distribution of species occurrences (Figure <ref type="figure" target="#fig_1">2A</ref>), the top-30 accuracy A 30 is representative of the performance on the most common species whereas the macro-averaged top-30 accuracy MSA 30 is more representative of the performance of the rare species. The final increase in the MSA 30 score at epoch 65 is due to the DRW optimizer previously described: re-weighting the loss toward training's end enables a boost on rare species performances <ref type="bibr" target="#b15">(Cao et al., 2019)</ref>. The top-30 accuracy A 30 tends to slightly decrease after the first quarter of the training phase. Our hypothesis is that this is mainly due to the use of the LDAM loss: as the training goes by, the models are reaching a better estimation of rare species ecological niche and tend to predict them more often to the detriment of common species that were chosen by default.</p><p>The model M trained and tested with the original time series provides better results than the three other models deprived of temporal information. M is the only one where the temporal dynamics are undamaged and hence fully exploitable to statistically draw predictions. The macro-average top-30 accuracy is 0.286 for the unaltered model M, against 0.216 for M 1 trained on shuffled data, 0.215 for M 2 trained on the yearly mean, and 0.149 for M 3 trained on a single random month.</p><p>The following analyses can be made of these results: 1. The strong performance decrease between M and M 3 shows that the temporal information contained in the time series is a key factor of the predictive performance. For most species, it appears to be as important as the spatial information alone (cf. macro-average accuracy plot MSA 30 ). 2. The comparison between M and M 1 shows that the decisive temporal information is largely related to the order of the images in the time series, i.e., to the months, specific features captured by the model (such as the ones resulting from yearly seasonality cycles). 3. The comparison between models M 1 and M 2 shows that their performances is almost identical (cf. MSA 30 plot). This means that the decisive information related to the unordered temporal variability can be synthesized efficiently by the mean of the time series. In other words, higher order statistical moments of the temporal dynamic independent from the time of the year are likely to be useless for predicting species composition (e.g., the standard deviation of acquisition noise). 4. The comparison between models M 1 and M 3 shows that the decisive temporal information is also largely explained by the unordered temporal variability of the images (typically due to some stochastic processes independent from the time of year).</p></div>
<div><head n="3.2.">Results by Number of Species Occurrences</head><p>Figure <ref type="figure" target="#fig_10">9A</ref> displays the performance of the four models as a function of the number N s of species occurrences in the training set (cf. equation 4). Not surprisingly, we can observe that the accuracy of the model is positively correlated with the number of occurrences. The more the occurrences in the training set and the better the top-30 accuracy. It should be noted, however, that the performance on the rarest species remains much better than that of a random predictor. Species having between 3 and 10 occurrences, for instance, are predicted in the set of the top-30 most probable species in 17% of the cases. A random predictor over the 13,700 species of the training set would have a top-30 accuracy below 0.22%. Figure <ref type="figure" target="#fig_10">9B</ref> displays the mean relative performance change between the unaltered model M and the three models M i (i ∈ {1, 2, 3}) as a function of the number of species occurrences (as shown in Equation <ref type="formula">8</ref>). It shows that the relative performance drop is inversely correlated with the species, number of occurrences. In other words, the rarer the species (in the data), the higher the performance gain obtained thanks to the temporal information. This can be explained by the fact that this is precisely on rare species predictions that the room for improvement is the bigger, as depicted on graph Figure <ref type="figure" target="#fig_10">9A</ref>. The use of time series thus makes it possible to compensate for the lack of occurrence data by increased knowledge of the temporal dynamics of the environment.</p></div>
<div><head n="3.3.">Results by Region and Regional Diversity Index</head><p>Figure <ref type="figure" target="#fig_11">10</ref> displays all results related to the regional analysis of our models.</p><p>The first sub-graph Figure <ref type="figure" target="#fig_11">10A</ref> shows that the predictive performance of the four models is negatively correlated with the regional diversity index. Regions with small diversity indexes 1 D r are the ones where the model predictions are the better. On the contrary, regions with high diversities show the models achieve poor performance. With q = 1, the diversity index equals the Shannon entropy exponential. This measure strongly depends on species richness. Hence, areas with high diversities are where there is a lot of possible different orchids. This means many possible classes for the models and a high risk of confusion between species with similar environmental preferences. Moreover, these areas are often including a lot of rare species and/or are still poorly observed. Regions with low 1 D r values are regions with relatively low species richness and tend to encompass common species that the models are predicting well (as shown in Figure <ref type="figure" target="#fig_10">9A</ref>).</p><p>The second sub-graph 10B) displays the relative performance change when comparing the model M to M i models, as a function of the regional diversity index. The most obvious trend is the red curve: when totally deprived of the habitat temporal dynamics, predictions on most diverse regions are proportionally more impacted than on low diversity regions. The tendency is more irregular for M 1 and M 2 but is globally valid too. It implies that, similar to rare species in Figure <ref type="figure" target="#fig_10">9B</ref>, the temporal information especially benefits highly diverse areas. The enlightenment of this tendency also is that this is where the room for improvement is the largest. Models especially take advantage of further temporal information to progress on hard tasks. Supplementary Figure <ref type="figure" target="#fig_1">2</ref> presents the results of the same experience but with categories formed on regions' the number of occurrences in the training set N r , the total number of occurrences entailed in region r during training. Unlike Figures <ref type="figure" target="#fig_11">10A,</ref><ref type="figure">B</ref>, no tendency can be drawn. It reaffirms our idea that it is region's diversity that is driving results spatially and not only the observation bias.</p><p>The map displayed in Figure <ref type="figure" target="#fig_11">10C</ref> depicts the top-30 accuracy per region achieved by the model M (i.e., the unaltered model with original time-series). A clear difference in performances can be observed between the southern and northern hemispheres. Looking at regions' diversity index 1 D r , written in green on the map, allows a better understanding of this gap. Northern regions (especially northern Europe) are presenting fewer species and are well sampled whereas regions around and below the equator (Australia excepted) are a lot more diverse and still insufficiently observed. Models, average performances are actually quite consistent on the Earth parallels. This map is the direct illustration of the Figure <ref type="figure" target="#fig_11">10A</ref> black curve.</p><p>Finally, map Figure <ref type="figure" target="#fig_11">10D</ref> shows that where the loss of the temporal information impacts the more the performances. It corresponds to red curve of Figure <ref type="figure" target="#fig_11">10B</ref> when the model trained with only one randomly picked and duplicated data month is compared to the reference model trained with full time series. Relative performance decreases in very diverse regions like southern China or Bolivia are really pronounced. On the contrary, performances in countries with low orchid diversities and well-observed like Norway of Finland are relatively spared by the input reduction.</p></div>
<div><head n="3.4.">Statistical Tests</head><p>A t-test between M and M 1 species micro-average accuracies SA 30,s (M) and SA 30,s (M 1 ) does confirm that results are notably different (p-value of 5e-42). The same conclusion arises from the comparison of the average top-30 accuracy per region: MRA 30 (M) = 0.591 with ordered data against MRA 30 (M 1 ) = 0.509 without, a p-value of 3.5e-9. This confirms that the order of the images in the time series does matter and that providing the data stacked in chronological order leads to significantly better performances than when providing data in random order.  </p></div>
<div><head n="3.5.">Model Evaluation Regarding Time and Spatial Data Mismatches</head><p>Figure <ref type="figure" target="#fig_12">11A</ref> reveals a marked gradient of performance depending on test occurrence observation year. This analysis discarded 15% of the 50,375 test occurrences presenting no observation date information. Each quartile includes approximately 11,000 points. Both micro and macro top-30 accuracy seem to be linearly correlated to the occurrence observation year quartile. The linear behavior is confirmed when choosing a division with a thinner percentile. Top-30 performances on the last quartile 2010-2019 are impressive: 0.834/0.484 of micro/macro average accuracy. When cutting the test set data at the median 1997, i.e., considering separately the oldest and the most recent half of test observations, performances are of 0.703/0.281 (oldest half) and 0.811/0.409 (most recent half). Moreover, it should be noted that all macro-average performances calculated on the test set's subsets are comparatively higher than overall performances because less distinct species are considered (as shown in Figure <ref type="figure" target="#fig_12">11</ref> species number in bold, against 4, 261 in the entire test set).</p><p>Figure <ref type="figure" target="#fig_12">11B</ref> focuses on the influence of test occurrence coordinates uncertainty on model performance. Test set is divided by quartiles on the studied variable, likewise Figure <ref type="figure" target="#fig_12">11A</ref>. In total, 31% of test observations do not include any information on coordinates uncertainty and are consequently put aside. Each quartile contains approximately 9,000 observations. Microaverage top-30 accuracy is identical on the first three quartiles and only drops when uncertainty is higher or equal than 5,000 m. Macro-average top-30 accuracy is similar when uncertainty is kept under 707 m, i.e., for the first two quartiles only (it is even slightly higher for the second one). Then, the macro-average performance goes a step down starting from the median of 707 m. Both micro and macro average performance are severely diminished when coordinates uncertainty is superior or equal to 5 km.</p></div>
<div><head n="4.">DISCUSSION</head></div>
<div><head n="4.1.">SDMs and Satellite Data</head><p>Remote sensing is an invaluable source of predictive features for SDMs and more widely for deep learning based earth observation applications <ref type="bibr" target="#b35">(He et al., 2015;</ref><ref type="bibr" target="#b82">Zhu et al., 2017;</ref><ref type="bibr" target="#b8">Borowiec et al., 2021)</ref>. Combined together, they offer a key opportunity in monitoring biodiversity facing climate change <ref type="bibr" target="#b61">(Randin et al., 2020)</ref>.</p><p>Species distribution models coupled with remote sensing data are often exploiting the widespread vegetation indexes Enhanced/Normalized Difference Vegetation Index (EVI or NDVI, <ref type="bibr" target="#b4">Bannari et al., 1995)</ref>. These indices are computed from satellite channels and are intended to reflect vegetation properties. The NDVI is said to assess photosynthetic activity and productivity <ref type="bibr" target="#b57">(Pettorelli et al., 2011)</ref>. Texture measures derived from satellite EVI were proven adapted to map habitat heterogeneity and bird species richness patterns <ref type="bibr" target="#b26">(Farwell et al., 2020)</ref>.</p><p>The WorldClim variables (weather station data interpolated with satellite-derived covariates, <ref type="bibr" target="#b38">Hijmans et al., 2005;</ref><ref type="bibr" target="#b28">Fick and Hijmans, 2017)</ref> certainly are the most widely used global SDM predictors <ref type="bibr" target="#b54">(Nogués-Bravo, 2009;</ref><ref type="bibr" target="#b73">Svenning et al., 2011)</ref>. This bio-climatic data approaches habitats, annual trends (e.g., annual precipitation) and seasonalities (e.g., temperature annual range and standard deviation). Contrary to our 1-year <software ContextAttributes="used">DeepOrchidSeries</software> dataset, here, the variables are averaged across several decades. Comparing the predictive power of these classic predictors (possibly completed with a land-cover raster) to our Sentinel-2 data will be the focus of future work.</p><p>Species distribution models and remote sensing data can also help rare species detection by capturing the biophysical conditions driving their distributions <ref type="bibr" target="#b16">(Cerrejón et al., 2021)</ref>. Recent studies have successfully leveraged the spatial structure of satellite images as input to CNN-based SDMs <ref type="bibr" target="#b23">(Deneu et al., 2021b)</ref>. Trained on fine-scale tensors, these models were proven able to learn and cluster species ecological preferences like annual mean temperature <ref type="bibr">(Deneu et al., 2021a)</ref>.</p><p>Regarding the use of the temporal dimension of satellite data in SDMs, few studies actually take advantage of it as underlined in <ref type="bibr" target="#b61">Randin et al. (2020)</ref>. In this regard, we can cite <ref type="bibr" target="#b19">(Cord and Rödder, 2011)</ref> who tried in 2011 to include EVI seasonality information in their SDMs inputs. Their study was however on a totally different range than us since they focused on eight Mexican anurans and used one-dimensional predictors.</p></div>
<div><head n="4.2.">Benefits of Deep-SDMs Trained on Remote Sensing Image Time-Series</head><p>The main outcome of our study is that using time-series of satellite images significantly improve Deep-SDM performance, in particular for rare species and in most diverse regions, supporting the interest of the approach for conservation science. Rare species are almost always threatened due to few occurrences means, without conservation measures, and greater extinction risk. Moreover, the world's most diverse regions include nearly all undiscovered species <ref type="bibr" target="#b42">(Joppa et al., 2011)</ref>. Better knowledge of the ecological niche of rare or little-prospected species should foster more appropriate and effective conservation measures to ensure their survival.</p><p>We collected time series of remote-sensing images to grasp the temporal variation in habitat properties. Our results confirm that this information is of high value to capture species, ecological niches and potential distributions. Our time series are also providing SDMs with the spatial structure of species habitats, a key information to enhance predictive performances <ref type="bibr" target="#b23">(Deneu et al., 2021b)</ref>.</p><p>Recent satellite missions offer both high temporal revisit frequency and high spatial resolution at the global scale, supporting the use of such data for niche modeling. The use of even more intensive remote sensing data, e.g., all products without any selection by month or on a wider time window, would probably allow even better estimation of ecological niche. That said, the Sentinel-2 data curation we devised here represents a good trade-off to acknowledge the phenology of orchid habitats at a broad spatial scale. Trying to avoid as much as possible clouds on selected images was also a sensitive point in our dataset creation workflow. A thinner temporal resolution would have resulted in richer time-series, but also a higher number of cloud frames. The question of whether the presence of clouds is in itself a piece of relevant information for characterizing the environment was not addressed in our study and remains nonetheless an open question.</p></div>
<div><head n="4.3.">Comparison With Other Open Remote Sensing Datasets for Deep Learning</head><p>Remote sensing datasets for deep learning applications are currently gaining much interest and are more and more accessible. The very recent launch of <software ContextAttributes="used">TorchGeo</software> <ref type="bibr" target="#b71">(Stewart et al., 2021)</ref>, a Python <software ContextAttributes="used">library</software> to easily handle geospatial datasets in the <software ContextAttributes="used">PyTorch</software> environment, illustrates the recent and still ongoing progress. However, the available datasets remain currently few and the temporal information provided by satellite revisits is almost never used <ref type="bibr" target="#b72">(Sumbul et al., 2019)</ref>. The available datasets are mostly used for land-cover classification <ref type="bibr" target="#b37">(Helber et al., 2019)</ref> or semantic segmentation <ref type="bibr" target="#b66">(Schmitt et al., 2019)</ref>, as described in the benchmark datasets provided in <software ContextAttributes="used">TorchGeo</software> (see <ref type="bibr" target="#b71">Stewart et al., 2021</ref> of Table <ref type="table" target="#tab_0">1</ref>). Sen12MS is for instance a global dataset including 180,662 patches of Sentinel-1/2 256 x 256 m images and MODIS-derived land cover maps <ref type="bibr" target="#b66">(Schmitt et al., 2019)</ref>. Another dataset, similar to ours in terms of spatial coverage, is named Seasonal Contrast (SeCo) <ref type="bibr">(Mañas et al., 2021)</ref> and was released in 2021. It gathers 2.65 km × 2.65 km Sentinel-2 image time-series around about 200 K locations worldwide. Time-series include 5 images separated by approximately 3 months. The objective was to learn an encoder that can be used for a variety of tasks, from land-cover classification to change detection. SeCo includes images from all over the world to represent a wide variety of landscapes. Among the currently available and open datasets, our dataset is, to the best of our knowledge, the only one providing monthly image data at so many points worldwide. In order to allow its reuse and the reproducibility of our experiments, the entire dataset is made publicly available with the Zenodo DOI 10.5281/zenodo.4972593. We also share the <software ContextAttributes="used">scripts</software> that allowed us to create it at https://gitlab.inria.fr/jestopin/sen2patch. In particular, these can be used to collect new image time series at locations other than those covered by our dataset.</p></div>
<div><head n="4.4.">Interpretability: In Which Cases Is the Modeling of the Temporal Dynamics the Most Beneficial?</head><p>One of the major conclusions of our study is that the regions benefiting the most from a performance gain due to the modeling of the temporal dynamics of satellite images are those with the highest species diversities. This conclusion may seem counterintuitive at first. Indeed, the regions with the highest diversities are often located toward the tropics and are not those with the most pronounced seasonal patterns. Consequently, the image time series in these regions are not expected to be the ones with the strongest temporal signal. However, it is important to understand that the model operates on a global scale with thousands of habitats to discriminate from each other. Whatever the temporal signature of a given habitat, it is a piece of useful information for distinguishing it from other habitats. At the extreme, the temporal signature of a constant habitat throughout the year is a strong marker of that habitat. A study led in Mediterranean natural habitats analyzed habitat discrimination from a variety of multispectral sensors answers simulated from field measurements, including Sentinel-2 <ref type="bibr" target="#b27">(Féret et al., 2015)</ref>. They showed that multi-temporal acquisitions outperform single data acquisition to discriminate habitats.</p><p>The reason for the higher performance gains in high diversity regions is actually more related to the higher model uncertainty in that regions. Species from these regions are indeed those for which there is the least amount of occurrence data available and our study clearly demonstrates that the performance gain is strongly correlated with this variable. In other words, our study shows that the addition of the temporal information allows reducing the model uncertainty related to the lack of occurrence data in high diversity regions. This result appears particularly interesting since habitats with the highest diversity and the rarest species are also the most threatened ones and modeling them is essential to put in place adapted conservation measures.</p></div>
<div><head n="4.5.">Key Considerations for Building New Models With Our Method or Using Existing Ones</head><p>Our method could be readily applied to other taxonomic groups than the orchids family. The ease and cost of implementation will mainly depend on the geographical distribution of the occurrences of the target taxon. With a family as large and widespread as the orchids, our method requires significant computing resources. Downloading Sentinel-2 tiles to a very large extent demands a lot of storage available (about 100Tb). To keep model training time reasonable, GPUs have to be used too. A computing cluster is more than welcome and the technical requirements can be a limitation for some researchers. However, once the dataset is built and the model is trained, predictions can perfectly be run on standard local machines. To this end, the model built for our study is shared publicly in the same Zenodo repository as the dataset (doi: 10.5281/zenodo.4972593). The new S2 image time-series as input can be used to predict species orchids composition anywhere on earth or to build highresolution maps of specific orchid species at a global scale. It may also be used for other ecological tasks via transfer learning approaches (i.e., keeping unchanged all the weights of the model except those of the last layer dedicated to species classification, <ref type="bibr" target="#b77">Torrey and Shavlik, 2010)</ref>.</p></div>
<div><head n="4.6.">On Temporal and Spatial Biases</head><p>In the context of species and habitats distribution modeling in general, a recurrent challenge is a possible mismatch, both in time and space, between the occurrences and the environmental variables <ref type="bibr" target="#b58">(Phillips et al., 2006)</ref>. As shown in Figure <ref type="figure" target="#fig_1">2B</ref>, in particular, a fraction of the occurrences in our dataset date from several decades ago, while the satellite data is from March 2020 to February 2021. If the environment changed since the observation, e.g., because of a housing project or deforestation, the model may learn incorrect relationships. Figure <ref type="figure" target="#fig_12">11A</ref> focuses on this particular issue and acknowledges the influence of occurrence observation date on model performances. The top-30 test accuracy is gradually higher on more recent occurrences than older ones. Interestingly, common and rare species predictions seem to respond in the same manner to temporal shifts between predictive habitat data and species observation dates.</p><p>Spatial mismatch can also happen because of the occurrences position uncertainty (Shown in Supplementary Figure <ref type="figure" target="#fig_0">1</ref>). However, our model being based on convolutional filters, it is highly robust to such spatial shifts until the true occurrence position does not exceed the extent of the input image (here, 640 m × 640 m). Ideally, only occurrences with a position uncertainty of less than 320 m (half of the patch size) should be considered with our method. Figure <ref type="figure" target="#fig_12">11B</ref> traduces the impact of test occurrence coordinates uncertainty on model performance. As expected, top-30 accuracy drops when uncertainty is substantial and there is actually very little chance that the predictive data is anywhere near the actual observation place (see performances on Q 4 quartile). Besides, performance on both common and rare species remains almost constant when uncertainty is inferior to the median equal to 707 meters. Thereby, when the maximum uncertainty is of the order of the patch size, the model performs as well as on very precise occurrences. Finally, the Q 3 marked difference of evolution between micro/macro top-30 accuracy could be explained by the following hypothesis: rare species predictions are more affected by a growing coordinates uncertainty than common species because of more locally specific habitat preferences.</p><p>In machine learning, such mismatch between labels and predictive data is called label noise <ref type="bibr" target="#b30">(Frénay and Verleysen, 2013)</ref> and is actively studied <ref type="bibr" target="#b33">(Ghosh et al., 2017;</ref><ref type="bibr" target="#b47">Lee et al., 2018)</ref>. The strength of our dataset in counteracting this noise is its very large size, as demonstrated by <ref type="bibr" target="#b64">Rolnick et al. (2017)</ref>. Their work showed that deep learning models can learn correct generalizations even with massively noisy datasets.</p><p>At last, the strong spatial bias present in the <software ContextAttributes="created">DeepOrchidSeries</software> dataset influences SDMs predictions <ref type="bibr" target="#b6">(Beck et al., 2014)</ref>. Such bias results from a very uneven sampling effort (Shown in Figure <ref type="figure" target="#fig_4">4C</ref> map) and not from orchids distribution. The use of methods to mitigate spatial bias at the cost of occurrence number is a promising direction to exploit <software ContextAttributes="created">DeepOrchidSeries</software> (see abovementioned publication). Nonetheless, true understanding of orchids distribution and health will only be reached with significant and uniform observation effort. Having access to constructive and global predictive data is remarkably valuable but not sufficient. Biodiversity hotspots <ref type="bibr" target="#b52">(Myers et al., 2000)</ref> urgently need to be sampled with high standards of care to limit human disturbance. Citizen science initiatives are also contributing to enhancing biodiversity monitoring worldwide <ref type="bibr" target="#b45">(Kobori et al., 2016;</ref><ref type="bibr" target="#b1">Affouard et al., 2017)</ref>.</p></div>
<div><head n="4.7.">Perspective 1: Enriching the Input With Other Predictors Informing Orchids Habitats</head><p>An exciting future development is to add other relevant predictors to our models. Other image time series like the frequently used bio-climatic variables from WorldClim<ref type="foot" target="#foot_4">6</ref> or Ecosystem Functional Attributes (EFAs, Arenas-Castro et al., 2018, although not independent since they also are computed from satellite data) would bring Supplementary Materials on species ecological niche. Complementary data like altitude <ref type="foot" target="#foot_5">7</ref> , available global human footprint rasters<ref type="foot" target="#foot_6">8</ref> , soil properties variables<ref type="foot" target="#foot_7">9</ref>  <ref type="bibr" target="#b5">(Batjes et al., 2020)</ref>, or ecoregions <ref type="bibr" target="#b55">(Olson et al., 2001)</ref> would help to crystallize species preferences and vulnerabilities as well.</p></div>
<div><head n="4.8.">Perspective 2: Using NN Architectures Designed to Extract Long-Term Temporal Dependencies</head><p>An active research avenue concerns adapting neural networks architectures to best analyze satellite image time series with broad temporal and spatial coverages. Recurrent CNNs (RCNNs, <ref type="bibr" target="#b46">Lai et al., 2015)</ref> achieve significant performance gain in landcover classification tasks <ref type="bibr" target="#b65">(Rußwurm and Körner, 2018;</ref><ref type="bibr" target="#b32">Garnot et al., 2019)</ref>, and we anticipate it should also be relevant for the analysis of species distributions and spatio-temporal dynamics. In our case, we can suggest a hybrid architecture relying on an Inception v3 model to first extract the spatial features at each week or month and then an RNN to encode the temporal dimension over a long period of time. 3D CNNs are another promising candidate architecture but, as pointed out by <ref type="bibr" target="#b32">Garnot et al. (2019)</ref>, convolutions in the temporal dimension are not well adapted to grasp long-term dependencies and assume a regular sampling of occurrences in time, which we do not have. Lastly, spatio-temporal encoders with temporal attention also merit to be tested when seeing their success on other tasks like satellite time-series segmentation <ref type="bibr" target="#b31">(Garnot and Landrieu, 2021)</ref>. For now, our CNN architecture is considering the stacked time-series of size twelve as a global temporal context. It was proven suited to grasp the local landscape dynamics yearly and globally improve species relative probability of presence prediction. But with larger time-series, attributing more modeling weight to the temporal dimension will be a must. This seems especially relevant given that predictions of rare species and predictions in very diverse regions benefit the most from the temporal information.</p></div>
<div><head n="5.">CONCLUSION</head><p>In this paper, we studied for the first time a worldwide SDM based on high-resolution remote sensing image time series. Therefore, we built and shared a substantial dataset (called <software>DeepOrchidSeries</software>) aimed at modeling the distribution of orchids on a global scale from Sentinel-2 data. The spatial structure and phenology of species habitat are captured over a whole year for 999,258 occurrences. We then trained deep-SDMs resting on an Inception v3 architecture whose input was modified to deal with 12 months time-series of RGB+IR images. The analysis of the resulting model reveals that the temporal information contained in the time series enables a strong improvement of the predictive performance compared to a purely spatial model. Thanks to interpretability experiments, we did show that seasonal patterns, in particular, are well captured, resulting in better discrimination of habitats all over the world. We also demonstrated that occurrence-poor species and diversity-rich regions are the ones that benefit the most from this improvement, revealing the importance of habitats, temporal dynamics to characterize biodiversity. We hope that this work will pave the way for even more elaborate spatio-temporal models allowing us to predict future trajectories of ecosystems in the context of rapid changes in habitats.</p></div><figure xml:id="fig_0"><head>FIGURE 1 |</head><label>1</label><figDesc>FIGURE 1 | Visual abstract of the proposed method. Layer 0: The dataset introduced in this paper (DeepOrchidSeries) is based on a filtered set of GBIF occurrences (Global Biodiversity Information Facility) coming from the study of Zizka et al. (2021). Layer 1: Sentinel-2 image time series were collected around each occurrence geolocation, keeping least cloudy data tiles every month between March 2020 and February 2021. Images are made of 640 x 640 m RGB+IR channels with 10 m spatial resolution. The dataset is available on Zenodo and the method to create it on the Gitlab.inria platform. Layer 2: We then trained deep species distribution models (deep-SDMs) based on a convolutional neural network (CNN) (Inception v3) to capture the spatio-temporal context and environmental preferences of species.Next, we conducted experiments where the input temporal dimension was modified (randomized, averaged or sampled) so as to measure its contribution to model performance. Layer 3: the results are finally broken down into three main dimensions of analysis: species frequency in the dataset, bioregion, and species diversity in these bioregions. The analysis reveals that occurrence-poor species and diversity-rich regions are the ones that benefit the most from the improvement provided by the temporal information.</figDesc><graphic coords="4,56.64,69.99,481.92,451.68" type="bitmap" /></figure>
<figure xml:id="fig_1"><head>FIGURE 2 |</head><label>2</label><figDesc>FIGURE 2 | (A) Distribution of Occurrences of species. Species are ordered by frequency. The dotted lines are flagging that 90% of the species are only gathering 9.1% of the occurrences. (B) Temporal distribution of occurrences. The two graphs are based on all dataset occurrences.</figDesc><graphic coords="5,56.64,69.63,481.92,245.04" type="bitmap" /></figure>
<figure xml:id="fig_2"><head>FIGURE 3 |</head><label>3</label><figDesc>FIGURE 3 | Creation workflow of DeepOrchidSeries dataset. Input is a set of geolocated occurrences, output gathers image time series informing on species habitat preferences. Code and details are available at https://gitlab.inria.fr/jestopin/sen2patch.</figDesc><graphic coords="6,56.64,69.31,481.92,177.36" type="bitmap" /></figure>
<figure xml:id="fig_3"><head /><label /><figDesc>Figure 4B illustrates three different patch sizes around an observation on an island of the South Australian coast. It shows that the 640 m × 640 m patch (40.96 ha) captures important landscape patterns around the record as well as potential threats due to surrounding land use.</figDesc></figure>
<figure xml:id="fig_4"><head>FIGURE 4 |</head><label>4</label><figDesc>FIGURE 4 | (A) Histogram of the number of occurrences per tile, (B) different patch sizes comparison around an occurrence located at (-39.883306, 144.050000), decimal degree system, (C) map of the selected tiles colored by the number of records contained (log10 scale). Three occurrences are located by α, β, and γ .Figure 5 provides the three associated image time-series.</figDesc><graphic coords="7,56.64,69.59,481.92,352.08" type="bitmap" /></figure>
<figure xml:id="fig_5"><head>FIGURE 5 |</head><label>5</label><figDesc>FIGURE 5 | Image time series associated with the three occurrences located in Figure 4C map. RGB images are shown on the first line and IR patches on the second. (A) is almost cloud-free and globally normalized before visualization (i.e., all months are divided by TS maximum pixel), (B) is a cloudless time series with a strong environmental gradient because of snow presence and is normalized by frame (i.e., each month data is divided by month maximum pixel, only for visualization), (C) is an especially cloudy time series also normalized by frame.</figDesc><graphic coords="8,56.64,69.99,481.92,307.68" type="bitmap" /></figure>
<figure xml:id="fig_6"><head>FIGURE 6 |</head><label>6</label><figDesc>FIGURE 6 | Cloud cover percentages of the 1,067,989 tested products, 180,747 (16.9%) selected against 887,242 (83.1%) dismissed. (A) all months taken together, (B) detailed by month.</figDesc><graphic coords="9,56.64,69.52,481.92,176.16" type="bitmap" /></figure>
<figure xml:id="fig_7"><head /><label /><figDesc>5 http://www.idris.fr/annonces/annonce-jean-zay-eng.html They were trained during 70 epochs with a batch size equal to 64. The training process took around 100 h per model (with 8 gpus working in parallel).</figDesc></figure>
<figure xml:id="fig_8"><head>FIGURE 7 |</head><label>7</label><figDesc>FIGURE 7  | Scheme illustrating the three transformations applied to the input image time-series toward interpreting the contribution of the temporal information. Only 6 RGB images are depicted but these procedures are applied on the whole 12-month-long time series, IR channel included (here N = 6 but would normally equal 12). The image time-series A (black legend) corresponds to the original data, i.e., to the images stacked in chronological order. The image series B 1 (green legend) is obtained by randomly permuting the original time series. The image series B 2 (red legend) is made of 1 month picked at random and replicated N times. The image series B 3 (blue legend) is constructed by averaging the 12 images of the original time series and replicating the resulting mean image N times. Please note that the same legend's colors will be used in the figures of the paper presenting the results of these experiments.</figDesc><graphic coords="12,56.64,69.88,481.92,364.80" type="bitmap" /></figure>
<figure xml:id="fig_9"><head>FIGURE 8 |</head><label>8</label><figDesc>FIGURE 8 | Micro (A) and macro (B) average top-30 accuracy on models validation and test sets. Micro-average results tend to represent common species whereas macro-average performances are more representative of rare species.</figDesc><graphic coords="13,85.14,69.35,425.28,226.32" type="bitmap" /></figure>
<figure xml:id="fig_10"><head>FIGURE 9 |</head><label>9</label><figDesc>FIGURE 9 | Macro-average top-30 accuracy (A) and relative top-30 accuracy change (B) averaged per category of the number of species occurrences in the training set. All models, performances are following the drop of N s when relative performance changes are inversely proportional to it.</figDesc><graphic coords="14,56.64,69.27,481.92,236.40" type="bitmap" /></figure>
<figure xml:id="fig_11"><head>FIGURE 10 |</head><label>10</label><figDesc>FIGURE 10 | Region top-30 accuracy (A) and relative top-30 accuracy change (B) averaged per cat. of 1 D r . Map (C) presents region top-30 accuracy with 1 D r indicated in green. Map (D) illustrates spatial decreases in performances when comparing M 3 to M, i.e., without/with the temporal information.</figDesc><graphic coords="15,77.63,69.47,439.92,595.20" type="bitmap" /></figure>
<figure xml:id="fig_12"><head>FIGURE 11 |</head><label>11</label><figDesc>FIGURE 11 | Model performances on the test set divided by quartiles Q i on (A) occurrence observation year and (B) occurrence coordinates uncertainty. The test accuracy is higher on more recent observations and on observations with reasonably low coordinates uncertainty.</figDesc><graphic coords="16,56.64,69.51,481.92,224.16" type="bitmap" /></figure>
<figure type="table" xml:id="tab_0"><head>TABLE 1 |</head><label>1</label><figDesc>Summary table of the number of occurrences and species in the training, validation, and test sets.</figDesc><table><row><cell>Set</cell><cell>Training</cell><cell>Validation</cell><cell>Test</cell></row><row><cell>#Occurrences</cell><cell>897,296</cell><cell>51,116</cell><cell>50,375</cell></row><row><cell>#Species</cell><cell>13,700</cell><cell>4,290</cell><cell>4,261</cell></row></table></figure>
			<note place="foot" xml:id="foot_0"><p>Frontiers in Plant Science | www.frontiersin.org</p></note>
			<note place="foot" xml:id="foot_1"><p>April 2022 | Volume 13 | Article 839327</p></note>
			<note place="foot" n="3" xml:id="foot_2"><p>https://scihub.copernicus.eu/, queries and downloads require an activated Scihub Copernicus account.</p></note>
			<note place="foot" n="4" xml:id="foot_3"><p>https://sentinel.esa.int/web/sentinel/missions/sentinel-2Frontiers in Plant Science | www.frontiersin.org</p></note>
			<note place="foot" n="6" xml:id="foot_4"><p>http://www.worldclim.org</p></note>
			<note place="foot" n="7" xml:id="foot_5"><p>https://lpdaac.usgs.gov/products/srtmgl1v003/ Frontiers in Plant Science | www.frontiersin.org</p></note>
			<note place="foot" n="8" xml:id="foot_6"><p>https://sedac.ciesin.columbia.edu/data/set/wildareas-v3-2009-human-footprint and 1993 version.</p></note>
			<note place="foot" n="9" xml:id="foot_7"><p>https://soilgrids.org/</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>ACKNOWLEDGMENTS</head><p>We warmly thank <rs type="person">Alexander Zizka</rs> for providing us with the filtered set of orchid occurrences. Our dataset contains modified Copernicus Sentinel data and Copernicus Service information (2020, 2021). Sentinel-2 MSI data used were available at no cost from <rs type="institution">ESA Sentinels Scientific Data Hub</rs>. This work was granted access to the HPC resources of IDRIS under the allocation <rs type="grantNumber">20XX-AD011011389R1</rs> made by <rs type="funder">GENCI</rs>. Finally, we would like to thank the reviewers for their insightful comments that helped us improve our manuscript.</p></div>
			</div>
			<div type="funding">
<div><head>FUNDING</head><p>The work was supported by the <rs type="funder">INRIA</rs> exploratory action <rs type="funder">CACTUS Fund</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_zVQMkfH">
					<idno type="grant-number">20XX-AD011011389R1</idno>
				</org>
			</listOrg>

			<div type="availability">
<div><head>DATA AVAILABILITY STATEMENT</head><p>-Code is available on the sen2patch gitlab: https://gitlab.inria.fr/ jestopin/sen2patch. -Occurrences initial GBIF query is https://doi.org/10.15468/dl. 4bijtu (accessed August 2019). -The dataset and models generated for this study can be found in Zenodo at: https://doi.org/10.5281/zenodo.4972593.</p></div>
			</div>

			<div type="annex">
<div><head>AUTHOR CONTRIBUTIONS</head><p>JE, MS, PB, FM, and AJ: conceptualization, investigation, methodology, writing-original draft, writing-review, and editing. JE and MS: data curation and software. PB and AJ: funding acquisition. PB, FM, and AJ: project administration. MS, PB, FM, and AJ: supervision. MS, FM, and AJ: validation. JE, FM, and AJ: visualization. All authors contributed to the article and approved the submitted version.</p></div>
<div><head>SUPPLEMENTARY MATERIAL</head><p>The Supplementary Material for this article can be found online at: https://www.frontiersin.org/articles/10.3389/fpls.2022.</p></div>
<div><head>839327/full#supplementary-material</head><p>Conflict of Interest: The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.</p><p>Publisher's Note: All claims expressed in this article are solely those of the authors and do not necessarily represent those of their affiliated organizations, or those of the publisher, the editors and the reviewers. Any product that may be evaluated in this article, or claim that may be made by its manufacturer, is not guaranteed or endorsed by the publisher.</p><p>Copyright © 2022 Estopinan, Servajean, Bonnet, Munoz and Joly. This is an openaccess article distributed under the terms of the Creative Commons Attribution License (CC BY). The use, distribution or reproduction in other forums is permitted, provided the original author(s) and the copyright owner(s) are credited and that the original publication in this journal is cited, in accordance with accepted academic practice. No use, distribution or reproduction is permitted which does not comply with these terms.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Micro-site conditions of epiphytic orchids in a human impact gradient in Kathmandu valley, Nepal</title>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">P</forename><surname>Adhikari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">S</forename><surname>Fischer</surname></persName>
		</author>
		<idno type="DOI">10.1007/s11629-009-2262-1</idno>
	</analytic>
	<monogr>
		<title level="j">J. Mountain Sci</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="331" to="342" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Pl@ ntnet app in the era of deep learning</title>
		<author>
			<persName><forename type="first">A</forename><surname>Affouard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Goëau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Bonnet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-C</forename><surname>Lombardo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Joly</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR: International Conference on Learning Representations</title>
		<meeting><address><addrLine>Toulon, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Standards for distribution models in biodiversity assessments</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">B</forename><surname>Araújo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">P</forename><surname>Anderson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Barbosa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">M</forename><surname>Beale</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">F</forename><surname>Dormann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Early</surname></persName>
		</author>
		<idno type="DOI">10.1126/sciadv.aat4858</idno>
	</analytic>
	<monogr>
		<title level="j">Sci. Adv</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">4858</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Assessing the multi-scale predictive ability of ecosystem functional attributes for species distribution modelling</title>
		<author>
			<persName><forename type="first">S</forename><surname>Arenas-Castro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gonçalves</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Alves</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Alcaraz-Segura</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Honrado</surname></persName>
		</author>
		<idno type="DOI">10.1371/journal.pone.0199292</idno>
	</analytic>
	<monogr>
		<title level="j">PLoS ONE</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page">199292</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A review of vegetation indices</title>
		<author>
			<persName><forename type="first">A</forename><surname>Bannari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Morin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Bonn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Huete</surname></persName>
		</author>
		<idno type="DOI">10.1080/02757259509532298</idno>
	</analytic>
	<monogr>
		<title level="j">Remote Sens. Rev</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="95" to="120" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Standardised soil profile data to support global mapping and modelling (wosis snapshot 2019)</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">H</forename><surname>Batjes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Ribeiro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Van Oostrum</surname></persName>
		</author>
		<idno type="DOI">10.5194/essd-12-299-2020</idno>
	</analytic>
	<monogr>
		<title level="j">Earth Syst. Sci. Data</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="299" to="320" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Spatial bias in the gbif database and its effect on modeling species' geographic distributions</title>
		<author>
			<persName><forename type="first">J</forename><surname>Beck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Böller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Erhardt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Schwanghart</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.ecoinf.2013.11.002</idno>
	</analytic>
	<monogr>
		<title level="j">Ecol. Inform</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="10" to="15" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Esa's sentinel missions in support of earth system science</title>
		<author>
			<persName><forename type="first">M</forename><surname>Berger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Moreno</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Johannessen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">F</forename><surname>Levelt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">F</forename><surname>Hanssen</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.rse.2011.07.023</idno>
	</analytic>
	<monogr>
		<title level="j">Remote Sens. Environ</title>
		<imprint>
			<biblScope unit="volume">120</biblScope>
			<biblScope unit="page" from="84" to="90" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Deep learning as a tool for ecology and evolution</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">L</forename><surname>Borowiec</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Frandsen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Dikow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mckeeken</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Valentini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">E</forename><surname>White</surname></persName>
		</author>
		<idno type="DOI">10.32942/osf.io/nt3as</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">A deep learning approach to species distribution modelling</title>
		<author>
			<persName><forename type="first">C</forename><surname>Botella</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Joly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Bonnet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Monestiez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Munoz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Multimedia Tools and Applications for Environmental Biodiversity Informatics</title>
		<meeting><address><addrLine>Montpellier, France</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="169" to="199" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Bias in presence-only niche models related to sampling effort and species niches: lessons for background point selection</title>
		<author>
			<persName><forename type="first">C</forename><surname>Botella</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Joly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Monestiez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Bonnet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Munoz</surname></persName>
		</author>
		<idno type="DOI">10.1371/journal.pone.0232078</idno>
	</analytic>
	<monogr>
		<title level="j">PLoS ONE</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page">232078</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Overview of geolifeclef 2019: plant species prediction using environment and animal occurrences</title>
		<author>
			<persName><forename type="first">C</forename><surname>Botella</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Servajean</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Bonnet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Joly</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Working Notes of CLEF 2019-Conference and Labs of the Evaluation Forum</title>
		<meeting><address><addrLine>Lugano, Switzerland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page">2380</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Uncovering ecological patterns with convolutional neural networks</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">G</forename><surname>Brodrick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">B</forename><surname>Davies</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">P</forename><surname>Asner</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.tree.2019.03.006</idno>
	</analytic>
	<monogr>
		<title level="j">Trends Ecol. Evolut</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="734" to="745" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">World geographical scheme for recording plant distributions</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">K</forename><surname>Brummitt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Pando</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Hollis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Brummitt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Working Group on Taxonomic Databases for Plant Sciences</title>
		<meeting><address><addrLine>Pittsburgh, PA)</addrLine></address></meeting>
		<imprint>
			<publisher>TDWG</publisher>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Deep Learning for the Earth Sciences: A Comprehensive Approach to Remote Sensing</title>
		<author>
			<persName><forename type="first">G</forename><surname>Camps-Valls</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Tuia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><forename type="middle">X</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Reichstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">Climate Science and Geosciences</title>
		<imprint>
			<date type="published" when="2021">2021</date>
			<publisher>John Wiley &amp; Sons</publisher>
			<pubPlace>Hoboken, NJ</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Learning imbalanced datasets with label-distribution-aware margin loss</title>
		<author>
			<persName><forename type="first">K</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gaidon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Arechiga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Ma</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1906.07413</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">No place to hide: Rare plant detection through remote sensing</title>
		<author>
			<persName><forename type="first">C</forename><surname>Cerrejón</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Valeria</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Marchand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">T</forename><surname>Caners</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">J</forename><surname>Fenton</surname></persName>
		</author>
		<idno type="DOI">10.1111/ddi.13244</idno>
	</analytic>
	<monogr>
		<title level="j">Diversity Distribut</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="948" to="961" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">An updated classification of orchidaceae</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">W</forename><surname>Chase</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">M</forename><surname>Cameron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">V</forename><surname>Freudenstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Pridgeon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Salazar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Van Den Berg</surname></persName>
		</author>
		<idno type="DOI">10.1111/boj.12234</idno>
	</analytic>
	<monogr>
		<title level="j">Bot. J. Linnean Soc</title>
		<imprint>
			<biblScope unit="volume">177</biblScope>
			<biblScope unit="page" from="151" to="174" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Set-valued classificationoverview via a unified framework</title>
		<author>
			<persName><forename type="first">E</forename><surname>Chzhen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Denis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hebiri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Lorieul</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2102.12318</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Inclusion of habitat availability in species distribution models through multi-temporal remote-sensing data?</title>
		<author>
			<persName><forename type="first">A</forename><surname>Cord</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Rödder</surname></persName>
		</author>
		<idno type="DOI">10.1890/11-0114.1</idno>
	</analytic>
	<monogr>
		<title level="j">Ecol. Appl</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="3285" to="3298" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Identification of citrus trees from unmanned aerial vehicle imagery using convolutional neural networks</title>
		<author>
			<persName><forename type="first">O</forename><surname>Csillik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Cherbini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Lyons</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kelly</surname></persName>
		</author>
		<idno type="DOI">10.3390/drones2040039</idno>
	</analytic>
	<monogr>
		<title level="j">Drones</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">39</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Is tree species diversity or species identity the more important driver of soil carbon stocks, c/n ratio, and ph?</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Dawud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Raulund-Rasmussen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Domisch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Finér</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Jaroszewicz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Vesterdal</surname></persName>
		</author>
		<idno type="DOI">10.1007/s10021-016-9958-1</idno>
	</analytic>
	<monogr>
		<title level="j">Ecosystems</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="645" to="660" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">How do deep convolutional sdm trained on satellite images unravel vegetation ecology?</title>
		<author>
			<persName><forename type="first">B</forename><surname>Deneu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Joly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Bonnet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Servajean</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Munoz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Pattern Recognition (ICPR)</title>
		<meeting><address><addrLine>Milan, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">12666</biblScope>
			<biblScope unit="page" from="148" to="158" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Convolutional neural networks improve species distribution modelling by capturing the spatial structure of the environment</title>
		<author>
			<persName><forename type="first">B</forename><surname>Deneu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Servajean</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Bonnet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Botella</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Munoz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Joly</surname></persName>
		</author>
		<idno type="DOI">10.1371/journal.pcbi.1008856</idno>
	</analytic>
	<monogr>
		<title level="j">PLoS Comput. Biol</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page">1008856</biblScope>
			<date type="published" when="2021">2021b</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Sentinel-2: Esa's optical high-resolution mission for gmes operational services</title>
		<author>
			<persName><forename type="first">M</forename><surname>Drusch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Del Bello</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Carlier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Colin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Fernandez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Gascon</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.rse.2011.11.026</idno>
	</analytic>
	<monogr>
		<title level="j">Remote Sens. Environ</title>
		<imprint>
			<biblScope unit="volume">120</biblScope>
			<biblScope unit="page" from="25" to="36" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Species diversity can drive speciation</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">C</forename><surname>Emerson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Kolm</surname></persName>
		</author>
		<idno type="DOI">10.1038/nature03450</idno>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">434</biblScope>
			<biblScope unit="page" from="1015" to="1017" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Habitat heterogeneity captured by 30-m resolution satellite image texture predicts bird richness across the united states</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">S</forename><surname>Farwell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">R</forename><surname>Elsen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Razenkova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Pidgeon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">C</forename><surname>Radeloff</surname></persName>
		</author>
		<idno type="DOI">10.1002/eap.2157</idno>
	</analytic>
	<monogr>
		<title level="j">Ecol. Appl</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page">2157</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Detecting the phenology and discriminating mediterranean natural habitats with multispectral sensors-an analysis based on multiseasonal field spectra</title>
		<author>
			<persName><forename type="first">J.-B</forename><surname>Féret</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Corbane</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Alleaume</surname></persName>
		</author>
		<idno type="DOI">10.1109/JSTARS.2015.2431320</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE J. Select. Top. Appl. Earth Observat. Remote Sens</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="2294" to="2305" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Worldclim 2: new 1-km spatial resolution climate surfaces for global land areas</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">E</forename><surname>Fick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Hijmans</surname></persName>
		</author>
		<idno type="DOI">10.1002/joc.5086</idno>
	</analytic>
	<monogr>
		<title level="j">Int. J. Climatol</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="4302" to="4315" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Paintings predict the distribution of species, or the challenge of selecting environmental predictors and evaluation statistics</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Fourcade</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">G</forename><surname>Besnard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Secondi</surname></persName>
		</author>
		<idno type="DOI">10.1111/geb.12684</idno>
	</analytic>
	<monogr>
		<title level="j">Glob. Ecol. Biogeogr</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="245" to="256" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Classification in the presence of label noise: a survey</title>
		<author>
			<persName><forename type="first">B</forename><surname>Frénay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Verleysen</surname></persName>
		</author>
		<idno type="DOI">10.1109/TNNLS.2013.2292894</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Neural Netw. Learn. Syst</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="845" to="869" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Panoptic segmentation of satellite image time series with convolutional temporal attention networks</title>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">S F</forename><surname>Garnot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Landrieu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision (Virtual)</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision (Virtual)</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="4872" to="4881" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Time-space tradeoff in deep learning models for crop classification on satellite multispectral image time series</title>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">S F</forename><surname>Garnot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Landrieu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Giordano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Chehata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IGARSS 2019-2019 IEEE International Geoscience and Remote Sensing Symposium</title>
		<meeting><address><addrLine>Yokohama, Japan</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="6247" to="6250" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Robust loss functions under label noise for deep neural networks</title>
		<author>
			<persName><forename type="first">A</forename><surname>Ghosh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Sastry</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence<address><addrLine>San Francisco, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">31</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Forest structure as a predictor of tree species diversity in the north carolina piedmont</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">R</forename><surname>Hakkenberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">K</forename><surname>Peet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">S</forename><surname>White</surname></persName>
		</author>
		<idno type="DOI">10.1111/jvs.12451</idno>
	</analytic>
	<monogr>
		<title level="j">J. Vegetat. Sci</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="1151" to="1163" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Will remote sensing shape the next generation of species distribution models? Remote Sens</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">S</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">A</forename><surname>Bradley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">F</forename><surname>Cord</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Rocchini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M.-N</forename><surname>Tuanmu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Schmidtlein</surname></persName>
		</author>
		<idno type="DOI">10.1002/rse2.7</idno>
	</analytic>
	<monogr>
		<title level="j">Ecol. Conservat</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="4" to="18" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Does the interpolation accuracy of species distribution models come at the expense of transferability?</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">K</forename><surname>Heikkinen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Marmion</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Luoto</surname></persName>
		</author>
		<idno type="DOI">10.1111/j.1600-0587.2011.06999.x</idno>
	</analytic>
	<monogr>
		<title level="j">Ecography</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="276" to="288" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Eurosat: A novel dataset and deep learning benchmark for land use and land cover classification</title>
		<author>
			<persName><forename type="first">P</forename><surname>Helber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Bischke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Dengel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Borth</surname></persName>
		</author>
		<idno type="DOI">10.1109/JSTARS.2019.2918242</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE J. Selec. Top. Appl. Earth Observat. Remote Sens</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2217" to="2226" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Very high resolution interpolated climate surfaces for global land areas</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Hijmans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">E</forename><surname>Cameron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Parra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">G</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Jarvis</surname></persName>
		</author>
		<idno type="DOI">10.1002/joc.1276</idno>
	</analytic>
	<monogr>
		<title level="j">Int. J. Climatol</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="1965" to="1978" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Diversity and evenness: a unifying notation and its consequences</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">O</forename><surname>Hill</surname></persName>
		</author>
		<idno type="DOI">10.2307/1934352</idno>
	</analytic>
	<monogr>
		<title level="j">Ecology</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="page" from="427" to="432" />
			<date type="published" when="1973">1973</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Atmospheric compensation of hyperspectral data: an overview and review of in-scene and physics-based approaches</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">J</forename><surname>Ientilucci</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Adler-Golden</surname></persName>
		</author>
		<idno type="DOI">10.1109/MGRS.2019.2904706</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Geosci. Remote Sens. Mag</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="31" to="50" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Batch normalization: Accelerating deep network training by reducing internal covariate shift</title>
		<author>
			<persName><forename type="first">S</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<meeting><address><addrLine>Lille, France</addrLine></address></meeting>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="448" to="456" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Biodiversity hotspots house most undiscovered plant species</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">N</forename><surname>Joppa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">L</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Myers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">L</forename><surname>Pimm</surname></persName>
		</author>
		<idno type="DOI">10.1073/pnas.1109389108</idno>
	</analytic>
	<monogr>
		<title level="j">Proc. Natl. Acad. Sci. U.S.A</title>
		<imprint>
			<biblScope unit="volume">108</biblScope>
			<biblScope unit="page" from="13171" to="13176" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Entropy and diversity</title>
		<author>
			<persName><forename type="first">L</forename><surname>Jost</surname></persName>
		</author>
		<idno type="DOI">10.1111/j.2006.0030-1299.14714.x</idno>
	</analytic>
	<monogr>
		<title level="j">Oikos</title>
		<imprint>
			<biblScope unit="volume">113</biblScope>
			<biblScope unit="page" from="363" to="375" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Convolutional neural networks accurately predict cover fractions of plant species and communities in unmanned aerial vehicle imagery</title>
		<author>
			<persName><forename type="first">T</forename><surname>Kattenborn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Eichel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wiser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Burrows</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">E</forename><surname>Fassnacht</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Schmidtlein</surname></persName>
		</author>
		<idno type="DOI">10.1002/rse2.146</idno>
	</analytic>
	<monogr>
		<title level="j">Remote Sens. Ecol. Conservat</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="472" to="486" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Citizen science: a new approach to advance ecology, education, and conservation</title>
		<author>
			<persName><forename type="first">H</forename><surname>Kobori</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Dickinson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Washitani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Sakurai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Amano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Komatsu</surname></persName>
		</author>
		<idno type="DOI">10.1007/s11284-015-1314-y</idno>
	</analytic>
	<monogr>
		<title level="j">Ecol. Res</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="1" to="19" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Recurrent convolutional neural networks for text classification</title>
		<author>
			<persName><forename type="first">S</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Twenty-Ninth AAAI Conference on Artificial Intelligence</title>
		<meeting><address><addrLine>Austin, TX</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Cleannet: transfer learning for scalable image classifier training with label noise</title>
		<author>
			<persName><forename type="first">K.-H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition<address><addrLine>Salt Lake City, UT</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="5447" to="5456" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Sentinel-2 sen2cor: L2a processor for users</title>
		<author>
			<persName><forename type="first">J</forename><surname>Louis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Debaecker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Pflug</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Main-Knorn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bieniarz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Mueller-Wilm</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings Living Planet Symposium 2016</title>
		<meeting>Living Planet Symposium 2016<address><addrLine>Prague, Czech Republic</addrLine></address></meeting>
		<imprint>
			<publisher>Spacebooks Online</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<author>
			<persName><forename type="first">O</forename><surname>Ma Nas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Lacoste</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Giro-I Nieto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Vazquez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Rodriguez</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2103.16607</idno>
		<title level="m">Seasonal contrast: UNSUPERVISED pre-training from uncurated remote sensing data</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Machine learning and the end of atmospheric corrections: A comparison between high-resolution sea surface salinity in coastal areas from top and bottom of atmosphere sentinel-2 imagery</title>
		<author>
			<persName><forename type="first">E</forename><surname>Medina-Lopez</surname></persName>
		</author>
		<idno type="DOI">10.3390/rs12182924</idno>
	</analytic>
	<monogr>
		<title level="j">Remote Sens</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<date type="published" when="2020">2020. 2924</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Explicit integration of dispersal-related metrics improves predictions of sdm in predatory arthropods</title>
		<author>
			<persName><forename type="first">J</forename><surname>Monsimet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Devineau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Petillon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Lafage</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41598-020-73262-2</idno>
	</analytic>
	<monogr>
		<title level="j">Sci. Rep</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="1" to="12" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Biodiversity hotspots for conservation priorities</title>
		<author>
			<persName><forename type="first">N</forename><surname>Myers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Mittermeier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">G</forename><surname>Mittermeier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">A</forename><surname>Da Fonseca</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kent</surname></persName>
		</author>
		<idno type="DOI">10.1038/35002501</idno>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">403</biblScope>
			<biblScope unit="page" from="853" to="858" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
		<author>
			<persName><forename type="first">B</forename><surname>Newman</surname></persName>
		</author>
		<title level="m">Orchids as indicators of ecosystem health in urban bushland fragments</title>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
		<respStmt>
			<orgName>Murdoch University</orgName>
		</respStmt>
	</monogr>
	<note>Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Predicting the past distribution of species climatic niches</title>
		<author>
			<persName><forename type="first">D</forename><surname>Nogués-Bravo</surname></persName>
		</author>
		<idno type="DOI">10.1111/j.1466-8238.2009.00476.x</idno>
	</analytic>
	<monogr>
		<title level="j">Glob. Ecol. Biogeogr</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="521" to="531" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Terrestrial ecoregions of the world: a new map of life on eartha new global map of terrestrial ecoregions provides an innovative tool for conserving biodiversity</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Olson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Dinerstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">D</forename><surname>Wikramanayake</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">D</forename><surname>Burgess</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">V</forename><surname>Powell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">C</forename><surname>Underwood</surname></persName>
		</author>
		<idno type="DOI">10.1641/0006-3568(2001)051[0933:TEOTWA]2.0.CO;2</idno>
	</analytic>
	<monogr>
		<title level="j">Bioscience</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="page" from="933" to="938" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Biodiversity redistribution under climate change: Impacts on ecosystems and human well-being</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">T</forename><surname>Pecl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">B</forename><surname>Araújo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Bell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Blanchard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">C</forename><surname>Bonebrake</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I.-C</forename><surname>Chen</surname></persName>
		</author>
		<idno type="DOI">10.1126/science.aai9214</idno>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">355</biblScope>
			<date type="published" when="2017">2017. 9214</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">The normalized difference vegetation index (ndvi): unforeseen successes in animal ecology</title>
		<author>
			<persName><forename type="first">N</forename><surname>Pettorelli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ryan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Mueller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Bunnefeld</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Jędrzejewska</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lima</surname></persName>
		</author>
		<idno type="DOI">10.3354/cr00936</idno>
	</analytic>
	<monogr>
		<title level="j">Climate Res</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="page" from="15" to="27" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Maximum entropy modeling of species geographic distributions</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Phillips</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">P</forename><surname>Anderson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Schapire</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.ecolmodel.2005.03.026</idno>
	</analytic>
	<monogr>
		<title level="j">Ecol. Modell</title>
		<imprint>
			<biblScope unit="volume">190</biblScope>
			<biblScope unit="page" from="231" to="259" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Modeling of species distributions with maxent: new extensions and a comprehensive evaluation</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Phillips</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Dudík</surname></persName>
		</author>
		<idno type="DOI">10.1111/j.0906-7590.2008.5203.x</idno>
	</analytic>
	<monogr>
		<title level="j">Ecography</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="161" to="175" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Sample selection bias and presence-only distribution models: implications for background and pseudo-absence data</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Phillips</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Dudík</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Elith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">H</forename><surname>Graham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Lehmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Leathwick</surname></persName>
		</author>
		<idno type="DOI">10.1890/07-2153.1</idno>
	</analytic>
	<monogr>
		<title level="j">Ecol. Appl</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="181" to="197" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Monitoring biodiversity in the anthropocene using remote sensing in species distribution models</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">F</forename><surname>Randin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">B</forename><surname>Ashcroft</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bolliger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Cavender-Bares</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">C</forename><surname>Coops</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Dullinger</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.rse.2019.111626</idno>
	</analytic>
	<monogr>
		<title level="j">Remote Sens. Environ</title>
		<imprint>
			<biblScope unit="volume">239</biblScope>
			<biblScope unit="page">111626</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Similarity-based large-scale distribution mapping of orchids</title>
		<author>
			<persName><forename type="first">K</forename><surname>Remm</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Remm</surname></persName>
		</author>
		<idno type="DOI">10.1007/s10531-008-9547-5</idno>
	</analytic>
	<monogr>
		<title level="j">Biodivers Conserv</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="1629" to="1647" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Cross-validation strategies for data with temporal, spatial, hierarchical, or phylogenetic structure</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">R</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Bahn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ciuti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Boyce</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Elith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Guillera-Arroita</surname></persName>
		</author>
		<idno type="DOI">10.1111/ecog.02881</idno>
	</analytic>
	<monogr>
		<title level="j">Ecography</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page" from="913" to="929" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<monogr>
		<title level="m" type="main">Deep learning is robust to massive label noise</title>
		<author>
			<persName><forename type="first">D</forename><surname>Rolnick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Veit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Shavit</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1705.10694</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Multi-temporal land cover classification with sequential recurrent encoders</title>
		<author>
			<persName><forename type="first">M</forename><surname>Rußwurm</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Körner</surname></persName>
		</author>
		<idno type="DOI">10.3390/ijgi7040129</idno>
	</analytic>
	<monogr>
		<title level="j">ISPRS Int. J. Geoinformat</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">129</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<monogr>
		<title level="m" type="main">Sen12msa curated dataset of georeferenced multi-spectral sentinel-1/2 imagery for deep learning and data fusion</title>
		<author>
			<persName><forename type="first">M</forename><surname>Schmitt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">H</forename><surname>Hughes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><forename type="middle">X</forename><surname>Zhu</surname></persName>
		</author>
		<idno type="DOI">10.5194/isprs-annals-IV-2-W7-153-2019</idno>
		<idno type="arXiv">arXiv:1906.07789</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">A mathematical theory of communication</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">E</forename><surname>Shannon</surname></persName>
		</author>
		<idno type="DOI">10.1002/j.1538-7305.1948.tb01338.x</idno>
	</analytic>
	<monogr>
		<title level="j">Bell Syst. Techn. J</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="379" to="423" />
			<date type="published" when="1948">1948</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">A systematic analysis of performance measures for classification tasks</title>
		<author>
			<persName><forename type="first">M</forename><surname>Sokolova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Lapalme</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.ipm.2009.03.002</idno>
	</analytic>
	<monogr>
		<title level="j">Inf. Process. Manag</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="page" from="427" to="437" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Classification and change detection using landsat tm data: when and how to correct atmospheric effects? Remote Sens</title>
		<author>
			<persName><forename type="first">C</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">E</forename><surname>Woodcock</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">C</forename><surname>Seto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">P</forename><surname>Lenney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Macomber</surname></persName>
		</author>
		<idno type="DOI">10.1016/S0034-4257(00)00169-3</idno>
	</analytic>
	<monogr>
		<title level="j">Environ</title>
		<imprint>
			<biblScope unit="volume">75</biblScope>
			<biblScope unit="page" from="230" to="244" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Dropout: a simple way to prevent neural networks from overfitting</title>
		<author>
			<persName><forename type="first">N</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="1929" to="1958" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<monogr>
		<title level="m" type="main">Torchgeo: deep learning with geospatial data</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Stewart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Robinson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">A</forename><surname>Corley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ortiz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M L</forename><surname>Ferres</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Banerjee</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2111.08872</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Bigearthnet: a largescale benchmark archive for remote sensing image understanding</title>
		<author>
			<persName><forename type="first">G</forename><surname>Sumbul</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Charfuelan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Demir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Markl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IGARSS 2019-2019 IEEE International Geoscience and Remote Sensing Symposium</title>
		<meeting><address><addrLine>Yokohama</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="5901" to="5904" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Applications of species distribution modeling to paleobiology</title>
		<author>
			<persName><forename type="first">J.-C</forename><surname>Svenning</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Fløjgaard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">A</forename><surname>Marske</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Nógues-Bravo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Normand</forename></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename></persName>
		</author>
		<idno type="DOI">10.1016/j.quascirev.2011.06.012</idno>
	</analytic>
	<monogr>
		<title level="j">Quat. Sci. Rev</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="2930" to="2947" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Rethinking the inception architecture for computer vision</title>
		<author>
			<persName><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wojna</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition<address><addrLine>Las Vegas, NV</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="2818" to="2826" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">Biomoda platform for ensemble forecasting of species distributions</title>
		<author>
			<persName><forename type="first">W</forename><surname>Thuiller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Lafourcade</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Engler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">B</forename><surname>Araújo</surname></persName>
		</author>
		<idno type="DOI">10.1111/j.1600-0587.2008.05742.x</idno>
	</analytic>
	<monogr>
		<title level="j">Ecography</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="369" to="373" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">Predicting patterns of plant species richness in megadiverse south africa</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">F</forename><surname>Thuiller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">F</forename><surname>Midgley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Rougeti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Cowling</surname></persName>
		</author>
		<idno type="DOI">10.1111/j.0906-7590.2006.04674.x</idno>
	</analytic>
	<monogr>
		<title level="j">Ecography</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="733" to="744" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">Transfer learning</title>
		<author>
			<persName><forename type="first">L</forename><surname>Torrey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Shavlik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Handbook of Research on Machine Learning Applications and Trends: Algorithms, Methods, and Techniques</title>
		<meeting><address><addrLine>Madison, WI</addrLine></address></meeting>
		<imprint>
			<publisher>IGI global</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="242" to="264" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main">Using the u-net convolutional network to map forest types and disturbance in the atlantic rainforest with very high resolution images</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">H</forename><surname>Wagner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sanchez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Tarabalka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">G</forename><surname>Lotte</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">P</forename><surname>Ferreira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">P</forename><surname>Aidar</surname></persName>
		</author>
		<idno type="DOI">10.1002/rse2.111</idno>
	</analytic>
	<monogr>
		<title level="j">Remote Sens. Ecol. Conservat</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="360" to="375" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">Using species distribution models to predict new occurrences for rare plants</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">N</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Seo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Thorne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">K</forename><surname>Nelson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Erwin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>O'brien</surname></persName>
		</author>
		<idno type="DOI">10.1111/j.1472-4642.2009.00567.x</idno>
	</analytic>
	<monogr>
		<title level="j">Diversity Distribut</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="565" to="576" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<analytic>
		<title level="a" type="main">Quantifying anthropogenic threats to orchids using the iucn red list</title>
		<author>
			<persName><forename type="first">J</forename><surname>Wraith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Pickering</surname></persName>
		</author>
		<idno type="DOI">10.1007/s13280-017-0964-0</idno>
	</analytic>
	<monogr>
		<title level="j">Ambio</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="page" from="307" to="317" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<analytic>
		<title level="a" type="main">Macroecology in the age of big data-where to go from here?</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">O</forename><surname>Wüest</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">E</forename><surname>Zimmermann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zurell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Alexander</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Fritz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Hof</surname></persName>
		</author>
		<idno type="DOI">10.1111/jbi.13633</idno>
	</analytic>
	<monogr>
		<title level="j">J. Biogeogr</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="page" from="1" to="12" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<analytic>
		<title level="a" type="main">Deep learning in remote sensing: a comprehensive review and list of resources</title>
		<author>
			<persName><forename type="first">X</forename><forename type="middle">X</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Tuia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Mou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G.-S</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Xu</surname></persName>
		</author>
		<idno type="DOI">10.1109/MGRS.2017.2762307</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Geosci. Remote Sens. Mag</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="8" to="36" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<analytic>
		<title level="a" type="main">Coordinatecleaner: standardized cleaning of occurrence records from biological collection databases</title>
		<author>
			<persName><forename type="first">A</forename><surname>Zizka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Silvestro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Andermann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Azevedo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Duarte Ritter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Edler</surname></persName>
		</author>
		<idno type="DOI">10.1111/2041-210X.13152</idno>
	</analytic>
	<monogr>
		<title level="j">Methods Ecol. Evolut</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="744" to="751" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b84">
	<analytic>
		<title level="a" type="main">Automated conservation assessment of the orchid family with deep learning</title>
		<author>
			<persName><forename type="first">A</forename><surname>Zizka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Silvestro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Vitt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">M</forename><surname>Knight</surname></persName>
		</author>
		<idno type="DOI">10.1111/cobi.13616</idno>
	</analytic>
	<monogr>
		<title level="j">Conservat. Biol</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="897" to="908" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b85">
	<analytic>
		<title level="a" type="main">A standard protocol for reporting species distribution models</title>
		<author>
			<persName><forename type="first">D</forename><surname>Zurell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Franklin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>König</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Bouchet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">F</forename><surname>Dormann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Elith</surname></persName>
		</author>
		<idno type="DOI">10.1111/ecog.04960</idno>
	</analytic>
	<monogr>
		<title level="j">Ecography</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="page" from="1261" to="1277" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>