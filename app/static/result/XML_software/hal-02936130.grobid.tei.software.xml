<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Extending a Fuzzy Polarity Propagation Method for Multi-Domain Sentiment Analysis with Word Embedding and POS Tagging</title>
				<funder ref="#_9Yavx6v">
					<orgName type="full">Agence Nationale de la Recherche</orgName>
					<orgName type="abbreviated">ANR</orgName>
				</funder>
				<funder ref="#_BXhGxWp">
					<orgName type="full">French government</orgName>
				</funder>
				<funder ref="#_V7BgXnf">
					<orgName type="full">CNRS</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Claude</forename><surname>Pasquier</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Célia</forename><surname>Da Costa Pereira</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Andrea</forename><forename type="middle">G B</forename><surname>Tettamanzi</surname></persName>
						</author>
						<title level="a" type="main">Extending a Fuzzy Polarity Propagation Method for Multi-Domain Sentiment Analysis with Word Embedding and POS Tagging</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">66FED8948CCA1084F0BFF429F3E4AE39</idno>
					<idno type="DOI">10.3233/FAIA200338</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-04-12T14:51+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Within multi-domain sentiment analysis, we study how different domain-dependent polarities can be learned for the same concepts. To this aim, we extend an existing approach based on the propagation of fuzzy polarities over a semantic graph capturing background linguistic knowledge to learn concept polarities with respect to various domains and their uncertainty from labeled datasets. In particular, we use POS tagging to refine the association between terms and concepts and word embedding to enhance the construction of the semantic graph. The proposed approach is then evaluated on a standard benchmark, showing that the combined use of POS tagging and word embedding improves its performance. One particularly strong point of the proposed approach is its recall, which is always very close to 100%. In addition, we observe that it exhibits good cross-domain generalization capabilities.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>The aim of a sentiment analysis task is to determine the polarity (positive, negative or neutral) of a document with respect to a topic <ref type="bibr" target="#b30">[31,</ref><ref type="bibr" target="#b29">30]</ref>, given the polarities of the different words in the document. However, as it has been pointed out in <ref type="bibr" target="#b41">[42]</ref> for example, the polarity of some words often depends on the domain knowledge considered. By way of example, let us consider (as in <ref type="bibr" target="#b41">[42]</ref>) the word "long" which has a positive polarity in the Camera domain, but a negative polarity if we are characterizing the execution time of a computer program. <ref type="bibr">Schouten et al.</ref> showed in <ref type="bibr" target="#b32">[33]</ref> that including conceptbased features instead of term-based features always helps improving the performance of multi-domain sentiment analysis methods. The good quality of the results obtained with this relatively straightforward setup encourages the use of more advanced ways of handling semantic information.</p><p>Several other solutions have been proposed in the literature. For instance, Yoshida et al. <ref type="bibr" target="#b41">[42]</ref> proposed a solution to improve transfer learning methods. To be more precise, while the solutions in the literature learn a model for a given (single) domain and make it applicable to another (single) domain <ref type="bibr" target="#b9">[10]</ref>, the solution they proposed consists in generalizing that method-the model was constructed from the datasets corresponding to different domains and was also applicable to different domains. However, as it has been well underlined by Abdullah et al. <ref type="bibr" target="#b0">[1]</ref>, the main drawback of transfer learning techniques is that 1 Université Côte d'Azur, CNRS, I3S, France, email: claude.pasquier@univcotedazur.fr, celia.da-costa-pereira@univ-cotedazur.fr 2 Université Côte d'Azur, Inria, CNRS, I3S, France, email: andrea.tettamanzi@univ-cotedazur.fr Even though the methods were able to adapt the relevant sentiment features between different domains, the transfer learning approach imposes the necessity to build a new transfer model, each time a new domain needs to be analysed. This limits its generalization's capability.</p><p>Dragoni et al. <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b8">9]</ref> use fuzzy logic to model the relationships between the polarity of concepts and the domain. They used a two-level graph, where the first level represents the relations between concepts, whereas the second level represents the relations between the concepts and their polarities in the various targeted domains, the idea being to capture the fact that the same concept can be positive in one domain, but negative in another. This is accomplished thanks to a polarity propagation algorithm and without the necessity of starting the learning process for each different domain. The main advantage of that approach, named MDFSA (Multi-Domain Fuzzy Sentiment Analyzer) which has been the winner of the ESWC 2014 Concept-Level Sentiment Analysis Challenge <ref type="bibr" target="#b6">[7]</ref>, is that it both accounts for the conceptual representation of the terms in the documents by using WordNet and SenticNet, and proposes one possible solution avoiding to build a new model each time a new domain needs to be analysed.</p><p>However, by simply using these resources, some problems remain:</p><p>1. it is not possible to discard some of the remaining ambiguities due to the fact that a synset (roughly, a concept) corresponds to a group of words (nouns, adjectives, verbs and adverbs) that can be interchangeable and that denote a particular meaning or usedepending on the type of the term used (noun, adjective, verb or adverb), the meaning of the word can change; as an example the term "light" that can be, according to WordNet 3.1, a noun ("do you have a light?"), a verb ("light a cigarette"), an adjective ("a light diet") or an adverb ("experienced travelers travel light"). 2. another disadvantage is that in the implementation of their work, they of course consider each domain as independent of each other, but they use the same stopping criterion for the propagation algorithm for the different domains which could be challenged-the iterative process stops as soon as the sum of the variations in polarity for each concept and domain falls below a fixed threshold, without taking into account the fact that the size of the domains may be very different, so that simultaneous stopping of propagation could be premature for some domains and delayed for others; 3. in MDFSA, the propagation of polarities takes place without taking into account the similarity of related concepts in the graph. Indeed, the more similar the concepts are, the higher should be the weights associated with them in the graph.</p><p>Here, we propose an extension of the MDFSA approach whose aim is to propose solutions for the three above-mentioned problems.</p><p>For the purpose of (1), deciding whether a term occurring in a document is associated to a synset v or not, we look at its POS tag and we consider it an instance of v only if its POS tag matches the POS of v. Concerning (2), the propagation stopping problem, we propose to specify a threshold that applies to each domain separately and that is relative to the number of different nodes composing the semantic graph of the domain. Finally, concerning <ref type="bibr" target="#b2">(3)</ref>, the similarities between the related concepts in the graph, in addition to the synonymy relationships defined in WordNet, we use a pre-trained word embedding model to complete the semantic graph with relationships of closeness between terms.</p><p>The results obtained are promising and encouraging. Indeed, when applied to the DRANZIERA dataset <ref type="bibr" target="#b8">[9]</ref>, with the same evaluation protocol as in <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b8">9]</ref>, the average precision obtained over all 20 domains is 0.7617, which constitutes a significant improvement over MDFSA-NODK <ref type="bibr" target="#b7">[8]</ref> which obtains a precision of 0.7145 and IRSA-NODK <ref type="bibr" target="#b5">[6]</ref> with a precision of 0.6784. An important result is that this improvement in precision score does not come at the expense of the recall value, which is considerably higher than the other methods tested on the same dataset.</p><p>We have also trained our method on each of the domains of the DRANZIERA dataset and use the obtained models to predict the orientation (positive or negative) of movie reviews from distinct datasets <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b16">17]</ref>. Surprisingly, the best precision was obtained when the training was performed with the DRANZIERA reviews belonging to the 'Music' domain. Other domains that lead to good results are 'Books', 'Movies TV' and 'Video games', which are all somehow broadly related to entertainment or culture.</p><p>The rest of the paper is structured as follows. Section 2 presents some background with relevant definitions on Fuzzy Set theory. Section 3 describes all the originalities of our approach with a detailed description of the respurces we used. Section 4 presents the fuzzy polarity propagation algorithm in general, and the extensions we have done in particular. Section 5 presents the experiments and discuss the results. Finally, Section 6 concludes the paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">BACKGROUND ON FUZZY SET THEORY</head><p>In this section we provide basic definitions and results about fuzzy sets, which will be used in the rest of the article.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Fuzzy Sets</head><p>Fuzzy sets <ref type="bibr" target="#b42">[43]</ref>, allow the representation of imprecise information. Information is imprecise when the value of the variable to which it refers cannot be completely determined within a given universe of discourse. Fuzzy sets are then a generalization of classical sets obtained by replacing the characteristic function of a set A, χ A , which takes up values in {0, 1} (χ A (x) = 1 iff x ∈ A, χ A (x) = 0 otherwise) with a membership function μ A , which can take up any value in [0, 1]. The value μ A (x) or, more simply, A(x) is the membership degree of element x in A, i.e., the degree to which x belongs in A.</p><p>A fuzzy set is completely defined by its membership function. Therefore, it is useful to define a few terms describing various features of this function, summarized in Figure <ref type="figure" target="#fig_0">1</ref>. Given a fuzzy set A, its core is the (conventional) set of all elements x such that A(x) = 1; its support, supp(A), is the set of all x such that A(x) &gt; 0. A fuzzy set is normal if its core is nonempty. The set of all elements x of A such that A(x) ≥ α, for a given α ∈ (0, 1], is called the α-cut of A, denoted A α . The usual set-theoretic operations of union, intersection, and complement can be defined as a generalization of their counterparts on classical sets by introducing two families of operators, called triangular norms and triangular co-norms. In practice, it is usual to employ the min norm for intersection and the max co-norm for union. Given two fuzzy sets A and B, and an element x,</p><formula xml:id="formula_0">(A ∪ B)(x) = max{A(x), B(x)}; (1) (A ∩ B)(x) = min{A(x), B(x)}; (2) Ā(x) = 1 -A(x).</formula><p>(3)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">The Extension Principle</head><p>The extension principle <ref type="bibr" target="#b43">[44]</ref> is the main formal tool for making any mathematical theory fuzzy in a consistent and well-founded way.</p><p>Let U be the Cartesian product of n universes U 1 , . . . , U n and let A 1 , . . . , A n be an equal number of fuzzy sets defined in U 1 , . . . , U n respectively.</p><p>Suppose t : U → V is a morphism from U into a new universe V . The question we ask is what the image of a fuzzy subset of U in this new universe V would be under the morphism t. This image would also be a fuzzy set, and its membership function would be calculated from the membership function of the original set and the morphism t.</p><p>Let B represent the fuzzy set induced in V by morphism t from the fuzzy sets A 1 , . . . , A n defined in U . The Extension Principle states that B has membership function, for all y ∈ V ,</p><formula xml:id="formula_1">μ B (y) = sup (x 1 ,...,x n )∈t -1 (y) min{μ A 1 (x 1 ), . . . , μ A n (x n )}. (<label>4</label></formula><formula xml:id="formula_2">)</formula><p>B is said to extend fuzzy sets A1, . . . , A n in V . Equation 4 is expressed for morphisms t of general form. If t is a discrete-valued function, the sup operator can be replaced by the max operator.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Defuzzification Methods</head><p>There may be situations in which the output of a fuzzy inference needs to be a crisp number y * instead of a fuzzy set R. Defuzzification is the conversion of a fuzzy quantity into a precise quantity.</p><p>At least seven methods in the literature are popular for defuzzifying fuzzy outputs <ref type="bibr" target="#b14">[15]</ref>, which are appropriate for different application contexts. The centroid method is the most prominent and physically appealing of all the defuzzification methods. It results in a crisp value</p><formula xml:id="formula_3">y * = yμR(y)dy μR(y)dy , (<label>5</label></formula><formula xml:id="formula_4">)</formula><p>where the integration can be replaced by summation in discrete cases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">MATERIAL</head><p>Our method is based on fuzzy set theory (cf. Section 2) and exploits background knowledge about concepts. This background knowledge is represented by a semantic graph composed of vertices, which represent either concepts or terms, and edges, which represent semantic relations. In our approach, we distinguish concepts, which are abstract notions representing meaning, from terms, which are tangible ways of expressing concepts (in written language, they are words or groups of words).</p><p>The backbone of our semantic graph is based on WordNet <ref type="bibr" target="#b21">[22]</ref>, an online lexical database in which nouns, verbs, adjectives, and adverbs are organized into sets of synonyms (synsets), each representing a lexicalized concept. In this database, all synsets are connected to other synsets by means of semantic relationships. In our work, we use the relationships of synonymy, antonymy and hypernymy.</p><p>WordNet is built around the notion of concept, but a written text is composed of words, not concepts, and words having several distinct meanings (which is the norm for the most frequent words <ref type="bibr" target="#b4">[5]</ref>) are represented as many distinct synsets. It is therefore necessary to undergo a preprocessing phase in order to link the words found in the texts as accurately as possible to their corresponding synsets. The first approach we propose here to reduce ambiguity is to parse the text in order to take into account the part of speech (POS) of the tokens when associating the corresponding synset. Indeed, many terms, taken independently, can belong to different grammatical types (for example the word "course" that, depending on the context, can be a verb, a noun or an adverb). Using the POS of terms enables a more reliable association with synsets.</p><p>Another approach, complementary to the use of POS tags, is the integration with other public resources.</p><p>In our method, we combine WordNet with SenticNet <ref type="bibr" target="#b3">[4]</ref>, a publicly available resource for opinion mining. The latest version (Sen-ticNet5) covers 100,000 common-sense concepts, which are assigned values corresponding to various characteristics (polarity, pleasantness, attention, sensitivity, and aptitude) and are semantically linked to other concepts. The use of SenticNet allows, on the one hand, to extend the coverage of WordNet by allowing synsets to be assigned to terms or groups of terms that are not indexed in WordNet and, on the other hand, to resolve a number of cases of ambiguity. The methodology employed to link WordNet and SenticNet entries is identical to that used by Dragoni et al <ref type="bibr" target="#b7">[8]</ref>. It should be noted here that Sen-ticNet is only used to extend WordNet coverage and to increase the accuracy of associations between terms and synsets. The polarities defined by SenticNet, which represent typical values for each term, are not used, because the very assumption on which our approach is based is that polarity is not an intrinsic property of a term, but an extrinsic property that depends on the relation between a term and a domain.</p><p>In addition to the synonymy relationships defined in WordNet, already used in the literature, we use a dataset obtained by word embedding to complete the semantic graph with relationships of closeness (or similarity) between terms. The dataset that we use is a pretrained model computed by applying Word2vec <ref type="bibr" target="#b20">[21]</ref> on roughly 100 billion words from a Google News dataset. <ref type="foot" target="#foot_0">3</ref> This dataset allows to obtain the proximity between each pair of terms by calculating the cosine similarity between their vector representations. In the final semantic network, the distance between terms in the vector space is used to link each term to its five closest terms. These edges are weighted with the value of the cosine similarity between the terms, whereas relationships extracted from WordNet are weighted with 1 (for synonymy and hypernymy relationships) or -1 (for antonymy).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">METHOD</head><p>The algorithm used to learn concept polarities for various domains is an extension of the one described in <ref type="bibr" target="#b7">[8]</ref>. It consists of three phases, which are:</p><p>1. Semantic graph construction from background knowledge; 2. Concept polarity initialization, based on a training set of documents, associated with a domain and labeled with a rating; 3. Propagation of polarity information over the semantic graph.</p><p>Its result is an estimation of polarities, represented as convex fuzzy sets over the [-1, +1] interval, for each concept and for each domain. Figure <ref type="figure">2</ref> illustrates the idea of a semantic graph, whose construction and use is detailed below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Semantic Graph Construction</head><p>The semantic graph is constructed as a graph (V, E). Each element of V is either a concept (in our case a synset defined in WordNet) or the canonical form (lemma) of a term used in the description of the reviews.</p><p>The edges in E are created:</p><p>• between pairs of synsets linked by an is-a relationship in Word-Net, with weight +1;</p><p>• between lemmas associated to WordNet synsets and linked by an synonym relationship, with weight 1; • between lemmas associated to WordNet synsets and linked by an antonym relationship, with weight -1; • between each lemma and the five closest lemmas according to the pretrained word2vec model, with their cosine similarity as weight.</p><p>Each vertex v ∈ V is labeled by a vector p(v) of polarities, one per domain, so that p i (v) is the polarity of v with respect to domain i.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Concept Polarity Initialization</head><p>The initial polarities p (0) (v) of all the vertices of the semantic graph are computed, for each domain i, as</p><formula xml:id="formula_5">p (0) i (v) = pi (v) ∈ [-1, 1],<label>(6)</label></formula><p>where pi (v) is the average polarity of the documents of domain i in the training set, in which at least a term of v occurs. If no term of v occurs in a document of domain i, p</p><formula xml:id="formula_6">(0) i (v) = 0.</formula><p>Here, unlike in the literature, for the purpose of deciding whether a term occurring in a document is associated to a synset v or not, we look at its POS tag and we consider it an instance of v only if its POS tag matches the POS of v.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Polarity Propagation</head><p>In this phase, information about the polarity of vertices is propagated through the edges of the graph, so that concepts for which no polarity information could be directtly extracted from the training set (i.e., those v such that p (0) i (v) = 0 for some i) can "assimilate", as it were, the polarity of their close relatives. In addition, this propagation process may contribute to correct or fine-tune the polarity of incorrectly initialized concepts and, thus, reduce noise.</p><p>Polarity propagation through the graph is carried out iteratively. At each iteration t = 1, 2, . . ., the polarity p (t) i (v) of each vertex v for domain i is updated based on the values of its neighbors N (v) = {v j | (v, v j ) ∈ E} as follows: <ref type="bibr" target="#b6">(7)</ref> where 0 &lt; λ &lt; 1 is the propagation rate, a parameter of the algorithm.</p><formula xml:id="formula_7">p (t+1) (v) = (1 -λ) p (t) (v) + λ 1 N (v) v ∈N (v) p (t) (v ),</formula><p>Notice that the propagation of polarity for one domain does not interact with the same process for the other domains and we can thus consider that polarity propagation is carried out in and independently for each domain.</p><p>Inspired by the principle of simulated annealing <ref type="bibr" target="#b17">[18]</ref>, the propagation rate is decreased at each iteration, according to a parameter A called annealing rate. Thus, the value of λ at iteration t is calculated according to the value of λ at iteration t -1 as follow:</p><formula xml:id="formula_8">λ t = Aλ t-1 . (<label>8</label></formula><formula xml:id="formula_9">)</formula><p>In the method proposed by Dragoni et al. <ref type="bibr" target="#b7">[8]</ref>, the iterative process stops as soon as the sum of the variations of the polarity for each concept and domain falls below a fixed threshold. The drawback of using a fixed convergence limit is that it depends on the dataset used. Indeed, a dataset composed of many domains using lots of different terms will logically generate a greater variation than a smaller dataset. In our proposed method, we specify a threshold that applies to each domain separately and that is relative to the number of different nodes composing the semantic graph of the domain. Thus, for a domain i, the polarity propagation stops when the average variation in term polarity,</p><formula xml:id="formula_10">Δ (t) i = 1 V v p (t) i (v) -p (t-1) i (v) ,<label>(9)</label></formula><p>falls below a threshold L, which is the convergence limit. We denote by t stop i the total number of iterations carried out for domain i until</p><formula xml:id="formula_11">Δ (t) i &lt; L.</formula><p>At each iteration t = 0, 1, 2, . . ., the vectors p (t) (v) are saved in order to exploit them for the calculation of the shapes of the fuzzy membership functions describing the polarity of concept v for each domain. Indeed, the final polarities are represented as trapezoidal fuzzy membership functions, whose core is the interval between the initial polarity computed from the training set, p i (v), t = 0, . . . , t stop i . To sum up, for each domain i, μ v,i is a trapezoid with parameters (a, b, c, d), like the one depicted in Figure <ref type="figure" target="#fig_2">3</ref>, where</p><formula xml:id="formula_12">a = min{p (0) i (v), p (t stop i ) i (v)}, b = max{p (0) i (v), p (t stop i ) i (v)}, c = max{-1, a -σ 2 v,i /2}, d = min{1, b + σ 2 v,i /2}.</formula><p>The idea here is that the most likely values for the polarity of v for a domain are those comprised between the initial and final value of the polarity propagation phase and the more quickly the polarity values converged during that phase, the least uncertainty there is about the resulting polarity estimate. Conversely, a polarity value that converged slowly or with many fluctuations is going to yield a less reliable, and thus more uncertain, estimate.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Document Polarity Calculation</head><p>Once the model is trained according to the algorithm described in the previous sections, the (fuzzy) polarity of a novel document D of domain i is computed as the average of the fuzzy polarities (represented by their trapezoidal membership functions) of all the synsets v whose terms occur in the document:</p><formula xml:id="formula_13">μ i = 1 V i v∈V i μ v,i , (<label>10</label></formula><formula xml:id="formula_14">)</formula><p>where</p><formula xml:id="formula_15">V i = {v ∈ V | v occurs in D}.</formula><p>This average of fuzzy is computed by applying the extension principle, thus yielding, for all x ∈ [-1, 1],</p><formula xml:id="formula_16">μ i (x) = sup x= 1 V i v∈V i x v min v∈ μ v,i (x v ).<label>(11)</label></formula><p>However, given that all μ v,i are trapezoidal with parameters</p><formula xml:id="formula_17">(a v , b v , c v , d v )</formula><p>, as pointed out in <ref type="bibr" target="#b7">[8]</ref>, μ i will always be trapezoidal as well, with parameters</p><formula xml:id="formula_18">1 V i ⎛ ⎝ v∈V i a v , v∈V i b v , v∈V i c v , v∈V i d v ⎞ ⎠ . (<label>12</label></formula><formula xml:id="formula_19">)</formula><p>This fuzzy polarity reflects the uncertainty of the estimate obtained by the model. If a single polarity figure is needed for the application at hand, that can be obtained by applying a defuzzification method, like the centroid method of Equation <ref type="formula" target="#formula_3">5</ref>. This is, at least, what we did for the empirical validation of our method, presented in Section 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">EXPERIMENTS AND RESULTS</head><p>The proposed system has been evaluated using the DRANZIERA evaluation protocol <ref type="bibr" target="#b8">[9]</ref>, a multi-domain sentiment analysis benchmark, which consists of a dataset containing product reviews from 20 different domains, crawled from the Amazon web site, as well as guidelines allowing the fair evaluation and comparison of opinion mining systems. In the dataset of the DRANZIERA benchmark, each domain is composed of five thousand positive and five thousand negative reviews that are split in five folds containing one thousand positive and one thousand negative reviews each.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Experimental Protocol</head><p>As suggested by the guideline of the DRANZIERA evaluation protocol <ref type="bibr" target="#b8">[9]</ref>, the performance of the method has been assessed by performing a 5-fold cross validation. For each specific domain, the method was trained on four of the five folds provided with the benchmark and tested on the remaining fold. The process is repeated five times so that each fold is in turn used for testing. The algorithm depends on three different parameters: the propagation rate λ, which determines the diffusion rate of the polarity values between concepts, the convergence limit L, which represents the criterion for stopping the polarity propagation phase for each domain, and the annealing rate A, used to decrease, at each iteration, the propagation rate (cf. Equation <ref type="formula" target="#formula_8">8</ref>). Using a small portion of the dataset, we have therefore experimented 297 different configurations of parameters (λ, L, A) by varying the propagation rate between 0.1 and 0.9 in 0.1 steps, by testing all values for annealing rate between 0.0 and 1.0 in 0.1 steps and using 10 -1 , 10 -2 and 10 -3 as values for the convergence limit. Our experiments show that using a propagation rate of 0.3, an annealing rate of 0.5 and a convergence limit of 0.01 lead to the best results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Results of DRANZIERA Evaluation</head><p>When applied to the DRANZIERA dataset with the settings previously identified, namely λ = 0.3, L = 0.01, and A = 0.5, the average precision obtained over all 20 domains is 0.7617, which constitutes a significant improvement over MDFSA-NODK <ref type="bibr" target="#b7">[8]</ref>, which obtains a precision of 0.7145, and IRSA-NODK <ref type="bibr" target="#b5">[6]</ref> with a precision of 0.6784. It should be noted that this improvement in precision is not detrimental to the recall value, which is higher than the other methods. As a result, the proposed method obtains an even greater improvement with respect to the other methods if performance is measured in terms of the F1 score, in particular a 6.8% improvement with respect to MDFSA-NODK. Table <ref type="table">1</ref> provides a summary of the comparison of the results obtained by our method with four other methods evaluated on the DRANZIERA dataset, whose results are provided in <ref type="bibr" target="#b8">[9]</ref>.</p><p>Table <ref type="table">1</ref>: Average precision and recall obtained on the 20 domains of the DRANZIERA dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>Precision Recall F1 score MDFSA <ref type="bibr" target="#b7">[8]</ref> 0.6832 0.9245 0.7857 MDFSA-NODK <ref type="bibr" target="#b8">[9]</ref> 0.7145 0.9245 0.8060 IRSA <ref type="bibr" target="#b5">[6]</ref> 0.6598 0.8742 0.7520 IRSA-NODK <ref type="bibr" target="#b8">[9]</ref> 0.6784 0.8742 0.7640 Our Method 0.7617 0.9947 0.8627</p><p>The breakdown of the results obtained on the 20 domains of the DRANZIERA dataset are listed in Table <ref type="table" target="#tab_1">2</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Cross-Domain Transfer Experiment</head><p>To test the generalization capabilities of our approach, we have strived to use our model, trained with DRANZIERA data, on other datasets. Sentiment analysis has become extremely popular but datasets available for use by multi-domain sentiment analysis are still scarce. Ribeiro et al. <ref type="bibr" target="#b31">[32]</ref> benchmarked 24 sentiment analysis methods on 18 datasets. Most of these datasets contain messages posted on various channels (discussion forums, Twitter). However, two datasets do represent movie reviews that could benefit from being processed with our method (although the DRANZIERA dataset does not contain the 'movies' domain as such, it includes some related domains, for example 'Movies TV' or 'Amazon Instant Video', whose reviews may be used to infer the rating of movies).</p><p>We chose to use the dataset proposed by Hutto et al. <ref type="bibr" target="#b16">[17]</ref>, a reanalysis of Pang and Lee's dataset <ref type="bibr" target="#b26">[27]</ref> by 20 independent human raters which can be considered as gold-standard quality.</p><p>Our method, trained on each of the domains of the DRANZIERA dataset was used to predict the orientation of each movie review between positive and negative. The best precision was obtained when the training was performed with the DRANZIERA reviews belonging to the 'Music' domain. The other domains for which the transfer of the learned model is effective are 'Books', 'Movies TV' and 'Video games'.</p><p>Although these are not exactly the categories for which one would have expected to obtain the best cross-domain transfer quality, the result is still consistent. Overall, the reviews that most closely mirror those of the movie reviews are more oriented towards cultural goods, while the most distant ones concern more tangible goods ('Shoes', 'Automotive', 'Home Kitchen', 'Baby'). Table <ref type="table" target="#tab_2">3</ref> lists the precision obtained on both datasets according to the category of the DRANZIERA dataset used for training. Recall values are not displayed because the variation is small; they range from 0.9901 to 0.9965. We can notice, in Table <ref type="table" target="#tab_2">3</ref>, that the domain used for training has a great influence on the results. The precision therefore varies by nearly 0.15 between a transfer done from the 'Music' domain and a transfer from the 'Baby' domain. However, the difference can also be partly explained by the intrinsic score obtained on each DRANZIERA domain. We can indeed notice in Table <ref type="table" target="#tab_1">2</ref>, that the difference in precision between the 'Music' domain and the 'Baby' domain is slightly more than 0.14. Overall, there is a decrease in accuracy when the method, trained on a DRANZIERA domain, is applied to an independent dataset; which seems perfectly logical. However, we can observe significant differences according to the domains. Some cross-domain transfers go very well, such as the transfer from domains like 'Books', 'Movies TV' or 'Amazon Instant Video' to movie reviews since the accuracy decline is less than 0.03. Other cross-domain transfers are more problematic, such as those from 'Electronics', 'Beauty', 'Sports Outdoors', 'Clothing Accessories' or 'Shoes' to movies reviews since the accuracy falls by more than 0.2. These observations also seem to make perfect sense.</p><p>Considering precision, our method is only outperformed by 4 of the 24 methods tested by Ribeiro et al.: SenticNet <ref type="bibr" target="#b2">[3]</ref>, Stanford recursive deep model <ref type="bibr" target="#b34">[35]</ref>, Sentiment140 <ref type="bibr" target="#b10">[11]</ref> and SO-CAL <ref type="bibr" target="#b35">[36]</ref> that obtain a precision of 0.9630, 0.8270, 0.7308 and 0.7165 respectively. The best method, consisting in using only the polarity reported in SenticNet, obtains a high precision but only on a relatively small part of the reviews since its coverage is 0.6941. The second and fourth best methods, Stanford DM and SO-CAL, have a coverage of the same order, 0.9192 and 0.8910 respectively while Sentiment140 is able to attribute a rating to only 18.67% of the reviews. The very good recall of 0.9922 obtained by our method is only exceeded by Emoticons DS. However, the high recall of 0.9979 scored by Emoticon DS is associated with a modest accuracy of 0.5027.</p><p>When recall is considered together with precision (cf. Table <ref type="table" target="#tab_3">4</ref>), our method obtains an F1 score of 0.8223, which is higher than the F1 score of the most precise method, 0.8067, but short of Stanford DM, which has the highest F1 score with 0.8707, while SO-CAL is lower, at 0.7943, and Sentiment140 is far behind with an F1 score of only 0.2974.  <ref type="bibr" target="#b25">[26]</ref> 0.6593 0.7259 0.6910 ANEW SUB <ref type="bibr" target="#b39">[40]</ref> 0.5680 0.9630 0.7145 Emolex <ref type="bibr" target="#b24">[25]</ref> 0.6477 0.7439 0.6925 Emoticons <ref type="bibr" target="#b11">[12]</ref> 0.6000 0.0005 0.0010 Emoticons DS <ref type="bibr" target="#b13">[14]</ref> 0.5027 0.9979 0.6686 NRC Hashtag <ref type="bibr" target="#b22">[23]</ref> 0.6234 0.9347 0.7480 LIWC07 <ref type="bibr" target="#b36">[37]</ref> 0.6300 0.6608 0.6450 LIWC15 <ref type="bibr" target="#b28">[29]</ref> 0.6335 0.6608 0.6469 Opinion Finder <ref type="bibr" target="#b40">[41]</ref> 0.2655 0.4912 0.3447 Opinion Lexicon <ref type="bibr" target="#b15">[16]</ref> 0.6977 0.7728 0.7333 PANAS-t <ref type="bibr" target="#b12">[13]</ref> 0.6630 0.0340 0.0647 Pattern.en <ref type="bibr" target="#b33">[34]</ref> 0.6784 0.6559 0.6670 SANN <ref type="bibr" target="#b27">[28]</ref> 0.6181 0.6176 0.6178 SASA <ref type="bibr" target="#b38">[39]</ref> 0.5741 0.5824 0.5782 Semantria <ref type="bibr" target="#b19">[20]</ref> 0.6964 0.6880 0.6922 SenticNet <ref type="bibr" target="#b2">[3]</ref> 0.9630 0.6941 0.8067 Sentiment140 <ref type="bibr" target="#b10">[11]</ref> 0.7308 0.1867 0.2974 Sentiment140 L <ref type="bibr" target="#b23">[24]</ref> 0.6318 0.9351 0.7541 SentiStrength <ref type="bibr" target="#b37">[38]</ref> 0.6754 0.2698 0.3856 SentiWordNet <ref type="bibr" target="#b1">[2]</ref> 0.6145 0.6253 0.6199 SO-CAL <ref type="bibr" target="#b35">[36]</ref> 0.7165 0.8910 0.7943 Stanford DM <ref type="bibr" target="#b34">[35]</ref> 0.8270 0.9192 0.8707 Umigon <ref type="bibr" target="#b18">[19]</ref> 0.6344 0.5395 0.5831 VADER <ref type="bibr" target="#b16">[17]</ref> 0.6519 0.8270 0.7291 Our Method 0.7021 0.9922 0.8223</p><p>Overall, our method is characterized by its excellent coverage. Indeed, this one is always above 0.99, which means that less than 1% of the reviews are not classified.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">CONCLUSION</head><p>We have proposed solutions to solve three remaining problems of the MDFSA approach. The first solution allows to eliminate some ambiguities arising when associating different types of words (nouns, adjectives, verbs, adverbs) with their synset, thus allowing to propagate the polarity of the document where they occur to the correct vertex of the semantic graph. The second solution that we have proposed consists of making the "propagation stopping time" dependent on the domain size-the propagation phase depends on the number of nodes composing the semantic graph of the domain-, unlike in the MDFSA approach, where the propagation phase stops at the same time for all the domains. This solution allows to save computing cycles for those domains whose polarities converge fast, while guaranteeing that the polarities of all the domains converge. Finally, we improved the construction of the semantic graph by adding weighted edges connecting each vertex to the vertices of its five most similar terms according to a pre-trained word embedding model, thus favoring the propagation of polarities between semantically similar concepts and terms.</p><p>The resulting approach has been validated using a standard evaluation protocol. The results of the evaluation show a significant improvement with respect to the state of the art. We have also tested the cross-domain generalization capabilities of our approach with very promising results.</p><p>Our results seem to confirm that making the construction of the semantic graph more accurate by disambiguating the terms occurring in documents and connecting semantically similar vertices helps to improve both the precision and the coverage of the approach.</p><p>The extensions we have proposed solve, if only partially, some known issues of the approach, but we know there is still much room for improvement by injecting more linguistic knowledge, which is, therefore, the main direction for future work. That might include using a dependency parser to analyze the texts and applying graph embedding techniques to the dependency graph of the sentences where the terms occur. Another possibility would be to use a more sophisticated disambiguation method than just looking at the POS tags of the terms.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Core, support, and α-cuts of a set A of the real line, having membership function μ A .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure</head><label></label><figDesc>Figure An illustration of the semantic graph constructed by the proposed method. Circles represent the vertices of the graph and solid lines its edges. The documents of the training set are shown around the semantic graph. Dashed lines represent the occurrence, in a document, of a term associated with a vertex of the graph (i.e., a lemma or a WordNet synset). Documents are rated (e.g., on a scale from -to ++, which may then be mapped to the [-1, 1] interval).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: A fuzzy set with a trapezoidal membership function, defined by the four parameters (a, b, c, d).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>i</head><label></label><figDesc>(v), and the polarity resulting from the propagation phase, p and whose support extends beyond the core on either side by half the variance σ 2 v,i of the distribution of p (t)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Detail of the results obtained on the 20 domains of the DRANZIERA dataset.</figDesc><table><row><cell>Domain</cell><cell>precision</cell><cell>recall</cell><cell>F1 score</cell></row><row><cell>Music</cell><cell>0.8123</cell><cell>0.9918</cell><cell>0.8931</cell></row><row><cell>Books</cell><cell>0.6789</cell><cell>0.994</cell><cell>0.8068</cell></row><row><cell>Video Games</cell><cell>0.7993</cell><cell>0.9907</cell><cell>0.8848</cell></row><row><cell>Movies TV</cell><cell>0.684</cell><cell>0.9954</cell><cell>0.8108</cell></row><row><cell>Software</cell><cell>0.7344</cell><cell>0.9948</cell><cell>0.8450</cell></row><row><cell>Amazon Instant Video</cell><cell>0.6131</cell><cell>0.9974</cell><cell>0.7594</cell></row><row><cell>Electronics</cell><cell>0.8166</cell><cell>0.9949</cell><cell>0.8970</cell></row><row><cell>Beauty</cell><cell>0.8662</cell><cell>0.9947</cell><cell>0.9260</cell></row><row><cell>Toys Games</cell><cell>0.7746</cell><cell>0.9947</cell><cell>0.8710</cell></row><row><cell>Sports Outdoors</cell><cell>0.8022</cell><cell>0.9951</cell><cell>0.8883</cell></row><row><cell>Health</cell><cell>0.7874</cell><cell>0.993</cell><cell>0.8783</cell></row><row><cell>Office Products</cell><cell>0.7548</cell><cell>0.9965</cell><cell>0.8590</cell></row><row><cell>Patio</cell><cell>0.7611</cell><cell>0.9942</cell><cell>0.8622</cell></row><row><cell>Tools Home Improvement</cell><cell>0.7704</cell><cell>0.9932</cell><cell>0.8677</cell></row><row><cell>Pet Supplies</cell><cell>0.7361</cell><cell>0.9945</cell><cell>0.8460</cell></row><row><cell>Clothing Accessories</cell><cell>0.8302</cell><cell>0.998</cell><cell>0.9064</cell></row><row><cell>Shoes</cell><cell>0.8797</cell><cell>0.9961</cell><cell>0.9343</cell></row><row><cell>Automotive</cell><cell>0.7364</cell><cell>0.9951</cell><cell>0.8464</cell></row><row><cell>Home Kitchen</cell><cell>0.7274</cell><cell>0.9947</cell><cell>0.8403</cell></row><row><cell>Baby</cell><cell>0.6687</cell><cell>0.9955</cell><cell>0.8000</cell></row><row><cell>Average</cell><cell>0.7617</cell><cell>0.9947</cell><cell>0.8627</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 :</head><label>3</label><figDesc>Precision of cross-domain transfer from the 20 categories of the DRANZIERA dataset to gold-standard quality movie reviews.</figDesc><table><row><cell>Domain</cell><cell>expert-rated movies [17]</cell></row><row><cell>Music</cell><cell>0.7003</cell></row><row><cell>Books</cell><cell>0.6658</cell></row><row><cell>Video Games</cell><cell>0.6622</cell></row><row><cell>Movies TV</cell><cell>0.6634</cell></row><row><cell>Software</cell><cell>0.6456</cell></row><row><cell>Amazon Instant Video</cell><cell>0.6384</cell></row><row><cell>Electronics</cell><cell>0.6116</cell></row><row><cell>Beauty</cell><cell>0.6075</cell></row><row><cell>Toys Games</cell><cell>0.6035</cell></row><row><cell>Sports Outdoors</cell><cell>0.6012</cell></row><row><cell>Health</cell><cell>0.6014</cell></row><row><cell>Office Products</cell><cell>0.5939</cell></row><row><cell>Patio</cell><cell>0.5932</cell></row><row><cell>Tools Home Improvement</cell><cell>0.5873</cell></row><row><cell>Pet Supplies</cell><cell>0.5885</cell></row><row><cell>Clothing Accessories</cell><cell>0.5875</cell></row><row><cell>Shoes</cell><cell>0.5853</cell></row><row><cell>Automotive</cell><cell>0.5788</cell></row><row><cell>Home Kitchen</cell><cell>0.5623</cell></row><row><cell>Baby</cell><cell>0.5524</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 :</head><label>4</label><figDesc>A comparison of our method (trained on the Music domain of DRANZIERA) with all the methods benchmarked by Ribeiro et al.<ref type="bibr" target="#b31">[32]</ref>, when applied to the user-rated movies dataset. The highest score of each column is highlited in boldface</figDesc><table><row><cell>Method</cell><cell>Precision</cell><cell>Recall</cell><cell>F1 score</cell></row><row><cell>AFINN</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_0"><p>the dataset is downloadable from https://frama.link/google word2vec</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>ACKNOWLEDGEMENTS</head><p><rs type="person">Célia da Costa Pereira</rs> acknowledges support of the <rs type="projectName">PEPS AIRINFO</rs> project funded by the <rs type="funder">CNRS</rs>.</p><p><rs type="person">Andrea Tettamanzi</rs> has been supported by the <rs type="funder">French government</rs>, through the <rs type="programName">3IA Côte d'Azur "Investments in the Future</rs>" project managed by the <rs type="funder">National Research (ANR)</rs> with the reference number <rs type="grantNumber">ANR-19-P3IA-0002</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funded-project" xml:id="_V7BgXnf">
					<orgName type="project" subtype="full">PEPS AIRINFO</orgName>
				</org>
				<org type="funding" xml:id="_BXhGxWp">
					<orgName type="program" subtype="full">3IA Côte d&apos;Azur &quot;Investments in the Future</orgName>
				</org>
				<org type="funding" xml:id="_9Yavx6v">
					<idno type="grant-number">ANR-19-P3IA-0002</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Challenges and recommended solutions in multi-source and multi-domain sentiment analysis</title>
		<author>
			<persName><forename type="first">Aniza</forename><surname>Nor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ali</forename><surname>Abdullah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ainin</forename><surname>Feizollah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nor</forename><surname>Sulaiman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anuar</forename><surname>Badrul</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="144957" to="144971" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Sentiwordnet 3.0: An enhanced lexical resource for sentiment analysis and opinion mining</title>
		<author>
			<persName><forename type="first">Stefano</forename><surname>Baccianella</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrea</forename><surname>Esuli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fabrizio</forename><surname>Sebastiani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">LREC</title>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="2200" to="2204" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Senticnet 5: Discovering conceptual primitives for sentiment analysis by means of context embeddings</title>
		<author>
			<persName><forename type="first">Erik</forename><surname>Cambria</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Soujanya</forename><surname>Poria</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Devamanyu</forename><surname>Hazarika</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kenneth</forename><surname>Kwok</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="1795" to="1802" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Senticnet: A publicly available semantic resource for opinion mining</title>
		<author>
			<persName><forename type="first">Erik</forename><surname>Cambria</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><surname>Speer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Catherine</forename><surname>Havasi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amir</forename><surname>Hussain</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI Fall Symposium: Commonsense Knowledge</title>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Polysemy and brevity versus frequency in language</title>
		<author>
			<persName><forename type="first">Bernardino</forename><surname>Casas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Antoni</forename><surname>Hernández-Fernández</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ramon</forename><surname>Ferrer-I Cancho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jaume</forename><surname>Baixeries</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Speech &amp; Language</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="page" from="19" to="50" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note>Neus Català,</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Shellfbk: an information retrieval-based system for multi-domain sentiment analysis</title>
		<author>
			<persName><forename type="first">Mauro</forename><surname>Dragoni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 9th International Workshop on Semantic Evaluation</title>
		<meeting>the 9th International Workshop on Semantic Evaluation<address><addrLine>SemEval</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015">2015. 2015</date>
			<biblScope unit="page" from="502" to="509" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A fuzzy system for concept-level sentiment analysis</title>
		<author>
			<persName><forename type="first">Mauro</forename><surname>Dragoni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrea</forename><forename type="middle">G B</forename><surname>Tettamanzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Célia</forename><surname>Da</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Costa</forename><surname>Pereira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SemWebEval@ESWC</title>
		<title level="s">Communications in Computer and Information Science</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="volume">475</biblScope>
			<biblScope unit="page" from="21" to="27" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Propagating and aggregating fuzzy polarities for concept-level sentiment analysis</title>
		<author>
			<persName><forename type="first">Mauro</forename><surname>Dragoni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrea</forename><forename type="middle">G B</forename><surname>Tettamanzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Célia</forename><surname>Da</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Costa</forename><surname>Pereira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognitive Computation</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="186" to="197" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">DRANZIERA: an evaluation protocol for multi-domain opinion mining</title>
		<author>
			<persName><forename type="first">Mauro</forename><surname>Dragoni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrea</forename><forename type="middle">G B</forename><surname>Tettamanzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Célia</forename><surname>Da</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Costa</forename><surname>Pereira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th International Conference on Language Resources and Evaluation (LREC 2016)</title>
		<meeting>the 10th International Conference on Language Resources and Evaluation (LREC 2016)<address><addrLine>Paris, France</addrLine></address></meeting>
		<imprint>
			<publisher>European Language Resources Association (ELRA)</publisher>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Domain adaptation for large-scale sentiment classification: A deep learning approach</title>
		<author>
			<persName><forename type="first">Xavier</forename><surname>Glorot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Antoine</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<publisher>Omnipress</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="513" to="520" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Twitter sentiment classification using distant supervision</title>
		<author>
			<persName><forename type="first">Alec</forename><surname>Go</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richa</forename><surname>Bhayani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lei</forename><surname>Huang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
		<respStmt>
			<orgName>Standford University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">CS224N Project Report</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Comparing and combining sentiment analysis methods</title>
		<author>
			<persName><forename type="first">Pollyanna</forename><surname>Gonc ¸alves</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matheus</forename><surname>Araújo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fabrício</forename><surname>Benevenuto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Meeyoung</forename><surname>Cha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the first ACM conference on Online social networks</title>
		<meeting>the first ACM conference on Online social networks</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="27" to="38" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Panas-t: A pychometric scale for measuring sentiments on twitter</title>
		<author>
			<persName><forename type="first">Pollyanna</forename><surname>Gonc ¸alves</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fabrício</forename><surname>Benevenuto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Meeyoung</forename><surname>Cha</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1308.1857</idno>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Tweetin&apos;in the rain: Exploring societal-scale effects of weather on mood</title>
		<author>
			<persName><forename type="first">Aniko</forename><surname>Hannak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><surname>Anderson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lisa</forename><forename type="middle">Feldman</forename><surname>Barrett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sune</forename><surname>Lehmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alan</forename><surname>Mislove</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mirek</forename><surname>Riedewald</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Sixth International AAAI Conference on Weblogs and Social Media</title>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Defuzzification in fuzzy controllers</title>
		<author>
			<persName><forename type="first">Hans</forename><surname>Hellendoorn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christoph</forename><surname>Thomas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Intelligent and Fuzzy Systems</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="109" to="123" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Mining and summarizing customer reviews</title>
		<author>
			<persName><forename type="first">Minqing</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bing</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the tenth ACM SIGKDD international conference on Knowledge discovery and data mining</title>
		<meeting>the tenth ACM SIGKDD international conference on Knowledge discovery and data mining</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="168" to="177" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Vader: A parsimonious rule-based model for sentiment analysis of social media text</title>
		<author>
			<persName><forename type="first">J</forename><surname>Clayton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><surname>Hutto</surname></persName>
		</author>
		<author>
			<persName><surname>Gilbert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Eighth international AAAI conference on weblogs and social media</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Optimization by simulated annealing</title>
		<author>
			<persName><forename type="first">Scott</forename><surname>Kirkpatrick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Gelatt</surname><genName>Jr</genName></persName>
		</author>
		<author>
			<persName><forename type="first">Mario</forename><forename type="middle">P</forename><surname>Vecchi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SCIENCE</title>
		<imprint>
			<biblScope unit="volume">220</biblScope>
			<biblScope unit="issue">4598</biblScope>
			<biblScope unit="page" from="671" to="680" />
			<date type="published" when="1983">1983</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Umigon: sentiment analysis for tweets based on lexicons and heuristics</title>
		<author>
			<persName><forename type="first">Clement</forename><surname>Levallois</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International workshop on Semantic Evaluation</title>
		<meeting>the International workshop on Semantic Evaluation</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Sentiment extraction -measuring the emotional tone of content</title>
		<author>
			<persName><surname>Lexalytics</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Efficient estimation of word representations in vector space</title>
		<author>
			<persName><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Greg</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeffrey</forename><surname>Dean</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1301.3781</idno>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Wordnet: a lexical database for english</title>
		<author>
			<persName><forename type="first">George</forename><forename type="middle">A</forename><surname>Miller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="39" to="41" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main"># emotional tweets</title>
		<author>
			<persName><forename type="first">M</forename><surname>Saif</surname></persName>
		</author>
		<author>
			<persName><surname>Mohammad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First Joint Conference on Lexical and Computational Semantics</title>
		<meeting>the First Joint Conference on Lexical and Computational Semantics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="246" to="255" />
		</imprint>
	</monogr>
	<note>Proceedings of the Sixth International Workshop on Semantic Evaluation</note>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><surname>Saif</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Svetlana</forename><surname>Mohammad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaodan</forename><surname>Kiritchenko</surname></persName>
		</author>
		<author>
			<persName><surname>Zhu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1308.6242</idno>
		<title level="m">Nrccanada: Building the state-of-the-art in sentiment analysis of tweets</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Crowdsourcing a wordemotion association lexicon</title>
		<author>
			<persName><forename type="first">M</forename><surname>Saif</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><forename type="middle">D</forename><surname>Mohammad</surname></persName>
		</author>
		<author>
			<persName><surname>Turney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Intelligence</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="436" to="465" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">A new anew: Evaluation of a word list for sentiment analysis in microblogs</title>
		<author>
			<persName><surname>Finn Årup Nielsen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1103.2903</idno>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">A sentimental education: Sentiment analysis using subjectivity summarization based on minimum cuts</title>
		<author>
			<persName><forename type="first">Bo</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lillian</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 42nd annual meeting on Association for Computational Linguistics</title>
		<meeting>the 42nd annual meeting on Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="271" to="278" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Sentiment analysis of user comments for one-class collaborative filtering over ted talks</title>
		<author>
			<persName><forename type="first">Nikolaos</forename><surname>Pappas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrei</forename><surname>Popescu-Belis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 36th international ACM SIGIR conference on Research and development in information retrieval</title>
		<meeting>the 36th international ACM SIGIR conference on Research and development in information retrieval</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="773" to="776" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">The development and psychometric properties of liwc2015</title>
		<author>
			<persName><forename type="first">Ryan</forename><forename type="middle">L</forename><surname>James W Pennebaker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kayla</forename><surname>Boyd</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kate</forename><surname>Jordan</surname></persName>
		</author>
		<author>
			<persName><surname>Blackburn</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Sentiment analysis for the tweets that contain the word &quot;earthquake</title>
		<author>
			<persName><forename type="first">Mironela</forename><surname>Pirnau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2018 10th International Conference on Electronics, Computers and Artificial Intelligence (ECAI)</title>
		<imprint>
			<date type="published" when="2018-06">June 2018</date>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">The CLAUSY system at ESWC-2018 challenge on semantic sentiment analysis</title>
		<author>
			<persName><forename type="first">Andi</forename><surname>Rexha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><surname>Kröll</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mauro</forename><surname>Dragoni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roman</forename><surname>Kern</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SemWebEval@ESWC</title>
		<title level="s">Communications in Computer and Information Science</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">927</biblScope>
			<biblScope unit="page" from="186" to="196" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Sentibench-a benchmark comparison of state-of-the-practice sentiment analysis methods</title>
		<author>
			<persName><forename type="first">Matheus</forename><surname>Filipe N Ribeiro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pollyanna</forename><surname>Araújo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marcos</forename><surname>Gonc ¸alves</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fabrício</forename><surname>André Gonc ¸alves</surname></persName>
		</author>
		<author>
			<persName><surname>Benevenuto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">EPJ Data Science</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">23</biblScope>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">The benefit of concept-based features for sentiment analysis</title>
		<author>
			<persName><forename type="first">Kim</forename><surname>Schouten</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Flavius</forename><surname>Frasincar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SemWebEval@ESWC</title>
		<title level="s">Communications in Computer and Information Science</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="volume">548</biblScope>
			<biblScope unit="page" from="223" to="233" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Pattern for python</title>
		<author>
			<persName><forename type="first">Tom</forename><surname>De</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Smedt</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Walter</forename><surname>Daelemans</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="2063" to="2067" />
			<date type="published" when="2012-06">Jun. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Recursive deep models for semantic compositionality over a sentiment treebank</title>
		<author>
			<persName><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Perelygin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jean</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><surname>Chuang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Potts</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 conference on empirical methods in natural language processing</title>
		<meeting>the 2013 conference on empirical methods in natural language processing</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="1631" to="1642" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Lexicon-based methods for sentiment analysis</title>
		<author>
			<persName><forename type="first">Maite</forename><surname>Taboada</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julian</forename><surname>Brooke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Milan</forename><surname>Tofiloski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kimberly</forename><forename type="middle">D</forename><surname>Voll</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Manfred</forename><surname>Stede</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="267" to="307" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">The psychological meaning of words: Liwc and computerized text analysis methods</title>
		<author>
			<persName><forename type="first">R</forename><surname>Yla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><forename type="middle">W</forename><surname>Tausczik</surname></persName>
		</author>
		<author>
			<persName><surname>Pennebaker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of language and social psychology</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="24" to="54" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Heart and soul: Sentiment strength detection in the social web with sentistrength (summary book chapter)</title>
		<author>
			<persName><forename type="first">Mike</forename><surname>Thelwall</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Cyberemotions: Collective emotions in cyberspace</title>
		<meeting><address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="119" to="134" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">A system for real-time twitter sentiment analysis of 2012 us presidential election cycle</title>
		<author>
			<persName><forename type="first">Hao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dogan</forename><surname>Can</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abe</forename><surname>Kazemzadeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Franc</forename><surname>¸ois Bar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shrikanth</forename><surname>Narayanan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACL 2012 system demonstrations</title>
		<meeting>the ACL 2012 system demonstrations</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="115" to="120" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Norms of valence, arousal, and dominance for 13,915 english lemmas</title>
		<author>
			<persName><forename type="first">Amy Beth</forename><surname>Warriner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Victor</forename><surname>Kuperman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marc</forename><surname>Brysbaert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Behavior research methods</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1191" to="1207" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Recognizing contextual polarity in phrase-level sentiment analysis</title>
		<author>
			<persName><forename type="first">Theresa</forename><surname>Wilson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Janyce</forename><surname>Wiebe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paul</forename><surname>Hoffmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of human language technology conference and conference on empirical methods in natural language processing</title>
		<meeting>human language technology conference and conference on empirical methods in natural language processing</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="347" to="354" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Transfer learning for multiple-domain sentiment analysis-identifying domain dependent/independent word polarity</title>
		<author>
			<persName><forename type="first">Yasuhisa</forename><surname>Yoshida</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tsutomu</forename><surname>Hirao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tomoharu</forename><surname>Iwata</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Masaaki</forename><surname>Nagata</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuji</forename><surname>Matsumoto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="1286" to="1291" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Fuzzy sets</title>
		<author>
			<persName><forename type="first">A</forename><surname>Lotfi</surname></persName>
		</author>
		<author>
			<persName><surname>Zadeh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information and Control</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="338" to="353" />
			<date type="published" when="1965">1965</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">The concept of a linguistic variable and its application to approximate reasoning -i</title>
		<author>
			<persName><forename type="first">A</forename><surname>Lotfi</surname></persName>
		</author>
		<author>
			<persName><surname>Zadeh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Inf. Sci</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="199" to="249" />
			<date type="published" when="1975">1975</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
