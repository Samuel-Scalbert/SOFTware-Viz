<TEI xmlns="http://www.tei-c.org/ns/1.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xml:space="preserve" xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd">
	<teiHeader xml:lang="fr">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">XCM: An Explainable Convolutional Neural Network for Multivariate Time Series Classification</title>
			</titleStmt>
			<publicationStmt>
				<publisher />
				<availability status="unknown"><licence /></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Kevin</forename><surname>Fauvel</surname></persName>
							<email>kevin.fauvel@inria.fr</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Inria</orgName>
								<orgName type="institution" key="instit2">Univ Rennes</orgName>
								<orgName type="institution" key="instit3">CNRS</orgName>
								<orgName type="institution" key="instit4">IRISA</orgName>
								<address>
									<settlement>Rennes</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Tao</forename><surname>Lin</surname></persName>
							<email>lintao1@zju.edu.cn</email>
							<affiliation key="aff1">
								<orgName type="institution">Zhejiang University</orgName>
								<address>
									<settlement>Hangzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Véronique</forename><surname>Masson</surname></persName>
							<email>veronique.masson@irisa.fr</email>
							<affiliation key="aff2">
								<orgName type="institution" key="instit1">Univ Rennes</orgName>
								<orgName type="institution" key="instit2">Inria</orgName>
								<orgName type="institution" key="instit3">CNRS</orgName>
								<orgName type="institution" key="instit4">IRISA</orgName>
								<address>
									<settlement>Rennes</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Élisa</forename><surname>Fromont</surname></persName>
							<email>elisa.fromont@irisa.fr</email>
							<affiliation key="aff3">
								<orgName type="institution" key="instit1">Univ Rennes</orgName>
								<orgName type="institution" key="instit2">IUF</orgName>
								<orgName type="institution" key="instit3">Inria</orgName>
								<orgName type="institution" key="instit4">CNRS</orgName>
								<orgName type="institution" key="instit5">IRISA</orgName>
								<address>
									<settlement>Rennes</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Alexandre</forename><surname>Termier</surname></persName>
							<email>alexandre.termier@irisa.fr</email>
							<affiliation key="aff2">
								<orgName type="institution" key="instit1">Univ Rennes</orgName>
								<orgName type="institution" key="instit2">Inria</orgName>
								<orgName type="institution" key="instit3">CNRS</orgName>
								<orgName type="institution" key="instit4">IRISA</orgName>
								<address>
									<settlement>Rennes</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">XCM: An Explainable Convolutional Neural Network for Multivariate Time Series Classification</title>
					</analytic>
					<monogr>
						<imprint>
							<date />
						</imprint>
					</monogr>
					<idno type="MD5">74B35E09B958F3B651AB9369A1705347</idno>
					<idno type="DOI">10.3390/math9233137</idno>
					<note type="submission">Submitted on 7 Dec 2021</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-04-12T14:52+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid" />
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Explainable Convolutional Neural Network for Multivariate Time Series Classification convolutional neural network</term>
					<term>explainability</term>
					<term>multivariate time series classification</term>
				</keywords>
			</textClass>
			<abstract>
<div><p>ou non, émanant des établissements d'enseignement et de recherche français ou étrangers, des laboratoires publics ou privés.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="fr">
		<body>
<div><head n="1.">Introduction</head><p>Following the remarkable availability of multivariate temporal data, Multivariate Time Series (MTS) analysis is becoming a necessary procedure in a wide range of application domains (e.g., finance <ref type="bibr" target="#b0">[1]</ref>, healthcare <ref type="bibr" target="#b1">[2]</ref>, mobility <ref type="bibr" target="#b2">[3]</ref>, and natural disasters <ref type="bibr" target="#b3">[4]</ref>). A time series is a sequence of real values ordered according to time; and when a set of coevolving time series are recorded simultaneously by a set of sensors, it is called an MTS. In this paper, we address the issue of MTS classification, which consists of learning the relationship between an MTS and its label.</p><p>According to the results published, the most accurate state-of-the-art MTS classifier on average is a deep learning approach (MLSTM-FCN <ref type="bibr" target="#b4">[5]</ref>). MLSTM-FCN consists of the concatenation of a Long Short-Term Memory (LSTM) block with a Convolutional Neural Network (CNN) block composed of three convolutional sub-blocks. However, MLSTM-FCN outperforms the second-best MTS classifier (Bag-of-Words method <software ContextAttributes="used">WEASEL+MUSE</software> <ref type="bibr" target="#b5">[6]</ref>) only on the large datasets (relatively to the public UEA archive <ref type="bibr" target="#b6">[7]</ref>training set size ≥ 500). This deep learning approach contains a significant number of trainable parameters, which could be an important reason for its poor performance on small datasets. Moreover, for many applications, the adoption of machine learning methods cannot rely solely on their prediction performance. For example, the European Union's General Data Protection Regulation (GDPR), which became enforceable on 25 May 2018, introduces a right to explanation for all individuals so that they can obtain "meaningful explanations of the logic involved" when automated decision making has "legal effects" on individuals or similarly "significantly affecting" them ( https://ec.europa.eu/info/law/law-topic/data-protection_en (accessed on 1 November 2021)). As far as we have seen, an architecture concatenating a LSTM network with a CNN such as MLSTM-FCN, or a classifier based on unigrams/bigrams extraction following a Symbolic Fourier Approximation <ref type="bibr" target="#b7">[8]</ref> such as <software ContextAttributes="used">WEASEL+MUSE</software>, cannot provide perfectly faithful explanations as they rely solely on post hoc model-agnostic explainability methods <ref type="bibr" target="#b8">[9]</ref>, which could prevent their use in numerous applications. Faithfulness is critical as it corresponds to the level of trust an end-user can have in the explanations of model predictions, i.e., the level of relatedness of the explanations to what the model actually computes. Hence, we propose a new compact (in terms of the number of parameters) and explainable deep learning approach for MTS classification that performs well on both large and small datasets while providing faithful explanations.</p><p>CNNs along with post hoc model-specific saliency methods such as Gradientweighted Class Activation Mapping-Grad-CAM <ref type="bibr" target="#b9">[10]</ref>-have the potential to have a compact architecture while enabling faithful explanations <ref type="bibr" target="#b10">[11]</ref>. A recent CNN, <software ContextAttributes="used">MTEX</software>-CNN <ref type="bibr" target="#b11">[12]</ref> proposes using 2D and 1D convolution filters in sequence to extract key MTS information, i.e., information relative to the observed variables and time, respectively. However, as confirmed by our experiments, the features related to time which are extracted from the output features of the first stage (relative to each observed variable) cannot fully incorporate the timing information from the input data and subsequently yield poor performance compared to the state-of-the-art MTS classifiers. In addition, the significant number of trainable parameters of <software ContextAttributes="used">MTEX</software>-CNN affects its generalization ability on small datasets. Finally, <software ContextAttributes="used">MTEX</software>-CNN requires upsampling processes on feature maps when applying Grad-CAM, which can lead to an imprecise identification of the regions of the input data that are important for predictions.</p><p>Therefore, we propose a new faithfully eXplainable CNN method for MTS classification (XCM) which improves <software>MTEX</software>-CNN in three substantial ways: (i) it generates features by extracting information relative to the observed variables and timestamps in parallel and directly from the input data; (ii) it enhances the generalization ability by adopting a compact architecture (in terms of the number of parameters); and (iii) it allows precise identification of the observed variables and timestamps of the input data that are important for predictions by avoiding upsampling processes. Summarizing our main contributions:</p></div>
<div><head>•</head><p>We present XCM, an end-to-end new compact and explainable convolutional neural network for MTS classification which supports its predictions with faithful explanations;</p></div>
<div><head>•</head><p>We show that XCM outperforms the state-of-the-art MTS classifiers on both the large and small UEA datasets <ref type="bibr" target="#b6">[7]</ref>; • We illustrate on a synthetic dataset that XCM enables a more precise identification of the regions of the input data that are important for predictions compared to the current faithfully explainable deep learning MTS classifier <software ContextAttributes="used">MTEX-CNN</software>; •</p><p>We show that XCM outperforms the current most accurate state-of-the-art algorithm on a real-world application while enhancing explainability by providing faithful and more informative explanations.</p><p>The rest of this paper is organized as follows: Section 2 presents the related work concerning MTS classification and explainability; Section 3 details XCM architecture; Section 4 presents our evaluation method; and finally, Section 5 discusses our results.</p></div>
<div><head n="2.">Related Work</head><p>In this section, we first introduce the background of our study. Then, we present the state-of-the-art MTS classifiers, and we end with existing explainability methods supporting CNNs models' predictions.</p></div>
<div><head n="2.1.">Background</head><p>We address the issue of supervised learning for classification. Classification consists of learning a function that maps an input data to its label: given an input space X, an output space Y, an unknown distribution P over X × Y, a training set sampled from P, and a 0-1 loss function ℓ 0-1 compute function h * as follows:</p><formula xml:id="formula_0">h * = arg min h E (x,y)∼P [ℓ 0-1 (h, (x, y))]<label>(1)</label></formula><p>In this study, classification is performed on multivariate time series datasets. A Multivariate Time Series (MTS) M = {x 1 , ..., x d } ∈ R d * l is an ordered sequence of d ∈ N streams with x i = (x i,1 , ..., x i,l ), where l is the length of the time series and d is the number of multivariate dimensions. We address MTS generated from automatic sensors with a fixed and synchronized sampling along all dimensions. An example of an MTS with two dimensions and a length of 100 is given at the top of Figure <ref type="figure" target="#fig_4">5</ref>.</p><p>Before presenting the state-of-the-art MTS classifiers, we introduce some notions about neural networks and the subfamily of our approach, Convolutional Neural Networks (CNNs). A neural network is a composition of L parametric functions referred to as layers, where each layer is considered a representation of the input domain <ref type="bibr" target="#b12">[13]</ref>. One layer l i , such as i ∈ {1, ..., L}, contains neurons, which are small units that compute one element of the layer's output. The layer l i takes as input the output of its previous layer l i-1 and applies a transformation to compute its own output. The behavior of these transformations is controlled by a set of parameters θ i for each layer and an activation sublayer to shape the nonlinearity of the network. These parameters are called weights and link the input of the previous layer to the output of the current layer based on matrix multiplication. This process is also referred to as feedforward propagation in the deep learning literature and is the constituent of multilayer perceptrons (MLPs). A neural network is usually called "deep" when it contains more than one layer between its input and output layer. Following the good performance of CNN architectures in image recognition <ref type="bibr" target="#b13">[14]</ref> and natural language processing <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b15">16]</ref>, CNNs have started to be adopted for time series analysis <ref type="bibr" target="#b16">[17]</ref>. CNNs are neural networks that use convolution in place of general matrix multiplication in at least one of their layers <ref type="bibr" target="#b12">[13]</ref>. A convolution can be seen as applying and sliding a filter over the time series. The use of different types, numbers and sequences of filters allow the learning of multiple discriminative features (feature maps) useful for the classification task.</p></div>
<div><head n="2.2.">MTS Classifiers</head><p>The state-of-the-art MTS classifiers are usually grouped into three categories: similarity-based, feature-based and deep learning methods.</p><p>Similarity-based methods make use of similarity measures to compare two MTS (e.g., Euclidean distance). Dynamic Time Warping (DTW) has been shown to be the best similarity measure to use along with the k-Nearest Neighbors (k-NN) <ref type="bibr" target="#b17">[18]</ref>. DTW is not a distance metric as it does not fully satisfy the required properties (the triangle inequality in particular), but its use as similarity measure along with the NN-rule is valid <ref type="bibr" target="#b18">[19]</ref>. There are two versions of kNN-DTW for MTS, dependent (DTW D ) and independent (DTW I ), and neither dominates the other <ref type="bibr" target="#b19">[20]</ref>. DTW I measures the cumulative distances of all dimensions independently measured under DTW. DTW D uses a similar calculation with single-dimensional time series; it considers the squared Euclidean accumulated distance over the multiple dimensions.</p><p>Next, feature-based methods can be categorized into two families: shapelet-based and Bag-of-Words (BoW) classifiers. Shapelets models (gRSF <ref type="bibr" target="#b20">[21]</ref> and UFS <ref type="bibr" target="#b21">[22]</ref>) use subsequences (shapelets) to transform the original time series into a lower-dimensional space that is easier to classify. On the other hand, BoW models (LPS <ref type="bibr" target="#b22">[23]</ref>, mv-ARF <ref type="bibr" target="#b23">[24]</ref>, SMTS <ref type="bibr" target="#b24">[25]</ref> and <software ContextAttributes="created">WEASEL+MUSE</software> <ref type="bibr" target="#b5">[6]</ref>) convert time series into a bag of discrete words and use a histogram of words representation to perform the classification. <software ContextAttributes="created">WEASEL+ MUSE</software> shows better results compared to gRSF, LPS, mv-ARF, SMTS and UFS on average <ref type="bibr">(20 MTS datasets)</ref>. <software ContextAttributes="created">WEASEL+MUSE</software> generates a BoW representation by applying various sliding windows with different sizes on each discretized dimension (Symbolic Fourier Approximation) to capture features (unigrams, bigrams and dimension identification). Following a feature selection with chi-square test, it classifies the MTS based on a logistic regression.</p><p>Finally, deep learning methods (FCN <ref type="bibr" target="#b25">[26]</ref>, MLSTM-FCN <ref type="bibr" target="#b4">[5]</ref>, <software ContextAttributes="created">MTEX</software>-CNN <ref type="bibr" target="#b11">[12]</ref>, ResNet <ref type="bibr" target="#b26">[27]</ref>, TapNet <ref type="bibr" target="#b27">[28]</ref> and TST <ref type="bibr" target="#b28">[29]</ref>) use Long-Short Term Memory (LSTM), Convolutional Neural Networks (CNN) or Transformers. According to the results published and our experiments, the current state-of-the-art model (MLSTM-FCN) is proposed in <ref type="bibr" target="#b4">[5]</ref> and consists of a LSTM layer and a stacked CNN layer along with squeeze-and-excitation blocks to generate latent features. A recent network, TapNet <ref type="bibr" target="#b27">[28]</ref>, also consists of a LSTM layer and a stacked CNN layer, followed by an attentional prototype network. However, TapNet shows lower accuracy results (https://github.com/xuczhang/xuczhang.github. io/blob/master/papers/aaai20_tapnet_full.pdf (accessed on 1 November 2021)) on average on the 30 public UEA MTS datasets compared to MLSTM-FCN (MLSTM-FCN results presented in Table <ref type="table" target="#tab_2">3</ref>). There is no basis of comparison for MLSTM-FCN with <software ContextAttributes="created">MTEX</software>-CNN <ref type="bibr" target="#b11">[12]</ref> as <software ContextAttributes="created">MTEX</software>-CNN has not been evaluated on public datasets. As illustrated in Figure <ref type="figure" target="#fig_0">1</ref>, <software ContextAttributes="created">MTEX</software>-CNN is a two-stage CNN network which first extracts information relative to each feature with 2D convolution filters and then extracts information relative to time with 1D convolution filters. The output feature map is fed into fully connected layers for classification.</p><p>Therefore, in this work, we choose to benchmark XCM to the best-in-class for each similarity-based, feature-based and deep learning category (DTW D /DTW I , <software>WEASEL+ MUSE</software> and MLSTM-FCN classifiers). We also include <software ContextAttributes="created">MTEX</software>-CNN in the benchmark to demonstrate the superiority of our approach as <software ContextAttributes="created">MTEX</software>-CNN has not been evaluated on the public UEA datasets.</p></div>
<div><head n="2.3.">Explainability</head><p>In addition to their prediction performance, machine learning methods have to be assessed on how they can support their decisions with explanations. Two levels of explanations are generally distinguished: global and local <ref type="bibr" target="#b29">[30]</ref>. Global explainability means that explanations concern the overall behavior of the model across the full dataset, while local explainability informs the user about a particular prediction. As previously introduced with the example of the GDPR, our new CNN approach needs to be able to support each individual prediction. Thus, we present in this section the local explainability methods for CNNs.</p><p>CNNs classifiers do not provide explainability-by-design at the local level. Thus, some post hoc model-agnostic explainability methods could be used. These methods provide explanations for any machine learning model. They treat the model as a blackbox and do not inspect internal model parameters. The main line of work consists of approximating the decision surface of a model using an explainable one (e.g., LIME <ref type="bibr" target="#b30">[31]</ref>, SHAP <ref type="bibr" target="#b31">[32]</ref>, Anchors <ref type="bibr" target="#b32">[33]</ref> and LORE <ref type="bibr" target="#b33">[34]</ref>). However, the explanations from the surrogate models cannot be perfectly faithful with respect to the original model <ref type="bibr" target="#b8">[9]</ref>, which is a prerequisite for numerous applications.</p><p>Then, some post hoc model-specific explainability methods exist. These methods are specifically designed to extract explanations for a particular model. They usually derive explanations by examining internal model structures and parameters. The approaches based on back-propagation are seen as the state-of-the-art explainability methods for deep learning models <ref type="bibr" target="#b34">[35]</ref>. Methods based on back-propagation (e.g., Gradient Explanation <ref type="bibr" target="#b35">[36]</ref>, Guided Backpropagation <ref type="bibr" target="#b36">[37]</ref>, ε-Layer-wise Relevance Propagation <ref type="bibr" target="#b37">[38]</ref>, Gradient ⊙ Input <ref type="bibr" target="#b38">[39]</ref>, Integrated Gradients <ref type="bibr" target="#b39">[40]</ref>, DeepLift <ref type="bibr" target="#b40">[41]</ref> and Grad-CAM <ref type="bibr" target="#b9">[10]</ref>) calculate the gradient, or its variants, of a particular output with respect to the input using back-propagation to derive the contribution of features. In particular, Gradientweighted Class Activation Mapping (Grad-CAM) <ref type="bibr" target="#b9">[10]</ref> has proven to be an adequate method for supporting CNNs predictions. Grad-CAM identifies the regions of the input data that are important for predictions in CNNs using the class-specific gradient information. The method has been shown to provide faithful explanations with regard to the model <ref type="bibr" target="#b10">[11]</ref>. The faithfulness of the explanations provided by Grad-CAM is shown following a methodology based on model parameter and data randomization tests. However, the precision of the explanations provided by Grad-CAM, i.e., the fraction of explanations that are relevant to a prediction, can vary across CNN architectures as Grad-CAM is sensitive to the upsampling processes on feature maps to match the input data dimensions.</p><p>Therefore, we support the predictions of our new CNN model XCM with Grad-CAM, a post hoc model-specific explainability method which provides faithful explanations at local level. The design of our network architecture avoids upsampling processes and enables Grad-CAM to identify the observed variables and timestamps of the input data that are important for predictions more precisely as compared to what the current explainable deep learning MTS classifier <software>MTEX</software>-CNN give.</p><p>Table <ref type="table" target="#tab_0">1</ref> presents an overview of the challenges addressed by the state-of-the-art MTS classifiers and how we position our new method XCM. We evaluate the classification performance of XCM and its explainability in Section 5. The next section presents XCM in details. </p></div>
<div><head n="3.">XCM</head><p>In this section, we present our new eXplainable Convolutional neural network for Multivariate time series classification (XCM). The first part details the architecture of the network, and the second part explains how XCM can provide explanations by identifying the observed variables and timestamps of the input data that are important for predictions.</p></div>
<div><head n="3.1.">Architecture</head><p>Our approach aims to design a new compact and explainable CNN architecture that performs well on both the large and small UEA datasets. As illustrated in Figure <ref type="figure" target="#fig_0">1</ref>, a recent explainable CNN, <software ContextAttributes="created">MTEX-CNN</software> <ref type="bibr" target="#b11">[12]</ref>, proposes to use 2D and 1D convolution filters in sequence to extract key MTS information, i.e., information relative to the observed variables and time, respectively. However, CNN architectures such as <software ContextAttributes="created">MTEX-CNN</software> have significant limitations. The use of 2D and 1D convolution filters in sequence means that the features related to time (features maps from 1D convolution filters) are extracted from the processed features related to observed variables (features maps from 2D convolution filters). Therefore, features related to time cannot fully incorporate the timing information from the input data and can only partially reflect the necessary information to discriminate between the different classes. Thus, (i) our approach XCM extracts both features related to observed variables (2D convolution filters) and time (1D convolution filters) directly from the input data, which leads to more discriminative features by incorporating all the relevant information and ultimately to a better classification performance on average than the 2D/1D sequential approach (see results in Section 5.1). Then, a CNN architecture using fully connected layers to perform classification, especially with the size of the first layer depending on the time series length as in <software ContextAttributes="created">MTEX-CNN</software>, is prone to overfitting and can lead to the explosion of the number of trainable parameters. Thus, (ii) the output feature maps of XCM are processed with a 1D global average pooling before being input to a softmax layer for classification. The use of 1D global average pooling followed by a softmax layer for classification reduces the number of parameters and improves the generalization ability of the network compared to fully connected layers. Global average pooling consists of summarizing each feature map by its average. This operation improves the generalization ability of the network, as it does not have parameters to train, and it provides robustness to spatial translations of the input <ref type="bibr" target="#b41">[42]</ref>. In the possible cases when the sequences of events in an MTS change, the robustness to spatial translation ensures that the classification result is not modified. Finally, the use of non fully padded convolution filters as in <software ContextAttributes="created">MTEX-CNN</software> can lead to an imprecise identification of the regions of the input data that are important for predictions as <software ContextAttributes="created">Grad-CAM</software> is sensitive to upsampling processes. Therefore, (iii) the 2D and 1D convolution filters of XCM are fully padded. As detailed in the next section, the output feature maps can then be analyzed with the Grad-CAM explainability method without altering the precision of the explanations through upsampling processes. Figure <ref type="figure" target="#fig_1">2</ref> illustrates XCM, and the following paragraphs detail the architecture.  Firstly, XCM extracts information relative to the observed variables with 2D convolution filters (upper green part in Figure <ref type="figure" target="#fig_1">2</ref>). This upper part is composed of one 2D convolutional block which is then converted to one feature map to reduce the number of parameters with a 1 × 1 convolution filter. The convolutional block contains a 2D convolution layer followed by a batch normalization layer <ref type="bibr" target="#b42">[43]</ref> and a ReLU activation layer <ref type="bibr" target="#b43">[44]</ref>. We set the kernel size of the 2D convolution filters to Window Size × 1, where Window Size is a hyperparameter which specifies the time window size, i.e., the size of the subsequence of the MTS expected to be interesting to extract discriminative features, and ×1 means for each observed variable. Thus, these 2D convolution filters (number: F in Figure <ref type="figure" target="#fig_1">2</ref>) allow the extraction of features per observed variable. The features are extracted using a sliding window (strides equal to 1), and we use padding instead of half padding to keep the dimension of the feature maps the same as the input data. The padding allows us to avoid using upsampling and interpolation methods on the features maps when building the attribution maps, i.e., the heatmaps of dimensions T × D that identify the regions of the input data that are important for predictions (detailed in the next section). Then, batch normalization brings normalization at the layer level, and it enables faster convergence and better generalization of the network <ref type="bibr" target="#b44">[45]</ref>. In addition, the ReLU activation layer induces nonlinearity in the network. Next, the output feature maps are fed into a module (1 × 1 convolution filter) <ref type="bibr" target="#b45">[46]</ref> which reduces the number of parameters. It projects the feature maps into one following a channel-wise pooling.</p><p>In parallel, XCM extracts information relative to time with 1D convolution filters (lower red part in Figure <ref type="figure" target="#fig_1">2</ref>). This lower part is the same as the upper part, except that the 2D convolution filters are replaced by 1D. We set the kernel size of the 1D convolution filters to Window Size × D, where Window Size is the same hyperparameter as 2D convolution filters and D is the number of observed variables of the input data. The 1D convolution filters slide over the time axis only (stride equals to 1) and capture the interaction between the different time series. Following the use of padding, the output feature map of this lower part has a dimension of T × 1, with T the time series length of the input data. The use of padding, similar to 2D convolution filters, allows us to avoid using upsampling of the features maps on the dimension related to the information extracted (time-T) when building the attribution maps (detailed in the next section).</p><p>In the following step, the output feature maps from these two parts are concatenated and form a feature map of dimensions T × (D + 1). We apply the same 1D convolution block (1D convolution layer-F filters, kernel size Window Size × (D + 1), stride 1 and padding + batch normalization + ReLU activation layer) as presented in the previous paragraph to slide over the time axis and capture the interaction between the features extracted. Finally, we add a 1D global average pooling on the output feature maps and perform classification with a softmax layer. As previously introduced, the use of global average pooling instead of fully connected layers improves the generalization ability of the network.</p><p>In order to assess the potential advantage of concatenating the 2D and 1D convolution blocks instead of having them in sequence, independently from the choice of the classification layers (fully connected layers as in <software>MTEX</software>-CNN versus 1D global average pooling with a softmax layer in XCM), we include in our experiments in Section 5.1 a variant of XCM (XCM-Seq). XCM-seq is the same as XCM except that the 2D and 1D convolution blocks are in sequence. The next section presents how the architecture of XCM allows the communication of explanations supporting the model predictions with Grad-CAM.</p></div>
<div><head n="3.2.">Explainability</head><p>The new CNN architecture of XCM has been designed to enable the precise identification of the observed variables and timestamps that are important for predictions based on Gradient-weighted Class Activation Mapping (Grad-CAM) <ref type="bibr" target="#b9">[10]</ref>. As presented in Section 2.3, Grad-CAM identifies the regions of the input data that are important for predictions in CNNs using the class-specific gradient information. More specifically, Grad-CAM can output two types of attribution maps from XCM architecture: one related to observed variables and another one related to time. Attribution maps are heatmaps of the same size as the input data where some colors indicate features that contribute positively to the activation of the target output <ref type="bibr" target="#b34">[35]</ref>. These attribution maps constitute the explanations provided to support XCM model predictions and are available at the sample level. The following paragraphs explain how we adapt Grad-CAM for XCM.</p><p>In order to build the first attribution map related to observed variables, Grad-CAM is applied to the output feature maps of the 2D convolution layer which uses convolution filters per observed variable (first block in the upper green part in Figure <ref type="figure" target="#fig_1">2</ref>). To obtain the class-discriminative attribution map, L c 2D ∈ R T×D with T the time series length and D the number of observed variables, we first compute the gradient of the score for class c (y c ) with respect to feature map activations A k of the convolutional layer, i.e., ∂y c ∂A k with k ∈ [1, . . . , F] the identifier of the feature map. These gradients flowing back are global-average-pooled over the time series length (T) and observed variables (D) dimensions (indexed by i and j, respectively) to obtain the weight of each feature map. Thus, as regards the feature map k, we calculate the weight as:</p><formula xml:id="formula_1">w c k = 1 T × D ∑ i ∑ j ∂y c ∂A k ij (<label>2</label></formula><formula xml:id="formula_2">)</formula><p>We then use the weights to compute a weighted combination between all the feature maps for that particular class and use a ReLU to keep only the positive attributions to the predictions (Equation ( <ref type="formula" target="#formula_3">3</ref>)).</p><formula xml:id="formula_3">L c 2D = ReLU ∑ k w c k A k<label>(3)</label></formula><p>The second attribution map, L c 1D , relates to time and is built on the same principle. Grad-CAM is applied to the output feature maps of the 1D convolution layer which uses convolution filters sliding over the time axis (first block in the lower red part in Figure <ref type="figure" target="#fig_1">2</ref>). With respect to the feature maps activations M and the class c, we calculate L c 1D as:</p><formula xml:id="formula_4">q c k = 1 T ∑ i ∂y c ∂M k i (4) L c 1D = ReLU ∑ k q c k M k<label>(5)</label></formula><p>Thus, L c 1D has T × 1 as dimensions. We then upsample it to match the input data dimensions T × D with a bilinear interpolation in order to obtain the attribution map. This operation does not alter the time attribution results as the padding on the 1D convolution filters ensured that the feature extraction over the time dimension has kept the time series length. Therefore, the upsampling only replicates the results over the observed variables. An example of observed variables and time attribution maps on a synthetic dataset is presented in Section 5.2.</p><p>Before discussing the performance and explainability results of XCM, we present in the next section the evaluation setting.</p></div>
<div><head n="4.">Evaluation</head><p>In this section, we present the methodology employed (datasets, algorithms, hyperparameters and metrics) to evaluate our approach.</p></div>
<div><head n="4.1.">Datasets</head><p>We benchmarked XCM on the 30 currently available public UEA MTS datasets <ref type="bibr" target="#b6">[7]</ref>. We kept the train/test splits provided in the archive. The characteristics of each dataset are presented in Table <ref type="table" target="#tab_1">2</ref>. ). We used the same setting as XCM.</p><p>All the networks that we implemented (XCM, XCM-Seq and <software>MTEX</software>-CNN) were trained with 100 epochs, the categorical crossentropy loss and the Adam optimization (computing infrastructure: Debian 8 operating system, GPU NVIDIA GeForce RTX 2080 Ti with 11Gb GRAM and 96Gb of RAM). Concerning Grad<software ContextAttributes="created">-CAM</software>, we used the implementation available for Keras (https://github.com/jacobgil/keras-grad-cam (accessed on 1 November 2021)).</p></div>
<div><head n="4.3.">Hyperparameters</head><p>For each dataset, hyperparameters were set by grid search based on the best average accuracy following a stratified 5-fold cross-validation on the training set.</p></div>
<div><head n="4.4.">Metrics</head><p>For each dataset, we computed the classification accuracy-the metric used to benchmark the MTS classifiers on the public UEA datasets <ref type="bibr" target="#b6">[7]</ref>. Then, we presented the average rank and the number of wins/ties to compare the different classifiers on the same datasets. Finally, we presented the critical difference diagram <ref type="bibr" target="#b46">[47]</ref>, the statistical comparison of multiple classifiers on multiple datasets based on the nonparametric Friedman test, to show the overall performance of XCM. We used the implementation available in R package <software ContextAttributes="created">scmamp</software> (https://www.rdocumentation.org/packages/<software ContextAttributes="created">scmamp</software>/ versions/0.2.55/topics/plotCD (accessed on 1 November 2021)).</p></div>
<div><head n="5.">Results</head><p>In this section, we first present the performance results of XCM on the public UEA datasets. Then, we illustrate how XCM can reconcile performance and explainability on a synthetic dataset. Finally, we end this section by showing that XCM outperforms the current most accurate state-of-the-art algorithm in a real-world application while providing faithful and more informative explanations.</p></div>
<div><head n="5.1.">Performance</head><p>The accuracy results on the public UEA test sets of XCM and the other MTS classifiers are presented in Table <ref type="table" target="#tab_2">3</ref>. A blank in the table indicates that the approach ran out of memory. The best accuracy for each dataset is denoted in boldface. Firstly, we observe that XCM obtains the best average rank and the lowest rank variability across the datasets (rank: 2.3, standard error: 0.4), followed by MLSTM-FCN in second position (rank: 3.5, standard error: 0.5) and <software ContextAttributes="created">WEASEL+MUSE</software> in third position (rank: 4.0, standard error: 0.5). Using the categorization of the datasets published in the archive website (http://www.timeseriesclassification.com/dataset.php (accessed on 1 November 2021)), we do not see any influence from the different train set sizes, MTS lengths, number of dimensions, number of classes and dataset types on XCM performance relative to the other classifiers on the UEA datasets.</p><p>More specifically, XCM exhibits better performance than MLSTM-FCN and <software>WEASEL +MUSE</software> on both the large (rank: 1.9, MLSTM-FCN rank: 2.1, <software ContextAttributes="created">WEASEL+MUSE</software> rank: 4.6-train size ≥ 500, 23% of the datasets) and small datasets (rank: 2.4, MLSTM-FCN rank: 4.0, <software ContextAttributes="created">WEASEL+MUSE</software> rank: 3.9-train size &lt; 500, 77% of the datasets). We can assume that the more compact architecture of XCM compared to the other deep learning classifiers provides a better generalization ability on the UEA datasets (average rank on the number of trainable parameters: XCM 1.7, MLSTM-FCN: 1.9, <software ContextAttributes="created">MTEX</software>-CNN: 2.0). Furthermore, the results confirm the superiority of the XCM approach based on the extraction in parallel and directly from the input data of features relative to the observed variables and time compared to the sequential approaches. XCM outperforms both XCM-Seq and <software ContextAttributes="created">MTEX</software>-CNN on average on the UEA datasets (rank: 2.3, XCM-Seq: 5.0, <software ContextAttributes="created">MTEX</software>-CNN: 7.2).</p><p>With regard to the hyperparameter Window Size of XCM, Figure <ref type="figure" target="#fig_2">3</ref> shows the average relative drop in performance across the datasets when using the other time window sizes than the one used in the best configuration given in Table <ref type="table" target="#tab_2">3</ref>. In order to evaluate the relative impact with respect to the range of performance, we defined four categories of datasets: datasets with XCM original accuracy&lt; 50%, datasets with 50% ≤ accuracy &lt; 75%, datasets with 75% ≤ accuracy &lt; 90% and datasets with accuracy ≥ 90%. First, as expected, we observe that the average relative impact of using suboptimal time window sizes is higher when XCM level of performance is low (average relative drop in accuracy: 13.1% when XCM accuracy &lt; 50% versus 3.0% when XCM accuracy ≥ 90%). Then, the average relative drop in accuracy when using suboptimal time window sizes is not negligible but remains limited in all the cases. This drop is below 15% on average on the category where XCM has the lowest level of accuracy (13.1% ± 3.2%) and below 10% on average across all the datasets (7.0% ± 1.3%).  <ref type="table" target="#tab_2">3</ref>. The performance drop is presented across four categories of datasets, defined according to XCM levels of accuracy shown in Table <ref type="table" target="#tab_2">3</ref>. Abbreviation: Acc-Accuracy.</p><p>Finally, we performed a statistical test to evaluate the performance of XCM compared to the other MTS classifiers. We present in Figure <ref type="figure" target="#fig_3">4</ref> the critical difference plot with alpha equals to 0.05 from results shown in Table <ref type="table" target="#tab_2">3</ref>. The values correspond to the average rank, and the classifiers linked by a bar do not have a statistically significant difference. The plot confirms the top three ranking as presented before (XCM: 1, MLSTM-FCN: 2, and <software ContextAttributes="created">WEASEL+MUSE</software>: 3), without showing a statistically significant difference between each other. We notice that XCM is the only classifier with a significant performance difference compared to DTW D . </p></div>
<div><head n="5.2.">Explainability</head><p>In this section, we illustrate how our approach XCM reconciles performance and explainability and show that XCM enables a more precise identification of the regions of the input data that are important for predictions compared to the current deep learning MTS classifier also providing faithful explainability-<software>MTEX</software>-CNN. We perform the comparison on a synthetic dataset as the construction of such a dataset allows us to know the expected explanations, with such information not being available in the public UEA datasets. Concerning the evaluation of the results, we adopt the intersection-over-union as a metric, i.e., the extent of overlap between the predicted and expected explanations.</p><p>The synthetic dataset is composed of 20 MTS (50%/50% train/test split) with a length of 100, two dimensions, and two balanced classes. The difference between the 10 MTS belonging to the negative class and the one belonging to the positive class stems from a 20% time window of the MTS. Negative class MTS are sine waves, and as illustrated in the plot on the top part of Figure <ref type="figure" target="#fig_4">5</ref>, positive class MTS are sine waves with a square signal on 20% of the dimension 1 (see timestamps between 60 and 80).</p><p>First, <software ContextAttributes="used">MTEX</software>-CNN and XCM (Batch Size: 1, Window Size: 20%) correctly predict the 10 MTS of the test set (accuracy 100%). We observe that XCM and <software ContextAttributes="used">MTEX</software>-CNN obtain the same performance whereas XCM has around 10 times fewer parameters than <software ContextAttributes="used">MTEX</software>-CNN (trainable parameters: XCM 17k, <software ContextAttributes="used">MTEX</software>-CNN 232k). Moreover, <software ContextAttributes="used">MTEX</software>-CNN and XCM with Grad-CAM all correctly identify the discriminative time window. However, as shown in Figure <ref type="figure" target="#fig_4">5</ref>, the attribution maps of <software ContextAttributes="used">MTEX</software>-CNN and XCM with the same explainability method (Grad-CAM) are different. Figure <ref type="figure" target="#fig_4">5</ref> shows one MTS sample belonging to the positive class, and the time and observed variables attribution maps supporting <software ContextAttributes="used">MTEX</software>-CNN and XCM predictions. Attribution maps are heatmaps of the same size as the input data. The more intense the red, the stronger the features (observed variables, time) positively contribute to the prediction. We observe that the attribution maps drawn from XCM are more precise than the ones from <software ContextAttributes="used">MTEX</software>-CNN, i.e., the intersection-over-union of the explanations is higher for XCM than for <software ContextAttributes="used">MTEX</software>-CNN (intersection-over-union: XCM 0.65 versus <software ContextAttributes="used">MTEX</software>-CNN 0.4). On the time attribution map, high attribution values (above 0.6) for XCM begin on timestamp 63 and end on timestamp 76 (expected: [60, 80], intersection-over-union: 0.65), whereas for <software ContextAttributes="used">MTEX</software>-CNN they begin later (timestamp 68, intersection-over-union: 0.4). Concerning the attribution map of the observed variables, as expected, we see that high attributions values on the discriminative dimension (dimension 1) appear at the same timestamps as high attribution values on the time attribution map for XCM (timestamps 63 and 76, intersection-over-union: 0.65). Nonetheless, the observed variables attribution map of <software ContextAttributes="used">MTEX</software>-CNN shows high attribution values on a window larger than the discriminative one (timestamps range <ref type="bibr" target="#b33">[34,</ref><ref type="bibr">83]</ref>, intersection-over-union: 0.41). As <software ContextAttributes="used">MTEX</software>-CNN attribution maps exhibit a red color gradient, the precision of identification of the regions of the input data on <software ContextAttributes="used">MTEX</software>-CNN attribution maps could be enhanced by setting a higher threshold than 0.6 for the attribution values. However, the red color gradient is due to the upsampling processes needed to match the 2D/1D output features maps of <software ContextAttributes="used">MTEX</software>-CNN to the size of the input data when applying Grad-CAM. Grad-CAM is applied at a local level, which means that we would need to potentially set a different threshold for each instance and that would render <software ContextAttributes="used">MTEX</software>-CNN explainability method impractical. Thus, based on the same attribution threshold (0.6), XCM allows a more precise identification of the regions of the input data that are important for predictions than <software ContextAttributes="used">MTEX</software>-CNN. Both <software ContextAttributes="used">MTEX</software>-CNN and XCM have periodically high attribution values on dimension 2 of the observed variables attribution maps. It could be surprising as the sinusoidal signal on this dimension is the same across all MTS; however, the fact that this information is uniformly high or low renders it irrelevant for explanations. Therefore, considering that XCM-Seq attributions maps are the same as XCM ones, we can assume that the use of half padding on the different convolution layers to reduce the number of parameters in <software ContextAttributes="used">MTEX</software>-CNN, i.e., the use of upsampling to retrieve the input data dimensions on the attribution maps, can lead to a less precise identification of the regions of the input data that are important for predictions.</p></div>
<div><head n="5.3.">Real-World Application</head><p>Machine learning methods have great potential to improve the detection of determining events for milk production in dairy farms, which is one of the most important steps toward meeting both food production and environmental goals <ref type="bibr" target="#b47">[48]</ref>. A key factor for dairy farms performance is reproduction. Reproduction directly impacts milk production as cows start to produce milk after giving birth to a calf; and milk productivity declines after the first 3 months. Furthermore, the most prevalent reason for cow culling, the act of slaughtering a cow, is a reproduction issue (e.g., long interval between two calves) <ref type="bibr" target="#b48">[49]</ref>. Thus, it is crucial to detect estrus, the only period when the cow is susceptible to pregnancy, to timely inseminate cows and therefore optimize resource use in dairy farms.</p><p>The ground truth is estrus estimation using automated progesterone analysis in milk <ref type="bibr" target="#b49">[50,</ref><ref type="bibr" target="#b50">51]</ref>. However, the cost of this solution prohibits its extensive implementation. Thus, the machine learning challenge lies in developing a binary MTS classifier to detect estrus (class estrus/non-estrus) based on affordable sensor data (activity and body temperature). Commercial solutions based on these affordable sensor data have been developed. Nonetheless, their adoption rate remains moderate <ref type="bibr" target="#b51">[52]</ref>. These commercial detection solutions suffer from insufficient performance (false alerts and incomplete estrus coverage) and from a lack of justifications supporting alerts. Therefore, aside from an enhanced performance, decision support solutions need to provide to the farmers some explanations supporting the alerts.</p><p>The offline dataset consists of 15.5k MTS samples of length 4 with seven variables: the body temperature variable and six activity variables (rumination, ingestion, rest, standing up, over activity and other activity). A time series corresponds to a 4 day period (MTS length 4): the day of estrus (Day 0) and the previous 3 days. The labels are set with the ground truth in estrus detection-progesterone dosage in whole milk. We compare XCM with <software ContextAttributes="used">Grad-CAM</software> to a reference commercial solution (HeatPhone <ref type="bibr" target="#b52">[53]</ref>) and the most accurate state-of-the-art MTS classifier of our benchmark (see Section 4.2) on this real-world application-MLSTM-FCN-with SHAP <ref type="bibr" target="#b31">[32]</ref>. As far as we have seen, an architecture concatenating a LSTM network with a CNN such as MLSTM-FCN can only rely on post hoc model-agnostic explainability methods to support its predictions. We chose the state-of-the-art explainability method SHAP as its granularity of explanation is comparable to Grad<software ContextAttributes="used">-CAM</software> (both global and local). Indeed, Grad<software ContextAttributes="used">-CAM</software> can also offer global explainability by averaging the attribution maps values per class. SHAP provides the relative importance of the observed variables and timestamps on predictions. Performance is calculated following a five-fold cross-validation and an arithmetic mean of the F1-scores on test sets. The choice of this metric is driven by two reasons. First, no assumption is made about the dairy management style; farmers can favor a higher estrus detection rate (higher recall) or fewer false alerts (higher precision) according to their needs. Second, there is a class imbalance (33% of estrus days) which renders irrelevant the accuracy metric.</p><p>As presented in Table <ref type="table" target="#tab_3">4</ref>, we observe that XCM outperforms the current state-ofthe-art deep learning approach (MLSTM-FCN) and the reference commercial solution by increasing the average F1-score (69.7% versus 63.1 % and 55.3%) and obtaining the lowest variability across folds (1.5% versus 1.5% and 5.1%). In addition, concerning XCM explainability, Figure <ref type="figure" target="#fig_5">6</ref> shows an example of the observed variables and time attribution maps supporting the correct prediction of an MTS sample belonging to the class Estrus. We plot the MTS sample with a heatmap to ease the readability. The intersection of attribution maps and sample values inform us that the prediction was made mainly based on the presence of a high overactivity (or low rest) of the animal on the day of estrus (attribution values above 0.6 on Day 0 and on the variable over activity, which has a high value). This behavior is aligned with the literature on estrus detection <ref type="bibr" target="#b53">[54]</ref>, as it is the behavior associated with most of the estrus. The current state-of-the-art MTS classifiers MLSTM-FCN and XCM have different explainability methods (SHAP-post hoc model-agnostic, Grad-CAM-post hoc modelspecific) which come with their own form of explanations. In order to assess and benchmark these two MTS classifiers also with respect to their explainability, we use a framework that we have proposed in <ref type="bibr" target="#b54">[55]</ref>. The framework details a set of characteristics (performance, model comprehensibility, granularity of the explanations, information type, faithfulness and user category) that systematize the performance-explainability assessment of machine learning methods. The results of the framework are represented in a parallel coordinates plot in Figure <ref type="figure">7</ref>. Both deep learning approaches are hard-tounderstand models (Comprehensibility: Black-Box) which provide explanations at both global and local levels (Granularity: Global and Local) that can be analyzed by a domain expert (User: Domain Expert). However, in addition to giving the relative importance of observed variables and time as MLSTM-FCN with SHAP, XCM with Grad-CAM provides more informative explanations by supplying the corresponding sample values (Information: MLSTM-FCN with SHAP-Features+Time and XCM with Grad-CAM-Features+Time+Values). Furthermore, unlike MLSTM-FCN with SHAP and as discussed in Section 2.3, XCM with Grad-CAM approach provides faithful explanations, which is a prerequisite to reduce solution mistrust from the farmers (Faithfulness: MLSTM-FCN with SHAP-Imperfect and XCM with Grad-CAM-Perfect). Therefore, XCM outperforms the current state-of-the-art algorithm on the real-world application (Performance: Best), while enhancing explainability by providing faithful and more informative explanations. Finally, the performance-explainability framework introduced in the previous paragraph can also be used to identify the limitations of XCM, which point to the directions to improve our approach. We see in Figure <ref type="figure">7</ref> that the level of information of the explanation provided by XCM with Grad-CAM (Features+Time+Values) could be enhanced. Therefore, aside from automating the hyperparameter setting of XCM (Window Size), it would be interesting to work on synthesizing the attribution maps to improve the level of information.</p></div><figure xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Figure 1. MTEX-CNN architecture. Abbreviations: D-number of observed variables, de-dense layer size, F-number of filters, k-kernel size and T-time series length.</figDesc><graphic coords="7,178.18,535.33,381.10,149.94" type="bitmap" /></figure>
<figure xml:id="fig_1"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2. XCM architecture. Abbreviations: BN-Batch Normalization, D-number of observed variables, F-number of filters, T-time series length and Window Size-kernel size, which corresponds to the time window size.</figDesc></figure>
<figure xml:id="fig_2"><head>Figure 3 .</head><label>3</label><figDesc>Figure 3. XCM average relative accuracy drop across the UEA datasets when using other time window sizes than the one used in the best configuration given in Table3. The performance drop is presented across four categories of datasets, defined according to XCM levels of accuracy shown in Table3. Abbreviation: Acc-Accuracy.</figDesc><graphic coords="13,235.34,262.10,266.76,173.82" type="bitmap" /></figure>
<figure xml:id="fig_3"><head>Figure 4 .</head><label>4</label><figDesc>Figure 4. Critical difference plot of the MTS classifiers on the UEA datasets with alpha equal to 0.05.</figDesc><graphic coords="13,197.23,615.77,342.98,111.04" type="bitmap" /></figure>
<figure xml:id="fig_4"><head>Figure 5 .</head><label>5</label><figDesc>Figure 5. Observed variables and time attribution maps supporting the correct MTEX-CNN and XCM predictions of an MTS from the synthetic dataset belonging to the class Positive. Abbreviation: Dim-Dimension.</figDesc><graphic coords="14,180.08,340.07,377.30,294.79" type="bitmap" /></figure>
<figure xml:id="fig_5"><head>Figure 6 .</head><label>6</label><figDesc>Figure 6. Observed variables and time attribution maps supporting the correct XCM prediction of an MTS from the real-world test set, which belongs to the class Estrus. The MTS sample is represented under the form of a heatmap with the regions important for the prediction highlighted with a red square.</figDesc><graphic coords="17,245.90,124.01,245.73,341.93" type="bitmap" /></figure>
<figure type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>Overview of the state-of-the-art MTS classifiers.</figDesc><table><row><cell /><cell>ED</cell><cell>DTW</cell><cell>MLSTM FCN</cell><cell>MTEX CNN</cell><cell>WEASEL+ MUSE</cell><cell>XCM</cell></row><row><cell>Performance</cell><cell /><cell /><cell /><cell /><cell /></row><row><cell>Small Datasets</cell><cell /><cell /><cell /><cell /><cell>✓</cell><cell>✓</cell></row><row><cell>Large Datasets</cell><cell /><cell /><cell>✓</cell><cell /><cell /><cell>✓</cell></row><row><cell>Explainability</cell><cell /><cell /><cell /><cell /><cell /></row><row><cell>Faithful Explainability</cell><cell>✓</cell><cell>✓</cell><cell /><cell>✓</cell><cell /><cell>✓</cell></row></table></figure>
<figure type="table" xml:id="tab_1"><head>Table 2 .</head><label>2</label><figDesc>UEA MTS datasets. Abbreviations: AS-Audio Spectra, ECG-Electrocardiogram, EEG-Electroencephalogram, HAR-Human Activity Recognition and MEG-Magnetoencephalography. and with the following hyperparameters: SFA word lengths {2, 4, 6}, SFA quantization method {equi-depth, equi-frequency}, windows length [4, max(MTS length)]; • XCM: we implemented the algorithm with Keras in Python 3.6. 2D convolution layers with: 128 feature maps, kernel size: Window Size × 1, strides 1 × 1, padding same and ReLU activation. In addition, 1D convolution layers with: 128 feature maps, kernel size: Window Size, strides 1, padding same and ReLU activation. The hyperparameters are: batch size {1, 8, 32} and Window Size (the time window size-kernel size), expressed as a percentage of the total size of the MTS</figDesc><table><row><cell>Datasets</cell><cell>Type</cell><cell>Train</cell><cell>Test</cell><cell>Length</cell><cell>Dimensions</cell><cell>Classes</cell></row><row><cell>Articulary Word Recognition</cell><cell>Motion</cell><cell>275</cell><cell>300</cell><cell>144</cell><cell>9</cell><cell>25</cell></row><row><cell>Atrial Fibrilation</cell><cell>ECG</cell><cell>15</cell><cell>15</cell><cell>640</cell><cell>2</cell><cell>3</cell></row><row><cell>Basic Motions</cell><cell>HAR</cell><cell>40</cell><cell>40</cell><cell>100</cell><cell>6</cell><cell>4</cell></row><row><cell>Character Trajectories</cell><cell>Motion</cell><cell>1422</cell><cell>1436</cell><cell>182</cell><cell>3</cell><cell>20</cell></row><row><cell>Cricket</cell><cell>HAR</cell><cell>108</cell><cell>72</cell><cell>1197</cell><cell>6</cell><cell>12</cell></row><row><cell>Duck Duck Geese</cell><cell>AS</cell><cell>60</cell><cell>40</cell><cell>270</cell><cell>1345</cell><cell>5</cell></row><row><cell>Eigen Worms</cell><cell>Motion</cell><cell>128</cell><cell>131</cell><cell>17,984</cell><cell>6</cell><cell>5</cell></row><row><cell>Epilepsy</cell><cell>HAR</cell><cell>137</cell><cell>138</cell><cell>206</cell><cell>3</cell><cell>4</cell></row><row><cell>Ering</cell><cell>HAR</cell><cell>30</cell><cell>30</cell><cell>65</cell><cell>4</cell><cell>6</cell></row><row><cell>Ethanol Concentration</cell><cell>Other</cell><cell>261</cell><cell>263</cell><cell>1751</cell><cell>3</cell><cell>4</cell></row><row><cell>Face Detection</cell><cell>EEG/MEG</cell><cell>5890</cell><cell>3524</cell><cell>62</cell><cell>144</cell><cell>2</cell></row><row><cell>Finger Movements</cell><cell>EEG/MEG</cell><cell>316</cell><cell>100</cell><cell>50</cell><cell>28</cell><cell>2</cell></row><row><cell>Hand Movement Direction</cell><cell>EEG/MEG</cell><cell>320</cell><cell>147</cell><cell>400</cell><cell>10</cell><cell>4</cell></row><row><cell>Handwriting</cell><cell>HAR</cell><cell>150</cell><cell>850</cell><cell>152</cell><cell>3</cell><cell>26</cell></row><row><cell>Heartbeat</cell><cell>AS</cell><cell>204</cell><cell>205</cell><cell>405</cell><cell>61</cell><cell>2</cell></row><row><cell>Insect Wingbeat</cell><cell>AS</cell><cell>30,000</cell><cell>20,000</cell><cell>200</cell><cell>30</cell><cell>10</cell></row><row><cell>Japanese Vowels</cell><cell>AS</cell><cell>270</cell><cell>370</cell><cell>29</cell><cell>12</cell><cell>9</cell></row><row><cell>Libras</cell><cell>HAR</cell><cell>180</cell><cell>180</cell><cell>45</cell><cell>2</cell><cell>15</cell></row><row><cell>LSST</cell><cell>Other</cell><cell>2459</cell><cell>2466</cell><cell>36</cell><cell>6</cell><cell>14</cell></row><row><cell>Motor Imagery</cell><cell>EEG/MEG</cell><cell>278</cell><cell>100</cell><cell>3000</cell><cell>64</cell><cell>2</cell></row><row><cell>NATOPS</cell><cell>HAR</cell><cell>180</cell><cell>180</cell><cell>51</cell><cell>24</cell><cell>6</cell></row><row><cell>PenDigits</cell><cell>Motion</cell><cell>7494</cell><cell>3498</cell><cell>8</cell><cell>2</cell><cell>10</cell></row><row><cell>PEMS-SF</cell><cell>Other</cell><cell>267</cell><cell>173</cell><cell>144</cell><cell>963</cell><cell>7</cell></row><row><cell>Phoneme</cell><cell>AS</cell><cell>3315</cell><cell>3353</cell><cell>217</cell><cell>11</cell><cell>39</cell></row><row><cell>Racket Sports</cell><cell>HAR</cell><cell>151</cell><cell>152</cell><cell>30</cell><cell>6</cell><cell>4</cell></row><row><cell>Self Regulation SCP1</cell><cell>EEG/MEG</cell><cell>268</cell><cell>293</cell><cell>896</cell><cell>6</cell><cell>2</cell></row><row><cell>Self Regulation SCP2</cell><cell>EEG/MEG</cell><cell>200</cell><cell>180</cell><cell>1152</cell><cell>7</cell><cell>2</cell></row><row><cell>Spoken Arabic Digits</cell><cell>AS</cell><cell>6599</cell><cell>2199</cell><cell>93</cell><cell>13</cell><cell>10</cell></row><row><cell>Stand Walk Jump</cell><cell>ECG</cell><cell>12</cell><cell>15</cell><cell>2500</cell><cell>4</cell><cell>3</cell></row><row><cell>U Wave Gesture Library</cell><cell>HAR</cell><cell>120</cell><cell>320</cell><cell>315</cell><cell>3</cell><cell>8</cell></row><row><cell cols="2">4.2. Algorithms</cell><cell /><cell /><cell /><cell /><cell /></row><row><cell /><cell cols="6">We compare our algorithm XCM implemented in Python 3.6 (code available on</cell></row><row><cell cols="7">GitHub https://github.com/XAIseries/XCM) to the state-of-the-art MTS classifiers,</cell></row><row><cell cols="5">as detailed in Section 2.2, and to the variant XCM-Seq:</cell><cell /><cell /></row><row><cell>•</cell><cell cols="6">DTW D , DTW I and ED-with and without normalization (n): we reported the</cell></row><row><cell /><cell cols="3">results published in the UEA archive [7];</cell><cell /><cell /><cell /></row><row><cell>•</cell><cell cols="6">MLSTM-FCN: we used the implementation available (https://github.com/houshd/</cell></row><row><cell /><cell cols="6">MLSTM-FCN (accessed on 1 November 2021)) and ran it with the parameter settings</cell></row><row><cell /><cell cols="6">recommended by the authors in the paper [5] (128-256-128 filters, kernel sizes 8/5/3,</cell></row><row><cell /><cell cols="6">initialization of convolution kernels Uniform He, reduction ratio of 16, 250 training</cell></row><row><cell /><cell cols="6">epochs, dropout of 0.8, Adam optimizer) and with the following hyperparameters:</cell></row><row><cell /><cell cols="4">batch size {1, 8, 32}, number of LSTM cells {8, 64, 128};</cell><cell /><cell /></row><row><cell>•</cell><cell cols="6">MTEX-CNN: we implemented the algorithm with Keras in Python 3.6 based on the</cell></row><row><cell /><cell cols="6">description of the paper [12]. We ran it with the parameter settings recommended by</cell></row><row><cell /><cell cols="6">the authors (Stage 1: two convolution layers with half padding and ReLU activation,</cell></row><row><cell /><cell cols="6">kernel sizes 8 × 1 and 6 × 1, strides 2 × 1, feature maps 64 and 128, dropout 0.4.</cell></row><row><cell /><cell cols="6">Stage 2: one convolution layer with ReLU activation, strides 2, kernel size 2, feature</cell></row><row><cell /><cell cols="2">maps 128, dropout 0.</cell><cell /><cell /><cell /><cell /></row></table><note><p><p />4. Dense layer dimension 128 and L2 regularization 0.2) and with the following hyperparameter: batch size {1, 8, 32};• <software ContextAttributes="used">WEASEL+MUSE</software>: we used the implementation available (https://github.com/patrickzib/ SFA (accessed on 1 November 2021)) and ran it with the parameter settings recommended by the authors in the paper[6] (chi = 2, bias = 1, p = 0.1, c = 5 and L2R_LR_DUAL solver)</p></note></figure>
<figure type="table" xml:id="tab_2"><head>Table 3 .</head><label>3</label><figDesc>Accuracy results on the UEA MTS datasets. Abbreviations: Batch-Batch Size, DW D -DTW D , DW I -DTW I , MC-MTEX-CNN, MF-MLSTM-FCN, Win %-Time Window Size, WM-WEASEL+MUSE and XC-XCM.</figDesc><table><row><cell>Datasets</cell><cell>XC</cell><cell>XC Seq</cell><cell cols="6">MC MF WM ED DW I DW D</cell><cell>ED (n)</cell><cell>DW I (n)</cell><cell>DW D (n)</cell><cell>XC Parameters Batch Win %</cell></row><row><cell>Articulary Word Recognition</cell><cell cols="11">98.3 92.7 92.3 98.6 99.3 97.0 98.0 98.7 97.0 98.0 98.7</cell><cell>32</cell><cell>80</cell></row><row><cell>Atrial Fibrilation</cell><cell cols="11">46.7 33.3 33.3 20.0 26.7 26.7 26.7 20.0 26.7 26.7 22.0</cell><cell>1</cell><cell>60</cell></row><row><cell>Basic Motions</cell><cell cols="11">100.0 100.0 100.0 100.0 100.0 67.5 100.0 97.5 67.6 100.0 97.5</cell><cell>32</cell><cell>20</cell></row><row><cell>Character Trajectories</cell><cell cols="11">99.5 98.8 97.4 99.3 99.0 96.4 96.9 99.0 96.4 96.9 98.9</cell><cell>32</cell><cell>80</cell></row><row><cell>Cricket</cell><cell cols="11">100.0 93.1 90.3 98.6 98.6 94.4 98.6 100.0 94.4 98.6 100.0</cell><cell>32</cell><cell>20</cell></row><row><cell>Duck Duck Geese</cell><cell cols="11">70.0 52.5 65.0 67.5 57.5 27.5 55.0 60.0 27.5 55.0 60.0</cell><cell>8</cell><cell>80</cell></row><row><cell>Eigen Worms</cell><cell cols="9">43.5 45.0 41.9 80.9 89.0 55.0 60.3 61.8 54.9</cell><cell /><cell>61.8</cell><cell>32</cell><cell>40</cell></row><row><cell>Epilepsy</cell><cell cols="11">99.3 93.5 94.9 96.4 99.3 66.7 97.8 96.4 66.6 97.8 96.4</cell><cell>32</cell><cell>20</cell></row><row><cell>Ering</cell><cell cols="11">13.3 13.3 13.3 13.3 13.3 13.3 13.3 13.3 13.3 13.3 13.3</cell><cell>32</cell><cell>20</cell></row><row><cell>Ethanol Concentration</cell><cell cols="11">34.6 31.6 30.8 29.4 31.6 29.3 30.4 32.3 29.3 30.4 32.3</cell><cell>32</cell><cell>80</cell></row><row><cell>Face Detection</cell><cell cols="9">63.9 63.8 50.0 57.4 54.5 51.9 51.3 52.9 51.9</cell><cell /><cell>52.9</cell><cell>32</cell><cell>60</cell></row><row><cell>Finger Movements</cell><cell cols="11">60.0 60.0 49.0 61.0 54.0 55.0 52.0 53.0 55.0 52.0 53.0</cell><cell>32</cell><cell>40</cell></row><row><cell>Hand Movement Direction</cell><cell cols="11">44.6 40.1 18.9 37.8 37.8 27.9 30.6 23.1 27.8 30.6 23.1</cell><cell>32</cell><cell>80</cell></row><row><cell>Handwriting</cell><cell cols="11">41.2 38.6 24.6 54.9 53.1 37.1 50.9 60.7 20.0 31.6 28.6</cell><cell>32</cell><cell>60</cell></row><row><cell>Heartbeat</cell><cell cols="11">77.6 74.1 72.2 71.4 72.7 62.0 65.9 71.7 61.9 65.8 71.7</cell><cell>32</cell><cell>80</cell></row><row><cell>Insect Wingbeat</cell><cell cols="4">10.5 10.5 10.5 10.5</cell><cell /><cell>12.8</cell><cell /><cell cols="2">11.5 12.8</cell><cell /><cell /><cell>32</cell><cell>20</cell></row><row><cell>Japanese Vowels</cell><cell cols="11">98.6 94.6 95.1 99.2 97.8 92.4 95.9 94.9 92.4 95.9 94.9</cell><cell>32</cell><cell>80</cell></row><row><cell>Libras</cell><cell cols="11">84.4 79.4 81.1 92.2 89.4 83.3 89.4 87.2 83.3 89.4 87.0</cell><cell>32</cell><cell>80</cell></row><row><cell>LSST</cell><cell cols="11">61.2 54.2 31.5 64.6 62.8 45.6 57.5 55.1 45.6 57.5 55.1</cell><cell>32</cell><cell>100</cell></row><row><cell>Motor Imagery</cell><cell cols="9">54.0 53.0 50.0 53.0 50.0 51.0 39.0 50.0 51.0</cell><cell /><cell>50.0</cell><cell>8</cell><cell>40</cell></row><row><cell>NATOPS</cell><cell cols="11">97.8 93.9 88.3 96.7 88.3 85.0 85.0 88.3 85.0 85.0 88.3</cell><cell>32</cell><cell>40</cell></row><row><cell>PenDigits</cell><cell cols="11">99.1 96.7 87.8 99.0 96.9 97.3 93.9 97.7 97.3 93.9 97.7</cell><cell>8</cell><cell>60</cell></row><row><cell>PEMS-SF</cell><cell cols="4">75.7 80.9 11.6 69.9</cell><cell /><cell cols="6">70.5 73.4 71.1 70.5 73.4 71.1</cell><cell>32</cell><cell>80</cell></row><row><cell>Phoneme</cell><cell cols="2">22.5 11.9</cell><cell>2.6</cell><cell cols="8">27.5 19.0 10.4 15.1 15.1 10.4 15.1 15.1</cell><cell>32</cell><cell>40</cell></row><row><cell>Racket Sports</cell><cell cols="11">89.5 86.8 82.9 89.4 91.4 86.4 84.2 80.3 86.8 84.2 80.3</cell><cell>32</cell><cell>80</cell></row><row><cell>Self Regulation SCP1</cell><cell cols="11">87.8 81.6 78.5 86.7 74.4 77.1 76.5 77.5 77.1 76.5 77.5</cell><cell>32</cell><cell>80</cell></row><row><cell>Self Regulation SCP2</cell><cell cols="11">54.4 55.0 50.0 52.2 52.2 48.3 53.3 53.9 48.3 53.3 53.9</cell><cell>32</cell><cell>80</cell></row><row><cell>Spoken Arabic Digits</cell><cell cols="11">99.5 99.4 98.6 99.4 98.2 96.7 96.0 96.3 96.7 95.9 96.3</cell><cell>32</cell><cell>80</cell></row><row><cell>Stand Walk Jump</cell><cell cols="11">40.0 46.7 53.3 46.7 33.3 20.0 33.3 20.0 20.0 33.3 20.0</cell><cell>32</cell><cell>60</cell></row><row><cell>U Wave Gesture Library</cell><cell cols="11">89.4 81.9 81.2 86.3 90.3 88.1 86.9 90.3 88.1 86.8 90.3</cell><cell>32</cell><cell>100</cell></row><row><cell>Average Rank</cell><cell>2.3</cell><cell>5.0</cell><cell>7.2</cell><cell>3.5</cell><cell>4.0</cell><cell>7.1</cell><cell>5.9</cell><cell>4.8</cell><cell>7.4</cell><cell>6.4</cell><cell>5.3</cell></row><row><cell>Wins/Ties</cell><cell>16</cell><cell>4</cell><cell>3</cell><cell>7</cell><cell>7</cell><cell>2</cell><cell>2</cell><cell>4</cell><cell>2</cell><cell>2</cell><cell>3</cell></row></table></figure>
<figure type="table" xml:id="tab_3"><head>Table 4 .</head><label>4</label><figDesc>Estrus detection F1-score on test sets with 95% confidence interval.</figDesc><table><row><cell /><cell>XCM</cell><cell>MLSTM-FCN</cell><cell>Commercial Solution</cell></row><row><cell>F1-Score</cell><cell>69.7 ± 1.5</cell><cell>63.1 ± 1.5</cell><cell>55.3 ± 5.1</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgments:</head><p>We would like to thank <rs type="person">Philippe Faverdin</rs> for his invaluable feedback that has been instrumental for our work.</p></div>
			</div>
			<div type="availability">
<div><head>Data Availability Statement:</head><p>The UEA multivariate time series classification archive is available online: https://www.timeseriesclassification.com/index.php</p></div>
			</div>

			<div type="annex">
<div><head>Black</head></div>
<div><head n="6.">Conclusions</head><p>We have presented XCM, a new compact and explainable convolutional neural network for MTS classification, which extracts information relative to the observed variables and time directly from the input data. XCM exhibits a better average rank than the state-of-the-art classifiers on both the large and small public UEA datasets. Moreover, it was designed to enable faithful explainability based on Grad-CAM method and the precise identification of the regions of the input data that are important for predictions. Following the illustration of the performance and explainability of XCM on a synthetic dataset, we showed how XCM can outperform the current most accurate state-of-the-art algorithm MLSTM-FCN on a real-world application while enhancing explainability by providing faithful and more informative explanations.</p><p>In our future work, we would like to automate XCM hyperparameter setting (Window Size) and evaluate the impact of different fusion methods of the 2D and 1D feature maps (e.g., weighting scheme) on XCM performance. With regard to explainability, it would be interesting to further enhance the explanations of XCM with Grad-CAM by synthesizing the attribution maps with multidimensional sequential patterns to improve the level of information.</p><p>Author Contributions: Conceptualization, K.F.; methodology, K.F., T.L., V.M., E.F. and A.T.; validation, K.F., V.M., E.F. and A.T.; formal analysis, K.F. and T.L.; investigation, K.F.; data curation, K.F.; writing-original draft preparation, K.F.; writing-review and editing, K.F., V.M., E.F. and A.T.; visualization, K.F.; supervision, V.M., E.F. and A.T.; project administration, E.F. and A.T. All authors have read and agreed to the published version of the manuscript. </p></div>
<div><head>Informed Consent Statement: Not applicable</head></div>
<div><head>Conflicts of Interest:</head><p>The authors declare no conflict of interest.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Investment Behaviors Can Tell What Inside: Exploring Stock Intrinsic Properties for Stock Trend Prediction</title>
		<author>
			<persName><forename type="first">C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Xing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
		<meeting>the 25th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining<address><addrLine>Anchorage, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019">August 4-8, 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Predicting Alzheimer's Disease with Actigraphy Data</title>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Rong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kwok</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><surname>Tatc</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
		<meeting>the 24th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining<address><addrLine>London, United Kingdom</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018">August 19-23, 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">DeepUrbanEvent: A System for Predicting Citywide Crowd Dynamics at Big Events</title>
		<author>
			<persName><forename type="first">R</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Shibasaki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
		<meeting>the 25th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining<address><addrLine>Anchorage, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019">August 4-8, 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A Distributed Multi-Sensor Machine Learning Approach to Earthquake Early Warning</title>
		<author>
			<persName><forename type="first">K</forename><surname>Fauvel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Balouek-Thomert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Melgar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Silva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Simonet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Antoniu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Costan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Masson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Parashar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Rodero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Termier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 34th AAAI Conference on Artificial Intelligence</title>
		<meeting>the 34th AAAI Conference on Artificial Intelligence<address><addrLine>New York, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020">February 7-12, 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Multivariate LSTM-FCNs for Time Series Classification</title>
		<author>
			<persName><forename type="first">F</forename><surname>Karim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Majumdar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Darabi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Harford</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Netw</title>
		<imprint>
			<biblScope unit="volume">116</biblScope>
			<biblScope unit="page" from="237" to="245" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<author>
			<persName><forename type="first">P</forename><surname>Schäfer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Leser</surname></persName>
		</author>
		<idno>arXiv</idno>
		<title level="m">Multivariate Time Series Classification with WEASEL + MUSE</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">The UEA Multivariate Time Series Classification Archive</title>
		<author>
			<persName><forename type="first">A</forename><surname>Bagnall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lines</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Keogh</surname></persName>
		</author>
		<idno>arXiv</idno>
		<imprint>
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A Symbolic Fourier Approximation and Index for Similarity Search in High Dimensional Datasets</title>
		<author>
			<persName><forename type="first">P</forename><surname>Schäfer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Högqvist</surname></persName>
		</author>
		<author>
			<persName><surname>Sfa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 15th International Conference on Extending Database Technology</title>
		<meeting>the 15th International Conference on Extending Database Technology<address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012">March 27-30, 2012</date>
			<biblScope unit="page" from="516" to="527" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Stop Explaining Black Box Machine Learning Models for High Stakes Decisions and Use Interpretable Models Instead</title>
		<author>
			<persName><forename type="first">C</forename><surname>Rudin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="206" to="215" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Grad-CAM: Visual Explanations from Deep Networks via Gradient-Based Localization</title>
		<author>
			<persName><forename type="first">R</forename><surname>Selvaraju</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Vedantam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Cogswell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Parikh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Batra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Comput. Vis</title>
		<imprint>
			<biblScope unit="volume">128</biblScope>
			<biblScope unit="page" from="336" to="359" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Sanity Checks for Saliency Maps</title>
		<author>
			<persName><forename type="first">J</forename><surname>Adebayo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gilmer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Muelly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hardt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 32nd International Conference on Neural Information Processing Systems</title>
		<meeting>the 32nd International Conference on Neural Information Processing Systems<address><addrLine>Montreal, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018">December 3-8, 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">MTEX-CNN: Multivariate Time Series EXplanations for Predictions with Convolutional Neural Networks</title>
		<author>
			<persName><forename type="first">R</forename><surname>Assaf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Giurgiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Bagehorn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Schumann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Data Mining</title>
		<meeting>the IEEE International Conference on Data Mining<address><addrLine>Beijing, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019">November 8-11, 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<author>
			<persName><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<title level="m">Deep Learning</title>
		<meeting><address><addrLine>Cambridge, MA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Densely Connected Convolutional Networks</title>
		<author>
			<persName><forename type="first">G</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Van Der Maaten</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Weinberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the 2017 IEEE Conference on Computer Vision and Pattern Recognition<address><addrLine>Hawaii, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017">July 21-26, 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Sequence to Sequence Learning with Neural Networks</title>
		<author>
			<persName><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th International Conference on Neural Information Processing Systems</title>
		<meeting>the 27th International Conference on Neural Information Processing Systems<address><addrLine>Montreal, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014">December 8-13, 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Pre-Training of Deep Bidirectional Transformers for Language Understanding</title>
		<author>
			<persName><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
		<author>
			<persName><surname>Bert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics<address><addrLine>Minneapolis, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019">June 2-7, 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Deep Learning for Time-Series Analysis</title>
		<author>
			<persName><forename type="first">Cristian</forename><surname>Borges Gamboa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename></persName>
		</author>
		<idno>arXiv</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Multivariate Time Series Classification Using Dynamic Time Warping Template Selection for Human Activity Recognition</title>
		<author>
			<persName><forename type="first">S</forename><surname>Seto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Symposium Series on Computational Intelligence</title>
		<meeting>the IEEE Symposium Series on Computational Intelligence<address><addrLine>Cape Town, South Africa</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015">December 7-10, 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Is the DTW "Distance" Really a Metric? An Algorithm Reducing the Number of DTW Comparisons in Isolated Word Recognition</title>
		<author>
			<persName><forename type="first">E</forename><surname>Vidal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Casacuberta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Segovia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Speech Commun</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="333" to="344" />
			<date type="published" when="1985">1985</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Generalizing DTW to the Multi-Dimensional Case Requires an Adaptive Approach</title>
		<author>
			<persName><forename type="first">M</forename><surname>Shokoohi-Yekta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Keogh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Data Min. Knowl. Discov</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="1" to="31" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Generalized Random Shapelet Forests</title>
		<author>
			<persName><forename type="first">I</forename><surname>Karlsson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Papapetrou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Boström</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Data Min. Knowl. Discov</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="1053" to="1085" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Ultra-Fast Shapelets for Time Series Classification</title>
		<author>
			<persName><forename type="first">M</forename><surname>Wistuba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Grabocka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Schmidt-Thieme</surname></persName>
		</author>
		<idno>arXiv</idno>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Time Series Representation and Similarity Based on Local Autopatterns</title>
		<author>
			<persName><forename type="first">M</forename><surname>Baydogan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Runger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Data Min. Knowl. Discov</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="476" to="509" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Autoregressive Forests for Multivariate Time Series Modeling</title>
		<author>
			<persName><forename type="first">K</forename><surname>Tuncel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Baydogan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognit</title>
		<imprint>
			<biblScope unit="volume">73</biblScope>
			<biblScope unit="page" from="202" to="215" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Learning a Symbolic Representation for Multivariate Time Series Classification</title>
		<author>
			<persName><forename type="first">M</forename><surname>Baydogan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Runger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Data Min. Knowl. Discov</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="400" to="422" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Time Series Classification from Scratch with Deep Neural Networks: A Strong Baseline</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Oates</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 International Joint Conference on Neural Networks</title>
		<meeting>the 2017 International Joint Conference on Neural Networks<address><addrLine>Anchorage, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017">May 14-19, 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Deep Residual Learning for Image Recognition</title>
		<author>
			<persName><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the 2016 IEEE Conference on Computer Vision and Pattern Recognition<address><addrLine>Las Vegas, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016">June 27-30, 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">TapNet: Multivariate Time Series Classification with Attentional Prototypical Network</title>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 34th AAAI Conference on Artificial Intelligence</title>
		<meeting>the 34th AAAI Conference on Artificial Intelligence<address><addrLine>New York, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020">February 7-12, 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">A Transformer-Based Framework for Multivariate Time Series Representation Learning</title>
		<author>
			<persName><forename type="first">G</forename><surname>Zerveas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Jayaraman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Patel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bhamidipaty</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Eickhoff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery and Data Mining, Virtual Event</title>
		<meeting>the 27th ACM SIGKDD Conference on Knowledge Discovery and Data Mining, Virtual Event</meeting>
		<imprint>
			<date type="published" when="2021">August 14-18, 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Techniques for Interpretable Machine Learning</title>
		<author>
			<persName><forename type="first">M</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Commun. ACM</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="page" from="68" to="77" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Explaining the Predictions of Any Classifier</title>
		<author>
			<persName><forename type="first">M</forename><surname>Ribeiro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Guestrin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
		<meeting>the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining<address><addrLine>San Francisco, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016">August 13-17, 2016</date>
		</imprint>
	</monogr>
	<note>Why Should I Trust You?</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">A Unified Approach to Interpreting Model Predictions</title>
		<author>
			<persName><forename type="first">S</forename><surname>Lundberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 31st International Conference on Neural Information Processing Systems</title>
		<meeting>the 31st International Conference on Neural Information Processing Systems<address><addrLine>Long Beach, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017-09">December 4-9, 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Anchors: High-Precision Model-Agnostic Explanations</title>
		<author>
			<persName><forename type="first">M</forename><surname>Ribeiro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Guestrin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 32nd AAAI Conference on Artificial Intelligence</title>
		<meeting>the 32nd AAAI Conference on Artificial Intelligence<address><addrLine>New Orleans, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018">February 2-7, 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Factual and Counterfactual Explanations for Black Box Decision Making</title>
		<author>
			<persName><forename type="first">R</forename><surname>Guidotti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Monreale</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Giannotti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Pedreschi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ruggieri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Turini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Intell. Syst</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="14" to="23" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Towards Better Understanding of Gradient-Based Attribution Methods for Deep Neural Networks</title>
		<author>
			<persName><forename type="first">M</forename><surname>Ancona</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Ceolini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Öztireli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gross</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Learning Representations</title>
		<meeting>the International Conference on Learning Representations<address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018">May 1-3, 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Visualizing Higher-Layer Features of a Deep Network</title>
		<author>
			<persName><forename type="first">D</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Vincent</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ICML Workshop on Learning Feature Hierarchies</title>
		<meeting>the ICML Workshop on Learning Feature Hierarchies<address><addrLine>Montreal, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009-06-09">June 9, 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Striving for Simplicity: The All Convolutional Net</title>
		<author>
			<persName><forename type="first">J</forename><surname>Springenberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Dosovitskiy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Brox</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Riedmiller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Learning Representations (Workshop Track)</title>
		<meeting>the International Conference on Learning Representations (Workshop Track)<address><addrLine>San Diego, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015-09">May 7-9, 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">On Pixel-Wise Explanations for Non-Linear Classifier Decisions by Layer-Wise Relevance Propagation</title>
		<author>
			<persName><forename type="first">S</forename><surname>Bach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Binder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Montavon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Klauschen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Samek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS ONE</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page">130140</biblScope>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Not Just a Black Box: Learning Important Features Through Propagating Activation Differences</title>
		<author>
			<persName><forename type="first">A</forename><surname>Shrikumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Greenside</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Shcherbina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kundaje</surname></persName>
		</author>
		<idno>arXiv</idno>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Axiomatic Attribution for Deep Networks</title>
		<author>
			<persName><forename type="first">M</forename><surname>Sundararajan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Taly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 34th International Conference on Machine Learning</title>
		<meeting>the 34th International Conference on Machine Learning<address><addrLine>Sydney, Australia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017">August 6-11, 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Learning Important Features through Propagating Activation Differences</title>
		<author>
			<persName><forename type="first">A</forename><surname>Shrikumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Greenside</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kundaje</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 34th International Conference on Machine Learning</title>
		<meeting>the 34th International Conference on Machine Learning<address><addrLine>Sydney, Australia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017">August 6-11, 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Network in Network</title>
		<author>
			<persName><forename type="first">M</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yan</surname></persName>
		</author>
		<idno>arXiv</idno>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift</title>
		<author>
			<persName><forename type="first">S</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 32nd International Conference on Machine Learning</title>
		<meeting>the 32nd International Conference on Machine Learning<address><addrLine>Lille, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015">July 6-11, 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Rectified Linear Units Improve Restricted Boltzmann Machines</title>
		<author>
			<persName><forename type="first">V</forename><surname>Nair</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th International Conference on Machine Learning</title>
		<meeting>the 27th International Conference on Machine Learning<address><addrLine>Haifa, Israel</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010">June 21-24, 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Understanding Batch Normalization</title>
		<author>
			<persName><forename type="first">N</forename><surname>Bjorck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Gomes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Selman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Weinberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 32nd International Conference on Neural Information Processing Systems</title>
		<meeting>the 32nd International Conference on Neural Information Processing Systems<address><addrLine>Montreal, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018">December 3-8, 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Going Deeper with Convolutions</title>
		<author>
			<persName><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Sermanet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Reed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Anguelov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rabinovich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition<address><addrLine>Boston, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015">June 7-12, 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Statistical Comparisons of Classifiers over Multiple Data Sets</title>
		<author>
			<persName><forename type="first">J</forename><surname>Demšar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="1" to="30" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<author>
			<persName><forename type="first">T</forename><surname>Searchinger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Waite</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Hanson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ranganathan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Dumas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Matthews</surname></persName>
		</author>
		<title level="m">Creating a Sustainable Food Future</title>
		<meeting><address><addrLine>Washington, USA</addrLine></address></meeting>
		<imprint>
			<publisher>World Resources Institute</publisher>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">A Summary of the Reasons Why Farmers Cull Cows</title>
		<author>
			<persName><forename type="first">S</forename><surname>Bascom</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Young</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Dairy Sci</title>
		<imprint>
			<biblScope unit="volume">81</biblScope>
			<biblScope unit="page" from="2299" to="2305" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Dairy Cows' Reproductive Response to Feeding Level Differs According to the Reproductive Stage and the Breed</title>
		<author>
			<persName><forename type="first">E</forename><surname>Cutullic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Delaby</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Gallard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Disenhaus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Animal</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="731" to="740" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Estimating genetic parameters for fertility in dairy cows from in-line milk progesterone profiles</title>
		<author>
			<persName><forename type="first">A</forename><surname>Tenghe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bouwman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Berglund</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Strandberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Blom</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Veerkamp</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Dairy Sci</title>
		<imprint>
			<biblScope unit="volume">98</biblScope>
			<biblScope unit="page" from="5763" to="5773" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Characterization of Dutch Dairy Farms Using Sensor Systems for Cow Management</title>
		<author>
			<persName><forename type="first">W</forename><surname>Steeneveld</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Hogeveen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Dairy Sci</title>
		<imprint>
			<biblScope unit="volume">98</biblScope>
			<biblScope unit="page" from="709" to="717" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Comparison of Three Devices for the Automated Detection of Estrus in Dairy Cows</title>
		<author>
			<persName><forename type="first">A</forename><surname>Chanvallon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Coyral-Castel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gatien</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lamy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Ribaud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Allain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Clément</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Salvetti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Theriogenology</title>
		<imprint>
			<biblScope unit="volume">82</biblScope>
			<biblScope unit="page" from="734" to="741" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Milk Yield and Estrous Behavior During Eight Consecutive Estruses in Holstein Cows Fed Standardized or High Energy Diets and Grouped According to Live Weight Changes in Early Lactation</title>
		<author>
			<persName><forename type="first">C</forename><surname>Gaillard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Barbu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sørensen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sehested</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Callesen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Vestergaard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Dairy Sci</title>
		<imprint>
			<biblScope unit="volume">99</biblScope>
			<biblScope unit="page" from="3134" to="3143" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">A Performance-Explainability Framework to Benchmark Machine Learning Methods: Application to Multivariate Time Series Classifiers</title>
		<author>
			<persName><forename type="first">K</forename><surname>Fauvel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Masson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">É</forename><surname>Fromont</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IJCAI-PRICAI 2020 Workshop on Explainable AI, Virtual Event</title>
		<meeting>the IJCAI-PRICAI 2020 Workshop on Explainable AI, Virtual Event</meeting>
		<imprint>
			<date type="published" when="2021-01-08">January 8, 2021</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>