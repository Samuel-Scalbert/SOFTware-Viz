<TEI xmlns="http://www.tei-c.org/ns/1.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xml:space="preserve" xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Human-in-the-Loop Feature Selection</title>
				<funder>
					<orgName type="full">Accenture Labs, Ireland</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher />
				<availability status="unknown"><licence /></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Alvaro</forename><forename type="middle">H C</forename><surname>Correia</surname></persName>
						</author>
						<author role="corresp">
							<persName><forename type="first">Freddy</forename><surname>Lecue</surname></persName>
							<email>freddy.lecue@inria.fr</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">ENSTA ParisTech</orgName>
								<address>
									<settlement>Palaiseau</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">Utrecht University</orgName>
								<address>
									<country key="NL">The Netherlands</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="institution">CortAIx Thales</orgName>
								<address>
									<settlement>Montreal</settlement>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="institution">Inria</orgName>
								<address>
									<settlement>Sophia Antipolis</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Human-in-the-Loop Feature Selection</title>
					</analytic>
					<monogr>
						<imprint>
							<date />
						</imprint>
					</monogr>
					<idno type="MD5">52D7A7181D55A732E1FA4297DA449717</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-04-12T14:45+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid" />
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div><p>Feature selection is a crucial step in the conception of Machine Learning models, which is often performed via datadriven approaches that overlook the possibility of tapping into the human decision-making of the model's designers and users. We present a human-in-the-loop framework that interacts with domain experts by collecting their feedback regarding the variables (of few samples) they evaluate as the most relevant for the task at hand. Such information can be modeled via Reinforcement Learning to derive a per-example feature selection method that tries to minimize the model's loss function by focusing on the most pertinent variables from a human perspective. We report results on a proof-of-concept image classification dataset and on a real-world risk classification task in which the model successfully incorporated feedback from experts to improve its accuracy.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div><head>Introduction</head><p>Selecting a subset of the available features for a given Machine Learning task, also known as feature selection, is a critical step that helps in the design of relevant, accurate and robust models <ref type="bibr" target="#b12">(Guyon and Elisseeff 2003;</ref><ref type="bibr" target="#b6">Chandrashekar and Sahin 2014)</ref>. Although ideally models should be capable of identifying the most predictive features during training, a large input space can reduce performance due to the "curse of dimensionality": the amount of data required to fit a reliable estimator increases exponentially with the number of variables. Therefore, a model based on a smaller number of features might produce better results while being faster and more cost-effective.</p><p>A way of tackling this problem is to select features according to experts' prior knowledge, but that is costly, time demanding and manual. Furthermore, often the users with the relevant understanding of the domain and task are not the ones designing the model. An alternative is to resort to methods that automatically rank and select features under some measure of relevance or importance. Even so, a limitation common to manual and automatic approaches alike is that they define a single feature subset to represent the entire dataset. When the amount of training data is small compared to the number of features, a single subset is unlikely to be able to describe all observations <ref type="bibr" target="#b0">(Avdiyenko, Bertschinger, and Jost 2012)</ref>.</p><p>Towards this challenge, we present a per-example feature selection method by including the human-in-the-loop. We propose a framework where experts are asked to identify the most relevant features for a few examples. Reinforcement Learning (RL) allows us to use that feedback to explicitly model the probability of selecting each feature and derive a policy that produces a new feature subset for each observation in the dataset. Each example is thus represented by a different set of features, which is the only input to a subsequent learning algorithm (e.g., a classifier or regressor). The feature selection policy is learned through policy gradient methods to minimize both (i) the loss function of the associated learning algorithm and (ii) the dissimilarity between the feature subsets chosen by the model and the users.</p><p>Such an approach can not only improve the performance of the model but also render its decision-making more interpretable to human users. As the final prediction relies only on the selected feature subset, which is individual to each example, one can interpret those variables as an explanation for the model's output. Moreover, by mimicking human annotation in selecting the most relevant features, the model can better reflect causal relationships in the experts' minds.</p><p>We frame our model as a stochastic computation graph <ref type="bibr" target="#b22">(Schulman et al. 2015)</ref> and compare two different solvers: Score Function (SF) and Pathwise Derivative (PD) estimators. We validate our method in two scenarios: (i) a proofof-concept image classification task and (ii) a real-world project risk classification task. In the latter, which is highly human-curated, our architecture improves the baseline accuracy by more than 50%. We also study the influence of different hyperparameters and factors of practical relevance, such as the required number of pieces of feedback and the presence of conflicting information from different experts.</p><p>The next section reviews related work. Then, we present (i) the feature selection problem, (ii) our human-in-the-loop approach, (iii) the stochastic computation graph framework with the SF and PD solvers, and finally (iv) the experiments in the two tasks described above.</p></div>
<div><head>Related Work</head><p>The literature is rich in feature selection methods, and we refer to <ref type="bibr" target="#b12">(Guyon and Elisseeff 2003)</ref> and <ref type="bibr" target="#b6">(Chandrashekar and Sahin 2014)</ref> for excellent surveys. More precisely, we are concerned with variable elimination techniques, where only a subset of the available features is selected. These are traditionally divided in filters <ref type="bibr" target="#b25">(Tyagi and Mishra 2013)</ref>, wrappers <ref type="bibr" target="#b17">(Kohavi and John 1997)</ref> and embedded methods <ref type="bibr" target="#b12">(Guyon and Elisseeff 2003)</ref>. Filter methods consist of a preprocessing step where the top-k features are selected by ranking them against some score function, such as the mutual information between input and target variables. Conversely, wrapper methods rank feature subsets following some performance measure such as the accuracy in the training data. That requires retraining the model for each candidate subset, which can be computationally costly and time-consuming. Finally, embedded methods try to solve that problem by performing feature selection while training the learning algorithm.</p><p>Our approach can be classified as an embedded method because we jointly train the feature selection and the learning algorithm via gradient descent. However, it distinguishes itself from conventional ones because it selects a different subset of the features for each observation. Such a perexample approach can better describe the data <ref type="bibr" target="#b0">(Avdiyenko, Bertschinger, and Jost 2012)</ref> and render the output more interpretable, as the selected variables can be understood as the "causes" that drive the model's decision-making.</p><p>Per-example feature selection has also been studied in <ref type="bibr" target="#b0">(Avdiyenko, Bertschinger, and Jost 2012)</ref>. They proposed a filter method based on the mutual information between features and target variables, conditioned on the specific values of each example. The mutual information is then used as a score to rank the k most relevant features for each input. Their work contrasts with ours in two significant ways: (i) their method is deterministic and completely data-driven, whereas ours include human feedback to provide insights that cannot be automatically inferred from small or complex datasets; (ii) they build a subset sequentially, while our method produces a candidate subset in a single step, with no need for an arbitrary stop criterion.</p><p>Our model is also inspired by recent developments in attention mechanisms in deep learning <ref type="bibr" target="#b20">(Mnih et al. 2014;</ref><ref type="bibr" target="#b27">Xu et al. 2015;</ref><ref type="bibr" target="#b3">Bengio, Léonard, and Courville 2013;</ref><ref type="bibr" target="#b1">Bahdanau, Cho, and Bengio 2015)</ref>. By attributing weights to the different hidden states in a neural network, attention mechanisms are also selecting the most relevant features to minimize the model's cost function. Our contribution lies in the application of such attention mechanisms to human-inthe-loop architectures as a way to provide prior knowledge to the model on-the-fly.</p><p>Finally, our model also relates to probabilistic approaches to knowledge elicitation <ref type="bibr" target="#b4">(Cano, Masegosa, and Moral 2011;</ref><ref type="bibr" target="#b13">House, Leman, and Han 2015;</ref><ref type="bibr" target="#b8">Daee et al. 2017</ref>). The work by Daee et al. is particularly relevant because they also query users about feature importance. However, they only model global feature relevance, whereas we propose a per-example feature selection method capable of eliciting the variables that drive the prediction for each observation.</p></div>
<div><head>Feature Selection</head><p>We assume a supervised learning scenario, where a parametric model is trained to minimize some cost function C(x, y, θ), where x is the input, y is the target, and θ is the set of parameters defining the model. For clarity, we refer to the model's prediction as ŷ to contrast with the true value y.</p></div>
<div><head>Framework</head><p>We propose a framework where the annotators or the users not only provide the ground truth y but also select the most relevant features for some of the examples in the dataset. That is common practice when experts emphasize some characteristics of the data to drive the machine learning modeling <ref type="bibr" target="#b21">(Raghavan, Madani, and Jones 2006)</ref>. To model that annotation and perform feature selection (variable elimination) on a per-example basis, we introduce a mask a that is applied over the input vector x to filter out irrelevant features in each observation. Therefore, if an example is given by x ∈ R d , where each dimension corresponds to a feature x j , then a is an indicator variable in {0, 1} d , such that:</p><formula xml:id="formula_0">a j = 1, if x j is used for example x a j = 0, otherwise.</formula><p>(1)</p><p>We denote the input to the learning algorithm by x , which is now given by x = x a, where is the element-wise or Hadamard product. As the feature selection is performed on a per-example basis, a must be a function of the input x. However, if a is an indicator variable, we cannot apply gradient descent to minimize the loss C(x , y, θ) because it is no longer differentiable with respect to the function that defines a. For that reason, we make variable a stochastic and model the probability of a conditioned on x. Given that a ∈ {0, 1} d , we can associate each component a j to a Bernoulli distribution parametrized by qj and obtain:</p><formula xml:id="formula_1">π(a|x) = d j=1 qaj j (1 -qj ) (1-aj ) . (<label>2</label></formula><formula xml:id="formula_2">)</formula><p>Our objective is to concentrate the mass of the distribution π(a|x) on values of a that minimize the loss function C(x , y, θ). To achieve that, we will resort to RL and, in particular, policy gradient methods <ref type="bibr" target="#b24">(Sutton and Barto 2011)</ref>. Hence, we will refer to π(a|x) as a policy, which should tell us the best a given the current input x. Keeping the RL jargon, the function that defines such a policy will be called an agent. The probability qj of each feature being selected by this agent will be a function of x and approximated by a neural network with parameters ψ, where the last layer consists of a sigmoid function to squash the results into a probability space. The vector composed of all d parameters qj is estimated in a single step by this neural network. qψ = (q 1 , q2 , ..., qd ) = h(x; ψ).</p><p>(3)</p><p>Note that we defined a as an indicator variable to produce a variable elimination method: the features are either in the selected subset of variables or not. However, our framework can be easily extended to any number of states to represent the relative importance of each feature, which could also be seen as mid-ground between the soft and hard attention models proposed in <ref type="bibr" target="#b2">(Bengio et al. 2016)</ref>. In that case, assuming K possible states, the policy π(a|x) can be rewritten in the following more general form:</p><formula xml:id="formula_3">π(a|x) = d j=1 K k=1 q[aj=k] jk , (<label>4</label></formula><formula xml:id="formula_4">)</formula><p>where qjk is the probability of assigning state k to feature j and [a j = k] evaluates to 1 if a j = k, 0 otherwise.</p></div>
<div><head>Human-Like Feature Selection</head><p>The framework described above can also be used to model the feature selection performed by humans. We will assume without loss of generality that the annotators' feedback can be translated into a vector q ∈ [0, 1] d , where each element q j reflects the importance attributed to feature j. In that case, q is directly comparable to the model's output q, which can also be interpreted as the relevance of each feature. The intuition is that if q j or qj is close to one, feature j is determinant to predict ŷ and is negligible otherwise. Therefore, to train the agent to mimic the feature selection done by the users, first we need to define a similarity measure between q and q. The distance between q and q is also a cost function, which we will refer to as C f (x, q, ψ) in ( <ref type="formula">5</ref>) to distinguish it from C(x , y, θ). The Euclidean distance is a straightforward option of a distance measure, which results</p><formula xml:id="formula_5">C f (x, q, ψ) = E x ||q i -qi || 2 = E x ||q i -h(x; ψ)|| 2 . (5)</formula><p>The Mean Squared Error (MSE) between q and q, as defined above, is not the only possibility, and other dissimilarity functions might be pertinent depending on the application and type of feedback. For instance, an alternative is the cosine distance</p><formula xml:id="formula_6">C f (x, q, ψ) = 1- q q ||q|| 2 ||q|| 2 = 1- q h(x; ψ) ||q|| 2 ||h(x; ψ)|| 2 . (6)</formula><p>With the cosine distance, we penalize the agent if the two vectors do not have the same orientation in space but ignore differences in magnitude.</p><p>Once the similarity measure is defined, we just have to add C f (x, q, ψ) to the final cost function to which we will refer as C in (7) to simplify the notation.</p><formula xml:id="formula_7">C = C(x, y, q, θ, ψ) = C(x , y, θ) + λ C f (x, q, ψ). (7)</formula><p>That can be interpreted as the sum of two reward signals that encourage the agent to achieve a good performance at the machine learning task while mimicking human feature selection. In (7) λ is a hyperparameter that balances the tradeoff between these two signals. Such sum of errors for different tasks is common practice in multi-task learning <ref type="bibr" target="#b5">(Caruana 1997</ref>) Note that the framework does not require human feature selection data to be provided for all data. For examples with no available feedback, C f (x, q, ψ) is set to zero.</p></div>
<div><head>Stochastic Computation Graphs</head><p>The mask a is stochastic and before making a prediction, we first need to sample a from the policy defined in (2). Hence, we can frame the whole model, including the feature selection and the learning algorithm, as a stochastic computation graph <ref type="bibr" target="#b22">(Schulman et al. 2015)</ref>. That allows for a straightforward comparison of possible solvers and clear representations of the model as depicted in Figures <ref type="figure" target="#fig_1">1</ref> and<ref type="figure" target="#fig_2">2</ref>  As in <ref type="bibr" target="#b22">(Schulman et al. 2015)</ref>, square nodes are deterministic, whereas round ones are stochastic. Inputs and parameters are represented by their corresponding vector names.</p><p>The challenge in a stochastic computation graph is that the standard backpropagation algorithm is no longer sufficient because the cost C(x , y, θ) is non-deterministic and non-differentiable with respect to the parameters ψ. In that case, we need some way of estimating ∇ ψ E a [ C ], the gradient of the expected loss function with respect to the policy parameters. To that end, we can resort to one of the following estimators to find the optimal policy π(a|x): (i) the Score Function (SF) and (ii) the Pathwise Derivative (PD) estimators <ref type="bibr" target="#b22">(Schulman et al. 2015)</ref>.</p></div>
<div><head>Score Function Estimator</head><p>The Score Function estimator (SF), also known as the RE-INFORCE algorithm <ref type="bibr" target="#b26">(Williams 1992)</ref>, consists in rewriting</p><formula xml:id="formula_8">∇ ψ E a [ C ] as E a C ∇ ψ log π(a|x, ψ)</formula><p>. Practically, it allows the complete model to be trained by gradient descent to minimize a surrogate cost function C defined as follows:</p><formula xml:id="formula_9">C = C log π(a|x, ψ) + C.<label>(8)</label></formula><p>In many cases, it is desirable to favor a subset with a smaller number of features, even if that does not decrease C . To encourage the desired sparsity in the mask a, we follow the approach used in <ref type="bibr" target="#b2">(Bengio et al. 2016</ref>) and introduce a regularizer L s , which penalizes the model if qj is not sparse.</p><formula xml:id="formula_10">L s = E (|| 1 d d j qj ) -φ|| 2 ,<label>(9)</label></formula><p>where φ ∈ [0, 1] is an hyperparameter that specifies the desired sparsity of activation. We also want q to have high variance across different examples to avoid always selecting the same subset of features. Hence, we add another regularizer to penalize low variance across examples in the same batch.</p><formula xml:id="formula_11">L v = - d j 1 m m i qij - 1 m m i qij 2 , (<label>10</label></formula><formula xml:id="formula_12">)</formula><p>where the index i refers to each example x and m is the batch size. The model is then trained to minimize C + λ s L s + λ v L v , where λ s and λ v are hyperparameters that balance the trade-off between the cost C and the desired sparsity and variance in the feature subset.</p></div>
<div><head>Pathwise Derivative Estimator</head><p>The second alternative is to use the Pathwise Derivative estimator (PD), which is also known as the reparametrization trick and was made popular by variational autoencoders introduced in <ref type="bibr" target="#b15">(Kingma and Welling 2014)</ref>. We can sample from π(a|x) by first sampling a latent variable z from a known fixed probability distribution p(z) and transforming it using some function to recover a. In that case, the mask a is no longer sampled from a random variable because we introduce another stochastic node z to account for the randomness in the process. The corresponding graph for the pathwise derivative estimator is shown in Figure <ref type="figure" target="#fig_2">2</ref>. Here the mask a is no longer a stochastic node.</p><p>In variational autoencoders, z is usually distributed according to a Gaussian distribution <ref type="bibr" target="#b15">(Kingma and Welling 2014;</ref><ref type="bibr" target="#b16">Kingma et al. 2016</ref>), but the reparametrization trick can be extended to categorical variables by sampling z from a Gumbel-softmax distribution <ref type="bibr" target="#b14">(Jang, Gu, and Poole 2017;</ref><ref type="bibr" target="#b19">Maddison, Mnih, and Teh 2015)</ref>. To use that distribution, we first need to rewrite a as a one-hot vector to match the output of a softmax. Assuming K different possible states, a jk is the probability of assigning state k to feature j, which can be calculated as</p><formula xml:id="formula_13">a jk = exp((log(q jk ) + g k )/τ ) K l=1 exp((log(q jl ) + g l )/τ ) for k in 1, ..., K,<label>(11)</label></formula><p>where g 0 , g 1 , ..., g k , are samples from Gumbel(0,1) (Gumbel 1954) and τ is a hyperparemeter that defines how close the distribution is from the argmax function. For τ &gt; 0, equation ( <ref type="formula" target="#formula_13">11</ref>) is smooth and differentiable, but for τ = 0 it is simply an argmax function. Hence, during training τ is maintained positive, but we gradually decrease its value as the model approaches convergence. During test time, we do not need the cost function to be fully differentiable and τ is set to zero to recover an argmax function.</p><p>Now the mask is a matrix a ∈ R d×K and we need to reduce it to a vector of size d before multiplying it by the input x. One way to do so is to multiply a by a set of weights w ∈ R K , so that aw ∈ [0, 1] d . For instance, if we want to parametrize a Bernoulli distribution as in (2), a j would have two states and w would be [0, 1] T . Note that for τ &gt; 0, a is no longer an indicator variable, but is continuous in the interval [0, 1]. That is a relaxation that renders the graph wholly differentiable during training, but we regain the original definition of a in (1) during test time when τ = 0.</p><p>The advantage of the pathwise derivative estimator is that it does not require a surrogate cost function and we can update the whole model via gradient descent by minimizing (7). We also observed that the PD estimator does not require the same type of regularization as the SF estimator, which reduces the number of hyperparameters that need fine-tuning. However, it does introduce another hyperparameter for the temperature τ , so that the entropy in the Gumbel-softmax can be regulated during training.</p></div>
<div><head>Experimental Results</head><p>We validate our feature selection method on: (i) a proofof-concept image classification task for reproducibility and (ii) a real-world project risk classification task. All experiments were developed on top of the <software>Tensorflow</software> python <software ContextAttributes="used">API</software> (GoogleResearch 2015) and run on a single GPU Nvidia GEFORCE GTX 1080 Ti. The <software ContextAttributes="used">code</software> for the image classification task can be found at github.com/AlCorreia/ Human-in-the-loop-Feature-Selection.</p><p>Set-up: The architecture of our feature selection model is similar for both use cases, which shows the generality of our approach. The classifier was a neural network with a feedforward architecture and a hidden layer of 256 neurons. The last activation was a softmax to yield the negative log-likelihood used as loss function for the classification task. The RL agent was also neural network-based with a single hidden layer of 128 neurons. In both cases, the activation function between the layers was a rectified linear unit (ReLU). For the project risk classification dataset, categorical features were embedded in a vector of size log 2 n where n is the total number of categories. These embeddings were learned via backpropagation with the rest of the model.</p></div>
<div><head>Runs:</head><p>The model based on the PD estimator was trained for 100 epochs with batches of 876 projects (1000 images), but the feedback was only provided during the last 50 epochs. The SF estimator was trained the same way, but as it proved noisier, we also pretrained the network without any feature selection for 40 epochs. In each training phase, the whole model was updated via Adagrad <ref type="bibr" target="#b9">(Duchi, Hazan, and Singer 2011)</ref> with initial learning rate of .5. The hyperparameter λ in (7) was set to 1, so that minimizing the cost function and reproducing the feedback were equally important objectives. For the SF estimator, the regularization parameters φ, λ s and λ v in ( <ref type="formula" target="#formula_10">9</ref>) and ( <ref type="formula" target="#formula_11">10</ref>) were set to .2, 1 and 1, respectively. For the PD estimator, different values for the temperature parameter were tested, but for the results in Table 4 and 5, it was set to 10 and decayed by 4% every 100 steps to slowly render the model more deterministic.</p></div>
<div><head>Image Classification Task</head><p>Context: We tested our model on an augmented MNIST dataset <ref type="bibr" target="#b18">(LeCun et al. 1998</ref>) composed of cluttered images as in <ref type="bibr" target="#b20">(Mnih et al. 2014)</ref>. We randomly positioned each digit inside a larger frame and added four 8x8 sub patches of other digits to random locations of the image. For that task, the features x are not the raw pixels, but the output of a single convolutional layer (1x4x4x8), which discards the trivial solution of simply selecting non-zero pixels.</p><p>To prove that the agent can select relevant features, the attention vector was equally applied over all the filters of the convolution to make the mask directly related to locations in the image. Thus, one can interpret whether the agent's selection was pertinent by visually comparing it against the actual position of the digit.</p><p>Feedback Computation: We simulated user feedback by fitting a 2D Gaussian with the position of the center of the digit for the mean. All training data was generated on-thefly by repeating the above process. The test data was composed of a fixed set of 5000 images produced in the same way. Figure <ref type="figure" target="#fig_3">3</ref> shows an example of a cluttered image and its corresponding feedback. Selected Features: Figure <ref type="figure">4</ref> shows the evolution of the probabilities q corresponding to Figure <ref type="figure" target="#fig_3">3</ref>, during the training of the model with the PD estimator. The model gradually learned to focus on a single region of the image, but q only became sharp after the feedback was introduced. </p></div>
<div><head>Comparing Estimators</head><p>Table <ref type="table" target="#tab_0">1</ref> shows the results obtained with both estimators when applying the proposed feature selection method on a cluttered dataset with a frame of 60x60. Both estimators produced similar results during the first phase when the feature selection was based on the classification cost only. Despite similar performances, the PD estimator has the advantage of not requiring pretraining nor any regularization or variance reduction parameters.</p><p>In both cases the inclusion of the simulated feedback produced a considerable improvement in the accuracy of the model. However, the SF estimator proved more efficient in incorporating the human feature selection, outperforming the PD estimator by almost 5%. The difference can be attributed to the difficulty in fine-tuning the hyperparameter τ for the PD estimator based on the Gumbel-softmax. Even though the temperature was decayed during training, τ was probably still too high to allow for an efficient integration of the feedback. As indicated by the experiments presented in the next section, for τ around 1.0 the PD estimator produces similar results to those obtained with the SF here.</p></div>
<div><head>Impact of Temperature on Accuracy</head><p>The temperature τ is the only hyperparameter that needs to be fine-tuned when solving the graph with the PD estimator. We ran the model with the same architecture described above, but with five different values for the temperature. Differently from the previous experiments, in this case the value of τ was kept constant during the whole training. When τ is close to zero, the Gumbel-softmax approaches an argmax over the probabilities qj , which means the agent only exploits and always picks the value for a that maximizes the reward under its current policy. For τ &gt; 0, a j becomes stochastic, which allows the agent to explore and observe the loss for intermediate values of a. However, if τ is high, equation ( <ref type="formula" target="#formula_13">11</ref>) is close to an uniform distribution over its K categories and a jk is 1 K for every k. Hence, assuming a fixed set of weights w, the final value for a j would remain constant and independent of the policy parameters ψ, preventing the agent from updating its policy effectively. That is reflected in the results presented in Table <ref type="table" target="#tab_1">2</ref>. A temperature value of 1.0 produced the most accurate model, presumably striking a balance between exploration and exploitation.</p></div>
<div><head>From Bernoulli to Categorical Distribution</head><p>We studied the influence of the number of states K on the PD estimator. The results in Table <ref type="table" target="#tab_2">3</ref> show that the accuracy of the model decreases with the number of states. One can infer two different reasons for that: (i) as the number of states increases, the search problem grows in complexity and (ii) given that the MNIST data is itself binary, the benefit of having multiple states does not compensate for the increase in complexity. However, in all cases the model benefited from the feedback and achieved similar accuracy values to those presented Table <ref type="table" target="#tab_0">1</ref>. One can also conclude that the feedback is all the more valuable when the search space is large. During the feedback collection phase, 114 business experts contributed by informing on: (i) (recommended) class, (ii) important features, (iii) textual comments (manually used to filter out some cases) cf. Figure <ref type="figure" target="#fig_5">5</ref>. A total of 613, 916 pieces of feedback on 87, 657 active contracts (their classification and important features) have been collected over a 6-month pilot with an average of 7 pieces of feedback per project, and 45 per person/day. On average, the business experts provided feedback on 11 (standard deviation of 3.9) variables per example. Naturally, some feedback is conflicting among users: 21.6% (resp. 12.8%) of the feedback conflict at class (resp. feature importance) level.</p></div>
<div><head>Motivation:</head><p>The PRC problem fits our framework as (i) baseline approaches reach a (low) maximum accuracy of 31.45% (random forest), (ii) project risk assessment is a highly human-curated task where experts can expose their knowledge by identifying relevant features, and (iii) completely data-driven approaches would require large amounts of data given the sparsity inherent of this context.</p><p>Feedback Computation: From now on, we will use the term feedback to refer to the feature-level annotation only, as we are mostly interested in feature selection. We limited the feedback to the binary impact of each feature because it facilitates the labeling task and better correlates with our variable elimination framework. Therefore, for each observation i, a piece of feedback translates to a binary vector q i ∈ {0, 1} d , where q i,j = 1 iff feature j is relevant for example i. Each example i received feedback from an average of 7 users. Consequently, for all experiments except those on Table <ref type="table" target="#tab_5">7</ref>, each i appeared multiple times in the dataset with different q i 's. All those observations were treated independently and randomly selected during training.</p><p>Validation: Accuracy is measured by comparing the predicted risk class with the real-world observations of risk for completed projects. Training, testing and validation sets correspond to 60/20/20% of the projects, respectively, with each class equally distributed in the validation and test sets.</p><p>Baseline: There are two baselines for the experiments: (i) a random forest trained with the same features, which attained accuracy of 31.45% and (ii) a neural network with the same architecture described above (cf. Technical Context set-up), but without any feature selection. The latter classifies correctly 29.01% of the examples in the test set after 100 epochs with batches of 876 examples.</p><p>Selected Features: After training with the feedback, the model selected a relatively low number of features: 2 to 12 (mean: 4.6, std: 1.5). Such a low number of selected features is desirable as it favors the interpretability of the model.</p></div>
<div><head>Impact of Estimators on Accuracy</head><p>Table <ref type="table" target="#tab_3">4</ref> reports the accuracy obtained with SF and PD estimators when applying our method on the PRC dataset. The results show a very similar pattern to the one observed in the image classification dataset. Once more the SF was superior by 5%, but the PD was slightly more accurate before the introduction of feedback.</p></div>
<div><head>Impact of Temperature on Accuracy</head><p>We also varied the temperature τ for the PD estimator on the PRC dataset. The results presented in Table <ref type="table" target="#tab_4">5</ref> support the same conclusions we reached on the image classification task. A τ of 1.0 lead to a higher accuracy both before and after the introduction of feedback, which suggests that would be a good default τ value for the PD estimator.  Qualitative Feedback Impact (2): We run the same tests with 4, 8, 16 and 32 states cf. Table <ref type="table" target="#tab_5">7</ref> to evaluate the influence of the number of states K on the performance of the PD estimator. To match these different numbers of states, we combined the input from multiple users into a single score per example, q i ∈ {0, 1 16 , ... 15 16 , 1} ( 16 is the max. number of reviews per example). That score was adjusted proportionally to match the other versions with 2, 4, 8 and 32 states. The accuracy of the model increases with the number of states up to K = 8 (outperforming results in Table <ref type="table" target="#tab_3">4</ref>) and then decreases. Although the search problem grows in complexity with the number of states, that seems to be compensated by the more fine-grained feedback. However, for K &gt; 8 the model starts to underperform, which indicates that at that point the number of pieces of feedback available is no longer enough to offset the larger search space. These results contrast with the ones shown in Table <ref type="table" target="#tab_2">3</ref>, as the more complex PRC dataset benefits more from granular feedback.</p><p>Quantitative Feedback Impact (1): As 12.8% of the feedback is conflicting among users, we evaluated the impact of such conflicts in Table <ref type="table" target="#tab_6">8</ref>. We varied this ratio by removing any conflicting feedback up to the point of not having any conflicts cf. case 0. We only removed pieces of feedback which had no common basis, q i,j = q i,j ∀j. Interestingly, the best result was obtained when including 6% of the conflicting feedback. Although counterintuitive, such feedback might relax the constraint on some features, freeing the model to focus on minimizing the classification error. Quantitative Feedback Impact (2): Table <ref type="table" target="#tab_7">9</ref> reports the impact of the quantity of feedback, considering similar ratio of conflicting feedback as for Tables <ref type="table" target="#tab_3">4</ref> and<ref type="table" target="#tab_4">5</ref>. The accuracy plateaus with 80% of feedback. Thus, an average of 5.6 comments per project is required to obtain 77.54% of accuracy, which above the goal set up by the project stakeholders. </p></div>
<div><head>Lessons Learnt</head><p>We learned a few important characteristics of the proposed human-in-the-loop architecture: 1. We observed the SF estimator does not respond well to dropout <ref type="bibr" target="#b23">(Srivastava et al. 2014)</ref>. Conversely, the PD estimator seems to benefit from this type of regularization (we used a dropout rate of 0.8 for all PD experiments); 2. The architecture used to model the agent is independent of the estimator. One can change between them during training to take advantage of both methods; 3. The influence of the dissimilarity distance (MSE/cosine) was marginal here but might vary with the application.</p></div>
<div><head>Conclusion and Future Work</head><p>We address the problem of human-in-the-loop per-example feature selection as a stochastic computation graph. It is a general approach that can be applied to a variety of machine learning tasks with little modifications, as demonstrated by the very distinct datasets we tackled in this paper. Direct applications could be in the context of transfer learning <ref type="bibr" target="#b7">(Chen et al. 2018)</ref>. With the image classification dataset, we visually proved the model can identify the most relevant features of each example, even though in that simple task, that did not reflect in a gain in accuracy. With the PRC dataset, we showed that our model successfully employed real human feedback to produce a significant improvement in accuracy, while also providing business-driven insights to the users. Most importantly, this new architecture enables a symbiotic interaction with stakeholders as the feature selection not only can enhance the model performance but also inform the most relevant properties of each example to the users. Thus, this type of interaction might prove useful in further developments of explainable artificial intelligence. We identify two main lines of research for future work. The first is to extend the architecture to the full active learning scenario, where the model asks the users about specific examples. The second is to model the dependence between the features explicitly via a prior distribution over the probabilities q or a more complex RL policy. We framed the model as an RL problem precisely to support extensions of this sort.</p></div><figure xml:id="fig_0"><head /><label /><figDesc>.</figDesc></figure>
<figure xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Stochastic graph for the score function estimator.As in<ref type="bibr" target="#b22">(Schulman et al. 2015)</ref>, square nodes are deterministic, whereas round ones are stochastic. Inputs and parameters are represented by their corresponding vector names.</figDesc></figure>
<figure xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Stochastic graph for the pathwise derivative estimator. Here the mask a is no longer a stochastic node.</figDesc></figure>
<figure xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Cluttered MNIST image and simulated feedback.</figDesc><graphic coords="6,187.10,215.75,50.41,50.41" type="bitmap" /></figure>
<figure xml:id="fig_4"><head /><label /><figDesc>Figure 4: Evolution of the probabilities vector q during training of the model with PD estimator and MSE feedback.</figDesc><graphic coords="6,64.92,459.78,50.41,50.41" type="bitmap" /></figure>
<figure xml:id="fig_5"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: User interface for Project Risk Classification problem (human feedback collection inside dashed zone).</figDesc></figure>
<figure type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Estimators Impact on Accuracy (%).</figDesc><table><row><cell cols="2">Feedback / Estimator SF</cell><cell>PD</cell></row><row><cell>Before Feedback</cell><cell>85.35</cell><cell>85.70</cell></row><row><cell>Cosine Feedback</cell><cell>92.30</cell><cell>88.40</cell></row><row><cell>MSE Feedback</cell><cell>91.16</cell><cell>89.61</cell></row></table></figure>
<figure type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Temperature Impact on Accuracy (%).</figDesc><table><row><cell cols="3">Temperature Value Before feedback After feedback</cell></row><row><cell>0.25</cell><cell>84.77</cell><cell>88.70</cell></row><row><cell>0.50</cell><cell>85.48</cell><cell>89.76</cell></row><row><cell>1.0</cell><cell>86.5</cell><cell>91.20</cell></row><row><cell>3.0</cell><cell>84.10</cell><cell>88.90</cell></row><row><cell>10.0</cell><cell>84.77</cell><cell>88.82</cell></row></table></figure>
<figure type="table" xml:id="tab_2"><head>Table 3 :</head><label>3</label><figDesc>Number of States on Accuracy (%).</figDesc><table><row><cell>States</cell><cell>Before Feedback</cell><cell>Cosine</cell><cell>MSE</cell></row><row><cell>2</cell><cell>85.15</cell><cell>88.40</cell><cell>89.50</cell></row><row><cell>3</cell><cell>83.82</cell><cell>88.70</cell><cell>89.61</cell></row><row><cell>10</cell><cell>80.83</cell><cell>88.69</cell><cell>88.98</cell></row><row><cell>20</cell><cell>74.24</cell><cell>86.62</cell><cell>85.40</cell></row><row><cell /><cell cols="3">Project Risk Classification Task</cell></row><row><cell cols="4">Business Context: We experimented our feature selection</cell></row><row><cell cols="4">method on a Project Risk Classification (PRC) dataset. 4</cell></row><row><cell cols="4">years of project risk profiles of a leading service company,</cell></row><row><cell cols="4">capturing 349, 324 projects across 97 features (19 categor-</cell></row><row><cell cols="4">ical and 78 numerical) and classified among 5 categories</cell></row><row><cell cols="3">(from high to no financial risk) are captured.</cell><cell /></row></table></figure>
<figure type="table" xml:id="tab_3"><head>Table 4 :</head><label>4</label><figDesc>Accuracy (%) on PRC Test Set with Each Estimator.</figDesc><table><row><cell cols="2">Feedback / Estimator SF</cell><cell>PD</cell></row><row><cell>Before Feedback</cell><cell>29.53</cell><cell>29.99</cell></row><row><cell>Cosine Feedback</cell><cell>82.49</cell><cell>77.51</cell></row><row><cell>MSE Feedback</cell><cell>80.11</cell><cell>78.44</cell></row></table></figure>
<figure type="table" xml:id="tab_4"><head>Table 5 :</head><label>5</label><figDesc>Temperatures on Accuracy on PRC (PD &amp; MSE).</figDesc><table><row><cell cols="4">Temperature Value Before feedback After feedback</cell></row><row><cell>0.25</cell><cell>28.78</cell><cell /><cell>77.82</cell></row><row><cell>0.50</cell><cell>30.02</cell><cell /><cell>78.77</cell></row><row><cell>1.0</cell><cell>31.15</cell><cell /><cell>81.87</cell></row><row><cell>3.0</cell><cell>27.98</cell><cell /><cell>78.33</cell></row><row><cell>10.0</cell><cell>28.36</cell><cell /><cell>78.07</cell></row><row><cell cols="3">Feedback Impact on Accuracy</cell><cell /></row><row><cell cols="4">Qualitative Feedback Impact (1): Table 6 presents an</cell></row><row><cell cols="4">analysis of the optimal moment to start injecting the feed-</cell></row><row><cell cols="4">back into the model solved with the SF estimator. Even</cell></row><row><cell cols="4">though pre-training the network without any feature selec-</cell></row><row><cell cols="4">tion is beneficial, feedback should be provided no later than</cell></row><row><cell cols="4">40 epochs into the training phase to reach optimal results.</cell></row><row><cell cols="4">Table 6: Feedback epoch on Accuracy on PRC (SF &amp; MSE).</cell></row><row><cell cols="4">Epoch(#) Accuracy(%) Epoch(#) Accuracy(%)</cell></row><row><cell>10</cell><cell>63.54</cell><cell>50</cell><cell>78.54</cell></row><row><cell>20</cell><cell>71.66</cell><cell>60</cell><cell>71.45</cell></row><row><cell>30</cell><cell>77.88</cell><cell>70</cell><cell>60.87</cell></row><row><cell>40</cell><cell>80.11</cell><cell>80</cell><cell>52.10</cell></row></table></figure>
<figure type="table" xml:id="tab_5"><head>Table 7 :</head><label>7</label><figDesc>Accuracy (%) on PRC Test Set with PD Estimator on Different Number of States.</figDesc><table><row><cell>States</cell><cell>Before Feedback</cell><cell>Cosine</cell><cell>MSE</cell></row><row><cell>2</cell><cell>24.01</cell><cell>72.99</cell><cell>73.11</cell></row><row><cell>4</cell><cell>29.53</cell><cell>77.00</cell><cell>77.51</cell></row><row><cell>8</cell><cell>28.71</cell><cell>79.21</cell><cell>79.44</cell></row><row><cell>16</cell><cell>26.39</cell><cell>78.01</cell><cell>78.33</cell></row><row><cell>32</cell><cell>26.14</cell><cell>76.17</cell><cell>76.24</cell></row></table></figure>
<figure type="table" xml:id="tab_6"><head>Table 8 :</head><label>8</label><figDesc>Conf. Feedback on Accuracy on PRC (SF &amp; MSE).</figDesc><table><row><cell>Number (#)</cell><cell>Conf. Feedback (%)</cell><cell>Accuracy (%)</cell></row><row><cell>864,393</cell><cell>12.8</cell><cell>80.11</cell></row><row><cell>607,776</cell><cell>9</cell><cell>84.56</cell></row><row><cell>405,184</cell><cell>6</cell><cell>86.67</cell></row><row><cell>202,592</cell><cell>3</cell><cell>78.89</cell></row><row><cell>0</cell><cell>0</cell><cell>69.87</cell></row></table></figure>
<figure type="table" xml:id="tab_7"><head>Table 9 :</head><label>9</label><figDesc>Feedback Size on Accuracy on PRC (SF &amp; MSE).</figDesc><table><row><cell cols="3">Feedback Size(#) Feedback Ratio(%) Accuracy(%)</cell></row><row><cell>0</cell><cell>0</cell><cell>29.53</cell></row><row><cell>3,376,538</cell><cell>50</cell><cell>61.65</cell></row><row><cell>5,402,460</cell><cell>80</cell><cell>77.54</cell></row><row><cell>6,077,768</cell><cell>90</cell><cell>78.11</cell></row><row><cell>6,753,076</cell><cell>100</cell><cell>80.11</cell></row></table></figure>
		</body>
		<back>

			<div type="funding">
<div><p>* Work funded by <rs type="funder">Accenture Labs, Ireland</rs> for an internship.</p></div>
			</div>
			<listOrg type="funding">
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Adaptive Sequential Feature Selection for Pattern Classification</title>
		<author>
			<persName><forename type="first">L</forename><surname>Avdiyenko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Bertschinger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Jost</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCCI International Joint Conference of Computational Intelligence</title>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="474" to="482" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Neural Machine Translation By Jointly Learning To Align and Translate</title>
		<author>
			<persName><forename type="first">D</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2015">2015. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Conditional computation in neural networks for faster models</title>
		<author>
			<persName><forename type="first">E</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P.-L</forename><surname>Bacon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Pineau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Precup</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">N</forename><surname>Networks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Computing</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations, Workshop Track</title>
		<meeting><address><addrLine>ICLR</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016">2016. 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Estimating or Propagating Gradients Through Stochastic Neurons for Conditional Computation</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Léonard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1308.34321-12</idno>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A method for integrating expert knowledge when learning bayesian networks from data</title>
		<author>
			<persName><forename type="first">A</forename><surname>Cano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">R</forename><surname>Masegosa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Moral</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1382" to="1394" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Multitask learning</title>
		<author>
			<persName><forename type="first">R</forename><surname>Caruana</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine Learning</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="41" to="75" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A survey on feature selection methods</title>
		<author>
			<persName><forename type="first">G</forename><surname>Chandrashekar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Sahin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computers and Electrical Engineering</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="16" to="28" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Knowledge-based transfer learning explanation</title>
		<author>
			<persName><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Lécué</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">Z</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Horrocks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Principles of Knowledge Representation and Reasoning: Proceedings of the Sixteenth International Conference</title>
		<meeting><address><addrLine>KR; Tempe, Arizona</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018-10-30">2018. 2018. 30 October -2 November 2018</date>
			<biblScope unit="page" from="349" to="358" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Knowledge elicitation via sequential probabilistic inference for highdimensional prediction</title>
		<author>
			<persName><forename type="first">P</forename><surname>Daee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Peltola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Soare</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kaski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine Learning</title>
		<imprint>
			<biblScope unit="volume">106</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1599" to="1620" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Adaptive Subgradient Methods for Online Learning and Stochastic Optimization</title>
		<author>
			<persName><forename type="first">J</forename><surname>Duchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Hazan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Singer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2121" to="2159" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">TensorFlow: Large-scale machine learning on heterogeneous systems</title>
		<author>
			<persName><surname>Googleresearch</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">J</forename><surname>Gumbel</surname></persName>
		</author>
		<title level="m">Statistical theory of extreme values and some practical applications: a series of lectures</title>
		<imprint>
			<publisher>US Govt. Print. Office</publisher>
			<date type="published" when="1954">1954</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">An Introduction to Variable and Feature Selection</title>
		<author>
			<persName><forename type="first">I</forename><surname>Guyon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Elisseeff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="1157" to="1182" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Bayesian visual analytics: Bava. Statistical Analysis and Data Mining</title>
		<author>
			<persName><forename type="first">L</forename><surname>House</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Leman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The ASA Data Science Journal</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="13" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Categorical Reparameterization with Gumbel-Softmax</title>
		<author>
			<persName><forename type="first">E</forename><surname>Jang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Poole</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1" to="13" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Auto-Encoding Variational Bayes</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2nd International Conference on Learning Representations (ICLR)</title>
		<meeting>the 2nd International Conference on Learning Representations (ICLR)</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Improving Variational Inference with Inverse Autoregressive Flow</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Salimans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Jozefowicz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Neural Information Processing Systems, number Nips</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Wrappers for feature subset selection</title>
		<author>
			<persName><forename type="first">R</forename><surname>Kohavi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">H</forename><surname>John</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="273" to="324" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Gradient-Based Learning Applied to Document Recognition</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Haffner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the IEEE</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">86</biblScope>
			<biblScope unit="page" from="2278" to="2324" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">The Concrete Distribution: A Continuous Relaxation of Discrete Random Variables</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J</forename><surname>Maddison</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mnih</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">W</forename><surname>Teh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="3528" to="3536" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Recurrent Models of Visual Attention</title>
		<author>
			<persName><forename type="first">V</forename><surname>Mnih</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Heess</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Kavukcuoglu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="2204" to="2212" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Active learning with feedback on features and instances</title>
		<author>
			<persName><forename type="first">H</forename><surname>Raghavan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Madani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Jones</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Machine Learning</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="1655" to="1686" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Gradient Estimation Using Stochastic Computation Graphs</title>
		<author>
			<persName><forename type="first">J</forename><surname>Schulman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Heess</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Weber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Abbeel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="3528" to="3536" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Dropout: A Simple Way to Prevent Neural Networks from Overfitting</title>
		<author>
			<persName><forename type="first">N</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="1929" to="1958" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Reinforcement Learning : An Introduction</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">S</forename><surname>Sutton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">G</forename><surname>Barto</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011">2011</date>
			<publisher>MIT press Cambridge</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">A Survey on Different Feature Selection Methods for Microarray Data Analysis</title>
		<author>
			<persName><forename type="first">V</forename><surname>Tyagi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mishra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Applications</title>
		<imprint>
			<biblScope unit="volume">67</biblScope>
			<biblScope unit="issue">16</biblScope>
			<biblScope unit="page" from="975" to="8887" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Simple Statistical Gradient-Following Algorithms for Connectionist Reinforcement Learning</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Williams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine learning</title>
		<imprint>
			<date type="published" when="1992">1992</date>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="229" to="256" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Show , Attend and Tell : Neural Image Caption Generation with Visual Attention</title>
		<author>
			<persName><forename type="first">K</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">S</forename><surname>Zemel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="2048" to="2057" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>