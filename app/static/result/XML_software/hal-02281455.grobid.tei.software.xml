<TEI xmlns="http://www.tei-c.org/ns/1.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xml:space="preserve" xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Overview of LifeCLEF 2019: Identification of Amazonian Plants, South &amp; North American Birds, and Niche Prediction</title>
			</titleStmt>
			<publicationStmt>
				<publisher />
				<availability status="unknown"><licence /></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Alexis</forename><surname>Joly</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Inria</orgName>
								<orgName type="institution" key="instit2">LIRMM</orgName>
								<address>
									<settlement>Montpellier</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Hervé</forename><surname>Goëau</surname></persName>
							<affiliation key="aff1">
								<orgName type="laboratory" key="lab1">CIRAD</orgName>
								<orgName type="laboratory" key="lab2">UMR AMAP</orgName>
								<address>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Christophe</forename><surname>Botella</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Inria</orgName>
								<orgName type="institution" key="instit2">LIRMM</orgName>
								<address>
									<settlement>Montpellier</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="laboratory">UMR AMAP</orgName>
								<orgName type="institution">INRA</orgName>
								<address>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Stefan</forename><surname>Kahl</surname></persName>
							<affiliation key="aff6">
								<orgName type="institution">Chemnitz University of Technology</orgName>
								<address>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Maximilien</forename><surname>Servajean</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Hervé</forename><surname>Glotin</surname></persName>
							<affiliation key="aff3">
								<orgName type="department">LIS</orgName>
								<orgName type="institution" key="instit1">Univ. Toulon</orgName>
								<orgName type="institution" key="instit2">Aix Marseille Univ</orgName>
								<orgName type="institution" key="instit3">CNRS</orgName>
								<orgName type="institution" key="instit4">DYNI SABIOD</orgName>
								<address>
									<settlement>Marseille</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Pierre</forename><surname>Bonnet</surname></persName>
							<affiliation key="aff1">
								<orgName type="laboratory" key="lab1">CIRAD</orgName>
								<orgName type="laboratory" key="lab2">UMR AMAP</orgName>
								<address>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Robert</forename><surname>Planqué</surname></persName>
							<affiliation key="aff4">
								<orgName type="institution">Xeno-canto foundation</orgName>
								<address>
									<country key="NL">The Netherlands</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Fabian-Robert</forename><surname>Stöter</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Willem-Pier</forename><surname>Vellinga</surname></persName>
							<affiliation key="aff4">
								<orgName type="institution">Xeno-canto foundation</orgName>
								<address>
									<country key="NL">The Netherlands</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Maximillien</forename><surname>Servajean</surname></persName>
							<affiliation key="aff7">
								<orgName type="laboratory">LIRMM</orgName>
								<orgName type="institution" key="instit1">Université Paul Valéry</orgName>
								<orgName type="institution" key="instit2">University of Montpellier</orgName>
								<orgName type="institution" key="instit3">CNRS</orgName>
								<address>
									<settlement>Montpellier</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Fabian</forename><surname>Robert-Stöter</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Henning</forename><surname>Müller</surname></persName>
							<affiliation key="aff5">
								<orgName type="institution">HES-SO</orgName>
								<address>
									<settlement>Sierre</settlement>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Overview of LifeCLEF 2019: Identification of Amazonian Plants, South &amp; North American Birds, and Niche Prediction</title>
					</analytic>
					<monogr>
						<imprint>
							<date />
						</imprint>
					</monogr>
					<idno type="MD5">13F5A5B4747B77523820EECF36B73A27</idno>
					<idno type="DOI">10.1007/978-3-030-28577-7_29</idno>
					<note type="submission">Submitted on 15 Nov 2019</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-04-12T14:47+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid" />
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div><p>whether they are published or not. The documents may come from teaching and research institutions in France or abroad, or from public or private research centers.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div><head n="1">LifeCLEF Lab Overview</head><p>Identifying organisms is a key for accessing information related to the uses and ecology of species. This is an essential step in recording any specimen on earth to be used in ecological studies. Unfortunately, this is difficult to achieve due to the level of expertise necessary to correctly record and identify living organisms (for instance plants are one of the most difficult groups to identify with an estimated number of 400,000 species). This taxonomic gap has been recognized since the Rio Conference of 1992, as one of the major obstacles to the global implementation of the Convention on Biological Diversity. Among the diversity of methods used for species identification, Gaston and O'Neill <ref type="bibr" target="#b9">[10]</ref> discussed in 2004 the potential of automated approaches typically based on machine learning and multimedia data analysis. They suggested that, if the scientific community is able to (i) overcome the production of large training datasets, (ii) more precisely identify and evaluate the error rates, (iii) scale up automated approaches, and (iv) detect novel species, it will then be possible to initiate the development of a generic automated species identification system that could open up vistas of new opportunities for theoretical and applied work in biological and related fields. Since the question raised by Gaston and O'Neill <ref type="bibr" target="#b9">[10]</ref>, automated species identification: why not?, a lot of work has been done on the topic (e.g. <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b21">22]</ref>) and it is still attracting much research today, in particular in deep learning <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b27">28]</ref>. In order to measure the progress made in a sustainable and repeatable way, the <software ContextAttributes="used">LifeCLEF</software><ref type="foot" target="#foot_0">9</ref> research platform was created in 2014 as a continuation of the plant identification task <ref type="bibr" target="#b19">[20]</ref> that was run within the <software ContextAttributes="used">ImageCLEF</software> lab<ref type="foot" target="#foot_1">10</ref> the three years before <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b16">17]</ref>. <software ContextAttributes="used">LifeCLEF</software> enlarged the evaluated challenge by considering animals in addition to plants, and audio and video contents in addition to images. In 2018, a new challenge dedicated to the location-based prediction of species was finally introduced (<software ContextAttributes="used">GeoLifeCLEF</software>). The main novelties of the 2019 edition of <software ContextAttributes="used">LifeCLEF</software> compared to the previous year are the following:</p><p>1. <software>PlantCLEF</software> focus on tropical flora: The main novelty of the 2019 edition of <software ContextAttributes="used">PlantCLEF</software> is to focus the challenge on the flora of data deficient tropical regions, i.e. regions having the richest biodiversity but for which data availability is much lower than northern countries. 2. Big soundscape data for <software ContextAttributes="used">BirdCLEF</software>: The main novelty of the 2019 edition of <software ContextAttributes="used">BirdCLEF</software> is the introduction of a very large dataset of 350 hours of manually annotated soundscape recordings in addition to the historical mono-species recordings provided by the Xeno-canto community. 3. New data and evaluation metric for <software ContextAttributes="used">GeoLifeCLEF</software>: The 2019 edition of the <software ContextAttributes="used">GeoLifeCLEF</software> challenge tackles some of the methodological weaknesses that were revealed by the pilot 2018 edition and introduces a new big dataset fixing some issues of the previous one.</p><p>About 250 researchers or students registered to at least one of the three challenges of the lab and 16 of them finally crossed the finish line by completing runs and participating in the collaborative evaluation. In the following sections, we provide a synthesis of the methodology and main results of each of the three challenges of <software>LifeCLEF</software>2019. More details can be found in the overview reports of each challenge and the individual reports of the participants (references provided below).</p></div>
<div><head n="2">Task1: PlantCLEF</head><p>A detailed description of the task and a more complete discussion of the results can be found in the dedicated working note <ref type="bibr" target="#b15">[16]</ref>.</p></div>
<div><head n="2.1">Methodology</head><p>The <software>PlantCLEF</software> challenge considers the problem of classifying plant observations based on several images of the same individual plant rather than considering a classical single-image classification task. Indeed, it is usually required to observe several organs of a plant to identify it accurately (e.g. the flower, the leaf, the fruit, the stem, etc.). As a consequence, the same individual plant is often photographed several times by the same observer resulting in contextually similar pictures and/or near-duplicates. To avoid bias, it is crucial to consider such image sets as a single plant observation that should not be split across the training and the test set. In addition to the raw pictures, plant observations are usually associated with contextual and social data. This includes geo-tags or location names, time information, author names, collaborative ratings, vernacular names (common names), picture type tags, etc. Within all <software ContextAttributes="used">PlantCLEF</software> challenges, the use of this additional information was considered as part of the problem because it was judged as potentially useful for a real-world usage scenario.</p><p>In 2018, a novelty of the challenge was to involve expert botanists in the evaluation in order to evaluate how fare automated systems are from their expertise. In particular, 9 of the best expert botanists of the French flora accepted to compete with AI algorithms on a difficult subset of the whole test set. The results confirmed that identifying plants from images is a difficult task, even for some of the highly skilled specialists who accepted to participate in the experiment. The results showed that there is still a margin of progression but that it is becoming tighter and tighter. The best system was able to correctly classify 84% of the test samples, better than 5 of the 9 experts. The main novelty of the 2019 edition of <software>PlantCLEF</software> is to transpose this methodology to the flora of tropical regions, that is expected to be much more challenging because of the much lower amount of available training data for that species. Indeed, tropical regions are the richest in terms of biodiversity but unfortunately also the poorest in terms of data.</p></div>
<div><head n="2.2">Dataset and Evaluation Protocol</head><p>We provided a new training data set of 10K species mainly focused on the Guiana shield and the Amazon rain forest, known to be the largest collection of living plants and animal species in the world (see figure1). As for the previous two years, this training data was mainly aggregated by querying popular image search engines with the binomial Latin name of the targeted species. We actually did show in previous editions of <software ContextAttributes="used">LifeCLEF</software> that training deep learning models on such noisy big data is as effective as training models on cleaner but smaller expert data <ref type="bibr" target="#b13">[14]</ref>, <ref type="bibr" target="#b14">[15]</ref>. The average number of images per species in that new data set is much lower than the data set used in the previous editions of <software ContextAttributes="used">PlantCLEF</software> (about 1 vs. 3). Many species contain only a few images and some of them might even contain only 1 image, making a much more challenging task. Moreover, in this context of lack of data, image search engines very often return the same image several times for different species. This typically happens when an image is displayed in a web page that contains a text list of several species, for example a web page of a genus in Wikipedia: if the species in the list are quite rare and poorly illustrated on the web, an image search engine will return the same image for most species on the list. The training data were organized into sub-directories (one for each species), but each image was named according to its content with an MD5 like hash technique, in order to facilitate the detection of "duplicated" images.</p><p>For the test set, on the other hand, we relied on highly trusted expert data (with a presumably very low error rate). The test set contains 742 plant observations that all had to be classified by the participating systems. However, only a small part was used for the comparison with the 5 human experts who participated to the evaluation (actually 117 observations).</p><p>Participants were allowed to use complementary training data (e.g. for pretraining purposes) but at the condition that (i) the experiment is entirely reproducible, i.e. that the used external resource is clearly referenced and accessible to any other research group in the world, (ii) the use of external training data or not is mentioned for each run, and (iii) the additional resource does not contain any of the test observations. The main evaluation measure for the challenge was the top-1 accuracy in order to be comparable with the latter's task concerning flora in temperate regions. Mean Reciprocal Rank and and the top-3 accuracy have also been used as complementary measures to allow a fair comparison with the human experts since they have been allowed to make up to three species proposals.</p><p>Fig. <ref type="figure">1</ref>. Regions of origin of the 10k species selected for <software ContextAttributes="used">PlantCLEF</software> 2019: French Guiana, Suriname, Guyana, Brazil (states of Amapa, Para, Amazonas) the data set, but only 6 research groups succeeded in submitting runs, i.e. files containing the predictions of the system(s) they ran. Details of the methods and systems used in the runs are synthesized in the overview working note paper of the task <ref type="bibr" target="#b15">[16]</ref> and further developed in the individual working notes of most of the participants (Holmes <ref type="bibr" target="#b6">[7]</ref>, CMP <ref type="bibr" target="#b31">[32]</ref>, MRIM-LIG <ref type="bibr" target="#b8">[9]</ref>). We report in Figure <ref type="figure">2</ref> the performance achieved by the 26 collected runs and the 5 participating human experts, while Figure3 reports the results on the whole test data set.</p></div>
<div><head>Fig. 2. Scores between Experts and Machine</head><p>The tropical flora is much more difficult to identify. Results are significantly lower than last year both for machines and human experts with an equivalent number of species of 10k, confirming the assumption that a tropical flora is inherently more difficult than the more generalist flora. The best of the experts, actually recognized by peers as the most expert in the world of the Guyanese flora, reached a top1 of 0.675 (against 0.96 for the best expert during <software ContextAttributes="used">ExpertCLEF</software> 2018 <ref type="bibr" target="#b14">[15]</ref>). Comparison of medians (0.376 vs 0.8 ) and minimums (0.154 vs 0.613) over the two years further highlights theses difficulties.</p><p>Deep learning algorithms were defeated from far by the best experts. The best automated system is half as good as the best expert with a gap of 0.365, whereas last year the gap was only 0.12. Moreover, there is a strong disparity in results between participants despite the use of popular and recent Convolutional Neural Networks (DensetNet, ResNet, Inception-ResNet-V2, Inception-V4), while during the last four <software>PlantCLEF</software> editions a homogenization of high results forming a "skyline" has often been observed. These differences in accuracy can be explained in part by the way participants managed the training set.</p><p>Although previous investigations have shown the unreasonable effectiveness of noisy data for fine-grained recognition <ref type="bibr" target="#b23">[24]</ref>, <ref type="bibr" target="#b13">[14]</ref>, several teams considered that the training dataset was too noisy and too imbalanced. They made consistent efforts for removing duplicates pictures (Holmes), for removing non plant pictures (Holmes, CMP), for adding new pictures (CMP), or for reducing the classes imbalance with smoothed re-sampling and other data sampling schemes (MRIM).</p><p>Removing duplicate images seems to be effective. Even if it reduces dramatically the training dataset to 230k pictures and from 8,263 species, and even if it may remove images for valuable for poorly illustrated species, the Holmes team reported in their preliminary tests that removing all the duplicate pictures allowed to significantly increase the top1 from 43,7% to 47,97% on a validation set of 20k images extracted from the training set <ref type="bibr" target="#b6">[7]</ref>.</p><p>Removing non plant images would not really be useful. The Holmes team reported that if 29k non-plant images are automatically removed in addition to duplicates, it actually slightly decrease the top1 from 47.97% to 47.76%. It is as if most of the non-plant noise is finally carried by the duplicate images. Extending the training data set improve the performances. The CMP team did not remove duplicate images but automatically eliminated about 20k non-plant images. Above all, they considerably extended the training set by adding more than 238k images from the GBIF, exploiting finally more than 666k images. At first glance, their best method obtained a top1 of 8.5%, far behind the Holmes team which reached 31.6% with considerably fewer images (250k vs 666k) and a system based on same architectures (InceptionV4 and Inception-ResNet-V2). However, the CMP team reported a bug in their submission files, and the real best top-1 accuracy that they should have achieved was actually at best 41%, 10 points more than the winning Holmes run file. It is worth noting that this outof-competition run could made better predictions than the third human expert. Open questions. Could the CMP team have obtained even better accuracy if they had massively eliminated duplicate images like the Holmes team? To what extent the 238k additional images from GBIF are noisy? If the GBIF website showed that there are few non plant pictures like faces and drawings, there is actually a high proportion of herbarium images for rare species, and it is difficult to evaluate how much pictures are duplicated in several species or/and incorrectly identified. Therefore, the management of different types of noise (duplicates, identification errors, non-plants, different domains like herbariums, ...) in a data deficient context require further investigations.</p></div>
<div><head n="3">Task2: BirdCLEF</head><p>A detailed description of the task and a more complete discussion of the results can be found in the dedicated overview paper <ref type="bibr" target="#b22">[23]</ref>. In 2016, the <software ContextAttributes="used">BirdCLEF</software> challenge was extended and also featured complex soundscape recordings in addition to the classical mono-species Xeno-Canto recordings. This enables research for more passive monitoring scenarios such as setting up a network of mobile recorders that would continuously capture the surrounding sound environment. One of the limitations of this new content, however, was that the vocalizing birds were not localized in the recordings. Thus, to allow a more accurate evaluation, new time-coded soundscapes were introduced within the <software ContextAttributes="used">BirdCLEF</software> 2017 and 2018 challenges. In total, 6.5 hours of recordings were collected in the Amazonian forests and were manually annotated by two experts including a native of the Amazon forest, in the form of time-coded segments with associated species name. Unfortunately, past editions of <software ContextAttributes="used">BirdCLEF</software> showed no significant improvements in that domain, despite excellent scores for mono-species recordings. Therefore, the 2019 edition of the <software ContextAttributes="used">BirdCLEF</software> challenge mainly focused on this soundscape scenario but extended it to North American bird species for which the available data is considerably bigger.</p></div>
<div><head n="3.2">Dataset and Evaluation Protocol</head><p>The new data includes about 350 hours of manually annotated soundscapes from past editions and soundscapes that were recorded using 30 field recorders between January and June of 2017 in Ithaca, NY, USA. This dataset was split into a validation set with labels provided to the participants (about 10%) and a test set to be processed by the evaluated systems. As for training data, we provided an newly composed Xeno-Canto subset covering 659 species from South and North America. Additionally, <software>eBird</software>.org frequency lists were provided to enable participants to decide which species are plausible for a given time, date and location. The goal of the task was to localize and identify all audible birds within the provided soundscape test set. Each soundscape was divided into segments of 5 seconds, and a list of species associated to probability scores had to be returned for each segment. The used evaluation metric was the classification mean Average Precision (cmAP ), considering each class c of the ground truth as a query. This means that for each class c, all predictions with ClassId = c are extracted from the run file and ranked by decreasing probability in order to compute the average precision for that class. The mean across all classes is computed as the main evaluation metric. More formally:</p><formula xml:id="formula_0">cmAP = C c=1 AveP (c) C</formula><p>where C is the number of classes (species) in the ground truth and AveP (c) is the average precision for a given species c computed as:</p><formula xml:id="formula_1">AveP (c) = nc k=1 P (k) × rel(k) n rel (c) .</formula><p>where k is the rank of an item in the list of the predicted segments containing c, n c is the total number of predicted segments containing c, P (k) is the precision at cut-off k in the list, rel(k) is an indicator function equaling 1 if the segment at rank k is a relevant one (i.e. is labeled as containing c in the ground truth) and n rel (c) is the total number of relevant segments for class c. </p></div>
<div><head n="3.3">Participants and Results</head><p>103 participants registered for the <software ContextAttributes="used">BirdCLEF</software> 2019 challenge and downloaded the dataset. Five of them succeeded in submitting runs. Details of the methods and systems used in the runs are synthesized in the overview working notes paper of the task <ref type="bibr" target="#b22">[23]</ref> and further developed in the individual working notes of the participants (MfN <ref type="bibr" target="#b25">[26]</ref>, ASAS <ref type="bibr" target="#b5">[6]</ref>, NWPU <ref type="bibr" target="#b20">[21]</ref>, MIHAI <ref type="bibr" target="#b7">[8]</ref>). In Figure <ref type="figure" target="#fig_1">4</ref> we report the performance achieved by the 25 collected runs.</p><p>In this edition, participants built on established systems from previous years, all submitted runs featured a CNN classifier trained on spectrograms-very deep networks once again performed best. Participants were able to significantly improve the detection performance. In fact, we saw an increase of more than 180% for the best performing runs (2018: 0.193 -2019: 0.356). This result is probably largely due to the high number of North American soundscapes that are less complex than their South American counterparts. However, the recognition performance for South American soundscapes also increased significantly compared to 2018 with a cmAP of 0.293 in 2019 over 0.222 from last year. Participants were allowed to use any publicly available metadata and even the provided validation data to improve the performance of their systems. Although expert annotations are not an adequate (or even easy-to-acquire) addition for the training of a recognition system for unseen habitats, the increase in overall performance is considerable. The highest scoring run submitted by MfN achieved a sample-wise mean average precision (our secondary metric) of 0.446 without the use of validation samples and 0.745 when validation data was used for training. These scores imply that domain adaption to new acoustic environments (and recorder characteristics) plays a crucial role and should be subject of investigation in future editions.</p></div>
<div><head n="4">Task3: GeoLifeCLEF</head><p>A detailed description of the task and a more complete discussion of the results can be found in the dedicated working note <ref type="bibr" target="#b3">[4]</ref>.</p></div>
<div><head n="4.1">Methodology</head><p>Predicting the shortlist of species that are likely to be observed at a given geographical location should significantly help to reduce the candidate set of species to be identified. However, none of the attempt to do so within previous Life-CLEF editions successfully used this information. The <software>GeoLifeCLEF</software> challenge was specifically created in 2018 to tackle this problem through a standalone task. More generally, automatically predicting the list of species that are likely to be observed at a given location might be useful for many other scenarios in biodiversity informatics. It could facilitate biodiversity inventories through the development of location-based recommendation services (typically on mobile phones) as well as the involvement of non-expert nature observers. It might also serve educational purposes thanks to biodiversity discovery applications providing functionalities such as contextualized educational pathways. The aim of the challenge is to predict the list of species that are the most likely to be observed at a given location. Therefore, we provide a large training set of species occurrences, each occurrence being associated to a multi-channel image characterizing the local environment. Indeed, it is usually not possible to learn a species distribution model directly from spatial positions because of the limited number of occurrences and the sampling bias. What is usually done in ecology is to predict the distribution on the basis of a representation in the environmental space, typically a feature vector composed of climatic variables (average temperature at that location, precipitation, etc.) and other variables such as soil type, land cover, distance to water, etc. The originality of <software ContextAttributes="used">GeoLifeCLEF</software> is to generalize such niche modeling approach to the use of an image-based environmental representation space. Instead of learning a model from environmental feature vectors, the goal of the task will be to learn a model from k-dimensional image patches, each patch representing the value of an environmental variable in the neighborhood of the occurrence. As last year, the task consists of predicting plant species from location, but we added a very large and newly published dataset of plant occurrences from a citizen science project. We also proposed to participants to use an even bigger dataset of non-plant species that might interact with plants.</p></div>
<div><head n="4.2">Data Set and Evaluation Protocol</head><p>Training set -The training data provided for the task included three distinct occurrences data sets:</p><p>-<software ContextAttributes="used">Pl@ntNetFranceRaw</software>: 2,367,145 occurrences of plants that were collected via the Pl@ntNet application and automatically identified (using a convolutional neural network). These original data is described and permanently hosted in <ref type="bibr" target="#b2">[3]</ref>.</p><p>-Pl@ntNetFranceTrusted: a subset of <software>Pl@ntNetFranceRaw</software> including only the occurrences for which the prediction score (softmax output of the CNN) was higher than a threshold equal to 0.98. -GBIFPlantFrance: 291,392 occurrences of 3,336 plant species collected by experts on the French territory between 1835 and 2017 (coming from the GBIF database 11 . -GBIFAllFrance: 10,618,839 occurrences of species from other kingdoms than plants including mammals, birds, amphibians, insects and fungus (also coming from the GBIF database).</p><p>Environmental data -We provided 33 geographic rasters of various spatial resolutions containing containing bioclimatic, pedologic, topologic, hydrographic and land cover variables suited for modeling plant species distributions. The original data compilation is freely downloadable and described in details at <ref type="bibr" target="#b1">[2]</ref>. We also provided a python tool allowing to extract the automatically environmental patches: A 3 dimensions array where each layer is the is a window matrix cropped into one raster, and centered at the specified location.</p><p>Test set -We used 25,000 plant occurrences of high location accuracy (inferior to 50 meters) and identification certainty collected by the Mediterranean National Botanical Conservatory (CBNmed) and their partners over the French Mediterranean region. They have been selected to insure that spatial coverage is uniform and that locally each present species have an equivalent number of occurrences.</p><p>Evaluation -Several tens of plant species coexist in some square meters. Thus, we have chosen to evaluate the ability of algorithms to predict the true species label of an occurrence among the predicted 30 highest ranked species. We thus used the top30 accuracy as primary metric:</p><formula xml:id="formula_2">Top30(L 1 , ..., L n occ ) = n occ i=1 1 {si∈Li} n occ</formula><p>Where s i is the species label of occurrence i and L i is the list of the 30 species labels predicted with highest probability for occurrence i by the algorithm.</p></div>
<div><head n="4.3">Participants and Results</head><p>61 participants registered for the <software ContextAttributes="used">GeoLifeCLEF</software> 2019 challenge and downloaded the dataset. Five of them succeeded in submitting 44 runs in total. Details of the methods and systems used in the runs are synthesized in the overview working note paper of the task <ref type="bibr" target="#b3">[4]</ref> and further developed in the individual working notes of the participants (LIRMM <ref type="bibr" target="#b29">[30]</ref>, SaraSi <ref type="bibr" target="#b32">[33]</ref>, SSN CSE <ref type="bibr" target="#b24">[25]</ref>, sergiu atodiresei <ref type="bibr" target="#b0">[1]</ref> and Lot of Lof <ref type="bibr" target="#b28">[29]</ref>). In Figure <ref type="figure" target="#fig_2">5</ref> we report the performance achieved by the 44 collected runs. The 5 best runs of this challenge all used Convolutional Neural Network models applied to environmental patches, which confirms results of last year edition. This performance gap might be also due to the fact that those models training included both <software ContextAttributes="used">Pl@ntNetFranceRaw</software> and GBIFPlantFrance plant occurrences, whereas non-CNN methods only used Pl@ntNet occurrences. The best run included non plant occurrences (corresponding species labels were added to the model output) along with plants occurrences. It had sharp performance improvement compared to the similar architecture learnt without including this data by the same participant (see run 27006). This strongly suggests that the model takes advantages of the correlations existing between plant species and other groups to reconstruct a more faithful biotic context that helps the prediction of plants species.</p><p>There may be significant room for improvement for the implementation of the best run. Indeed, the architecture or learning process employed by LIRMM for the CNN may be limitating as we can see the same method learnt on plants only (run 27006) achieved lower performance than SaraSi CNN implementations (runs 27086, 27087, 27088). More generally, further investigations should build on this approach of using a wide range of species in learning models. Also it would be important to compare <software>Pl@ntNetFranceRaw</software> and <software ContextAttributes="used">GBIFPlant</software>-France data sets and their fusion, to deal for example with observers preferences bias towards species.</p></div>
<div><head n="5">Conclusions and Perspectives</head><p>The main outcome of this collaborative evaluation is a new snapshot of the performance of state-of-the-art computer vision, bio-acoustic and machine learning techniques towards building real-world biodiversity monitoring systems. This study shows that recent deep learning techniques still allow some consistent progress for most of the evaluated tasks. The results of <software>GeoLifeCLEF</software>, in particular, revealed for the first time that deep neural networks are able to transfer knowledge from a kingdom to another one in a very effective way. However, our study also shows that data availability is a major issue to be resolved if we want to transpose the best results obtained to any habitat on earth. The results of <software ContextAttributes="used">BirdCLEF</software> have once again shown significant progress on a difficult task based on soundscapes even if the newly introduced North American soundscapes seems to be less complex than their South American counterparts. Domain adaption to new acoustic environments (and recorder characteristics) played a crucial role and should be subject of investigation in future editions. The results of Plant-CLEF, in particular, reveal that the identification performance on Amazonian plants is considerably lower than the one obtained on temperate plants of Europe and North America. The analysis of the results showed that the management of different types of noise (duplicates, errors, non-plants), of different type of </p></div><figure xml:id="fig_0"><head>Fig. 3 .3. 1 Methodology</head><label>31</label><figDesc>Fig. 3. Scores achieved by all systems evaluated within the plant identification task of LifeCLEF 2019</figDesc><graphic coords="8,134.77,115.84,345.82,160.56" type="bitmap" /></figure>
<figure xml:id="fig_1"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Scores achieved by all systems evaluated within the bird identification task of LifeCLEF 2019</figDesc><graphic coords="10,134.77,115.83,345.82,154.52" type="bitmap" /></figure>
<figure xml:id="fig_2"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. Top30 metric per run and participant on GeoLifeCLEF 2019 task</figDesc><graphic coords="14,134.77,243.59,368.51,257.95" type="bitmap" /></figure>
			<note place="foot" n="9" xml:id="foot_0"><p>http://www.lifeclef.org/</p></note>
			<note place="foot" n="10" xml:id="foot_1"><p>http://www.imageclef.org/</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><p>Acknowledgements We would like to thank very warmly <rs type="person">Julien Engel</rs>, <rs type="person">Rémi Girault</rs>, <rs type="person">Jean-François Molino</rs> and the two other expert botanists who agreed to participate in the task on plant identification. We also we would like to thank the <rs type="institution">University of Montpellier</rs> and the <rs type="institution">Floris'Tic project (ANRU)</rs> who contributed to the funding of the 2019-th edition of <software ContextAttributes="used">LifeCLEF</software>.</p></div>
			</div>			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Location-based species recommendation -geolifeclef 2019 challenge</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">S</forename><surname>Atodiresei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Iftene</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CLEF working notes 2019</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A compilation of environmental geographic rasters for sdm covering france (version 1) [data set</title>
		<author>
			<persName><forename type="first">C</forename><surname>Botella</surname></persName>
		</author>
		<idno type="DOI">10.5281/zenodo.2635501</idno>
		<ptr target="http://doi.org/10.5281/zenodo.2635501" />
	</analytic>
	<monogr>
		<title level="j">Zenodo</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Pl@ntnet queries 2017-2018 in france</title>
		<author>
			<persName><forename type="first">C</forename><surname>Botella</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Bonnet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Joly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Lombardo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Affouard</surname></persName>
		</author>
		<idno type="DOI">10.5281/zenodo.2634137</idno>
		<ptr target="http://doi.org/10.5281/zenodo.2634137" />
		<imprint>
			<date type="published" when="2019">2019</date>
			<pubPlace>Zenodo</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Overview of geolifeclef 2019: plant species prediction using environment and animal occurrences</title>
		<author>
			<persName><forename type="first">C</forename><surname>Botella</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Servajean</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Bonnet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Joly</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CLEF working notes</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page">2019</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Sensor network for the monitoring of ecosystem: Bird species recognition</title>
		<author>
			<persName><forename type="first">J</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Ee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Roe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Intelligent Sensors, Sensor Networks and Information</title>
		<imprint>
			<date type="published" when="2007">2007. 2007</date>
		</imprint>
	</monogr>
	<note>ISSNIP 2007. 3rd International Conference on</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Bird sound classification using convolutional neural networks</title>
		<author>
			<persName><forename type="first">Chih-Yuan</forename><surname>Koh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jaw-Yuan</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">L T D Y H</forename><surname>Hsieh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">H</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CLEF working notes</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page">2019</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Plant identification on amazonian and guiana shield flora: Neuon submission to lifeclef 2019 plant</title>
		<author>
			<persName><forename type="first">S</forename><surname>Chulif</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Jing Heng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Wei Chan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Al Monnaf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">L</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CLEF (Working Notes)</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Bird species identification using neural networks</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Costandache</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CLEF working notes</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page">2019</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Non-local densenet for plant clef 2019 contest</title>
		<author>
			<persName><forename type="first">Dat</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thanh</forename></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">Q</forename><surname>Goeuriot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CLEF (Working Notes)</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Automated species identification: why not?</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">J</forename><surname>Gaston</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>O'neill</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Philosophical Transactions of the Royal Society of London B: Biological Sciences</title>
		<imprint>
			<biblScope unit="volume">359</biblScope>
			<biblScope unit="issue">1444</biblScope>
			<biblScope unit="page" from="655" to="667" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Plant identification using deep neural networks via optimization of transfer learning parameters</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Ghazi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Yanikoglu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Aptoula</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">235</biblScope>
			<biblScope unit="page" from="228" to="235" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<author>
			<persName><forename type="first">H</forename><surname>Glotin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Dugan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Halkias</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sueur</surname></persName>
		</author>
		<ptr target="http://sabiod.org/ICML4B2013_book.pdf" />
		<title level="m">Proc. 1st workshop on Machine Learning for Bioacoustics -ICML4B. ICML</title>
		<meeting>1st workshop on Machine Learning for Bioacoustics -ICML4B. ICML<address><addrLine>Atlanta USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Plant identification based on noisy web data: the amazing performance of deep learning (lifeclef 2017)</title>
		<author>
			<persName><forename type="first">H</forename><surname>Goëau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Bonnet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Joly</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CLEF 2017-Conference and Labs of the Evaluation Forum</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1" to="13" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Plant identification based on noisy web data: the amazing performance of deep learning (lifeclef 2017)</title>
		<author>
			<persName><forename type="first">H</forename><surname>Goëau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Bonnet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Joly</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Working Notes of CLEF 2017 (Cross Language Evaluation Forum)</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Overview of expertlifeclef 2018: how far automated identification systems are from the best experts ?</title>
		<author>
			<persName><forename type="first">H</forename><surname>Goëau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Bonnet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Joly</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CLEF working notes 2018</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Overview of lifeclef plant identification task 2019: diving into data deficient tropical countries</title>
		<author>
			<persName><forename type="first">H</forename><surname>Goëau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Bonnet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Joly</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Working Notes of CLEF 2019 (Cross Language Evaluation Forum)</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">The imageclef 2013 plant identification task</title>
		<author>
			<persName><forename type="first">H</forename><surname>Goëau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Bonnet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Joly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Bakic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Barthélémy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Boujemaa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">F</forename><surname>Molino</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CLEF 2013</title>
		<meeting><address><addrLine>Valencia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">The imageclef 2011 plant images classification task</title>
		<author>
			<persName><forename type="first">H</forename><surname>Goëau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Bonnet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Joly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Boujemaa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Barthélémy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">F</forename><surname>Molino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Birnbaum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Mouysset</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Picard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CLEF 2011</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Imageclef2012 plant images identification task</title>
		<author>
			<persName><forename type="first">H</forename><surname>Goëau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Bonnet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Joly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Yahiaoui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Barthélémy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Boujemaa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">F</forename><surname>Molino</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CLEF 2012</title>
		<meeting><address><addrLine>Rome</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">The imageclef plant identification task</title>
		<author>
			<persName><forename type="first">H</forename><surname>Goëau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Joly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Bonnet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Bakic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Barthélémy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Boujemaa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">F</forename><surname>Molino</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2nd ACM international workshop on Multimedia analysis for ecological data</title>
		<meeting>the 2nd ACM international workshop on Multimedia analysis for ecological data</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2013">2013. 2013</date>
			<biblScope unit="page" from="23" to="28" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Inception-v3 based method of lifeclef 2019 bird recognition</title>
		<author>
			<persName><forename type="first">Jisheng</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bolun</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">C Z F</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CLEF working notes 2019</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Interactive plant identification based on social image data</title>
		<author>
			<persName><forename type="first">A</forename><surname>Joly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Goëau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Bonnet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Bakić</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Barbe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Selmi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Yahiaoui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Carré</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Mouysset</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">F</forename><surname>Molino</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ecological Informatics</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="22" to="34" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Overview of birdclef 2019: Large-scale bird recognition in soundscapes</title>
		<author>
			<persName><forename type="first">S</forename><surname>Kahl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">R</forename><surname>Stöter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Glotin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Planqué</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">P</forename><surname>Vellinga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Joly</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CLEF (Working Notes)</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">The unreasonable effectiveness of noisy data for fine-grained recognition</title>
		<author>
			<persName><forename type="first">J</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Sapp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Toshev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Duerig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Philbin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="301" to="320" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Species recommendation using machine learning -geolifeclef</title>
		<author>
			<persName><forename type="first">N</forename><surname>Krishna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">R</forename><surname>Kaushik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Mirunalini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Chandrabose</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Jaisakthi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CLEF working notes</title>
		<imprint>
			<date type="published" when="2019">2019. 2019</date>
			<biblScope unit="page">2019</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Bird species identification in soundscapes</title>
		<author>
			<persName><forename type="first">M</forename><surname>Lasseck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CLEF working notes 2019</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Contour matching for a fish recognition and migration-monitoring system</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">B</forename><surname>Schoenberger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Shiozawa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Zhan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Optics East</title>
		<imprint>
			<publisher>International Society for Optics and Photonics</publisher>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="37" to="48" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Multi-organ plant classification based on convolutional and recurrent neural networks</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">S</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Remagnino</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="4287" to="4301" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Species recommendation using intensity models and sampling bias correction (geolifeclef 2019: Lof of lof team)</title>
		<author>
			<persName><forename type="first">P</forename><surname>Monestiez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Botella</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CLEF working notes</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page">2019</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><surname>Negri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Servajean</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Joly</surname></persName>
		</author>
		<title level="m">Plant prediction from cnn model trained with other kingdom species (geolifeclef 2019: Lirmm team)</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page">2019</biblScope>
		</imprint>
	</monogr>
	<note>CLEF working notes</note>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<ptr target="http://sabiod.org/nips4b" />
		<title level="m">NIPS Int. Conf.: Proc. Neural Information Processing Scaled for Bioacoustics, from Neurons to Big Data</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Recognition of the amazonian flora by inception networks with test-time class prior estimation</title>
		<author>
			<persName><forename type="first">L</forename><surname>Picek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Šulc</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Matas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CLEF (Working Notes)</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Species recommendation using environment and biotic associations</title>
		<author>
			<persName><forename type="first">S</forename><surname>Si-Moussi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hedde</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Daufresne</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CLEF working notes</title>
		<imprint>
			<biblScope unit="page">2019</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">A toolbox for animal call recognition</title>
		<author>
			<persName><forename type="first">M</forename><surname>Towsey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Planitz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Nantes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wimmer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Roe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioacoustics</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="107" to="125" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Automated species recognition of antbirds in a mexican rainforest using hidden markov models</title>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">M</forename><surname>Trifa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">N</forename><surname>Kirschel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">E</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">E</forename><surname>Vallejo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of the Acoustical Society of America</title>
		<imprint>
			<biblScope unit="volume">123</biblScope>
			<biblScope unit="page">2424</biblScope>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>