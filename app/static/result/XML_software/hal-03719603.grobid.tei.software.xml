<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Parsimonious Representation of Knowledge Uncertainty Using Metadata About Validity and Completeness</title>
				<funder ref="#_4CH8HTp">
					<orgName type="full">French government</orgName>
				</funder>
				<funder ref="#_WDbqwFW">
					<orgName type="full">Agence Nationale de la Recherche</orgName>
					<orgName type="abbreviated">ANR</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Célia</forename><surname>Da Costa Pereira</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Université Côte d&apos;Azur</orgName>
								<orgName type="institution" key="instit2">CNRS</orgName>
								<orgName type="institution" key="instit3">I3S</orgName>
								<address>
									<settlement>Sophia Antipolis</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Didier</forename><surname>Dubois</surname></persName>
							<email>dubois@irit.fr</email>
							<affiliation key="aff1">
								<orgName type="institution">IRIT -CNRS</orgName>
								<address>
									<addrLine>118, route de Narbonne</addrLine>
									<settlement>Toulouse</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Henri</forename><surname>Prade</surname></persName>
							<email>prade@irit.fr</email>
							<affiliation key="aff1">
								<orgName type="institution">IRIT -CNRS</orgName>
								<address>
									<addrLine>118, route de Narbonne</addrLine>
									<settlement>Toulouse</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Andrea</forename><forename type="middle">G B</forename><surname>Tettamanzi</surname></persName>
							<email>andrea.tettamanzi@univ-cotedazur.fr</email>
							<affiliation key="aff2">
								<orgName type="institution" key="instit1">Université Côte d&apos;Azur</orgName>
								<orgName type="institution" key="instit2">Inria</orgName>
								<orgName type="institution" key="instit3">CNRS</orgName>
								<orgName type="institution" key="instit4">I3S</orgName>
								<address>
									<settlement>Sophia Antipolis</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Parsimonious Representation of Knowledge Uncertainty Using Metadata About Validity and Completeness</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">AE47505940AC51EF340E6C6BE27DD54F</idno>
					<idno type="DOI">10.5220/0010874000003116</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-04-12T14:53+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>Knowledge Representation, Possibility Theory</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We investigate how metadata about the uncertainty of knowledge contained in a knowledge base can be expressed parsimoniously and used for reasoning. We propose an approach based on possibility theory, whereby a classical knowledge base plus metadata about the degree of validity and completeness of some of its portions are used to represent a possibilistic belief base. We show how reasoning on such belief base can be done using a classical reasoner.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION AND RELATED WORK</head><p>In general, the process of getting a piece of information from a Knowledge Base (KB) is driven by practical purposes-such a piece of information will be used to justify certain decisions, for example. Its quality has therefore an important role to play in the success of the decisions made. The quality of a piece of information can be measured by considering different dimensions. Most contributions in the literature concentrate exclusively on the amount of true (known) facts in a KB for assessing its quality. <ref type="bibr" target="#b16">(Wick et al., 2013)</ref>, for example, propose several algorithms for estimating a value of confidence based on the probability of a fact in a KB being true. In <ref type="bibr" target="#b6">(Dong et al., 2014)</ref>, the authors studied the applicability of data fusion techniques to solve the problem of knowledge base feeding. The criterion they used to construct quality knowledge bases was to identify the true values of data items among multiple observed values provided from different (and maybe unknown) sources with different reliabilities. However, as it has been pointed out for example by <ref type="bibr" target="#b15">(Razniewski et al., 2016)</ref>,</p><p>In other words, a knowledge base is in general incomplete. This obviously has an impact on the overall quality of a KB-the more it is incomplete the lesser is its quality and the more the pieces of information extracted from it have to be considered (used) with caution.</p><p>The problem of representing both validity and completeness has begun to be dealt with for information stored in databases many years ago before being addressed for knowledge bases (KBs). For example, we can consider the model of database integrity proposed by <ref type="bibr" target="#b14">(Motro, 1989)</ref> and the work by <ref type="bibr" target="#b4">(Demolombe, 1996)</ref>, who used modal logic for reasoning about validity and completeness of information stored in relational databases as precursors of some ideas that have later been adopted for KBs. However, the representation of the incompleteness in information stored in the databases has been inspired by earlier works on the representation of incompleteness in knowledge bases as the ones proposed by <ref type="bibr" target="#b12">(Levesque, 1980;</ref><ref type="bibr" target="#b13">Levesque, 1982)</ref> and the one proposed by <ref type="bibr" target="#b0">(Collins et al., 1975)</ref> for reasoning with this kind of knowledge bases.</p><p>Recent work on annotating KBs with metadata about their completeness has been done, in the context of the semantic Web, by <ref type="bibr" target="#b3">(Darari et al., 2013;</ref><ref type="bibr" target="#b15">Razniewski et al., 2016)</ref>, who studied the way in which statements about completeness can be used when answering queries. According to their approach, it is then possible, given a statement about a topic, to specify if information about it in the base is complete or not. However, the gradual view of completeness in data sources has not been considered.</p><p>Solutions to construct a possibilistic belief base from a crisp KB using topical validity and completeness metadata, like <ref type="bibr" target="#b2">(da Costa Pereira et al., 2017)</ref>, suffer from some limitations, mainly due to the fact that, in order to guarantee consistency, they have to sacrifice much of the expressive power of the knowledge representation language. In particular, the "facts" that can be recorded in the knowledge base are restricted only to ground formulas without negation and disjunction. Indeed, negative information (i.e., facts that do not hold) is critical for the correctness of queries involving negation <ref type="bibr" target="#b15">(Razniewski et al., 2016)</ref>. Completeness and negative information are closely related: if we know that a portion of a KB is complete, it is as if we knew an infinity of negated facts (all those relevant to that portion that are not in the KB).</p><p>Motivated by the above considerations, we want to answer the following research question: is it possible that a classical knowledge base plus metadata information on the (gradual) validity and completeness with respect to a few configurations (groups, portions, subjects, topics of statements it contains), enables one to represent a possibilistic belief base and perform possibilistic inferences by using a classical reasoner? This research question leads us to the following subquestion: which should be a suitable definition for such a configuration which in turn will allow us to define appropriate validity and completeness functions?</p><p>We propose a framework based on possibility theory to represent and reason about gradual notions of validity and completeness in KBs. Since it would be impractical to associate values of possibility and necessity to each single assertion in a knowledge base (KB), we show that, thanks to validity and completeness metadata, it is possible to express degrees of possibility/necessity for formulas entailed by the KB in a parsimonious way (i.e., without having to associate a weight to each single formula) and to perform possibilistic inferences on top of a classical KB, considering, in addition to possibilistic uncertainty, also negative information.</p><p>In particular, we present a way to represent validity and completeness information (with respect to particular slices of information) in a knowledge base in a way that permits said validity and completeness information to simulate the knowledge base as a possibilistic knowledge base, where the possibilistic information is derived exclusively from the validity and completeness. The advantage of this approach is that the validity and completeness is only assessed at the slice level, where in a possibilistic knowledge base, the possibility distribution needs to be defined for all facts. Therefore, when the number of slices is much smaller than the number of facts, the proposed representation is much more parsimonious.</p><p>The paper is organized as follows: Section 2 gives then some background about the formal tools we use. We present our proposal in Section 3, which explains how (gradual) validity and completeness are related to the beliefs of an agent. Finally, Section 4 discusses some possible applications of our proposal.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">BACKGROUND</head><p>We first provide a brief refresher on possibility theory, before recalling the basics of possibilistic logic, a logic where classical formulas are weighted in terms of certainty.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Possibility Theory</head><p>Fuzzy sets <ref type="bibr" target="#b17">(Zadeh, 1965)</ref> are sets whose elements have degrees of membership in [0, 1]. Possibility theory <ref type="bibr" target="#b8">(Dubois and Prade, 1988</ref>) is a mathematical theory of uncertainty that relies upon fuzzy set theory, in that the (fuzzy) set of possible values for a variable of interest is used to describe the uncertainty as to its precise value. At the semantic level, the membership function of such set, π, is called a possibility distribution and its range is [0, 1]. A possibility distribution can represent the available knowledge of an agent. π(I ) represents the degree of compatibility of the interpretation I with the available knowledge about the real world if we are representing uncertain pieces of knowledge. By convention, π(I ) = 1 means that it is totally possible for I to be the real world, 1 &gt; π(I ) &gt; 0 means that I is only somehow possible, while π(I ) = 0 means that I is certainly not the real world.</p><p>A possibility distribution π is said to be normalized if there exists at least one interpretation I 0 s.t.</p><p>π(I 0 ) = 1, i.e., there exists at least one possible situation which is consistent with the available knowledge.</p><p>Definition 1. (Possibility and Necessity Measures) A possibility distribution π induces a possibility measure and its dual necessity measure, denoted by Π and N respectively. Both measures apply to a classical set S ⊆ Ω and are defined as follows:</p><formula xml:id="formula_0">Π(S) = max I ∈S π(I );<label>(1)</label></formula><formula xml:id="formula_1">N(S) = 1 -Π( S) = min I ∈ S {1 -π(I )}.<label>(2)</label></formula><p>In words, Π(S) expresses to what extent S is consistent with the available knowledge. Conversely, N(S) expresses to what extent S is entailed by the available knowledge. It is equivalent to the impossibility of its complement S-the more S is impossible, the more S is certain. A few properties of Π and N induced by a normalized possibility distribution on a finite universe of discourse Ω are the following. For all subsets A, B ⊆ Ω:</p><formula xml:id="formula_2">1. Π(A ∪ B) = max{Π(A), Π(B)}; 2. Π(A ∩ B) ≤ min{Π(A), Π(B)}; 3. Π( / 0) = N( / 0) = 0; Π(Ω) = N(Ω) = 1; 4. N(A ∩ B) = min{N(A), N(B)}; 5. N(A ∪ B) ≥ max{N(A), N(B)}; 6. Π(A) = 1 -N( Ā) (duality); 7. N(A) &gt; 0 ⇒ Π(A) = 1; Π(A) &lt; 1 ⇒ N(A) = 0; A consequence of these properties is that max{Π(A), Π( Ā)} = 1. In case of complete ig- norance on A, Π(A) = Π( Ā) = 1.</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Possibilistic Logic</head><p>Before going into details about possibilistic logic, we would like to put forward our motivation for such a logic for handling uncertainty in this work. Information is often pervaded with uncertainty, and it may be convenient to associate pieces of information with certainty levels. These certainty levels can often be qualitatively assessed only using a finite completely ordered scale ranging from "fully certain" to "not certain at all", with intermediary levels such as "almost certain", or "somewhat certain". Possibility theory offers such a qualitative setting, when a finite subset of [0, 1] including 0 and 1 is used and then only the ordering of the degrees in [0, 1] is meaningful, in agreement with the use of max and min operators. Moreover, the inverse mapping 1-(•) exchanges the necessity scale with a possibility scale, such as "fully possible", "quite possible", "somehow possible", "not possible at all (= impossible)". In the following, the pieces of information are associated with certainty levels which are viewed as lower bounds of necessity measures. Then, the min-decomposability of necessity measures with respect to conjunction acknowledges the fact that to be certain at least at some level α that a conjunction of facts is true, we should be certain at least at level α that the truth of each fact is certain at least at level α.</p><p>Possibilistic logic <ref type="bibr" target="#b7">(Dubois et al., 1994)</ref> has been originally motivated by the need to manipulate syntactic expressions of the form (φ, α) where φ is a classical logic formula, and α is a certainty level, with the intended semantics that N(φ) ≥ α, where N is a necessity measure. It is then possible to consider that all the propositions of the considered language can be totally ordered on a given scale. In our case, propositions are formulas. Besides, in possibilistic logic, a level of inconsistency can be associated with a knowledge base as recalled now.</p><p>A possibilistic knowledge base B is a set of possibilistic logic formulas</p><formula xml:id="formula_3">{(φ i , α i ) | i = 1, . . . , m}. Clearly, B can be layered into a set of nested classical bases B α = {φ i | (φ i , α i ) ∈ B and α i ≥ α} such that B α ⊆ B β if α ≥ β. Proving syntacti- cally B ⊢ (φ, α)</formula><p>amounts to proceeding by refutation and proving B ∪ {(¬φ, 1)} ⊢ (⊥, α) by repeated application of the resolution rule</p><formula xml:id="formula_4">(¬φ ∨ ψ, α), (φ ∨ ν, β) ⊢ (ψ ∨ ν, min(α, β)). Moreover, B ⊢ (φ, α) if and only if B α ⊢ φ and α &gt; inc(B), where inc(B) is inconsistency level of B defined as inc(B) = max{α | B ⊢ (⊥, α)}. It can be shown that inc(B) = 0 iff B * is consistent, with B * = {φ i | (φ i , α i ) ∈ B}.</formula><p>Thus reasoning from a possibilistic base just amounts to reasoning classically with subparts of the base whose formulas are strictly above the certainty level.</p><p>A possibilistic knowledge base</p><formula xml:id="formula_5">B = {(φ i , α i ) | i = 1, . . . , m} encodes the constraints N(φ i ) ≥ α i .</formula><p>B is thus semantically associated with a possibility distribution <ref type="bibr" target="#b7">(Dubois et al., 1994)</ref> </p><formula xml:id="formula_6">π B (I ) = min i=1,...,m max(φ I i , 1 -α i ),</formula><p>where φ I i = 1 if I is a model of φ i , and φ I i = 0 otherwise. As it can be seen, π B (I ) is all the larger as the interpretation I makes false only formulas with low certainty levels. π B is the largest possibility distribution, i.e., the least committed distribution assigning the largest possibility levels in agreement with the constraints N(φ i ) ≥ α i for i = 1, . . . , m. The distribution π B rank-orders the interpretations I of the language induced by the φ i 's according to their plausibility on the basis of the strength of the pieces of information in B. If the set of formulas B * is consistent then the distribution π B is normalized (i.e., ∃I , π B (I ) = 1). The semantic entailment is defined by</p><formula xml:id="formula_7">B |= (φ, α) iff ∀I , π B (I ) ≤ π {(φ,α)} (I ).</formula><p>Reasoning by refutation in propositional possibilistic logic is sound and complete, applying the syntactic resolution rule. Namely, it can be shown that</p><formula xml:id="formula_8">B |= (φ, α) iff B ⊢ (φ, α) and inc(B) = 1 -max I π B (I ).</formula><p>Algorithms for reasoning in possibilistic logic and an analysis of their complexity, which is similar to the one of classical logic, multiplied by the logarithm of the number of levels used in the necessity scale, can be found in <ref type="bibr" target="#b11">(Lang, 2001)</ref>.</p><p>As it was hypothesized by <ref type="bibr" target="#b14">(Motro, 1989)</ref> for the case of relational databases, here, to formalize the concepts of validity and completeness in the the case of knowledge bases, we shall assume the existence of a hypothetical knowledge base that captures a designated environment of the real world perfectly. The knowledge base K mentioned in the paper is then an approximation of such hypothetical knowledge base.</p><p>When dealing with relational databases, only the statements explicitly present in the database are considered as true (valid). The others are considered as false (closed world assumption). When dealing with sets of formulas, the true statements are those explicitly represented in the dataset, plus those which can be inferred thanks to a reasoner. However, due to the open world assumption, we cannot suppose that the other statements are false-the truth status of some statements may be unknown in case of incomplete knowledge.</p><p>In this section, we recall the notions of validity and completeness, first introduced in <ref type="bibr" target="#b4">(Demolombe, 1996)</ref>, and made gradual in the setting of possibilistic logic <ref type="bibr" target="#b9">(Dubois and Prade, 1997)</ref> for dealing with relational databases and adapt them to the more general setting of knowledge bases, where (i) the open world assumption holds, (ii) implicit knowledge can be inferred by logical deduction, and (iii) negative information is also taken into account unlike what was proposed in <ref type="bibr" target="#b2">(da Costa Pereira et al., 2017)</ref>.</p><p>It is often the case that the knowledge contained in a knowledge base is not all certain to the same degree. There will be statements whose truth is absolutely certain. This might be the case of ontological axioms or integrity constraints. Other groups of statements, obtained for example from the same source or covering the same subject, might have the same degree of certainty, but statements from different portions of the knowledge base might be believed with greater or lower certainty.</p><p>Our working hypothesis is that, as suggested by <ref type="bibr" target="#b2">(da Costa Pereira et al., 2017)</ref>, the degree of certainty of every piece of information depends on the degree to which the knowledge base is valid and complete with respect to all groups, portions, subjects, topics (or whatever else we wish to call them) of statements it contains. We think that an intuitive name for this notion of a semantically determined homogeneous portion of a knowledge base may be a slice and we will stick to this term from now on.</p><p>While it is true that the term slice might lead to confusion with the same term as used in the hypercube data model <ref type="bibr" target="#b10">(Gray et al., 1997)</ref>, as a matter of fact, the suggestion that a slice may be a subset defined by fixing one or more dimensions constitutes a good and useful intuition. Indeed, if we interpret slices as knowledge "topics" or "domains", then this is exactly what slices are, with the specificity that here every "dimension" can be viewed as a binary truth assignment to a formula, e.g., in a hypotetical knowledge base about travel,"x is a flight and x departs from London", thus giving the slice of the knowledge base that provides information about flights departing from London.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Postulates</head><p>To be able to talk about the validity and completeness of information stored in a knowledge base with respect to a particular slice, we need a formal way of defining the latter. We begin with the most general and neutral definition, whereby a slice T is just a set of formulas. A more precise definition is deferred to when we will have discussed the properties that a slice must satisfy.</p><p>A few basic postulates for slices, based on common sense arguments, are the following.</p><p>P1 Slices are non-empty. We assume slices are defined by the designer or a user of a knowledge base in order to state metadata about the validity and completeness of portions of knowledge in the base; defining an empty slice would defeat its purpose.</p><p>P2 Slices are all distinct. Defining two equivalent slices would be redundant and of no practical use; therefore, we can safely bar this possibility.</p><p>P3 For every slice not contained in another slice (we may call it a "top-level" slice), there exists a formula entailed by the knowledge base that only belongs in that slice and in no other slice.</p><p>What justifies stating Postulate P3 is that for every portion of a knowledge base a knowledge engineer might want to define in order to state metadata on it, one would expect that either that portion is a proper subset of another portion (i.e., a sort of sub-topic or sub-domain), or, if it is not, then its very definition is motivated by the existence of some facts that are not covered by other slices. For instance, in a knowledge base about travel, I might want to define a slice about "airports" because there are assertions involving airports, like "London Heathrow (LHR) has four operational terminals", that do not deal with any other possible slices, like "flights", "airlines", "aircraft", and so on. Or I might choose to define "aviation", which includes all of them, including the assertion about LHR, which is not covered by any other existing slice. Let K be a set of formulas in a decidable logical language L, for which there exists a reasoner capable of performing inferences and deduce other formulas which are not explicitly contained in K.</p><p>Under the closed-world hypothesis typical of databases, which is the setting in which <ref type="bibr" target="#b9">(Dubois and Prade, 1997)</ref> was stated, it would be reasonable to admit that what cannot be deduced from an agent's knowledge base corresponds to what the agent believes to be false.</p><p>However, in the case of a knowledge base, the open-world assumption holds and the agent is capable of performing logical inferences (e.g., thanks to a reasoner). Therefore, we must think in terms of logical entailment of formulas.</p><p>Without loss of generality, we will assume a Herbrand semantics for L. Definition 2. The Herbrand base of L is the set H L of all ground atoms in L. An interpretation (or model) is a function I : H L → {0, 1}, which can also be viewed as a subset of the Herbrand base, I ⊆ H L (the set of all atoms φ such that φ I = 1). We denote Ω 2 H L the set of all interpretations.</p><p>We write K |= φ to denote the fact that formula φ is a logical consequence of all the formulas in K. Using a sound and complete reasoner, if K |= φ, φ can also be deduced from K by the agent (which we write K ⊢ φ), whereas if K ̸ ⊢ φ (φ cannot be deduced from K), this means that K ̸ |= φ (φ is not a logical consequence of K). Finally, given a set S of formulas, K |= S if and only if ∀φ ∈ S, K |= φ.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Graded Validity and Completeness</head><p>The purpose of a knowledge base is to store axioms and assertions that summarize an agent's knowledge about the world or, at least, a limited portion of the world, which is relevant to the problem the agent is intended to deal with. We will take an objectivist stance by assuming that there exists, among all the possible interpretations on language L, one that reflects the actual state of affairs. Let us denote such interpretation by I * . Then we may say that the objective truth of any formula φ ∈ L is given by φ I * . To be absolutely clear about that, we are assuming that I * is real and an objective truth exists for every formula, independently of a knowledge base K and of the agent using it. As a matter of fact, the knowledge represented in (a slice of) K might (and will, in general) not reflect reality perfectly or accurately.</p><p>Given this premise, the notions of validity and completeness of a knowledge base K with respect to a slice may be defined as follows:</p><p>• K is valid with respect to a slice iff, for every formula φ in that slice, K |= φ implies that I * |= φ, i.e., φ is objectively true; • K is complete with respect to a slice iff, for every formula φ in that slice, K ̸ |= φ implies that I * ̸ |= φ, i.e., φ is objectively false. As pointed out in Section 1, we will use the term beliefs to refer to (possibly partial, incomplete, or invalid) information held by an agent. An agent may then believe something to different degrees. We suppose that these degrees depend on both the degree of completeness of the sets of statements and on the reliability or trustworthiness of the information source. For example <ref type="bibr" target="#b2">(da Costa Pereira et al., 2017)</ref>, information related to an Air France flight should be complete if the source is the Air France carrier itself. However, the completeness could be lower if the source is a private travel agency with a partial coverage about the current flights from the different companies including those of Air France. Similarly, the degree of trust to be associated with information fed by a clerk should be lower than the one to be associated with information fed by a supervisor. Still, we would like to stress that the way in which such degrees are obtained is out of the scope of this paper.</p><p>As pointed out in Section 2, possibility theory is well suited to model degrees of certainty or, dually, degrees of possibility. Besides, possibility theory, unlike other theories of uncertainty like probability theory, is well -suited to model total ignorance which is necessary to represent situations in which we have, for example, both K ̸ |= φ and K ̸ |= ¬φ. This is the reason why, here, we adopt this theory to represent the gradual property of both the reliability of an information source as well as the completeness of information regarding a particular slice.</p><p>We assume that K is a consistent, classical (as opposed to possibilistic) knowledge base, i.e., K contains statements (such as axioms and assertions) expressed in one of the decidable logical languages usually employed to represent knowledge in practical applications (examples might be Datalog, description logics, RDF + RDFS, or one of the profiles of OWL).</p><p>We assume that, in addition to K, metadata about validity and completeness of information stored in K are given in the form of two functions, Val and Comp, which associate a degree of validity and completeness, respectively, to a number of slices defined on K. Let S K ⊂ 2 L the set of such slices. In practice, these two functions might be implemented by a lookup table, listing their values for each defined slice. Definition 3. Let Val : S K → [0, 1] be such that, for each slice T ∈ S K , Val(T ) is the degree to which K contains valid information about slice T , which means, for all formulas φ such that K |= φ and φ ∈ T , N(φ) ≥ Val(T ).</p><p>Intuitively, if we can deduce φ from the knowledge base K, and φ belongs in slice T , and we know that the source who fed K is (somehow) reliable for domain of T then the agent should believe φ at least as much as the degre to which the source is reliable. If the source is fully reliable then φ will be certain for the agent.</p><p>Definition 4. Let Comp : S K → [0, 1] be such that, for each slice T ∈ S K , Comp(T ) is the degree to which K contains complete information about slice T , which means, for all formulas φ such that K ̸ |= φ and φ ∈ T ,</p><formula xml:id="formula_9">Π(φ) ≤ 1 -Comp(T ).</formula><p>Intuitively, if we cannot deduce φ from the knowledge base K, and φ belongs in slice T , and we know that information in K about slice T is (somehow) complete, then φ should be certainly false.</p><p>It is reasonable to assume that, given two slices T and T ′ ,</p><formula xml:id="formula_10">T ⊆ T ′ ⇒ Val(T ) ≥ Val(T ′ ),<label>(3)</label></formula><formula xml:id="formula_11">T ⊆ T ′ ⇒ Comp(T ) ≥ Comp(T ′ ).<label>(4)</label></formula><p>Indeed, if we are told that K contains reliable (resp. complete) information about a broader domain T ′ to a given degree α, then K cannot be less reliable (complete) about a narrower (i.e., more specific) domain T ; if anything, it might be more reliable (complete) about T if a more reliable (complete) source is available just for T . The extent to which the agent believes φ depends on (i) what is supposed to be known about φ -can we deduce φ from K? -, and (ii) on the validity and completeness of K with respect to the slices that contain φ. That being the case, K, together with the metadata provided by Val and Comp, should allow us to compute the degree of possibility and necessity for any arbitrary formula φ, as follows:</p><formula xml:id="formula_12">Π(φ) = 1, if K |= φ, min T :φ∈T {1 -Comp(T )}, otherwise;</formula><p>(5)</p><formula xml:id="formula_13">N(φ) = max T :φ∈T Val(T ), if K |= φ, 0, otherwise.<label>(6)</label></formula><p>Let us call π the hypothetical possibility distribution that induces the possibility and necessity measures of Equations 5 and 6 and let B a hypothetical possibilistic belief base corresponding to it. Furthermore, among all possibility distributions compatible with Π and N, we will select the one that makes the least commitment, i.e., the maximal (most general) one.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Existence Conditions</head><p>We now derive a necessary condition for the existence of such a possibility distribution π.</p><p>Let φ be such that K |= φ; if K is consistent, K ̸ |= ¬φ. By the duality property of the possibility and necessity measures, it must be Π(φ) = 1-N(¬φ); this is satisfied by Equations 5 and 6, since Π(φ) = 1 and N(¬φ) = 0. Proposition 1. Let us assume that K is consistent and that there exists a possibility distribution π that induces the possibility and necessity measures of Equations 5 and 6. Then, for all φ such that K |= φ, max</p><formula xml:id="formula_14">T :φ∈T Val(T ) = max T ′ :¬φ∈T ′ Comp(T ′ ).<label>(7)</label></formula><p>Proof. If measures N and Π are induced by the same possibility distribution π, it must be N(φ) = 1 -Π(¬φ); therefore, by Equations 5 and 6, we can write max</p><formula xml:id="formula_15">T :φ∈T Val(T ) = N(φ) = 1 -Π(¬φ) = 1 -min T ′ :¬φ∈T ′ {1 -Comp(T ′ )} = max T ′ :¬φ∈T ′ Comp(T ′ ),</formula><p>which proves the thesis.</p><p>A formula φ such that K ̸ |= φ and K ̸ |= ¬φ poses no problem, because Comp and Val do not interact:</p><formula xml:id="formula_16">Π(φ) = min T :φ∈T {1 -Comp(T )}, Π(¬φ) = min T ′ :¬φ∈T ′ {1 -Comp(T ′ )}, N(φ) = N(¬φ) = 0.</formula><p>We now prove that a formula and its negation cannot belong in the same slice, unless the two functions Val and Comp are identical.</p><p>Proposition 2. Either Val(T ) = Comp(T ) for all slice T , or, for all formula φ and for all slice T , φ ∈ T ⇒ ¬φ ̸ ∈ T .</p><p>Proof. By contradiction: we show that if φ ∈ T and ¬φ ∈ T , a contradiction can be derived. Let φ be a formula belonging in just one slice T . If the slices for which Val or Comp are defined as all distinct, there will always be at least one such formula. If not, the equivalent slices can be merged together so that all slices are distinct. By the assumption, ¬φ ∈ T too. Now, we apply Equations 5 and 6 to compute the possibility and necessity of both φ and ¬φ: without loss of generality, let us assume K |= φ, and therefore, K ̸ |= ¬φ; then</p><formula xml:id="formula_17">Π(φ) = 1, Π(¬φ) = 1 -Comp(T ), N(φ) = Val(T ), N(¬φ) = 0.</formula><p>By the duality property,</p><formula xml:id="formula_18">Val(T ) = N(φ) = 1 -Π(¬φ) = Comp(T ).</formula><p>We can observe that the case in which Val = Comp defeats the very purpose of having the two complementary notions of validity and completeness; if that were the case, it would suffice to call the function into which those two notions would confound themselves "trust", because it would reflect a general notion of reliability of information about a given slice. Therefore, since we are interested in investigating the use of validity and completeness as two distinct notions, in what follows, we will make the assumption that, in general, Val ̸ = Comp. As a consequence, we now know that any acceptable definition of what a slice is will have to satisfy the postulate that a formula and its negation cannot belong in the same slice: formally, for every slice T and formula φ, φ ∈ T ⇒ ¬φ ̸ ∈ T . For instance, a slice might be defined as the set of (ground) formulas that are satisfied by a formula with free variables (i.e., a query).</p><p>With this notion of slice (i.e., such that if a formula belongs to a slice, then the negation of that formula does not belong in the slice), we are able to prove possibilistic generalizations of results obtained by <ref type="bibr" target="#b5">(Demolombe, 1999)</ref> in a KD doxastic logic.</p><p>First of all, the fact that a formula and its negation cannot belong to the same slice motivates the definition of the dual of a slice. Definition 5. Let T be a slice. The dual of T , denoted ¬T , is the slice such that φ ∈ T iff ¬φ ∈ ¬T .</p><p>The dual of a slice is thus a sort of complement, but not in the set-theoretic sense, because there may exist a formula ψ such that ψ ̸ ∈ T and ψ ̸ ∈ ¬T ; therefore, in general, ¬T ̸ = T . A straightforward consequence of Definition 5 is that ¬(¬T ) = T .</p><p>The intuition behind the next proposition is that if the knowledge base is consistent and if information is complete concerning both T and ¬T , then, for each formula φ in T or in ¬T , either the agent believes φ or it believes ¬φ.  </p><formula xml:id="formula_19">N(φ) = 1 -Π(¬φ) ≥ Comp(¬T ); N(¬φ) = 1 -Π(φ) ≥ Comp(T ); hence, max{N(φ), N(¬φ)} ≥ ≥ max{Comp(¬T ), Comp(T )} ≥ min{Comp(T ), Comp(¬T )}.</formula><formula xml:id="formula_20">T ′ :φ∈T ′ Val(T ′ ) ≤ Val(T ),</formula><p>which, together with Equation <ref type="formula">9</ref>, yields the thesis.</p><p>No other case being possible, this concludes the proof.</p><p>It has been proven <ref type="bibr" target="#b5">(Demolombe, 1999)</ref> that, for a consistent base K, if K is complete about ¬T (the complement of slice T ), then K is valid about slice T ; the following an extension of that result to the gradual case. Proposition 5. If K is consistent, for all slice T , Comp(¬T ) ≤ Val(T ). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Complexity of Reasoning</head><p>The results that have been derived above show that one can "simulate", as it were, a possibilistic belief base by means of a crisp base K together with metadata about the validity and completeness of K with respect to a number of "slices" (i.e., sets of formulas). It is not important to know a least-commitment possibility distribution that induces the possibility and necessity measures of Equations 5 and 6 or to represent one of its corresponding possibilistic bases B explicitly, since K, together with its associated metadata Val and Comp, is sufficient to compute any possibilistic inference using any available classical reasoner, as demonstrated by the algorithm shown in <ref type="bibr">Figure 1, adapted from (da Costa Pereira et al., 2017)</ref>.</p><p>Require: K ⊂ L: a consistent KB; φ ∈ L: a formula; Ensure: N(φ).</p><p>1: α ← 0 2: if K |= φ then end for 14: end if 15: return α. Property 2. The cost of Algorithm 1, is at most ∥S K ∥ + 2 classical inferences, where ∥S K ∥ is the number of slices defined for K.</p><p>Proof. Algorithm 1 needs first of all to execute at most two classical inferences: the one in Line 2 and, in case K ̸ |= φ, the one in Line 8. Then, checking whether a formula belongs in a topic costs at most one classical inference and it has to be done for all the slices defined for K.</p><p>Notice that, according to this result, while the cost of a possibilistic inference is higher then the cost of a classical inference, it is so only by a factor which depends on the number of slices defined on the KB. It is to be expected that this number will, in general, be much smaller than the number of facts contained in the KB. In other words, the overall complexity of possibilistic inference will be in the same class as classical inference.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">DISCUSSION AND CONCLUSION</head><p>We have shown that a classical knowledge base plus metadata information on the (gradual) validity and completeness of its "slices" enables one to represent a possibilistic belief base and perform possibilistic inferences by using a classical reasoner at a cost which, albeit larger than the classical counterpart by a multiplicative factor proportional to the number of slices, lies in the same complexity class. All of our results are valid for the general case of a decidable fragment of first-order logic and thus they can be readily transferred to state-of-the-art and popular knowledge representation languages, like Datalog and RDF + OWL and their reasoners. This also means that our suggestion to use gradual metadata about validity and completeness may be applied to representing and reasoning with possibilistic uncertainty on top of the standard infrastructure of the semantic Web, without requiring any ad hoc extension and at a reasonable cost. In that setting, one way of implementing the notion of a slice might be through RDF named graphs.</p><p>Future work includes demonstrating how our proposal can be deployed on the semantic Web infrastructure to represent and reason about uncertain knowledge with a proof-of-concept implementation.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>Assuming the usual definition of satisfaction (given an interpretation I ∈ Ω and a formula φ ∈ L, I |= φ if and only if φ evaluates to true in I ), we define the notion of entailment as follows: K |= φ if and only if, for every interpretation I ∈ Ω, I |= K implies I |= φ.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Proposition 3 .</head><label>3</label><figDesc>If K is consistent, for all slice T , min{Comp(T ), Comp(¬T )} ≤ min φ∈T max{N(φ), N(¬φ)}. Proof. We prove this proposition by showing that, for all formula φ ∈ T , min{Comp(T ), Comp(¬T )} ≤ max{N(φ), N(¬φ)}, from which the thesis follows. Given a formula φ ∈ T , there are just three mutually exclusive cases: Case I. K |= φ and, therefore, by the consistency of K, K ̸ |= ¬φ; we thus have, by Def. 4, N(φ) = 1 -Π(¬φ) ≥ Comp(¬T ); hence, max{N(φ), N(¬φ)} ≥ ≥ N(φ) ≥ Comp(¬T ) ≥ min{Comp(T ), Comp(¬T )}. Case II. K ̸ |= φ and K ̸ |= ¬φ; we thus have, by Def. 4,</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>Case III. K |= ¬φ and, therefore, by the consistency of K, K ̸ |= φ; we thus have, by Def. 4,N(¬φ) = 1 -Π(φ) ≥ Comp(T ); hence, max{N(φ), N(¬φ)} ≥ ≥ N(¬φ) ≥ Comp(T ) ≥ min{Comp(T ), Comp(¬T )}.Since the three above cases are exhaustive for every formula φ ∈ T , this concludes the proof. Proposition 4. If π is the least commitment possibility distribution such that Equations 5 and 6 hold, for all slice T , Val(T ) = min φ∈T :K|=φ N(φ). (8) Proof. By Def. 3, Val(T ) ≤ N(φ) for all φ ∈ T such that K |= φ; therefore, we can write Val(T ) ≤ min observe that the set of slices {T ′ : φ ∈ T ′ } always includes T as one of its elements, because φ ∈ T ; therefore, max T ′ :φ∈T ′ Val(T ′ ) ≥ Val(T ); furthermore, • either T is a top-level slice and, by Postulate P3, there exists a formula φ * ∈ T that does not belong to any other slice, in which case max T ′ :φ * ∈T ′ Val(T ′ ) = max{Val(T )} = Val(T ), whence we can conclude that min φ∈T :K|=φ max T ′ :φ∈T ′ Val(T ′ ) = Val(T ), which is the thesis; • or there exists another slice T such that T ⊂ T , for which, by Equation 3, Val( T ) ≤ Val(T ), which leads us to conclude that min φ∈T :K|=φ max</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>Proof. By Def. 4, Comp(¬T ) ≤ 1 -Π(¬ψ) = N(ψ), for all ¬ψ ∈ ¬T (and, therefore, ψ ∈ T ) such that K ̸ |= ¬ψ; let β = min ψ∈T :K̸ |=¬ψ N(ψ); then we can write Comp(¬T ) ≤ β. Clearly, β ≤ min φ∈T :K|=φ N(φ), because {φ ∈ T : K |= φ} ⊆ {ψ ∈ T : K ̸ |= ¬ψ}, since K |= φ ⇒ K ̸ |= ¬φ. Therefore, by Proposition 4, we have Comp(¬T ) ≤ β ≤ min φ∈T :K|=φ N(φ) = Val(T ), which proves the thesis.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: An algorithm that "simulates" a possibilistic inference from B using K, Val, and Comp.Property 1. Algorithm 1 is correct (i.e., it computes N(φ)).Proof. If K |= φ, Equation 6 is applied; otherwise, Equation 5 together with duality: N(φ) = 1 -Π(¬φ).</figDesc></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>ACKNOWLEDGEMENTS</head><p>This work has been partially supported by the <rs type="funder">French government</rs>, through the <rs type="programName">3IA Côte d'Azur "Investments in the Future</rs>" project managed by the <rs type="funder">National Research Agency (ANR)</rs> with the reference number <rs type="grantNumber">ANR-19-P3IA-0002</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_4CH8HTp">
					<orgName type="program" subtype="full">3IA Côte d&apos;Azur &quot;Investments in the Future</orgName>
				</org>
				<org type="funding" xml:id="_WDbqwFW">
					<idno type="grant-number">ANR-19-P3IA-0002</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Reasoning from incomplete knowledge</title>
		<author>
			<persName><forename type="first">A</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">H</forename><surname>Warnock</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Aiello</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">L</forename><surname>Miller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Representation and Understanding</title>
		<editor>
			<persName><forename type="first">D</forename><forename type="middle">G</forename><surname>Bobrow</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Collins</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="1975">1975</date>
			<biblScope unit="page" from="383" to="415" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Morgan</forename><surname>Kaufmann</surname></persName>
		</author>
		<imprint>
			<pubPlace>San Diego</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Handling topical metadata regarding the validity and completeness of multiple-source information: A possibilistic approach</title>
		<author>
			<persName><forename type="first">C</forename><surname>Da Costa Pereira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Dubois</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Prade</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">G B</forename><surname>Tettamanzi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SUM</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<meeting><address><addrLine>Berlin</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">10564</biblScope>
			<biblScope unit="page" from="363" to="376" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Completeness statements about RDF data sources and their use for query answering</title>
		<author>
			<persName><forename type="first">F</forename><surname>Darari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Nutt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Pirrò</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Razniewski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Semantic Web -ISWC 2013 -12th International Semantic Web Conference</title>
		<meeting><address><addrLine>Sydney, NSW, Australia; Berlin</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2013-10-21">2013. October 21-25, 2013</date>
			<biblScope unit="page" from="66" to="83" />
		</imprint>
	</monogr>
	<note>Proceedings, Part I</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Answering queries about validity and completeness of data: From modal logic to relational algebra</title>
		<author>
			<persName><forename type="first">R</forename><surname>Demolombe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Writings on Computer Science)</title>
		<editor>
			<persName><forename type="first">Datalogiske</forename><surname>Skrifter</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="1996">1996</date>
			<biblScope unit="volume">62</biblScope>
			<biblScope unit="page" from="265" to="276" />
		</imprint>
		<respStmt>
			<orgName>Roskilde. Roskilde University</orgName>
		</respStmt>
	</monogr>
	<note>FQAS</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Database validity and completeness: Another approach and its formalisation in modal logic</title>
		<author>
			<persName><forename type="first">R</forename><surname>Demolombe</surname></persName>
		</author>
		<ptr target="CEUR-WS.org" />
	</analytic>
	<monogr>
		<title level="m">KRDB</title>
		<title level="s">CEUR Workshop Proceedings</title>
		<meeting><address><addrLine>Aachen</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="11" to="13" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">From data fusion to knowledge fusion</title>
		<author>
			<persName><forename type="first">X</forename><forename type="middle">L</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Gabrilovich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Heitz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Horn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. VLDB Endow</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="881" to="892" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Possibilistic logic</title>
		<author>
			<persName><forename type="first">D</forename><surname>Dubois</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Prade</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Handbook of logic in artificial intelligence and logic programming (vol. 3): nonmonotonic reasoning and uncertain reasoning</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Oxford University Press</publisher>
			<date type="published" when="1994">1994</date>
			<biblScope unit="page" from="439" to="513" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Possibility Theory-An Approach to Computerized Processing of Uncertainty</title>
		<author>
			<persName><forename type="first">D</forename><surname>Dubois</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Prade</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1988">1988</date>
			<publisher>Plenum Press</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Valid or complete information in databases -A possibility theory-based analysis</title>
		<author>
			<persName><forename type="first">D</forename><surname>Dubois</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Prade</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">DEXA</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<meeting><address><addrLine>Berlin</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1997">1997</date>
			<biblScope unit="volume">1308</biblScope>
			<biblScope unit="page" from="603" to="612" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Data cube: A relational aggregation operator generalizing group-by, cross-tab, and sub totals</title>
		<author>
			<persName><forename type="first">J</forename><surname>Gray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Chaudhuri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bosworth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Layman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Reichart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Venkatrao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Pellow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Pirahesh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Data Min. Knowl. Discov</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="29" to="53" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Possibilistic logic: complexity and algorithms</title>
		<author>
			<persName><forename type="first">J</forename><surname>Lang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Handbook of Defeasible Reasoning and Uncertainty Management Systems</title>
		<editor>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Gabbay</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Ph</forename><surname>Smets</surname></persName>
		</editor>
		<meeting><address><addrLine>Dordrecht</addrLine></address></meeting>
		<imprint>
			<publisher>Kluwer Acad. Publ</publisher>
			<date type="published" when="2001">2001</date>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="179" to="220" />
		</imprint>
	</monogr>
	<note>Algorithms for Uncertainty and Defeasible Reasoning</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Incompleteness in knowledge bases</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">J</forename><surname>Levesque</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIGART Bull</title>
		<imprint>
			<biblScope unit="volume">74</biblScope>
			<biblScope unit="page" from="150" to="152" />
			<date type="published" when="1980">1980</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">The logic of incomplete knowledge bases</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">J</forename><surname>Levesque</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">On Conceptual Modelling</title>
		<meeting><address><addrLine>Intervale; New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1982">1982</date>
			<biblScope unit="page" from="165" to="189" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Integrity = validity + completeness</title>
		<author>
			<persName><forename type="first">A</forename><surname>Motro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Database Syst</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="480" to="502" />
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">But what do we actually know?</title>
		<author>
			<persName><forename type="first">S</forename><surname>Razniewski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">M</forename><surname>Suchanek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Nutt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AKBC@NAACL-HLT</title>
		<meeting><address><addrLine>Stroudsburg, PA</addrLine></address></meeting>
		<imprint>
			<publisher>The Association for Computer Linguistics</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="40" to="44" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Assessing confidence of knowledge base content with an experimental study in entity resolution</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">L</forename><surname>Wick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kobren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mccallum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 workshop on Automated knowledge base construction, AKBC@CIKM 13</title>
		<meeting>the 2013 workshop on Automated knowledge base construction, AKBC@CIKM 13<address><addrLine>San Francisco, California, USA; New York</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2013-10-27">2013. October 27-28, 2013</date>
			<biblScope unit="page" from="13" to="18" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Fuzzy sets</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">A</forename><surname>Zadeh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information and Control</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="338" to="353" />
			<date type="published" when="1965">1965</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
