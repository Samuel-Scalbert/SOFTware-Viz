<TEI xmlns="http://www.tei-c.org/ns/1.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xml:space="preserve" xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A Distributed Multi-Sensor Machine Learning Approach to Earthquake Early Warning</title>
			</titleStmt>
			<publicationStmt>
				<publisher />
				<availability status="unknown"><licence /></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Kevin</forename><surname>Fauvel</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Univ Rennes</orgName>
								<orgName type="institution" key="instit2">Inria</orgName>
								<orgName type="institution" key="instit3">CNRS</orgName>
								<orgName type="institution" key="instit4">IRISA</orgName>
								<address>
									<settlement>Rennes</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Daniel</forename><surname>Balouek-Thomert</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Rutgers Discovery Informatics Institute</orgName>
								<orgName type="institution">Rutgers University</orgName>
								<address>
									<region>New Jersey</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Diego</forename><surname>Melgar</surname></persName>
							<email>dmelgarm@uoregon.edu</email>
							<affiliation key="aff2">
								<orgName type="department">Department of Earth Sciences</orgName>
								<orgName type="institution">University of Oregon</orgName>
								<address>
									<settlement>Oregon</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Pedro</forename><surname>Silva</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Univ Rennes</orgName>
								<orgName type="institution" key="instit2">Inria</orgName>
								<orgName type="institution" key="instit3">CNRS</orgName>
								<orgName type="institution" key="instit4">IRISA</orgName>
								<address>
									<settlement>Rennes</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Anthony</forename><surname>Simonet</surname></persName>
							<email>anthony.simonet@rutgers.edu</email>
							<affiliation key="aff1">
								<orgName type="department">Rutgers Discovery Informatics Institute</orgName>
								<orgName type="institution">Rutgers University</orgName>
								<address>
									<region>New Jersey</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Gabriel</forename><surname>Antoniu</surname></persName>
							<email>gabriel.antoniu@inria.fr</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Univ Rennes</orgName>
								<orgName type="institution" key="instit2">Inria</orgName>
								<orgName type="institution" key="instit3">CNRS</orgName>
								<orgName type="institution" key="instit4">IRISA</orgName>
								<address>
									<settlement>Rennes</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Alexandru</forename><surname>Costan</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Univ Rennes</orgName>
								<orgName type="institution" key="instit2">Inria</orgName>
								<orgName type="institution" key="instit3">CNRS</orgName>
								<orgName type="institution" key="instit4">IRISA</orgName>
								<address>
									<settlement>Rennes</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Véronique</forename><surname>Masson</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Univ Rennes</orgName>
								<orgName type="institution" key="instit2">Inria</orgName>
								<orgName type="institution" key="instit3">CNRS</orgName>
								<orgName type="institution" key="instit4">IRISA</orgName>
								<address>
									<settlement>Rennes</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Manish</forename><surname>Parashar</surname></persName>
							<email>parashar@rutgers.edu</email>
							<affiliation key="aff1">
								<orgName type="department">Rutgers Discovery Informatics Institute</orgName>
								<orgName type="institution">Rutgers University</orgName>
								<address>
									<region>New Jersey</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Ivan</forename><surname>Rodero</surname></persName>
							<email>irodero@rutgers.edu</email>
							<affiliation key="aff1">
								<orgName type="department">Rutgers Discovery Informatics Institute</orgName>
								<orgName type="institution">Rutgers University</orgName>
								<address>
									<region>New Jersey</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Alexandre</forename><surname>Termier</surname></persName>
							<email>alexandre.termier@irisa.fr</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Univ Rennes</orgName>
								<orgName type="institution" key="instit2">Inria</orgName>
								<orgName type="institution" key="instit3">CNRS</orgName>
								<orgName type="institution" key="instit4">IRISA</orgName>
								<address>
									<settlement>Rennes</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">A Distributed Multi-Sensor Machine Learning Approach to Earthquake Early Warning</title>
					</analytic>
					<monogr>
						<imprint>
							<date />
						</imprint>
					</monogr>
					<idno type="MD5">5E3A0CDFBA6B2F078CB1DCFA895BDC27</idno>
					<idno type="DOI">10.1609/aaai.v34i01.5376</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-04-12T14:49+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid" />
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div><p>Our research aims to improve the accuracy of Earthquake Early Warning (EEW) systems by means of machine learning. EEW systems are designed to detect and characterize medium and large earthquakes before their damaging effects reach a certain location. Traditional EEW methods based on seismometers fail to accurately identify large earthquakes due to their sensitivity to the ground motion velocity. The recently introduced high-precision GPS stations, on the other hand, are ineffective to identify medium earthquakes due to its propensity to produce noisy data. In addition, GPS stations and seismometers may be deployed in large numbers across different locations and may produce a significant volume of data consequently, affecting the response time and the robustness of EEW systems. In practice, EEW can be seen as a typical classification problem in the machine learning field: multi-sensor data are given in input, and earthquake severity is the classification result. In this paper, we introduce the Distributed Multi-Sensor Earthquake Early Warning (<software>DMSEEW</software>) system, a novel machine learning-based approach that combines data from both types of sensors (GPS stations and seismometers) to detect medium and large earthquakes. <software ContextAttributes="used">DMSEEW</software> is based on a new stacking ensemble method which has been evaluated on a realworld dataset validated with geoscientists. The system builds on a geographically distributed infrastructure, ensuring an efficient computation in terms of response time and robustness to partial infrastructure failures. Our experiments show that <software ContextAttributes="used">DMSEEW</software> is more accurate than the traditional seismometeronly approach and the combined-sensors (GPS and seismometers) approach that adopts the rule of relative strength.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div><head n="1">Introduction</head><p>Earthquakes cause substantial loss of life and damage to the built environment across areas spanning hundreds of kilometers from their origins. These large ground motions often lead to hazards such as tsunamis, fires and landslides. To mitigate the disastrous effects, a number of Earthquake Early Warning (EEW) systems have been built around the world <ref type="bibr" target="#b0">(Allen and Melgar 2019)</ref>. These critical systems, operating 24/7, are expected to automatically detect and characterize earthquakes as they happen, and to deliver alerts before the ground motion actually reaches sensitive areas so that protective measures could be taken.</p><p>A recent review by <ref type="bibr" target="#b0">(Allen and Melgar 2019)</ref> identified the detection of the whole spectrum of earthquakes with damaging potential and particularly large earthquakes as an outstanding problem in the field of EEW. An EEW system needs to be able to detect both medium (5 ≤ magnitude &lt; 6, Richter scale) and large earthquakes (6 ≤ magnitude, Richter scale). Depending on the distance from the origin of the earthquake, both of these can cause serious damages. Seismometers, which have long been the bulwark of seismology to detect earthquakes, have a difficulty to detect and characterize large earthquakes <ref type="bibr" target="#b12">(Melgar et al. 2013)</ref> due to a well-known saturation issue caused by their sensitivity to ground motion velocity. As a result, earthquakes over magnitude 7.5 tend to be underestimated. A promising solution to this issue <ref type="bibr" target="#b13">(Melgar et al. 2015)</ref> emerged with novel high-precision Global Positioning System (GPS) sensors, with their millimeter to centimeter accuracy when measuring high ground motion velocity. However, GPS are unable to characterize medium earthquakes, as they are prone to containing significant signals from a variety of noise sources, mostly of atmospheric origin. Consequently, multisensor solutions (leveraging both GPS and seismometers) appear as a promising approach. As EEW can be assimilated as a classification problem, where the input is sensor data and the ouput is a class (normal activity/medium earthquake/large earthquake); recent machine learning approaches designed to combine large volumes of data from multiple data sources can be applied.</p><p>Integrating and processing high-frequency data streams from multiple sensors scattered over a large territory in a timely manner requires high-performance computing techniques and equipments. Thus, a machine learning earthquake detection solution has to be designed jointly with experts in distributed computing and cyberinfrastructure to enable real-time alerts. Because of the large number of sensors and their high sampling rate, a traditional centralized approach which transfers all data to a single point may be impractical. We therefore design a distributed machine learning-based approach.</p><p>In this paper, we use machine learning methods to address the most urgent challenges faced by EEW systems, i.e. integrating multiple data sources in real-time to cover the whole spectrum of potentially damaging earthquakes (medium and large). Our solution relies on two complementary types of sensors (GPS stations and seismometers). We introduce a new machine learning technique specifically tailored to allow efficient computation on large-scale distributed cyberinfrastructures.</p><p>The contributions of this paper are the following:</p><p>• We propose a new EEW approach to characterize the whole spectrum of earthquakes with damaging potential (both medium and large) using a real-world dataset collected and validated with geoscientists combining two complementary data sources;</p><p>• We present <software>DMSEEW</software> (Distributed Multi-Sensor Earthquake Early Warning), a new stacking ensemble method jointly designed with cyberinfrastructure experts, which enables real-time earthquake detection and robustness to partial infrastructure failures;</p><p>• We show that <software>DMSEEW</software> is more accurate than both the seismometer-only baseline approach, the combined sensors (GPS and seismometers) baseline approach that adopts the rule of relative strength and detects all large earthquakes with a precision of 100%.</p></div>
<div><head n="2">Background and Related Work</head><p>Before discussing in detail our approach, it is necessary to introduce some key concepts and to understand how our strategy fits in the state-of-the-art literature on EEW systems.</p></div>
<div><head n="2.1">Earthquake Early Warning</head><p>An earthquake is the shaking of the surface of the Earth caused by seismic waves. Among these seismic waves, two types stand out: Primary waves (P-waves) and Secondary waves (S-waves). Both waves have the same origin -most commonly an abrupt movement of tectonic plates. However, P-waves travel through Earth's crust around 1.7 times faster than S-waves which propagate through Earth's interior. In addition, only S-waves are responsible for the severe damages. P-waves cause soft shaking due to their longitudinal shape (they move sideways), whereas S-waves are transverse waves (they move up and down). Therefore, an Earthquake Early Warning (EEW) system, which aims to provide an alert before the damaging effects reach sensitive areas, relies on the detection of the P-wave before the S-wave arrives. This gives communities, organizations and governments a time window of seconds to minutes to take protective actions.</p><p>Traditionally, inertial seismometers are used to detect primary waves. The inertial mass is designed to remain stationary following sudden movements while the frame and drum move with the ground to record waves. However, during large earthquakes, ground motion velocity causes the inertial mass to be displaced above the allowed span. This effect is called saturation. As a result, earthquakes over magnitude 7.5 (Richter scale) tend to be underestimated. On the other hand, GPS satellites are not affected by earthquakes, so a GPS receiver station on Earth can be used to assess strong ground motion based on the station displacement. However, GPS is sensitive to a variety of noise sources, mostly of atmospheric origin, and is unable to characterize moderate earthquakes. Both sensors produce data in the form of 3D time series indicating the direction of a ground motion (eastwest, north-south and up-down) at a frequency of around 20Hz.</p><p>P-waves follow a propagation model (IASP91 <ref type="bibr" target="#b10">(Kennet 1991</ref>)) which we use for labeling the time series (sequences of measurements) corresponding to an earthquake. Based on the distance below Earth's surface where each earthquake happened, we estimate the P-wave arrival time on each sensor (seismometers and GPS stations) according to its distance to the epicenter with the propagation model.</p></div>
<div><head n="2.2">Multivariate Time Series Classification</head><p>A time series is multivariate when a sequence of measurements from multiple variables are present. Multivariate Time Series (MTS) collected from GPS stations (3 dimensions: east-west, north-south and up-down) and seismometers (3 dimensions: east-west, north-south and up-down) are labeled in 3 classes according to the the potential damage of the ground motion: normal activity, medium earthquakes, large earthquakes. Therefore, earthquake detection can be formulated as a MTS classification problem.</p><p>MTS classifiers are composed of 3 categories: similaritybased, feature-based and deep learning methods.</p><p>Similarity-based methods make use of similarity measures (e.g. Euclidean distance) to compare two MTS. Dynamic Time Warping (DTW) has been shown to be the best similarity measure to use along k-Nearest Neighbors (k-NN) <ref type="bibr" target="#b19">(Seto, Zhang, and Zhou 2015)</ref> and is called kNN-DTW. There are two versions of kNN-DTW for MTS: dependent (DTW D ) and independent (DTW I ). Neither dominates over the other <ref type="bibr" target="#b21">(Shokoohi-Yekta et al. 2017)</ref>. DTW I measures the cumulative distances of all dimensions independently measured under DTW. DTW D uses a similar calculation with single-dimensional time series; it considers the squared Euclidean cumulated distance over the multiple dimensions.</p><p>Feature-based methods include shapelets and bag-ofwords (BoW) models. Shapelets models use subsequences (shapelets) to transform the original time series into a lowerdimensional space that is easier to classify. gRSF (Karlsson, Papapetrou, and Boström 2016) and UFS <ref type="bibr" target="#b23">(Wistuba, Grabocka, and Schmidt-Thieme 2015)</ref> are the current stateof-the-art shapelets models in MTS classification. They relax the major limiting factor of the time to find discriminative subsequences in multiple dimensions (shapelet discovery) by randomly selecting shapelets. gRSF creates decision trees over randomly extracted shapelets and shows better performance than UFS on average (14 MTS datasets) <ref type="bibr" target="#b9">(Karlsson, Papapetrou, and Boström 2016)</ref>. On the other hand, BoW models (LPS <ref type="bibr" target="#b2">(Baydogan and Runger 2016)</ref>, mv-ARF <ref type="bibr" target="#b22">(Tuncel and Baydogan 2018)</ref>, SMTS <ref type="bibr" target="#b1">(Baydogan and Runger 2014)</ref> and <software ContextAttributes="used">WEASEL</software>+<software ContextAttributes="used">MUSE</software> <ref type="bibr" target="#b18">(Schäfer and Leser 2017)</ref>) convert time series into a bag of discrete words, and use a histogram of words representation to perform the classification. <software ContextAttributes="used">WEASEL</software>+<software ContextAttributes="used">MUSE</software> shows the best results com-pared to gRSF, LPS, mv-ARF and SMTS on average (20 MTS datasets) <ref type="bibr" target="#b18">(Schäfer and Leser 2017)</ref>. <software ContextAttributes="used">WEASEL</software>+<software ContextAttributes="used">MUSE</software> generates a BoW representation by applying various sliding windows with different sizes on each discretized dimension (Symbolic Fourier Approximation) to capture features (unigrams, bigrams, dimension identification).</p><p>Finally, deep learning methods use Long-Short Term Memory (LSTM) and/or Convolutional Neural Networks (CNN) to extract latent features. The current state-of-theart model (MLSTM-FCN) is proposed in <ref type="bibr" target="#b6">(Fazle, Majumdar, and Harford 2018)</ref> and consists of a LSTM layer and a stacked CNN layer along with Squeeze-and-Excitation blocks to generate latent features. MLSTM-FCN is shown to be better than <software ContextAttributes="used">WEASEL</software>+<software ContextAttributes="used">MUSE</software> on large datasets on average (relative to the 20 MTS datasets tested).</p><p>Therefore, in this work we choose to experiment with the best-in-class for each category (similaritybased, feature-based and deep learning): DTW D , DTW I , <software>WEASEL</software>+<software ContextAttributes="used">MUSE</software> and MLSTM-FCN classifiers.</p></div>
<div><head n="2.3">Targeting a Distributed Cyberinfrastructure</head><p>A cyberinfrastructure is the set of logical and physical computational systems onto which a scientific application is deployed. In the context of EEW, a cyberinfrastructure has to support the processing of large amounts of data produced by geographically distributed seismic sensors, such as GPS stations and seismometers, in real-time.</p><p>Current approaches to EEW in the literature make use of centralized data processing strategies: all sensors send their data, through a network, to a data center where processing will take place <ref type="bibr" target="#b7">(Fischer et al. 2012)</ref>. This strategy implicitly depends on cyberinfrastructures supporting almost insignificant network latency and very high bandwidth, often provided by costly fiber networks. Furthermore a lot of trust is placed in the reliability of the network and telemetry paths <ref type="bibr" target="#b0">(Allen and Melgar 2019</ref>). In the case of large earthquakes, power failures and wiring disconnections can frequently lead to regional shutdowns, as happened after the magnitude-9 earthquake in Japan in 2011 <ref type="bibr" target="#b8">(Hoshiba and Ozaki 2012)</ref>.</p><p>In this work, we target a distributed cyberinfrastructure for executing the proposed EEW system, meaning that data processing tasks can be performed in different parts of the infrastructure and at different locations. In particular, we favor processing part of the data at the edge of the network, i.e. as close as possible to the sources of data, in order to reduce the amount of data transferred to the main data center <ref type="bibr" target="#b24">(Yang et al. 2010</ref>).</p></div>
<div><head n="2.4">EEW Machine Learning Solutions</head><p>Machine learning in seismology is still a developing field. There are a couple of studies <ref type="bibr" target="#b25">(Yoon et al. 2015;</ref><ref type="bibr" target="#b11">Li et al. 2018;</ref><ref type="bibr" target="#b15">Perol, Gharbi, and Denolle 2018)</ref> using machine learning methods for earthquake characterization based on P-wave detection (EEW). However, none of them used a combination of GPS and seismometers data so the whole spectrum of earthquakes with damaging potential is not appropriately covered. Additionally, none of them used a distributed approach.</p><p>The three studies <ref type="bibr" target="#b25">(Yoon et al. 2015;</ref><ref type="bibr" target="#b11">Li et al. 2018;</ref><ref type="bibr" target="#b15">Perol, Gharbi, and</ref> Denolle 2018) adopted a binary classification approach (earthquakes vs. noise) with no distinction between medium and large earthquakes. Moreover, the detection is only based on seismometers data, so the saturation issue on large earthquakes is present. Two of these studies <ref type="bibr" target="#b15">(Perol, Gharbi, and Denolle 2018;</ref><ref type="bibr" target="#b25">Yoon et al. 2015)</ref> limit their scope to medium earthquakes. <ref type="bibr" target="#b25">Yoon et al. (2015)</ref> proposed a waveform similarity-based method optimized by locality-sensitive hashing search using seismometers data from California. It presented a precision of 88.1% and a recall of 87.5%. <ref type="bibr" target="#b11">Li et al. (2018)</ref> developed a generative adversarial network with a random forest on seismometers data from Southern California and Japan. It obtained an accuracy of 99.2%. Perol, Gharbi, and Denolle (2018) trained a convolutional neural network using seismometers data from Oklahoma and showed a precision of 94.8% and a recall of 100%.</p><p>Lastly, these studies use a centralized data processing strategy and implicitly assume that data arrive almost instantly at the processing cluster. This assumption implies an insignificant latency and an overall network reliability which is unfeasible in real-life scenarios having high latency and/or low bandwidth networks.</p><p>Consequently, a distributed EEW machine learning-based solution that can be generalized to the whole spectrum of earthquakes with damaging potential is necessary.</p></div>
<div><head n="3">A Distributed Machine Learning Approach to Earthquake Early Warning</head><p>In this section, we present the Distributed Multi-Sensor Earthquake Early Warning algorithm (<software>DMSEEW</software>), a new two-step stacking ensemble method for earthquake detection. A stacking ensemble is a method which takes the predictions of sub-models as inputs and then attempts to learn how to best combine the input predictions to make a better output prediction. <software ContextAttributes="used">DMSEEW</software> takes sensor-level class predictions (normal activity, medium earthquake or large earthquake) based on the data gathered by each individual sensor (GPS stations and seismometers). It then aggregates those sensor-level class predictions using a bag-of-words representation in order to calculate a final prediction for the earthquake category. The rest of this section explains the algorithm steps and introduces the cyberinfrastructure onto which <software ContextAttributes="used">DMSEEW</software> would be deployed in a real-life scenario.</p></div>
<div><head n="3.1">Algorithm</head><p>Step 1 -Predicting the MTS Category at the Sensor-Level: We have two types of sensors -GPS stations and seismometers, and we train one MTS classifier per sensor type. The classifiers are trained using a dataset composed of time series of 3 dimensions (east-west, north-south and up-down) and fixed time length (60 seconds, defined in Section 4.1). We illustrate this first step of our approach in the upper part of Figure <ref type="figure" target="#fig_0">1</ref>.</p><p>In order to predict the earthquake category at the individual sensor level, we employ the WEASEL+<software ContextAttributes="used">MUSE</software> (Schäfer Step 2 -Detecting Earthquakes by Combining Sensorlevel Predictions: We collect the class predictions from the different sensors (GPS stations and seismometers) and perform a bag-of-words representation. Each sensorpredicted class is considered to be a word and the relative frequency vector of the words from each earthquake is used to classify its category. This frequency vector is normalized by the number of instances (number of MTS per earthquake, i.e. number of sensors) to obtain the relative frequency vector. The last step consists of combining the bag-of-words of GPS stations and seismometers to characterize the whole spectrum of earthquakes with damaging potential. We illustrate this second step of our approach in the lower part of Figure <ref type="figure" target="#fig_0">1</ref>. For example, 80% of seismometers and 100% of GPS stations for event 1 predict that the activity recorded is normal. Finally, we train a classifier on this bag-of-words representation to perform the combined class prediction. As presented in Section 5, 1-nearest neighbor outperforms other classifiers.</p></div>
<div><head n="3.2">Cyberinfrastructure</head><p>We propose a distributed cyberinfrastructure composed of geographically distributed data sources. Its objective is to support the processing of high volumes of data produced by GPS stations or seismometers, meanwhile meeting the realtime requirements of EEW applications. Furthermore, in disaster situations, such as partial network shutdown, this type of architecture allows for the redirection of data produced at sensor-level (i.e. individual sensor predictions) to other processing data centers. Figure <ref type="figure" target="#fig_1">2</ref> provides an overview of the cyberinfrastructure. In summary, the cyberinfrastructure has two main levels: the sensor-level and the central level. The sensor-level is composed of sensing devices (i.e. GPS stations and seismometers) with limited computing capabilities. The central level is composed of well-provisioned computing systems that can accommodate large computing demands (e.g. cloud datacenters). This type of architecture has been the subject of several contributions in the context of Edge computing <ref type="bibr" target="#b20">(Shi et al. 2016;</ref><ref type="bibr" target="#b17">Satyanarayanan 2017)</ref>, an emerging paradigm adapted for Internet of Things (IoT) scenarios. Due to space constraints, we leave an in-depth discussion of cyberinfrastructure in a future work. In this paper, we focus on the distributed algorithm in charge of analyzing the data produced by seismic sensors and on its interaction with those main levels of the infrastructure.</p></div>
<div><head>GPS Stations + Seismometers</head></div>
<div><head>Intermediary</head><p>Distributed execution. The first step of the algorithm is performed on the sensor-level part of the infrastructure. There, a MTS classifier is ran on each individual sensor (GPS stations and seismometers) in order to generate sensorlevel class predictions based on data produced by each sensor. Then, the output of the MTS classifier from each sensor is transferred over the network to the central level part of the cyberinfrastructure. There, the second part of the algorithm is ran, i.e., a machine learning method combines all the class predictions from GPS stations and seismometers to form a final class prediction. It is important to highlight that, in comparison to the traditional centralized EEW cyberinfrastructures, this approach drastically reduces the amount of data over the network since most of data produced by a sensor is not related to an earthquake event and thus can be filtered out. Moreover, a sensor-level prediction is, in fact, an aggregation of data, hence, it also helps reduce on the amount of data sent to central to level data centers.</p></div>
<div><head n="4">Experiments</head><p>In this section, we introduce the methodology and datasets used for evaluating our work, as well as our preprocessing routines and experimental setting. In addition, we render public our real-world dataset collected and validated with geoscientists and we make public reference to the code of our machine learning algorithms used.</p></div>
<div><head n="4.1">Dataset</head><p>We employ a real-world dataset<ref type="foot" target="#foot_0">1</ref>  <ref type="bibr" target="#b5">(Fauvel et al. 2019</ref>) composed of GPS and seismometers data on normal activity/medium earthquakes/large earthquakes collected and validated with geoscientists. There are two main difficulties to construct such a dataset: i) large earthquakes are rare and ii) GPS data is not continuously recorded. The dataset has been built around the most complete GPS/seismometers dataset of large earthquakes (29 earthquakes worldwide) which occurred between 2001 and 2018 <ref type="bibr" target="#b16">(Ruhl et al. 2019</ref>) with the corresponding metadata (time, magnitude, and location). We adopted a differentiated approach between GPS and seismometers data to augment the dataset and present it in the following two paragraphs. MTS length is set to 60 seconds for both GPS and seismometers. This value reflects the relevant time window to distinguish primary waves from noise across geographical regions, as recognized by the geoscience community.</p><p>First, the two main seismometers data repositories worldwide are the American Incorporated Research Institutions for Seismology (IRIS) and the Japanese National Research Institute for Earth science and Disaster Resilience (NIED). Earthquake origins are defined differently between the two repositories, preventing a direct comparison of P-wave arrival time on each seismometer. Therefore, in order to be able to adopt a homogeneous labeling method, we limited our study to the data available from IRIS (14 large earthquakes remaining over 29). Seismometers data corresponding to medium earthquakes are sampled from medium earthquakes occurring in the same region as large earthquakes (-179 ≤ longitude ≤ 25, -62 ≤ latitude ≤ 73). The number of medium earthquakes is calculated by the ratio of medium over large earthquakes during the past 10 years in the region. Then, we keep a ratio above 30% between the number of MTS corresponding to earthquakes (medium + large) and total (earthquakes + normal activity) number of MTS to prevent a class imbalance issue during the training phase. So, we collect two normal activity MTS for each medium earthquake MTS (9 and 7 minutes before each medium earthquake) to respect this ratio. IRIS data (normal activity, medium earthquakes) is collected with the international Federation of Digital Seismograph Networks (FDSN) client available in Python package <software ContextAttributes="used">ObsPy</software><ref type="foot" target="#foot_1">2</ref> . Based on geoscience expertise, the relevant region of seismometers is set to 1,000 kilometers around the earthquake epicenter.</p><p>Second, unlike seismometers data, GPS displacement data is not continuously recorded. Furthermore, GPS data outside of large earthquake periods can be considered as normal activity (noise). Hence, our approach based on GPS sensors characterizes only normal activity and large earthquakes. We collected GPS normal activity data from an archive of real-time GPS positions maintained by the University of Oregon<ref type="foot" target="#foot_2">3</ref> which stores a representative extract of GPS noise. Normal activity MTS are randomly sampled from the archive to match the number of seismometers events (255, normal activity and medium earthquakes) and to keep a ratio above 30% between the number of large earthquakes MTS and normal activity in order to avoid class imbalance issues.</p><p>The number of sensor records available varies between earthquakes according to the location and the magnitude of the earthquake. The full dataset composition is presented in Table <ref type="table" target="#tab_0">1</ref>. </p></div>
<div><head n="4.2">Preprocessing</head><p>First, seismometers data are available as digital signal, which is specific for each sensor. Therefore, we converted each instrument digital signal to its physical signal (acceleration) to obtain comparable seismometers data. Second, we performed standardization (StandardScaler <ref type="bibr" target="#b14">(Pedregosa et al. 2011</ref>)) of the GPS and seismometers data (fitted on train sets and applied on test sets) to harmonize the different scales. Standardization procedure allows us to keep outliers, which are fundamental in P-wave detection, as compared to the normalization procedure. Finally, we perform data aggregation by second (mean) which permits a common time scale between sensors (frequency between sensors can differ) without deteriorating the P-wave signal.</p></div>
<div><head n="4.3">Experimental Setting</head><p>In this section, we present the algorithms evaluated and the methods used to assess them.</p><p>Algorithms We evaluate different algorithms at sensorlevel and central level according to the data type in order to define the two blocks of our machine learning solution (Figure <ref type="figure" target="#fig_0">1</ref>). At sensor-level, we have a multivariate time series classification task. Therefore, as presented in section 2.2 on MTS classification, we compare the following algorithms:</p><p>• DTW D and DTW I : we use the public implementation <ref type="foot" target="#foot_3">4</ref>based on the original paper (Shokoohi-Yekta et al. 2017);</p><p>• <software ContextAttributes="used">WEASEL+MUSE</software>: we use the public implementation<ref type="foot" target="#foot_4">5</ref> with the recommended settings (SFA word lengths l in <ref type="bibr">[2,</ref><ref type="bibr">4,</ref><ref type="bibr">6]</ref>, windows length in [4:60], chi=2, bias=1, p=0.1, c=5 and a solver equals to L2R LR DUAL) (Schäfer and Leser 2017);</p><p>• MLSTM-FCN, we test the public implementation<ref type="foot" target="#foot_5">6</ref> based on the original paper <ref type="bibr" target="#b6">(Fazle, Majumdar, and Harford 2018)</ref>, using the recommended settings (128-256-128 filters, 250 training epochs, a dropout of 0.8 and a batch size of 128);</p><p>At central level, we have a classification task on a bagof-words representation (relative frequency vector) for each earthquake based on individual class predictions of GPS stations and seismometers. We compare the state-of-the art classifiers with the following implementations: K-Nearest Neighbors<ref type="foot" target="#foot_6">7</ref> ; Elastic Net 7 ; Support Vector Machine 7 with a radial basis function kernel due to the lower number of features than the number of samples in our dataset; Random Forest 7 and Extreme Gradient Boosting<ref type="foot" target="#foot_7">8</ref> . Hyperparameters Optimization Firstly, at sensor-level, classifier hyperparameters setting is presented in previous section with the public implementations of the algorithms used. Next, hyperparameters of classifiers at central level are set by <software ContextAttributes="used">hyperopt</software>, a sequential model-based optimization using a tree of Parzen estimators search algorithm <ref type="bibr" target="#b4">(Bergstra, Yamins, and Cox 2013)</ref>. <software ContextAttributes="used">Hyperopt</software> chooses the next hyperparameters decision from the previous choices and a tree-based optimization algorithm. Tree of Parzen estimators meet or exceed grid search and random search performance for hyperparameters setting <ref type="bibr" target="#b3">(Bergstra et al. 2011)</ref>. We use the implementation available in the Python package <software ContextAttributes="used">hyperopt</software> 9 . Optimization is undertaken to maximize accuracy score considering our multiclass study.</p><p>Classification Performance Classifiers are trained (at sensor and central level) with a 3 class labeling (see section 4.1) on seismometers data and a 2 class labeling on GPS data. We performed a stratified k-fold cross-validation which kept the same proportion of earthquakes of different categories for each fold. K is set to 3 considering the number of large earthquakes (14 earthquakes). We present the dataset split in Table <ref type="table" target="#tab_1">2</ref>. Therefore, the results presented corresponds to the 3-fold performance on the test sets. Classifiers are trained to optimize the accuracy score. </p></div>
<div><head n="5">Results and Discussions</head><p>This section first presents the results at sensor-level (DM-SEEW step 1). Then, we evaluate the performance of our combined approach (<software>DMSEEW</software> steps 1 and 2) compared to the traditional seismometers baseline approach and the combined sensors (GPS and seismometers) baseline approach that adopts the rule of relative strength.</p></div>
<div><head n="5.1">Sensor-Level Predictions</head><p>We present the accuracy results of the different MTS classifiers on GPS stations (2,072 MTS, 2 classes) and seismometers (13,265 MTS, 3 classes) in Table <ref type="table" target="#tab_2">3</ref>.  We observe that <software ContextAttributes="used">WEASEL</software>+<software ContextAttributes="used">MUSE</software> outperforms MLSTM-FCN and similarity-based classifiers (DTW D and DTW I ) on both GPS and seismometers data. The difference between <software ContextAttributes="used">WEASEL</software>+<software ContextAttributes="used">MUSE</software> and other classifiers is particularly important on seismometers data. We can infer that the noise reduction performed by the truncated Fourier Transform and discretization of <software ContextAttributes="used">WEASEL</software>+<software ContextAttributes="used">MUSE</software> led to a better exploitation of the P-wave information.</p><p>The detection results obtained from both GPS stations and seismometers data confirm the complementary performance of these sensors. GPS data distinguishes large earthquakes while the detection based on seismometers data performs poorly (F1 score on large earthquakes: GPS 99%, seismometers 28%). In the next section, we present the results of a combined prediction benefiting from the complementary performance of these sensors following the transfer of all sensor-level class predictions to a central computation facility.</p></div>
<div><head n="5.2">Combined Predictions at Central Level</head><p><software>DMSEEW</software> benefits from the complementary performances through the combination of sensor-level class predictions (GPS and seismometers) using a bag-of-words representation, followed by the training of a classifier on this representation. There is no state-of-the-art method covering the whole spectrum of earthquakes with damaging potential (medium and large). In order to evaluate the performance of <software ContextAttributes="used">DMSEEW</software>, we define two baselines at central level.</p><p>The first is the traditional seismometer approach which relies on seismometers data only. We compute the performance of the traditional seismometer approach by calculating the arg max directly on the seismometers bag-of-words representation for each of the 269 events in our dataset. The second baseline corresponds to the combined sensors (GPS and seismometers) baseline approach that adopts the rule of relative strength in order to assess the value added by <software ContextAttributes="used">DMSEEW</software> combining approach. It is defined based on the strengths of each sensor type: if the GPS bag-of-words representation indicates that the event is a large earthquake, a large earthquake is predicted. Else, we calculate the arg max between normal activity and medium earthquake on the seismometers bag-of-words representation. Table <ref type="table" target="#tab_3">4</ref> shows the performance of the two baselines and <software ContextAttributes="used">DMSEEW</software>. The traditional seismometer approach is indicated as "Baseline Seismometer" and the combined rule-based approach as "Baseline Combined". The <software ContextAttributes="used">DMSEEW</software> scores correspond to average results on test sets of the 1-Nearest Neighbors (1NN) trained on the combined bag-of-words representation (GPS and seismometers representations). 1NN outperforms other classifiers (Elastic Net, Support Vector Machine, Random Forest, Extreme Gradient Boosting) on the 3-fold crossvalidation. Our dataset has a class imbalance (normal activity 63%/medium earthquakes 32%/large earthquakes 5%), but it does not affect the detection performance on the least represented class. <software ContextAttributes="used">DMSEEW</software> detects all the large earthquakes (100.0% recall) without false alert (100.0% precision). The 1-NN of <software ContextAttributes="used">DMSEEW</software> is always able to closely match an existing typical distribution of GPS predictions in case of large earthquakes, which allows the correct 1-NN classification.</p><p>It is critical for an EEW system to detect all the large earthquakes with a precision of 100%. The decisions subsequent to a large earthquake alert imply major mitigation measures for the population possibly impacted. We observe in Table <ref type="table" target="#tab_3">4</ref> that <software ContextAttributes="created">DMSEEW</software> outperforms both baselines (accuracy score: 76.9% versus 74.7% and 73.2%). Moreover, <software ContextAttributes="created">DMSEEW</software> outperforms both baselines on medium and large earthquakes detection. Figure <ref type="figure" target="#fig_2">3</ref> shows the precision-recall curves of DM-SEEW versus both baseline on medium and large earthquakes (second and third plots). Firstly, <software ContextAttributes="created">DMSEEW</software> obtains an average F1-score on test sets for medium earthquakes detection of 51.6% versus 45.0% for the baseline seismometer and 46.0% for the baseline combined. The higher F1-score of <software ContextAttributes="created">DMSEEW</software> on medium earthquakes compared to both baselines is driven by higher performances on both precision and recall (precision: 76.7% versus 65.9% baseline seismometer versus 70.7% baseline rule-based, recall: 38.8% versus 34.1% baselines). Lastly, <software ContextAttributes="created">DMSEEW</software> obtains an average F1-score on test sets for large earthquake detection of 100.0% versus 55.2% for the baseline seismometer and 72.7% for the baseline combined. The higher F1-score of <software ContextAttributes="created">DMSEEW</software> on large earthquakes compared to both baselines is also driven by higher performances on both precision and recall (precision: 100.0% versus 53.3% baseline seismometer versus 63.2% baseline rule-based, recall: 100.0% versus 57.1% baseline seismometer versus 85.7% baseline rulebased). These performances confirm the interest of combining GPS stations and seismometers data to cover the whole spectrum of earthquakes with damaging potential (medium and large). In addition, it reveals the benefit of <software ContextAttributes="created">DMSEEW</software> combined approach instead of the combined sensors (GPS and seismometers) baseline approach that adopts the rule of relative strength.</p></div>
<div><head n="6">Conclusion</head><p>The use of machine learning methods in seismology is still in an early phase. One area of development where it demonstrated promising results is earthquake early warning (EEW), i.e. the characterization of an earthquake before it reaches sensitive areas. Current state-of-the-art methods based on seismometers data only demonstrated an applicability limited to medium earthquakes. In contrast, GPSbased methods are only suitable for large earthquake detection.</p><p>We propose <software>DMSEEW</software>, a novel stacking ensemble approach for characterizing the whole spectrum of earthquakes with damaging potential by combining both GPS and seismometer data. Our evaluation on a real-world dataset collected with domain experts demonstrates that the proposed distributed stacking ensemble approach improves the detection of both medium and large earthquakes compared to traditional seismometer only approach and the combined sensors (GPS and seismometers) baseline approach that adopts the rule of relative strength (F1 score: +7% and +6% on medium earthquakes, +45% and +27% on large earthquakes). In addition, <software ContextAttributes="created">DMSEEW</software> detects all large earthquakes with a precision of 100%.</p><p>While existing solutions rely on fully centralized processing of the sensor data, our approach assumes distributed data processing based on a geographically distributed cyberinfrastructure. This design significantly reduces the volume of data transmitted in the network, meets the real-time requirements while increasing reliability of the EEW system. With regards to future work, we plan to simulate different scenarios in an existing EEW execution platform to evaluate <software>DM-SEEW</software> response time and robustness. Then, we plan to work on the evaluation of <software ContextAttributes="created">DMSEEW</software> on the other main seismic network through collaboration with the Japanese National research Institute for Earth science and Disaster resilience (NIED).</p></div>
<div><head n="7">Acknowledgments</head><p>This research is supported by the NSF under grants numbers OAC 1640834, OAC 1835661, OAC 1835692, OCE 1745246 and the French ANR OverFlow project (ANR-15-CE25-0003).</p></div><figure xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Distributed Multi-Sensor Earthquake Early Warning Algorithm (DMSEEW).</figDesc><graphic coords="5,233.81,148.39,237.63,52.08" type="bitmap" /></figure>
<figure xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: High-level architecture and data workflow for the Earthquake Early Warning System.</figDesc></figure>
<figure xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Precision-Recall Curves of DMSEEW.</figDesc></figure>
<figure type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Dataset Composition</figDesc><table><row><cell># 60s MTS</cell><cell>Seismometers (# Events)</cell><cell>GPS (# Events)</cell></row><row><cell>Normal Activity</cell><cell>7,718 (170)</cell><cell>1,424 (255)</cell></row><row><cell>Medium Earthquakes</cell><cell>3,859 (85)</cell><cell>None</cell></row><row><cell>Large Earthquakes</cell><cell>1,688 (14)</cell><cell>648 (14)</cell></row><row><cell>Total</cell><cell>13,265 (269)</cell><cell>2,072 (269)</cell></row></table></figure>
<figure type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Cross-Validation Split</figDesc><table><row><cell># Events</cell><cell>Fold 1</cell><cell>Fold 2</cell><cell>Fold 3</cell><cell>Total</cell></row><row><cell>Seismometers</cell><cell>90</cell><cell>90</cell><cell>89</cell><cell>269</cell></row><row><cell>Normal Activity</cell><cell>56</cell><cell>57</cell><cell>57</cell><cell>170</cell></row><row><cell>Medium Earthquakes</cell><cell>29</cell><cell>28</cell><cell>28</cell><cell>85</cell></row><row><cell>Large Earthquakes</cell><cell>5</cell><cell>5</cell><cell>4</cell><cell>14</cell></row><row><cell>GPS</cell><cell>90</cell><cell>90</cell><cell>89</cell><cell>269</cell></row><row><cell>Normal Activity</cell><cell>85</cell><cell>85</cell><cell>85</cell><cell>255</cell></row><row><cell>Medium Earthquakes</cell><cell>None</cell><cell>None</cell><cell>None</cell><cell>None</cell></row><row><cell>Large Earthquakes</cell><cell>5</cell><cell>5</cell><cell>4</cell><cell>14</cell></row></table></figure>
<figure type="table" xml:id="tab_2"><head>Table 3 :</head><label>3</label><figDesc>Accuracy Score on Test Sets of the MTS Classifiers Trained on GPS or Seismometers Data</figDesc><table><row><cell>Accuracy (%)</cell><cell>DTW D</cell><cell>DTW I</cell><cell>MLSTM -FCN</cell><cell>WEASEL + MUSE</cell></row><row><cell>Seismometers</cell><cell>35.3</cell><cell>35.5</cell><cell>54.6</cell><cell>63.6</cell></row><row><cell>GPS</cell><cell>97.9</cell><cell>97.8</cell><cell>98.9</cell><cell>99.5</cell></row><row><cell cols="3">9 https://github.com/hyperopt/hyperopt</cell><cell /><cell /></row></table></figure>
<figure type="table" xml:id="tab_3"><head>Table 4 :</head><label>4</label><figDesc>Performances on Test Sets of DMSEEW and the Two Baselines. Standard Errors are Presented in Parentheses</figDesc><table><row><cell /><cell>Baseline Seismometer</cell><cell>Baseline Combined</cell><cell>DMSEEW</cell></row><row><cell>Normal Activity</cell><cell /><cell /><cell /></row><row><cell>Precision (%)</cell><cell>76.2 (1.8)</cell><cell>76.6 (1.5)</cell><cell>75.5 (1.8)</cell></row><row><cell>Recall (%)</cell><cell>94.1 (3.2)</cell><cell>94.1 (3.2)</cell><cell>94.1 (3.2)</cell></row><row><cell>F1 (%)</cell><cell>84.2 (0.6)</cell><cell>84.4 (0.7)</cell><cell>83.8 (0.9)</cell></row><row><cell>Medium Earthquakes</cell><cell /><cell /><cell /></row><row><cell>Precision (%)</cell><cell>65.9 (12.2)</cell><cell>70.7 (10.5)</cell><cell>76.7 (9.7)</cell></row><row><cell>Recall (%)</cell><cell>34.1 (11.8)</cell><cell>34.1 (11.8)</cell><cell>38.8 (7.3)</cell></row><row><cell>F1 (%)</cell><cell>45.0 (11.5)</cell><cell>46.0 (12.0)</cell><cell>51.6 (6.1)</cell></row><row><cell>Large Earthquakes</cell><cell /><cell /><cell /></row><row><cell>Precision (%)</cell><cell>53.3 (17.9)</cell><cell>63.2 (16.2)</cell><cell>100.0 (0.0)</cell></row><row><cell>Recall (%)</cell><cell>57.1 (19.2)</cell><cell>85.7 (13.3)</cell><cell>100.0 (0.0)</cell></row><row><cell>F1 (%)</cell><cell>55.2 (11.6)</cell><cell>72.7 (6.1)</cell><cell>100.0 (0.0)</cell></row><row><cell>Total</cell><cell /><cell /><cell /></row><row><cell>Accuracy (%)</cell><cell>73.2 (1.5)</cell><cell>74.7 (1.8)</cell><cell>76.9 (1.6)</cell></row></table></figure>
			<note place="foot" n="1" xml:id="foot_0"><p>https://figshare.com/articles/Earthquake Early Warning Dataset/9758555</p></note>
			<note place="foot" n="2" xml:id="foot_1"><p>https://docs.obspy.org/packages/obspy.clients.fdsn.html</p></note>
			<note place="foot" n="3" xml:id="foot_2"><p>http://tunguska.uoregon.edu/rtgnss/data/cwu/mseed/</p></note>
			<note place="foot" n="4" xml:id="foot_3"><p>https://github.com/DavideNardone/MTSS<software>-Multivariate-Time-Series-Software</software></p></note>
			<note place="foot" n="5" xml:id="foot_4"><p>5 https://github.com/patrickzib/</p></note>
			<note place="foot" n="6" xml:id="foot_5"><p>SFA 6 https://github.com/titu1994/</p></note>
			<note place="foot" n="7" xml:id="foot_6"><p> https://scikit-learn.</p></note>
			<note place="foot" n="8" xml:id="foot_7"><p>org/stable/ 8 https://xgboost.readthedocs.io/en/latest/python/</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Earthquake Early Warning: Advances, Scientific Challenges, and Societal Needs</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Allen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Melgar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annual Review of Earth and Planetary Sciences</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="page" from="361" to="388" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Learning a Symbolic Representation for Multivariate Time Series Classification</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">G</forename><surname>Baydogan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Runger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Data Mining and Knowledge Discovery</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="400" to="422" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Time Series Representation and Similarity Based on Local Autopatterns</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">G</forename><surname>Baydogan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Runger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Data Mining and Knowledge Discovery</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="476" to="509" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Algorithms for Hyper-Parameter Optimization</title>
		<author>
			<persName><forename type="first">J</forename><surname>Bergstra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Bardenet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Kégl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th International Conference on Neural Information Processing Systems</title>
		<meeting>the 24th International Conference on Neural Information Processing Systems</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Making a Science of Model Search: Hyperparameter Optimization in Hundreds of Dimensions for Vision Architectures</title>
		<author>
			<persName><forename type="first">J</forename><surname>Bergstra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Yamins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Cox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 30th International Conference on Machine Learning</title>
		<meeting>the 30th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Earthquake Early Warning Dataset</title>
		<author>
			<persName><forename type="first">K</forename><surname>Fauvel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Balouek-Thomert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Melgar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Silva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Simonet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Antoniu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Costan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Masson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Parashar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Rodero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Termier</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note>figshare</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Multivariate LSTM-FCNs for Time Series Classification</title>
		<author>
			<persName><forename type="first">K</forename><surname>Fazle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Majumdar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Darabi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Harford</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Networks</title>
		<imprint>
			<biblScope unit="volume">116</biblScope>
			<biblScope unit="page" from="237" to="245" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A Wireless Mesh Sensing Network for Early Warning</title>
		<author>
			<persName><forename type="first">J</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Redlich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zschau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Milkereit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Picozzi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Network and Computer Applications</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="538" to="547" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Earthquake Early Warning and Tsunami Warning of JMA for the 2011 off the Pacific Coast of Tohoku Earthquake</title>
		<author>
			<persName><forename type="first">M</forename><surname>Hoshiba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Ozaki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Seismological Society of Japan</title>
		<imprint>
			<biblScope unit="volume">64</biblScope>
			<biblScope unit="page" from="155" to="168" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Generalized Random Shapelet Forests</title>
		<author>
			<persName><forename type="first">I</forename><surname>Karlsson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Papapetrou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Boström</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Data Mining and Knowledge Discovery</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="1053" to="1085" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Iaspei 1991 Seismological Tables</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">L N</forename><surname>Kennet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Terra Nova</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="122" to="122" />
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Machine Learning Seismic Wave Discrimination: Application to Earthquake Early Warning</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Meier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Hauksson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Andrews</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Geophysical Research Letters</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="page" from="4773" to="4779" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">On Robust and Reliable Automated Baseline Corrections for Strong Motion Seismology</title>
		<author>
			<persName><forename type="first">D</forename><surname>Melgar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bock</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Sanchez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">W</forename><surname>Crowell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Geophysical Research: Solid Earth</title>
		<imprint>
			<biblScope unit="volume">118</biblScope>
			<biblScope unit="page" from="1177" to="1187" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Earthquake Magnitude Calculation Without Saturation from the Scaling of Peak Ground Displacement</title>
		<author>
			<persName><forename type="first">D</forename><surname>Melgar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">W</forename><surname>Crowell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Geng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Allen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bock</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Riquelme</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">M</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Protti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ganas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Geophysical Research Letters</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="page" from="5197" to="5205" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Scikit-Learn: Machine Learning in Python</title>
		<author>
			<persName><forename type="first">F</forename><surname>Pedregosa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Varoquaux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gramfort</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Michel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Thirion</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Grisel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Blondel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Prettenhofer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Dubourg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Vanderplas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Passos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Cournapeau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Brucher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Perrot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Duchesnay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2825" to="2830" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Convolutional Neural Network for Earthquake Detection and Location</title>
		<author>
			<persName><forename type="first">T</forename><surname>Perol</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gharbi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Denolle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science Advances</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Quantifying the Value of Real-Time Geodetic Constraints for Earthquake Early Warning Using a Global Seismic and Geodetic Data Set</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J</forename><surname>Ruhl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Melgar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">I</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Grapenthin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Allen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Geophysical Research: Solid Earth</title>
		<imprint>
			<biblScope unit="volume">124</biblScope>
			<biblScope unit="page" from="3819" to="3837" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">The Emergence of Edge Computing</title>
		<author>
			<persName><forename type="first">M</forename><surname>Satyanarayanan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="page" from="30" to="39" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Multivariate Time Series Classification with WEASEL+MUSE</title>
		<author>
			<persName><forename type="first">P</forename><surname>Schäfer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Leser</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">ArXiv</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Multivariate Time Series Classification Using Dynamic Time Warping Template Selection for Human Activity Recognition</title>
		<author>
			<persName><forename type="first">S</forename><surname>Seto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the</title>
		<title level="s">IEEE Symposium Series on Computational Intelligence</title>
		<meeting>the</meeting>
		<imprint>
			<date type="published" when="2015">2015. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Edge Computing: Vision and Challenges</title>
		<author>
			<persName><forename type="first">W</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Internet of Things Journal</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="637" to="646" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Generalizing DTW to the Multi-Dimensional Case Requires an Adaptive Approach</title>
		<author>
			<persName><forename type="first">M</forename><surname>Shokoohi-Yekta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Keogh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Data Mining and Knowledge Discovery</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="1" to="31" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Autoregressive Forests for Multivariate Time Series Modeling</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">S</forename><surname>Tuncel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">G</forename><surname>Baydogan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">73</biblScope>
			<biblScope unit="page" from="202" to="215" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Ultra-Fast Shapelets for Time Series Classification</title>
		<author>
			<persName><forename type="first">M</forename><surname>Wistuba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Grabocka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Schmidt-Thieme</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note type="report_type">ArXiv</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Geospatial Cyberinfrastructure: Past, Present and Future</title>
		<author>
			<persName><forename type="first">C</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Raskin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Goodchild</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gahegan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computers, Environment and Urban Systems</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="264" to="277" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Earthquake Detection Through Computationally Efficient Similarity Search</title>
		<author>
			<persName><forename type="first">C</forename><surname>Yoon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>O'reilly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">J</forename><surname>Bergen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">C</forename><surname>Beroza</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science Advances</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>