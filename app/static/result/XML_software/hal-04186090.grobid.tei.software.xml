<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="fr">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main"></title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Sébastien</forename><surname>Ferré</surname></persName>
							<email>ferre@irisa.fr</email>
							<affiliation key="aff0">
								<orgName type="laboratory">MDL au service de l&apos;automatisation de tâches uniques d&apos;abstraction et de raisonnement (ARC</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution" key="instit1">Univ Rennes</orgName>
								<orgName type="institution" key="instit2">CNRS</orgName>
								<orgName type="institution" key="instit3">IRISA Campus de Beaulieu</orgName>
								<address>
									<postCode>35042</postCode>
									<settlement>Rennes</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><surname>Le Principe</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution" key="instit1">Univ Rennes</orgName>
								<orgName type="institution" key="instit2">CNRS</orgName>
								<orgName type="institution" key="instit3">IRISA Campus de Beaulieu</orgName>
								<address>
									<postCode>35042</postCode>
									<settlement>Rennes</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">8936938B98326D0302FFCF4ECDE05ABE</idno>
					<note type="submission">Submitted on 23 Aug 2023</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-04-12T14:51+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>est destinée au dépôt et à la diffusion de documents scientifiques de niveau recherche, publiés ou non, émanant des établissements d'enseignement et de recherche français ou étrangers, des laboratoires publics ou privés.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="fr">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Le principe MDL au service de l'automatisation de tâches uniques d'abstraction et de raisonnement <ref type="bibr">(ARC)</ref> à partir de peu d'exemples</p><p>Sébastien Ferré * 1 Introduction</p><p>L'Intelligence artificielle (IA) a fait des progrès spectaculaires sur certaines tâches, parfois au-delà des performances humaines : ex., reconnaissance d'images, jeux de plateau, traitement automatique de la langue <ref type="bibr" target="#b5">(Devlin et al., 2019)</ref>. Cependant, l'IA manque encore de la flexibilité de l'intelligence humaine pour s'adapter à de nouvelles tâches à partir de peu d'exemples. Pour pousser la recherche en IA dans ce sens, <ref type="bibr" target="#b4">Chollet (2019)</ref> a introduit une mesure de l'intelligence qui valorise l'efficacité d'acquisition d'aptitudes plutôt que la performance dans ces aptitudes. Autrement dit, la quantité de connaissances a priori et d'expérience qu'un agent nécessite pour atteindre un niveau correct dans toute une famille de tâches (ex., les jeux de plateaux) compte plus que la performance atteinte dans n'importe quelle tâche particulière (ex., les échecs).</p><p>Chollet a aussi introduit le challenge ARC (Abstraction and Reasoning Corpus), une forme de test psychométrique visant à mesurer et comparer l'intelligence des machines comme des humains. ARC est une collection de tâches qui consistent à apprendre à générer une grille colorée à partir d'une autre grille colorée, et ce à partir de quelques exemples seulement. C'est un challenge très difficile : le gagnant d'une compétition Kaggle 1 n'a pu résoudre que 20% des tâches (avec beaucoup de codage en dur et une recherche brute) alors que les humains peuvent résoudre plus de 80% des tâches <ref type="bibr" target="#b10">(Johnson et al., 2021)</ref>. Les approches existantes <ref type="bibr" target="#b7">(Fischer et al., 2020;</ref><ref type="bibr" target="#b3">Alford et al., 2021)</ref> font de la synthèse de programme où un programme est une composition de transformations primitives opérant sur des grilles, et où l'apprentissage se fait par recherche dans le vaste espace des programmes. En revanche, les études psychologiques ont montré que les programmes naturels produits par les humains sont centrés-objets et déclaratifs plutôt que procéduraux <ref type="bibr" target="#b10">(Johnson et al., 2021;</ref><ref type="bibr" target="#b2">Acquaviva et al., 2021)</ref>. Quand on demande aux humains de verbaliser des instructions permettant de résoudre une tâche, ils commencent par décrire la grille d'entrée en terme d'objets puis comment générer la grille de sortie à partir des ces objets.</p><p>Nous apportons deux contributions par rapport aux approches existantes :</p><p>1. des modèles de grilles qui permettent à la fois d'analyser et de générer des grilles en terme d'objets et de calculs sur ces objets ;</p><p>2. une recherche efficace parmi les modèles de grilles avec le principe MDL (Minimum Description Length) <ref type="bibr" target="#b12">(Rissanen, 1978)</ref>.</p><p>Le principe MDL vient de la théorie de l'information et dit que le modèle qui décrit le mieux des données est celui qui les compresse le plus <ref type="bibr" target="#b12">(Rissanen, 1978;</ref><ref type="bibr" target="#b8">Grünwald et Roos, 2019)</ref>, appliqué par exemple en fouille de données <ref type="bibr" target="#b13">(Vreeken et al., 2011;</ref><ref type="bibr" target="#b6">Faas et Leeuwen, 2020)</ref>. Nous présentons des résultats encourageants avec des modèles de grilles simples et loin de couvrir toutes les connaissances a priori supposées connues dans ARC <ref type="bibr" target="#b4">(Chollet, 2019)</ref>. Des modèles corrects sont trouvés pour 61 tâches variées. La plupart de ces modèles sont similaires aux programmes naturels produits par les humains. Un dépôt GitHub 2 fournit le code source et un rapport technique contenant des détails techniques et un historique de versions montrant notre progression dans le challenge ARC.</p><p>Le papier est organisé comme suit. La section 2 présente le challenge ARC et la section 3 les approches existantes. La section 4 définit nos modèles centrés-objet et la section 5 explique comment les apprendre avec le principe MDL. La section 6 présente les résultats expérimentaux et les compare avec les approches existantes. 3 Approches existantes ARC est un challenge récent et difficile et peu d'approches ont été publiées jusqu'à présent. Toutes celles dont nous avons connaissance définissent un DSL (Domain-Specific Language) de programmes qui transforment une grille en une autre grille, et cherchent un programme qui soit correct sur les exemples d'apprentissage <ref type="bibr" target="#b7">(Fischer et al., 2020;</ref><ref type="bibr" target="#b3">Alford et al., 2021)</ref>. Leurs différences se trouvent dans les transformations primitives considérées (connaissances a priori) et dans la stratégie de recherche. Il est tentant de définir toujours plus de primitives pour résoudre plus de tâches, comme le gagnant Kaggle l'a fait, mais cela implique une moindre intelligence d'après la mesure de Chollet. Pour guider la recherche dans le vaste espace des programmes, <ref type="bibr" target="#b7">Fischer et al. (2020)</ref> utilisent un algorithme évolutionniste grammatical, et <ref type="bibr" target="#b3">Alford et al. (2021)</ref> utilisent des réseaux de neurones. Une difficulté est que la grille de sortie est généralement utilisée seulement pour l'évaluation d'un programme candidat, ce qui rend la recherche comme aveugle. <ref type="bibr" target="#b3">Alford et al. (2021)</ref> réduisent cette difficulté avec une recherche bidirectionnelle, partant des deux grilles à la fois. Ces approches ont un problème de passage à l'échelle car l'espace de recherche croit de façon exponentielle avec la taille du DSL. Nous comparons leur performance sur ARC dans la section 6. <ref type="bibr" target="#b10">Johnson et al. (2021)</ref> rapportent une étude psychologique sur ARC qui révèle que les humains utilise des représentations mentales à base d'objets. C'est en contraste avec les programmes à base de transformations des approches existantes. De façon intéressante, les tâches qui sont perçues comme les plus difficiles par les humains -celles basées sur l'algèbre de Boole (ex., un ou exclusif entre deux sous-grilles) et les symétries (ex., rotations, miroirs) -sont précisément celles qui sont les mieux traitées par les approches existantes. L'étude fait ressortir deux défis : (1) un large ensemble de primitives semble inévitable, surtout en géométrie ; et (2) une approche centrée-objet entraine le problème d'identifier les objets dans une grille, lesquels peuvent être partiellement visibles du fait d'occlusions entre objets. Une ressource précieuse est LARC (Language-annotated ARC) <ref type="bibr" target="#b2">(Acquaviva et al., 2021)</ref>, collectée par crowd-sourcing. Elle fournit pour la plupart des tâches d'entrainement un ou plusieurs programmes naturels. Ce sont de courtes descriptions textuelles produites par des participants et ayant permis à d'autres participants de générer les grilles de sortie attendues sans accès aux exemples d'apprentissage. Ces programmes naturels confirment l'aspect centré-objet des représentations humaines.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">ARC -Abstraction and Reasoning Corpus</head><p>Au-delà du challenge ARC, le domaine de la synthèse de programme étudie l'apprentissage de programmes à partir de quelques exemples d'entrée-sortie <ref type="bibr" target="#b11">(Lieberman, 2001)</ref>, par exemple pour remplir automatiquement une colonne d'un tableau à partir des autres colonnes <ref type="bibr" target="#b9">(Gulwani, 2011)</ref>. Là encore, les programmes sont généralement des compositions de fonctions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Modèles centrés-objet pour les grilles ARC</head><p>Nous introduisons des modèles centrés-objet pour décrire les grilles ARC en termes d'objets, ayant différentes formes, couleurs, tailles et positions. Ces modèles sont utilisés à la fois pour analyser une grille, c'est-à-dire comprendre son contenu selon le modèle et pour générer une grille en utilisant le modèle comme patron.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Des combinaisons de motifs et de fonctions comme modèles</head><p>Le principe d'un modèle de grille est de distinguer les éléments invariants des élements variants entre les différentes grilles d'une tâche. Dans la tâche b94a9452, toutes les grilles d'entrée contiennent un objet carré mais leurs tailles, couleurs et positions varient. Cela peut s'exprimer par un motif Square(size: ?, color: ?, pos: ?), où Square est appelé un constructeur et les points d'interrogation représentent des inconnues (similaires aux variables Prolog). Il y a aussi des constructeurs pour les positions en tant que vecteur 2D, Vec(i: ?, j: ?), et des valeurs primitives pour les tailles (ex., 3) et les couleurs (ex., blue). Les motifs peuvent être imbriqués, comme dans Square(3, ?,Vec( ?,2)) qui signifie "un carré de taille 3 dont le coin en haut à gauche est sur la colonne d'indice 2", de façon à avoir des modèles aussi spécifiques que nécessaire. Les motifs sans inconnue sont appelés des descriptions, par exemple Square(3,blue,Vec(2,4)).</p><p>Les motifs seuls ne permettent pas de faire dépendre la grille de sortie de la grille d'entrée, ce qui est indispensable pour résoudre les tâches ARC. Nous ajoutons donc deux ingrédients aux modèles de grille (en pratique, aux modèles de sortie) : des références aux éléments d'une description (en pratique, la description de la grille d'entrée) et des applications de fonctions pour effectuer des calculs sur ces éléments. Dans l'exemple, le modèle pour le petit carré dans les grilles de sortie pourrait être Square(!small.size, !large.color, !small.pos-!large.pos), où par exemple le chemin !small.size est une référence à la taille du petit carré dans la grille d'entrée. Ce modèle dit que "le petit carré en sortie a la taille du petit carré en entrée, la couleur du grand carré et que sa position est la différence entre les positions des deux carrés."</p><p>Les figures 2, 3 listent respectivement les constructeurs et fonctions des modèles de grille que nous avons utilisé dans nos expériences. Chaque constructeur/fonction a un type résultat et des arguments typés. Les types des arguments contraignent les constructeurs/fonctions pouvant être utilisés, et les noms des arguments des constructeurs sont utilisés pour référencer les éléments d'un modèle ou d'une description.</p><p>Nos modèles de grille décrivent une grille comme ayant une certaine taille, une certaine couleur de fond et une pile de couches (layers), où chaque couche contient un objet. Un objet a une forme et une position. La figure 4 montre un modèle correct pour la tâche b94a9452. Ce modèle peut se lire : "Trouve deux rectangles pleins empilés sur un fond noir dans la grille d'entrée. Puis génère une grille de sortie dont la taille est celle de l'objet de dessous (lay[1]) et dont la couleur de fond est la couleur de l'objet de dessus (lay[0]). Enfin, ajoute un rectangle plein dont la taille est celle de l'objet de dessus, dont la couleur est celle de l'objet de dessous, et dont la position est la différence entre celles des deux objets." </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Analyse et génération de grilles selon un modèle</head><p>Nous introduisons deux opérations qui doivent être définies pour tout modèle M de grille : l'analyse d'une grille g en une description π et la génération d'une description π et donc d'une grille g. Ces opérations sont analogues à l'analyse syntaxique et à la génération de phrases à partir d'une grammaire, où les arbres syntaxiques correspondent aux descriptions π.</p><p>Dans les deux opérations, les références présentes dans le modèle M sont d'abord résolues en utilisant une description π comme environnement ε, c-à-d. comme contexte d'évaluation. Concrètement, chaque référence est un chemin dans ε et est remplacée par la sous-description au bout de ce chemin. Les éventuelles fonctions s'appliquant à ces références sont alors évaluées. Il en résulte un modèle réduit M seulement constitué de motifs.</p><p>Analyse. L'analyse d'une grille g consiste à remplacer les inconnues du modèle réduit M par des descriptions correspondant au contenu de la grille. Il n'est pas nécessaire que tout le contenu de la grille soit décrit, ce qui autorise des modèles partiels. Une grille est analysée du dessus vers le dessous pour prendre en compte les superpositions d'objets. L'analyse d'un objet est contextuelle, elle dépend de ce qui reste à couvrir dans la grille après l'analyse des couches supérieures. Pour des raisons d'efficacité, chaque grille est pré-traitée pour en extraire une collection de parties unicolores et les objets sont analysés comme des unions de ces parties. Comme l'analyse des grilles peut devenir combinatoire, nous majorons le nombre de descriptions produites par l'analyse et nous les ordonnons d'après les mesures de longueurs de description définies en section 5. À titre d'exemple, l'analyse de la première grille d'entrée de la tâche b94a9452 avec le modèle M i de la figure <ref type="figure">4</ref> trouve la meilleure description suivante : π i = Grid(Vec(12,13), black, [PosShape(Vec(2,4), Rectangle(Vec(2,2), yellow, Full)), Pos-Shape(Vec(1,3), Rectangle(Vec(4,4), red, Full)) ]).</p><p>Génération. La génération d'une grille consiste à remplacer les éventuelles inconnues restantes dans le modèle réduit M par des decriptions aléatoires du bon type, de façon à obtenir une description de grille, qui peut ensuite être convertie en grille concrète. Par exemple, le modèle de sortie M o de la figure 4 appliqué avec la description π i ci-dessus de la première grille d'entrée génère la description suivante : π o = Grid(Vec(4,4), yellow, [PosShape(Vec(1,1), Rectangle(Vec(2,2), red, Full))]). Cette description est bien conforme à la grille de sortie attendue.</p><p>Un point important est que ces deux opérations retournent des ensembles et non des descriptions uniques. En effet, il existe souvent plusieurs façons d'analyser une grille selon un modèle, par exemple si le modèle mentionne un seul objet alors que la grille en contient plusieurs. Il existe aussi plusieurs grilles pouvant être générées par un modèle dès lors qu'il contient des inconnues. De plus amples détails sur ces opérations sont disponibles dans le rapport technique (voir dépôt GitHub).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Prédire, décrire et créer des grilles avec des modèles de tâches</head><p>Un modèle de tâche M = (M i , M o ) est composé d'un modèle de grille d'entrée M i et d'un modèle de grille de sortie M o . Nous démontrons la versatilité de tels modèles en montrant qu'ils peuvent être employés selon trois modes : prédire la grille de sortie à partir de la grille d'entrée, décrire une paire de grilles de façon conjointe, ou créer une nouvelle paire de grilles pour la tâche. Nous utilisons ci-dessous la notation π ∈ parse(M, ε, g) pour dire que π est une des analyses de la grille g d'après le modèle M et l'environnement ε ; et la notation π, g ∈ generate(M, ε) pour dire que π est une des descriptions générées par le modèle M avec l'environnement ε, et que g est la grille décrite par π.</p><p>Le mode prédire est employé quand un modèle a déjà été appris, dans la phase d'évaluation sur les exemples test. Il consiste d'abord à analyser la grille d'entrée avec l'environnement vide nil pour en obtenir une description π i , puis à générer la grille de sortie en utilisant cette description de la grille d'entrée comme environnement.</p><formula xml:id="formula_0">predict(M, g i ) = {g o | π i ∈ parse(M i , nil , g i ), π o , g o ∈ generate(M o , π i )}</formula><p>Le mode décrire est employé dans la phase d'apprentissage du modèle (voir la section 5). Il permet d'obtenir une description jointe d'une paire de grilles. Il consiste en l'analyse successive de la grille d'entrée et de la grille de sortie. Notons que l'analyse de la grille de sortie dépend du résultat de l'analyse de la grille d'entrée, d'où le terme de description jointe.</p><formula xml:id="formula_1">describe(M, g i , g o ) = {(π i , π o ) | π i ∈ parse(M i , nil , g i ), π o ∈ parse(M o , π i , g o )}</formula><p>Le mode créer permet de créer un nouvel exemple de la tâche. Il consiste en la génération successive d'une grille d'entrée et d'une grille de sortie, cette dernière étant conditionnée par la première. Ce mode n'est pas employé dans le challenge ARC mais il pourrait contribuer à la mesure de l'intelligence d'un système. En effet, si un agent a vraiment compris une tâche, il devrait être capable de produire de nouveaux exemples.</p><formula xml:id="formula_2">create(M ) = {(g i , g o ) | π i , g i ∈ generate(M i , nil ), π o , g o ∈ generate(M o , π i )}</formula><p>Ces trois modes font apparaitre une différence essentielle entre nos modèles centrés-objet et les programmes transformatifs des approches existantes. Ces derniers sont conçus pour la prédiction (calcul de la sortie en fonction de l'entrée), ils ne fournissent pas une description des grilles. Un nouvel exemple pourrait être créé en générant aléatoirement une grille d'entrée et en lui appliquant le programme mais en général, il ne respecterait pas la plupart des invariants de la tâche (ex., bitmap aléatoire plutôt qu'un carré plein).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Apprentissage d'un modèle avec le principe MDL</head><p>L'apprentissage avec le principe MDL consiste à chercher le modèle qui compresse le plus les données. Dans le cadre de ARC, les données à compresser sont les exemples d'apprentissage. Il y a donc deux choses à définir : (1) les longueurs de description (abbr. DL) des modèles et des exemples et (2) l'espace de recherche des modèles ainsi que la stratégie d'apprentissage.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Longueurs de description</head><p>Une approche courante de MDL consiste à définir la longueur de description globale comme la somme de deux parties (two-parts MDL) : le modèle M et les données D encodées selon le modèle <ref type="bibr" target="#b8">(Grünwald et Roos, 2019)</ref>.</p><formula xml:id="formula_3">L(M, D) = L(M ) + L(D | M )</formula><p>Dans notre cas, le modèle est un modèle de tâche composé de deux modèles de grilles ; et les données sont l'ensemble des exemples d'apprentissage. Pour compenser le faible nombre d'exemples et permettre des modèles suffisamment complexes, nous utilisons un facteur de répétition α ≥ 1, comme si chaque exemple était répété α fois.</p><formula xml:id="formula_4">L(M ) = L(M i ) + L(M o ) L(D | M ) = α (g i ,g o ) L(g i , g o | M )</formula><p>La DL d'un exemple est la description jointe la plus compressive d'une paire de grilles.</p><formula xml:id="formula_5">L(g i , g o | M ) = min{L(π i , g i | M i , nil )+L(π o , g o | M o , π i ) | π i , π o ∈ describe(M, g i , g o )}</formula><p>Les termes de la forme L(π, g | M, ε) dénotent la DL d'une grille g encodée selon un modèle de grille M et un environnement ε, via la description π résultant de l'analyse. On peut décomposer ces termes en se servant de π comme représentation intermédiare d'une grille.</p><formula xml:id="formula_6">L(π, g | M, ε) = L(π | M, ε) + L(g | π)</formula><p>Le terme L(π | M, ε) mesure la quantité d'information qui doit être ajoutée au modèle et à l'environnement pour coder la description, typiquement les valeurs des inconnues. Le terme L(g | π) mesure les différences entre la grille originale et la grille produite par la description. Un modèle correct est obtenu quand L(π o , g o | M o , π i ) = 0 pour tous les exemples, c'est-à-dire quand il ne reste plus rien à coder pour les grilles de sorties et donc que les grilles de sorties sont parfaitement prédites.</p><p>Trois DL élémentaires doivent donc être définies :</p><p>-L(M ) : la DL d'un modèle de grille ; -L(π | M, ε) : la DL d'une description de grille, selon le modèle de grille et l'environnement utilisés pour son analyse ; -L(g | π) : la DL d'une grille, relativement à une description de grille, c'est-à-dire l'encodage des erreurs et omissions commises par la description. Nous esquissons ces définitions pour nos modèles de grilles définis en section 4. Nous rappelons que les DL sont généralement dérivées de distributions de probabilités via l'équation L(x) = -log P (x), qui correspond à un codage optimal <ref type="bibr" target="#b8">(Grünwald et Roos, 2019)</ref>.</p><p>L(M ) correspond à l'encodage d'un arbre de syntaxe avec des constructeurs, valeurs, inconnues, références et fonctions comme noeuds. Leur typage pose des contraintes sur les imbrications possibles : ex., le type Object a un seul constructeur et pas de fonction. Nous appliquons une distribution uniforme entre constructeurs possibles (resp. entre valeurs ou entre fonctions). Nous appliquons un codage universel pour les entiers pour lesquels il n'y a pas de bornes connues. Une référence est encodée selon une distribution uniforme parmi tous les éléments de l'environnement qui ont un type compatible. Nous donnons aux inconnues une probabilité plus basse qu'aux constructeurs, et aux références/fonctions une plus haute, afin de favoriser les modèles qui sont plus spécifiques et font dépendre la sortie de l'entrée.</p><p>L(π | M, ε) correspond à l'encodage des éléments de la description π qui sont inconnus dans le modèle, ou bien qui diverge du modèle. Comme les descriptions forment en fait un sous-ensembles des modèles, les définitions pour L(M ) peuvent être réutilisées.</p><p>L(g | π) correspond à encoder quelles cellules de la grille g sont mal spécifiées par la description π. Chaque cellule est codée comme un objet point PosShape(Vec(i,j),Point(c)).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Espace de recherche et stratégie</head><p>L'espace de recherche des modèles est caractérisé par : (1) un modèle initial et (2) un opérateur de raffinement qui retourne une liste de raffinements de modèle M 1 . . . M n , à partir d'un modèle M . Un raffinement peut insérer un nouvel élément dans le modèle, remplacer une inconnue par un constructeur (introduisant de nouvelles inconnues pour les arguments du constructeur), ou remplacer un élément par une expression (une composition de références, valeurs et fonctions). L'opérateur de raffinement a accès aux données via les descriptions jointes, il peut donc être guidée par elles. Comme dans des approches MDL antérieures en fouille de données <ref type="bibr" target="#b13">(Vreeken et al., 2011)</ref>, nous adoptons une heuristique gloutonne guidée par la DL des modèles. À chaque étape, en partant du modèle initial, le raffinement réduisant le plus la DL globale L(M, D) est sélectionné. La recherche s'arrête quand aucun raffinement ne permet de réduire la DL. Pour compenser le fait que dans certaines tâches les grilles d'entrée et de sortie ont des tailles très différentes, ce qui peut arrêter précocement la recherche de modèle, nous utilisons comme critère une DL normalisée L qui donne le même poids aux composantes entrée et sortie de la DL globale L(M, D), avec par convention une valeur de 2 (1+1) pour le modèle initial :</p><formula xml:id="formula_7">L(M, D) = L(M i ,D i ) L(M i init ,D i ) + L(M o ,D o ) L(M o init ,D o ) .</formula><p>Notre modèle initial utilise le modèle de grille vide Grid( ?, ?,[]) pour l'entrée et la sortie. Les raffinements disponibles sont :</p><p>-l'insertion d'un nouvel objet, à n'importe quelle position dans la pile de couches -pris parmi PosShape( ?,Point( ?)), PosShape( ?,Rectangle( ?, ?, ?)), PosShape( ?, !shape) ou !object -où shape/object est une référence à une forme/objet de l'entrée ; -le remplacement d'une inconnue au chemin p par un constructeur (resp. une valeur) quand, pour chaque exemple, il existe une description π telle que π.p matche ce constructeur (resp. égale cette valeur) ; -le remplacement d'un élément du modèle au chemin p par une expression e du même type quand, pour chaque exemple, il existe une description π telle que π.p = e. La figure 5 montre la trace d'apprentissage de la tâche b94a9452, montrant à chaque étape le raffinement le plus compressif. Cette trace révèle comment l'agent apprenant résoud la tâche : "Il y a un rectangle lay[1] dans l'entrée (1) et un rectangle lay[0] dans la sortie (2). La grille de sortie est de la taille de lay[1] en entrée (3). Il y a un autre rectangle lay[0] dans l'entrée, au-dessus de lay[1] (4). On peut utiliser sa couleur pour le fond de la sortie (5), et sa taille pour lay[0] en sortie (6). La couleur de lay[0] en sortie est la couleur de lay[1] en entrée (7) et sa position est égale à la différence entre les positions des deux rectangles en entrée (9). Tous les rectangles sont pleins (8,10,11) et le fond de l'entrée est noir (12)."</p><p>22/36 et 14/18, soit 5.5% et 3.5% des 400 tâches. Sur les tâches d'entrainement, qui offrent à ce jour la meilleure base de comparaison, notre approche est donc celle qui résoud le plus grand nombre de tâches.</p><p>Efficacité et complexité des modèles. Le temps moyen d'apprentissage est de 15.1s sur les tâches d'entrainement (avec timeout=30s). Sur les 52 tâches résolues, ce temps moyen chute à 4.9s et le temps médian encore plus bas à 2.1s. Cela montre que quand une solution peut être trouvée, elle est généralement trouvée rapidement. Dans les tâches résolues, le nombre de raffinements va de 5 à 29 (médiane=13). Cela donne une mesure de la complexité des modèles appris. Une telle profondeur dans l'espace de recherche ne pourrait jamais être atteinte dans une recherche par force brute (le gagnant Kaggle se limite à une composition de 4 fonctions). Le principe MDL joue ici un rôle crucial dans le guidage de la recherche.</p><p>Modèles appris. Les modèles appris pour les tâches résolues sont très divers malgré la simplicité de leur classe. Ils expriment des transformations diverses : ex., déplacer un objet, échanger deux couleurs, prolonger des lignes, mettre un objet derrière un autre, ordonner des objets du plus grand au plus petit, enlever du bruit. Notons qu'aucune de ces transformations n'est une primitive dans notre classe de modèles, ils sont appris en terme d'objets, d'arithmétique de base, de géométrie simple et de principe MDL.</p><p>Nous avons comparé nos modèles appris aux programmes naturels de LARC <ref type="bibr" target="#b2">(Acquaviva et al., 2021)</ref>. De façon remarquable, pour une majorité de nos modèles, il existe un programme naturel qui peut être considéré comme une reformulation de notre modèle, c'est-à-dire mettant en jeu les mêmes objets et les mêmes opérations. Par exemple, le programme naturel pour la tâche courante b94a9452 est : "[L'entrée a] une forme carrée avec un petit carré centré à l'intérieur du grand carré sur un fond noir. Les deux carrés sont de différentes couleurs. Faire une grille de sortie qui est de la même taille que le grand carré. La taille et la position du petit carré intérieur devrait être les mêmes que dans la grille d'entrée. Les couleurs des deux carrés sont échangées." Pour les autres modèles, certaines notions utilisées par les programmes naturels manquent à notre classe de modèles mais sont compensées par d'autres éléments de nos modèles : ex., des relations topologiques tels que "à côté de" ou "au dessus" (compensées par les trois tentatives), la couleur majoritaire (compensée par le principe MDL sélectionnant le plus gros objet). Cependant, dans la plupart des cas, les mêmes objets sont identifiés.</p><p>Ces observations démontrent que nos modèles centrés-objet s'alignent bien avec les programmes naturels produits par des humains, contrairement aux approches basées sur la composition de transformations. Un exemple de programme appris par <ref type="bibr" target="#b7">Fischer et al. (2020)</ref> sur la tâche 23b5c85d est strip_black; split_colors; sort_Area; top; crop, qui est une séquences de transformations grille-à-grille, sans mention explicite d'objets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion et perspectives</head><p>Nous avons montré la capacité de notre approche à automatiser des tâches ARC variées et à produire des modèles similaires aux programmes naturels. Des résultats encourageants sont obtenus pour un challenge reconnu comme particulièrement difficile, et ce malgré des modèles simples, loin de couvrir les connaissances a priori supposées dans ARC. Nous croyons que l'extensibilité de notre approche permettra des progrès continus dans le futur. Au-delà de l'ajout de constructeurs et de fonctions, relativement aisé, des verrous scientifiques sont les traitements conditionnels et les itérations sur des collections d'objets. Nous souhaitons</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>FIG. 1 -</head><label>1</label><figDesc>FIG. 1 -Tâches d'entrainement b94a9452 (en haut) et 23581191 (en bas).</figDesc><graphic coords="3,110.55,150.81,374.17,91.73" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>M</head><label></label><figDesc>FIG.4-Un modèle correct pour la tâche b94a9452.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>ARC est une collection de tâches 3 , où chaque tâche est constituée d'exemples d'apprentissage (en moyenne 3.3) et d'exemples de test (1 parfois 2). Chaque exemple est composé d'une 2. https://github.com/sebferre/ARC-MDL 3. Données et interface de test à https://github.com/fchollet/ARC grille d'entrée et d'une grille de sortie. Chaque grille est une matrice (de taille 1x1 à 30x30) remplie d'entiers codant des couleurs (10 couleurs distinctes). Pour une tâche donnée, la taille des grilles peut varier d'un exemple à l'autre et entre l'entrée et la sortie. Chaque tâche est un problème d'apprentissage dont le but est d'apprendre un programme ou modèle qui génère la grille de sortie à partir de la grille d'entrée, et ce à partir de seulement quelques paires de grilles comme exemples. Le critère de succès est que toutes les grilles de sorties test soient identiques aux grilles attendues (à la cellule près). Cependant, trois tentatives par grilles sont permises pour chaque grille test pour compenser les éventuelles ambiguités dans la définition d'une tâche. La figure 1 montre deux tâches ARC (sans les grilles de sortie test attendues). La première sert d'exemple courant dans la suite du papier. Le challenge ARC est composé de 1000 tâches : 400 "tâches d'entrainement" 4 pour le développement d'IA, 400 tâches d'évaluation et 200 tâches secrètes pour des évaluations indépendantes.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>Une forme est un point coloré ou est défini par un masque coloré inscrit dans un rectangle. Un masque est soit un bitmap quelconque soit une forme commune Les fonctions disponibles couvrent pour l'essentiel des opérations arithmétiques sur les entiers et les vecteurs représentant des positions, des tailles et des déplacements ; et des notions géométriques telles que mesures (ex., aire), translations, symétries, mises à l'échelle et motifs périodiques (ex., tuilage). Les inconnues sont ici limitées aux types primitifs et aux vecteurs et ne peuvent pas apparaitre comme argument de fonction. Les références et les fonctions ne sont utiles que dans les modèles de sortie.</figDesc><table><row><cell>type</cell><cell>constructeurs</cell></row><row><cell>Grid</cell><cell>Grid(size: Vector, color: Color, layers: Object[])</cell></row><row><cell cols="2">Object PosShape(pos: Vector, shape: Shape)</cell></row><row><cell cols="2">Shape Point(color: Color)</cell></row><row><cell></cell><cell>Rectangle(size: Vector, color: Color, mask: Mask)</cell></row><row><cell cols="2">Vector Vec(i: Int, j: Int)</cell></row><row><cell>Mask</cell><cell>Bitmap(bitmap : Bitmap)</cell></row><row><cell></cell><cell>Full, Border, ...</cell></row><row><cell></cell><cell>FIG. 2 -Constructeurs par type</cell></row></table><note><p><p><p>Arithmétique : addition et soustraction ; multiplication et division par une petite constante (2..3) ; minimum, maximum et moyenne de deux entiers ; écart entre deux positions (|x -y| + 1) ; versions vectorisées des fonctions précédentes (e.g., (i 1 , j 1 ) + (i 2 , j 2 ) = (i 1 + i 2 , j 1 + j 2 )) ; projection d'un vecteur sur un axe. Géométrie : aire d'une forme ; positions extrêmes et médianes d'un objet selon chaque axe (ex., haut et bas, milieu) ; vecteur de translation d'un objet contre un autre ; mise à l'échelle d'un masque ou d'une forme d'un facteur constant ou par rapport à un vecteur taille ; extension d'un masque, forme ou objet à une certaine taille en respectant un motif périodique (ex., en damier) ; tuilage d'un masque ou d'une forme un petit nombre de fois selon les deux axes ; application de symétries aux masques, formes et objets (combinaisons de rotations et de réflexions). Autres fonctions : recoloration d'une forme ou d'un objet ; opérations logiques sur les masques bitmaps.</p>FIG. 3 -Fonctions par catégorie</p>telle qu'un rectangle plein ou un contour de rectangle (border). Les positions et tailles sont des vecteurs 2D d'entiers. Trois types primitifs sont employés : les entiers, les couleurs et les bitmaps.</p></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_0"><p>Le terme "entrainement" est trompeur car ces tâches visent à l'entrainement des développeurs d'IA, pas à l'entrainement des systèmes d'IA. Les tâches ARC peuvent être résolues par les humains sans entrainement spécifique.</p></note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Évaluation</head><p>Nous avons évalué notre approche sur les 800 tâches publiques ARC. Les quelques paramètres ont été réglés sur la base des tâches d'entrainement. Pour assurer un partage du temps de calcul entre l'analyse des grilles et la recherche dans l'espace des modèles, nous définissons quelques limites. Le nombre de descriptions produites par l'analyse d'une grille est limité à 64 et seules les 3 plus compressives sont retenues pour le calcul des raffinements. À chaque étape, au plus 10.000 expressions sont considérées et seuls les 20 raffinements qui sont estimés réduire le plus la DL globale sont évalués. Le taux de répétition α est fixé à 10. Les tâches sont traitées indépendamment les unes des autres, sans apprentissage de l'une à l'autre. Les résultats sont donnés pour un temps d'apprentissage par tâche limité à 30s, l'augmenter augmente le temps de calcul sans résoudre davantage de tâches.</p><p>Les logs d'apprentissage/prédiction et les images des tâches d'entrainement résolues sont disponibles sur le dépôt GitHub (voir la version 2.5 pour les résultats de ce papier).</p><p>Taux de succès. Notre approche résoud 52/400 (13%) tâches d'entrainement et 9/400 (2.25%) tâches d'évaluation. Cela suggère que les tâches d'évaluations sont significativement plus difficiles que les tâches d'entrainement, ce qui a également été observé par d'autres auteurs <ref type="bibr" target="#b7">(Fischer et al., 2020)</ref>. Bien que trois prédictions soit permises par exemple test, la première prédiction est correcte dans 41 des 52 tâches d'entrainement résolues. Cela montre que les modèles appris sont précis dans leur compréhension des tâches. Pour quelques autres tâches, le système trouve un modèle qui est correct sur les exemples d'apprentissage mais échoue sur au moins un exemple test : 7 tâches d'entrainement et 6 tâches d'évaluation.</p><p>Il n'est malheureusement pas aisé de comparer ces résultats à ceux des travaux antérieurs. Le gagnant Kaggle "icecuber" atteint le score impressionnant de 20.6% mais il est mesuré sur 100 tâches secrètes ne faisant pas partie des 800 tâches publiques. <ref type="bibr" target="#b7">Fischer et al. (2020)</ref> atteignent un score de 7.68% sur les tâches d'entrainement et de 3% sur les 100 tâches secrètes. <ref type="bibr" target="#b3">Alford et al. (2021)</ref> rapportent deux expériences sur de petits sous-ensembles de tâches d'entrainement, choisies pour correspondre à leur DSL. Les taux de succès sont respectivement de</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Summary</head><p>The ARC (Abstraction and Reasoning Corpus) challenge has been proposed to push AI research towards more generalization capability rather than ever more performance. It is a collection of unique tasks about generating colored grids, specified by a few examples only. We propose object-centered models analogous to the natural programs produced by humans. The MDL (Minimum Description Length) principle is exploited for an efficient search in the vast model space. We obtain encouraging results with a class of of simple models: various tasks are solved and the learned models are close to natural programs.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m">approche à d&apos;autres contextes comme celui du traitement de chaines dans les feuilles de calcul</title>
		<imprint>
			<publisher>Gulwani</publisher>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">Références</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">LARC : Language annotated Abstraction and Reasoning Corpus</title>
		<author>
			<persName><forename type="first">S</forename><surname>Acquaviva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Pu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Nye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">H</forename><surname>Tessler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tenenbaum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Annual Meeting of the Cognitive Science Society</title>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">43</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Neural-guided, bidirectional program search for abstraction and reasoning</title>
		<author>
			<persName><forename type="first">S</forename><surname>Alford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gandhi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rangamani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Banburski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Dandekar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Poggio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Chin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Int. Conf. Complex Networks and Their Applications</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="657" to="668" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<author>
			<persName><forename type="first">F</forename><surname>Chollet</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1911.01547</idno>
		<title level="m">On the measure of intelligence</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">BERT : pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conf. North American Chapter of the Association for Computational Linguistics : Human Language Technologies, NAACL-HLT</title>
		<editor>
			<persName><forename type="first">J</forename><surname>Burstein</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Doran</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename><surname>Solorio</surname></persName>
		</editor>
		<imprint>
			<publisher>Assoc. Computational Linguistics</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="4171" to="4186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Vouw : geometric pattern mining using the MDL principle</title>
		<author>
			<persName><forename type="first">M</forename><surname>Faas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">V</forename><surname>Leeuwen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Int. Symp. Intelligent Data Analysis</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="158" to="170" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Solving Abstract Reasoning Tasks with Grammatical Evolution</title>
		<author>
			<persName><forename type="first">R</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Jakobs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mücke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Morik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">LWDA, CEUR-WS 2738</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="6" to="10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<author>
			<persName><forename type="first">P</forename><surname>Grünwald</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Roos</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1908.08484</idno>
		<title level="m">Minimum description length revisited</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Automating string processing in spreadsheets using input-output examples</title>
		<author>
			<persName><forename type="first">S</forename><surname>Gulwani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Symp. Principles of Programming Languages</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="317" to="330" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Fast and flexible : Human program induction in abstract reasoning tasks</title>
		<author>
			<persName><forename type="first">A</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">K</forename><surname>Vong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">M</forename><surname>Lake</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">M</forename><surname>Gureckis</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2103.05823</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Your Wish is My Command</title>
		<author>
			<persName><forename type="first">H</forename><surname>Lieberman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Morgan Kaufmann series in interactive technologies</title>
		<imprint>
			<publisher>Morgan Kaufmann / Elsevier</publisher>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Modeling by shortest data description</title>
		<author>
			<persName><forename type="first">J</forename><surname>Rissanen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Automatica</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="465" to="471" />
			<date type="published" when="1978">1978</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Krimp : mining itemsets that compress</title>
		<author>
			<persName><forename type="first">J</forename><surname>Vreeken</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Van Leeuwen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Siebes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Data Mining and Knowledge Discovery</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="169" to="214" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
