<TEI xmlns="http://www.tei-c.org/ns/1.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xml:space="preserve" xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Impressions and Strategies of Academic Advisors When Using a Grade Prediction Tool During Term Planning</title>
				<funder ref="#_P22Vxjx">
					<orgName type="full">unknown</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher />
				<availability status="unknown"><licence /></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Luis</forename><surname>Gal√°rraga</surname></persName>
							<email>luis.galarraga@inria.fr</email>
							<affiliation key="aff1">
								<orgName type="institution">INRIA Rennes</orgName>
								<address>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Impressions and Strategies of Academic Advisors When Using a Grade Prediction Tool During Term Planning</title>
					</analytic>
					<monogr>
						<imprint>
							<date />
						</imprint>
					</monogr>
					<idno type="MD5">D9173BE6C2326BD399FAD8D9E6B115BE</idno>
					<idno type="DOI">10.1145/3544548.3581575</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-04-12T14:47+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid" />
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Human-centered computing ‚Üí Empirical studies in visualization academic advising</term>
					<term>course recommendation</term>
					<term>grade prediction</term>
				</keywords>
			</textClass>
			<abstract>
<div><p>Academic advising brings numerous benefits to the mission of Higher Education Institutions. One central and challenging duty of advisors is course recommendation for term planning. This task requires both knowledge of the study programs as well as a thorough analysis of the students' unique circumstances. Limited time and a large student population make this task overwhelming. As a result, an important body of research has sought to expedite term planning via data-oriented decision-support tools. The impact of such tools on students has been extensively studied. However, the advisors' perspective remains largely unexplored. We contribute to redressing this gap by studying how a grade prediction tool shapes academic advisors' approach to course recommendation. We found that while the advisors' usual strategies tend to prevail, their recommendations largely depend on the advisee's historical performance. That said, advisors also acknowledge the limitations of grades as a measure of academic success.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div><head n="1">INTRODUCTION</head><p>Academic advising processes are implemented by Higher Education Institutions (HEIs) to promote exchanges between students and experts in aspects of the students' academic life <ref type="bibr" target="#b26">[27]</ref>. These exchanges are conducted under the assumption that the experts' advice contributes to the creation of supportive academic environments that meet the students' needs and, hence, foster their development. A vast body of research on academic support systems has identified multiple benefits of academic advising both for students and HEIs. For students, advising guarantees not only more informed enrollment decisions, but also guidance on matters that may affect their academic success and performance <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b19">20]</ref>. For educational institutions, academic advising can provide firsthand feedback on the impact of institutional policies, keep students focused on relevant goals, channel the students' academic interests, and establish policies to improve student achievement <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b18">19]</ref>. For all these reasons, academic advising is often a requirement of educational accreditation boards <ref type="bibr" target="#b4">[5]</ref> such as ABET <ref type="foot" target="#foot_0">1</ref> .</p><p>At the center of academic advising lie the academic advisors, whose role is fundamental for the success of any academic support system. Advisors act as mediators that inform students about institutional policies, principles, and expectations. By meeting students on a regular basis, advisors can identify institutional features that adversely affect the students' experience. Equally important, advisors get to develop a sense of the students' needs beyond academic matters. All this can promote the development of institutional actions oriented to improve student well-being.</p><p>Although widely effective, some aspects of academic advising often require significant logistical efforts and resources. In particular, guiding students in the selection of courses for a forthcoming academic term can be prone to errors-due to the introduction of subjective judgments. This task requires assessing each student's academic history in light of their enrollment options at a specific point of their study program, and is particularly challenging in programs with curricula that do not include many elective courses. The challenges around course recommendation have motivated several research efforts to relieve the advisors' workload. Most of these efforts have focused on empowering students with data and tools to make faster and more informed enrollment decisions. The effects of these tools on the students' decision-making process and final decisions have been extensively investigated and are quite well understood.</p><p>On the contrary, advisor-oriented support is less common, and the effects of data-based tools on the advisors' approach to course recommendation are lesser-known. In this paper we take steps to fill this gap by investigating how a tool that provides course grade predictions (and explanations thereof) shapes the approach of academic advisors to course recommendation. We present the findings of a study in which academic advisors of an Engineering-oriented public university used a grade prediction tool to recommend a set of courses to students with three different academic profiles, namely low-, average-, and high-performing. We analyzed the effects of the tool on the advisors' decisions as well as on their recommendation strategy. Moreover, we studied how these decisions differ based on the advisee's performance profile. Our observations suggest that when using the tool, advisors barely change their self-reported usual recommendation approach. That is, the grade predictions and explanations provided by the tool did not have a major influence on how advisors decided which courses students should take in an upcoming term. That said, advisors did look at complementary information such as the student's academic and enrollment history, in order to build a more precise profile of the advisee. This, in particular, resulted in longer interactions with the tool when making recommendations for the low-performing student, for whom advisors also tried to maximize the GPA gain. We also found that a grade prediction tool may rise concerns not only about the trustworthiness of the predictions and their impact on the students' motivations, but also about the limitations of the GPA to characterize academic performance.</p><p>With our study results, we contribute: 1) a characterization of the advisor's decision-making process for course recommendation in the presence of grade predictions and different student academic profiles; 2) a discussion of the advisors' concerns raised by a gradeprediction tool in the context of course recommendation; and 3) a reflection on the need for human intervention to prevent the undesired effects of grade-based predictions in academic support systems. Our findings provide guidance for the design of data-based solutions to make the student-advisor dialogue more effective.</p></div>
<div><head n="2">RELATED WORK</head><p>Before describing our study, we first summarize the challenges around academic advising that motivate the use of data-oriented decision-support tools. We then survey studies on the effects of data and predictive tools on students and advisors. We conclude this section with a body of empirical evidence that highlights several features of AI-based tools that impact people's decision making, particularly in the context of academic advising and course recommendation. This body of work constitutes the conceptual base that informs our study.</p></div>
<div><head n="2.1">Academic Advising and the Challenges of Course Recommendation</head><p>Appropriate academic advising is critical for the success of students <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b61">61]</ref>. Advising helps HEIs in supporting at-risk students and strengthening their motivations <ref type="bibr" target="#b28">[29]</ref> which, in turn, can reduce student attrition and prevent graduation delays and potential dropouts <ref type="bibr" target="#b57">[57,</ref><ref type="bibr" target="#b60">60]</ref>. The Global Community for Academic Advising (NACADA<ref type="foot" target="#foot_2">2</ref> ) recognizes four dimensions of academic advising at HEIs: (i) who does the advising (e.g., faculty vs. other dedicated professionals), (ii) where and how advising services are available (e.g., on-campus vs. via online tools, face-to-face vs. remote advising), (iii) whether advising responsibilities are centralized by the university or delegated to its academic departments, and (iv) whether specific advisors specialize in topics or they all are able to assist students with any program-specific and university-wide matter. The academic advising model adopted by a HEI is defined by each of these dimensions, which depend on the HEI's values, resources, and educational models.</p><p>An important aspect of any academic advising program is assisting students with course enrollment. In this process, advisors help students shape their academic path through choices oriented to the realization of their career and life goals <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b48">48]</ref>. The interactions between students and advisors are conducted under the assumption that, due to their experience, advisors are able to foresee the long-term consequences of the students' decisions-something that is less accessible to the latter due to their incomplete knowledge.</p><p>A long history of research suggests that course recommendation can indeed reduce the risks associated to bad enrollment decisions <ref type="bibr">[18-20, 42, 54, 59</ref>]. However, when providing guidance on which courses a student should take next, academic advisors face the challenge of reconciling multiple relevant factors, such as the students' profile (e.g., academic history, interests, and skills) and the features of the courses available for enrollment (e.g., contents, difficulty, imposed workload). This makes course recommendation a time-consuming task that is also prone to errors and susceptible to personal, non-objective opinions. Logistic criteria, such as schedule restrictions and the number of places that courses can accommodate, make the task even harder. These aspects often force advisors to provide a "plan B", in case students are unable to enroll in the courses of a primary recommendation. Other challenges arise from the HEI's educational model: in universities with largely elective curricula, students have more options and thus, course recommendation tends to be easier. Less flexible curricula make enrollment decisions more critical, because poor term planning usually incurs delays that can have a long-lasting impact on the students' academic experience and success <ref type="bibr" target="#b3">[4]</ref>.</p><p>The process of course recommendation is particularly problematic when it takes place as part of an academic advising session, as these must often occur within a short time window. The problem exacerbates when students also seek assistance with personal issues that affect their academic lives. Given that advisors may serve other roles within their institution, time-related restrictions can be a barrier in achieving the goals of an academic advising system <ref type="bibr" target="#b13">[14]</ref>.</p></div>
<div><head n="2.2">Data-and AI-based Support for Course Selection and Recommendation</head><p>The challenges explained above have motivated a plethora of tools oriented to support students and advisors in term planning and course recommendation. Most of these tools share a common denominator: they capitalize on historical data to provide users with objective information to make better, more informed decisions. At their onset, most of these tools primarily provided data-rich environments with descriptive statistics of the courses in a program, and the progress and performance of the students (e.g., <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b46">46,</ref><ref type="bibr" target="#b49">49,</ref><ref type="bibr" target="#b50">50,</ref><ref type="bibr" target="#b63">63]</ref>). A more recent generation of tools enables users to simulate scenarios and make decisions in the light of dataand AI-based predictions (e.g., <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b52">52]</ref>). The benefits and drawbacks of both kinds of tools have been extensively investigated, particularly from the students' perspective. The "Cornell Experiment", for example, showed that when course grades are published online, low-performing students tend to choose leniently graded courses <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b7">8]</ref>. Along the same lines, Chaturapruek et al. found that using a tool that exposes historical official transcripts and detailed end-of-course evaluation surveys lowered students' GPA-an effect that was also observed when the tool provided information about course time commitment <ref type="bibr" target="#b15">[16]</ref>.</p><p>A parallel line of research has explored how predictive tools support students' decision-making for enrollment. Backenk√∂hler et al. proposed a tool to compose a personalized curriculum for a given student, by optimizing predicted performance and time-todegree <ref type="bibr" target="#b3">[4]</ref>. Jiang and colleagues describe a course recommendation tool that takes into account students' interest, prior knowledge, and development <ref type="bibr" target="#b30">[31]</ref>. Recent efforts by Pardos et al. have focused on promoting serendipity in the exploration of enrollment options in largely elective academic programs <ref type="bibr" target="#b51">[51]</ref>. In previous work, we investigated how a tool that presented courses' historical data and grade predictions affects students' enrollment choices <ref type="bibr" target="#b41">[41]</ref>. We found that in the presence of grade predictions, students may be tempted to approach course selection as a grade maximization problem: they tend to choose courses with high potential GPA gain, often disregarding other important factors such as the imposed load or time commitments.</p><p>Nevertheless, when used properly, course recommendation tools provide students with a comprehensive view of their study program, and support them in making enrollment decisions in light of more relevant and personalized options <ref type="bibr" target="#b38">[38]</ref>.</p><p>While the support for students to select courses is extensive, the needs of advisors around course recommendation have received less attention. LISSA <ref type="bibr" target="#b14">[15]</ref>, <software ContextAttributes="used">eAdvisor</software> <ref type="bibr" target="#b52">[52]</ref>, and LADA <ref type="bibr" target="#b25">[26]</ref> are notable examples of tools that seek to support advisors in making more objective course recommendations. LISSA and <software ContextAttributes="used">eAdvisor</software>'s main goal is to support the dialogue between students and advisors through visual descriptive dashboards, following principles from the Visual Learning Analytics community <ref type="bibr" target="#b58">[58]</ref>. LISSA also provides graduation time predictions that advisors can consider when recommending courses. The support of <software ContextAttributes="used">eAdvisor</software> includes automatic identification of students who are unlikely to succeed in their major, enabling advisors to provide additional academic support on enrollment options. Beyond descriptive data, LADA assists academic advisors through prediction models that enable comparative analyses. When advisors build a semester plan for a given student, LADA uses clustering techniques to find similar students (according to advisee's grades and the selected courses). The tool then predicts the advisee's "chances of success" and academic risk from the data of similar students that made similar enrollment decisions at comparable points of their degree.</p><p>The use of LISSA and LADA has been studied with several samples of advisors from HEIs with varied advising models. The results of these studies show use differences between experienced and inexperienced advisors <ref type="bibr" target="#b14">[15]</ref>. Our work builds upon-and expandsthese observations by investigating how a grade prediction tool shapes advisors' strategies, and how these strategies vary according to the advisee's academic profile.</p></div>
<div><head n="2.3">AI-supported Human Decision-making</head><p>The use of AI-based solutions for course selection has motivated a prolific body of research on how these solutions affect people's decision making and shape their attitudes, perceptions, and behavioral outcomes <ref type="bibr" target="#b34">[35]</ref>. Aspects such as attachment, trust, fairness, transparency, and interpretability of AI-based tools are growing in importance and attention <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b21">22]</ref>. These factors are also relevant for data-based tools designed to support students and advisors in course selection and recommendation. In particular, transparency in the predictions provided by automatic advising is required in order to increase confidence <ref type="bibr" target="#b25">[26]</ref>. Some tools offer transparency by explaining the reasons behind a given prediction. Yu et al., for example, explored ways of explaining students why they had been recommended a particular set of courses using different types of explanations, each designed with a different level of personalization <ref type="bibr" target="#b62">[62]</ref>. Other efforts have taken a more visual approach in explaining the factors that play a role in the outcome of grade prediction models for course selection and recommendation <ref type="bibr" target="#b41">[41]</ref>.</p><p>The factors that shape people's perceptions and attitudes toward AI-based tools for academic advising are more critical when such tools seek to replace the role of the advisors, mainly for repetitive tasks-such as a course recommendation. This kind of tools are described under the term "virtualized advising", defined by Thompson et al. as "a means by which advising is provided through an impersonal means such as via an online advising program" <ref type="bibr">[56, p. 13]</ref>. Along these lines, recent work has proposed data-based tools that automatically determine the set of courses a student should take in an upcoming semester (e.g., <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b43">43]</ref>). Some of these tools take specific designs such as chatbots (e.g., <ref type="bibr" target="#b33">[34,</ref><ref type="bibr" target="#b35">36]</ref>). Although promising, most of these tools are still at a very early stage and their benefits to real-world settings are yet to be seen. One of the main drawbacks of these tools is that their AI models can hardly incorporate factors outside a student's academic life that are, nevertheless, relevant to make appropriate enrollment decisions and recommendations. Thus, they can hardly replicate the benefits of person-to-person academic advising.</p><p>Our study surfaces some aspects of the design of AI-based tools for academic advising that may be perceived by advisors as problematic. This comprises trust in the predictions and concerns about how such tools could negatively influence the students' enrollment motivations.</p></div>
<div><head n="3">RESEARCH CONTEXT AND RESEARCH QUESTIONS</head><p>Our research takes place within an Engineering-oriented public university with a well-established academic advising system for its 32 undergraduate programs. The study curricula of those programs are relatively rigid, that is, students have some elective credits, but most of the courses are compulsory and cannot be avoided. Students can, though, take a course anytime they wish, provided that they have passed the course's prerequisites. In the remaining of this section, we provide details about the advising system of our research site, as well as its current technological support for the student-advisor meetings. We also describe a grade prediction tool that is part of an ongoing effort to improve the student-advisor dialogue. The eventual deployment of this tool motivates the research questions addressed in this paper.</p></div>
<div><head n="3.1">The Academic Advising System</head><p>Our study site has a decentralized advising model in which the advising responsibilities are delegated to the university's academic departments. The departmental advisors are faculty members, who are assigned up to 40 advisees every term, depending on their workload.</p><p>All students are assigned an academic advisor-that may change throughout their student life-, but advising sessions are not mandatory for everyone. Meetings with advisors are compulsory twice every term for specific groups of students: (i) first years, (ii) students with a GPA below the average GPA of their academic program, (iii) those who failed a course in the previous semester, and (iv) those who must retake a previously failed course. The first advising meeting takes place two weeks before the term starts, and is mainly devoted to address enrollment. Hence, the expected outcome of this meeting is a course set recommendation for the students' forthcoming term. More often than not, this meeting also provides information about the contents of the recommended courses and guidance on the students' time commitments and strategies to deal with the term's load. The second advising session takes place right after the midterms and is meant to monitor the students' performance and to discuss matters that may be affecting their well-being. Students who are not required to attend the advising sessions can still do so if they want to. The academic advising system was originally designed for inperson meetings that used to take place mostly at the advisors' office. However, students could request remote and asynchronous advising sessions. The COVID-19 pandemic forced advisors and students to conduct the meetings over conference software. Before the pandemic, the vast majority of advising meetings were conducted in-person. However, nowadays, most advising sessions are conducted remotely.</p></div>
<div><head n="3.2">Current Support</head><p>During their meetings with students, the advisors of our research site use an in-house web tool that provides access to the academic history and the records of previous advising sessions of their assigned students. The tool also presents relevant statistics (e.g., current GPA, number of failed courses, academic progress) and depictsvia line charts-the student's academic evolution, namely, passed and failed courses per academic term. This tool also allows advisors to post their time availability and students to book advising meetings.</p><p>During the term planning meetings, advisors use the tool to recommend a set of courses to students. While discussing the students' enrollment options, advisors compose a course set by dragging textual elements that represent the advisee's available courses. Advisors can store their recommendation in the tool and retrieve it in future meetings. Students, however, do not have access to the recommendation after the meeting is over.</p></div>
<div><head n="3.3">A Grade Prediction Tool</head><p>The university of our research site is currently taking steps to improve the dialogue between students and advisors through technology. One of these efforts is a tool named <software ContextAttributes="used">iCoRA</software> <ref type="bibr" target="#b12">[13]</ref>, which enables the composition of course sets from those available for enrollment. By capitalizing on historical data about the different courses in the study program, <software ContextAttributes="used">iCoRA</software> provides performance predictions for each of the recommended courses.</p><p>The development of <software>iCoRA</software> is motivated by a growing student population that imposes an ever-increasing load on the advisors. It also responds to the fact that when making course enrollment decisions, students are exposed to a large ecosystem of non-official-and sometimes contradicting-information about the courses they could enroll in. For instance, according to an in-house inquiry conducted at our research site, 83% of the students in the CS department ask other fellow students about the difficulty of the courses, and the reputation of the lecturers. Since the feedback obtained by the students can vary greatly depending on whom they ask, the tool counterbalances the influence of the vox populi by providing a more objective view that allows for more informed decisions. On the advisors' side, the tool pursues several goals: 1) providing advisors with data-based evidence to better justify their course recommendations; 2) reducing the subjective bias that advisors may introduce in their enrollment recommendations due to their learning/teaching experience (e.g., regarding the perceived difficulty of a given course); and 3) making advise more consistent across students and advisors-as the same student may receive different advise from different advisors, and the same advisor may make different enrollment recommendations to students with quite similar academic histories. Another important goal of <software ContextAttributes="used">iCoRA</software> is to optimize the advising process, which often incurs time and financial resources from HEIs.</p><p>Figure <ref type="figure" target="#fig_1">1</ref> shows <software ContextAttributes="used">iCoRA</software>'s interface. The composition of course sets takes place via drag and drop operations. As an advisor drags courses from the advisee's academic program (Figure <ref type="figure" target="#fig_1">1</ref>.a) onto the grade prediction panel (Figure <ref type="figure" target="#fig_1">1</ref>.b), the tool updates the predicted grades for the chosen courses. Predictions are computed using machine learning models that take into account the student's performance on previous course enrollments (specially the courses' prerequisites), their success and failure history, and the chosen total workload in hours per week-based on the number of study hours of each course specified by the curriculum. The predicted grade for each course is shown as a range on a horizontal scale between 0 and 10, according to the university's grading system. This range is computed via quantile regression with gradient boosting trees. This provides us with three predictions, namely a lower bound, an average prediction, and an upper bound that we use to construct the ranges depicted by the tool. The lower and upper bounds of the individual course predictions are used to provide optimistic and pessimistic estimates for the GPA the student would obtain if the predictions became true. This GPA estimate is shown above   the individual course predictions (Figure <ref type="figure" target="#fig_1">1</ref>.c). The tool also enables access to the courses' historical information such as the distribution of grades and the historical success and failure rates (Figure <ref type="figure" target="#fig_1">1</ref>.d).</p><p>The tool also shows the academic load imposed by a given set of courses (Figure <ref type="figure" target="#fig_1">1</ref>.e).</p><p>To promote transparency in the prediction process, <software ContextAttributes="used">iCoRA</software> also provides explanations for the predicted grades. These explanations convey how much the inputs to the tool's predictive models contribute to its outputs. Advisors can access these explanations through the Why button associated to a grade prediction (Figure <ref type="figure" target="#fig_3">2</ref>.a). Clicking on this button opens a modal window (Figure <ref type="figure" target="#fig_3">2</ref>.b) showing a pie chart that depicts the relative contribution of the features used by the tools' prediction models. These explanations are provided to make advisors aware of the factors that could impact a student's performance in a given course. In light of these explanations, advisors could, for example, reduce the academic load imposed by a given set of courses when this feature exhibits an important negative influence on a predicted grade.</p><p>The features of <software>iCoRA</software> respond to the perceived needs of the university's academic advisors. Its design is the result of an iterative design process that comprised several sketching and brainstorming meetings with academic advisors, students, as well as education, visualization, and HCI researchers. The design process also included several critique sessions in which stakeholders looked at earlier versions of the tool and provided feedback for subsequent iterations.</p><p>The effects of <software ContextAttributes="used">iCoRA</software> on students, when they use it for term planning, have been previously investigated and reported in <ref type="bibr" target="#b41">[41]</ref>. However, the tool's potential benefits and drawbacks in supporting course recommendations from the advisors' perspective are still unknown. This motivates the following research questions (RQs):</p><p>RQ1: What are the effects of grade predictions on the advisors' approach to course recommendation? RQ2: How does the advisee's profile impact the advisors' strategy to recommend courses?</p><p>The study we report below aims to answer these questions in the interest of deploying <software>iCoRA</software> in a real-world setting.</p></div>
<div><head n="4">METHODOLOGY</head><p>We conducted a study to investigate the influence of <software>iCoRA</software>'s grade predictions on academic advisors when assisting students with different performance profiles in planning their upcoming term.</p></div>
<div><head n="4.1">Participants</head><p>We sent email invitations to recruit academic advisors of a Computer Science (CS) undergraduate program with over 600 students. Approximately 35% of these students must attend advising sessions every term for one or more of the reasons explained in Section 3.1. </p></div>
<div><head>RESEARCH METHODS FOR COMPUTER SCIENCE x</head><p>The aspects that most impact the predicted performance for the</p></div>
<div><head>RESEARCH METHODS FOR COMPUTER SCIENCE course is shown below.</head><p>Hover over the pie chart segments to reveal the feature's name.</p><p>Features with a positive impact Features with a negative impact Out of the 29 advisors of the CS program, 15 volunteered to participate in the study (8 female; 7 male; 34-59 years old; median age 41). These participants were lecturers with significant academic advising experience (median 6 years) who assist between 5 and 40 students every academic term (average 17). Most advisors (n=11) reported dedicating around 15 minutes per advising session. However, the advisors also remarked that the meetings' duration vary significantly, depending on how much guidance students need.</p></div>
<div><head n="4.2">Three Student Profiles</head><p>We asked advisors to use <software ContextAttributes="used">iCoRA</software> to recommend courses to three fictional students who were about to enroll in their fifth semester. The students exhibited distinguishable academic performance profiles, namely low, average, and high GPA (6.50, 7.50, and 8.74, respectively). The GPA of the average-performing student was equal to that of the overall CS study program. We decided the GPA of the other student profiles based on what an outstanding and a struggling student usually mean within the program. Besides their GPA, the students had different academic histories: the high-performing student had never failed a course, while the opposite was true for the other two. The average-performing student had failed 3 courses (once each), while the low-performing student had failed a total of 17 courses (some in multiple occasions). Figure <ref type="figure" target="#fig_4">3</ref> shows the academic history of our three fictional students as shown in <software ContextAttributes="used">iCoRA</software>. The red rectangles that appear behind some of the depicted course represent failed enrollment instances.</p><p>We built these three academic profiles to simulate three types of students that advisors usually encounter in their advising sessions. For each student profile, the advisors' task was to make recommendations among the same set of 10 available courses for enrollment.</p></div>
<div><head n="4.3">Adapting iCoRA</head><p>To address our research questions, we adapted <software ContextAttributes="used">iCoRA</software> to provide our participants with the data they normally have at hand during the advising sessions with students. This included: the advisee's enrollment history, their progress, and their performance evolution depicted through line charts (see Figure <ref type="figure" target="#fig_5">4</ref>).</p><p>These modifications made <software>iCoRA</software> and the university's current advising tool comparable in terms of functionality, except for three additional features: <software ContextAttributes="used">iCoRA</software> also provides course historical information, academic performance predictions, and explanations thereof. For all of this, <software ContextAttributes="used">iCoRA</software> takes a visual approach. For instance, the student's academic history as well as the courses available for enrollment are organized into a grid of visual elements with connections representing course prerequisites. This visual approach is in contrast to the current advising tool, which is mostly based on HTML form elements.</p><p>We also created a set of hardwired performance prediction models for the courses available for enrollment. The models were designed to comply with the courses' historical difficulty, with their actual workload, and with the observation that, overall, higher workloads lead to worse academic performance among students. In particular, the relationship between workload and predicted grade is piece-wise linear with negative slopes, and is parameterized by two thresholds that define the change in the function's slope. These thresholds correspond to the inflection points in the curve of the example shown in Figure <ref type="figure">5</ref>. In our study, each course had three different prediction models, which accounted for the difference in expected performance for the low-, average-, and high-performing students. These models had different intercepts (the predicted grade at zero workload), different slopes, and thresholds, and were designed to never predict grades lower than 5.5 or higher than 10. The explanations for the predicted grades, available through the prediction's Why button, are computed with SHAP <ref type="bibr" target="#b36">[37]</ref>, a featureattribution explanation method based on coalitional game theory. We run the explanation module on all the inputs traditionally used by <software ContextAttributes="used">iCoRA</software>, namely the advisee's academic history, the selected courses' prerequisites, and the chosen academic load.</p></div>
<div><head n="4.4">Procedure</head><p>We conducted individual experimental sessions using video conferencing software to test and interview participants remotely. Each study session took approximately 60 minutes and consisted of the following activities:</p><p>Introduction to <software>iCoRA</software>. After providing consent and filling out a questionnaire about demographics and academic advising experience, each participant watched a 6-minute video that explained <software ContextAttributes="used">iCoRA</software>'s GUI. The video described how to compose sets of courses, as well as the tool's performance predictions and its explanations. After watching the video, participants were given the opportunity to ask questions about the tool's functionality.  Course recommendation tasks. Advisors were then asked to use our adapted version of <software ContextAttributes="used">iCoRA</software> to recommend a course set for the upcoming academic term to each of our three fictional students. Advisors were told that these advisees would have online access to the course recommendations made during the study session. No restrictions were specified about the number of courses advisors were allowed to recommend or about the time they could spend in the task. We shuffled the students' order across participants to reduce order effects.</p><p>Closing Interview. The experiment concluded with a semi-structured interview in which we asked participants about their perspectives on <software>iCoRA</software>. This included their general opinion on the tool, perceived benefits and drawbacks, and their thoughts on an eventual deployment of the tool at their institution.</p></div>
<div><head n="4.5">Data Collection, Statistical Tests, and Qualitative Analysis</head><p>We recorded the courses that each student was advised to take, including any partial sets that the advisors built with <software>iCoRA</software> while making their recommendations. We characterize these course sets by their incurred workload and GPA gains. We also recorded how frequently and how long advisors engaged with the Why button's explanations of the predicted grades.</p><p>To verify if the student's profile had an impact on the nature of the recommendations, we conducted a Kruskal-Wallis H test among the three groups of observations drawn from each student profile (i.e., course set's workloads, GPA gains, and engagement with the explanations). The null hypothesis of the Kruskal-Wallis H test is that the median of the population is the same, regardless of the student Welcome advisor ANONYMOUS ANONYMOUS profile-otherwise it is said that some profiles stochastically dominate others. When the test revealed stochastic dominance (with a significance level ùëù &lt; 0.05) from at least one of the observation groups, we conducted a post-hoc pairwise Dunn's test with Bonferroni correction to detect the pairwise dominance relationships between the profiles.</p></div>
<div><head>General information of ANONYMOUS STUDENT</head><note type="other">Failed Passed</note><p>We also captured 312 minutes of the participants' advising process in the form of video screen captures. We audio recorded the closing interviews (181 minutes in total) and fully transcribed them. Using an inductive, thematic analysis technique <ref type="bibr" target="#b10">[11]</ref>, we structured the participants' remarks from the interviews. Initially, two authors coded at least seven interviews independently. This initial coding sought to identify emerging patterns in the advisors' strategies and rationale for course recommendation, as well as their vision and the perceived benefits of the tool. In a second stage, we redistributed coding assignments so that each interview was analyzed by at least two different researchers. Through regular meetings, the research team iteratively revised the initial topics and refined higher-level themes that emerged from the data. Figure <ref type="figure">5</ref>: Predicted GPA as a function of the workload for the Software Engineering II course. In our study, for all the courses available for enrollment, the predicted loss in GPA points due to an additional hour of workload depended on whether the advisee had a low, average, or high overall workload.</p></div>
<div><head>High-performing student</head></div>
<div><head>Student performance</head><p>No </p></div>
<div><head n="5">FINDINGS</head><p>This section presents the findings of our study with the academic advisors. We begin describing the quantitative results derived from the advisors' decisions and interactions with <software>iCoRA</software>. This is followed by the results of our thematic analysis of the interviews.</p></div>
<div><head n="5.1">Quantitative Analyses</head><p>We first describe and compare the advisors' recommendations for each of the student profiles of our experiment. This comprises (a) an analysis of the academic load of the recommendations for each profile operationalized by the total number of study hours per week, the number of courses, and the predicted GPA gain; and (b) a visualization of frequent combinations of courses recommended by the advisors. In a second stage, we analyze (c) the time spent on the recommendation task, (d) the total number of drag-and-drop steps carried out before making a recommendation, and (e) the time invested in reading the tool's explanations for the predicted grades.</p></div>
<div><head n="5.1.1">Advisors' Recommended Load.</head><p>A natural way to characterize the recommendations made by the advisors is to compute the study workload incurred by those recommendations. This can be operationalized by the number of recommended courses and the total number of study hours (per week) of those courses. We did not consider the grades and GPA predicted by <software>iCoRA</software> in this analysis because, due to our experimental protocol, the prediction models across courses and student profiles had different difficulty levels: they had a different intercept (i.e., predicted grade at zero workload) and a different slope (i.e., the models penalized the grade differently for each additional hour of work). This makes absolute GPA comparisons meaningless. That said, we can indeed compare predicted GPAs among student profiles if we control for the difficulty of the prediction models used by a given advisor. To do so, we report the corrected gain in GPA of a recommended set of courses, denoted by Œì. Given a set of courses ùê∂ùë† recommended by a given advisor to a student ùë†, the corrected gain in GPA is computed as</p><formula xml:id="formula_0">Œì ùë† = ùõæ ùê∂ ùë† ùõæ ùê∂ avg (gpa ùê∂ ùë† opt -gpa ùë† ),</formula><p>where: gpa ùë† is the advisee's initial GPA (6.50, 7.50 or 8.74 for the low-, average-, and high-performing student respectively), gpa C s opt is the GPA's optimistic prediction 3 (see Section 3.3) if the student took the courses in ùê∂ùë† , and ùõæ ùê∂ ùë† ‚áëùõæ ùê∂ avg is the correction factor. 3 The gains for the GPA's pessimistic prediction are always negative.</p><p>The term ùõæ ùê∂ ùë† &lt; 0 is a measure of the difficulty of ùê∂ùë† defined as the average loss in GPA points for every hour of additional workload for the courses in ùê∂ùë† . This value is computed as the average slope of the linear models used to predict each of the grades in ùê∂ùë† given the total number of study hours. To account for the fact that ùõæ ùê∂ ùë† is different across the different student profiles, we divide it by ùõæ ùê∂ avg , the average difficulty of the models used by the same advisor for the average-performing student. That way, we make the GPA gains comparable across student profiles for the same advisor.</p><p>The results of this study are reported in Table <ref type="table" target="#tab_3">1</ref>, where we can observe that on average, advisors assigned lower workloads to the low-performing student. That said, we could not reject the null hypothesis of the Kruskal-Wallis H test for the total hours and for the number of courses. We can also see that the GPA gain is positive only for the low-performing student, i.e., the advisors managed to increase the GPA of the low-performing student, whereas for the other profiles the recommended set led to a (very) slight performance drop. This is confirmed by the Kruskal-Wallis H test that reveals statistical dominance (ùêª (32) = 32.70, ùëù &lt; 10 -7 ). The Dunn's posthoc test, reported in Table <ref type="table" target="#tab_4">2</ref>, shows a significant difference between the low-performing student and the other advisees. This suggests that the advisors not only focused on protecting the low-performing student from high workloads but also took more care of improving their GPA. Similar trends can be observed when looking at the non-corrected GPA gain gpa ùê∂ ùë† optgpa ùë† (although the values are not the same). These results are in line with the comments of some of the advisors who were rather optimistic about the grades of the high-performing student despite the predicted decrease in the advisee's GPA (see Section 5.2).</p></div>
<div><head n="5.1.2">Frequently Recommended Courses and Courses Combinations.</head><p>To identify "popular formulas" within the advisors' recommendations, we conducted an analysis based on course frequency, itemset mining, and agreement. Figure <ref type="figure" target="#fig_7">6</ref> shows a frequency ranking of the different recommended courses per student profile. The figure reveals that the course Entrepreneurship and Innovation was overall the most frequently recommended-10 out 15 times for the average performing student, 11 times for the other students. This may be explained by the fact that this course is, albeit time-consuming,  usually perceived as easy for CS students. This makes it a good bet for advisors. The Web and <software ContextAttributes="used">Mobile Apps Development</software> course was also a popular choice: it was recommended 12 times to the average-and high-performing students, and 9 times to the lowperforming student. This makes it the most recommended course for the average-performing student, and the second most popular suggestion for the other students. This probably has its roots on the course's perceived practical value. One of the advisors defined it as "a door to the job market" [P15] in reference to the observation that students can capitalize on the skills acquired immediately after passing this course. Despite some general trends in the selection of the courses, we also observed trends that depend on the student's profile. For instance, the Algorithm Analysis course ranked the most popular in the recommendations for the high-performing student (13 out of 15 times), whereas it was recommended only 5 times to the lowperforming student-always in combination with Web and <software ContextAttributes="used">Mobile Apps Development</software>. As stated by one of the advisors, this course is theoretical and requires students to work hard. Conversely, the Information Security course was recommended 6 times to all students except for the high-performing one, who got it recommended only once. Advisors may have not prioritized this course as it is not the prerequisite of any other.</p><formula xml:id="formula_1">low</formula><p>Finally, we conducted an agreement analysis based on the Jaccard coefficient. If ùê∂ 1 and ùê∂ 2 are two sets of courses recommended to the same student by two different advisors, then the Jaccard coefficient ùí• (ùê∂ 1 , ùê∂ 2 ) quantifies the consensus between those recommendations. We compute ùí• (ùê∂ 1 , ùê∂ 2 ) as the number of courses recommended by both advisors divided by the joint number of recommended courses, put differently:</p><formula xml:id="formula_2">ùí• (ùê∂ 1 , ùê∂ 2 ) = ‚ãÉÔ∏Ä ùê∂ 1 ‚à© ùê∂ 2 ‚ãÉÔ∏Ä ‚ãÉÔ∏Ä ùê∂ 1 ‚à™ ùê∂ 2 ‚ãÉÔ∏Ä</formula><p>Identical recommendations yield a Jaccard score of 1.0, whereas values closer to 0 denote high disagreement. We computed ùí• (ùê∂ 1 , ùê∂ 2 ) for every pair of recommendation sets leading to 15√ó14 ‚áë2 = 105 pairs of recommendations (recall that the score is commutative) per student profile. We report the average Jaccard score in Table <ref type="table" target="#tab_5">3</ref>. The results suggest a trend towards disagreement for the low-performing student, i.e., ùí• (ùê∂ 1 , ùê∂ 2 ) = 0.34, whereas, for the high-performing student, each pair of advisors agreed, on average, almost on half of the courses that would be suggested to the student. In all cases, the standard deviation is significant and almost constant.  <ref type="table">4</ref>: Time spent and number of actions (addition of removal of courses) before submitting a recommendation.</p></div>
<div><head>High</head></div>
<div><head n="5.1.3">Interaction</head><p>Effort of the Recommendation Task. We also analyzed the effort invested by the advisors in the recommendation for each student profile. We characterize the advisors' effort in terms of a) the time they interacted with <software ContextAttributes="used">iCoRA</software> before submitting a course set recommendation, and b) the number of drag and drop operations this interaction incurred. Table <ref type="table">4</ref> reports the average values of these metrics across all advisors. The values suggest that, on average, the advisors spent more time making a recommendation for the low-performing student-which may explain why they tended to disagree more on the courses this student should take. A similar trend can be observed for the number of actions-addition and removal of courses via drag-and-drop operations-carried out during the advising session, so to say, that the less performing the student is, the more effortful the recommendation tends to be. Despite these results, we could not reject the null hypothesis of the Kruskal-Wallis H test, very likely due to the high standard deviation of these observations.</p></div>
<div><head n="5.1.4">Interest in Explanations.</head><p>We configured <software ContextAttributes="used">iCoRA</software> to log the advisors' interactions with the explanations of the predicted grades for the individual courses. While almost all advisors (14/15) opened the grade explanations at some point during the recommendation tasks, overall, they showed little interest in this functionality. We registered an average interaction time of 1.28 minutes per advisor (with a standard deviation of 1.02 minutes) during the entire experimentif we exclude the advisor who did not invoke the explanations at all. On average, advisors invoked the explanations 3.16 times during the entire experiment. However, most interactions happened only for one of the three advising tasks. If we consider each of the 45 recommendation tasks, only 19 tasks incurred an interaction with the explanations, with those making an average time of 55.33 seconds (with a standard deviation of 52.78 seconds). Out of those 19 recommendation tasks, 11 saw more than one invocation of the explanations. We remark, however, the high dispersion of the time observations as they span from 10 to 179 seconds. Five interactions lasted more than one minute, and two of them are explained by the fact that the advisors kept the explanations open while interacting with the experimenter. In the other three cases, the advisors took the time to understand the explanations and thought out loud. Finally, we also notice that the low-performing student sparked more interest in the explanations, as shown in Table <ref type="table">5</ref>. This goes in line with the longer recommendation time invested by the advisors when dealing with this student. That said, these results must be taken with a grain of salt given the high variance exhibited by our observations.</p></div>
<div><head n="5.2">Qualitative Analysis</head><p>We present in this section the findings of our qualitative analysis of the interview data and the video recordings of the advisors' interactions with <software>iCoRA</software>. These observations provide a broader interpretation of the quantitative results presented earlier, as they uncover subjective factors that advisors brought into their decision process and their perspectives on <software ContextAttributes="used">iCoRA</software>.</p></div>
<div><head n="5.2.1">General Perspectives and Perceived</head><p>Benefits. With no exception, all advisors were enthusiastic about the perspective of having at hand a tool like <software ContextAttributes="used">iCoRA</software>. Some explicitly stated appreciating its functionality in comparison to the tool they currently use to conduct the advising sessions: "[<software ContextAttributes="used">iCoRA</software>] could be extremely useful because it goes one step further than what currently exists [for the advising sessions]" [P11]; "There was information that I did not know before and now, because of the tool, I do. So, the tool helps me contrast the ideas I had in mind about certain courses of our curriculum." [P15]. The most recognized advantages were centered around the data aspects of the tool: "It gives us, advisors, statistics and historical data to make better decisions" [P02]; "Because of the data it provides, this tool could make students understand more clearly about whether or not they could fail a course." [P03]. In particular, the tool's grade predictions were seen as instruments to provide students with more objective recommendations: "Making blind decisions never has advantages. I think with a tool like this, students will get a more 'educated' recommendation" [P09]; "Based on the data, I can explain to the student, 'this is the probability that you will fail'. I can provide advise based on real data [...] to convince the students [which courses are appropriate to take]" [P10]; "This tool would allow me to provide more well-founded recommendations. In turn, students will receive more accurate information based on data and not only on the experience of the advisor" [P09]; "The data used by the tool makes the advise we can provide slightly stronger"  <ref type="table">5</ref>: Advisors' engagement with the explanations per recommendation task and student profile. Average values are provided with the standard deviation in parentheses for the times.</p></div>
<div><head>5.2.2</head><p>Advisors' approach to recommending courses. Our video and interview analyses revealed that advisors approached course recommendation mainly by considering their experience and personal perspectives on the courses. All advisors looked at the grades predicted by <software>iCoRA</software> at some point during the study session, but the predictions were not taken into account in all the course recommendations tasks.</p><p>When looking at the predictions, advisors considered both the grade of each selected course and the potential effect of the courses on the student's GPA. The latter was the main criterion in at least one course recommendation for 13 advisors: "I was trying that their GPA did not decrease; I did not really pay attention to the courses' individual grades." [P10]; "I left the 'Algorithm Analysis' course out because it was going to decrease the students' GPA more significantly. So, I decided to replace it with the 'Entrepreneurship and Innovation' course." [P05]; "I went for the course sets that gave the student the highest GPA gain. The courses' individual grades the tool predicted didn't help me much [to make a decision]. My goal was that the student improved their GPA." [P08]. In all these instances advisors described this GPA-driven strategy as their usual approach to course recommendation.</p><p>When prompted on which other factors they considered, most advisors (12/15) mentioned the order the courses appear in the study program. As stated earlier, the curriculum we worked with is relatively inflexible (in contrast to many Global North universities, that include a large number of elective credits). Hence, students do not really have much room for optional courses. Also, as courses have set prerequisites, there are few paths students can take at a given point of their academic history. In such a context, advisors considered course order an important criterion to decide which courses recommend: "I consider the logical relationship between courses and their order in the curriculum." [P11]; "I tried to make them take the courses in an ordered fashion. In my opinion, the courses that are not prerequisites of others could wait." [P10].</p><p>Regardless of whether they closely observed the predicted grades, the impact on the students' GPA, or the order of courses in the curriculum, all advisors tried to balance the load of the sets they suggested: "I would suggest them to take two hard courses and two easy ones." [P11]. Balancing the term's academic load was particularly important when making course recommendations to the lowperforming student: "Because of the GPA this student has, I would go for not recommending them a course set with a high load." [P13]; "When they have a GPA like this, one normally does not recommend them to take more than four courses [per term]." [P08]. As our quantitative results show, advisors spent on average more time trying to assemble a course set for this student. In most cases, this was due to repeated attempts to find a set with minimal load and low negative impact on the student's GPA. One advisor even tried to find "easy" courses to counterbalance the load imposed by science courses: "None of these courses is easier than 'Entrepreneurship and Innovation'! [...] And there are no more humanities courses<ref type="foot" target="#foot_3">4</ref> available for this student to take!" The strategies all advisors took to recommend courses to the low-performing student are in stark contrast to those applied for the other student profiles of our experiment. In the case of the highperforming student, for example, most advisors were willing to recommend high-load sets even in the presence of not-too-optimistic predictions: "It's going to be a complicated term but since this is a good student, I'd also recommend them the 'Information Security' course-despite the fact that it may decrease their GPA because it will be a busy term." [P10]; "I paid attention to the GPA of all the students. However, there was one student who had a very good GPA, so I recommended them to take the entire row of courses [as they appear in the visual depiction of the curriculum]." [P13]; "I always tried to keep a healthy balance between performance and academic load. However, because this was a good student, there is a guarantee that they will be able to get through their [high-load] term." [P09].</p><p>Our inquiries also show that advisors relied heavily on their experience and knowledge of the curriculum's courses. 9/15 advisors overlooked or decided to ignore the courses' historical and official workload information. These advisors suggested that their experience was enough to have a clear idea of the difficulty level of each course: "From experience, one already knows which are the courses in which students usually have problems." . Four advisors relied so much in their experience that they completely ignored the predictions of the tool and used it only to compose sets and send their recommendations to the students: "I would make my recommendations based on my experience, because [as advisors] we know the stuff." [P12]. In these cases, advisors reviewed the student's academic history thoroughly to get a sense of the student's academic weaknesses and strengths. This information was also important to establish the students' affinity to specific types of courses and to identify course combinations that proved problematic in the past: "When there are failures, I would like to know which courses the student passed and which ones they failed. For me, it is not enough to know how many they passed. I need to know if the problematic courses came from one branch [of the curriculum] or another, or if the student needs to take a course for a second or third time." [P12]. Two advisors used the student's academic history to know how many courses the student took in previous semesters and adapt the load accordingly: "The fact that the student took only 4 courses [in the previous term] suggests that they reduced the number of courses either due to the pandemic, to family issues, or to work duties [...] Based on that and assuming this situation will not change, I would recommend them between four or five courses." [P07].</p><p>Our analysis also reveals that advisors had an already wellestablished idea of the relative importance of the courses. Importance was often defined in terms of the contents covered in a course and their applicability in practical matters of a student's life. For example, some courses were considered important for the students who, after that academic term, will be applying for internships or jobs. Such criteria prevailed, even if we consider that students are not obliged to take the courses in a specific order, and even when the tool presented pessimistic predictions: "This student must take the 'Web and <software ContextAttributes="used">Mobile Apps Development</software>' course. It doesn't matter that it has a low grade predicted in both course sets." [P10]; "Web Development is one of the most useful courses for students" [P01]. Besides the short-term professional perspectives the Web and <software ContextAttributes="used">Mobile Apps Development</software> course offers, this course is also a co-requisite <ref type="foot" target="#foot_4">5</ref> of Software Engineering II. This type of relationship between courses also influenced their perceived importance: "Also, I find it important that the student takes the 'Software Engineering II' course [this term] because otherwise, they will be in trouble." [P01]. The latter quote makes reference to the fact that the courses Software Engineering I and II have a common group final project, hence it is important that members of the same group take the courses at the same time.</p><p>We saw some level of iteration during the composition of the course sets. That is, in eight instances, advisors composed more than one set of courses and assessed their advantages and disadvantages for the students in light of the tool's predictions. Having said that, we observed little engagement with explanations and with the courses' historical information. Advisors trusted their guts when it came to characterizing a course, regardless of how the tool presented it. They considered some courses easier than others but not because of the information provided by the tool. Rather, it seems like they had a preconceived opinion on which courses were easier or harder than others. Also, the workload was mostly observed in terms of the number of courses, not the number of hours a student would have to invest.</p></div>
<div><head n="5.2.3">Advisors' Concerns.</head><p>Albeit largely enthusiastic, our participants' responses to the tool also raised concerns on the implications of adopting <software>iCoRA</software> as part of the university's advising system. The main concerns revolved around how reliable the tool's predictions were and how much they could (and should) be trusted: "It is impossible to know if the predictions will come true or not next term." [P09]; "I do not know the certainty that the prediction will be fulfilled." [P10]. In a few cases, advisors stated not to trust the predictions at all: "I can't really trust this [the tool's predictions]. I just don't think the grades of a group of students can be used to predict the performance of another." [P11]. That said, our video analysis revealed that most advisors assumed that the predictions could be trusted to some extent and that at least for the sake of the experiment, the explanations were consistent with the participants' experience and expectations. These comments, however, suggest that an eventual deployment of <software ContextAttributes="created">iCoRA</software> (or a similar tool) in a real-life setting, will require additional actions and mechanisms to generate trust. One of those mechanisms are <software ContextAttributes="created">iCoRA</software>'s explanations, to which advisors paid little attention as explained earlier.</p><p>One advisor proposed checking whether the students followed the recommendations as a way to evaluate the impact of the tool. The advisor's rationale was that monitoring how closely students followed the counselor's advice could be seen as a proxy of how good the tool is in fulfilling its goal: "We should get some sort of feedback on whether or not the student followed the advisor's recommendation. Students should perhaps state [through the tool] why they decided (or not) to choose the courses that were recommended and the tool could report that to us." [P12]. Some advisors, who advocated for making <software>iCoRA</software> available to the students, also expressed concerns on the implications of doing so. In particular, they reflected on the undesired effects of grade predictions on the students' behaviors and motivations at enrollment time: "The tool could push the students to always focus on their grades and not on what they are going to learn [in a course], as it is purely based on the grades but provides no information about the contents of a course." [P10]. To avoid this, one advisor suggested showing the probability of passing or failing the courses, rather than predicting grades: "I would rather see the probability of the student passing the courses. If there is a 15% chance that the student will pass a course, the tool would show that in red. On the other hand, if the probability is high, over 70% for example, everything would appear in solid green."</p><formula xml:id="formula_3">[P01].</formula><p>The presence of the advisor was seen as paramount to mitigate the potential drawbacks of the tool: "Some students could misuse the tool, especially those who would not know how to interpret what they see. To avoid this, the presence of the advisor is crucial, especially for very young students and for those with no affinity to statistics." [P04]. Along these lines, others also highlighted that the presence of the advisor is needed due to the aspects that any tool or predictive algorithm cannot deal with: "[A tool like this] should not be a replacement of the advisor, because we do more than just recommending courses. There are human aspects that only the advisor can address during the advising sessions." [P04]; "Obviously, we want to understand trends and the tool provides a lot of information for that [...] However, there is no qualitative information [in <software>iCoRA</software>], only quantitative data. The student's personal and emotional problems are not captured by the tool."</p><formula xml:id="formula_4">[P15].</formula><p>Finally, advisors reflected on how the tool would change the duration of their advising sessions. Rather than seeing <software>iCoRA</software> as a tool to make the advising sessions shorter, the general opinion was the tool could indeed make the advising sessions longer, because it could motivate advisors to play around with the grade predictions until finding a course set that satisfies them: "By having the ability to compose several sets, one could spend a lot of time trying to find suitable combinations for the student." [P13]; "Advisors could use the tool to design a plan before the student comes to the advising session. But either way, this implies spending more time." [P10]; "It may take longer to carry out the advising session because there is not a unique path of interaction in the tool." [P04].</p></div>
<div><head>5.2.4</head><p>Supporting the Dialogue Between Advisors and Students. Advisors' statements during the interviews suggest that they deem their role in supporting students' enrollment important. Regardless of the students' academic history, advisors conducted the advising process carefully, were always willing to provide relevant and effective course recommendations that benefit students, and often reflected aloud about the potential impact of their recommendations in the light of the student's circumstances.</p><p>Despite all the effort put into producing recommendations, all advisors, with no exceptions, acknowledged the importance of letting students have the final saying when it comes to selecting courses. For this to happen more effectively, advisors suggested that students should be able to explore the courses' historical data and have access to the tool's predictions before the advising meetings take place: "It would be great if students could come to the advising sessions with an input after having used the tool." [P12]. Rather than delegating the full responsibility of choosing good courses to the students, advisors proposed deploying the tool as a way to make the student-advisor more effective and efficient: "If the tool was available to both students and teachers [advisors], the students could compose and bring [to the advising sessions] their own course sets. This would speed up our dialogue." [P08]; "It would be great if the student could fill in [in the tool] everything before the advising meeting, so that [through the tool] they inform advisors which course sets they are interested in." [P01]; "Students could benefit from a tool like this to explore [their enrollment options] on their own. If they come [to the advising meetings] with a scenario they have built in advance, that could decrease the time needed for the advising sessions." [P04]. Along these lines, some advisors also acknowledged the need for mechanisms to motivate students to play with the tool: "We could encourage the students to use the tool by making its use a prerequisite for the advising sessions."</p><formula xml:id="formula_5">[P14].</formula><p>Some advisors suggested a mixed approach in which the tool provides an initial recommendation that can be later discussed by both parties during the advising meetings: "The tool could say 'this is the most favorable scenario' and it should be possible for us [students and advisors] to customize that initial recommendation [during the advising sessions]." [P04]. Along the same lines, two advisors suggested that the tool should enable the comparison of different course sets to assess the potential effects of these recommendations in light of their differences: "It seems to me that we should be able to quickly compare and see the differences between sets. You should be able to visualize the differences between the sets one and two." [P01]; "It would be nice if we could see them [the course sets] all at the same time, like the comparisons of items one can do when shopping online, in which it is possible to identify differences among them." [P04].</p><p>All these comments highlight <software>iCoRA</software>'s potential to make the advisor-advisee dialogue more effective, without replacing the advisors and without overriding the students' interests in, and affinities to, specific courses.</p></div>
<div><head n="6">DISCUSSION</head><p>Our discussion is guided by the research questions formulated in Section 3, about the effects of grade predictions (RQ1) and the advisee's profile (RQ2) on the advisors' recommendation approach. We build upon the quantitative and qualitative analyses presented in the previous section and structure our analysis in terms of the advisors' strategy to make recommendations and their attitude towards <software>iCoRA</software>. Last but not least, we discuss the ethical considerations and implications of using grade-based predictions for assisting term planning.</p></div>
<div><head n="6.1">Advisors' Approach</head><p>In regards to RQ1, the qualitative analysis presented in Section 5.2.2 suggests that, in general, the advisors' opinion and experience prevailed over the predictions made by <software ContextAttributes="created">iCoRA</software>. A recurrent behavior during the experimental advising sessions consisted of focusing attention on a course and pondering its effect on the student's performance based on the advisors' knowledge of the study program. Such knowledge comprises three aspects: (a) the advisors' previous exchanges with the students, (b) the advisors' perception of the actual workload of the courses, and (c) the general institutional enrollment guidelines. Thanks to their continuous contact with the students, advisors count on an informed view of which courses are generally challenging. Advisors reconcile that information with what they know about the courses (e.g., contents, theory vs. practical components, presence of group projects, professional perspectives), as well as with their intuition about appropriate enrollment choices. In general, advisors observed on two enrollment guidelines: follow the order of the courses in the study program whenever possible <ref type="foot" target="#foot_5">6</ref> , and balance performance and workload. In many cases, advisors' prior views not only overrode <software ContextAttributes="created">iCoRA</software>'s predictions, but also the course's workload and time commitment information the tool provided. That is, even if a course incurred many hours of work according to the study program, advisors overlooked that information in favor of what they knew about the course's actual demands. This preponderance of the advisors' own view over the tool's predictions stands in sharp contrast to what has been observed for students, who based their decisions mostly on the information provided by the tool, including both the workload and predicted grades <ref type="bibr" target="#b41">[41]</ref>.</p><p>While advisors mostly trusted their intuition, we should not conclude that they completely overlooked the information provided by the tool. In eight cases, the advisors thoroughly examined the students' academic history to build a more precise profile of the advisee. By looking at how many (and which) courses the students had taken the previous semester or by inspecting their performance in some key courses (e.g., courses that require programming skills), advisors built a more specific picture of the student's performance, preferences, and potential circumstances. This aimed to provide personalized advice. Two advisors (P01, P14) hypothesized that one of the students might be working, or going through family issues, from the fact that they had taken few courses in the previous semester. The advisors thus used that information to reduce the workload incurred by their recommendations. While this deductive exercise is presumably a consequence of using fictional students in our experiment, it does confirm that the advisors do consider the students' unique circumstances when recommending courses. By circumstances we mean the students' personal situation, their potential preferences for certain courses, or their preference for particular enrollment strategies such as taking the courses in order, taking a specific number of courses per term, or minimizing the number of semesters.</p><p>But the advisors did not only use <software>iCoRA</software> to overcome the lack of explicit personal circumstances. Our evidence suggests that they did look at the predictions made by the tool as a sort of validation or fine-tuning of their intuition. This validation goes in line with their internalized tendency to preserve the student's GPA-in continuous trade-off with the workload. Some advisors would look at the predicted GPA every time they added a course to the recommendation, whereas others would first apply their personal strategy to compose a recommendation and make small adjustments at the end based on the predicted GPA. Regardless of the recommendation strategy, the advisors based the fine-tuning mostly on the predicted GPA, and looked rarely at the individual grade predictions for the courses. Three advisors (P01, P07, P15) who looked at the historical information of the courses (difficulty, approval rate, and workload) mostly ignored this information in favor of their own opinion about the courses. The remaining advisors completely overlooked the course information component of the tool.</p><p>Concerning RQ2, there is a clear distinction between the strategy applied to advise the low-performing advisee and the other students. Advisors were more willing to take risks for the advisees with better performance profiles because they believed these students could overcome pessimistic grade predictions. This is supported not only by the advisors' comments but also by our quantitative analysis: The GPA gains for the low-performing student were positive in contrast to the other students. While we could not show statistical significance for the differences in advising time among the different profiles, we did observe higher averages and dispersion for the time invested in the low-performing student. This profile also incurred the highest disagreement among advisors, as shown in Table <ref type="table" target="#tab_5">3</ref>.</p></div>
<div><head n="6.2">Advisors' Attitude and Concerns</head><p>Our observations indicate that advisors had an overall positive attitude towards <software>iCoRA</software>. Four of them (P01, P02, P13, and P15) praised the fact that the course recommendation revolves around a visual representation of the curriculum, contrary to the current advising tool. This is particularly important (for both advisors and students) because the study program of our research site is highly structured and restricts the courses the students can take at a given time. Advisors also appreciated the data-supported advising paradigm implemented by <software ContextAttributes="created">iCoRA</software>, which they deem to be a good asset for improving the quality of their course recommendations.</p><p>Most advisors considered that having access to the historical information of the courses and the students' academic performance allows for more informed decisions that would enrich the value of the advising meeting. In that regard, they all agreed that a tool like <software>iCoRA</software> is not meant to replace the advisors, but rather empower stakeholders with pertinent, more objective information beyond the vox populi. All participants insisted on the importance of the advising sessions for students to discuss extra-curricular aspects that nevertheless have an impact on their performance and welfare.</p><p>Despite the overall positive attitude towards <software>iCoRA</software>, the advisors expressed some concerns about the deployment of such a tool to support the advising sessions. The first source of concern was the trustworthiness of the predictions. In most cases, the advisors did not question the validity of <software ContextAttributes="created">iCoRA</software>'s verdicts and assumed it was worth looking at the grade predictions for validating their recommendations. However, two advisors (P09 and P11) did not trust the predictions and argued that such functionality would require extensive validation before deployment. Besides, it is not clear whether the bulk of the advisors did not challenge the predictions because these were given in the context of an experiment-which may also explain the little engagement with the explanations. All this implies that any eventual deployment of the tool will require additional work to guarantee users' trust.</p><p>A few advisors pointed out that the panel containing the historical information of the courses was overloaded and could be simplified by removing some of its elements. This can explain why most participants took no notice of this information and relied on their own knowledge of the study program. Finally the general consensus among advisors is that using <software>iCoRA</software> without prior preparation, would not reduce the duration of the advising sessions because, as we saw for the low-performing student, it encourages the advisors to invest more time and effort to find a well balanced set of courses. That said, such a phenomenon can be easily mitigated if at least one of the actors, either the advisor or the student, prepared one or two possible scenarios to seed the discussion.</p></div>
<div><head n="6.3">Advisors' Vision on a Grade Prediction Tool</head><p>As explained in Section 3.3, the design of <software ContextAttributes="created">iCoRA</software> is the result of an iterative process that involved different stakeholders, including academic advisors <ref type="bibr" target="#b12">[13]</ref>. None of our participants, however, took part in the tool's design process. Thus, our experiment was also a first-time introduction of the tool to some of its future users. This allowed us to capture the advisors' vision of how a tool that provides grade predictions for course recommendation should look like. We discuss here the implications of the functionalities our participants mentioned during the interviews.</p><p>If the tool were to be used by students, including information on the courses' content may bring an important benefit: It would provide students with a fuller picture of their enrollment options and may channel part of the students' focus from the predicted grades toward the courses' learning outcomes. A similar effect could be achieved on the advisors' side by replacing the grade predictions with probabilities of success (or failure). This design could perhaps shift the advisors' attention away from the student's GPA, in favor of a less performance-driven course recommendation strategy.</p><p>The vision of other advisors included logistical aspects of the enrollment process. More specifically, they suggested augmenting <software>iCoRA</software> with the time schedules of the courses. That would make sure that the outcome of the advising session is a feasible recommendation. Otherwise, students face the risk of having to alter their original plan during the enrollment period or have a backup plan in case the recommended course schedule is not feasible. Logistical aspects were also mentioned regarding the organization of the academic advising sessions. Some advisors suggested that to have a starting point for the discussion, the students should have access to the tool before meeting their advisors. Others indicated that the tool could automatically propose sets of courses to the advisorsets of reasonable workloads that, at the same time, optimize for GPA. This functionality, however, does not take into account the student's preferences and skills and would require integrating the courses' timetables.</p><p>Finally, a few advisors advocated for comparisons between course sets in <software>iCoRA</software> to contrast the pros and cons of two (or more) recommendation strategies (e.g., one conservative versus one more challenging), and to provide alternative recommendations to the students-in case they change their minds or run into schedule constraints. In this respect, the comparison could also include course sets prepared by the students before the advising meeting. This would require making <software ContextAttributes="created">iCoRA</software> accessible to the students, and could potentially speed up the advisor-student dialogue.</p></div>
<div><head n="6.4">Ethical Considerations of Assisting Term Planning with Grade Predictions</head><p>During advising meetings for term planning, academic advisors can provide the scaffolding that students need to make better, more informed, and more objective enrollment decisions. Our current research direction is to support this process via grade-based predictions. Grades are meant to convey important information to a wide range of stakeholders <ref type="bibr" target="#b44">[44]</ref>. In the market context of our research site, for example, the students' GPA is carefully considered by potential employers during applicant screening. Using gradebased predictions also has a practical value: given that GPA data is readily available in most HEIs, it can be easily used in the deployment of AI-based tools oriented to assist advisors in recommending courses. However, assisting course recommendation solely through GPA-based predictions could be detrimental to the mission of any academic support system. As with any AI system, grade prediction models may contain biases (e.g., demographic, socioeconomic, ethnic) and may reflect discriminatory behavior toward certain groups <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b40">40]</ref>. Another problematic aspect of grade-based predictions is that they are insufficient to holistically describe a student's performance <ref type="bibr" target="#b55">[55]</ref>. The student's grades cannot reflect their development of learning outcomes, levels of engagement, or learning style <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b47">47,</ref><ref type="bibr" target="#b53">53]</ref>. Finally, grade-based prediction models are insufficient to capture the students' circumstances beyond their academic performance. When considering the students' enrollment options, there are factors beyond their grades that play a role. Aspects such as the students' life goals, extracurricular activities, and family or health circumstances must also be considered when advising students on what courses to take next. Making course recommendations while ignoring aspects beyond predicted grades would fall into what Greller and Drachsler characterize as "potential dangers" of educational data <ref type="bibr" target="#b22">[23]</ref>.</p><p>Previous empirical evidence suggests that students are heavily influenced by grade-prediction tools when making enrollment choices <ref type="bibr" target="#b41">[41]</ref>. That is, students experience a sort of cognitive commitment by which they trust, almost blindly, what the tool predicts about their future performance. We did not observed a similar effect on the advisors who, conversely, tend to rely on their own experience and personal views of the courses. Besides, advisors have a innate tendency to account for the students' extracurricular circumstances, which is vital for proper academic advising. It follows that appropriate human judgment should not be replaced by a grade prediction tool, because advising students implies integrating non-quantitative information that cannot be handled by a tool like <software ContextAttributes="created">iCoRA</software>. The academic advisors' expertise is therefore paramount to address the potential negative impacts of grade-based AI tools while exploiting its virtues for the sake of a more effective student-advisor dialogue.</p></div>
<div><head n="7">LIMITATIONS AND FUTURE WORK</head><p>Our findings are limited by the size and characteristics of our sample. We deliberately set out to test participants from a specific CS undergraduate program. While small (n = 15), our sample included 52% of the departmental advisors of our research site. We acknowledge, however, that this group may not be representative of all potential audiences. In particular, our participants were familiar with prediction models, something that cannot be taken for granted for advisors from other study programs. Further empirical work is still needed to fully understand the influence of grade predictions on academic advisors from other areas. These investigations could take a comparative approach to uncover differences in the advising processes with and without a tool like <software>iCoRA</software>.</p><p>Another limitation of our experimental design is that advisors made course recommendations in the absence of students, something that does not happen in the actual advising sessions conducted at our research site. This meant that our participants had access to the students' academic and enrollment history, without any knowledge of the students' personal circumstances. We decided in favor of this design to study the effects of <software ContextAttributes="created">iCoRA</software> in isolation, without the confounding factor that the students' unique circumstances may have introduced. Along the same lines, in our experiment, we used synthetic student profiles rather than data from real students. We did so to have full control of the experimental performance profiles and to make sure these were clearly distinguishable. This also allowed us to confront advisors to students with the same enrollment options. This study design choice, however, may have an impact on the generalizability and validity of our results, because, in reality, students may exhibit phases of low/high performance, or may have more affinity to specific areas of their study program. It could also be argued that the marked performance profiles we used may have influenced how much advisors focused on the students' GPA during the recommendation tasks. Notwithstanding, we highlight that during the interviews, our participants described the GPA-driven advising strategy as their usual approach to course recommendation. This is not surprising because the institutional policies of our research site rely heavily on the GPA as an academic performance metric. This is illustrated, for example, by the academic advising policies described in Section 3.1. Despite the prominence of the GPA in the current institutional policies of our research site, our participants seemed fully aware of the limitations of this metric as a proxy for academic success, so much so that they deemed their meetings with students as an opportunity to mitigate the GPA's potential negative effects. In this regard, our research work has helped to raise voices for the use of alternative, more comprehensive-and less troublesome-metrics of student performance (e.g., mastery learning approaches <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b24">25]</ref>, portfolios <ref type="bibr" target="#b39">[39,</ref><ref type="bibr" target="#b55">55]</ref>), or simply assessing performance via ungraded tasks <ref type="bibr" target="#b32">[33,</ref><ref type="bibr" target="#b45">45]</ref>. The long-term effects and implications of these changes, however, deserve their own space and are outside the scope of this paper.</p><p>Finally, while our observations suggest that a tool like <software>iCoRA</software> may require the introduction of mechanisms to build trust, our study does not provide answers on how to design or implement those mechanisms. Further research efforts are still needed to investigate the requirements for AI-based tools to be successfully adopted in the context of academic advising and course recommendation.</p></div>
<div><head n="8">CONCLUSION</head><p>This paper investigated the effects that grade predictions have on academic advisors during term planning. To this end, academic advisors of a CS undergraduate program within an Engineeringoriented HEI used a tool that supports the composition of course sets and provides grade predictions and explanations thereof. The advisors used the tool to recommend courses for the forthcoming academic term of three different students. The students had the same set of courses available for enrollment, but they exhibited distinguishable academic performance profiles, namely low, average, and high GPA.</p><p>Our observations show that the advisors' self-reported usual approach to course recommendation is barely influenced by the presence of the predicted grades. Instead, advisors mostly rely on their experience and personal views about the courses' workload, time commitments, and relative importance. So much so that some advisors even disregarded the predictive support of the tool altogether. We also found that advisors, tend to make more challenging recommendations to high-performing students, even in the presence of pessimistic predictions. Our results also suggest that advisors may spend more time interacting with the grade prediction tool when recommending courses to low-performing advisees, attempting to maximize the potential GPA gain for this kind of student.</p><p>These observations highlight the importance of advisors in any academic support system, particularly given previous empirical evidence that shows that students are heavily influenced by grade predictions during course selection. Although advisors valued the predictive support to make more informed recommendations, they also raised concerns about the trustworthiness and validation of the predicted grades. These insights may guide the design and development of new data-based supporting tools for academic advising.</p></div><figure xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: GUI of the grade prediction tool used in our study. The tool shows the courses of the student's academic program (a). When recommending courses, advisors can drag elements from the student's program onto the grade prediction panel (b). In response to these interactions, the tool predicts the student's performance in each of the selected courses and computes the student's GPA (c) that would result if the predictions became true. Clicking a course of the study program reveals its history and general information (d). The tool also shows the weekly load imposed by the composed set of courses (e).</figDesc></figure>
<figure xml:id="fig_3"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Clicking the Why button (a) associated to a grade prediction opens a modal window explaining the reasons behind the predicted grade (b). Interacting with the pie chart displays descriptions of the features and how it influences the grade.</figDesc></figure>
<figure xml:id="fig_4"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Academic history of the student profiles used in our study. Red rectangles behind the courses of the study program represent past failed enrollment instances.</figDesc></figure>
<figure xml:id="fig_5"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: General information GUI component of the modified version of iCoRA used in our study. This interface component provides advisors with information on the student's enrollment history and performance evolution.</figDesc></figure>
<figure xml:id="fig_7"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Courses' recommendation occurrence. The number within the circle representing each course indicates the number of total times it was suggested by the advisors to the corresponding students.</figDesc></figure>
<figure xml:id="fig_8"><head /><label /><figDesc>[P10]. Advisors also based their recommendation on the skills required to pass the courses: "Besides the general academic history, I pay attention to how they [students] have done in Computer Science courses. In particular, in courses that require programming skills [...] If they have performed poorly in those courses, I would exclude similar ones from my recommendation." [P15].</figDesc></figure>
<figure xml:id="fig_9"><head /><label /><figDesc>[P13]; "This [the course's number of hours] is what the curriculum specifies, but not what the students tell me [...] Personally, I would ignore this information." [P15]</figDesc></figure>
<figure type="table" xml:id="tab_3"><head>Table 1 :</head><label>1</label><figDesc>Number of courses and total hours recommended per student profile.</figDesc><table><row><cell /><cell /><cell>. courses</cell><cell /><cell /><cell>Total hours</cell><cell /><cell /><cell>GPA gain Œì ùë†</cell><cell /></row><row><cell /><cell cols="9">Median Mean Std. dev Median Mean Std. dev Median Mean Std. dev</cell></row><row><cell>high</cell><cell>4</cell><cell>4.27</cell><cell>0.96</cell><cell>33</cell><cell>34.0</cell><cell>7.14</cell><cell>-0.03</cell><cell>-0.02</cell><cell>0.03</cell></row><row><cell>average</cell><cell>4</cell><cell>4.13</cell><cell>0.63</cell><cell>33</cell><cell>33.4</cell><cell>5.30</cell><cell cols="2">-0.003 -0.001</cell><cell>0.01</cell></row><row><cell>low</cell><cell>4</cell><cell>3.80</cell><cell>0.67</cell><cell>33</cell><cell>30.4</cell><cell>6.60</cell><cell>0.06</cell><cell>0.06</cell><cell>0.04</cell></row></table></figure>
<figure type="table" xml:id="tab_4"><head>Table 2 :</head><label>2</label><figDesc>Post-hoc comparisons for the GPA gain. Corrected p-values shown.</figDesc><table><row><cell /><cell /><cell>average</cell><cell>high</cell></row><row><cell>low</cell><cell>1</cell><cell cols="2">0.000901 4.96 √ó 10 -8</cell></row><row><cell>average</cell><cell>-</cell><cell>1</cell><cell>0.13</cell></row><row><cell>high</cell><cell>-</cell><cell>-</cell><cell>1</cell></row></table></figure>
<figure type="table" xml:id="tab_5"><head>Table 3 :</head><label>3</label><figDesc>Recommendation agreement (via the Jaccard coefficient) for the different student performance profiles.</figDesc><table><row><cell /><cell /><cell cols="2">Average</cell><cell>Low</cell><cell /></row><row><cell cols="6">Mean Std. dev Mean Std. dev Mean Std. dev</cell></row><row><cell>0.48</cell><cell>0.20</cell><cell>0.37</cell><cell>0.21</cell><cell>0.34</cell><cell>0.22</cell></row></table></figure>
			<note place="foot" n="1" xml:id="foot_0"><p>https://www.abet.org CHI<ref type="bibr" target="#b22">'23,</ref> April  </p></note>
			<note place="foot" xml:id="foot_1"><p><ref type="bibr" target="#b22">[23]</ref><ref type="bibr" target="#b23">[24]</ref><ref type="bibr" target="#b24">[25]</ref><ref type="bibr" target="#b25">[26]</ref><ref type="bibr" target="#b26">[27]</ref><ref type="bibr" target="#b27">[28]</ref> 2023, Hamburg, Germany M√©ndez et al.</p></note>
			<note place="foot" n="2" xml:id="foot_2"><p>https://nacada.ksu.edu</p></note>
			<note place="foot" n="4" xml:id="foot_3"><p>As the study was conducted in an Engineering-oriented university, both students and advisors often perceive courses from the humanities and social sciences as easier.</p></note>
			<note place="foot" n="5" xml:id="foot_4"><p>If A is co-requisite of B, then A cannot be taken after B. They can still be taken at the same time.</p></note>
			<note place="foot" n="6" xml:id="foot_5"><p>This excludes prerequisites since they are enforced by the structure of the curriculum.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>ACKNOWLEDGMENTS</head><p>The authors wish to thank the reviewers and associate chairs for their advice and insightful comments. We would also like to express our gratitude to the academic advisors who generously donated their time to participate in this study. This research was supported and partially financed by <rs type="projectName">TAILOR</rs>, a project funded by <rs type="programName">EU Horizon 2020 research and innovation programme</rs> under GA No. <rs type="grantNumber">952215</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funded-project" xml:id="_P22Vxjx">
					<idno type="grant-number">952215</idno>
					<orgName type="project" subtype="full">TAILOR</orgName>
					<orgName type="program" subtype="full">EU Horizon 2020 research and innovation programme</orgName>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<idno type="DOI">10.11120/plan.2001.00020026</idno>
		<ptr target="https://doi.org/10.11120/plan.2001.00020026" />
		<title level="m">QAA Code of Practice for the assurance of academic quality and standards in higher education: Career Education, Information and Guidance (CEIG)</title>
		<imprint>
			<publisher>Taylor &amp; Francis</publisher>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">UniBud: A Virtual Academic Adviser</title>
		<author>
			<persName><forename type="first">Abdulrahman</forename><surname>Alkhoori</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohammad</forename><surname>Amin Kuhail</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abdulla</forename><surname>Alkhoori</surname></persName>
		</author>
		<idno type="DOI">10.1109/URC49805.2020.9099191</idno>
		<ptr target="https://doi.org/10.1109/URC49805.2020.9099191" />
	</analytic>
	<monogr>
		<title level="m">12th Annual Undergraduate Research Conference on Applied Computing (URC)</title>
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
			<biblScope unit="page" from="1" to="4" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Virtual advising: A tool for retention, engagement, and success for the graduate distance learner</title>
		<author>
			<persName><forename type="first">Georgina</forename><surname>Arg√ºello</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mar√≠a</forename><surname>Grethel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M√©ndez</forename></persName>
		</author>
		<ptr target="https://eric.ed.gov/?id=EJ1299512" />
	</analytic>
	<monogr>
		<title level="j">Distance Learning</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="51" to="57" />
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Data-Driven Approach towards a Personalized Curriculum</title>
		<author>
			<persName><forename type="first">Michael</forename><surname>Backenk√∂hler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Felix</forename><surname>Scherzinger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adish</forename><surname>Singla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Verena</forename><surname>Wolf</surname></persName>
		</author>
		<ptr target="https://eric.ed.gov/?id=ED593214" />
		<imprint>
			<date type="published" when="2018">2018. 2018</date>
			<publisher>International Educational Data Mining Society</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">To Meet The Academic Advising Needs Of The Students In A More Interactive And Effective Way</title>
		<author>
			<persName><forename type="first">Farhad</forename><surname>Bilal Baha'addin</surname></persName>
		</author>
		<idno type="DOI">10.17577/IJERTV2IS4715</idno>
		<ptr target="https://doi.org/10.17577/IJERTV2IS4715" />
	</analytic>
	<monogr>
		<title level="j">International Journal of Engineering Research &amp; Technology</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">4</biblScope>
			<date type="published" when="2013">2013. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Cooling Out in the Community College: What is the Effect of Academic Advising on Students' Chances of Success</title>
		<author>
			<persName><surname>Bahr</surname></persName>
		</author>
		<idno type="DOI">10.1007/s11162-008-9100-0</idno>
		<ptr target="https://doi.org/10.1007/s11162-008-9100-0" />
	</analytic>
	<monogr>
		<title level="j">Research in Higher Education</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="704" to="732" />
			<date type="published" when="2008-07">2008. Jul 2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Quest for Knowledge and Pursuit of Grades: Information, Course Selection, and Grade Inflation</title>
		<author>
			<persName><forename type="first">Talia</forename><surname>Bar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vrinda</forename><surname>Kadiyali</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Asaf</forename><surname>Zussman</surname></persName>
		</author>
		<idno type="DOI">10.2139/ssrn.1019580</idno>
		<ptr target="https://doi.org/10.2139/ssrn.1019580" />
	</analytic>
	<monogr>
		<title level="j">Behavioral &amp; Experimental Economics</title>
		<imprint>
			<date type="published" when="2008">2008. 2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Grade Information and Grade Inflation: The Cornell Experiment</title>
		<author>
			<persName><forename type="first">Talia</forename><surname>Bar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vrinda</forename><surname>Kadiyali</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Asaf</forename><surname>Zussman</surname></persName>
		</author>
		<idno type="DOI">10.1257/jep.23.3.93</idno>
		<ptr target="https://doi.org/10.1257/jep.23.3.93" />
	</analytic>
	<monogr>
		<title level="j">Journal of Economic Perspectives</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="93" to="108" />
			<date type="published" when="2009-09">2009. September 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Mastery learning</title>
		<author>
			<persName><forename type="first">H</forename><surname>James</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><forename type="middle">B</forename><surname>Block</surname></persName>
		</author>
		<author>
			<persName><surname>Burns</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Review of research in education</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="3" to="49" />
			<date type="published" when="1976">1976. 1976</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Review of Research on Student-Facing Learning Analytics Dashboards and Educational Recommender Systems</title>
		<author>
			<persName><forename type="first">Robert</forename><surname>Bodily</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Katrien</forename><surname>Verbert</surname></persName>
		</author>
		<idno type="DOI">10.1109/TLT.2017.2740172</idno>
		<ptr target="https://doi.org/10.1109/TLT.2017.2740172" />
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Learning Technologies</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="405" to="418" />
			<date type="published" when="2017">2017. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Transforming Qualitative Information: Thematic Analysis and Code Development</title>
		<author>
			<persName><forename type="first">Richard</forename><forename type="middle">E</forename><surname>Boyatzis</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998">1998</date>
			<publisher>Sage</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Course Enrollment Recommender System</title>
		<author>
			<persName><forename type="first">Hana</forename><surname>Byd≈æovsk√°</surname></persName>
		</author>
		<ptr target="https://eric.ed.gov/?id=ED592681" />
		<imprint>
			<date type="published" when="2016">2016. 2016</date>
			<publisher>International Educational Data Mining Society</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A Student-oriented Tool to Support Course Selection in Academic Counseling Sessions</title>
		<author>
			<persName><forename type="first">Jaime</forename><surname>Castells</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Poul</forename><surname>Mohammad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luis</forename><surname>Doust</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gonzalo</forename><surname>Gal√°rraga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Margarita</forename><surname>Gabriel M√©ndez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alberto</forename><surname>Ortiz-Rojas</surname></persName>
		</author>
		<author>
			<persName><surname>Jim√©nez</surname></persName>
		</author>
		<ptr target="http://ceur-ws.org/Vol-2704/paper4.pdf" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Workshop on Adoption, Adaptation and Pilots of Learning Analytics in Underrepresented Regions, co-located with the 15th European Conference on Technology Enhanced Learning 2020 (ECTEL</title>
		<meeting>the Workshop on Adoption, Adaptation and Pilots of Learning Analytics in Underrepresented Regions, co-located with the 15th European Conference on Technology Enhanced Learning 2020 (ECTEL</meeting>
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Academic advising in undergraduate education: A systematic review</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">Y</forename><surname>Zenobia</surname></persName>
		</author>
		<author>
			<persName><surname>Chan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hang</forename><surname>Ho Yan Chan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><surname>Chak</surname></persName>
		</author>
		<author>
			<persName><surname>Chow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nga</forename><surname>Sze</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ka</forename><forename type="middle">Yan</forename><surname>Choy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Koon Yiu</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pui</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yu</forename><surname>Kan</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.nedt.2019.01.009</idno>
		<ptr target="https://doi.org/10.1016/j.nedt.2019.01.009" />
	</analytic>
	<monogr>
		<title level="j">Nurse Education Today</title>
		<imprint>
			<biblScope unit="volume">75</biblScope>
			<biblScope unit="page" from="58" to="74" />
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Learning Analytics Dashboards to Support Adviser-Student Dialogue</title>
		<author>
			<persName><forename type="first">Sven</forename><surname>Charleer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Vande Moere</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joris</forename><surname>Klerkx</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Katrien</forename><surname>Verbert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tinne</forename><surname>De</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Laet</forename></persName>
		</author>
		<idno type="DOI">10.1109/TLT.2017.2720670</idno>
		<ptr target="https://doi.org/10.1109/TLT.2017.2720670" />
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Learning Technologies</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="389" to="399" />
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">How a Data-Driven Course Planning Tool Affects College Students' GPA: Evidence from Two Field Experiments</title>
		<author>
			<persName><forename type="first">Sorathan</forename><surname>Chaturapruek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><forename type="middle">S</forename><surname>Dee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ramesh</forename><surname>Johari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ren√©</forename><forename type="middle">F</forename><surname>Kizilcec</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mitchell</forename><forename type="middle">L</forename><surname>Stevens</surname></persName>
		</author>
		<idno type="DOI">10.1145/3231644.3231668</idno>
		<ptr target="https://doi.org/10.1145/3231644.3231668" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fifth Annual ACM Conference on Learning at Scale</title>
		<meeting>the Fifth Annual ACM Conference on Learning at Scale<address><addrLine>London, United Kingdom; New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="page">10</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Human confidence in artificial intelligence and in themselves: The evolution and impact of confidence on adoption of AI advice</title>
		<author>
			<persName><forename type="first">Leah</forename><surname>Chong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guanglu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kosa</forename><surname>Goucher-Lambert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kenneth</forename><surname>Kotovsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Cagan</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.chb.2021.107018</idno>
		<ptr target="https://doi.org/10.1016/j.chb.2021.107018" />
	</analytic>
	<monogr>
		<title level="j">Computers in Human Behavior</title>
		<imprint>
			<biblScope unit="volume">127</biblScope>
			<biblScope unit="page">107018</biblScope>
			<date type="published" when="2022">2022. 2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<author>
			<persName><forename type="first">B</forename><surname>Wollscheid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Stensaker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Jongbloed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Vossensteyn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Cremonini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Hovdhaugen</surname></persName>
		</author>
		<author>
			<persName><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName><surname>Kottmann</surname></persName>
		</author>
		<idno type="DOI">10.2766/826962</idno>
		<ptr target="https://doi.org/doi/10.2766/826962" />
		<title level="m">Dropout and completion in higher education in Europe : main report</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
		<respStmt>
			<orgName>European Commission, Sport Directorate-General for Education</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Publications Office</note>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Academic advisement and student retention: Empirical connections and systemic interventions</title>
		<author>
			<persName><forename type="first">Joe</forename><surname>Cuseo</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003">2003. 2003</date>
			<publisher>National Academic Advising Association</publisher>
			<biblScope unit="page" from="2019" to="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">The Role of Academic Advising in Student Retention and Persistence</title>
		<author>
			<persName><forename type="first">Jayne</forename><forename type="middle">K</forename><surname>Drake</surname></persName>
		</author>
		<idno type="DOI">10.1002/abc.20062</idno>
		<ptr target="https://doi.org/10.1002/abc.20062" />
	</analytic>
	<monogr>
		<title level="j">About Campus</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="8" to="12" />
			<date type="published" when="2011">2011. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Academic advising as student development</title>
		<author>
			<persName><forename type="first">Steven</forename><forename type="middle">C</forename><surname>Ender</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roger</forename><forename type="middle">B</forename><surname>Winston</surname><genName>Jr</genName></persName>
		</author>
		<author>
			<persName><forename type="first">Theodore</forename><forename type="middle">K</forename><surname>Miller</surname></persName>
		</author>
		<idno type="DOI">10.1002/ss.37119821703</idno>
		<ptr target="https://onlinelibrary.wiley.com/doi/pdf/10.1002/ss.37119821703" />
	</analytic>
	<monogr>
		<title level="j">New Directions for Student Services</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="3" to="18" />
			<date type="published" when="1982">1982. 1982. 1982</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Attachment and trust in artificial intelligence</title>
		<author>
			<persName><forename type="first">Omri</forename><surname>Gillath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ting</forename><surname>Ai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><forename type="middle">S</forename><surname>Branicky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shawn</forename><surname>Keshmiri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><forename type="middle">B</forename><surname>Davison</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ryan</forename><surname>Spaulding</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.chb.2020.106607</idno>
		<ptr target="https://doi.org/10.1016/j.chb.2020.106607" />
	</analytic>
	<monogr>
		<title level="j">Computers in Human Behavior</title>
		<imprint>
			<biblScope unit="volume">115</biblScope>
			<biblScope unit="page">106607</biblScope>
			<date type="published" when="2021">2021. 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Translating Learning into Numbers: A Generic Framework for Learning Analytics</title>
		<author>
			<persName><forename type="first">Wolfgang</forename><surname>Greller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hendrik</forename><surname>Drachsler</surname></persName>
		</author>
		<ptr target="http://www.jstor.org/stable/jeductechsoci.15.3.42" />
	</analytic>
	<monogr>
		<title level="j">Journal of Educational Technology &amp; Society</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="42" to="57" />
			<date type="published" when="2012">2012. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">An Effective Student Grouping and Course Recommendation Strategy Based on Big Data in Education</title>
		<author>
			<persName><forename type="first">Yu</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yue</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuanyan</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaojuan</forename><surname>Ban</surname></persName>
		</author>
		<idno type="DOI">10.3390/info13040197</idno>
		<ptr target="https://doi.org/10.3390/info13040197" />
	</analytic>
	<monogr>
		<title level="j">Information</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page">4</biblScope>
			<date type="published" when="2022">2022. 2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Implementing mastery learning</title>
		<author>
			<persName><surname>Thomas R Guskey</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022">2022</date>
			<publisher>Corwin Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">LADA: A Learning Analytics Dashboard for Academic Advising</title>
		<author>
			<persName><forename type="first">Francisco</forename><surname>Guti√©rrez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Karsten</forename><surname>Seipp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xavier</forename><surname>Ochoa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Katherine</forename><surname>Chiluiza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tinne</forename><surname>De Laet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Katrien</forename><surname>Verbert</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.chb.2018.12.004</idno>
		<ptr target="https://doi.org/10.1016/j.chb.2018.12.004" />
	</analytic>
	<monogr>
		<title level="j">Computers in Human Behavior</title>
		<imprint>
			<biblScope unit="volume">107</biblScope>
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<author>
			<persName><surname>Wesley R Habley</surname></persName>
		</author>
		<ptr target="https://nacada.ksu.edu/Resources/Journal/Current-Past-Book-Reviews/The-Status-of-Academic-Advising-Findings-from-the-" />
	</analytic>
	<monogr>
		<title level="m">The status of academic advising: Findings from the ACT sixth national survey</title>
		<imprint>
			<publisher>ACT-Sixth-National-Survey</publisher>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">A Serverless Academic Adviser Chatbot</title>
		<author>
			<persName><forename type="first">Heba</forename><surname>Ismail</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nada</forename><surname>Hussein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rawan</forename><surname>Elabyad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Salma</forename><surname>Said</surname></persName>
		</author>
		<idno type="DOI">10.1145/3485557.3485587</idno>
		<ptr target="https://doi.org/10.1145/3485557.3485587" />
	</analytic>
	<monogr>
		<title level="m">The 7th Annual International Conference on Arab Women in Computing in Conjunction with the 2nd Forum of Women in Research (Sharjah, United Arab Emirates)</title>
		<meeting><address><addrLine>ArabWIC; New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2021">2021. 2021</date>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
	<note>Article 27</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Early Alert of Academically At-Risk Students: An Open Source Analytics Initiative</title>
		<author>
			<persName><forename type="first">M</forename><surname>Sandeep</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Erik</forename><forename type="middle">W</forename><surname>Jayaprakash</surname></persName>
		</author>
		<author>
			<persName><surname>Moody</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Eitel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><forename type="middle">R</forename><surname>Laur√≠a</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joshua</forename><forename type="middle">D</forename><surname>Regan</surname></persName>
		</author>
		<author>
			<persName><surname>Baron</surname></persName>
		</author>
		<idno type="DOI">10.18608/jla.2014.11.3</idno>
		<ptr target="https://doi.org/10.18608/jla.2014.11.3" />
	</analytic>
	<monogr>
		<title level="j">Journal of Learning Analytics</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="6" to="47" />
			<date type="published" when="2014-05">2014. May 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Towards Equity and Algorithmic Fairness in Student Grade Prediction</title>
		<author>
			<persName><forename type="first">Weijie</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zachary</forename><forename type="middle">A</forename><surname>Pardos</surname></persName>
		</author>
		<idno type="DOI">10.1145/3461702.3462623</idno>
		<ptr target="https://doi.org/10.1145/3461702.3462623" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 AAAI/ACM Conference on AI, Ethics, and Society (Virtual Event, USA) (AIES '21)</title>
		<meeting>the 2021 AAAI/ACM Conference on AI, Ethics, and Society (Virtual Event, USA) (AIES '21)<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="608" to="617" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Goal-Based Course Recommendation</title>
		<author>
			<persName><forename type="first">Weijie</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zachary</forename><forename type="middle">A</forename><surname>Pardos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qiang</forename><surname>Wei</surname></persName>
		</author>
		<idno type="DOI">10.1145/3303772.3303814</idno>
		<ptr target="https://doi.org/10.1145/3303772.3303814" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 9th International Conference on Learning Analytics &amp; Knowledge</title>
		<meeting>the 9th International Conference on Learning Analytics &amp; Knowledge<address><addrLine>Tempe, AZ, USA; New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="36" to="45" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Prediction of student course selection in online higher education institutes using neural network</title>
		<author>
			<persName><forename type="first">Ahmad</forename><forename type="middle">A</forename><surname>Kardan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hamid</forename><surname>Sadeghi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Saeed</forename><surname>Shiry Ghidary</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohammad Reza Fani</forename><surname>Sani</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.compedu.2013.01.015</idno>
		<ptr target="https://doi.org/10.1016/j.compedu.2013.01.015" />
	</analytic>
	<monogr>
		<title level="j">Computers and Education</title>
		<imprint>
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="page" from="1" to="11" />
			<date type="published" when="2013">2013. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<author>
			<persName><forename type="first">Alfie</forename><surname>Kohn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Susan</forename><forename type="middle">D</forename><surname>Blum</surname></persName>
		</author>
		<title level="m">Ungrading: Why Rating Students Undermines Learning (and What to Do Instead</title>
		<imprint>
			<publisher>West Virginia University Press</publisher>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Engaging Students With a Chatbot-Based Academic Advising System</title>
		<author>
			<persName><forename type="first">Mohammad</forename><surname>Amin Kuhail</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haseena</forename><surname>Al Katheeri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joao</forename><surname>Negreiros</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ahmed</forename><surname>Seffah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Omar</forename><surname>Alfandi</surname></persName>
		</author>
		<idno type="DOI">10.1080/10447318.2022.2074645</idno>
		<ptr target="https://doi.org/10.1080/10447318.2022.2074645" />
	</analytic>
	<monogr>
		<title level="j">International Journal of Human-Computer Interaction</title>
		<imprint>
			<biblScope unit="volume">0</biblScope>
			<biblScope unit="issue">0</biblScope>
			<biblScope unit="page" from="1" to="27" />
			<date type="published" when="2022">2022. 2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">The future of artificial intelligence at work: A review on effects of decision automation and augmentation on workers targeted by algorithms and third-party observers</title>
		<author>
			<persName><forename type="first">Markus</forename><surname>Langer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><forename type="middle">N</forename><surname>Landers</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.chb.2021.106878</idno>
		<ptr target="https://doi.org/10.1016/j.chb.2021.106878" />
	</analytic>
	<monogr>
		<title level="j">Computers in Human Behavior</title>
		<imprint>
			<biblScope unit="volume">123</biblScope>
			<biblScope unit="page">106878</biblScope>
			<date type="published" when="2021">2021. 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Design and Functionality of a University Academic Advisor Chatbot as an Early Intervention to Improve Students' Academic Performance</title>
		<author>
			<persName><forename type="first">Sin-Ban</forename><surname>Mei Shyan Lim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ian</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName><surname>Chai</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-981-33-4069-5_15</idno>
		<ptr target="https://doi.org/10.1007/978-981-33-4069-5_15" />
	</analytic>
	<monogr>
		<title level="m">Computational Science and Technology</title>
		<editor>
			<persName><forename type="first">Rayner</forename><surname>Alfred</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Hiroyuki</forename><surname>Iida</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Haviluddin</forename><surname>Haviluddin</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Patricia</forename><surname>Anthony</surname></persName>
		</editor>
		<meeting><address><addrLine>Singapore, Singapore</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="167" to="178" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">A Unified Approach to Interpreting Model Predictions</title>
		<author>
			<persName><forename type="first">M</forename><surname>Scott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Su-In</forename><surname>Lundberg</surname></persName>
		</author>
		<author>
			<persName><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 31st International Conference on Neural Information Processing Systems (NIPS'17)</title>
		<meeting>the 31st International Conference on Neural Information Processing Systems (NIPS'17)</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Red Hook</title>
		<idno type="DOI">10.5555/3295222.3295230</idno>
		<ptr target="https://doi.org/10.5555/3295222.3295230" />
		<imprint>
			<publisher>Curran Associates Inc</publisher>
			<biblScope unit="page" from="4768" to="4777" />
			<pubPlace>, NY, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">A review on Recommender Systems for course selection in higher education</title>
		<author>
			<persName><forename type="first">N D</forename><surname>Lynn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A W R</forename><surname>Emanuel</surname></persName>
		</author>
		<idno type="DOI">10.1088/1757-899x/1098/3/032039</idno>
		<ptr target="https://doi.org/10.1088/1757-899x/1098/3/032039" />
	</analytic>
	<monogr>
		<title level="m">IOP Conference Series: Materials Science and Engineering</title>
		<imprint>
			<date type="published" when="1098-03">2021. 1098. mar 2021</date>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">32039</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">How convincing is alternative assessment for use in higher education?</title>
		<author>
			<persName><forename type="first">Effie</forename><surname>Maclellan</surname></persName>
		</author>
		<idno type="DOI">10.1080/0260293042000188267</idno>
		<ptr target="https://doi.org/10.1080/0260293042000188267" />
	</analytic>
	<monogr>
		<title level="j">Assessment &amp; Evaluation in Higher Education</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="311" to="321" />
			<date type="published" when="2004">2004. 2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">A Survey on Bias and Fairness in Machine Learning</title>
		<author>
			<persName><forename type="first">Ninareh</forename><surname>Mehrabi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fred</forename><surname>Morstatter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nripsuta</forename><surname>Saxena</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kristina</forename><surname>Lerman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aram</forename><surname>Galstyan</surname></persName>
		</author>
		<idno type="DOI">10.1145/3457607</idno>
		<ptr target="https://doi.org/10.1145/3457607" />
	</analytic>
	<monogr>
		<title level="j">ACM Comput. Surv</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page">35</biblScope>
			<date type="published" when="2021-07">2021. jul 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Showing Academic Performance Predictions during Term Planning: Effects on Students' Decisions, Behaviors, and Preferences</title>
		<author>
			<persName><forename type="first">Gonzalo</forename><surname>Gabriel M√©ndez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luis</forename><surname>Gal√°rraga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Katherine</forename><surname>Chiluiza</surname></persName>
		</author>
		<idno type="DOI">10.1145/3411764.3445718</idno>
		<ptr target="https://doi.org/10.1145/3411764.3445718" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems</title>
		<meeting>the 2021 CHI Conference on Human Factors in Computing Systems<address><addrLine>Yokohama, Japan; New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page">17</biblScope>
		</imprint>
	</monogr>
	<note>Article 22</note>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Recruitment, advising, and retention programs -Challenges and solutions to the international problem of poor nursing student retention: A narrative literature review</title>
		<author>
			<persName><forename type="first">E</forename><surname>Quanza</surname></persName>
		</author>
		<author>
			<persName><surname>Mooring</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.nedt.2016.03.003</idno>
		<ptr target="https://doi.org/10.1016/j.nedt.2016.03.003" />
	</analytic>
	<monogr>
		<title level="j">Nurse Education Today</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page" from="204" to="208" />
			<date type="published" when="2016">2016. 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Process Automation Tool for Academic Advising</title>
		<author>
			<persName><forename type="first">Mirna</forename><surname>Nachouki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mahmoud</forename><surname>Abou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Naaj</forename></persName>
		</author>
		<idno type="DOI">10.1109/ISSPIT47144.2019.9001864</idno>
		<ptr target="https://doi.org/10.1109/ISSPIT47144.2019.9001864" />
	</analytic>
	<monogr>
		<title level="m">IEEE International Symposium on Signal Processing and Information Technology (ISSPIT)</title>
		<imprint>
			<date type="published" when="2019">2019. 2019</date>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Optimizing Grade Point Averages During the Pandemic at a Regional University</title>
		<author>
			<persName><forename type="first">T</forename><surname>Jaideep</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chae</forename><forename type="middle">Mi</forename><surname>Naidu</surname></persName>
		</author>
		<author>
			<persName><surname>Lim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Business Education Innovation Journal</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">7</biblScope>
			<date type="published" when="2020-12">2020. December 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Implementing non-traditional assessment strategies in teacher preparation: Opportunities and challenges</title>
		<author>
			<persName><forename type="first">Mira</forename><forename type="middle">Cole</forename><surname>Jennifer R Newton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Danielle</forename><forename type="middle">M</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName><surname>Feeney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Culture and Values in Education</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="39" to="51" />
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">A course recommendation model for students based on learning outcome</title>
		<author>
			<persName><forename type="first">Anh</forename><surname>Viet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hoa-Huy</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Duc-Loc</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Minh-Duc</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><surname>Le</surname></persName>
		</author>
		<idno type="DOI">10.1007/s10639-021-10524-0</idno>
		<ptr target="https://doi.org/10.1007/s10639-021-10524-0" />
	</analytic>
	<monogr>
		<title level="j">Education and Information Technologies</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="5389" to="5415" />
			<date type="published" when="2021">2021. 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Assessment Outcomes of Pre-service Teachers</title>
		<author>
			<persName><forename type="first">Deborah</forename><forename type="middle">M</forename><surname>Oh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Simeon</forename><surname>Slovacek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Susan</forename><surname>Tucker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ann</forename><surname>Hafner</surname></persName>
		</author>
		<idno type="DOI">10.1080/0260293032000059630</idno>
		<ptr target="https://doi.org/10.1080/0260293032000059630" />
	</analytic>
	<monogr>
		<title level="j">Assessment &amp; Evaluation in Higher Education</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="279" to="295" />
			<date type="published" when="2003">2003. 2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Design of a learning analytics system for academic advising in Nigerian universities</title>
		<author>
			<persName><forename type="first">Emmanuel</forename><surname>Okewu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Olawande</forename><surname>Daramola</surname></persName>
		</author>
		<idno type="DOI">10.1109/ICCNI.2017.8123785</idno>
		<ptr target="https://doi.org/10.1109/ICCNI.2017.8123785" />
	</analytic>
	<monogr>
		<title level="m">2017 International Conference on Computing Networking and Informatics (ICCNI)</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">An Improved Course Recommendation System Based on Historical Grade Data Using Logistic Regression</title>
		<author>
			<persName><forename type="first">Dauda</forename><surname>Idowu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joseph</forename><surname>Oladipo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Muyideen</forename><surname>Bamidele Awotunde</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oluwasegun</forename><surname>Abdulraheem</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ghaniyyat</forename><surname>Osemudiame Ige</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adekola</forename><surname>Bolanle Balogun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fatimoh</forename><surname>Rasheed Tomori</surname></persName>
		</author>
		<author>
			<persName><surname>Abidemi Taofeek-Ibrahim</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-89654-6_15</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-89654-6_15" />
	</analytic>
	<monogr>
		<title level="m">Applied Informatics</title>
		<editor>
			<persName><forename type="first">Hector</forename><surname>Florez</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Ma Florencia Pollo-Cattaneo</forename></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="207" to="221" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Connectionist recommendation in the wild: on the utility and scrutability of neural networks for personalized course guidance</title>
		<author>
			<persName><forename type="first">Fan</forename><surname>Pardos</surname></persName>
		</author>
		<author>
			<persName><surname>Jiang</surname></persName>
		</author>
		<idno type="DOI">10.1007/s11257-019-09218-7</idno>
		<ptr target="https://doi.org/10.1007/s11257-019-09218-7" />
	</analytic>
	<monogr>
		<title level="j">User Modeling and User-Adapted Interaction</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="487" to="525" />
			<date type="published" when="2019-02">2019. Feb 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Designing for Serendipity in a University Course Recommendation System</title>
		<author>
			<persName><forename type="first">Zachary</forename><forename type="middle">A</forename><surname>Pardos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weijie</forename><surname>Jiang</surname></persName>
		</author>
		<idno type="DOI">10.1145/3375462.3375524</idno>
		<ptr target="https://doi.org/10.1145/3375462.3375524" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Tenth International Conference on Learning Analytics &amp; Knowledge</title>
		<meeting>the Tenth International Conference on Learning Analytics &amp; Knowledge<address><addrLine>Frankfurt, Germany; New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="350" to="359" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Improving Advising Using Technology and Data Analytics</title>
		<author>
			<persName><forename type="first">Elizabeth</forename><forename type="middle">D</forename><surname>Phillips</surname></persName>
		</author>
		<idno type="DOI">10.1080/00091383.2013.749151</idno>
		<ptr target="https://doi.org/10.1080/00091383.2013.749151" />
	</analytic>
	<monogr>
		<title level="j">Change: The Magazine of Higher Learning</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="48" to="55" />
			<date type="published" when="2013">2013. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Problem-based learning and performance-based testing: Effective alternatives for undergraduate surgical education and assessment of student performance</title>
		<author>
			<persName><forename type="first">Richard</forename><forename type="middle">W</forename><surname>Schwartz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><forename type="middle">E</forename><surname>Burgett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amy</forename><forename type="middle">V</forename><surname>Blue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><forename type="middle">B</forename><surname>Donnelly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">A</forename><surname>Sloan</surname></persName>
		</author>
		<idno type="DOI">10.3109/01421599709019341</idno>
		<ptr target="https://doi.org/10.3109/01421599709019341" />
	</analytic>
	<monogr>
		<title level="j">Medical Teacher</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="19" to="23" />
			<date type="published" when="1997">1997. 1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">College Counseling and Student Retention: Research Findings and Implications for Counseling Centers</title>
		<author>
			<persName><forename type="first">Bruce</forename><forename type="middle">S</forename><surname>Sharkin</surname></persName>
		</author>
		<idno type="DOI">10.1002/j.2161-1882.2004.tb00241.x</idno>
		<ptr target="https://onlinelibrary.wiley.com/doi/pdf/10.1002/j.2161-1882.2004.tb00241.x" />
	</analytic>
	<monogr>
		<title level="j">Journal of College Counseling</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="99" to="108" />
			<date type="published" when="2004">2004. 2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">The overall effects of end-of-course assessment on student performance: A comparison between multiple choice testing, peer assessment, case-based assessment and portfolio assessment</title>
		<author>
			<persName><forename type="first">Katrien</forename><surname>Struyven</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Filip</forename><surname>Dochy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Steven</forename><surname>Janssens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wouter</forename><surname>Schelfhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sarah</forename><surname>Gielen</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.stueduc.2006.08.002</idno>
		<ptr target="https://doi.org/10.1016/j.stueduc.2006.08.002" />
	</analytic>
	<monogr>
		<title level="j">Studies in Educational Evaluation</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="202" to="222" />
			<date type="published" when="2006">2006. 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Improving Retention Among College Students: Investigating the Utilization of Virtualized Advising</title>
		<author>
			<persName><forename type="first">R</forename><surname>Lemaro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Leon</forename><forename type="middle">C</forename><surname>Thompson</surname></persName>
		</author>
		<author>
			<persName><surname>Prieto</surname></persName>
		</author>
		<ptr target="https://www.proquest.com/scholarly-journals/improving-retention-among-college-students/docview/1462525754/se-2Copyright-CopyrightJordan" />
	</analytic>
	<monogr>
		<title level="j">Academy of Educational Leadership Journal</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="13" to="26" />
			<date type="published" when="2013">2013. 2013. 2013. Last updated -2021-09-09</date>
			<publisher>SubjectsTermNotLitGenreText -United States-US</publisher>
		</imprint>
	</monogr>
	<note>Document feature -Tables; Diagrams</note>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">The Higher Education Enrollment Decision: Feedback on Expected Study Success and Updating Behavior</title>
		<author>
			<persName><forename type="first">Chris</forename><surname>Van Klaveren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Karen</forename><surname>Kooiman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilja</forename><surname>Cornelisz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Martijn</forename><surname>Meeter</surname></persName>
		</author>
		<idno type="DOI">10.1080/19345747.2018.1496501</idno>
		<ptr target="https://doi.org/10.1080/19345747.2018.1496501" />
	</analytic>
	<monogr>
		<title level="j">Journal of Research on Educational Effectiveness</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="67" to="89" />
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Visual Learning Analytics of Educational Data: A Systematic Literature Review and Research Agenda</title>
		<author>
			<persName><forename type="first">Camilo</forename><surname>Vieira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paul</forename><surname>Parsons</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vetria</forename><surname>Byrd</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.compedu.2018.03.018</idno>
		<ptr target="https://doi.org/10.1016/j.compedu.2018.03.018" />
	</analytic>
	<monogr>
		<title level="j">Computers &amp; Education</title>
		<imprint>
			<biblScope unit="volume">122</biblScope>
			<biblScope unit="page" from="119" to="135" />
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Developing institutional strategies to support failing/failed part-time students in higher education</title>
		<author>
			<persName><forename type="first">Graham</forename><surname>Whitehead</surname></persName>
		</author>
		<idno type="DOI">10.1921/jpts.v11i2.265</idno>
		<ptr target="https://doi.org/10.1921/jpts.v11i2.265" />
	</analytic>
	<monogr>
		<title level="j">The Journal of Practice Teaching and Learning</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="27" to="46" />
			<date type="published" when="2013-03">2013. Mar. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Exploratory Students' Experiences With First-Year Academic Advising</title>
		<author>
			<persName><forename type="first">Jamie</forename><forename type="middle">L</forename><surname>Workman</surname></persName>
		</author>
		<idno type="DOI">10.12930/NACADA-14-005</idno>
		<ptr target="https://doi.org/10.12930/NACADA-14-005" />
	</analytic>
	<monogr>
		<title level="j">NACADA Journal</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="5" to="12" />
			<date type="published" when="2015">2015. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Academic advising: does it really impact student success?</title>
		<author>
			<persName><forename type="first">Adena</forename><forename type="middle">D</forename><surname>Young-Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tracie</forename><forename type="middle">D</forename><surname>Burt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephanie</forename><surname>Dixon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Melissa</forename><forename type="middle">J</forename><surname>Hawthorne</surname></persName>
		</author>
		<idno type="DOI">10.1108/09684881311293034</idno>
		<ptr target="https://doi.org/10.1108/09684881311293034" />
	</analytic>
	<monogr>
		<title level="j">Quality Assurance in Education</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="7" to="19" />
			<date type="published" when="2013-01">2013. Jan 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Orienting Students to Course Recommendations Using Three Types of Explanation</title>
		<author>
			<persName><forename type="first">Run</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zach</forename><surname>Pardos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hung</forename><surname>Chau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Brusilovsky</surname></persName>
		</author>
		<idno type="DOI">10.1145/3450614.3464483</idno>
		<ptr target="https://doi.org/10.1145/3450614.3464483" />
	</analytic>
	<monogr>
		<title level="m">Adjunct Proceedings of the 29th ACM Conference on User Modeling, Adaptation and Personalization</title>
		<meeting><address><addrLine>Utrecht, Netherlands; New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="238" to="245" />
		</imprint>
	</monogr>
	<note>UMAP '21)</note>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Knowledge-Based Major Choosing Decision Making for Remote Students</title>
		<author>
			<persName><forename type="first">Qing</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fang</forename><surname>Yu</surname></persName>
		</author>
		<idno type="DOI">10.1109/CSSE.2008.379</idno>
		<ptr target="https://doi.org/10.1109/CSSE.2008.379" />
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Science and Software Engineering</title>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="474" to="478" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>