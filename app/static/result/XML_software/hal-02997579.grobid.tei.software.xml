<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">32nd International Conference on Algorithmic Learning Theory Efficient Algorithms for Stochastic Repeated Second-price Auctions</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Juliette</forename><surname>Achddou</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Juliette</forename><surname>Achdou</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Olivier</forename><surname>Cappé</surname></persName>
						</author>
						<author role="corresp">
							<persName><forename type="first">Aurélien</forename><surname>Garivier</surname></persName>
							<email>aurelien.garivier@ens-lyon.</email>
						</author>
						<author>
							<persName><forename type="first">Vitaly</forename><surname>Feldman</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Katrina</forename><surname>Ligett</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Sivan</forename><surname>Sabato</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">COM</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">1000mercis Group</orgName>
								<orgName type="institution" key="instit1">ENS Paris</orgName>
								<orgName type="institution" key="instit2">Université PSL</orgName>
								<orgName type="institution" key="instit3">INRIA</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="institution">CAPPE</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="laboratory">CNRS.FR ENS Paris</orgName>
								<orgName type="institution" key="instit1">Université PSL</orgName>
								<orgName type="institution" key="instit2">CNRS</orgName>
								<orgName type="institution" key="instit3">INRIA</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff4">
								<orgName type="laboratory">FR UMPA</orgName>
								<orgName type="institution" key="instit1">CNRS</orgName>
								<orgName type="institution" key="instit2">INRIA</orgName>
								<orgName type="institution" key="instit3">ENS Lyon</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">32nd International Conference on Algorithmic Learning Theory Efficient Algorithms for Stochastic Repeated Second-price Auctions</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">0B5DB28CC05BD37076F02546FCF5442C</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-04-12T14:54+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>bandits</term>
					<term>online learning</term>
					<term>auctions</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Developing efficient sequential bidding strategies for repeated auctions is an important practical challenge in various marketing tasks. In this setting, the bidding agent obtains information, on both the value of the item at sale and the behavior of the other bidders, only when she wins the auction. Standard bandit theory does not apply to this problem due to the presence of action-dependent censoring. In this work, we consider second-price auctions and propose novel, efficient UCBlike algorithms for this task. These algorithms are analyzed in the stochastic setting, assuming regularity of the distribution of the opponents' bids. We provide regret upper bounds that quantify the improvement over the baseline algorithm proposed in the literature. The improvement is particularly significant in cases when the value of the auctioned item is low, yielding a spectacular reduction in the order of the worst-case regret. We further provide the first parametric lower bound for this problem that applies to generic UCB-like strategies. As an alternative, we propose more explainable strategies which are reminiscent of the Explore Then Commit bandit algorithm. We provide a critical analysis of this class of strategies, showing both important advantages and limitations. In particular, we provide a minimax lower bound and propose a nearly minimax-optimal instance of this class. by Amin et al. (2013); Mohri and Medina (2014); Drutsa (2017); Kanoria and Nazerzadeh (2014); Vanunts and Drutsa (2019); Drutsa (2020).</p><p>Online learning algorithms can be used to maximize the cumulative return of the buyers via the choice of their bid, as was done for the sellers. <ref type="bibr" target="#b26">Weed et al. (2016)</ref> proposed an online algorithm for second-price auctions in the stochastic and adversarial settings. In particular, for the stochastic setup, the authors consider a strategy which consists of bidding the empirical average of the past observed values plus an exploration bonus. This way of balancing exploration and exploitation can be framed into the family of Upper Confidence Bound (UCB) strategies, that were first used for multi-armed bandits, see <ref type="bibr" target="#b19">Lattimore and Szepesvári (2018)</ref> for an introduction to multi-armed bandits and Auer et al. (2002)  for the first analysis of UCB. <ref type="bibr" target="#b26">Weed et al. (2016)</ref> provides upper bounds on the regret of UCBID, under the assumption that F satisfies some form of "margin condition" (see Assumption 2 in Appendix A). Weed et al. ( <ref type="formula">2016</ref>) also exhibit a minimax lower bound that pertains to the specific case where M t is deterministic. <ref type="bibr" target="#b12">Feng et al. (2018)</ref> extend the results of <ref type="bibr" target="#b26">Weed et al. (2016)</ref> to different kind of auctions mechanisms, including multi-item auctions with stochastic allocation rules.</p><p>Another extension is considered by Flajolet and Jaillet ( <ref type="formula">2017</ref>), who study contextual strategies for repeated second-price auctions with a budget. Using UCB strategies developed for linear bandits <ref type="bibr" target="#b9">Dani et al. (2008);</ref> Abbasi-Yadkori et al. (2011), Flajolet and<ref type="bibr" target="#b13">Jaillet (2017)</ref> introduce an algorithm for bidding adaptively to contexts that represent new users or inventories arriving sequentially, under the assumption that the expected reward is a linear function of the context. The latter algorithm also includes elements from the Bandit with Knapsacks framework <ref type="bibr" target="#b4">Badanidiyuru et al. (2013)</ref>, which are used to handle a financial budget constraint.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>This work is devoted to the design of strategies for bidders participating in repeated second-price auctions. Second-price auctions have the unique property of being dominant-strategy incentivecompatible, which means that a bidder's return in a second-price auction is always better when she plays truthfully than with any other bidding strategy. This property explains the widespread use of second-price auctions in various sales and marketing contexts. In particular, second-price auctions have long been the predominant auction structure in the field of programmatic advertising. There, they allow advertising spaces owned by editors to be sold to the highest bidder among publishers who need to display their ads in fractions of a second. It is therefore possible to model an advertising campaign of one of the publishers as a sequence of second-price auctions that involve varying sets of other bidders -since not all publishers bid on the same inventories-with an initially unknown payoff (materialized by clicks or by a purchase amount subsequent to the display of the advertisement). In this context, the different publishers typically do not assign the same value to the placements and thus each bidder has a different private value in the auction. If reserve prices are used, these can be interpreted as additional fixed virtual bids that are present in each auction. In this work, we adopt the point of view of a single bidder with the aim of developing provably efficient online learning strategies that maximize her cumulative reward.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1.">Model</head><p>We consider that similar items are sold in T sequential second-price auctions. For t in 1, . . . , T , the auction unfolds in the following way. First, the bidder submits her bid B t for the item that is of unknown value V t . The other players submit their bids, the maximum of which is called M t . If M t ≤ B t (which includes the case of ties), the bidder observes and receives V t , and pays M t . Otherwise, the bidder loses the auction and does not observe V t . We make the following additional assumptions. The values {V t } t≥1 are independent and identically distributed random variables in the unit interval [0,1]; their expectation is denoted by E(V t ) = v. The maximal bids {M t } t≥1 are independent and identically distributed random variables in the unit interval [0, 1]; their cumulative distribution function is denoted by F .</p><p>Neither v nor F are assumed to be known initially to the bidder. The above model corresponds to a continuously-armed bandit with a very particular structure: the higher the bid, the higher the probability of observing a value and hence of learning useful information for estimating the optimal bid v (see Appendix A.1 for a simple proof that v is actually optimal,under a mild assumption on F ). Therefore, exploration requires that the bids B t are not set too low while exploitation is achieved by bidding as close as possible to the estimated value of v. Under the optimal bidding policy, i.e., when B t = v, only a fraction F (v) of the rounds results in an actual observation of V t . In the example of online advertising, the values are typically binary with very small expectation (click or conversion rates are usually less than a few percents). We will therefore be interested in algorithms that also perform satisfactorily in situations when the parameter v and F (v), are very small. The assumption that the bids M t are stochastic is well suited to contexts in which the set of bidders varies in time, the bids depend on unobservable time-varying contextual information or when the bidders do not assign the same value to the placements. In this work, we restrict ourselves to this setting (also considered by <ref type="bibr" target="#b26">Weed et al. (2016)</ref> or <ref type="bibr" target="#b13">Flajolet and Jaillet (2017)</ref>) and refer to Section 4 of <ref type="bibr" target="#b26">(Weed et al., 2016)</ref> for techniques applicable to other scenarios where fast learning rates cannot be achieved.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2.">Related Works</head><p>Following the pioneering study by <ref type="bibr" target="#b25">Vickrey (1961)</ref> on one-item second-price auctions, a line of work emerged on mechanism design, a field aimed at designing mechanisms, and in particular auctions, that satisfy some fixed properties (for example being dominant strategy incentive compatible). <ref type="bibr" target="#b23">Myerson (1981)</ref> proves that second price auctions with reserve prices, i.e. in which the seller herself submits a virtual bid, guarantees a maximum return to the seller when the players are symmetric, while maintaining the dominant strategy incentive compatibility of the auction. In particular, the same author also proves that if the valuations of each of the bidders are drawn independently from known distributions then a closed-form expression exists for the optimal reserve price.</p><p>For the case when the distributions of the valuations of the bidders are unknown, <ref type="bibr" target="#b5">Blum et al. (2004)</ref>; <ref type="bibr" target="#b7">Cesa-Bianchi et al. (2014)</ref> studied online learning strategies to maximize the cumulative payoff of the seller while learning the optimal reserve price in repeated auctions. <ref type="bibr">Medina and Mohri (2014)</ref> instead consider a supervised learning problem with features associated to each of the auctions and adopt a full information setting instead of a bandit setting. They justify this change of setting by the fact that sellers often have access to all the bids. <ref type="bibr" target="#b5">Blum et al. (2004)</ref> also work in the full information setting and rely on the weighted majority algorithm <ref type="bibr" target="#b20">(Littlestone et al., 1989)</ref> to learn the reserve price. In the aforementioned papers, bidders are not assumed to be strategic, which is fixed</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.3.">Main Contributions</head><p>In the stochastic framework considered by <ref type="bibr" target="#b26">Weed et al. (2016)</ref> and recalled in Section 2, we propose three new algorithms. We start in Section 3 by considering UCB algorithms that rely on tighter confidence bounds than those used for UCBID. We propose two such algorithms, named kl-UCBID and Bernstein-UCBID, which rely, respectively, on the use of Chernoff and Bernstein deviation inequalities. These algorithms are inspired by the works of <ref type="bibr" target="#b14">Garivier and Cappé (2011)</ref> and <ref type="bibr" target="#b2">Audibert et al. (2009)</ref> for the multi-armed bandit case. Under regularity assumptions, the analysis reveals an improvement over UCBID that is dramatic in cases in which v is small, yielding a remarkable reduction of the order of the worst-case regret in Theorem 5. The analysis requires to fix a gap in the proof scheme of <ref type="bibr" target="#b26">Weed et al. (2016)</ref>, which has an impact for small values of v. In section 3.3, we provide a lower bound valid for optimistic strategies in the cases when the distribution of M t admits a bounded density. This lower bound differs from the result of <ref type="bibr" target="#b26">Weed et al. (2016)</ref> because it is parameter-dependent (rather than minimax) and not restricted to the case when the distribution of M t is degenerate (and hence, when the auction outcome is deterministic given the bid). This new lower bound highlights the impact of v on the performance of the algorithms.</p><p>However UCB strategies can be hard to accept and/or to implement by practitioners in some contexts. With this in mind, we also consider in Section 4 a class of simpler, two-phases strategies that bid maximally until a stopping time, then either abandon the bid (typically in cases when v is deemed to be small) or default to the running average of observed values. We provide a critical analysis of this approach, showing both important advantages and limitations: an excellent behavior for relatively a large v, and a sub-optimal behavior in case of a small value. We provide a minimax lower bound for this class of strategies; it shows that their worst-case regret is bound to be larger than that of the best UCB algorithm. These findings are illustrated by numerical simulations in Section 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Model and Assumptions</head><p>We precise the setup presented in Section 1.1 with the following notation. Let N t = t s=1 1{M s ≤ B s } be the number of times the bidder won up to time t, which, we stress, is also the number of observations of values up to time t. Let Vt := 1 Nt t s=1 V s 1(M s ≤ B s ), be the empirical mean of the values observed before time t and Wt := 1/N t t s=1 (V s -Vt ) 2 1(M s ≤ B s ), the population variance of the values observed before time t. Lastly, w denotes the variance of V t .</p><p>We define the utility of a bidder who submits a bid b as the difference between the received value and the paid price: the utility function at time t is therefore expressed as</p><formula xml:id="formula_0">U t (b) = (V t -M t )1{b ≥ M t }.</formula><p>As a measure of performance of bidding algorithms, we use the following notion of expected cumulative regret:</p><formula xml:id="formula_1">R T := max b∈[0,1] T t=1 E[U t (b)] - T t=1 E[U t (B t )].</formula><p>It is a well known fact that bidding v is an optimal bidding strategy in second price auctions. A proof of this result is given in Appendix A.1, showing in particular that if the density of M t vanishes around this valuation v, then v is one of many maximizers of the utility, while if F admits a strictly positive density, then U t (b) is unimodal, in the sense that it is first non-decreasing and then non-increasing. This is interesting, because it allows for the use of specific algorithms designed for unimodal bandits Yu and Mannor (2011); <ref type="bibr" target="#b8">Combes and Proutiere (2014)</ref>. We will see, however, that these algorithms are sub-optimal as they do not fully exploit the structure of the problem.</p><p>The local behavior of F around the unknown value v is a key parameter that influences the regret achievable by sequential bidding strategies. In the main body of this paper we focus exclusively on the most natural assumption that the distribution of the maxima of the bids of the opponents admits a density that is bounded in an interval containing v.</p><p>Assumption 1 Locally bounded density. There exists ∆ &gt; 0 such that F admits a density f bounded on [v, v + ∆], i.e., there exists β &gt; 0, such that ∀x ∈</p><formula xml:id="formula_2">[v, v + ∆], f (x) &lt; β.</formula><p>This assumption corresponds to a local version of the margin condition introduced by <ref type="bibr" target="#b26">Weed et al. (2016)</ref> (corresponding to their case of α=1). Broader results are provided in Appendix, covering the different local behaviors of F around v (as defined by Assumption 2).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">UCB-type algorithms</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Specification of the Algorithms</head><p>We start by studying Upper Confidence Bound strategies, similar to the UCBID algorithm proposed by <ref type="bibr" target="#b26">Weed et al. (2016)</ref>. At each time step, the algorithms submit an upper confidence bound of v, thus allowing -whith high probability-for at least as many observations as the optimal strategy (i.e. bidding v from the first round on). The two proposed algorithms, klUCBID and BernsteinUCBID, differ from UCBID by the use of tighter upper confidence bounds. Namely, for t &gt; 1, they respectively submit a bid equal to</p><formula xml:id="formula_3">B t = U CB t (γ) =            min 1, Vt-1 + γ log(t) 2N t-1 for UCBID inf x ∈ ( Vt-1 , 1] : kl( Vt-1 , x) = γ log(t) N t-1 for klUCBID min 1, Vt-1 + 2 Wt-1 log(3t γ ) N t-1 + 3 log(3t γ ) N t-1</formula><p>for BernsteinUCBID , where kl(p, q) denotes the Kullback Leibler divergence between two Bernoulli distributions of expectations p and q and where γ &gt; 0 is a parameter that impacts the exploration level. At time t = 1, all three algorithms bid B t = 1, ensuring an initial observation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Upper Bounds on the Regret</head><p>We start with a new analysis of the UCBID algorithm, which completes that of <ref type="bibr" target="#b26">Weed et al. (2016)</ref> by emphasizing the presence of an important multiplicative factor.</p><p>Theorem 1 If F satisfies Assumption 1 and F (v) &gt; 0, then the regret of the UCBID algorithm with parameter γ &gt; 1 is bounded as follows:</p><formula xml:id="formula_4">R T ≤ 2βγ F (v) log 2 T + O(log T ).</formula><p>This result is proved in Appendix B.6 , which also includes the exact (non asymptotic) form of the upper bound. The main difference with the result of <ref type="bibr" target="#b26">Weed et al. (2016)</ref> is the factor 1/F (v) that arises in the upper bound. This factor can be interpreted as the average time between two successive observations under the optimal policy, which consists of bidding v and winning the auction with probability F (v). When v is small, one thus has to wait a long time before an optimistic bid B t gets near to v, especially because as B t tends to v, the algorithm is given fewer and fewer observations to learn from. Furthermore, the lower bound derived in Section 3.3 also displays the same form of dependence on v. Lemma 13 (in Appendix) is the key ingredient used to control the deviations of the bid B t from v using a resampling argument. Contrary to the case of multi-armed bandits, there is no gap between the optimal policy and other possible strategies. To obtain the (squared) logarithmic rate of growth of the regret in Theorem 1, it is important to recognize that, under Assumption 1, the expected utility E[U t (b)] is locally quadratic around v.</p><p>We now present the results pertaining to the two proposed algorithms kl-UCBID and Bernstein-UCBID. These bounds show a significant improvement by including a variance term of primary importance in applications.</p><p>Theorem 2 If F satisfies Assumption 1, the kl-UCBID algorithm with parameter γ &gt; 1 yields the following bound on the regret:</p><formula xml:id="formula_5">R T ≤ 8γv(1 -v) β log(T ) 2 F (v) 1 + o(1) .</formula><p>Theorem 3 If F satisfies Assumption 1 and F (v) &gt; 0, the Bernstein-UCBID algorithm with parameter γ &gt; 2 yields a regret bounded as follows :</p><formula xml:id="formula_6">R T ≤ β F (v) 8wγ log 2 (T ) + O(log T ).</formula><p>The proofs of Theorems 2 and 3 can be found respectively in Appendix C and B.7. Theorem 3 relies on a non-asymptotic bound that can be found in Appendix B.7. The remainder term in Theorem 2 is less precise as a consequence of the fact that the kl-UCBID upper confidence bound does not admit a closed-form expression. Indeed the term v(1 -v) appears as a part of the second order Taylor approximation of kl(v , x) for values of v sufficiently close to v. A non-asymptotic bound for kl-UCBID is also proven in Appendix C.3, but with larger multiplicative constants. The leading terms in the bound on the regret of kl-UCBID and the bound for the regret of Bernstein-UCBID are smaller than that of UCBID, as v(1 -v) is always less than 1/4. The difference becomes particularly significant for small values of v. The comparison between kl-UCBID and Bernstein-UCBID is more subtle. It is always true that w, which is the variance of the distribution of V t , is smaller than v(1 -v), since V t ∈ [0, 1]; this means that Bernstein-UCBID is a very robust algorithm. In the case of Bernoulli rewards however, w = v(1 -v) and Chernoff's upper confidence bound is tighter than Bernstein's: consistently, we observe in numerical simulations that kl-UCBID dominates Bernstein-UCBID (see Section 5). Note that we focus solely on Assumption 1 in the main body of the paper for simplicity, but that this assumption is weaker than Assumption 2 that is required in the proof of the upper bounds of the regret in the Appendix. Assumption 2 is more general and extends to all cases when F is continuous in a neighborhood of v. Theorem 16 for example gives upper bounds for the regret of UCB depending on the behavior of F around v, the worst order of the regret being O(log T √ T ). On the contrary, if F is discontinuous at v, a bound of the order of log T √ T still holds for the regret of all three UCB algorithms, as we will show in Theorem 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Lower Bound on the Regret of Optimistic Strategies</head><p>This section provides a lower bound for the regret of any optimistic algorithm.</p><p>Theorem 4 We consider all environments where V t follows a Bernoulli distribution with expectation v and F admits a density f that is bounded from below and above, with f (b) ≥ β ¯&gt; 0. If a strategy is such that, for all such environments, R T ≤ O(T a ), for all a &gt; 0, and if there exists γ &gt; 0 such that for all such environments, P(B t &lt; v) &lt; t -γ , then this strategy must satisfy:</p><formula xml:id="formula_7">lim inf T →∞ R T log T ≥ β ¯v(1 -v) 16F (v) . (<label>1</label></formula><formula xml:id="formula_8">)</formula><p>This result is proved in Appendix D. The first assumption, R T ≤ O(T a ), is a requirement of minimal uniform performance similar to the assumption used to prove the lower bound of <ref type="bibr" target="#b18">Lai and Robbins (1985)</ref> for multi-armed bandits (see, e.g., <ref type="bibr" target="#b19">Lattimore and Szepesvári (2018)</ref>). The second assumption, namely P(B t &lt; v) &lt; t -γ , implies that the strategy must avoid underestimating the expected value; the latter assumption is naturally satisfied by the class of UCB-like strategies.</p><p>This result extends the lower bound proved by <ref type="bibr" target="#b26">Weed et al. (2016)</ref> in two important ways. First, it is not restricted to the case where the maximal opponent bid M t is constant (which is particular since there are in this case only two policies that can be optimal by either losing or winning all auctions). Second, this is a parameter-dependent bound, rather than a minimax one, that highlights the influence of the parameters of the problem (v and F ).</p><p>The upper bounds obtained in Section 3.2 for the regret of the three algorithms are of the order of log 2 T , when F satisfies Assumption 1. The lower bound 1 is therefore not sufficient to ensure that the rate of log 2 T is actually asymptotically optimal. In contrast, the dependence on v of the lower bound is enlightening, since it shows that Bernstein-UCBID and kl-UCBID are close to optimal with respect to v, when V t is drawn from a Bernoulli distribution. The regret bound for UCBID however is not on par with the lower bound for smaller values of v, suggesting a degraded performance in this regime (as will be illustrated by the numerical simulations in Section 5).</p><p>Idea of the proof In this paragraph we provide a quick overview of the proof, to highlight its differences from other lower bound arguments. For the complete proof, please refer to Appendix D.</p><p>Instead of considering only two alternative models that are difficult to distinguish from each other, and where mistaking one for the other necessarily leads to a high regret, we consider a different alternative for each of the T time steps. We fix a model in which all (V s ) T s=1 follow a Bernoulli distribution with expectation v, and the bids (M s ) T s=1 are distributed according to F . At each time t, we consider the alternative model where the values (V s ) T s=1 follow a Bernoulli distribution with expectation</p><formula xml:id="formula_9">v t = v + v(1-v)</formula><p>F (v)t , and the bids M t are distributed according to F . We apply Le Cam's method to obtain</p><formula xml:id="formula_10">P v B t &gt; v + v t 2 + P v t B t &lt; v + v t 2 ≥ 1 - 1 2 KL(P It v , P It v t ),<label>(2)</label></formula><p>where we name I t the information collected up to time t :</p><formula xml:id="formula_11">(M t-1 , V t-1 , . . . M 1 , V 1 ).</formula><p>The KL divergence between P It v and</p><formula xml:id="formula_12">P It v t can be proved to be equal to kl(v, v t )E v [N t ].</formula><p>Furthermore, Lemma 27 in Appendix D shows that the expected ratio of won auctions tends to F (v) under the assumptions of Theorem 4. Using this lemma, we obtain that ∀ &gt; 0, ∃t 1 ( ), ∀t ≥ t 1 ( ),</p><formula xml:id="formula_13">KL(P It v , P It v t ) ≤ kl(v, v t )(1 + )F (v)t.<label>(3)</label></formula><p>Combining Equations 2 and 3 yields an asymptotic bound on</p><formula xml:id="formula_14">P v B t &gt; v+v t 2 + P v t B t &lt; v+v t 2</formula><p>. The second assumption of Theorem 4 ensures that the probability of underbidding under the alternative model can be bounded by t -γ , so that it translates to a bound on the probability of overbidding by more than v(1-v) F (v)t under the fixed model. Combining this bound and the fact that</p><formula xml:id="formula_15">E v [(B t -v) 2 ] ≥ (v - v+v t 2 ) 2 P v B t &gt; v+v t 2 yields an asymptotic bound on T t=1 E v [(B t -v) 2 ] that reads lim inf T →∞ T t=1 E v [(B t -v) 2 ] log T ≥ v(1 -v) 8F (v) .</formula><p>If F admits a density bounded from below by β ¯, Lemma 9</p><formula xml:id="formula_16">(Appendix A.3) shows that R T (v) ≥ β 2 T t=1 E v [(B t -v) 2 ]:</formula><p>this concludes the proof.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Analysis of Worst Case Regrets</head><p>In addition to the parametric lower bound result, we provide another element that suggests that UCBID is outperformed by the other two strategies for small values of v. We do so by studying the maximal regret max v∈[0,1] R T (v) of the three strategies for all values of v ∈ [0, 1]. This maximal regret is likely to be reached when v is of the order of T -1/2 (respectively T -1/3 ) for UCBID (respectively BernsteinUCBID) (see Appendix E for more details).</p><p>Theorem 5 Without further assumption, the maximal regrets of UCBID, BernsteinUCBID and klUCBID are O( √ T log T ). If F has a density that is bounded from below and above by positive constants, the maximal regret of UCBID remains of the same order, while it is reduced to O(T 1 3 log 2 T ) for BernsteinUCBID and to O(log 2 T ) for klUCBID.</p><p>This result suggests that there exist important differences between UCBID, BernsteinUCBID and above all klUCBID. The proof highlights the overwhelming superiority of the latter in the presence of low values.</p><p>The worst-case upper-bounds should in principle be compared with a minimax lower bound. We refer to the lower bound of <ref type="bibr" target="#b26">Weed et al. (2016)</ref>, which is of the order of log T . By comparing it with the worst case bounds contained in this section and assuming that the obtained worst-case upper-bounds are tight, we observe that the maximal regret of UCBID is in reality not on par with the logarithmic lower-bound of <ref type="bibr" target="#b26">Weed et al. (2016)</ref>, since it is of the order of √ T log T , and not log T . Only klUCBID is guaranteed to close the gap between the worst-case regret and this minimax lower bound. The difference in the order of the worst-case regrets comes from the fact that the optimistic bonus contains a term linked to the variance in the case of klUCBID, whereas UCBID uses the very crude upper-bound 1/4. This has dramatic consequences for small values of v, causing a much higher worst-case regret for UCBID than for klUCBID.</p><p>Note that the bound on the regret of UCBID does not require any assumption on F and can even be proved without the assumption that the maximal bids M t of the adversaries are iid. (see the proof in Appendix E). Whereas in the multi-armed bandit setting, the known minimax lower bound for stochastic regret matches that of adversarial regret, this is not the case for second price auctions. Namely, <ref type="bibr" target="#b26">Weed et al. (2016)</ref> prove that the worst case adversarial regret is lower bounded by 1 32</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>√</head><p>T , while we prove here that the worst case regret of klUCBID is upper-bounded by O(log 2 T ). This discrepancy is in particular due to the fact that in the adversarial setting the maximal bids of the opponents M t can be chosen arbitrarily, so that they do not necessarily satisfy Assumption 1. Therefore, in the adversarial setting, the regret is linear around the optimal bid rather than quadratic, leading to higher regrets.</p><p>Idea of the proof. We only provide a sketch of the proof, please see Appendix E for details. We start with UCBID, with a different approach than in Section 3.2. The regret R T of any strategy is upper-bounded by</p><formula xml:id="formula_17">T t=1 E[(M t -v)1{v ≤ M t ≤ B t }] + T t=1 P(B t &lt; v), as proved in Lemma 14 in Appendix B.2. R T is hence also bounded by T t=1 E[(B t -v)1{M t ≤ B t }] + T t=1 P(B t &lt; v)</formula><p>, that is, the sum of the overbidding margins and the probabilities of underbidding. It is easy to show that the second term is smaller than a constant and can therefore be neglected for a large enough value of γ. This leaves us with the task of bounding the overbidding margins. By definition,</p><formula xml:id="formula_18">B t -v = Vt -v+ γ log T</formula><p>Nt . The deviations to the left, Vt -v, can be bounded with high probability by γ log T Nt , which results in the high probability bound:</p><formula xml:id="formula_19">B t -v ≤ 2 γ log T Nt . Since N t is incremented each time the auction is won, that is, each time M t is smaller than B t , we obtain T t=1 2 γ log T N t 1{M t ≤ B t } ≤ T n=1 2 γ log T n ≤ 2 γT log T .</formula><p>This yields the order of the worst case regret shown in Theorem 5 for UCBID.</p><p>As for BernsteinUCBID, the worst-case bound is also not a direct consequence of the bound presented in Section 3.2. We can use the same argument as for UCBID, but by bounding the deviations to the left using Berstein's instead of Hoeffding's inequality. This yields</p><formula xml:id="formula_20">E v [R T ] ≤ 2 2T w log(3T γ ) + O T ,</formula><p>where O T = O(log 2 (T )) does not depend on v. Using this bound for small values of v and the bound used in Section 3.2 for large values of v yields the given bound for BernsteinUCBID.</p><p>The proof of the worst-case regret for klUCBID requires some more work, as it cannot be based on the bound presented in Section 3.2 because of its asymptotic nature. It is a consequence of the time-dependent bound derived in Lemma 26 in Appendix C.3. This bound reads</p><formula xml:id="formula_21">E[R T ] ≤ C v F (v) log 2 (T ) + O T ,</formula><p>where C is a constant and O T does not depend on v and O T = o(log 2 T ) . We refer to Appendix C.3 for details.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">ETG algorithms</head><p>In multi-armed bandits, Explore Then Commit (ETC) strategies are a simplistic alternative to UCB. They are composed of two distinct phases: exploration, designed to estimate the return of each arm, and exploitation, where the agent plays the arm deemed more profitable. In the two arm case, ETC with an adaptive choice of the length of the exploration phase can reach competitive but sub-optimal performance (see e.g. <ref type="bibr" target="#b15">Garivier et al. (2016)</ref>). In the bidding model, due to the continuous nature of the problem at hand, the ETC strategy is not viable since any approach that simply commits to a fixed bid after some time is bound to incur a large regret. We consider instead the following class of strategies, termed Explore Then Greedy (ETG). In the exploration phase, the maximal value of the bid (B t = 1) is chosen to force observation. After a well-chosen stopping time, the bidder chooses either to abandon the bids (choosing B t = 0), or to continue with the running average of observed values (greedy phase). In the sequel, the exploration phase ends as soon as one is reasonably certain that the value v will either never more be under-estimated by a factor larger than 2 (stopping time τ 1 ), or is not worth bidding (stopping time τ 0 ).</p><p>ETG strategies have the advantage of being simple both to explain and to implement. Indeed, they only require the possibility of executing tests and of computing the running average. In the context of digital advertising, simplicity is critical, as most bidders operate through specialized platforms that only allow simple operations because of the very high frequency of auctions. ETG strategies are also closer to the methods that are naturally implemented by marketers and are therefore easily explainable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">ETGstop</head><p>We propose one instance of ETG, that we call ETGstop, defined by the following choice of stopping times τ 1 and τ 0 :</p><formula xml:id="formula_22">τ 1 := inf t ∈ [1, T ] : exp - tL t 8 ≤ 1 T 2 , τ 0 = inf t ∈ [1, T ] : U t ≤ 1 T 1 3 (4)</formula><p>where we denote by</p><formula xml:id="formula_23">L t = min{v ∈ [0, Vt [: exp -tkl( Vt , v) ≤ 1/T 2 } and by U t = max{v ∈ [ Vt , 1[: exp(-tkl( Vt , v)) ≥ 1/T 2 }</formula><p>the kl-lower and upper confidence bound for the confidence level 1/T 2 . This choice of τ 1 allows to guarantee that with high probability, if τ 1 is smaller than τ 0 , all bids will be larger than v 2 in the second phase. Indeed, we prove that for all n, P(</p><formula xml:id="formula_24">V (n) ≤ v 2 ) ≤ exp(-nkl(v, v 2 )) ≤ exp(-nv 8 )</formula><p>, where V (n) denotes the empirical mean of the first n observed values (see Lemma 11 in Appendix A). With high probability, exp(-nv 8 ) ≤ exp(-nLτ 8 ) ≤ 1 T 2 , for all n &gt; τ , since L t is a lower confidence bound of v. Therefore, the probability that there exists a time step in the second phase for which the average of the observed values is less than v/2 is small. Choosing this stopping time as the starting point of the greedy phase therefore ensures a minimal ratio of won auctions in this second phase.</p><formula xml:id="formula_25">Theorem 6 If F admits a density f , that satisfies ∃ β ¯, β &gt; 0, ∀x ∈ [0, 1], β ¯≤ f (x) ≤ β, then the regret of ETGstop satisfies : max v∈[0,1] R T (v) ≤ O(T 1 3 log 2 T ),</formula><formula xml:id="formula_26">and if v &gt; 1 T 1 3 , then R T (v) ≤ 7 + 64 log(T ) + 60T -1/2 v + 4 F (v/2) + β log 2 T F (v/2) .</formula><p>This result (proved in Appendix F) shows that the order of the regret of ETGstop is similar to that of UCBID, klUCBID and BernsteinUCBID, when v is large enough. It is also worth noticing that the bound of the worst case regret for ETGstop is similar to that of BernsteinUCBID and compares favorably to that of UCBID. In the numerical experiments, we show that ETGstop can outperform all other algorithms for large values, whereas its regret for small values v is larger than those of UCBID and (of course) klUCBID. Can smarter ETG strategies be designed, which would reach a significantly better performance? The following lower bound answers negatively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Minimax Lower Bound of the regret for ETG strategies</head><p>Theorem 7 If F admits a density lower-bounded by β ¯&gt; 0, then the regret of any ETG strategy satisfies</p><formula xml:id="formula_27">max v∈[0,1] R T (v) ≥ β ¯4 T 1 3 -1 . (<label>5</label></formula><formula xml:id="formula_28">)</formula><p>The proof of this result is given in Appendix G. This bound makes ETGstop minimax optimal in the class of ETG strategies, up to a log 2 T multiplicative factor. According to Theorem 5, the worst-case regret of klUCBID is of the order of log 2 T . Thus, the lower bound in (5) proves that ETG strategies are bound to be suboptimal in the minimax sense. It should not come as a surprise: in the MAB framework already, Explore Then Commit strategies are sub-optimal by a factor 2 on every two-armed Gaussian problem <ref type="bibr" target="#b15">(Garivier et al., 2016)</ref>, and it is natural to think that ETG strategies should suffer from the same drawback. However, the difference between UCB and ETG strategies for second price auctions is way more substantial, since the regret of ETG strategies is necessarilyof an order much larger than that of klUCBID.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Simulations</head><p>In Figure <ref type="figure" target="#fig_1">1</ref>(a), we plot the average regret of UCBID, kl-UCBID and Bernstein-UCBID, when V t is drawn from a Bernoulli distribution of expectation 0.2 and M t is drawn from a uniform distribution. The regret is computed on 10,000 time steps and averaged on 50,000 Monte Carlo trials. The plot clearly shows that on the first steps and for this particular configuration, kl-UCBID outperforms UCBID and Bernstein-UCBID. Bernstein-UCBID has a larger regret than UCBID and kl-UCBID. This comes from the fact that the variance is v(1 -v) in the present case, which makes kl-UCBID a better candidate.</p><p>In Figure <ref type="figure" target="#fig_1">1</ref>(b), we plot the average regret of UCBID, kl-UCBID and Bernstein-UCBID, when V t takes only two values 0.195 and 0.205, each with probability 1/2 and M t is uniform. Here, the horizon is 100,000 and we make 5,000 Monte Carlo trials. As predicted by the analysis of Section 3.2, Bernstein-UCBID outperforms UCBID on the long run. However, the regret of both UCBID and kl-UCBID is smaller than that of Bernstein-UCBID on small times. This comes from the fact that the optimistic bonus is dominated, in the beginning, by the term 3 log(3t γ )/N t which tends to be larger than the optimistic bonuses of the two other algorithms during the first time steps. Note that this is an extreme case, in which the greedy strategy would perform well, since the variance is very small.</p><p>We now compare the UCB algorithms to the simpler algorithm ETGstop and to other benchmarks. Other candidate algorithms include the greedy strategy, which submits the current average of the observed values, the K-armed bandit UCB on a discrete set of values in the (0, 1) interval and a unimodal bandits algorithm like LSE <ref type="bibr" target="#b27">(Yu and Mannor, 2011)</ref>. Note that UCB on discrete values does not take the structure of the problem into account. These algorithms have been tested for Bernoulli distributed values of mean 0.3 and uniform M t and the result is plotted in Figure <ref type="figure" target="#fig_1">1(c</ref>). The algorithm named GreedyBID is the greedy one and the one named UCB discrete is UCB on discrete values. The case displayed in Figure <ref type="figure" target="#fig_1">1</ref>(c) corresponds to UCB run on a uniform grid of 100 values. It was checked that it is not possible to significantly improve the performance of UCB by varying the discretization: making it coarser increases the regret, while making it finer slows down learning. Figure <ref type="figure" target="#fig_1">1(c)</ref> shows that the greedy strategy, the K-armed bandit UCB on a discrete set of values and LSE behave linearly and are therefore rapidly outperformed by the UCB type algorithms. We ran the simulations with a modified version of ETGstop that awaits τ 1 = inf{t ∈ [1, T ] : tL t ≥ 2 log T } instead of τ 1 before it starts the greedy phase. This new stopping time guarantees that the bids are larger then v/10 -rather than v/2 for the analyzed version of ETGStop-with high probability. Indeed, for all n &gt; τ 1 , P( V (n) ≤ v 10 ) ≤ exp(-nkl(v, v/10)) ≤ exp(-nv) ≤ 1 T 2 (the third inequality is obtained thanks to Lemma 11 in Appendix A) since L τ 1 &lt; v with high probability. Therefore, this version of ETGStop waits less than the analyzed version before it starts the second phase, and is thus more competitive in the regime where v is small, but is likely to accumulate more regret in the greedy phase. This version of ETGstop does not perform as well as UCBID and klUCBID, but outperforms BernsteinUCBID on the long run, showing that it can perform satisfactorily for large enough values.</p><p>In Figure <ref type="figure" target="#fig_1">1</ref>(d), we plot the regret after 5,000 time steps of UCBID, kl-UCBID, Bernstein-UCBID and ETGStop when M t is uniform and V t follows a Bernoulli distribution, as a function of the expectation of V t . We ran the simulations on 20 different values of v, using 50,000 Monte Carlo trials in each case. As expected from the result of Section 4, ETGstop performs poorly when v is small but outperforms the other strategies when v is large enough. Note that the peak of the regret of ETGStop is obtained around v = T -1 3 as suggested by the proof of Theorem 6. The regret of UCBID seems to increase when v gets close to T -1 2 , contrasting with the regrets of BernsteinUCBID and kl-UCBID which seem to reach a maximum for larger values, as suggested by the proof of Theorem 5.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusion</head><p>We have proposed new UCB strategies for buyers in repeated second-price auctions. We have shown that they improve significantly over the state of the art, both experimentally and theoretically. Our analysis emphasizes the role played by two important factors: the frequency of wins at the optimal bid and the variance of the value distribution that takes a dramatic importance when the value of the item is close to 0 or 1. We have also shown that simpler strategies may reach asymptotic performances similar to those of UCB-like algorithms. In the online advertising context, such strategies could be set up more easily by smaller stakeholders who do not necessarily own a programmatic bidder, but bid through demand-side platforms. However, by studying the worst-case regret of such strategies, we have shown that this simplicity has a price: they perform poorly when the value v lies under a certain threshold.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix A. General Lemmas</head><p>A.1. Maximal Utility Lemma 8 Assume that F admits a density. The utility writes</p><formula xml:id="formula_29">U t (b) = (V t -M t )1{b ≥ M t }. If there exists a &lt; v (respectively b &gt; v), such that F is constant on [a, v] (respectively [v, b]) then [a, v] ⊂ arg max b∈[0,1] U t (b) (respectively [v, b] ⊂ arg max b∈[0,1] U t (b)). Otherwise, arg max b∈[0,1] E U t (b) = {v}.</formula><p>In either case,</p><formula xml:id="formula_30">max b∈[0,1] T t=1 E[U t (b)] = T t=1 E[{v -M t }1{M t &lt; v}].</formula><p>Proof If F admits a density f , then F is continuous and non decreasing. We can write:</p><formula xml:id="formula_31">E[U t (b)] = b 0 (v -m)f (m)dm = b 0 vf (m)dm - b 0 mf (m)dm = vF (b) -[mF (m)] b 0 + b 0 F (m)dm = (v -b)F (b) + b 0 F (m)dm, E[U t (v)] -E[U t (b)] = v 0 F (m)dm -(v -b)F (b) - b 0 F (m)dm = v b (F (m) -F (b))dm.</formula><p>This latter quantity is non negative. It vanishes if and only if</p><formula xml:id="formula_32">F is constant, on [b, v], if b &lt; v, and on [v, b], if v ≤ b. In particular, E[U t (b)] ≤ E([(V t -M t )1(M t ≤ v)]),</formula><p>and</p><formula xml:id="formula_33">max b∈[0,1] T t=1 E[U t (b)] = T t=1 E[{v -M t }1{M t ≤ v}].</formula><p>Equivalently, we can prove the same close form of</p><formula xml:id="formula_34">max b∈[0,1] T t=1 E[U t (b)</formula><p>] by observing that:</p><formula xml:id="formula_35">max b∈[0,1] T t=1 E[(V t -M t )1{M t ≤ b}] = max b∈[0,1] T t=1 E[(v -M t )1{M t ≤ b}], because V t does not depend on M t . As (v -M t )1{M t ≤ b} ≤ (v -M t )1{M t ≤ v} , one has max b∈[0,1] T t=1 E[U t (b)] = T t=1 E[(v -M t )1{M t ≤ v}] = T t=1 E[(V t -M t )1{M t ≤ v}].</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2. An Expression of the Regret</head><p>The instantaneous regret can be rewritten as</p><formula xml:id="formula_36">r t = (M t -V t )1{v &lt; M t ≤ B t } + (V t -M t )1{B t &lt; M t ≤ v}.<label>(6)</label></formula><p>In fact, the regret may only be different from zero when M t lies between v and B t , otherwise bidding v and B t lead to the same utility. In the right hand side of ( <ref type="formula" target="#formula_36">6</ref>), the first (respectively second) term describes the case when the bidder wins (respectively loses) the auction.</p><p>A.3. Quadratic lower and upper bounds of the regret Lemma 9 If F admits a density f , which satisfies</p><formula xml:id="formula_37">∃ β ¯, β &gt; 0, ∀x ∈ [0, 1], β ¯≤ f (x) ≤ β; Then, β ¯2 T t=1 E[(B t -v) 2 ] ≤ R T ≤ β 2 T t=1 E[(B t -v) 2 ].</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Proof</head><p>The instantaneous regret writes :</p><formula xml:id="formula_38">E[r t (b)] = E[U t (v)] -E[U t (b)] = v b F (m)dm -(v -b)F (b) = v b (F (m) -F (b))dm = v b m b f (u)dudm</formula><p>where the first equality comes from Lemma 8.</p><formula xml:id="formula_39">Hence β ¯ v b (m -b)dm ≤ r t (b) ≤ β v b (m -b)dm if b ≤ v, β ¯ b v (b -m)dm ≤ r t (b) ≤ β b v (b -m)dm if v &lt; b, Thus 1 2 β ¯(b -v) 2 ≤ r t (b) ≤ 1 2 β(b -v) 2 .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.4. Bounds on the KL divergence between Bernoulli distributions</head><p>Lemma 10 ∀p ∈ [0, 1], q ∈]0, 1]</p><formula xml:id="formula_40">kl(p, q) ≥ (p -q) 2 2x(1 -x) ≥ (p -q) 2 2x ,</formula><p>where x := p+2q 3 Proof Thanks to Taylor's form, kl(p, q) = (p-q) 2 2 1 0 ψ (q + s(p -q))2(1 -s)ds, where ψ : x → kl(x, q) and hence ψ (x) = 1</p><p>x(1-x) . We apply Jensen's inequality, using</p><formula xml:id="formula_41">1 0 2(1 -s)ds = 1 3 . 1 0 ψ (q + s(p -q))2(1 -s)ds ≥ ψ 1 0 q + s(p -q)2(1 -s)ds ≥ ψ 1 3 (p -q) + q ≥ ψ 1 3 (p + 2q) . Lemma 11 For any v in [0, 1], for any α ∈] -1, 1 v -1[, kl (1 + α)v, v ≥ α 2 v 2 1 + α/3 .</formula><p>Proof This lemma is a direct consequence of Lemma 10.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.5. An Inequality Based on Benett's Inequality</head><p>Lemma 12 For all n, such that n ≤ log T v ,</p><formula xml:id="formula_42">P V (n) -v ≥ v + log T n ≤ 1 T .</formula><p>For all n, such that n ≥ log T v ,</p><formula xml:id="formula_43">P V (n) -v ≥ 2v log T n ≤ 1 T .</formula><p>Proof We use Benett's inequality:</p><formula xml:id="formula_44">P( V (n) -v ≥ x) ≤ exp -nwg( x w )</formula><p>where g(u) = (1 + u) log(1 + u) -u. Let h x (w) = wg(x/w). For all x &gt; 0, h x is decreasing, its derivative being h x (w) = log(1 + x w ) -x w . Therefore</p><formula xml:id="formula_45">P( V (n) -v ≥ x) ≤ exp -nv(1 -v)g x v(1 -v) ≤ exp -nvg x v .</formula><p>We call v + (n) the solution of: vg(</p><formula xml:id="formula_46">x v ) = log T n in [0, ∞[ (it will become clear that the solution is unique). v + (n) satisfies P( V (n) ≥ v + (n)) ≤ 1</formula><p>T . We aim at bounding v + (n). Since g (u) = log(1 + u), and g (u) = 1 1+u &gt; 0 when u &gt; -1, g is strictly convex on [-1, ∞]. Also, we can define an inverse g -1 on ]0, ∞].</p><p>Additionally, g(e -1) = 1 and g (e -1) = 1, so g(x) ≥ x -(e -2) ≥ x -1, ∀x &lt; e -1, by convexity. When x ≥ e -1, we can prove g(x) ≥ x e-1 2 by analyzing the function g(x) -x e-1</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2</head><p>.</p><p>Therefore if log T vn ≥ 1,</p><formula xml:id="formula_47">v + (n) = vg -1 log T vn ≤ v + log T n ,</formula><p>and if log T vn ≤ 1,</p><formula xml:id="formula_48">v + (n) = vg -1 log T vn ≤ (e -1) v log T n ≤ 2v log T n .</formula><p>Appendix B. Proof of Theorem 1 and Theorem 3</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.1. Sketch of the Proofs</head><p>The methods used to obtain the bounds follow the same pattern for the three UCB algorithms. In this sketch of proof, we focus for simplicity on the case when Assumption 3 is valid, see Sections B.6 and B.7 for more general arguments. We first observe that the regret R T of any strategy is upper-bounded by</p><formula xml:id="formula_49">T t=1 E[(M t -v)1{v ≤ M t ≤ B t }] + T t=1 P(B t &lt; v).<label>(7)</label></formula><p>as proved in Lemma 14 in Section B.2 below. We start by bounding the second term of the right hand side of inequality ( <ref type="formula" target="#formula_49">7</ref>) by bounding the deviations to the left of Vt . Furthermore, when F satisfies Assumption 3 with parameter α and constant β, we can prove that</p><formula xml:id="formula_50">E[(M t -v)1{v ≤ M t ≤ B t }] ≤ E β (B t -v) 1+α + F (v) 1{M t &lt; B t } ,</formula><p>by conditioning on the intersection of F t-1 and the σ-algebra generated by 1{M t &lt; B t }. This is proved in Lemma 15 in Section B.2. Then we use the following result, proved by a re-sampling argument. (See Section B.2 for the proof.)</p><p>Lemma 13</p><formula xml:id="formula_51">E T t=1 β(B t -v) 1+α + F (v) 1{M t ≤ B t } ≤ β F (v) E T n=1 (B + (n) -v) 1+α + ,<label>(8)</label></formula><p>where</p><formula xml:id="formula_52">B + (n) = min 1, V (n) + γ log T 2n for UCBID, B + (n) = {x : x &gt; V (n), kl( V (n), x) = γ log T n } for kl-UCBID, B + (n) = min 1, V (n) + 2 W (n) log(3T γ ) n + 3 log(3T γ ) n</formula><p>for Bernstein-UCBID.</p><p>The virtual bids B + (n) (indexed by the number n of observations rather than by the time t) are obtained by replacing the value of t by the horizon T in the expression of the bids. They are a clear upper bound on B(n). Although the horizon is not known a priori, it is convenient to consider these virtual bids in the analysis. Bounding the right hand side sum in Lemma 13 is not hard in the case of UCBID and Bernstein-UCBID, using the following inequality for each term: for any non negative sequence</p><formula xml:id="formula_53">(A n ), E[X 1+α + ] = E[X 1+α + 1{X ≤ A n }] + E[X 1+α + 1{A n &lt; X}] ≤ E[A 1+α n ] + P(A n &lt; X) ,</formula><p>where</p><formula xml:id="formula_54">X = (B + (n) -v), knowing that X ∈ [0, 1].</formula><p>Setting A n equal to the minimum of 1 and two times the optimistic bonus (e.g. A n = min(1, 2 γ log T /(2n)) in the case of UCBID), one sees that the probability P(A n &lt; X) is smaller than the probability that the mean value be larger than v plus the optimistic bonus. We bound this latter probability, by bounding the deviations to the right of Vt . Using this inequality term-wise leads to the upper bounds on the regret presented in the paper for both UCBID and Bernstein-UCBID.</p><p>For kl-UCBID, the argument is somewhat different because there is no closed-form expression for the optimistic bonus, and the decomposition above cannot be used directly. Another difficulty is the fact that the Kullback-Leibler function for Bernoulli distribution is not symmetric. The proof of the upper bound on the regret of kl-UCBID is therefore more technical, but follows the same general pattern.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.2. Proof of the General Lemmas used for the Upper Bound of the regret of UCB strategies B.3. General Bound on the Regret</head><p>Lemma 14 The regret R T of any strategy is upper-bounded by</p><formula xml:id="formula_55">T t=1 E[(M t -v)1{v ≤ M t ≤ B t }] + T t=1 P(B t &lt; v).<label>(9)</label></formula><p>It holds</p><formula xml:id="formula_56">E[r t |M t , B t ] = (M t -v)1{v &lt; M t ≤ B t } + (v -M t )1{B t &lt; M t ≤ v}.</formula><p>Lemma 14 follows from (6) and uses the fact that E</p><formula xml:id="formula_57">[(v -M t )1{B t &lt; M t &lt; v}] ≤ E[1{B t &lt; M t }]</formula><p>, since all the variables at stake take their values in [0, 1].</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.4. Bound due to the Margin Condition</head><p>Lemma 15 If F satisfies Assumption (2) with parameter α and constant β, the expected cumulative regret is bounded by:</p><formula xml:id="formula_58">R T ≤ T t=1 E β(B t -v) α+1 + F (v) 1{M t &lt; B t } + T t=1 P(B t &lt; v). (<label>10</label></formula><formula xml:id="formula_59">)</formula><p>Compared to the bound in Equation ( <ref type="formula" target="#formula_49">7</ref>), only the first term has changed. The new one is slightly easier to bound, because instead of having to control the unknown quantity M t -v, we only have to control B t -v. Proof Let G t denote the sigma algebra generated by the intersections of elements of F t-1 and σ(1{M t ≤ B t }). We consider the following conditional expectation:</p><formula xml:id="formula_60">E [(M t -v)1{0 ≤ M t -v ≤ B t -v} |G t ] = Bt v (x -v)dF (x) F (B t ) 1{M t ≤ B t }1{v ≤ B t }. Thanks to the margin condition, if v ≤ B t , Bt v (x -v)dF (x) ≤ (B t -v) (F (B t ) -F (v)) ≤ β(B t -v) 1+α ,</formula><p>and</p><formula xml:id="formula_61">F (B t ) ≥ F (v) when v ≤ B t . Therefore, E [(M t -v)1{0 ≤ M t -v ≤ B t -v} |G t ] ≤ β(B t -v) 1+α F (v) 1{M t ≤ B t }1{v ≤ B t }.</formula><p>We stress that the above bound may be improved in some cases: indeed, if for example M t is distributed uniformly, then the exact value of the integral is 1 2 (B t -v) 2 , which is half of our upper bound (since the margin condition parameter is 1 in this case). Now it only remains to apply the chain rule and to sum over T terms to obtain the following bound :</p><formula xml:id="formula_62">T t=1 E [(M t -v)1{0 ≤ M t -v ≤ B t -v}] s ≤ T t=1 β(B t -v) 1+α + F (v) 1{M t ≤ B t }.</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.5. Proof of Lemma 13</head><p>We prove Lemma 13 by using a re-sampling argument.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E[</head><p>T t=1</p><formula xml:id="formula_63">(B t -v) α+1 + 1{M t ≤ B t }] ≤ E T t=1 t n=1 (B t -v) 1+α + 1{N t = n, N t-1 = n -1} ≤ E T t=1 t n=1 (B + (n) -v) 1+α + 1{N t = n, N t-1 = n -1} ≤ E T n=1 T t=1 (B + (n) -v) 1+α + 1{N t = n, N t-1 = n -1} ≤ E T n=1 (B + (n) -v) 1+α + .</formula><p>The second inequality follows from a simple re-writing, where we slightly abuse notation by taking N 0 = 0. The second inequality uses the fact that B + (n) is an upper bound of B(n). The third one follows from an inversion of the sums: note that we did not lose any information, since when t &gt; n, 1{N t = n, N t-1 = n -1} = 0.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.6. Upper Bound on the Regret of UCBID under Assumption 3</head><p>In this paragraph, we prove the following version of Theorem 1, under a margin condition holding on <ref type="bibr">[v, 1]</ref>. For a proof of the localized version, see section B.8.</p><p>Theorem 16 If F satisfies Assumption 2 with parameter α around v on [v, 1] and F (v) &gt; 0, then the UCBID algorithm with parameter γ &gt; 1 yields a regret bounded as follows :</p><formula xml:id="formula_64">R T ≤                          C γ + β F (v) 2(γ log T ) 1+α 2 1-α (T ) 1-α 2 + 1 + 1 if α &lt; 1, C γ + β F (v) ((2γ log T )(log T + 1) + 1) if α = 1, C γ + β F (v) 6γ log T α-1 + 1 if α &gt; 1.</formula><p>where</p><formula xml:id="formula_65">C γ := ∞ t=1 e √ γ log t+1 t γ &gt; 0.</formula><p>We first need the following lemma.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Lemma 17</head><p>The UCBID strategy ensures that the sum of probabilities in Lemma 15 is bounded by a constant:</p><formula xml:id="formula_66">T t=1 P(v &gt; B t ) ≤C γ := T t=1 e √ γ log t + 1 t γ .</formula><p>Proof We use Lemma 10 in <ref type="bibr" target="#b6">Cappé et al. (2013)</ref>, using the fact that V t is a random variable bounded in [0,1] and thus 1/2 subgaussian.</p><formula xml:id="formula_67">P(v &gt; B t ) = P(v -V (N t ) &gt; γ log t 2N t ) = P( 2N t (v -V (N t )) &gt; γ log t) ≤ P(∃n &lt; t, √ 2n(v -V (n) &gt; γ log t)</formula><p>≤ e γ log t log t exp (-γ log t)</p><formula xml:id="formula_68">≤ e √ γ log t + 1 t γ . Set X = (B + (n) -v).</formula><p>As explained in Section B.1, we use the following inequality :</p><formula xml:id="formula_69">∀A n &gt; 0, E[X 1+α + ] = E[X 1+α + 1{X ≤ A n }] + E[X 1+α + 1{A n &lt; X}] ≤ E[A 1+α n ] + P(A n &lt; X)</formula><p>Here we take A n equal to exactly the minimum of 1 and 2 times the optimistic bonus</p><formula xml:id="formula_70">A n = min 1, 2 γ log T 2n</formula><p>, so that P(A n &lt; X) is smaller than the probability that the mean overestimates v by more than the optimistic bonus. Hence,</p><formula xml:id="formula_71">E[(B + (n) -v) 1+α + ] ≤ (A n ) 1+α + P 2 γ log T 2n &lt; B + (n) -v .</formula><p>It holds that</p><formula xml:id="formula_72">P min 1, 2 γ log T 2n &lt; B + (n) -v ≤ P 2 γ log T 2n &lt; B + (n) -v + P(1 &lt; B + (n) -v) ≤ P 2 γ log T 2n &lt; V (n) -v + γ log T 2n ≤ P γ log T 2n &lt; V (n) -v ≤ T -γ ,</formula><p>where the last line follows from Hoeffding's inequality.</p><p>By combining Lemma 15, Lemma 13 and Lemma 17, we finally obtain</p><formula xml:id="formula_73">R T ≤ C γ + T n=1 β/F (v)E[(B + (n) -v) 1+α + ] ≤ C γ + β/F (v) T n=1 A 1+α n + T -γ ≤ C γ + β/F (v) T n=1 2γ log T n 1+α 2 + 1 ≤ C γ + β/F (v) (2γ log T ) 1+α 2 T n=1 1 n 1+α 2 + 1 , since A n ≤ 2γ log T n</formula><p>, ∀n ∈ N. For α &gt; 1, we improve the bound by using that A n = 1, ∀n ≤ 2γ log T. This yields,</p><formula xml:id="formula_74">R T ≤ C γ + β/F (v) T 1-γ + 2γ log T + 2γ log T 1+α 2 T n=2γ log T 1 n 1+α 2 ,</formula><p>We conclude by observing that :</p><formula xml:id="formula_75">T n=1 1 n 1+α 2 ≤ 2 1-α (T ) 1-α 2 + 1 if α &lt; 1 log T + 1 if α = 1,</formula><p>and that</p><formula xml:id="formula_76">T n=2γ log T 1 n 1+α 2 ≤ 2 (2γ log T ) α-1 2 α -1 if α &gt; 1.</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.7. Upper Bound on the Regret of Bernstein-UCBID under Assumption 3</head><p>We prove the following version of Theorem 3, under a margin condition holding on <ref type="bibr">[v, 1]</ref>. The proof under a localized margin condition is given in Appendix B.8.</p><p>Theorem 18 If F satisfies Assumption 2 with parameter α around v on [v, 1] and F (v) &gt; 0, the Bernstein-UCBID algorithm with parameter γ &gt; 2 yields a regret bounded as follows :</p><formula xml:id="formula_77">R T ≤C γ +                    β F (v) (8w log(3T γ )) 1+α 2 2 1-α T 1-α 2 + 1 + β F (v) (6c 1 log(3T γ )) 1+α + 1 if α &lt; 1, β F (v) 8w log(3T γ )(log T + 1) + β F (v) (6c 1 log(3T γ )) 1+α + 1 if α = 1, β F (v) ( 8w(α+1) α-1 + 1 α ) log(3T γ ) if α &gt; 1,</formula><p>where</p><formula xml:id="formula_78">c 1 := ∞ n=1 1 n 1+α ≤ ∞ n=1 1 n 2 = π 2 /6, and C γ := T t=1 t 1-γ .</formula><p>We first need the following lemma.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Lemma 19</head><p>The Bernstein-UCBID strategy ensures that the first term in Equation (10) in Lemma 15 is bounded by a constant:</p><formula xml:id="formula_79">T t=1 P(v &gt; B t ) ≤ T t=1 t 1-γ := C γ . Proof T t=1 P (B t &lt; v) ≤ T t=1 P   Vt + 2 Wt log(3t γ ) N t + 3 log(3t γ ) N t &lt; v   ≤ T t=1 t n=1 P v &gt; V (n) + 2 W (n) log(3t γ ) n + 3 log(3t γ ) n ≤ T t=1 t n=1 t -γ ≤ T t=1 t 1-γ ,</formula><p>where we use a simple union bound for the second inequality, and the Bernstein's deviation inequality for the third inequality.</p><p>Let X denote B + (n) -v. As explained in Section B.1, we use the following inequality :</p><formula xml:id="formula_80">∀A n &gt; 0, E[X 1+α + ] = E[X 1+α + 1{X ≤ A n }] + E[X 1+α + 1{A n &lt; X}] ≤ E[A 1+α n ] + P(A n &lt; X)</formula><p>Here we choose A n as 2 times the optimistic bonus</p><formula xml:id="formula_81">A n = min 1, 2 2 W (n) log(3T γ ) n + 3 log(3T γ ) n .</formula><p>It holds</p><formula xml:id="formula_82">E[(B + (n) -v) 1+α + ] ≤ E   min 1, 8 W (n) log(3T γ ) n + 6 log(3T γ ) n 1+α   (11) + P 8 W (n) log(3T γ ) n + 6 log(3T γ ) n &lt; B + (n) -v ≤ E min 1, 2 2 W (n) log(3T γ ) n 1+α + 6 log(3T γ ) n 1+α (<label>12</label></formula><formula xml:id="formula_83">)</formula><formula xml:id="formula_84">+ P 8 W (n) log(3T γ ) n + 6 log(3T γ ) n &lt; V (n) -v + 2 W (n) log(3T γ ) n + 3 log(3T γ ) n ≤ E min 1, 8 W (n) log(3T γ ) n 1+α 2 + min 1, 6 log(3T γ ) n 1+α<label>(13)</label></formula><formula xml:id="formula_85">+ P 2 W (n) log(3T γ ) n + 3 log(3T γ ) n &lt; V (n) -v ≤ E W (n) 1+α 2 min 1, 8 log(3T γ ) n 1+α 2 + min 1, 6 log(3T γ ) n 1+α + T -γ ,</formula><p>when α ≤ 1. The last inequality stems from Jensen's inequality, which can only be applied when α ≤ 1, and from Bernstein's deviation inequality.</p><formula xml:id="formula_86">When α ≥ 1, we can bound E[(B + (n) -v) 1+α + ] by E W (n) min 1, 8 log(3T γ ) n 1+α 2 + min 1 6 log(3T γ ) n 1+α + T -γ .</formula><p>Let us come back to the case when α ≤ 1.</p><formula xml:id="formula_87">Since E W (n) = n-1 n w ≤ w and γ &gt; 1, E[(B + (n) -v) 1+α + ] ≤ w 1+α 2 8 log(3T γ ) n 1+α 2 + 6 log(3T γ ) n 1+α + 1,</formula><p>By combining Lemma 15, Lemma 13 and Lemma 17, we obtain</p><formula xml:id="formula_88">R T ≤ C γ + T n=1 β/F (v)E[(B + (n) -v) 1+α + ] ≤ C γ + β/F (v) T n=1 w 1+α 2 8 log(3T γ ) n 1+α 2 + c 1 (6 log(3T γ )) 1+α + 1 , where c 1 := ∞ n=1 1 n 1+α ≤ ∞ n=1 1 n 2 = π 2 /6. When α &gt; 1, we argue that we can bound E[(B + (n) -v) 1+α + ] by E W (n) min 1, 8 log(3T γ ) n 1+α 2 + min 1, 6 log(3T γ ) n 1+α + T -γ ,</formula><p>since the first three inequalities ( <ref type="formula">11</ref>),( <ref type="formula" target="#formula_82">12</ref>), ( <ref type="formula" target="#formula_84">13</ref>), still hold. The regret is therefore bounded by</p><formula xml:id="formula_89">R T ≤ C γ + T n=1 β F (v) E[(B + (n) -v) 1+α + ] ≤ C γ + β F (v) T n=8 log(3T γ ) w 8 log(3T γ ) n 1+α 2 + T n=8 log(3T γ ) (6 log(3T γ )) n 1+α 1+α + 8 log(3T γ ) + 1 because 8 log(3T γ ) n 1+α 2 ≤ 1 and 6 log(3T γ ) n 1+α</formula><p>≤ 1, when n ≥ 8 log(3T γ ). We conclude by observing that : </p><formula xml:id="formula_90">T n=1 1 n 1+α 2 ≤ 2 1-α (T ) 1-α 2 + 1 if α &lt; 1; log T + 1 if α = 1. and that if α &gt; 1, T n=8 log(3T γ ) 1 n 1+α 2 ≤ 2 8 log(3T γ ) α-1 2 α -1 .</formula><formula xml:id="formula_91">D T = 2γ log T ∆ 2 + 1 for the case of UCBID, 12 ∆ + 32 ∆ 2 log(3T γ ) + 1 for Bernstein-UCBID.</formula><p>Proof Alternatively to inequality (7), we use</p><formula xml:id="formula_92">R T ≤ T t=1 E [(M t -v)1{v ≤ M t ≤ B t }] + T t=1 P(B t &lt; v) ≤ T t=1 E [(M t -v)1{v ≤ M t ≤ B t &lt; v + ∆}] + T t=1 P(B t &lt; v) + T t=1 P{v + ∆ ≤ B t , v ≤ M t ≤ B t }.</formula><p>The first two terms are bounded exactly as in the proofs of Theorems 16 and 18. The last term is treated as follows.</p><formula xml:id="formula_93">T t=1 P(v + ∆ ≤ B t , v ≤ M t ≤ B t ) ≤ T t=1 t n=1 P(v + ∆ ≤ B + (n))1{M t &lt; B t } ≤ t n=1 P(v + ∆ ≤ B + (n)) ≤ t n=1 P(∆ -A n ≤ V (n) -v) ≤ t n=1 P(A n ≤ V (n) -v) + P(∆ &lt; 2A n ),</formula><p>where A n corresponds to min 1, 2 γ log T 2n for UCBID and</p><formula xml:id="formula_94">A n is min 1, 2 2 W (n) log(3T γ ) n + 3 log(3T γ ) n ,</formula><p>for Bernstein-UCBID.</p><p>The second inequality is proved with similar arguments to those of the proof of Lemma 13. In the case of UCBID, when n &gt; 2γ log T ∆ 2 , ∆ ≥ 2A n , therefore P(∆ &lt; 2A n ) = 0 for n &gt; 2γ log T ∆ 2 . In the case of Bernstein-UCBID,</p><formula xml:id="formula_95">P(∆ &lt; 2A n ) ≤ 1{∆ &lt; 12 log(3T γ ) n } + P(∆ &lt; 32 W (n) log(3T γ ) n ), since ∆ &lt; a + b implies that ∆ &lt; 2a or ∆ &lt; 2b. When n &gt; 12 log(3T γ ) ∆</formula><p>, the first term is equal to 0. The second term is equal to P(</p><formula xml:id="formula_96">∆ 2 32 log(3T γ ) &lt; W (n) n ). Since W (n) ≤ 1, P( ∆ 2 32 log(3T γ ) W (n) n ) is smaller than 1{n ≤ 32 ∆ 2 log(3T γ )}. This yields T t=1 P(v + ∆ ≤ B t , v ≤ M t ≤ B t ), ≤ 1 + 2γ log T ∆ 2 for UCBID 12 ∆ + 32 ∆ 2 log 3T γ for Bernstein-UCBID.</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix C. Upper Bound of the Regret of klUCBID</head><p>We first prove the following version of Theorem 2 under the assumption that the margin condition holds uniformly on [v, 1]. We will explain how to adapt the proof to the localized margin condition in Appendix C.2.</p><p>Theorem 21 If F satisfies Assumption 3 and F (v) &gt; 0, the kl-UCBID algorithm with parameter γ &gt; 1 yields the following asymptotic bound on the regret:</p><formula xml:id="formula_97">lim sup T →∞ R T (log T ) 1+α 2 (T ) 1-α 2 ≤ 2β F (v)(1 -α) (8γv(1 -v))) 1+α 2 , if α &lt; 1. lim sup T →∞ R T (log T ) 2 ≤ β F (v) 8γv(1 -v), if α ≥ 1.</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.1. Analysis under Assumption 3</head><p>We first prove the following lemma.</p><p>Lemma 22 The kl-UCBID strategy ensures that the second term in Lemma 15 is bounded by a constant:</p><formula xml:id="formula_98">T t=1 P(B t &lt; v) ≤ C γ .</formula><p>Proof We apply Theorem 10 of <ref type="bibr" target="#b14">Garivier and Cappé (2011)</ref>, and sum over {1 . . . T } as in the proof of Lemma 17. Now let us bound the right hand side of inequality (8) in Lemma 13.We note that</p><formula xml:id="formula_99">E T n=1 (B + (n) -v) 1+α + ≤ T n=1 E[(U γ (n) -v) 1+α 1{L γ (n) &lt; v}] + P(v ≤ L γ (n)) ,</formula><p>where</p><formula xml:id="formula_100">U γ (n) = {q : V (n) &lt; q, kl( V (n), q) = γlogT n } = B + (n), and L γ (n) = {q : q ≤ V (n), kl( V (n), q) = γlogT n }.</formula><p>Before getting to the proof, we state an important lemma showing that for any θ, there exists a neighborhood in which for all θ, u, kl( θ, u) is lower bounded by a specific quadratic function of u -θ.</p><formula xml:id="formula_101">Lemma 23 ∀θ, ∀ , ∃η (θ) &lt; 1, such that if θ, u ∈ [θ -η (θ), θ + η (θ)], kl( θ, u) ≥ (u -θ) 2 2θ(1 -θ)(1 + ) .</formula><p>Proof Using the Lagrange form of Taylor theorem,</p><formula xml:id="formula_102">kl( θ, u) ≥ (u -θ) 2 2 max x∈[ θ,u] x(1 -x)</formula><p>.</p><p>By continuity of x(1 -x), there exists a neighborhood of θ, in which</p><formula xml:id="formula_103">x(1 -x) ≤ (1 + )θ(1 -θ). Therefore, if θ, u are in this interval, ∀x ∈ [ θ, u], x(1 -x) ≤ (1 + )θ(1 -θ).</formula><p>Lemma 24 For &gt; 0 and η defined as in Lemma 23, set</p><formula xml:id="formula_104">n 0 (v, T, ) = 8γ log T η 2 .</formula><p>Then ∀n ≥ n 0 (v, T, ),</p><formula xml:id="formula_105">E[(U γ (n) -v) 1+α + ] ≤ T -γ + P(v ≤ L γ (n)) + 2 2γ log T v(1 -v)(1 + ) n 1+α .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Proof</head><p>In this proof we will use the notation n 0 instead of n 0 (v, T, ) for the sake of clarity. We can show that n 0 is defined so that exp(-</p><formula xml:id="formula_106">n 0 (v,T, ) 2 η (v) 4 ) ≤ exp(-n 0 (v,T, ) 2 η 2 (v) 4 ) ≤ T -γ . Therefore, if n &gt; n 0 , with probability larger than 1 -T -γ , |v -V (n)| ≤ η /4, thanks to Hoeffding's inequality. Hence, if n &gt; n 0 , with probability larger than 1 -δ, if x ∈ [L γ (n), U γ (n)], | V (n) -x| ≤ 1 2 kl( V (n), x) ≤ γ log T 2n ≤ η 2 4 ≤ η 2 ,</formula><p>where the first inequality follows from Pinsker's inequality, the second stems from the definition of L γ (n) and U γ (n) and the third one as a result of the definition of n 0 . And</p><formula xml:id="formula_107">|v -x| ≤ | V (n) -x| + | V (n) -v| ≤ η /2 + η /4 ≤ η .</formula><p>Finally, using Lemma 23,</p><formula xml:id="formula_108">kl( V (n), x) - (x -V (n)) 2 2v(1 -v)(1 + ) ≥ 0.</formula><p>Hence, with probability larger than</p><formula xml:id="formula_109">1 -T -γ , U γ (n) -L γ (n) ≤ 2 2γ log T v(1 -v)(1 + ) n ,</formula><p>thanks to Lemma 23. Indeed the distance between U γ (n) and L γ (n) is larger than the distance between the two roots of the quadratic lower bound minus log T n . Therefore,</p><formula xml:id="formula_110">E[(U γ (n) -v) 1+α + ] ≤ E[(U γ (n) -v) 1+α + 1{v ∈ [L γ (n), U γ (n)]}] + P(v ≤ L γ (n)) ≤ 2 2γ log T v(1 -v)(1 + ) n 1+α + P(v ≤ L γ (n)) + T -γ . Since, in fact B + (n) = U γ (n), E T n=1 (B + (n) -v) 1+α + ≤ n 0 (v, T, ) + T n=n 0 (v,T, ) P(v ≤ L γ (n)) + T n=n 0 (v,T, ) T -γ + T n=n 0 (v,T, ) 2 2γ log T v(1 -v)(1 + ) n 1+α ≤ n 0 (v, T, ) + 2 T n=n 0 (v,T, ) T -γ + T n=n 0 (v,T, ) 2 2γ log T v(1 -v)(1 + ) n 1+α ≤ n 0 (v, T, ) + 2T 1-γ + T n=1 2 2γ log T v(1 -v)(1 + ) n 1+α ,</formula><p>where the third inequality comes from the fact that P(v ≤ L γ (n)) ≤ T -γ , which is a result of Chernoff's deviation inequality (see Corollary 10.14 of <ref type="bibr" target="#b19">Lattimore and Szepesvári (2018)</ref>). Thus,</p><formula xml:id="formula_111">R T ≤ C γ + n 0 (v, T, ) + 2T 1-γ + T n=1 2 2γ log T v(1 -v)(1 + ) n 1+α</formula><p>For α &lt; 1, We use :</p><formula xml:id="formula_112">T n=1 1 n 1+α 2 ≤ 1 + 2 1 -α (T ) 1-α 2 if α &lt; 1.</formula><p>We handle the case α ≥ 1 by observing that when n ≥ 8γv(1 -v)(1 + ) log T ,</p><formula xml:id="formula_113">2 2γ log T v(1-v)(1+ ) n 1+α ≤ 8 γ log T v(1-v)(1+ ) n .</formula><p>We also use that</p><formula xml:id="formula_114">T n=8γv(1-v)(1+ ) log T 1 n 1+α 2 ≤ T n=8γv(1-v)(1+ ) log T 1 n .</formula><p>Hence,</p><formula xml:id="formula_115">R T ≤ C γ + n 0 (v, T, ) + 2 +            β F (v) (8γv(1 -v)(1 + ) log T ) 1+α 2 2 1-α (T ) 1-α 2 if α &lt; 1 β F (v) 8v(1 -v)(1 + )γ log T (log T + 1) if α ≥ 1</formula><p>where n 0 (v, T, ) = max(n 0 (v, T, ), 8γv(1 -v) log T ).</p><p>Also, using the fact that</p><formula xml:id="formula_116">n 0 = 8γ log T η 2 , n 0 (v, T,</formula><p>) is therefore negligible compared to (log 2 T ) and to T 1-α 2 when α &lt; 1. And ∀ &gt; 0, lim sup</p><formula xml:id="formula_117">T →∞ R T (log T ) 1+α 2 (T ) 1-α 2 ≤ β F (v) (8γv(1 -v)(1 + )) 1+α 2 2 1 -α , if α &lt; 1. And ∀ &gt; 0, lim sup T →∞ R T (log T ) 2 ≤ β F (v) 8γv(1 -v)(1 + ), if α ≥ 1.</formula><p>Letting tend to 0 concludes the proof.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.2. Generalization to a Localized Margin Condition for kl-UCBID</head><p>Theorem 25 If F satisfies Assumption 2 and F (v) &gt; 0, the kl-UCBID algorithm with parameter γ &gt; 1 yields the following asymptotic bound on the regret:</p><formula xml:id="formula_118">lim sup T →∞ R T (log T ) 1+α 2 (T ) 1-α 2 ≤ 2β F (v)(1 -α) (8γv(1 -v))) 1+α 2 , if α &lt; 1. lim sup T →∞ R T (log T ) 2 ≤ β F (v) 8γv(1 -v), if α ≥ 1.</formula><p>In this case, we adapt the proof in Appendix C.1 by observing that</p><formula xml:id="formula_119">R T ≤ T t=1 E[(M t -v)1{v &lt; M t &lt; B t &lt; v + ∆}] + T t=1 P(v &lt; B t ) + T t=1 P(v + ∆ ≤ B t , M t &lt; B t ).</formula><p>The first two terms of the bound are analyzed exactly in Section C. The last one is bounded as follows</p><formula xml:id="formula_120">T t=1 P(v + ∆ ≤ B t , M t &lt; B t ) ≤ T n=1 P(v + ∆ ≤ B + (n)) ≤ T n=1 P(v ≤ L γ (n)) + T n=1 P(∆ &lt; B + (n) -L γ (n)) ≤ T 1-γ + T n=1 P(∆ &lt; U γ (n) -L γ (n)),</formula><p>where the first inequality results from the same steps as in the proof of Lemma 13, and the last one stems from the fact that P(v ≤ L γ (n)) ≤ T -γ , which is a result of the Chernoff deviation inequality (see Corollary 10.14 of <ref type="bibr" target="#b19">Lattimore and Szepesvári (2018)</ref>). For n &gt; n 0 (v, T, ),</p><formula xml:id="formula_121">U γ (n) -L γ (n) ≤ 2 2γv(1 -v)(1 + ) log T n and, ∆ &lt; U γ (n) -L γ (n) =⇒ ∆ &lt; 2 2γv(1 -v)(1 + ) log T n .</formula><p>Yet this latter condition on ∆ is equivalent to n &lt; 8γv(1-v)(1+ )</p><p>∆ 2 log T := n 1 (v, T, ). This yields, for T &gt; max(n 0 (v, T, ), n 1 (v, T, )) := n 2 (v, T, ),</p><formula xml:id="formula_122">T t=1 P(v + ∆ ≤ B t , M t &lt; B t ) ≤ T 1-γ + n 2 (v, T, ).</formula><p>Hence,</p><formula xml:id="formula_123">R T ≤ C γ + n 2 (v, T, ) + 3T 1-γ + T n=1 2 2γ log T v(1 -v)(1 + ) n 1+α ≤ C γ + n 2 (v, T, ) + 3 +            β F (v) (8γv(1 -v)(1 + ) log T ) 1+α 2 2 1-α (T ) 1-α 2 if α &lt; 1 β F (v) 8v(1 -v)(1 + )γ log T (log T + 1) if α ≥ 1 .</formula><p>Taking the upper limit when T → ∞ and letting tend to 0 concludes the proof.</p><p>C.3. Proof of an Alternative Bound of the Regret of klUCB, under Assumption 3</p><p>Lemma 26 Under Assumption 3, klUCBID incurs a regret bounded by</p><formula xml:id="formula_124">R T ≤ 1 + C γ + log T + 2 √ γ log T +                  β F (v) (6 + 4γ) 2 v log 2 T, for α = 1, β F (v) (6 + 4γ) 1+α 2 1-α v 1+α 2 log 1+α 2 (T )T 1-α 2 +5 log 2 T for α &lt; 1, β F (v) (6 + 4γ) 1+α 2 α-1 v 1+α 2 log(T ) + 5 log 2 T for α &gt; 1. . (14) Proof R T (v) ≤ T t=1 P(B t &lt; v) + T t=1 E (B t -v)1(v &lt; M t &lt; B t )1 N t ≤ log T v + T t=1 E (B t -v)1(v &lt; M t &lt; B t )1 N t ≥ log T v<label>(15)</label></formula><p>The first term of the right hand side of Equation 15 is bounded by a constant C γ := ∞ t=1 e √ γ log t+1 t γ thanks to Theorem 10 of <ref type="bibr" target="#b14">Garivier and Cappé (2011)</ref>.</p><p>We denote by n 0 = min T, log T v . We start by bounding the second term of the right hand side of Equation ( <ref type="formula" target="#formula_124">15</ref>). T t=1</p><formula xml:id="formula_125">(B t -v)1(v &lt; M t &lt; B t )1 N t ≤ log T v ≤ E T t=1 (B t -v)1(v &lt; M t &lt; B t )1 N t ≤ log T v ≤ E T t=1 n 0 n=1 (B + (n) -v)1 N t ≤ log T v 1(N t = n)1(N t+1 = n + 1) ≤ E n 0 n=1 (B + (n) -v) ≤ E n 0 n=1 (B + (n) -v)1 V (n) &lt; 2v + log T n + P V (n) ≥ 2v + log T n ≤ E n 0 n=1 (B + (n) -V (n) + V (n) -v)1 V (n) &lt; 2v + log T n + 1 T ,</formula><p>where the last line comes from Lemma 12. We know from Lemma 10 that</p><formula xml:id="formula_126">(U γ (n) -V (n)) 2 2 × 2((Uγ (n)-V (n)+ V (n))+ V (n) 3 ≤ kl( V (n), U γ (n)) = γ log T n .</formula><p>Hence if we denote by ∆(n</p><formula xml:id="formula_127">) := B + (n) -V (n), 3∆ 2 (n) 2(3 V (n) + 2∆(n)) ≤ γ log T n .</formula><p>Therefore,</p><formula xml:id="formula_128">3∆ 2 (n) ≤ 2γ log T n (3 V (n) + 2∆(n)) ≤ 2γ log T n 3(2v + log T n ) + 2∆(n) , when V (n) &lt; 2v + log T n .</formula><p>Hence</p><formula xml:id="formula_129">∆(n) ≤ 2γ log T 3n + 1 6 16γ 2 log 2 T n 2 + 36(2v + log T n ) n 2γ log T n ≤ 10γ 3 log T n + 4γ v log T n , when V (n) &lt; 2v + log T n . This yields E n 0 n=1 (B + (n) -V (n) + V (n) -v)1 N t ≥ log T v 1 V (n) &lt; v + log n ≤ E n 0 n=1 (∆(n) + V (n) -v)1 N t ≥ log T v 1 V (n) &lt; v + log T n ≤ 10γ 3 log T log(n 0 ) + 4vγ √ n 0 log T + vn 0 + log T log(n 0 ) ≤ 13γ 3 log T log(n 0 ) + 4 v v γ log T log T + log T. Finally, T t=1 E (B t -v)1(v &lt; M t &lt; B t )1 N t ≤ log T v ≤ n 0 T + 13γ 3 log 2 T + 2 √ γ log T + log T. (<label>16</label></formula><formula xml:id="formula_130">)</formula><p>We now bound the third term of the right hand side of Equation <ref type="formula" target="#formula_124">15</ref>.</p><formula xml:id="formula_131">T t=1 E (B t -v)1(v &lt; M t &lt; B t )1 N t ≥ log T v ≤ T t=1 E E (B t -v)1(v &lt; M t &lt; B t )1 N t ≥ log T v F t ∩ σ(M t &lt; B t ) ≤ T t=1 E β F (B t ) (B t -v) 1+α 1(v &lt; M t &lt; B t )1 N t ≥ log T v ≤ T n=n 0 +1 E β F (v) (B + (n) -v) 1+α ≤ T n=n 0 +1 E β F (v) B + (n) -v) 1+α 1 V (n) -v ≤ 2v log T n + P V (n) -v ≥ 2v log T n ≤ T n=n 0 +1 E β F (v) B + (n) -V (n) + V (n) -v) 1+α 1 V (n) -v ≤ 2v log T n + 1 T ,</formula><p>where the third inequality comes from a re-sampling argument coupled with the fact that F (B t ) ≥ F (v) in case of a won auction, and the last inequality follows from Lemma 12. Like for smaller values of n,</p><formula xml:id="formula_132">3∆ 2 (n) 2(3 V (n) + 2∆(n)) ≤ γ log T n .</formula><p>Therefore,</p><formula xml:id="formula_133">3∆ 2 (n) ≤ 2γ log T n (3 V (n) + 2∆(n)) ≤ 2γ log T n 3 v + 2v log T n + 2∆(n) ≤ 2γ log T n 3 v + √ 2v + 2∆(n) ≤ 2γ log T n 3 (1 + √ 2)v + 2∆(n) , when V (n) -v &lt; 2v log T n and n ≥ n 0 .</formula><p>This yields</p><formula xml:id="formula_134">∆(n) ≤ 2γ log T 3n + 1 6 16γ log 2 T n 2 + 36 × (1 + √ 2)v γ log T n ≤ 4γ log T 3n + (1 + √ 2)v log T n ≤ 4γ 3 √ v log T n + (1 + √ 2)v log T n ≤ 2 + 4γ 3 √ γv log T n ,</formula><p>when n &gt; n 0 and V (n) &lt; 2v log T n . We used that γ &gt; 1 in the first inequalities. Therefore</p><formula xml:id="formula_135">T n=n 0 +1 E β F (v) B + (n) -V (n) + V (n) -v) 2 1 V (n) -v ≤ 2v log T n ≤ T n=n 0 +1 β F (v) 2 + 4γ 3 γv log T n + 2v log T n 1+α ≤ T n=n 0 +1 β F (v) (6 + 4γ) 1+α v log T n 1+α 2 ≤ β F (v) (6 + 4γ) 1+α      v log T (log T -log(n 0 )) if α = 1 2 α-1 v 1+α 2 log 1+α 2 (T )T 1-α 2 if α &lt; 1 2 1-α v 1+α 2 log 1+α 2 (T ) log 1-α 2 (n 0 ), if α &gt; 1 .</formula><p>When using Equation ( <ref type="formula" target="#formula_124">15</ref>) and hence summing with C γ and the right hand side of Equation ( <ref type="formula" target="#formula_129">16</ref>), we obtain:</p><formula xml:id="formula_136">R T ≤ 1 + C γ + 2 √ γ log T + log T + β F (v) (6 + 4γ) 2 v log 2 T,</formula><p>for α = 1, using the fact that 10γ 3 &lt; (6 + 4γ) 2 , to make the terms proportional to log(n 0 ) disappear. Similarly,</p><formula xml:id="formula_137">R T ≤ 1+C γ + 13γ 3 log 2 T +2 √ γ log T +log T + β F (v) (6 + 4γ) 1+α 2 1 -α v 1+α 2 log 1+α 2 (T )T 1-α 2 , for α &lt; 1. And R T ≤ 1 + C γ + 13γ 3 log 2 T + 2 √ γ log T + log T + β F (v) (6 + 4γ) 1+α 2 α -1 v 1+α 2 log(T ),</formula><p>for α &gt; 1.</p><p>In fact,</p><formula xml:id="formula_138">KL(P It v , P It v t ) = KL(P I t-1 v , P I t-1 v t ) + KL(P (Mt,V t )|I t-1 v , P (Mt,V t )|I t-1 v t ),<label>and</label></formula><formula xml:id="formula_139">KL(P (Mt,V t )|I t-1 v , P (Mt,V t )|I t-1 v t ) = E[E[KL(ν It ⊗ D, ν It ⊗ D)|I t-1 ]] = E[kl(v, v )1(B t &gt; M t )].</formula><p>where ν It (respectively ν It ) denotes the law of V t knowing I t in the first environment (respectively the second), and D the law of M t . By induction, we obtain</p><formula xml:id="formula_140">KL(P It v , P It v t ) = kl(v, v t )E[N t ].</formula><p>Using Lemma 27, ∀ &gt; 0, ∃t 1 ( ), ∀t ≥ t 1 ( ),</p><formula xml:id="formula_141">KL(P It v , P It v t ) ≤ kl(v, v t )(1 + )F (v).</formula><p>Using the data processing inequality (see for example Garivier et al. ( <ref type="formula">2019</ref>)), we get</p><formula xml:id="formula_142">KL(P It v , P It v t ) ≥ kl P v B t &gt; v + v t 2 , P v t B t &gt; v + v t 2 ≥ 2 P v B t &gt; v + v t 2 -P v t B t &gt; v + v t 2 2 ≥ 2 P v B t &gt; v + v t 2 + P v t B t &lt; v + v t 2 -1 2 ,</formula><p>where the second inequality comes from Pinsker inequality. Therefore,</p><formula xml:id="formula_143">P v B t &gt; v + v t 2 + P v t B t &lt; v + v t 2 ≥ 1 - 1 2 KL(P It v , P It v t ).</formula><p>Specifically, ∀t &gt; t 0 ( ),</p><formula xml:id="formula_144">P v B t &gt; v + v t 2 + P v t B t &lt; v + v t 2 ≥ 1 - 1 2 kl(v, v t )(1 + )F (v)t. Using the fact that E v [(B t -v) 2 ] ≥ (v - v+v t 2 ) 2 P v B t &gt; v+v t 2 yields E v [(B t -v) 2 ] ≥ v -v t 2 2 P v B t &gt; v + v t 2 ≥ v(1 -v) 4F (v)t 1 - 1 2 (1 + )kl(v, v t )F (v)t -1/t γ ,</formula><p>using the assumption that the algorithm outputs a bid that does not underestimate v t :</p><formula xml:id="formula_145">P v t (B t &lt; v t ) &lt; 1 t γ . F (v)t</formula><p>≤ 1+ 2F (v)t which is proved with similar arguments to those used to prove Lemma 23.</p><p>Altogether, we have proved ∀t ≥ max(t 1 ( ), t 2 (v, )),</p><formula xml:id="formula_146">E v [(B t -v) 2 ] ≥ v(1 -v) 4F (v)t 1 - 1 4 (1 + ) 2 -1/t γ . Let t 0 (v, ) = max(t 1 ( ), t 2 (v, )). We obtain T t=1 E v [(B t -v) 2 ] ≥ T t=t 0 (v, ) v(1 -v) 4F (v)t 1 - 1 2 (1 + ) -1/t γ .</formula><p>Recall that, according to Lemma 9,</p><formula xml:id="formula_147">R T (v) ≥ β 2 T t=1 E v [(B t -v) 2 ]. Hence, ∀ &gt; 0, R T (v) ≥ β 2 v(1 -v) 4 1 - 1 2 (1 + ) log T t 0 (v, )</formula><p>-O(1).</p><p>And ∀ &gt; 0, lim inf</p><formula xml:id="formula_148">T →∞ R T (v) log T ≥ β 2 v(1 -v) 4F (v) 1 - 1 2 (1 + ) .</formula><p>Since this holds for all ,</p><formula xml:id="formula_149">lim inf T →∞ R T (v) log T ≥ β ¯ v(1 -v) 16F (v) .</formula><p>Proof We first start by bounding the regret of UCBID. The UCBID strategies incurs a regret bounded by:</p><formula xml:id="formula_150">E v [R T ] ≤E v T t=1 (v -B t )1(v &lt; M t &lt; B t ) + T t=1 P(v &gt; B t ) ≤ E v T t=1 2 γ log t 2N t 1(M t &lt; B t ) + T t=1 P Vt &gt; v + γ log t 2N t + T t=1 P(v &gt; B t ) ≤ E v T n=1 2 γ log T 2n + T t=1 P Vt &gt; v + γ log t 2N t + T t=1 P(v &gt; B t ) ≤ 2 γT log T + 2C γ ,</formula><p>where the third inequality follows from a resampling argument close to that of Lemma 13. By Pinsker's inequality, this bound also trivially holds for klUCBID. Along with the bound of Theorem 1, this suggests that the point where the maximal regret of UCBID is reached is O(T -1 2 ), under Assumption 1.</p><p>Next, we prove the bound for the regret of BernsteinUCBID. We proved in Section B.7, that the regret of BernsteinUCBID satisfies :</p><formula xml:id="formula_151">R T ≤ C γ + β F (v) 8w log(3T γ )(log T + 1) + β F (v) (6c 1 log(3T γ )) 2 + 1 . If v &gt; T -1 3 , this entails : R T ≤ C γ + 8 β β ¯log(3T γ )(log T + 1) + βT 1 3 (6c 1 log(3T γ )) 2 + 1 . If, on the other hand, v ≤ T -1 3 , E v [R T ] ≤ E v T t=1 (v -B t )1(v &lt; M t &lt; B t ) + T t=1 P(v &gt; B t )<label>(17)</label></formula><formula xml:id="formula_152">≤ T t=1 E v   2 2 Wt-1 log(3t γ ) N t-1 + 3 log(3t γ ) N t-1   + T t=1 P   Vt -v ≤ Wt-1 log(3t γ ) N t-1 + 3 log(3t γ ) N t-1   + T t=1 P(v &gt; B t ) ≤ T n=1 E v 2 2 W (n) log(3t γ ) n + 3 log(3T γ ) n + 2C γ ≤ T n=1 2 2w log(3T γ ) n + 3 log(3T γ ) n + 2C γ</formula><p>≤ 2 2w log(3T γ )T + 3 log(3T γ ) log T + 2C γ (18)</p><p>≤ 2 2 log(3T γ )T 1 3 + 3 log(3T γ ) log T + 2C γ</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F.1. Preliminary lemmas</head><p>The stopping time τ 1 (respectively ρ 1 ) is designed so that if it occurs before τ 0 (respectively ρ 0 ) then the bids in the second phase will be larger than v/2 with high probability. We show that if all bids in the second phase are larger than v/2, the regret in the second phase is bounded as follows.</p><p>Lemma 28 If F admits a density bounded by β then</p><formula xml:id="formula_153">E T t=ρ 1 r t 1 ∩ T s=ρ 1 { V (s) ≥ v 2 } 1(ρ 1 &lt; ρ 0 ) ≤ 4 + β log 2 T F (v/2) + 1.</formula><p>Proof We denote by A the advantageous event ∩ T s=ρ 1 { V (s) ≥ v 2 }. We first observe that:</p><formula xml:id="formula_154">ρ 1 &lt; ρ 0 and A =⇒ ∀t ∈ [1, T ] , B t ≥ v 2 .</formula><p>Indeed, in the first phase, B t = 1, and in the second phase, B t = Vt = V (N t ), with N t ≥ ρ 1 . Hence it holds with high probability that if t ≥ ρ 1 , ∀c &gt; 1, N t ≥ ρ 1 + F (v/2) c (t -ρ 1 ). Indeed, a strategy playing v/2 instead of Vt in this phase would obtain N t victories, where N t is the sum of ρ 1 , and of t -ρ 1 Bernoullis of expectation F (v/2), and it holds that N t ≥ N t , as a larger bid implies a larger number of won auctions. Therefore, if t ≥ ρ 1 , the probability that N t &lt; ρ 1 + F (v/2) c (t -ρ 1 ) conditioned on A ∩ {ρ 1 &lt; ρ 0 } can be bounded as follows.</p><formula xml:id="formula_155">P N t &lt; ρ 1 + F (v/2) c (t -ρ 1 ) A ∩ {ρ 1 &lt; ρ 0 } ≤ P N t &lt; ρ 1 + F (v/2) c (t -ρ 1 ) = E P F (v/2)(t -ρ 1 ) -(N t -ρ 1 ) &gt; F (v/2)(c -1) c (t -ρ 1 ) ρ 1 ≤ E exp - 2(c -1) 2 (F (v/2)) 2 c 2 (t -ρ 1 ) ≤ exp - 2(c -1) 2 (F (v/2)) 2 c 2 t ,</formula><p>where we used Hoeffding's inequality for the second inequality. Now, we can use the following :</p><formula xml:id="formula_156">E [r t 1{t ≥ ρ 1 }1 (A) 1(ρ 1 &lt; ρ 0 )]<label>(21)</label></formula><formula xml:id="formula_157">≤ E r t 1{t ≥ ρ 1 }1 N t-1 ≥ ρ 1 + F (v/2) c (t -ρ 1 -1) 1(ρ 1 &lt; ρ 0 ) + P N t-1 &lt; ρ 1 + F (v/2) c (t -ρ 1 -1), t ≥ ρ 1 1(ρ 1 &lt; ρ 0 ) ≤ E r t 1{t ≥ ρ 1 }1 N t-1 ≥ ρ 1 + F (v/2) c (t -ρ 1 -1) 1(ρ 1 &lt; ρ 0 ) (22) + exp - 2(c -1) 2 (F (v/2)) 2 c 2 t (<label>23</label></formula><formula xml:id="formula_158">)</formula><p>The first term of the right hand side of ( <ref type="formula">22</ref>) is bounded by :</p><formula xml:id="formula_159">E r t 1{t ≥ ρ 1 }1{N t-1 ≥ ρ 1 + F (v/2) c (t -ρ 1 -1)}1(ρ 1 &lt; ρ 0 ) ≤ E E E r t 1 {t ≥ ρ 1 } 1 N t-1 ≥ ρ 1 + F (v/2) c (t -ρ 1 -1) F t-1 1(ρ 1 &lt; ρ 0 ) ≤ E β 2 (v -B t ) 2 1{t ≥ ρ 1 }1 N t-1 ≥ ρ 1 + F (v/2) c (t -ρ 1 -1) 1(ρ 1 &lt; ρ 0 ) ,</formula><p>where the last line follows from Lemma 15. This is also clearly bounded by</p><formula xml:id="formula_160">E β 2 (v -B t ) 2 1 {t ≥ ρ 1 } 1 N t-1 ≥ ρ 1 + F (v/2) c (t -ρ 1 -1) 1(ρ 1 &lt; ρ 0 ) ≤ E β 2 log T N t-1 1{N t-1 ≥ ρ 1 + F (v/2) c (t -ρ 1 -1)}1{t ≥ ρ 1 }1(ρ 1 &lt; ρ 0 ) + P v -V (N t-1 ) ≥ log T N t-1 , t ≥ ρ 1 . (<label>24</label></formula><formula xml:id="formula_161">)</formula><p>By applying a union bound, followed by Hoeffding's inequality,the second term of ( <ref type="formula" target="#formula_160">24</ref>) is bounded as follows</p><formula xml:id="formula_162">P |v -V (N t-1 )| ≥ log T N t-1 , t ≥ ρ 1 ≤ t-1 s=1 P |v -V (s)| ≥ log T s , t ≥ ρ 1 ≤ 1 T .</formula><p>Summarizing,</p><formula xml:id="formula_163">E r t 1 t ≥ ρ 1 , N t-1 ≥ ρ 1 + F (v/2) c (t -ρ 1 -1) , ρ 1 &lt; ρ 0 ) ≤ E β 2 c log T F (v/2)t 1{t ≥ ρ 1 } + 1 T .</formula><p>Hence, when summing over T rounds,</p><formula xml:id="formula_164">E T t=ρ 1 r t 1 ∩ T s=ρ 1 { V (s) ≥ v 2 } 1(ρ 1 &lt; ρ 0 ) ≤ T t=1 E β 2 c log T F (v/2)t 1{t ≥ ρ 1 } + 1 T + exp - 2(c -1) 2 (F (v/2)) 2 c 2 (t -ρ 1 ) ≤ β 2 c log 2 T F (v/2)t + 1 + 1 1 -exp(-2 2(c-1) 2 (F (v/2)) 2 c 2 ) ≤ β 2 c log 2 T F (v/2)t + 1 + c 2 (c -1) 2 F ( v 2 )</formula><p>.</p><p>Picking c = 2 concludes the proof.</p><p>We claim that the stopping time τ 1 (respectively ρ 1 ) is designed so that if it occurs before τ 0 (respectively ρ 0 ) then the bids in the second phase will be larger than v/2 with high probability. The following lemma quantifies this statement.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Lemma 29</head><p>The event A := ∩ T s=ρ 1 { V (s) ≥ v 2 } occurs with high probability and</p><formula xml:id="formula_165">P (A c ) ≤ 2 T .</formula><p>Proof By a union bound,</p><formula xml:id="formula_166">P (A c ) ≤ P (v ≤ L ρ 1 ) + T n=1 P {v ≥ L ρ 1 } ∩ V (n) &lt; v 2 ∩ {n ≥ ρ 1 }<label>(25)</label></formula><p>The second term of Equation 25 is bounded by:</p><formula xml:id="formula_167">P {v ≥ L(ρ 1 )} ∩ V (n) &lt; v 2 ∩ {n ≥ ρ 1 } ≤ P exp(- nv 8 ) ≤ 1 T 2 ∩ V (n) &lt; v 2 ≤ 1 exp(- nv 8 ) ≤ 1 T 2 P V (n) &lt; v 2 ≤ 1 exp(- nv 8 ) ≤ 1 T 2 exp(- nv 8 ) ≤ 1 T 2 . (<label>26</label></formula><formula xml:id="formula_168">)</formula><p>where we use Lemma 11 along with Chernoff inequality to prove that ∀n, P( V (n) &lt; v 2 ) ≤ exp(-3 nv 20 ) ≤ exp(-nv 8 ). Let us go back to the probability of the unwanted event A c .</p><formula xml:id="formula_169">P ∪ T s=ρ 1 V (s) &lt; v 2 ≤ P(v ≤ L(ρ 1 )) + T t=1 P {v ≥ L(ρ 1 )} ∩ V (s) &lt; v 2 ∩ {t ≥ ρ 1 } ≤ 1 T + 1 T ≤ 2 T ,</formula><p>by another union bound and thanks to Equation (26).</p><p>The expectation of ρ 1 and ρ 0 are of critical importance. Indeed, the regret is larger than the expectation of their minimum multiplied by β ¯(1 -v) 2 /2. In the following lemma, we show in particular that the expectation of τ 1 is proportional to the inverse of v.</p><p>Lemma 30 The expectation of ρ 1 is bounded by</p><formula xml:id="formula_170">E[ρ 1 ] ≤ 64 log(T ) + 60T -1/2 v + 1.</formula><p>Proof First note that by Pinsker's inequality</p><formula xml:id="formula_171">L(n) ≥ V (n) - log(T ) 2n<label>(27)</label></formula><p>F.2.2. Case when</p><formula xml:id="formula_172">1 3T 1 3 ≤ v ≤ 1 T 1 3 . R T (v) ≤ E v 1(ρ 1 &lt; ρ 0 ) T t=1 r t + E v 1(ρ 0 &lt; ρ 1 ) T t=1 r t ≤ E v [ρ 0 1(ρ 0 &lt; ρ 1 )] + E v [ρ 1 1(ρ 1 &lt; ρ 0 )] + E v T t=ρ 1 r t 1(ρ 1 &lt; ρ 0 ) + E v T t=ρ 0 r t 1(ρ 0 &lt; ρ 1 ) ≤ E v [ρ 1 ] + 2 max E v T t=ρ 1 r t 1(ρ 1 &lt; ρ 0 ) , E v T t=ρ 0</formula><p>r t 1(ρ 0 &lt; ρ 1 ) .</p><p>The expected regret in the second phase when ρ 0 has been reached first is bounded by</p><formula xml:id="formula_173">E v T t=ρ 0 r t 1(ρ 0 &lt; ρ 1 ) ≤ βT × T -2 3 ≤ βT 1 3 ,</formula><p>while the expected regret in the second phase when ρ 1 has been reached first is bounded by : </p><formula xml:id="formula_174">E v T t=ρ 0 r t 1(ρ 0 &lt; ρ 1 ) ≤ E v T t=ρ 1 r t 1 ∩ T s=ρ 1 V (s) ≥ v 2 1(ρ 1 &lt; ρ 0 ) + T t=ρ 1 P v ∪ T s=ρ 1 V (s) &lt; v 2 ≤ 4 + β log 2 T F (v/</formula></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>(a) Regret plots of three UCB algorithms for values V t ∼ Ber(0.2) and uniform M t . (b) Regret plots of three UCB algorithms for V t supported on {0.195, 0.205} and uniform M t (c) Comparison with ETGstop and other algorithms, for V t ∼ Ber(0.3) and uniform M t . (d) Regret at time 5000 of studied policies for uniform M t and Bernoullidistributed V t of varying mean v.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Numerical simulations</figDesc><graphic coords="13,112.06,312.74,185.76,139.32" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>Generalization to a Localized Margin Condition for UCBID and Bernstein-UCBID Lemma 20 If F satisfies Assumption 2 with parameter α around v on [v, v + ∆], the upper bounds presented in Theorems 16 and 18 are unchanged, apart from an additive term</figDesc></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>© 2021 J. Achddou, O. Cappé &amp; A. Garivier.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_1"><p>log 2 T, according to Lemma 30.</p></note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Supplementary Material</head><p>Outline. The appendix is structured as follows: Appendix A contains general lemmas used in the rest of the appendix. Appendix B contains the proof of the parametric upper bounds of the regret of UCBID and BernsteinUCBID. A brief outline of the proof scheme precedes the proofs (Appendix B.1). The asymptotic and non asymptotic upper-bound for the regret of klUCBID can be found in Appendix C. The proof of the parametric lower bound for standard UCB strategies follows in Appendix D . Appendix E deals with the study of the worst case regret of UCB strategies. Appendix F provides the proof of the upper bound of the regret of ETGstop, while Appendix G contains that of the minimax lower bound of ETG strategies.</p><p>Additional Notation and Assumptions. The sequel requires the use of additional notations.</p><p>• We define (V (n)) n≥1 by V (n) := V τn where τ n = inf{t : N t = n}. V (n) is the n -th observation of a value.</p><p>• V (n) := 1/n n s=1 V (s) is the mean of the n first observed values.</p><p>• W (n) := 1/n n s=1 (V (s) -V (s)) 2 is the population variance of the n first observed values.</p><p>• We set V s = V s if M s ≤ B s , and V s = ∅ otherwise.</p><p>• Let F t = σ((M s , V s ) s≤t ) be the σ-algebra generated by the the bid maxima and the values observed up to time t.</p><p>• We denote by</p><p>T 2 } • We also define the instantaneous regret by</p><p>Whereas the results presented in the main body of the paper require the assumption that F admits a locally bounded density, we prove broader results, under the following assumption.</p><p>Assumption 2 Local margin condition. F satisfies the local margin assumption, with parameter α &gt; 0, if there exists strictly positive constants ∆ and β such that</p><p>Assumption 1 is a special case of Assumption 2 with α = 1.</p><p>Alternatively, we will use the uniform version of the margin condition.</p><p>Assumption 3 Uniform margin condition. F satisfies the uniform margin assumption, with parameter α &gt; 0, if there exists a positive constant β such that</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix D. Proof of the Lower Bound for Optimistic Strategies</head><p>We restate the Theorem for simplicity.</p><p>Theorem 4 We consider all environments where V t follows a Bernoulli distribution with expectation v and F admits a density f that is both upper bounded and lower bounded, with f (b) ≥ β ¯&gt; 0. If a strategy is such that, for all such environments, R T ≤ O(T a ), for all a &gt; 0, and there exists γ &gt; 0 such that for all such environments, P(B t &lt; v) &lt; t -γ , then this strategy must satisfy:</p><p>.</p><p>Proof We need the following lemma:</p><p>), ∀a &gt; 0, and F admits a density which is lower bounded by a positive constant and upper bounded. Then,</p><p>), ∀a &gt; 0, because of Lemma 9. By the tower rule, it holds</p><p>Since F admits a density f , upper bounded by a constant that we denote β,</p><p>Together with the fact that</p><p>and with the Cesaro theorem this result proves the lemma.</p><p>We get back to the proof of Theorem 4. We set a time step t ∈ [1, T ]. We consider two alternative environments with identical distributions for M t that differ by the distribution of V t . The value V t is distributed according to a Bernoulli distribution of expectation v in the first environment, respectively</p><p>Notation. We will denote by P v (•) the probability of an event under the first environment (respectively E v (•) the expectation of a random variable under the first environment), and by P v t (•) the probability of an event under the second environment (respectively E v t (•) the expectation of a random variable under the first environment). We denote by I t the information collected up to time t + 1 :</p><p>) is the law of I t in the first (respectively second) environment.</p><p>We consider the Kullback Leibler divergence between P It v and</p><p>This is proved using the chain rule for conditional KL.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix E. Proof of Theorem 5</head><p>The statement of Theorem 5is repeated here for simplicity.</p><p>Theorem 5 Without further assumption, the maximal regrets of UCBID, BernsteinUCBID and klUCBID are O( √ T log T ). If F has a density that is bounded from below and above by non negative constants, the maximal regret of UCBID remains of the same order, while it is reduced to O(T 1 3 log 2 T ) for BernsteinUCBID and to O(log 2 T ) for klUCBID.</p><p>where the third inequality comes from a resampling argument close to the one proved in the proof of Lemma 13, the fourth from the Jensen inequality, and the fifth from w ≤ v(1 -v).</p><p>In either case, R T (v) ≤ O(T 1 3 log 2 T ). This suggests that the point where the maximal regret of BernsteinUCBID is reached is a O(T -1 3 ). Note that without any assumption on F and for any v ∈ [0, 1] , Inequation 18 still holds. Since w &lt; 1 and log(3T γ ) = O(log T ), we prove that E v [R T ] ≤ O( √ T log T , without any assumpton on F .</p><p>The bound of the worst-case regret of klUCBD under Assumption 1 directly stems from Lemma 26.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix F. Proof of Theorem 6</head><p>In the main body of the paper, we stated the following theorem.</p><p>We recall that ETGstop is defined by the following choice of stopping times τ 1 and τ 0 :</p><p>where</p><p>We use the fact that this is completely equivalent to choosing the following stopping times</p><p>where the stopping times are defined from the number of observations rather than the number of auctions, because, in the first phase the bidder always observes the value of the item, as B t = 1. Therefore, in particular, min(ρ 1 , ρ 2 ) = min(τ 0 , τ 1 ). Note however that in general max(ρ 1 , ρ 2 ) = max(τ 0 , τ 1 ). In particular, when τ 0 is reached first, Vt = Vτ 0 , ∀t &gt; τ 0 because there is no further observation once τ 0 is reached, while this is not the case of V (n) : this means that L t will be constant after τ 0 while L(n) is not necessarily constant after τ 0 .</p><p>In the sequel, we will use these stopping times instead of τ 0 and τ 1 .</p><p>and by the generalized Pinsker inequality, kl(p, q) ≥ (p -q) 2 2 max{r(1 -r) : r ∈ (p, q)} .</p><p>Let n 0 = 64 log(T )/v , and n ≥ n 0 .</p><p>and hence nL(n) ≥ n/4 ≥ 16 log(T ).</p><p>and hence nL(n) ≥ 64 log(T )/v × v/2 &gt; 64 log(T ) &gt; 16 log T .</p><p>• Otherwise, V (n) &lt; min(v, 1/2) and hence</p><p>and hence L(n) ≤ 16 log(T )/n implies</p><p>To summarize:</p><p>Lemma 11 yields for α = -1/4</p><p>To conclude, we bound the expectation of ρ 1 as :</p><p>The following lemma shows that the expectation of ρ 0 is small when v</p><p>, the expectation of the stopping time ρ 0 is bounded by:</p><p>Proof We use the following classical equality</p><p>We can bound the probabilities in the latter sum by:</p><p>.</p><p>, when</p><p>where we used the second inequality of Lemma 11, in the last inequality. We conclude that E v [ρ 0 ] &lt; 32T</p><p>In order to show that the regret of ETGstop is bounded by O(T 1 3 ) when v is small, we prove that the probability of ρ 1 &lt; ρ 0 is small, for v small enough.</p><p>&gt; v, and</p><p>where we used Equation ( <ref type="formula">29</ref>) in the third inequality, and 1/(1 -exp(-u)) ≤ 2/u for 0 ≤ u ≤ 1 in the fourth inequality.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F.2. Proof of Theorem 6</head><p>We separately study the cases where v ≤ 1 3T</p><p>, and prove that in each</p><p>, we also prove</p><p>, we bound the regret as follows</p><p>thanks to Lemmas 32 and 31.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F.2.3. Case when</head><p>We conclude that</p><p>thanks to Lemmas 30, 28 and 29. In particular :</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix G. Proof of Theorem 7</head><p>We restate the theorem for the sake of readability.</p><p>Theorem 7 If F admits a density lower bounded by β ¯&gt; 0, the regret of any ETG strategy satisfies</p><p>Proof Let v = aT -1 3 . ETG strategies are fully characterized by their choice of τ 0 and τ 1 . Let us fix an ETG strategy, and let τ m = min(τ 0 , τ 1 ).</p><p>, or P v (τ m &lt; T 1 3 ) ≥ 1 2 , and in this case, P v ( Vτm = 0, τ m &lt; T where the third inequality comes from the fact that T 1 3 log(1 -aT -1 3 ) ≥ -a. If Vτm = 0, whatever the order in which τ 0 and τ 1 are reached, every bid in the second phase will be zero. Therefore, R T</p><p>To conclude, we pick a = 2 to obtain </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Improved algorithms for linear stochastic bandits</title>
		<author>
			<persName><forename type="first">Yasin</forename><surname>Abbasi-Yadkori</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dávid</forename><surname>Pál</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Csaba</forename><surname>Szepesvári</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="2312" to="2320" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Learning prices for repeated auctions with strategic buyers</title>
		<author>
			<persName><forename type="first">Kareem</forename><surname>Amin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Afshin</forename><surname>Rostamizadeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Umar</forename><surname>Syed</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="1169" to="1177" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Exploration-exploitation tradeoff using variance estimates in multi-armed bandits</title>
		<author>
			<persName><forename type="first">Jean-Yves</forename><surname>Audibert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rémi</forename><surname>Munos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Csaba</forename><surname>Szepesvári</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Theoretical Computer Science</title>
		<imprint>
			<biblScope unit="volume">410</biblScope>
			<biblScope unit="issue">19</biblScope>
			<biblScope unit="page" from="1876" to="1902" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Finite-time analysis of the multiarmed bandit problem</title>
		<author>
			<persName><forename type="first">Peter</forename><surname>Auer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicolo</forename><surname>Cesa-Bianchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paul</forename><surname>Fischer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine Learning</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="issue">2-3</biblScope>
			<biblScope unit="page" from="235" to="256" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Bandits with knapsacks</title>
		<author>
			<persName><forename type="first">Ashwinkumar</forename><surname>Badanidiyuru</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><surname>Kleinberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aleksandrs</forename><surname>Slivkins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE 54th Annual Symposium on Foundations of Computer Science</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2013">2013. 2013</date>
			<biblScope unit="page" from="207" to="216" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Online learning in online auctions</title>
		<author>
			<persName><forename type="first">Avrim</forename><surname>Blum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vijay</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Atri</forename><surname>Rudra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Felix</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Theoretical Computer Science</title>
		<imprint>
			<biblScope unit="volume">324</biblScope>
			<biblScope unit="issue">2-3</biblScope>
			<biblScope unit="page" from="137" to="146" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Kullback-Leibler upper confidence bounds for optimal sequential allocation</title>
		<author>
			<persName><forename type="first">Olivier</forename><surname>Cappé</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aurélien</forename><surname>Garivier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Odalric-Ambrym</forename><surname>Maillard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rémi</forename><surname>Munos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gilles</forename><surname>Stoltz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Annals of Statistics</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1516" to="1541" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Regret minimization for reserve prices in second-price auctions</title>
		<author>
			<persName><forename type="first">Nicolo</forename><surname>Cesa-Bianchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Claudio</forename><surname>Gentile</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yishay</forename><surname>Mansour</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Information Theory</title>
		<imprint>
			<biblScope unit="volume">61</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="549" to="564" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Unimodal bandits: Regret lower bounds and optimal algorithms</title>
		<author>
			<persName><forename type="first">Richard</forename><surname>Combes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexandre</forename><surname>Proutiere</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="521" to="529" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Stochastic linear optimization under bandit feedback</title>
		<author>
			<persName><forename type="first">Dani</forename><surname>Varsha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><forename type="middle">P</forename><surname>Hayes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sham</surname></persName>
		</author>
		<author>
			<persName><surname>Kakade</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Learning Theory</title>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Horizon-independent optimal pricing in repeated auctions with truthful and strategic buyers</title>
		<author>
			<persName><forename type="first">Alexey</forename><surname>Drutsa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th International Conference on World Wide Web</title>
		<meeting>the 26th International Conference on World Wide Web</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="33" to="42" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Optimal non-parametric learning in repeated contextual auctions with strategic buyer</title>
		<author>
			<persName><forename type="first">Alexey</forename><surname>Drutsa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICML</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Learning to bid without knowing your value</title>
		<author>
			<persName><forename type="first">Zhe</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chara</forename><surname>Podimata</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vasilis</forename><surname>Syrgkanis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 ACM Conference on Economics and Computation</title>
		<meeting>the 2018 ACM Conference on Economics and Computation</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="505" to="522" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Real-time bidding with side information</title>
		<author>
			<persName><forename type="first">Arthur</forename><surname>Flajolet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Patrick</forename><surname>Jaillet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="5168" to="5178" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">The KL-UCB algorithm for bounded stochastic bandits and beyond</title>
		<author>
			<persName><forename type="first">Aurélien</forename><surname>Garivier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Olivier</forename><surname>Cappé</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Learning Theory</title>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="359" to="376" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">On explore-then-commit strategies</title>
		<author>
			<persName><forename type="first">Aurélien</forename><surname>Garivier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tor</forename><surname>Lattimore</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Emilie</forename><surname>Kaufmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="784" to="792" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Explore first, exploit next: The true shape of regret in bandit problems</title>
		<author>
			<persName><forename type="first">Aurélien</forename><surname>Garivier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pierre</forename><surname>Ménard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gilles</forename><surname>Stoltz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mathematics of Operations Research</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="377" to="399" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Dynamic reserve prices for repeated auctions: Learning from bids</title>
		<author>
			<persName><forename type="first">Yash</forename><surname>Kanoria</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hamid</forename><surname>Nazerzadeh</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014">2014</date>
			<publisher>WINE</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Asymptotically efficient adaptive allocation rules</title>
		<author>
			<persName><forename type="first">Tze</forename><surname>Leung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lai</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Herbert</forename><surname>Robbins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Applied Mathematics</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="4" to="22" />
			<date type="published" when="1985">1985</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Bandit algorithms</title>
		<author>
			<persName><forename type="first">Tor</forename><surname>Lattimore</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Csaba</forename><surname>Szepesvári</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">The weighted majority algorithm</title>
		<author>
			<persName><forename type="first">Nick</forename><surname>Littlestone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Manfred</forename><forename type="middle">K</forename><surname>Warmuth</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1989">1989</date>
		</imprint>
		<respStmt>
			<orgName>University of California, Santa Cruz, Computer Research Laboratory</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Learning theory and algorithms for revenue optimization in second price auctions with reserve</title>
		<author>
			<persName><forename type="first">M</forename><surname>Andres</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mehryar</forename><surname>Medina</surname></persName>
		</author>
		<author>
			<persName><surname>Mohri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="262" to="270" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<author>
			<persName><forename type="first">Mehryar</forename><surname>Mohri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andres</forename><forename type="middle">Munoz</forename><surname>Medina</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1411.6305</idno>
		<title level="m">Revenue optimization in posted-price auctions with strategic buyers</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Optimal auction design</title>
		<author>
			<persName><surname>Roger B Myerson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mathematics of Operations Research</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="58" to="73" />
			<date type="published" when="1981">1981</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Optimal pricing in repeated posted-price auctions with different patience of the seller and the buyer</title>
		<author>
			<persName><forename type="first">Arsenii</forename><surname>Vanunts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexey</forename><surname>Drutsa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="941" to="953" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Counterspeculation, auctions, and competitive sealed tenders</title>
		<author>
			<persName><forename type="first">William</forename><surname>Vickrey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Finance</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="8" to="37" />
			<date type="published" when="1961">1961</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Online learning in repeated auctions</title>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Weed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vianney</forename><surname>Perchet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Philippe</forename><surname>Rigollet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Learning Theory</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="1562" to="1583" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Unimodal bandits</title>
		<author>
			<persName><forename type="first">Jia</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yu</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Shie</forename><surname>Mannor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="41" to="48" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
