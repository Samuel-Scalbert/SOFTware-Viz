<TEI xmlns="http://www.tei-c.org/ns/1.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xml:space="preserve" xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Cross-Platform Evaluation for Italian Hate Speech Detection</title>
				<funder ref="#_9RQgjaa #_6apGXyy #_MnWdHdG #_5DKdvS5">
					<orgName type="full">unknown</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher />
				<availability status="unknown"><licence /></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Michele</forename><surname>Corazza</surname></persName>
							<email>michele.corazza@inria.frmenini</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Université Côte d'Azur</orgName>
								<orgName type="institution" key="instit2">CNRS</orgName>
								<orgName type="institution" key="instit3">Inria</orgName>
								<address>
									<region>I3S</region>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Stefano</forename><surname>Menini</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Fondazione Bruno Kessler</orgName>
								<address>
									<settlement>Trento</settlement>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Elena</forename><surname>Cabrio</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Université Côte d'Azur</orgName>
								<orgName type="institution" key="instit2">CNRS</orgName>
								<orgName type="institution" key="instit3">Inria</orgName>
								<address>
									<region>I3S</region>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Sara</forename><surname>Tonelli</surname></persName>
							<email>satonelli@fbk.euelena.cabrio</email>
							<affiliation key="aff1">
								<orgName type="institution">Fondazione Bruno Kessler</orgName>
								<address>
									<settlement>Trento</settlement>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Serena</forename><surname>Villata</surname></persName>
							<email>serena.villata@unice.fr</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Université Côte d'Azur</orgName>
								<orgName type="institution" key="instit2">CNRS</orgName>
								<orgName type="institution" key="instit3">Inria</orgName>
								<address>
									<region>I3S</region>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Cross-Platform Evaluation for Italian Hate Speech Detection</title>
					</analytic>
					<monogr>
						<imprint>
							<date />
						</imprint>
					</monogr>
					<idno type="MD5">DCC50E85CE479627E2AD9228F2D69265</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-04-12T14:50+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid" />
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div><p>English. Despite the number of approaches recently proposed in NLP for detecting abusive language on social networks, the issue of developing hate speech detection systems that are robust across different platforms is still an unsolved problem. In this paper we perform a comparative evaluation on datasets for hate speech detection in Italian, extracted from four different social media platforms, i.e. Facebook, Twitter, <software>Instagram</software> and What-sApp. We show that combining such platform-dependent datasets to take advantage of training data developed for other platforms is beneficial, although their impact varies depending on the social network under consideration.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div><head n="1">Introduction</head><p>Given the well-acknowledged rise in the presence of toxic and abusive speech on social media platforms like Twitter and Facebook, there have been several efforts within the Natural Language Processing community to deal with such problem, since the computational analysis of language can be used to quickly identify offenses and ease the removal of abusive messages. Several workshops <ref type="bibr" target="#b16">(Waseem et al., 2017;</ref><ref type="bibr" target="#b11">Fišer et al., 2018)</ref> and evaluation campaigns <ref type="bibr" target="#b10">(Fersini et al., 2018;</ref><ref type="bibr" target="#b4">Bosco et al., 2018;</ref><ref type="bibr" target="#b17">Wiegand et al., 2018)</ref> have been recently organized to discuss existing approaches to hate speech detection, propose shared tasks and foster the development of benchmarks for system evaluation.</p><p>However, most of the available datasets and approaches for hate speech detection proposed so far concern the English language, and even more frequently they target a single social media platform (mainly Twitter). In low-resource scenarios it is therefore common to have smaller datasets for specific platforms, raising research questions such as: would it be advisable to combine such platform-dependent datasets to take advantage of training data developed for other platforms? Should such data just be added to the training set or they should be selected in some way? And what happens if training data are available only for one platform and not for the other?</p><p>In this paper we address all the above questions focusing on hate speech detection for Italian. After identifying a modular neural architecture that is rather stable and well-performing across different languages and platforms <ref type="bibr">(Corazza et al., to appear)</ref>, we perform our comparative evaluation on freely available datasets for hate speech detection in Italian, extracted from four different social media platform, i.e. Facebook, Twitter, Instagram and Whatsapp. In particular, we test the same model while altering only some features and pre-processing aspects. Besides, we use a multi-platform training set but test on data taken from the single platforms. We show that the proposed solution of combining platform-dependent datasets in the training phase is beneficial for all platforms but Twitter, for which results obtained by training on tweets only outperform those obtained with a training on the mixed dataset.</p></div>
<div><head n="2">Related work</head><p>In 2018, the first Hate Speech Detection (HaSpeeDe) task for Italian <ref type="bibr" target="#b4">(Bosco et al., 2018)</ref> has been organized at EVALITA-2018<ref type="foot" target="#foot_0">2</ref> , the evaluation campaign for NLP and speech processing tools for Italian. The task consists in automatically annotating messages from Twitter and Facebook, with a boolean value indicating the presence (or not) of hate speech. Two cross-platform tasks (Cross-HaSpeeDe) were also proposed, where the training was done on platform-specific data (Facebook or Twitter) and the test on data from another platform (Twitter or Facebook). In general, as expected, results obtained for Cross-HaSpeeDe were lower compared to those obtained for the indomain tasks, due to the heterogeneous nature of the datasets provided for the task, both in terms of class distribution and data composition. Indeed, not only are Facebook posts in the task dataset longer, but they are also on average more likely to contain hate speech (68% hate posts in the Facebook test set vs. 32% in the Twitter one). This led to a performance drop, with the best system scoring 0.8288 F1 on in-domain Facebook data, and 0.6068 when the same model is tested on Twitter data <ref type="bibr" target="#b7">(Cimino et al., 2018)</ref>.</p><p>The best performing systems on the cross-tasks were ItaNLP <ref type="bibr" target="#b7">(Cimino et al., 2018)</ref> when training on Twitter data and testing on Facebook, and Inria-FBK <ref type="bibr" target="#b8">(Corazza et al., 2018)</ref> in the other configuration. The former adopts a newly-introduced approach based on a 2-layer BiLSTM which exploits multi-task learning with additional data from the 2016 SENTIPOLC task<ref type="foot" target="#foot_1">3</ref> . The latter, instead, uses a simple recurrent model with one hidden layer of size 500, a GRU of size 200 and no dropout.</p><p>The Cross-HaSpeeDe tasks and the analysis of system performance in a cross-platform scenario are the starting point of this study. The task summary presented in <ref type="bibr" target="#b4">(Bosco et al., 2018)</ref> listed some remarks on the elements affecting the system robustness that led us extend the cross-platform experiments to new platforms, including also What-sApp and <software ContextAttributes="used">Instagram</software> data. To our knowledge, there have not been attempts to develop Italian systems for hate speech detection on these two platforms, probably because of the lack of suitable datasets. We therefore annotate our own <software ContextAttributes="used">Instagram</software> data for the task, while we take advantage of a recently developed dataset for cyberbullying detection to test our system on WhastApp.</p></div>
<div><head n="3">Data and linguistic resources</head><p>In the following, we present the datasets used to train and test our system and their annotations (Section 3.1). Then, we describe the word embeddings (Section 3.2) we have used in our experiments.</p></div>
<div><head n="3.1">Datasets</head><p>Twitter dataset released for the HaSpeeDe (Hate Speech Detection) shared task organized at EVALITA 2018. This dataset includes a total amount of 4,000 tweets (2,704 negative and 1,296 positive instances, i.e. containing hate speech), comprising for each tweet the respective annotation, as can be seen in Example 1. The two classes considered in the annotation are "hateful post" or "not".</p><p>1. Annotation: hateful.</p><p>altro che profughi? sono zavorre e tutti uomini (EN: other than refugees? they are ballast and all men).</p><p>Facebook dataset also released for the HaSpeeDe (Hate Speech Detection) shared task. It consists of 4,000 Facebook comments collected from 99 posts crawled from web pages (1,941 negative, and 2,059 positive instances), comprising for each comment the respective annotation, as can be seen in Example 2. The two classes considered in the annotation are "hateful post" or "not".</p></div>
<div><head n="2.">Annotation: hateful.</head><p>Matteo serve un colpo di stato. Qua tra poco dovremo andare in giro tutti armati come in America. (EN: Matteo, we need a coup. Soon we will have to go around armed as in the U.S.).</p><p>Whatsapp dataset collected to study pre-teen cyberbullying <ref type="bibr" target="#b15">(Sprugnoli et al., 2018)</ref>. Such dataset has been collected through a WhatsApp experimentation with Italian lower secondary school students and contains 10 chats, subsequently annotated according to different dimensions as the roles of the participants (e.g. bully, victim) and the presence of cyberbullying expressions in the message, distinguished between different classes of insults, discrimination, sexual talk and aggressive statements. The annotation is carried out at token level. To create additional training instances for our model, we join subsequent sentences of the same author (to avoid cases in which the user writes one word per message) resulting in 1,640 messages (595 positive instances).</p><p>We consider as positive instances of hate speech the ones in which at least one token was annotated as a cyberbullying expression, as in Example 3).</p><p>3. Annotation: Cyberbulling expression. fai schifo, ciccione! (EN: you suck, fat guy).</p><p><software ContextAttributes="created">Instagram</software> dataset includes a total amount of 6,710 messages, which we randomly collected from <software ContextAttributes="created">Instagram</software> focusing on students' profiles (6,510 negative and 200 positive instances) identified through the monitoring system described in <ref type="bibr" target="#b13">(Menini et al., 2019)</ref>. Since no <software ContextAttributes="created">Instagram</software> datasets in Italian were available, and we wanted to include this platform to our study, we manually annotated them as "hateful post" (as in Example 4) or "not".</p><p>4. Annotation: hateful. Sei una troglodita (EN: you are a caveman).</p></div>
<div><head n="3.2">Word Embeddings</head><p>In our experiments we test two types of embeddings, with the goal to compare generic with social media-specific ones. In both cases, we rely on Faxttext embeddings <ref type="bibr" target="#b3">(Bojanowski et al., 2017)</ref>, since they include both word and subword information, tackling the issue of out-of-vocabulary words, which are very common in social media data:</p><p>• Generic embeddings: we use embedding spaces obtained directly from the Fasttext website 4 for Italian. In particular, we use the Italian embeddings trained on Common Crawl and Wikipedia <ref type="bibr" target="#b12">(Grave et al., 2018)</ref> with size 300. A binary Fasttext model is also available and was therefore used;</p><p>4 urlhttps://fasttext.cc/docs/en/crawl-vectors.html</p><p>• Domain-specific embeddings: we trained Fasttext embeddings from a sample of Italian tweets <ref type="bibr" target="#b0">(Basile and Nissim, 2013)</ref>, with embedding size of 300. We used the binary version of the model.</p></div>
<div><head n="4">System Description</head><p>Since our goal is to compare the effect of various features, word embeddings, pre-processing techniques on hate speech detection applied to different platforms, we use a modular neural architecture for binary classification that is able to support both word-level and message-level features. The components are chosen to support the processing of social-media specific language.</p></div>
<div><head n="4.1">Modular neural architecture</head><p>We use a modular neural architecture (see Figure <ref type="figure" target="#fig_0">1</ref>) in Keras <ref type="bibr">(Chollet and others, 2015)</ref>. The architecture that constitutes the base for all the different models uses a single feed forward hidden layer of 500 neurons, with a ReLu activation and a single output with a sigmoid activation. The loss used to train the model is binary cross-entropy. We choose this particular architecture because it showed good performance in the EVALITA shared task for cross-platform hate speech detection, as well as in other hate speech detection tasks for German and English <ref type="bibr">(Corazza et al., to appear)</ref>. The architecture is built to support both word-level (i.e. embeddings) and message-level features. In particular, we use a recurrent layer to learn an encoding (x n in the Figure ) derived from word embeddings, obtained as the output of the recurrent layer at the last timestep. This encoding gets then concatenated with the other selected features, obtaining a vector of message-level features. </p><formula xml:id="formula_0">x 1 ⊕ x n ⊕ . . . RNN x i s i s i-1 y i x e</formula></div>
<div><head n="4.2">Preprocessing</head><p>The language used in social media platforms has some peculiarities with respect to standard language, as for example the presence of URLs, "@" user mentions, emojis and hashtags. We therefore run the following pre-processing steps:</p><p>• URL and mention replacement: both urls and mentions are replaced by the strings "URL" and "username" respectively;</p><p>• Hashtag splitting: Since hashtags often provide important semantic content, we wanted to test how splitting them into single words would impact on the performance of the classifier. To this end, we use the Ekphrasis tool <ref type="bibr" target="#b2">(Baziotis et al., 2017)</ref> to do hashtag splitting and evaluate the classifier performance with and without splitting. Since the aforementioned tool only supports English, it has been adapted to Italian by using language-specific <software ContextAttributes="created">Google ngrams</software>.<ref type="foot" target="#foot_2">5</ref> </p></div>
<div><head n="4.3">Features</head><p>• Word Embeddings: We evaluate the contribution of word embeddings extracted from social media data, compared with the performance obtained using generic embedding spaces, as described in Section 3.2.</p><p>• Emoji transcription: We the impact of keeping emojis or transcribing them in plain text. To this purpose, we use the official plaintext descriptions of the emojis (from the unicode consortium website), translated to Italian with Google translate and then manually corrected, as a substitute for emojis</p><p>• Hurtlex: We assess the impact of using a lexicon of hurtful words <ref type="bibr" target="#b1">(Bassignana et al., 2018)</ref>, created starting from the Italian hate lexicon developed by the linguist Tullio De Mauro, organized in 17 categories. This is used to associate to the messages a score for 'hurtfulness'</p><p>• Social media specific features: We consider a number of metrics related to the language used in social media platforms. In particular,</p></div>
<div><head n="5">Experimental Setup</head><p>In order to be able to compare the results obtained while experimenting with different training datasets and features, we used fixed hyperparameters, derived from our best submission at EVALITA 2018 for the cross-platform task that involved training on Facebook data and testing on Twitter. In particular, we used a GRU <ref type="bibr" target="#b5">(Cho et al., 2014)</ref> of size 200 as the recurrent layer and we applied no dropout to the feed-forward layer. Additionally, we used the provided test set for the two Evalita tasks, using 20% of the development set for validation. For <software ContextAttributes="used">Instagram</software> and WhatsApp, since no standard test set is available, we split the whole dataset using 60% of it for training, while the remaining 40% is split in half and used for validation and testing. For this purpose, we use the train test split function provided by <software ContextAttributes="used">sklearn</software> (Pedregosa et al., 2011), using 42 as seed for the random number generator. One of our goals was to establish whether merging data from multiple social media platforms can be used to improve performance on single platform test sets. In particular, we used the following datasets for training:</p><p>• Multi-platform: we merge all the datasets mentioned in Section 3 for training.</p><p>• Multi-platform filtered by length: we use the same datasets mentioned before, but only considered instances with a length lower or equal to 280 characters, ignoring URLs and user mentions. This was done to match Twitter length restrictions.</p><p>• Same Platform: for each of the datasets, we trained and tested the model on data from the same platform.</p><p>In addition to the experiments performed on different datasets, we also compare the system performance obtained by using different embeddings.</p><p>In particular, we train the system by using </p></div>
<div><head n="6">Results</head><p>For each platform, we report in Table <ref type="table">1</ref> the best performing configuration considering embedding type, features and emoji transcription. We also report the performance obtained by merging all training data (Multi-platform), using only platform-specific training data (Single platform) and filtering training instances &gt; 280 characters (Filtered Multi platform) when testing on Twitter. For <software ContextAttributes="used">Instagram</software>, Facebook and Whatsapp, the best performing configuration is identical. They all use emoji transcription, Twitter embeddings and social-specific features. Using multi-platform training data is also helpful, and all the best performing models on the aforementioned datasets use data obtained from multiple sources. However, the only substantial improvement can be observed in the WhatsApp dataset, probably because it is the smallest one, and the classifier benefits from more training data.</p><p>The results obtained on the Twitter test set differ from the aforementioned ones in several ways. First of all, the in-domain training set is the best performing one, while the restricted length dataset is slightly better than the non restricted one. These results suggest that learning to detect hate speech on the short length interactions that happen on Twitter does not benefit from using data from other platforms. This effect can be at least partially mitigated by restricting the length of the social interactions considered and retaining only the training instances that are more similar to Twitter ones.</p><p>Another remark concerning only Twitter is that Hurtlex is in this case more useful than social network specific features. While the precise cause for this would require more investigation, one possible explanation is the fact that Twitter is known for having a relatively lenient approach to content moderation. This would let more hurtful words slip in, increasing the effectiveness of Hurtlex as a feature, in addition to word embeddings. Additionally, emoji transcription seems to be less useful for Twitter than for other platforms. This might be explained with the fact that the Twitter dataset has relatively less emojis when compared to the others.</p><p>One final outtake confirmed by the results is the fact that embeddings trained on social media platforms (in this case Twitter) always outperform general-purpose embeddings. This shows that the language used on social platforms has peculiarities that might not be present in generic corpora, and that it is therefore advisable to use domain-specific resources.</p></div>
<div><head n="7">Conclusions</head><p>In this paper, we examined the impact of using datasets from multiple platforms in order to classify hate speech on social media. While the results of our experiments successfully demonstrated that using data from multiple sources helps the performance of our model in most cases, the resulting improvement is not always sizeable enough to be useful. Additionally, when dealing with tweets, using data from other social platforms slightly decreases performance, even when we filter the data to contain only short sequences of text. As for future work, further experiments could be performed, by testing all possible combinations of training sources and test sets. This way, we could establish what social platforms share more traits when it comes to hate speech, allowing for better detection systems. At the moment, however, the size of the datasets varies too broadly to allow for a fair comparison, and we would need to extend some of the datasets. Finally, another approach could be tested, where a model trained on Facebook is used for longer sequences of text, while the Twitter model is applied to the shorter ones.</p></div><figure xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Modular neural architecture for Italian hate speech detection</figDesc></figure>
<figure type="table" xml:id="tab_0"><head /><label /><figDesc>Italian Fasttext word embeddings trained on Common-Crawl and Wikipedia, and Fasttext word embeddings trained by us on a sample of Italian tweets</figDesc><table><row><cell>Platform</cell><cell>Training set</cell><cell cols="2">Embeddings Features</cell><cell>Emoji Transcription</cell><cell cols="3">F1 no hate F1 hate Macro AVG</cell></row><row><cell>Instagram</cell><cell>Multi Platform Single Platform</cell><cell>Twitter Twitter</cell><cell>Social Social</cell><cell>Yes Yes</cell><cell>0.984 0.981</cell><cell>0.432 0.424</cell><cell>0.708 0.702</cell></row><row><cell>Facebook</cell><cell>Multi Platform Single Platform</cell><cell>Twitter Twitter</cell><cell>Social Social</cell><cell>Yes Yes</cell><cell>0.773 0.733</cell><cell>0.871 0.892</cell><cell>0.822 0.812</cell></row><row><cell>WhatsApp</cell><cell>Multi Platform Single Platform</cell><cell>Twitter Twitter</cell><cell>Social Social</cell><cell>Yes Yes</cell><cell>0.852 0.814</cell><cell>0.739 0.694</cell><cell>0.796 0.754</cell></row><row><cell /><cell>Single Platform</cell><cell>Twitter</cell><cell>Hurtlex</cell><cell>No</cell><cell>0.879</cell><cell>0.717</cell><cell>0.798</cell></row><row><cell>Twitter</cell><cell>Filtered Multi Platform</cell><cell>Twitter</cell><cell>Hurtlex</cell><cell>No</cell><cell>0.858</cell><cell>0.720</cell><cell>0.789</cell></row><row><cell /><cell>Multi Platform</cell><cell>Twitter</cell><cell>Hurtlex</cell><cell>No</cell><cell>0.851</cell><cell>0.712</cell><cell>0.782</cell></row><row><cell /><cell /><cell cols="3">Table 1: Classification results</cell><cell /><cell /><cell /></row><row><cell cols="4">(Basile and Nissim, 2013), with an embedding</cell><cell /><cell /><cell /><cell /></row><row><cell cols="4">size of 300. As described in Section 4.3, we also</cell><cell /><cell /><cell /><cell /></row><row><cell cols="4">train our models including either social-media or</cell><cell /><cell /><cell /><cell /></row><row><cell cols="4">Hurtlex features. Finally, we compare classifi-</cell><cell /><cell /><cell /><cell /></row><row><cell cols="4">cation performance with and without emoji tran-</cell><cell /><cell /><cell /><cell /></row><row><cell>scription.</cell><cell /><cell /><cell /><cell /><cell /><cell /><cell /></row></table></figure>
			<note place="foot" n="2" xml:id="foot_0"><p>http://www.evalita.it/2018</p></note>
			<note place="foot" n="3" xml:id="foot_1"><p>http://www.di.unito.it/ ˜tutreeb/ sentipolc-evalita16/index.html</p></note>
			<note place="foot" n="5" xml:id="foot_2"><p>http://storage.googleapis.com/books/ ngrams/books/datasetsv2.html we measure the number of hashtags and mentions, the number of exclamation and question marks, the number of emojis, the number of words written in uppercase</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgments</head><p>Part of this work was funded by the <rs type="projectName">CREEP</rs> project (http://creep-project.eu/), a <rs type="projectName">Digital Wellbeing Activity</rs> supported by <rs type="projectName">EIT Digital</rs> in 2018 and 2019. This research was also supported by the <rs type="projectName">HATEMETER</rs> project (http:// hatemeter.eu/) within the <rs type="programName">EU Rights, Equality and Citizenship Programme</rs> <rs type="grantNumber">2014-2020</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funded-project" xml:id="_9RQgjaa">
					<orgName type="project" subtype="full">CREEP</orgName>
				</org>
				<org type="funded-project" xml:id="_6apGXyy">
					<orgName type="project" subtype="full">Digital Wellbeing Activity</orgName>
				</org>
				<org type="funded-project" xml:id="_MnWdHdG">
					<orgName type="project" subtype="full">EIT Digital</orgName>
				</org>
				<org type="funded-project" xml:id="_5DKdvS5">
					<idno type="grant-number">2014-2020</idno>
					<orgName type="project" subtype="full">HATEMETER</orgName>
					<orgName type="program" subtype="full">EU Rights, Equality and Citizenship Programme</orgName>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Sentiment analysis on italian tweets</title>
		<author>
			<persName><forename type="first">Valerio</forename><surname>Basile</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Malvina</forename><surname>Nissim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 4th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis</title>
		<meeting>the 4th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis<address><addrLine>Atlanta</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="100" to="107" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Hurtlex: A multilingual lexicon of words to hurt</title>
		<author>
			<persName><forename type="first">Elisa</forename><surname>Bassignana</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Valerio</forename><surname>Basile</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Viviana</forename><surname>Patti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">5th Italian Conference on Computational Linguistics, CLiC-it 2018</title>
		<imprint>
			<publisher>CEUR-WS</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">2253</biblScope>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">DataStories at SemEval-2017 Task 4: Deep LSTM with Attention for Message-level and Topic-based Sentiment Analysis</title>
		<author>
			<persName><forename type="first">Christos</forename><surname>Baziotis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nikos</forename><surname>Pelekis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christos</forename><surname>Doulkeridis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)</title>
		<meeting>the 11th International Workshop on Semantic Evaluation (SemEval-2017)<address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017-08">2017. August</date>
			<biblScope unit="page" from="747" to="754" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Enriching word vectors with subword information</title>
		<author>
			<persName><forename type="first">Piotr</forename><surname>Bojanowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Edouard</forename><surname>Grave</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Armand</forename><surname>Joulin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="135" to="146" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Overview of the EVALITA 2018 hate speech detection task</title>
		<author>
			<persName><forename type="first">Cristina</forename><surname>Bosco</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Felice</forename><surname>Dell'orletta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fabio</forename><surname>Poletto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Manuela</forename><surname>Sanguinetti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maurizio</forename><surname>Tesconi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Sixth Evaluation Campaign of Natural Language Processing and Speech Tools for Italian. Final Workshop (EVALITA 2018) co-located with the Fifth Italian Conference on Computational Linguistics (CLiC-it 2018)</title>
		<meeting>the Sixth Evaluation Campaign of Natural Language Processing and Speech Tools for Italian. Final Workshop (EVALITA 2018) co-located with the Fifth Italian Conference on Computational Linguistics (CLiC-it 2018)<address><addrLine>Turin, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Learning phrase representations using rnn encoder-decoder for statistical machine translation</title>
		<author>
			<persName><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bart</forename><surname>Van Merrienboer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Caglar</forename><surname>Gulcehre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dzmitry</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fethi</forename><surname>Bougares</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Holger</forename><surname>Schwenk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="1724" to="1734" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<author>
			<persName><forename type="first">Chollet</forename><surname>Franc</surname></persName>
		</author>
		<ptr target="https://github.com/fchollet/keras" />
		<title level="m">Keras</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Multi-task learning in deep neural networks at EVALITA</title>
		<author>
			<persName><forename type="first">Andrea</forename><surname>Cimino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lorenzo</forename><surname>De Mattei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Felice</forename><surname>Dell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">'</forename><surname>Orletta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Sixth Evaluation Campaign of Natural Language Processing and Speech Tools for Italian. Final Workshop (EVALITA 2018) co-located with the Fifth Italian Conference on Computational Linguistics (CLiC-it 2018)</title>
		<meeting>the Sixth Evaluation Campaign of Natural Language Processing and Speech Tools for Italian. Final Workshop (EVALITA 2018) co-located with the Fifth Italian Conference on Computational Linguistics (CLiC-it 2018)<address><addrLine>Turin, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Comparing different supervised approaches to hate speech detection</title>
		<author>
			<persName><forename type="first">Michele</forename><surname>Corazza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefano</forename><surname>Menini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pinar</forename><surname>Arslan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rachele</forename><surname>Sprugnoli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elena</forename><surname>Cabrio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sara</forename><surname>Tonelli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Serena</forename><surname>Villata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Sixth Evaluation Campaign of Natural Language Processing and Speech Tools for Italian. Final Workshop (EVALITA 2018) co-located with the Fifth Italian Conference on Computational Linguistics (CLiC-it 2018)</title>
		<meeting>the Sixth Evaluation Campaign of Natural Language Processing and Speech Tools for Italian. Final Workshop (EVALITA 2018) co-located with the Fifth Italian Conference on Computational Linguistics (CLiC-it 2018)<address><addrLine>Turin, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">to appear. Robust Hate Speech Detection: A Cross-Language Evaluation</title>
		<author>
			<persName><forename type="first">Michele</forename><surname>Corazza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefano</forename><surname>Menini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elena</forename><surname>Cabrio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sara</forename><surname>Tonelli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Serena</forename><surname>Villata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions on Internet Technology</title>
		<imprint />
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Overview of the task on automatic misogyny identification at ibereval 2018</title>
		<author>
			<persName><forename type="first">Elisabetta</forename><surname>Fersini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paolo</forename><surname>Rosso</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maria</forename><surname>Anzovino</surname></persName>
		</author>
		<ptr target="CEUR-WS.org" />
	</analytic>
	<monogr>
		<title level="m">IberEval@SEPLN</title>
		<title level="s">CEUR Workshop Proceedings</title>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">2150</biblScope>
			<biblScope unit="page" from="214" to="228" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Proceedings of the 2nd workshop on abusive language online (alw2)</title>
		<author>
			<persName><forename type="first">Darja</forename><surname>Fišer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruihong</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vinodkumar</forename><surname>Prabhakaran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rob</forename><surname>Voigt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zeerak</forename><surname>Waseem</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jacqueline</forename><surname>Wernimont</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2nd Workshop on Abusive Language Online (ALW2)</title>
		<meeting>the 2nd Workshop on Abusive Language Online (ALW2)</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Learning word vectors for 157 languages</title>
		<author>
			<persName><forename type="first">Edouard</forename><surname>Grave</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Piotr</forename><surname>Bojanowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Prakhar</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Armand</forename><surname>Joulin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Language Resources and Evaluation (LREC 2018)</title>
		<meeting>the International Conference on Language Resources and Evaluation (LREC 2018)</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A system to monitor cyberbullying based on message classification and social network analysis</title>
		<author>
			<persName><forename type="first">Stefano</forename><surname>Menini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Giovanni</forename><surname>Moretti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michele</forename><surname>Corazza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elena</forename><surname>Cabrio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sara</forename><surname>Tonelli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Serena</forename><surname>Villata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Third Workshop on Abusive Language Online</title>
		<meeting>the Third Workshop on Abusive Language Online<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019-08">2019. August</date>
			<biblScope unit="page" from="105" to="110" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Scikit-learn: Machine learning in Python</title>
		<author>
			<persName><forename type="first">F</forename><surname>Pedregosa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Varoquaux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gramfort</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Michel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Thirion</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Grisel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Blondel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Prettenhofer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Dubourg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Vanderplas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Passos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Cournapeau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Brucher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Perrot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Duchesnay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2825" to="2830" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Creating a whatsapp dataset to study pre-teen cyberbullying</title>
		<author>
			<persName><forename type="first">Rachele</forename><surname>Sprugnoli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefano</forename><surname>Menini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sara</forename><surname>Tonelli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Filippo</forename><surname>Oncini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Enrico</forename><surname>Piras</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2nd Workshop on Abusive Language Online (ALW2)</title>
		<meeting>the 2nd Workshop on Abusive Language Online (ALW2)</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="51" to="59" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Proceedings of the first workshop on abusive language online</title>
		<author>
			<persName><forename type="first">Zeerak</forename><surname>Waseem</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wendy</forename><surname>Hui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kyong</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dirk</forename><surname>Hovy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joel</forename><surname>Tetreault</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First Workshop on Abusive Language Online</title>
		<meeting>the First Workshop on Abusive Language Online</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Overview of the germeval 2018 shared task on the identification of offensive language</title>
		<author>
			<persName><forename type="first">Michael</forename><surname>Wiegand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Melanie</forename><surname>Siegel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Josef</forename><surname>Ruppenhofer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of GermEval 2018, 14th Conference on Natural Language Processing</title>
		<meeting>GermEval 2018, 14th Conference on Natural Language Processing<address><addrLine>KONVENS</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>