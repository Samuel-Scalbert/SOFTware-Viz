<TEI xmlns="http://www.tei-c.org/ns/1.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xml:space="preserve" xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Overview of BirdCLEF 2023: Automated Bird Species Identification in Eastern Africa</title>
			</titleStmt>
			<publicationStmt>
				<publisher />
				<availability status="unknown"><licence /></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Stefan</forename><surname>Kahl</surname></persName>
							<email>stefan.kahl@cornell.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Cornell Lab of Ornithology</orgName>
								<orgName type="laboratory">K. Lisa Yang Center for Conservation Bioacoustics</orgName>
								<orgName type="institution">Cornell University</orgName>
								<address>
									<settlement>Ithaca</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Chemnitz University of Technology</orgName>
								<address>
									<settlement>Chemnitz</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Tom</forename><surname>Denton</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">Google LLC</orgName>
								<address>
									<settlement>San Francisco</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Holger</forename><surname>Klinck</surname></persName>
							<email>holger.klinck@cornell.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Cornell Lab of Ornithology</orgName>
								<orgName type="laboratory">K. Lisa Yang Center for Conservation Bioacoustics</orgName>
								<orgName type="institution">Cornell University</orgName>
								<address>
									<settlement>Ithaca</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Hendrik</forename><surname>Reers</surname></persName>
							<email>reers@oekofor.de</email>
							<affiliation key="aff3">
								<orgName type="institution">OekoFor GbR</orgName>
								<address>
									<settlement>Freiburg</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Francis</forename><surname>Cherutich</surname></persName>
							<affiliation key="aff4">
								<orgName type="institution">Independent</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">HervÃ©</forename><surname>Glotin</surname></persName>
							<email>herve.glotin@univ-tln.fr</email>
							<affiliation key="aff5">
								<orgName type="department">AMU</orgName>
								<orgName type="institution" key="instit1">University of Toulon</orgName>
								<orgName type="institution" key="instit2">CNRS</orgName>
								<orgName type="institution" key="instit3">LIS</orgName>
								<address>
									<settlement>Marseille</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">HervÃ©</forename><surname>GoÃ«au</surname></persName>
							<email>herve.goeau@cirad.fr</email>
							<affiliation key="aff6">
								<orgName type="laboratory">CIRAD</orgName>
								<orgName type="institution">UMR AMAP</orgName>
								<address>
									<settlement>Montpellier</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Willem-Pier</forename><surname>Vellinga</surname></persName>
							<affiliation key="aff7">
								<orgName type="institution">Xeno-canto Foundation</orgName>
								<address>
									<settlement>Groningen</settlement>
									<country key="NL">Netherlands</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Robert</forename><surname>PlanquÃ©</surname></persName>
							<affiliation key="aff7">
								<orgName type="institution">Xeno-canto Foundation</orgName>
								<address>
									<settlement>Groningen</settlement>
									<country key="NL">Netherlands</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Alexis</forename><surname>Joly</surname></persName>
							<email>alexis.joly@inria.fr</email>
							<affiliation key="aff8">
								<orgName type="laboratory" key="lab1">Inria</orgName>
								<orgName type="laboratory" key="lab2">LIRMM</orgName>
								<orgName type="institution" key="instit1">University of Montpellier</orgName>
								<orgName type="institution" key="instit2">CNRS</orgName>
								<address>
									<settlement>Montpellier</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Overview of BirdCLEF 2023: Automated Bird Species Identification in Eastern Africa</title>
					</analytic>
					<monogr>
						<idno type="ISSN">1613-0073</idno>
					</monogr>
					<idno type="MD5">DB3121C27B35DCB893CB5CC665AB35D3</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-04-12T14:50+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid" />
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>LifeCLEF</term>
					<term>bird</term>
					<term>song</term>
					<term>call</term>
					<term>species</term>
					<term>retrieval</term>
					<term>audio</term>
					<term>collection</term>
					<term>identification</term>
					<term>fine-grained classification</term>
					<term>evaluation</term>
					<term>benchmark</term>
					<term>bioacoustics</term>
					<term>passive acoustic monitoring</term>
				</keywords>
			</textClass>
			<abstract>
<div><p>The <software>BirdCLEF</software> 2023 challenge focused on bird species classification in a dataset of Kenyan soundscape recordings. Kenya is home to over 1,000 species of birds, covering a wide range of ecosystems, from the savannahs of the Maasai Mara to the Kakamega rainforest, and even alpine regions on Kilimanjaro and Mount Kenya. Tracking this vast number of species with ML can be challenging, especially with minimal training data available for many species. This year the competition switched back to threshold-free evaluation metric, and introduced a two-hour time limit on inference to ensure the practical usability of models.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div><head n="1.">Introduction</head><p>Passive acoustic monitoring (PAM), utilizing autonomous sound recorders to observe animals and their habitats at ecologically relevant scales, has emerged as an indispensable survey method in conservation <ref type="bibr" target="#b0">[1]</ref>. The accessibility of inexpensive commercial off-the-shelf sound recorders has made data collection a straightforward process for the community. Arrays of sound recorders are frequently deployed over extended periods (weeks to months), generating large amounts of data that offer valuable insights into the abundance and distribution of vocalizing animals with high spatiotemporal resolution <ref type="bibr" target="#b1">[2]</ref>. Nevertheless, several challenges persist in PAM. It is not uncommon for data collection endeavors to produce tens of Terabytes of acoustic data that must be efficiently managed, stored, and analyzed <ref type="bibr" target="#b2">[3]</ref>. Particularly, the analysis task, which involves reliably extracting relevant signals from often intricate soundscapes, remains an active area of research. Furthermore, while common species typically have ample representation in existing training datasets, data for rare, listed, or endangered species is often limited, necessitating the development of novel and innovative algorithmic approaches to monitor these species in need.</p><p>Eastern African species play a crucial role in both ecological systems and evolutionary processes, making them of utmost importance for scientific research and conservation efforts <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b4">5]</ref>. This region is renowned for its exceptional biodiversity, particularly in terms of avian species, which exhibit a remarkable diversity of vocalizations <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b6">7]</ref>. The vocal signals produced by Eastern African species are integral to their communication and social interactions and serve as valuable indicators of their presence and behavior. However, despite their significance, Eastern African bird species are often underrepresented in sound collections like Xeno-canto <ref type="foot" target="#foot_0">1</ref>or Macaulay Library<ref type="foot" target="#foot_1">2</ref> . This lack of comprehensive acoustic data poses challenges for developing and applying machine learning algorithms aimed at monitoring and studying these species. Insufficient training data for these algorithms hinders their ability to detect and classify the vocalizations of Eastern African species accurately, impeding advancements in automated monitoring techniques. Consequently, addressing this issue and raising awareness is crucial for facilitating the development of robust machine-learning algorithms and enabling effective monitoring and conservation strategies for these important and underrepresented species.</p><p>The Bird Recognition Challenge (<software ContextAttributes="used">BirdCLEF</software>) is part of LifeCLEF 2023 <ref type="bibr" target="#b7">[8]</ref> and focuses on the development of reliable analysis frameworks to detect and identify avian vocalizations in continuous soundscape data. Launched in 2014, it has become one of the largest bird sound recognition competitions in terms of dataset size and species diversity, with several tens of thousands of recordings covering up to 1,500 species <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b9">10]</ref>. The <software ContextAttributes="used">BirdCLEF</software> 2023 competition challenged participants to develop reliable analysis frameworks to detect and identify the vocalizations of bird species in continuous Eastern African soundscapes, coping with limited training data for many species.</p></div>
<div><head n="2.">BirdCLEF 2023 Competition Overview</head><p>Recent advancements in the development of machine listening techniques for the identification of animal vocalizations have enhanced our ability to analyze long-term acoustic datasets comprehensively <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b11">12]</ref>. However, generating analysis outputs with high precision and recall, particularly when targeting a large number of species simultaneously, remains challenging. Bridging the gap between high-quality training samples (focal recordings) and noisy test samples (soundscape recordings) is a difficult task in the field of acoustic event detection and classification. The 2023 <software ContextAttributes="used">BirdCLEF</software> competition addressed this intricate challenge and was hosted on Kaggle<ref type="foot" target="#foot_2">3</ref> . This year's edition focused on identifying which birds are calling in long recordings made in Kenya. The competition was held in a "code competition" format, encouraging participants to share their code for the benefit of the community, especially scientists and practitioners who monitor bird populations for conservation purposes in Kenya. In addition, submissions were required to complete inference in less than 2 hours. We implemented this time constraint to ensure that the developed models can run efficiently on modest compute resources available to conservationists.</p></div>
<div><head n="2.1.">Goal and Evaluation Protocol</head><p>This year's competition featured two major changes compared to the previous few years: A new metric was used for evaluation (padded class-averaged mean-average precision, or pcmAP) and a time-limit of two CPU hours was placed on inference.</p></div>
<div><head n="2.2.">Metric</head><p>The cmAP metric was used in <software>BirdCLEF</software> competitions before the move to Kaggle, which previous to this year could not support cmAP. As a result, the competition in 2020, 2021, 2022, have used variants of F1 score. The downside to F1 is that it requires choosing a binary label for species in each inference window. There are numerous ways to reduce a model's output probabilities to a binary decision, which has led to substantial effort in recent years to find clever threshold selection techniques. Unfortunately, this makes it hard to evaluate the base model quality. In practice, correct selection of thresholds depends on the goals of the end-user (eg, according to preference in trading off precision and recall), so there is some preference for threshold-free evaluation of model quality.</p><p>This year, Kaggle added support for custom metrics, which allowed the competition to use the cmAP score, which is defined as:</p><formula xml:id="formula_0">ğ‘ğ‘šğ´ğ‘ƒ := âˆ‘ï¸€ ğ¶ ğ‘=1 ğ´ğ‘£ğ‘’ğ‘ƒ (ğ‘) ğ¶</formula><p>where ğ¶ is the number of target classes, and ğ´ğ‘£ğ‘’ğ‘ƒ (ğ‘) is the average precision for the ğ‘th species, computed as:</p><formula xml:id="formula_1">ğ´ğ‘£ğ‘’ğ‘ƒ (ğ‘) = âˆ‘ï¸€ ğ‘ ğ‘˜=1 ğ‘ƒ (ğ‘˜) Ã— ğ‘Ÿğ‘’ğ‘™(ğ‘˜) ğ‘› ğ‘Ÿğ‘’ğ‘™ (ğ‘)</formula><p>where k is the rank of an item in the list of examples containing class ğ‘, ğ‘ƒ (ğ‘˜) is the precision at cut-off ğ‘˜ in the list, ğ‘Ÿğ‘’ğ‘™(ğ‘˜) is an indicator function indicating whether class ğ‘ is present in the ğ‘˜th example, and ğ‘› ğ‘Ÿğ‘’ğ‘™ (ğ‘) is the total number of examples containing class ğ‘. cmAP computes the per-class mean average precision (treating each model output as an independent binary classifier), and then averages over all classes. An advantage of cmAP is that all species are weighted equally, regardless of the number of examples in the inference set. A disadvantage is that for species with very few examples in the dataset, the individual species MAP can be quite noisy, which in turn is reflected in the overall cmAP score.</p><p>To deal with this, we proposed a modification of ğ‘ğ‘šğ´ğ‘ƒ metric called padded cmAP, or pcmAP, in which ğ‘ 'free' examples are added to the top of each class. This limits the dynamic range of the per-species MAP scores, reducing the impact of noise in species with very few labels. For the competition, we used ğ‘ = 5.</p></div>
<div><head n="2.3.">Time Limits</head><p>Competitors were limited to two hours of inference time on CPU. This ensures that models are cost-effective for real-world usage. A side effect is reducing the impact of ensembling, a common Kaggle tactic which also obscures underlying model quality.</p></div>
<div><head n="2.4.">Dataset</head></div>
<div><head n="2.4.1.">Training Data</head><p>As in previous editions, training data was provided by the Xeno-Canto community and consisted of more than 16,900 recordings covering 264 species. Participants were allowed to use metadata to develop their systems, and were also allowed to gather more recordings from Xeno-Canto. Most notably, we provided detailed information on where and when focal and soundscape recordings were made, allowing participants to account for spatiotemporal occurrence patterns of bird species.</p></div>
<div><head n="2.4.2.">Test Data</head><p>As in previous years on Kaggle, the test data was completely hidden from participants. Hidden test data consisted of 191 soundscapes of 10-minute duration and were recorded at multiple locations west and southwest of Lake Baringo in Baringo County, Kenya (see figure <ref type="figure" target="#fig_0">1</ref>). Soundscapes were expertly annotated by local expert Francis Cherutich who provided 10,294 labels for 176 species.</p></div>
<div><head n="3.">Results</head><p>This year, we had 1,189 teams and nearly 1,400 competitors, and 21,519 total submissions. As in other recent years, two-thirds of the test data was used for the private leaderboard, and one third for the public leaderboard. The padded cmAP metric yielded a fairly high baseline score. A baseline using <software>BirdNET</software> 2.2 with no modifications gave a score of 0.771 on the public board and 0.664 on the private leaderboard. The overall winner achieved a public score of 0.844 and a private score of 0.764. There was relatively little 'shake-up' in the results -the top public entry dropped to third, and otherwise the top five maintained their order on the private leaderboard. This stability may be due to better cross-validation practices in recent competitions.</p><p>A few common themes emerged in the top solutions. First, the top competitors went out of their way to obtain more data and ensure that the data they were working with was clean. The pre-packaged Xeno-Canto data was limited to 500 samples per species to keep file sizes manageable; multiple top competitors went back to XC and downloaded the additional data. The second-place competitor also noticed some inconsistencies in converting the XC scientific names to the ebird codes used in previous-year test data; this may be due to subsequent changes in both the ebird and IOC taxonomy used by Xeno-Canto, but in any case reinforces the need for careful data handling.</p><p>Second, the top competitors took advantage of model optimization tools, managing to make ensembles of up to seven(!!) models run in the specified time limit. <software>ONNX</software>, a platform-independent model format, was particularly popular. A few competitors also saw large speed gains with OpenVINO, an Intel-specific model optimizer and inference library. Particularly creative: The third-place competitor (long-time <software ContextAttributes="used">BirdCLEF</software> participant Mario Lasseck) built a large ensemble and used a timer to stop inference before time ran out. They also report that <software ContextAttributes="used">OpenVino</software> only gave noticeable speedups over <software ContextAttributes="used">ONNX</software> at small batch sizes. (This makes some sense: The primary tool for speeding up inference on CPU is SIMD computation. A kernel implementation which uses SIMD over the batch dimension will under-perform on small batch sizes.)</p><p>This year, many of the test-sets from previous years were released on Zenodo, though these datasets have minimal overlap with this year's African species list. Many top competitors used the Zenodo data, but most only used it to find no-call segments for augmentation and training.</p><p>The top competitors generally trained models from scratch from the Xeno-Canto data, first using a pre-training phase and then fine-tuning to the particular species in the competition list. Competitors mostly restricted pre-training to the 250 species appearing in previous competitions.</p><p>We accepted five working notes for the proceedings.</p></div>
<div><head>Miyaguchi, et al. [13]:</head><p>This team experimented with using unsupervised source separation models for pseudo-labeling training data. They also included some UMAP plots of the model embedding space, which provide insight into the linear separability of the classes.</p></div>
<div><head>Mario Lasseck [14]:</head><p>A clear write-up from a long-standing <software>BirdCLEF</software> competitor using a combination of methods (energy measurement and pseudo-labels) to combat the weak-label problem in the training data. Lasseck also found benefit from a new reverb augmentation and applying SED attention over time.</p></div>
<div><head>Lihang Hong [15]:</head><p>The second-place entry used OpenVINO to get a full seven models running in an ensemble, while still meeting the two-hour inference time limit.</p></div>
<div><head>Paul Nussbaum [16]:</head><p>Presents a method for measuring data loss as features develop in the classification network. By applying pseudo-inverse techniques to the activations at each layer, one can try to recover the original inputs and measure corruption.</p></div>
<div><head>Mihai Minut et al. [17]:</head><p>An early effort from a new competitor, this write-up summarizes previous <software>BirdCLEF</software> results and presents experiments with data pre-processing and model architectures. They had more success with pre-trained ImageNet weights than with custom CNNs.</p><p>Notable excerpts from individual contributors who did not submit working notes:</p><p>â€¢ The fourth-place competitor, atfujita, used knowledge distillation, directly applying the techniques in (Knowledge distillation: A good teacher is patient and consistent) to distill the Google Bird Vocalizations model into a faster model. â€¢ The fist-place competitor, Volodymyr, emphasized over-sampling low-data classes during training. They sampled each class according to the distribution which balances the training data distribution. â€¢ Volodymyr also addressed around the 'weak-labels' problem in Xeno-Canto by training on longer 30-second segments and using an attention layer to aggregate the features. Since the attention-aggregated features are a weighted sum over the time dimension, the same model which is trained on 30 seconds of audio can then be applied to 5-second segments.</p></div>
<div><head n="4.">Conclusions and Lessons Learned</head><p>Thanks to the new metric and inference time limit, we saw a proliferation of new ideas this year, moving beyond the threshold tuning of the previous few years. The top entries included three approaches that we might call strong on Kaggle fundamentals, one entry which leveraged <software>OpenVino</software> to get a particularly large solution, and one entry which used model distillation to transfer strong pre-trained embeddings. We also saw more experimentation with modeling approaches overall.</p></div><figure xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Pictures illustrating the different habitat types in Kenya where the soundscape recordings were collected. Photos Francis Cherutich.</figDesc><graphic coords="5,89.29,256.23,204.19,136.18" type="bitmap" /></figure>
<figure xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Top 25 private leaderboard scores achieved by the best systems evaluated within the primary bird identification task of LifeCLEF 2023. Public and private test data were split randomly, private scores remained hidden until the submission deadline. Participants were able to optimize the recognition performance of their systems based on public scores, which likely explains some differences in scores.</figDesc><graphic coords="6,89.29,84.19,416.69,105.90" type="bitmap" /></figure>
			<note place="foot" n="1" xml:id="foot_0"><p>https://xeno-canto.org</p></note>
			<note place="foot" n="2" xml:id="foot_1"><p>https://www.macaulaylibrary.org</p></note>
			<note place="foot" n="3" xml:id="foot_2"><p>https://www.kaggle.com/c/birdclef-2023</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgments</head><p>We would also like to thank <rs type="institution">Kaggle</rs> for helping us host this competition. We are especially grateful for the incredible support and efforts of <rs type="person">Maggie Demkin</rs>, <rs type="person">Sohier Dane</rs>, and <rs type="person">Addison Howard</rs> who helped process the dataset and set up the competition. Special thanks to Google for sponsoring the prize money for this competition. Last but not least, thanks to everyone who provided/annotated data, participated in this contest, and shared their code base and write-ups with the <rs type="institution">Kaggle</rs> community.</p><p>All results, code notebooks, and forum posts are publicly available at: https://www.kaggle.com/c/birdclef-2023</p></div>
			</div>			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Terrestrial passive acoustic monitoring: review and perspectives</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">S M</forename><surname>Sugai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">S F</forename><surname>Silva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">W</forename><surname>Ribeiro</surname><genName>Jr</genName></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Llusia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BioScience</title>
		<imprint>
			<biblScope unit="volume">69</biblScope>
			<biblScope unit="page" from="15" to="25" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A roadmap for survey designs in terrestrial acoustic monitoring</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">S M</forename><surname>Sugai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Desjonqueres</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">S F</forename><surname>Silva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Llusia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Remote Sensing in Ecology and Conservation</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="220" to="235" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Perspectives in machine learning for wildlife conservation</title>
		<author>
			<persName><forename type="first">D</forename><surname>Tuia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Kellenberger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Beery</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">R</forename><surname>Costelloe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zuffi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Risse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mathis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">W</forename><surname>Mathis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Van Langevelde</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Burghardt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature communications</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="1" to="15" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">The combined effects of temperature and fragment area on the demographic rates of an afrotropical bird community over 34 years</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">H</forename><surname>Neate-Clegg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Etterson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">W</forename><surname>Tingley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">D</forename><surname>Newmark</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.biocon.2023.110051</idno>
		<ptr target="https://doi.org/10.1016/j.biocon.2023.110051" />
	</analytic>
	<monogr>
		<title level="j">Biological Conservation</title>
		<imprint>
			<biblScope unit="volume">282</biblScope>
			<biblScope unit="page">110051</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Conservation priorities for birds and biodiversity: Do east african important bird areas represent species diversity in other terrestrial vertebrate groups?</title>
		<author>
			<persName><forename type="first">T</forename><surname>Brooks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Balmford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Burgess</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Hansen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Moore</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Rahbek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Bennun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Byaruhanga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Kasoma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Njoroge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Pomeroy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Wondafrash</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">A</forename></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">P</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ostrich Supplement</title>
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<author>
			<persName><forename type="first">T</forename><surname>Stevenson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Fanshawe</surname></persName>
		</author>
		<title level="m">Field Guide to the Birds of East Africa: Kenya, Tanzania, Uganda, Rwanda, Burundi</title>
		<imprint>
			<publisher>Bloomsbury Publishing</publisher>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Duetting and chorus singing in african birds</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">B</forename><surname>Payne</surname></persName>
		</author>
		<idno type="DOI">10.1080/00306525.1971.9633401</idno>
	</analytic>
	<monogr>
		<title level="j">Ostrich</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="page" from="125" to="146" />
			<date type="published" when="1971">1971</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Overview of LifeCLEF 2023: evaluation of AI models for the identification and prediction of birds, plants, snakes and fungi</title>
		<author>
			<persName><forename type="first">A</forename><surname>Joly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Botella</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Picek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kahl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>GoÃ«au</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Deneu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Marcos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Estopinan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Leblanc</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Larcher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Chamidullin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Å ulc</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>HrÃºz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Servajean</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Glotin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>PlanquÃ©</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W.-P</forename><surname>Vellinga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Klinck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Denton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Eggel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Bonnet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>MÃ¼ller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference of the Cross-Language Evaluation Forum for European Languages</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Overview of LifeCLEF 2021: a System-oriented Evaluation of Automated Species Identification and Species Distribution Prediction</title>
		<author>
			<persName><forename type="first">A</forename><surname>Joly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>GoÃ«au</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kahl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Picek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Lorieul</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Cole</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Deneu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Servajean</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ruiz De CastaÃ±eda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Bolon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Glotin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>PlanquÃ©</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W.-P</forename><surname>Vellinga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Dorso</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Klinck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Denton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Eggel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Bonnet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>MÃ¼ller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twelfth International Conference of the CLEF Association (CLEF 2021)</title>
		<meeting>the Twelfth International Conference of the CLEF Association (CLEF 2021)</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Overview of BirdCLEF 2020: Bird sound recognition in complex acoustic environments</title>
		<author>
			<persName><forename type="first">S</forename><surname>Kahl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Clapp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Hopping</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>GoÃ«au</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Glotin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>PlanquÃ©</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W.-P</forename><surname>Vellinga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Joly</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CLEF: Conference and Labs of the Evaluation Forum</title>
		<meeting><address><addrLine>Thessaloniki, Greece</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020-09">Sep. 2020. 2020</date>
		</imprint>
	</monogr>
	<note>CLEF task overview 2020</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">BirdNET: A deep learning solution for avian diversity monitoring</title>
		<author>
			<persName><forename type="first">S</forename><surname>Kahl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">M</forename><surname>Wood</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Eibl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Klinck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ecological Informatics</title>
		<imprint>
			<biblScope unit="volume">61</biblScope>
			<biblScope unit="page">101236</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Deep neural networks for automated detection of marine mammal species</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Shiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Palmer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Roch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Fleishman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E.-M</forename><surname>Nosal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Helble</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Cholewiak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Gillespie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Klinck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Scientific reports</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="1" to="12" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Transfer Learning with Semi-Supervised Dataset Annotation for Birdcall Classification</title>
		<author>
			<persName><forename type="first">A</forename><surname>Miyaguchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gustineli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Hayduk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CLEF: Conference and Labs of the Evaluation Forum</title>
		<meeting><address><addrLine>Thessaloniki, Greece</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2023-09">Sep. 2023. 2023</date>
		</imprint>
	</monogr>
	<note>CLEF Working Notes 2023</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Bird Species Recognition using Convolutional Neural Networks with Attention on Frequency Bands</title>
		<author>
			<persName><forename type="first">M</forename><surname>Lasseck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CLEF: Conference and Labs of the Evaluation Forum</title>
		<meeting><address><addrLine>Thessaloniki, Greece</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2023-09">Sep. 2023. 2023</date>
		</imprint>
	</monogr>
	<note>CLEF Working Notes 2023</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Acoustic Bird Species Recognition at BirdCLEF 2023: Training Strategies for Convolutional Neural Network and Inference Acceleration using OpenVINO</title>
		<author>
			<persName><forename type="first">L</forename><surname>Hong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CLEF: Conference and Labs of the Evaluation Forum</title>
		<meeting><address><addrLine>Thessaloniki, Greece</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2023-09">Sep. 2023. 2023</date>
		</imprint>
	</monogr>
	<note>CLEF Working Notes 2023</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Reading the Robot Mind -Presenting Internal Data Flow of Deep Learning Neural Networks in a Format Familiar to Subject Matter Experts</title>
		<author>
			<persName><forename type="first">P</forename><surname>Nussbaum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CLEF: Conference and Labs of the Evaluation Forum</title>
		<meeting><address><addrLine>Thessaloniki, Greece</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2023-09">Sep. 2023. 2023</date>
		</imprint>
	</monogr>
	<note>CLEF Working Notes 2023</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Classic Approaches to Bird Song Classification</title>
		<author>
			<persName><forename type="first">M</forename><surname>Minut</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Simionescu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Iftene</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CLEF: Conference and Labs of the Evaluation Forum</title>
		<meeting><address><addrLine>Thessaloniki, Greece</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2023-09">Sep. 2023. 2023</date>
		</imprint>
	</monogr>
	<note>CLEF Working Notes 2023</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>