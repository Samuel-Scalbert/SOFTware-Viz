<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Distributed Intelligence on the Edge-to-Cloud Continuum: A Systematic Literature Review</title>
				<funder>
					<orgName type="full">HPC-BigData Inria Challenge (IPL)</orgName>
				</funder>
				<funder>
					<orgName type="full">Inria</orgName>
				</funder>
				<funder ref="#_Z8zdjNU">
					<orgName type="full">Agence Nationale de la Recherche</orgName>
					<orgName type="abbreviated">ANR</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Daniel</forename><surname>Rosendo</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">University of Rennes</orgName>
								<orgName type="institution" key="instit2">Inria</orgName>
								<orgName type="institution" key="instit3">CNRS</orgName>
								<orgName type="institution" key="instit4">IRISA</orgName>
								<address>
									<settlement>Rennes</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Alexandru</forename><surname>Costan</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">University of Rennes</orgName>
								<orgName type="institution" key="instit2">Inria</orgName>
								<orgName type="institution" key="instit3">CNRS</orgName>
								<orgName type="institution" key="instit4">IRISA</orgName>
								<address>
									<settlement>Rennes</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Patrick</forename><surname>Valduriez</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution" key="instit1">University of Montpellier</orgName>
								<orgName type="institution" key="instit2">Inria</orgName>
								<orgName type="institution" key="instit3">CNRS</orgName>
								<orgName type="institution" key="instit4">LIRMM</orgName>
								<address>
									<settlement>Montpellier</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Gabriel</forename><surname>Antoniu</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">University of Rennes</orgName>
								<orgName type="institution" key="instit2">Inria</orgName>
								<orgName type="institution" key="instit3">CNRS</orgName>
								<orgName type="institution" key="instit4">IRISA</orgName>
								<address>
									<settlement>Rennes</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Distributed Intelligence on the Edge-to-Cloud Continuum: A Systematic Literature Review</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">40BABA8D7A2134B8C4574C7D7B0AE632</idno>
					<idno type="DOI">10.1016/j.jpdc.2022.04.004</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-04-12T14:47+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>Edge computing Distributed Intelligence Big Data Analytics Computing Continuum Reproducibility</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The explosion of data volumes generated by an increasing number of applications is strongly impacting the evolution of distributed digital infrastructures for data analytics and machine learning (ML). While data analytics used to be mainly performed on cloud infrastructures, the rapid development of IoT infrastructures and the requirements for low-latency, secure processing has motivated the development of edge analytics. Today, to balance various trade-offs, ML-based analytics tends to increasingly leverage an interconnected ecosystem that allows complex applications to be executed on hybrid infrastructures where IoT Edge devices are interconnected to Cloud/HPC systems in what is called the Computing Continuum, the Digital Continuum, or the Transcontinuum.</p><p>Enabling learning-based analytics on such complex infrastructures is challenging. The large scale and optimized deployment of learning-based workflows across the Edge-to-Cloud Continuum requires extensive and reproducible experimental analysis of the application execution on representative testbeds. This is necessary to help understand the performance trade-offs that result from combining a variety of learning paradigms and supportive frameworks. A thorough experimental analysis requires the assessment of the impact of multiple factors, such as: model accuracy, training time, network overhead, energy consumption, processing latency, among others.</p><p>This review aims at providing a comprehensive vision of the main state-of-the-art libraries and frameworks for machine learning and data analytics available today. It describes the main learning paradigms enabling learning-based analytics on the Edge-to-Cloud Continuum. The main simulation, emulation, deployment systems, and testbeds for experimental research on the Edge-to-Cloud Continuum available today are also surveyed. Furthermore, we analyze how the selected systems provide support for experiment reproducibility. We conclude our review with a detailed discussion of relevant open research challenges and of future directions in this domain such as: holistic understanding of performance; performance optimization of applications;efficient deployment of Artificial Intelligence (AI) workflows on highly heterogeneous infrastructures; and reproducible analysis of experiments on the Computing Continuum.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>The current digital revolution is impacting human beings in the way they live, work, learn, and communicate. This has resulted in impressive progress in many areas such as Cloud Computing, High-Performance Computing (HPC), Artificial Intelligence (AI), Big Data Analytics, and the Internet of Things. Furthermore, new challenging application scenarios are emerging from a variety of domains such as autonomous vehicles, real-time manufacturing, precision agriculture, smart cities, to cite just a few <ref type="bibr" target="#b151">[152,</ref><ref type="bibr" target="#b92">93]</ref>.</p><p>The explosion of data generated by many applications in the aforementioned areas and the need for real-time analytics and fast decision making has resulted in a shift of the data processing paradigms, as well as of Machine Learning (ML) paradigms, from centralized approaches towards decentralized and multi-tier computing infrastructures and services <ref type="bibr" target="#b88">[89]</ref>. Data processing and AI workflows can no longer rely on traditional approaches that send all data to centralized and distant Cloud datacenters for processing or AI model training and inference. Instead, they need to leverage myriads of resources close to the data generation sites ingestion systems, among others) and reconciling many requirements or constraints in terms of interoperability, mobility, communication latency, network efficiency, data privacy, and hardware resource consumption (e.g., GPU memory, CPU power, storage size, and others) <ref type="bibr" target="#b155">[156]</ref>.</p><p>Furthermore, enabling intelligence on the Edge-to-Cloud Continuum to allow fast and accurate decision making requires the efficient deployment of complex AI workflows on massively distributed infrastructures composed by heterogeneous resources. Therefore, enabling intelligence on the Computing Continuum requires the reproducible and extensive evaluations of AI workflow deployments exploring the combination of a variety of ML paradigms and frameworks and analyzing their performance trade-offs and impact on performance metrics such as model accuracy, training time, network overhead, energy consumption and application processing latency.</p><p>This systematic literature review provides a comprehensive vision of the main state-of-the-art libraries and frameworks for ML and Data Analytics. It also describes the main learning paradigms for enabling intelligence on the Computing Continuum. The main contributions of this paper are:</p><p>1. A taxonomy of Data Analytics and AI libraries and frameworks, and ML paradigms that may compose Edge-to-Cloud workflows to enable intelligence on the Computing Continuum.</p><p>2. A synthetic presentation of the main systems for simulation, emulation, and deployment, as well as the relevant large scale testbeds for experimental evaluation of complex Edge-to-Cloud workflows.</p><p>3. An analysis of how the studies included in our systematic review provide support for experiment reproducibility, an important requirement of the research community that allows scientific claims to be verified by others. We evaluated each article in terms of: (a) access to artifacts; (b) definition of the experimental setup; and (c) access to results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">A discussion of the relevant open research challenges</head><p>and future directions to enable intelligence on the Edgeto-Cloud Continuum, such as: holistic understanding of performance of applications; performance optimization of Edge-to-Cloud workflows; efficient deployment of complex AI workflows on highly heterogeneous infrastructures; and support of the reproducible analysis of Edge-to-Cloud experiments.</p><p>The remainder of this paper is organized as follows. First, we compare our work with the existing surveys/reviews and motivate the need for our review in Section 2. In Section 3, we describe the methodology exploited to guide our systematic review. Then, we provide answers to the research questions raised by our methodology in Sections 4 to 9. In Section 4, we present the main frameworks and libraries for ML in the Edge and in the Cloud. In Section 5 we present the main frameworks and libraries for Data Analytics. Next, Section 6 discusses recent efforts on combining ML and Data Analytics across the Edge-to-Cloud Continuum, as well as the main learning paradigms used. Section 7 presents the main systems for simulation, emulation and deployment for experimental research and the relevant large-scale testbeds. Furthermore, it presents how the selected studies provide support for the experiment reproducibility. Finally, Section 8 highlights the major findings and Section 9 discusses the research challenges in this area. Section 10 concludes this review.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work and Motivation</head><p>Previous surveys and systematic reviews in the context of the Computing Continuum focused on a variety of domains, such as: resource management <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b93">94]</ref>, security and privacy <ref type="bibr">[104,</ref><ref type="bibr" target="#b7">8]</ref>, architectures <ref type="bibr" target="#b39">[40,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b63">64]</ref>, robotics <ref type="bibr" target="#b148">[149]</ref>, blockchain <ref type="bibr" target="#b137">[138,</ref><ref type="bibr" target="#b57">58]</ref>, just to cite a few. The scope of our work is larger: while focusing on distributed intelligence on the continuum, we review articles in the fields of Machine processing running on Edge devices is presented in <ref type="bibr" target="#b29">[30]</ref>. Authors discuss edge-only, hybrid edge-cloud and distributed computing approaches to accelerate deep learning training and inference. They summarize the selected articles in terms of architecture, DNN model, application, key metrics, and Edge hardware used. Lastly, they discuss the challenges in deploying deep learning on Edge-to-Cloud environments, such as: management and scheduling of Edge resources, energy consumption, application migration, benchmarks, and privacy. In this research direction, authors <ref type="bibr" target="#b149">[150]</ref> describe the methods and architectures to execute deep learning inference and training at the edge. They also discuss open issues regarding the deployment of deep learning at the edge.</p><p>An overview of existing Edge Computing systems is presented in <ref type="bibr" target="#b82">[83]</ref>. It discusses techniques to support Deep Learning models at the Edge, for example: <ref type="bibr" target="#b0">(1)</ref> systems and toolkits: OpenEI, a framework for Edge Intelligence; AWS IoT Greengrass, for ML Inference; Azure IoT Edge; and Cloud IoT Edge; and <ref type="bibr" target="#b1">(2)</ref> open source Deep Learning packages: Tensor-Flow, Caffe2, PyTorch, MXNet, and some distributed Deep Learning models over Cloud and Edge such as DDNN and Neurosurgeon.</p><p>The confluence of IoT and AI detailing their potential applications and open issues is discussed in <ref type="bibr" target="#b95">[96]</ref>. It presents the recent approaches for deploying DL on resource constrained Edge devices, Fog and Cloud. They also discuss the two main categories of IoT data generation, such as IoT streaming data and IoT Big Data, as well as their requirements for analytics. Lastly, authors highlight the challenges for the successful merging of DL and IoT applications, such as the lack of real-world datasets for IoT applications; the preprocessing of raw data for DL model training; ensuring data security and privacy in IoT applications; and online resource provisioning for IoT analytics; just to cite a few.</p><p>Data Analytics across the Edge-to-Cloud Continuum. In <ref type="bibr" target="#b13">[14]</ref> the authors provide a review focusing on the efforts of using Big Data Analytics solutions in the Edge-to-Cloud Continuum. They present the relevant Data Analytics platforms (e.g., Hadoop, Flink, Spark, Storm, Nifi, and others) and Machine Learning libraries (e.g., Spark MLlib, Tensorflow, Keras, Scikit-learn, etc.) to enable a real-time Big Data pipeline from the Edge to the Cloud. Lastly, authors discuss the following open challenges: interoperability, characterizing smart city applications, and privacy issues.</p><p>A survey on IoT Big Data Analytics covering Big Data generation, acquisition, storage, learning, and analytics is presented in <ref type="bibr" target="#b130">[131]</ref>. It discusses parallel processing models and engines for the analysis of Big Data such as Spark, Flink, and Storm. Regarding IoT Big Data learning, they present Machine Learning frameworks working on Big Data and processing in parallel such as Spark MLlib, SAMOA, and FlinkML. Lastly, authors highlight open issues related to Machine Learning and Big Data Analytics in IoT.</p><p>A review on Edge, Fog, and Cloud computing infrastructures used for IoT Big Data Analytics is presented in <ref type="bibr" target="#b12">[13]</ref>. Authors review the combination of DL and Big Data Analytics in the development of smart cities and provide a com-parison of deep learning frameworks and libraries; models; and datasets used in smart city applications. Furthermore, they review articles exploiting IoT and DL to develop intelligent applications and services for smart cities and outline the challenges in developing such applications.</p><p>In summary, all these related works focus on specific domains such as: Machine Learning on the Edge-to-Cloud continuum <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b124">125,</ref><ref type="bibr" target="#b97">98]</ref>; Deep Learning mainly focusing on the Edge, but also discussing hybrid Edge-Cloud deployments <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b149">150,</ref><ref type="bibr" target="#b82">83,</ref><ref type="bibr" target="#b95">96]</ref>; and Data Analytics on Edge-to-Cloud environments <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b130">131,</ref><ref type="bibr" target="#b12">13]</ref>.</p><p>Motivation: study the challenges of ML and DA convergence across the Continuum. As opposed to these previous studies, we are interested in the specific issues (and the frameworks that address them) arising at the frontier of DL and ML, as this combination is rapidly gaining traction as a standard for analytics on the continuum. To the best of our knowledge, our literature review is the first to systematically explore the recent efforts and to summarize the existing approaches on applying Machine Learning, Data Analytics, and their combination to enable distributed intelligence on the Edge, Cloud, and Edge-to-Cloud continuum. Furthermore, our review is unique especially from two main perspectives: <ref type="bibr" target="#b0">(1)</ref> it discusses relevant open challenges and research opportunities identified after reviewing the articles; and (2) it provides an extensive analysis of the articles in terms of experimental evaluations and validation, allowing to identify: (i) the relevant large-scale testbeds; (ii) simulation, emulation, and deployment systems; (iii) the common ML/DA frameworks and libraries; metrics; the common models/algorithms, datasets, and Edge hardware; (iv) the scale of the testbeds used to validate the proposed solutions; and (v) their support for reproducibility.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Review Methodology</head><p>The systematic review methodology leveraged in this work is based on <ref type="bibr" target="#b70">[71,</ref><ref type="bibr" target="#b47">48]</ref>. The Figure <ref type="figure" target="#fig_0">1</ref> illustrates the three main processes of the review, which are: 1) Planning the Review; 2) Conducting the Review; and 3) Reporting the Review. Next, we describe their corresponding activities in detail.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Planning the Review</head><p>In more and more application areas, we are witnessing the emergence of complex workflows that combine computing, analytics and learning. Such application workflows are evolving towards an interconnected ecosystem that often require a hybrid execution infrastructure from IoT devices to Cloud/HPC systems (aka Computing Continuum). A holistic understanding of the complex continuum ecosystem is challenging.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.1.">Identify the Need for the Review</head><p>This systematic review aims to provide a taxonomy of libraries, frameworks, and learning paradigms that compose Edge-to-Cloud workflows to enable intelligent analytics. Furthermore, we highlight systems and testbeds that allow the analysis of such Edge-to-Cloud workflows, as well as the recent efforts to enable the computing continuum vision and the relevant research opportunities.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.2.">Define the Research Questions</head><p>The objective of the systematic review is to answer the following research questions with a focus on the Edge-to-Cloud Continuum: </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.3.">Define the Search String</head><p>The keywords used in the search queries are: IoT, edge, fog, big data, stream processing, learning and intelligence. Therefore, the search string applied in the scientific databases is: "IoT" AND ("edge" OR "fog") AND "big data" AND "stream processing" AND ("learning" OR "intelligence").</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.4.">Define the Sources of Research</head><p>The selected scientific databases are: ScienceDirect, ACM, IEEE Xplore, Springer Link, and Usenix (FAST, NSDI, ATC, HotEdge, and HotCloud).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.5.">Define Inclusion and Exclusion Criteria</head><p>The search scope of this study is limited to journal and conference articles, magazines and book chapters published between January 2016 and August 2021.</p><p>The main characteristics that the articles must present to be included in this systematic review are: <ref type="bibr" target="#b0">(1)</ref> help to answer to at least one of the four research questions defined in Subsection 3.1.2; and (2) evaluate existing or propose novel systems, frameworks or architectures enabling intelligence on the Edge, Cloud, or Edge-to-Cloud environments. Articles not respecting these requirements are eliminated.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.6.">Define the Data Extraction Procedure</head><p>The process of extracting information from the articles consists in filling a form that is designed to answer the research questions of the systematic review. Therefore, the form is structured as follows: title, publication year, scientific database, venue, resume of the contributions, framework/libraries for learning or analytics cited, experimental approach, and open challenges or future works.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Conducting the Review</head><p>The search string applied on the scientific databases returned a total of 1159 articles: 242 from ScienceDirect; 206 from ACM; 325 from IEEE Xplore; 290 from Springer Link; and 96 from Usenix.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1.">Identify the Primary Studies</head><p>As a refinement step, we started the screening process, which consists in reading the abstract and conclusions for each article. This refinement step eliminates out of scope articles. Finally, we selected a total of 69 papers for quality evaluation and extraction of relevant information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2.">Evaluate the Quality of the Studies</head><p>The quality evaluation of the selected articles is based on checking if they are related to techniques or approaches that enable intelligent analytics on the Edge-to-Cloud continuum.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.3.">Extract the Relevant Information</head><p>For each one of the 69 articles selected in 3.2.1 we read the whole paper to extract the relevant information and then fill the form defined in 3.1.6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Reporting the Review</head><p>Lastly, two types of reports are issued: general statistics about the studies and answers to the questions raised by our methodology.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.1.">Present an Overview of the Studies</head><p>Since the form is filled, we generate relevant statistics derived from a global analysis of the articles. Such statistics are aligned to the research questions defined in 3.1.2 and they are presented in the next sections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.2.">Present the Answers to the Research Questions</head><p>Finally, according to the relevant information extracted from all articles, we structured the remaining sections of our   review based on the research questions. From the information registered in the form, we grouped, defined taxonomies, and summarized all articles in order to answer the research questions.</p><p>Figure <ref type="figure" target="#fig_3">2</ref> presents the percentage of selected papers per scientific database and per year of publication, respectively. We highlight that after the screening process, no article published in 2016 was selected. Table <ref type="table" target="#tab_0">1</ref> summarizes the selected articles by area and computing paradigm exploited.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Machine Learning Methods on the Edge-to-Cloud Continuum</head><p>Figure <ref type="figure" target="#fig_4">3</ref> presents the taxonomy of learning methods with a focus on the Edge and across the Edge-to-Cloud Continuum. The distributed training can be achieved across the Continuum or among Edge devices, while the inference is typically done at the Edge, for latency purposes. The Machine Learning frameworks/libraries identified in the articles are presented in Tables 11 (designed for the Cloud) and 12 (designed for the Edge), respectively. Table <ref type="table" target="#tab_1">2</ref> characterizes the selected articles with respect to the resources exploited in the experimental evaluations, such as: frameworks and libraries; application/task; metrics; hardware; models; and datasets. Table <ref type="table" target="#tab_2">3</ref> presents a quantitative analysis summarizing Table <ref type="table" target="#tab_1">2</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Inference on the Edge</head><p>Next, we present the recent efforts to enable inference on resource-limited Edge devices. The following papers focus on hardware and software aspects, as well as, frameworks and algorithms for the efficient inference on Edge devices.</p><p>In <ref type="bibr" target="#b41">[42]</ref> the authors discuss the potential research directions to enable Edge Intelligence. First, they discuss how AI technologies may help to solve complex problems in Edge Computing, such as: service placement; resource provisioning; network planning; mobility management; among others. Furthermore, they explore issues on performing AI on resource-scarce Edge devices and the recent research efforts to solve problems in this direction, such as: frameworks for model training and inference; accelerating DNN computation on hardware; model compression; asynchronous model aggregation, among others.</p><p>In <ref type="bibr" target="#b49">[50]</ref> the authors investigate the benefits of using embedded Machine Learning in wearable sensors to increase battery lifetime. Their approach focus on optimizing data generation and transferring and uses Support Vector Machines for classification. Evaluations show that their approach significantly reduces the amount of data transferred and therefore extends the battery lifetime of resource-constrained sensors.</p><p>A tree-based algorithm for efficient prediction on IoT devices is proposed in <ref type="bibr" target="#b75">[76]</ref>. Named Bonsai, the algorithm was designed to be fast, accurate, compact and energy-efficient at prediction time. Evaluations show that Bonsai outperforms state-of-the-art algorithms such as kNN, SVM, and single hidden layer NN algorithms in terms of accuracy, model size, inference time, and energy consumption.</p><p>A novel framework for collaborative DNN inference on Edge devices is proposed in <ref type="bibr" target="#b79">[80]</ref>. Named Edgent, the framework exploits DNN computation partitioning and DNN rightsizing to enable low-latency inference. Authors evaluate Edgent under static and dynamic bandwidth environments and considered performance metrics for model inference such as: accuracy, latency requirements, and throughput. Through experiments on Raspberry Pi (acting as a mobile device), they demonstrate the effectiveness of Edgent towards low-latency Edge intelligence.</p><p>In <ref type="bibr" target="#b42">[43]</ref> the authors discuss strategies for accelerating DNN inference by partitioning the model between Edge devices. Next, they evaluate the implementation of an offloading system for Deep Learning inference in a Raspberry Pi 3 with the Intel Movidius hardware accelerator. Experimental results considering metrics such as processing latency, data transfer latency, and network bandwidth demonstrate that intelligent offloading may improve the performance when running in resource constrained Edge devices.</p><p>In <ref type="bibr" target="#b168">[169]</ref> the authors propose three parallelism schemes (All-In-One, Pipeline, and Parallel) to deploy Deep Neural Networks (DNNs) on resource-constrained devices for inference. Each parallelism approach explores the finer granularity of containerizing a DNN model at the edge. Experimental evaluations show that parallelizing a VGG-16 model for inference starts to improve performance as network speed increases.</p><p>Since Edge devices are heterogeneous in terms of hardware characteristics and there is a variety of state-of-the-art Machine Learning packages that can be used for inference at the Edge, in <ref type="bibr" target="#b166">[167]</ref> authors investigate how such learning packages perform on different Edge devices. They compare TensorFlow, Caffe2, MXNet, PyTorch, and TensorFlow-Lite running two trained CNN-based models (AlexNet as the largescale model and SqueezeNet and MobileNet as the smallscale models) on Edge devices such as MacBook, FogNode, Jetson TX2, Raspberry Pi, and Nexus 6P. The performance comparison includes metrics such as latency, memory footprint, and energy.</p><p>In <ref type="bibr" target="#b61">[62]</ref> the authors propose a framework to automatically port a Cloud-based model to a suite of models for Edge devices. Named Mistify, the framework decouples the model design (optimized for accuracy) and the deployment (optimized for resource efficiency) phases. Experimental results show that Mistify reduces the DNN porting time needed to cater to a wide spectrum of Edge deployment scenarios by more than 10 times.</p><p>In summary, the articles demonstrated that techniques to minimize the data transfer, reduce the model size, partitioning and offloading the model, and parallelizing the inference among Edge devices, are effective to improve the performance when running in resource constrained Edge devices. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Distributed Training on the Edge</head><p>Next, we present the recent efforts to enable distributed Machine Learning and Deep Learning training on Edge devices. The following papers focus on lightweight Deep Learning models, learning paradigms, collaborative learning systems, and the frameworks and libraries for optimizing Deep Learning on mobile devices.</p><p>In <ref type="bibr" target="#b76">[77]</ref> the authors propose a system for enabling iterative collaborative processing (ICP) in resource constrained Edge environments with a focus on Machine Learning applications (e.g., model training). The proposed system consists in a central controller that coordinates all the Edge devices (workers). The controller communicates the initial values of the model parameters to all the Edge devices and updates the model parameters at the end of every iteration using the individual model parameters from all the Edge devices. Lastly, it sends the updated parameters to the workers for next iteration. This process repeats until the model parameters have converged.</p><p>CLONE <ref type="bibr" target="#b85">[86]</ref> is a collaborative learning setting on the Edge built on top of the Federated Learning algorithm and long short-term memory networks. In CLONE, the learning tasks are solved by a group of distributed Edge nodes. Each Edge node trains the neural network model locally based on its private data and uploads asynchronously the parameters to a Parameter EdgeServer. The EdgeServer aggregates those parameters and sends them back to Edge devices. Experimental results show that, compared to a stand-alone model training, CLONE reduces training time significantly without sacrificing prediction accuracy.</p><p>A Lightweight Convolutional Neural Network (L-CNN) is proposed in <ref type="bibr" target="#b101">[102]</ref> to enable real-time human identification on a network Edge using fewer resources and preserving the high accuracy of CNNs. In order to enhance performance on Edge, authors propose a hybrid lightweight tracking algorithm named Kerman (Kernelized Kalman filter). Kerman works along with L-CNN to further improve the speed and reliability of feature extraction for human abnormal behavior detection. Experimental results demonstrate that the proposed algorithms can track the humans as objects in real-time with decent accuracy at a resource consumption affordable by Edge devices.</p><p>Besides these novel approaches and systems to enable distributed training on the Edge, some recent efforts focus on understanding the performance of learning on the Edge.</p><p>A survey on Deep Learning applied on mobile networking is presented in <ref type="bibr" target="#b164">[165]</ref>. Mobile Data Analytics on Edge devices is achieved either through distributed Machine Learning systems such as MLbase, Gaia, TUX <ref type="bibr" target="#b157">[158]</ref>, and Adam; or, through Deep Learning libraries such as TensorFlow, Theano, PyTorch, and MXNET. Since mobile networks are ever changing, applications should learn and adapt fast to the domain changes. Therefore, authors discuss learning paradigms such as Online Learning, Lifelong Learning, and Transfer Learning. Lastly, a discussion on open source platforms (e.g., TensorFlow, Caffe, and NCNN) that seek to optimize Deep Learning on mobile devices is presented.</p><p>An empirical study of on-device Deep Learning for smartphones such as Android devices is presented in <ref type="bibr" target="#b161">[162]</ref>. The study includes 21 frameworks based on their popularity (forks and stars on GitHub) in which authors investigate how those frameworks are used in DL applications. Another study <ref type="bibr" target="#b74">[75]</ref> explores scenarios where it is advantageous to do training on the Edge. Experimental results show that peak memory footprint, which is crucial for training on Edge devices, can be reduced by checkpointing strategies such as full binomial checkpointing.</p><p>As a conclusion, the articles demonstrated that lightweight Deep Learning models may help to reduce the resource usage while preserving the model accuracy. Furthermore, collaborative model training strategies on resource-scarce Edge devices have been shown to be effective to reduce the training time without sacrificing accuracy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Distributed training across the Edge-to-Cloud Continuum</head><p>The articles presented in this section focus on deploying and distributing the processing of Machine Learning and Deep Learning workloads among Edge and Cloud environments. They propose novel systems and architectures and analyze the performance trade-offs of Cloud only vs. Edgeto-Cloud collaborative training.</p><p>An overview of challenges and of existing approaches to distributed Machine Learning for IoT applications in the Fog is presented in <ref type="bibr" target="#b118">[119]</ref>. The authors start by presenting the main challenges in processing IoT data, such as generation, transmission, and processing. Then, they highlight the challenges related to the execution of Machine Learning techniques in resource constrained Fog devices. Lastly, the authors present existing approaches to distribute intelligence on Fog devices with a focus on distributed processing and information sharing.</p><p>[85] provides a review of 5G on traditional and emerging technologies and share their ideas on future research challenges and opportunities. In particular, they exploit how 5G can help the development of Federated Learning. They present the domains impacted by 5G such as Edge comput-ing, security and privacy, artificial intelligence, and database systems.</p><p>A decentralized distributed Deep Learning system named DLion is proposed in <ref type="bibr" target="#b66">[67]</ref>. DLion builds on top of Tensor-Flow and implements techniques such as compute capacityaware batching, adaptive model parameter tuning, and networkaware data exchange features in order to reduce training time, improving model accuracy, and providing system scalability for Deep Learning in micro-clouds. Experiments compare DLion with existing distributed Deep Learning systems such as Gaia and Ako, showing that DLion reaches the target accuracy faster than them. Besides, the compute capacity-aware batching technique implemented in DLion helps to reduce the training time.</p><p>The authors of <ref type="bibr" target="#b127">[128]</ref> propose a container-based IoT gateway architecture for Ambient Assisted Living (AAL) scenarios to support the deployment of Deep Learning models. Such models are implemented and trained in the Cloud to detect the fall of people and deployed remotely on the Edge gateways to provide predictive analytics. Results show an improvement of the inference time compared to the Cloud-based approach.</p><p>Still in the same direction of fall detection, authors of <ref type="bibr" target="#b96">[97]</ref> propose a system that detects falls on Edge devices (e.g., mobile phones) by using Boosted Decisions Trees. The proposed approach reduces the amount of data and network traffic sent to the Cloud and presents almost the same detection capabilities as the classification process performed in the Cloud.</p><p>Authors of <ref type="bibr" target="#b169">[170]</ref> propose SAFACE, a three-layer Edge computing system for face recognition. SAFACE employs Unsupervised Learning which can gradually fine-tune a portion of the face recognition model. The three-layer system consists of: Cloud, to train the CNN model; middle servers, for face recognition, fine-tune pre-trained CNN model, and context-aware scheduling; and Edge, for face detection. Experimental results demonstrate its advantages in improving recognition accuracy and reducing processing latency.</p><p>In <ref type="bibr" target="#b56">[57]</ref>, a novel Edge-Cloud Machine Learning system is proposed. The system combines Edge and Cloud Computing for IoT Data Analytics by taking advantage of Edge nodes to reduce the network traffic and latency for Machine Learning tasks. The results show that using sliding window techniques, the network traffic can be reduced by up to 80% without significant loss of accuracy.</p><p>A novel architecture named Edge Cloud Orchestrator (ECO) is proposed in <ref type="bibr" target="#b143">[144]</ref>. This architecture aims to orchestrate and manage Machine Learning deployments and execution across distributed layers in both Edge and Cloud. It supports deployment scenarios such as Federated Learning, Transfer Learning, and Staged Model Deployment. Furthermore, it supports Machine Learning engines and algorithms such as Spark MLlib (supports a variety of learning algorithms for classification, regression, clustering, among others), FlinkML (supports SVM, multiple linear regression, k-Nearest neighbors, among others), and TensorFlow (supports SVM, Gradient Boosting Machine, Random Forests, Naive Bayes, k-nearest neighbors, etc.).</p><p>In <ref type="bibr" target="#b30">[31]</ref> the authors explore the use of Synthetic Gradients (SG) for model-parallel training of a Deep Neural Network (DNN) model. This approach distributes the training of the various layers in the Cloud and resource-limited Edge devices. They compare the feasibility of the SG approach with the conventional back propagation method and evaluate its accuracy and convergence speed considering a four-layered, an eight-layered, and a VGG16 model. Results show that the four-layered model presents comparable performance for SG and back propagation, but an accuracy degradation is observed for the VGG16 model using SG. Regarding the convergence speed, using SG, the model learns slower than the back propagation method even while increasing the number of layers in the model.</p><p>The articles previously presented demonstrate the benefits of collaborative Edge-to-Cloud training. The main performance improvements of such Edge-to-Cloud approaches refer to: reducing the training time without significant loss of accuracy; reducing the amount of data sent to the Cloud and thus the network traffic; and reducing the end-to-end processing latency of Machine Learning and Deep Learning applications.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Main takeaways</head><p>This section aims to answer the following research question: What are the main state-of-the-art methods for Machine Learning on the Edge-to-Cloud Continuum? We organize the existing approaches and the selected studies in two main categories, they are: inference and distributed training on the Edge; and distributed training combining Edge and Cloud.</p><p>We highlight that there is not a single library or framework that fits all the needs given the heterogeneous and complex nature of the Edge-to-Cloud Computing Continuum. Therefore, the idea is to provide scientists and engineers a clear vision of the main solutions and existing artifacts and resources (e.g., frameworks/libraries; application/task; metrics; hardware; models; and datasets) so that they can easily identify which ones may be exploited to better attend to their project and research needs.</p><p>Next, we summarize the main limitations of performing Machine Learning over Edge devices: (i) computing power: Edge devices are typically limited in terms of accelerator memory (CPU, GPU, TPU) and storage, thus they can not handle large ML/DL models. This can be alleviated either by minimizing the model size (while maintaining accuracy) or by distributing the model across devices <ref type="bibr" target="#b42">[43,</ref><ref type="bibr" target="#b168">169,</ref><ref type="bibr" target="#b61">62,</ref><ref type="bibr" target="#b76">77,</ref><ref type="bibr" target="#b85">86,</ref><ref type="bibr" target="#b101">102,</ref><ref type="bibr" target="#b74">75,</ref><ref type="bibr" target="#b66">67,</ref><ref type="bibr" target="#b30">31]</ref>; (ii) network communication: Edge devices are typically interconnected through wireless low-bandwidth and unreliable network links. They may become offline at any time for any reason or the network may be congested. This requires fault-tolerant and communication-efficient approaches for distributed model training <ref type="bibr" target="#b79">[80,</ref><ref type="bibr" target="#b168">169,</ref><ref type="bibr" target="#b56">57,</ref><ref type="bibr" target="#b97">98]</ref>; and (iii) energy consumption: Edge devices are typically battery-powered, thus they can not handle energy-intensive ML/DL tasks. This should be addressed by energy-efficient inference and training techniques to extend the battery lifetime <ref type="bibr" target="#b49">[50,</ref><ref type="bibr" target="#b75">76]</ref>. The articles presented will serve as a basis to identify the recent efforts and also how such libraries and frameworks are being used for: collaborative learning on the Edge and Fog; deploying Neural Networks and performing distributed Machine Learning tasks on resource-constrained devices; how these libraries and frameworks perform on Edge devices; and performance trade-offs for training on the Edge vs. on the Cloud.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Data Analytics Methods on the Edge-to-Cloud Continuum</head><p>Figure <ref type="figure" target="#fig_5">4</ref> presents the taxonomy of analytics approaches with a focus on the Edge and Edge-to-Cloud Continuum. The Data Analytics frameworks identified in the articles are presented in Tables 13 (designed for the Cloud) and 14 (designed for the Edge), respectively. Table <ref type="table" target="#tab_3">4</ref> characterizes the selected articles with respect to resources exploited in the experimental evaluations, such as: frameworks; application/task; metrics; and hardware. Table <ref type="table" target="#tab_4">5</ref> presents quantitative analysis summarizing Table <ref type="table" target="#tab_3">4</ref>. In the next subsections, we present how these frameworks support analytics on the Edge-to-Cloud Continuum.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Data Processing on the Edge</head><p>Typically, IoT applications are latency-sensitive and they generate large amounts of data from sensors and Edge devices. Processing such data efficiently on the Edge of the network to obtain insights and react fast is critical. This section presents the recent efforts and novel systems proposed to distribute data processing among Edge devices to achieve high throughput and low latency.</p><p>In <ref type="bibr" target="#b146">[147]</ref> the authors focus on using Edge computing for real-time analysis of healthcare systems. They discuss challenges of Edge computing such as: performance, deployment expertise in order to consider various parameters like infrastructure configurations, connectivity, and energy requirements; and data management.</p><p>A systematic study of data stream processing and analytics in the Fog considering four dimensions, such as system, data, human, and optimization is presented in <ref type="bibr" target="#b162">[163]</ref>. For each dimension, the authors present technical issues and new design challenges. For example, high throughput and low latency in stream processing systems can be achieved by optimizing their configurations such as: the number of bolts in the Storm DAG topology or the micro-batch size of Spark streaming, among others.</p><p>In the same direction of achieving high throughput and low latency, a novel stream processing engine focused on the Edge named EdgeWise is proposed in <ref type="bibr" target="#b55">[56]</ref>. The idea behind EdgeWise is the use of a congestion-aware scheduler and a fixed-size worker pool to improve throughput and latency. The authors compare EdgeWise with Storm deployed on a cluster of up to 8 Raspberry Pi nodes and they observe that EdgeWise reports up to 3 times improvement in throughput while keeping latency low. <ref type="bibr" target="#b36">[37]</ref> proposes an approach to enable distributed data processing within a cluster of Edge devices. The proposed approach extends Apache NiFi core functionality to include three custom processors such as CaptureVideo, DetectFaces, and RecogniseFaces. Experiments show that the proposed approach has the potential to outperform the Cloud-enabled setup.</p><p>A novel distributed architecture that extends Apache NiFi to enable stream data processing at the Edge of the IoT network is presented in <ref type="bibr" target="#b35">[36]</ref>. Edge Cluster Stream Processing (ECStream) allows time-constrained data-intensive applications to be entirely deployed and executed at the Edge and it is based on a task parallelism model where atomic tasks are offloaded to peer Edge devices, rather than the full workflow.</p><p>An Edge Intelligence framework for building serviceoriented IoT is proposed in <ref type="bibr" target="#b67">[68]</ref>. The framework allows developers to build stream processing capabilities on Edge server devices and use local streaming analytics to make IoT applications smart. Through annotation based programming primitives developers can design their local intelligent capabilities. The authors compare the latency of activity recognition engine implementations running on an Edge server and on the Cloud. Experiments show that the proposed framework can improve performance without degrading the recognition accuracy.</p><p>A new Fog platform for data stream analytics in IoT is proposed in <ref type="bibr" target="#b2">[3]</ref>. It aims to exploit the computational capacity of Fog devices to process and analyze data without requiring a frequent use of Cloud resources. Experimental evaluations show that the proposed system can analyze data streams with low processing delay and low network utilization.</p><p>In <ref type="bibr" target="#b65">[66]</ref> the authors propose Fed4Edge, a system that enables the coordination of resources available in Edge devices to process query pipelines in a collaborative way. Fed4Edge uses RDF Stream Processing (RSP) engines as autonomous processing agents. Large scale evaluations on a cluster of Raspberry Pi show that the scalability can be significantly improved by adding more Edge devices to a network of processing nodes.</p><p>A model synchronization mechanism for distributed and stateful data analytics named SCEDA is proposed in <ref type="bibr" target="#b8">[9]</ref>. The authors use Reinforcement Learning to make dynamic scheduling decisions by learning individual network connectivity trends of Edge nodes as well as the significance of their updates. The proposed approach tackles the concept drift and connectivity issues in Edge data analytics to minimize its accuracy handicap without losing its timeliness benefits. Experimental results show that SCEDA can achieve a comparable level of accuracy as core data analytics.</p><p>In summary, the articles presented exploit the computational capacity of Edge devices to process and analyze data in a distributed way. The proposed approaches contribute to allow data-intensive and latency-sensitive applications to be entirely processed on Edge devices.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Big Data Processing across the Edge-to-Cloud</head><p>The articles presented in this section focus on novel architectures and frameworks exploiting collaborative Edge-to-Cloud data processing for enabling real-time data analytics.</p><p>The articles also aim to analyze the performance trade-offs of Cloud only vs. Edge-to-Cloud collaborative data analytics.</p><p>In <ref type="bibr" target="#b37">[38]</ref>, the authors propose a novel IoT distributed Stream Processing architecture that distributes the workload among a cluster of Edge devices. The proposed solution extends Apache NiFi with new services to discover and select devices able to perform offloaded tasks according to hardware and software requirements. The evaluation scenario consists of an intelligent surveillance system and the authors compare the performance of a cluster of Edge devices with a Cloud setup. Results show that an Edge cluster of 6 nodes performs up to 5-6 times faster than the Cloud deployments.</p><p>Later, the same authors proposed <ref type="bibr" target="#b38">[39]</ref> a distributed hierarchical data fusion architecture based on Complex Event Processing technology to handle streaming data. This approach produces timely and accurate results with minimum time delay, as soon as necessary information is generated and collected. The authors compare their solution (distributed hierarchical data fusion) with a traditional one (sending all low-level sensor readings to a central Cloud for analysis) and evaluations show that at lower levels (e.g., Edge and Fog) decisions can be taken 20x and 90x times faster.</p><p>In <ref type="bibr" target="#b131">[132]</ref>, the authors propose a novel framework of collaborative Edge-Cloud processing for enabling live data analytics in wireless IoT networks. They also present potential key enablers for the proposed framework and highlight some of the research directions for Big Data aware collaborative Edge-Cloud processing, such as adaptive learning/prediction algorithms.</p><p>In <ref type="bibr" target="#b122">[123]</ref>, the authors propose a novel framework that allows the deployment and optimization [121] of Big Data Analytics applications on the Edge-to-Cloud continuum. They illustrate and validate the framework with a smart surveillance application composed by data processing frameworks such as Edgent (on the Edge) and Apache Flink and Kafka (on the Cloud). Experimental evaluations exploit the performance trade-offs of Cloud-centric vs. hybrid Edge-Cloud processing approaches to understand how they impact metrics such as latency and throughput of the application.</p><p>[161] proposes a novel framework that uses fine-grained stream processing to provide high resource utilization while meeting latency targets. Named Cameo, the framework dy-namically calculates and propagates priorities of events based on user latency targets. Experiments show that Cameo reduces query latency in single and multi-tenant settings.</p><p>Several models, technologies and solutions for medical data processing and analysis are presented in <ref type="bibr" target="#b72">[73]</ref>. The authors illustrate examples of case studies and practical solutions composed of health sensor data processed with Kafka and Spark (an application predicting skin temperature based on heart rate and step count values) using medical datasets publicly available such as PhysioNet, UbiqLog and CrowdSignals.</p><p>In <ref type="bibr" target="#b147">[148]</ref>, the authors review the state of the art of the analytics network methodologies for real-time IoT analytics. They also present some real-time IoT analytics use cases and software platforms such as Flink, Spark, Storm, and Druid along with their network requirements. Lastly, they present research problems and future research directions focusing on the network methodologies for the real-time IoT analytics.</p><p>In summary, the articles demonstrate the benefits of collaborative Edge-to-Cloud data analytics. The main performance improvements highlighted by these studies regarding the comparison of Edge-to-Cloud vs. Cloud only approaches refer to minimizing the processing latency of applications.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.">Main takeaways</head><p>This section aims to answer the following research question: What are the main state-of-the-art methods for data analytics on the Edge-to-Cloud Continuum? We organize the existing frameworks and the selected studies in two main categories, they are: data processing on the Edge; and Edgeto-Cloud Big Data processing.</p><p>From the analysis of the selected articles, we observe that, compared to the Cloud, a few stream processing frameworks tailored for the Edge exist, such as Apache NiFi, Edgent, and EdgeWise. We highlight that the recent works focus on proposing novel approaches for collaborative Edge-Cloud processing in order to enable live data analytics, instead of focusing on novel processing frameworks designed for running just on the Edge.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Approaches to Combine Machine Learning and Data Analytics</head><p>The convergence of Big Data and AI has become a research trend that grows over the years given the benefits of combining and applying both technologies in many areas, such as self-driving vehicles <ref type="bibr" target="#b60">[61]</ref>, precision agriculture <ref type="bibr" target="#b18">[19]</ref>, smart manufacturing <ref type="bibr" target="#b77">[78]</ref>, among others. Combining Big Data and AI leverages advanced analytics capabilities and allows the efficient extraction of valuable insights from vast amounts of data <ref type="bibr" target="#b45">[46]</ref>.</p><p>Next, we present the recent efforts on combining Big Data and AI to enable hybrid Cloud and Edge analytics. Figure <ref type="figure" target="#fig_6">5</ref> presents the taxonomy of approaches combining Machine Learning and Data Analytics with a focus on the Edge-to-Cloud Continuum. The ML and Data Analytics frameworks/libraries identified in the articles are presented in Tables <ref type="table" target="#tab_12">11</ref> and<ref type="table" target="#tab_13">12</ref> and Tables <ref type="table" target="#tab_14">13</ref> and<ref type="table" target="#tab_15">14</ref>, respectively. Table 7 characterizes the selected articles regarding resources exploited in the experimental evaluations, such as: frameworks/libraries; application/task; metrics; and hardware; models; and datasets. Table <ref type="table" target="#tab_5">6</ref> presents the main state-of-theart learning paradigms for collaborative learning. Table <ref type="table" target="#tab_9">8</ref> presents a quantitative analysis summarizing Table <ref type="table" target="#tab_8">7</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.">Combining Data Analytics and Learning on the Cloud</head><p>The articles presented in this section explore the joint usage of Data Analytics and Machine Learning frameworks and algorithms for analytics on Cloud resources. They also discuss the relevance of learning paradigms (e.g., Deep Learning, Online Learning, and Transfer Learning, among others) for Big Data Analytics.</p><p>Distributed Cloud-based Machine Learning tools such as Mahout, Spark MLlib, and FlinkML are presented in <ref type="bibr" target="#b117">[118]</ref>. Authors also present research directions and opportunities in the domain of developing parallel and distributed Machine Learning algorithms. For instance, they highlight that in streaming systems, there is a lack of online Machine Learning algorithms that are used to process real-time data to provide faster insights.</p><p>The survey <ref type="bibr" target="#b100">[101]</ref> presents ML and DL frameworks and libraries oriented towards fast processing and streaming of large-scale data, such as: TensorFlow, PyTorch, MXNet, Theano, FlinkML, and Spark MLlib. Authors highlight that there is no single tool suitable for every problem and often a combination of them is needed to succeed.</p><p>Authors of <ref type="bibr" target="#b108">[109]</ref> present key characteristics and challenges of handling Big Data. Regarding current trends in Big Data Analytics they refer to IoT and Edge analytics (to provide responses quickly as the events occur) and domain adaptation (where training data and test data are sampled from different distributions).</p><p>In <ref type="bibr" target="#b3">[4]</ref> the authors survey existing solutions for Big Data stream processing in terms of learning type, supported languages, and supported Machine Learning tools. Authors discuss frameworks and platforms such as Apache Spark, MOA, Samza, Storm, and Kafka.</p><p>Another survey <ref type="bibr" target="#b144">[145]</ref> presents existing open source tools for Big Data (e.g., Hadoop, Spark, Storm, and Flink) and Machine Learning (e.g., Mahout, Spark MLLib, and SAMOA).  In <ref type="bibr" target="#b87">[88]</ref> the authors present the challenges associated with Machine Learning in the context of Big Data and categorize them according to the Velocity, Volume, Variety, and Veracity dimensions of Big Data. They also present existing Machine Learning approaches and techniques for data manipulation (e.g., dimensionality reduction and data cleaning); processing manipulation (such as vertical/horizontal scaling and batch/stream oriented); and algorithm manipulation (e.g., algorithm modification with new paradigms). Lastly, they present learning paradigms relevant to Big Data such as Deep Learning, Lifelong Learning, Online Learning, and Transfer Learning.</p><p>A parallel Machine Learning algorithm for fault classification of mobile robotic roller bearings is proposed in <ref type="bibr" target="#b156">[157]</ref>. The proposed algorithm combines Support Vector Machine with Spark to realize parallel operations. Experimental evaluations under different training set sizes demonstrate that the proposed algorithm (Spark SVM on Mesos) outperforms MapReduce SVM, Storm SVM, Radial Basis Function Neural Network (RBFNN), Deep Belief Network (DBN), presenting higher: classification accuracy, processing speed, and convergence rate.</p><p>In <ref type="bibr" target="#b11">[12]</ref> the authors explore Spark MLlib with a variety of Big Data Machine Learning experiments on massive datasets to understand the qualitative and quantitative attributes of the platform. Experimental evaluations compare the performance of classification and clustering models (such as SVM, Decision Tree, Naive Bayes, Random Forest, and K-Means) on a variety of hardware and software configurations. Results show that with large datasets Spark MLlib outperforms Weka in terms of running time.</p><p>In <ref type="bibr" target="#b98">[99]</ref> the authors propose a system for real-time health status prediction based on the Spark Big Data processing framework. The proposed system predicts user's health status by applying a variety of decision tree models on streams of data. Experiments evaluate the generalization error of Decision Tree models based on maxDepth (tree depth) and maxBins (ordered splits) parameter values.</p><p>In <ref type="bibr" target="#b4">[5]</ref> the authors propose an Edge-Cloudlet-MultiResource three-tier architecture to enable real-time processing of video streams. The proposed system performs Deep Learning inference on Cloudlets and distributes processing stages on the available resources using an algorithm to satisfy user Quality of Service requirements. Results show that for a 10K element data streams, with a frame rate of 15-100 per second, the job completion in the proposed system takes 49% less time and saves 99% bandwidth compared to a centralized Cloud-only based approach.</p><p>An overview on Spiking Neural Networks (SNN) for Online Learning scenarios is presented in <ref type="bibr" target="#b83">[84]</ref>. According to the authors, the use of SNN in Online Learning allows fast realtime simulations of large networks and a low computational cost. SNN make possible the accumulation of knowledge as data become available without the requirement of storing and retraining the model with past samples. The authors also highlight research trends in the field of SNN and Online Learning such as Lifelong Machine Learning and Deep SNN Learning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.">Combining Data Analytics and Learning on the Edge-to-Cloud Continuum</head><p>Next, we present the recent efforts on combining state-ofthe-art Big Data Analytics and Machine Learning approaches to enable intelligence on the Edge-to-Cloud Continuum. The following works focus on novel systems, frameworks and architectures.</p><p>A novel architectural design for enabling machine and deep learning over heterogeneous data streams on hybrid Cloud and Edge Computing infrastructures is proposed in <ref type="bibr" target="#b73">[74]</ref>. Named Stream to Cloud and Edge (S2CE), the platform aims to enable mining of Big Data streams over Cloud and Edge. It provides functionalities of scalable processing, such as distributed processing, data fusion and preprocessing, and Exploit distributed resources of a cluster to speed up the convergence of model training.</p><p>• aims at parallelizing computing power.</p><p>• Exploit the knowledge obtained from a task to improve generalization about another.</p><p>• useful when you have lack of training data sets.</p><p>• models may be reused as a starting point for predicting in another, but related, domain.</p><p>• compared to separated model training, it improves learning efficiency and prediction accuracy for the task-specific models.</p><p>[ Train a centralized model in a distributed way without the need to share private data.</p><p>• aims at training on heterogeneous datasets.</p><p>• data privacy: transmits and aggregates trained model parameters instead of training data.</p><p>• enables scalability: leverages the concurrent use of a high number of Edge devices to be independently trained and periodically synchronized through a central parameter server.</p><p>[88, 165, 84, 52] 5%</p><p>Lifelong Learning or Continual Learning <ref type="bibr" target="#b132">[133]</ref> Learning is continuous and knowledge is retained and used to solve different problems.</p><p>• does not rebuild the knowledge model every time a new piece of data arrives, but only updates the existing knowledge with the new incoming data.</p><p>• can accommodate bigger datasets than batch learning.</p><p>• may be a promising solution for lack of data, real-time processing, and concept drift. Cloud and Edge resource management.</p><p>In <ref type="bibr" target="#b150">[151]</ref> the authors propose 5G Intelligent Internet of Things (5G I-IoT). This approach is based on Big Data mining, Deep Learning, and Reinforcement Learning to process data intelligently and to optimize communication channels. The framework consists of three building blocks: (1) a processing center in the Cloud to handle real-time data for decision making using Deep Learning and Reinforcement Learning;</p><p>(2) an object processor in the Fog to processes the raw data from sensing regions; and (3) the sensing regions in the Edge. Evaluations show that 5G I-IoT outperforms 4G-IoT and 5G-IoT in terms of effectiveness of channel utilization.</p><p>Authors of <ref type="bibr" target="#b126">[127]</ref> propose a Data Flow and Distributed Deep Neural Network (DF-DDNN) that integrates data flow and distributed Deep Learning in the IoT-Edge environment to bring down the latency and increase accuracy. Experimental results show that the proposed solution enables a latency reduction of up to 33% when compared to the existing traditional IoT-Cloud model. In <ref type="bibr" target="#b59">[60]</ref>, a hybrid technique combining batch learning, Online Learning, and stream mining to predict delays of public transport vehicles is proposed. The hybrid approach is validated by experiments with real public transport delay data streams.</p><p>Recent studies have also proposed novel architectures for collaborative Edge-Cloud learning and data analytics. A review of existing reference architecture designs of Big Data systems such as FAR-Edge <ref type="bibr" target="#b50">[51]</ref> and Global Edge Computing Architecture <ref type="bibr" target="#b134">[135]</ref> is presented in <ref type="bibr" target="#b105">[106]</ref>. Authors propose a novel reference architecture design of a Big Data system with a focus on the utilization of ML in Edge Computing environments. In <ref type="bibr" target="#b71">[72]</ref> the authors present an overview of AI approaches for Autonomous Vehicle (AV) and propose a concept architecture for integrating Artificial Intelligence with Edge Computing. They also discuss key issues and challenges on: data fusion, such as the reconstruction and understanding of the environment of AV; and Big Data Analytics for training systems and real-time decision-making of AV volumes of data.</p><p>A novel architecture that combines a data distribution layer connecting Fog nodes with a Cloud focusing on resilience, near real-time communication, and a traffic modeling approach is proposed in <ref type="bibr" target="#b110">[111]</ref>. The modeling approach is an Online Machine Learning technique named Conditional Restricted Boltzmann Machines (CRBM) to learn and predict traffic telemetry. Experimental results show that the Cloudbased processing approach can produce severe impact in the accuracy of Cloud-learned models due to network connectivity outages between the Fog and the Cloud.</p><p>An Edge-Cloud collaborative computing platform for Artificial Intelligence of Things (AIoT) is proposed in <ref type="bibr" target="#b119">[120]</ref>. Named Sophon Edge, the platform helps to build and deploy AIoT applications efficiently. It addresses challenges related to building AIoT applications in practice, such as heterogeneity (e.g., communication protocols, data format, operating systems, among others) and accuracy of AI algorithms (e.g., model refinement and tuning).</p><p>Authors of <ref type="bibr" target="#b128">[129]</ref> propose a system to detect falls lever-aging an Edge-Fog-Cloud architecture to deploy DL models into resource-constrained devices for DL inference. The architecture exploits Big Data Analytics resources for training DL models on the Cloud and performing inference on devices. They also present a practical and experimental deployment of DL models on Fog devices and the lightweight virtualization technologies, such as Docker containers, to optimize the resource usage. Their solution leverages the RNN (LSTM/GRU) algorithms since they are appropriate for sequential data such as IoT monitoring and they fulfill the resource constraint requirements and provide very high accuracy.</p><p>In summary, the systems, frameworks and architectures proposed by the articles aim to mainly: enable Cloud and Edge resource management; optimize network communication; provide efficient application deployments; and allow distributed data processing. Some approaches also exploit hybrid techniques combining batch learning, Online Learning, Reinforcement Learning, Deep Learning, among others to improve application performance (e.g., minimize latency, increase accuracy, etc.).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3.">Main takeaways</head><p>This section aims to answer the following research question: How are the existing Machine Learning and Data Analytics approaches combined to enable intelligence on the Edge-to-Cloud Continuum? We organize the selected studies in two main categories, they are: Data Analytics and Machine Learning on the Cloud; and Data Analytics combined with Machine Learning on the Edge-to-Cloud Continuum.</p><p>We highlight that the recent efforts (e.g. systems, frameworks and architectures) focus on applying, combining, and deploying Machine Learning paradigms such as Federated Learning, Transfer Learning, Multi-task Learning, Reinforcement Learning and Online Learning on distributed Edge devices for collaborative Edge-to-Cloud analytics. Such efforts focus mainly on addressing open challenges, such as: enabling fast and accurate predictive analytics; optimize communication channels and minimize connectivity issues in Edge data analytics; minimize the processing latency of applications to satisfy Quality of Service requirements; just to cite a few.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Experimental Research and Reproducibility</head><p>In this Section we introduce the main state-of-the-art simulation, emulation, and deployment systems supporting experimental research on the Edge, Fog, Cloud, and Edgeto-Cloud Continuum <ref type="bibr" target="#b142">[143,</ref><ref type="bibr" target="#b163">164]</ref>. Besides, we discuss the relevant experimental testbeds enabling Edge-to-Cloud experiments. We then analyze the previously selected articles in terms of experimental evaluation aspects, such as the size of the experimental testbed and the support to the reproducibility of experiments. • modeling and simulation of large scale Cloud computing data centers.</p><p>• modeling and simulation of virtualized server hosts and application containers.</p><p>• modeling and simulation of energy-aware computational resources.</p><p>• modeling and simulation of data center network topologies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>SCORE [53] ✓</head><p>Simulate energy-efficiency, security, and scheduling strategies in Cloud Computing environments.</p><p>• allows to prototype and compare different cluster scheduling strategies and policies.</p><p>• generates synthetic cluster workloads from empirical parameter distributions.</p><p>• allows the analysis of scheduling performance metrics.</p><p>ElasticSim <ref type="bibr" target="#b25">[26]</ref> ✓ Simulate autoscaling algorithms.</p><p>• supports resource runtime auto-scaling.</p><p>• supports stochastic task execution time modeling.</p><p>iFogSim <ref type="bibr" target="#b62">[63]</ref> ✓</p><p>Modeling and simulation of resource management techniques in IoT, Edge and Fog Computing environments</p><p>• inherits a number of features from CloudSim.</p><p>• provides resource management techniques in IoT, Edge and Fog.</p><p>• allows the execution of multiple applications on the infrastructure at the same time.</p><p>• supports migration of application modules from one fog device to another.</p><p>FogNetSim <ref type="bibr" target="#b114">[115]</ref> ✓ Simulate distributed fog computing environments.</p><p>• covers the network aspects such as delay, packet error rate, transmission range, handover, scheduling, and heterogeneous mobile devices.</p><p>• allows to simulate a large fog network.</p><p>• allows to simulate heterogeneous devices with varying features.</p><p>• supports handover: allows static and dynamic nodes in the network.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>FogTorch [25] ✓</head><p>QoS-aware deployment of IoT applications through the Fog.</p><p>• allows the specification of a Fog infrastructure along processing (e.g., CPU cores, RAM memory, storage) and QoS (e.g., latency, bandwidth) capabilities.</p><p>• allows the specification of applications to be deployed along with needed IoT devices, processing and QoS requirements.</p><p>FogExplorer <ref type="bibr" target="#b64">[65]</ref> ✓ Simulate QoS and cost evaluation of fog-based IoT applications.</p><p>• simulates processing cost and processing time for individual application modules.</p><p>• simulates transmission cost and transmission time for individual data streams.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Simulation Systems Edge Fog Cloud Main Goal Key Features</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IoTSim-Edge [100] ✓</head><p>Simulate the distribution and processing of streaming data generated by IoT devices in Edge computing environments.</p><p>• allows to define data analytic operations and their mapping to different parts of the infrastructure.</p><p>• supports modeling of heterogeneous IoT protocols along with their energy consumption profile.</p><p>• supports modeling of mobile devices and captures the effect of handoff caused by the movement of mobile devices.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>EdgeCloud-Sim [137] ✓</head><p>Simulate environments specific to Edge Computing scenarios.</p><p>• considers computing and networking resources.</p><p>• supports network modeling specific to WLAN and WAN.</p><p>• supports device mobility model and provides realistic and tunable load generator.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>YAFS [79] ✓</head><p>Analyze the design and deployment of applications through customized and dynamical strategies.</p><p>• allows dynamic scenarios: placement, path routing, orchestration, and workload movement.</p><p>• supports placement allocation algorithms and orchestration algorithms.</p><p>• provides functions to obtain metrics such as network utilization, network delay, response time, and waiting time.</p><p>XFogSim <ref type="bibr" target="#b89">[90]</ref> ✓ Simulate federated fog computing environments.</p><p>• provides resource allocation algorithms for resource sharing.</p><p>• supports static and mobile nodes (handover mechanisms).</p><p>• supports application evaluation in terms of: energy consumption, processing latency, scalability, and resource usage.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Emulation Systems Edge Fog Cloud Main Goal Key Features</head><p>EmuFog <ref type="bibr" target="#b90">[91]</ref> ✓</p><p>Enable the design of Fog Computing infrastructures and the emulation of real applications and workloads.</p><p>• generates networks that can be emulated easily with MaxiNet <ref type="bibr" target="#b153">[154]</ref>.</p><p>• supports topologies from BRITE <ref type="bibr" target="#b91">[92]</ref> and Caida <ref type="bibr" target="#b26">[27]</ref>.</p><p>• places fog nodes based on user-defined constrains (e.g., network latency or resource constraints).</p><p>Fogbed <ref type="bibr" target="#b33">[34]</ref> ✓</p><p>Enable the rapid prototyping of Fog components in virtualized environments.</p><p>• allows dynamic topology changes.</p><p>• provides traffic control links such as delay, rate, loss, and jitter.</p><p>• enables the deployment of Fog nodes as software containers under different network configurations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>RADICAL-DREAMER [116]</head><p>✓ ✓ ✓ Emulate resource and task/workload definition in Edge-to-Cloud applications.</p><p>• allows to evaluate workload and resource management aspects of applications.</p><p>• supports modeling task placement in Edge-to-Cloud applications.</p><p>• allows to evaluate deployment modalities and performance trade-offs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Deployment Systems</head><note type="other">Edge Fog Cloud Main Goal Key Features E2Clab</note><formula xml:id="formula_0">[123] ✓ ✓ ✓</formula><p>Understand and optimize the performance of Edgeto-Cloud workflows through reproducible experiments on largescale infrastructures.</p><p>• supports reproducible experiments.</p><p>• provides a Services abstraction to support other applications.</p><p>• provides resource monitoring (e.g., CPU, GPU, memory, network) and network emulation to define Edge-to-Cloud constraints such as delay, loss and rate.</p><p>• maps application parts with the underlaying testbed.</p><p>• allows to optimize workflows through optimization libraries for hyperparameter search in Ray Tune <ref type="bibr" target="#b81">[82]</ref>.</p><p>KubeEdge <ref type="bibr" target="#b158">[159]</ref> ✓ Deploy complex high level applications to the Edge.</p><p>• provides containerized application orchestration and device management to hosts at the Edge.</p><p>• provides core infrastructure support for networking, application deployment and metadata synchronization between Cloud and Edge.</p><p>• supports MQTT which enables Edge devices to access through Edge nodes.</p><p>Kubernetes <ref type="bibr" target="#b23">[24]</ref> ✓ Manage and automate the deployment, scaling, and management of containerized applications across multiple hosts.</p><p>• provides mechanisms for deployment, maintenance, and scaling of applications.</p><p>• provides service discovery and load balancing.</p><p>• allows to automatically mount storage systems, such as local storage and public Cloud providers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1.">Simulation, Emulation, and Deployment Systems for Experimental Research</head><p>Table <ref type="table" target="#tab_10">9</ref> summarizes the main open-source state-of-the-art simulation, emulation, and deployment systems for experimental research on the Edge-to-Cloud Continuum.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1.1.">Simulation Systems</head><p>Building experimental testbed environments is expensive and brings challenges to conduct reproducible experiments. In this sense, simulation systems play an important role as they allow to analyze systems behavior at very large scale while easily tuning a myriad of configuration parameters. Next, we present simulation systems used in the modeling of Cloud, Fog, and Edge computing environments.</p><p>Cloud-based simulation systems. CloudSim <ref type="bibr" target="#b27">[28]</ref> framework allows modeling and simulation of Cloud computing infrastructures and services in a repeatable manner. CloudSim allows users to model the behavior data centers, Virtual Machines and resource provisioning policies. ElasticSim <ref type="bibr" target="#b25">[26]</ref> is a workflow simulator that extends CloudSim. It focuses on supporting resource runtime auto-scaling and stochastic task execution time modeling. SCORE <ref type="bibr" target="#b52">[53]</ref> allows the execution of heterogeneous workloads for simulating energy-efficient monolithic and parallel-scheduling models.</p><p>Fog-based simulation systems. FogExplorer <ref type="bibr" target="#b64">[65]</ref> provides modeling and simulation to estimate QoS and cost evaluation of Fog-based IoT applications. FogExplorer allows users to choose good application designs during its design phase. FogTorch <ref type="bibr" target="#b24">[25]</ref> aims to support the deployment of IoT applications in Fog infrastructures considering software, hardware and QoS requirements. FogNetSim++ <ref type="bibr" target="#b114">[115]</ref> focuses on simulating large Fog networks and differs from others mainly by providing features that allow users to incorporate customized mobility models, scheduling algorithms, and manage handover mechanisms. XFogSim <ref type="bibr" target="#b89">[90]</ref> extends FogNetSim++ to simulate federated fog computing environments. xFogSim is lightweight, configurable, scalable and introduces the concept of fog federation for resource sharing among fog locations. Furthermore, it allows users to evaluate applications in terms of energy consumption, processing latency, scalability, and resource usage. YAFS <ref type="bibr" target="#b78">[79]</ref> aims to allow users to analyze application designs and incorporate strategies for placement, scheduling and routing. YAFS also supports dynamic allocation of new application modules, dynamic failures of network nodes, and user mobility. Furthermore, it facilitates the shareability of experiment results by generating logs of workload generation and computation, and link transmissions. Lastly, iFogSim <ref type="bibr" target="#b62">[63]</ref> focuses on resource management techniques in IoT, Edge and Fog computing environments. iFogSim allows users to measure, in a repeatable manner, the impact of resource management techniques in terms of latency, network congestion, energy consumption, and cost.</p><p>Edge-based simulation systems. EdgeCloudSim <ref type="bibr" target="#b136">[137]</ref> focuses on Edge Computing scenarios and allows one to conduct experiments considering computational and networking resources. IoTSim-Edge <ref type="bibr" target="#b99">[100]</ref> allows users to easily configure their Edge infrastructures and to capture the behavior of heterogeneous IoT and Edge devices in terms of sensing, processing, mobility, and data rate. Both Edge systems extend CloudSim.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1.2.">Emulation Systems</head><p>Compared to simulation, the emulation approach provides more realistic results. While simulators mimic the behavior and configurations of a real device, emulation systems duplicate the hardware and software features of a real device <ref type="bibr" target="#b138">[139]</ref>. Emulation systems are also a less expensive solution when compared to real deployments.</p><p>Fogbed <ref type="bibr" target="#b33">[34]</ref> allows resource provisioning emulation in Fog environments. It combines Containernet <ref type="bibr" target="#b111">[112]</ref> and Maxinet <ref type="bibr" target="#b153">[154]</ref> (both are extensions of the Mininet <ref type="bibr" target="#b68">[69]</ref> network emulator) to allow the use of virtual instances for resource provisioning emulation.</p><p>EmuFog <ref type="bibr" target="#b90">[91]</ref> focuses on the design of Fog Computing infrastructures and the emulation of real applications and workloads. In EmuFog, users can: design the network topology; embed Fog nodes in the topology; and run Docker-based applications on those nodes connected by an emulated network.</p><p>RADICAL-DREAMER <ref type="bibr" target="#b115">[116]</ref> provides the concepts of Task and Workload to model the characteristics of an application according to heterogeneous tasks. Besides, it provides the concept of Resource to model distributed infrastructures. RADICAL-DREAMER allows users to evaluate deployment configurations, performance trade-offs, and workload placement strategies for Edge-to-Cloud applications <ref type="bibr" target="#b86">[87]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1.3.">Deployment Systems</head><p>Deploying real-life applications on large-scale testbeds provides the most realistic results compared to simulation or emulation approaches. In this direction, a few systems have been proposed in the past few years.</p><p>E2Clab <ref type="bibr" target="#b122">[123]</ref> is a framework that implements a rigorous methodology for designing experiments with real-world workloads on the Edge-to-Cloud Continuum. E2Clab provides guidelines to move from real-world use cases to the design of relevant testbed setups for reproducible experiments enabling researchers to understand and optimize [121] the performance of applications. The key features provided by E2Clab are <ref type="bibr" target="#b121">[122]</ref>: (1) reproducible experiments; (2) the mapping of applications parts executed across the computing continuum with the physical testbed; (3) the support for experiment variation and transparent scaling of the scenario; (4) network emulation to define Edge-to-Cloud communication constraints; (5) experiment deployment, monitoring and backup of results; and (6) the application optimization.</p><p>Kubernetes <ref type="bibr" target="#b23">[24]</ref> aims to simplify the deployment and management of services that compose an application by providing mechanisms for deployment, maintenance, and scaling.</p><p>Using Kubernetes, users can manage containerized applications across multiple hosts. KubeEdge <ref type="bibr" target="#b158">[159]</ref> builds on top of Kubernetes to extend Cloud capabilities to the Edge and allows containerized application orchestration and device management to hosts at the Edge. KubeEdge key features are: core infrastructure support for networking; application deployment; and metadata synchronization between Cloud and Edge.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2.">Large-Scale Experimental Testbeds for Edge-to-Cloud Experiments</head><p>Several experimental testbeds allow researchers to evaluate their proposals in real-life settings by providing access to a large amount of resources (grouped in homogeneous or heterogeneous clusters, upon convenience) and, more importantly, supported by some vibrant communities of users and solid technical teams. We cite here just a few.</p><p>Grid5000 <ref type="bibr" target="#b19">[20]</ref> is a large-scale French testbed for experimental research with a focus on parallel and distributed computing including Cloud, HPC, Big Data, and AI. Grid5000 is merging with FIT IoT-Lab to enable Edge-to-Cloud experiments. FIT IoT-Lab <ref type="bibr" target="#b1">[2]</ref> is a large-scale multi-radio (e.g., IEEE 802.15.4, Bluetooth Low Energy, LoRa, etc.) and multi-platform (e.g., Arduino Zero, nRF52840-MDK, LoRa gateway, and many others) infrastructure for the Internet of Things. FIT IoT-Lab consists of more than 1.5K nodes and provides tools for monitoring energy consumption and network-related metrics, such as end-to-end delay, throughput and overhead. A recent effort on supporting experiments combining Grid5000 and FIT IoT-Lab testbeds is EnOSlib <ref type="bibr" target="#b31">[32]</ref>. EnOSlib is a library which brings reusable building blocks for configuring the infrastructure, provisioning software on remote hosts as well as organizing the experimental workflow.</p><p>Chameleon <ref type="bibr" target="#b69">[70]</ref> is a large-scale US experimental platform that aims to support Computer Science research in many areas, such as: systems, storage, networking, GPU, security, Artificial Intelligence, and High Performance Computing. CHI@Edge is an extension of Chameleon testbed that aims to support Edge Computing experiments. Combining Chameleon and CHI@Edge testbeds allows more realistic Edge-to-Cloud experiments since it provides access to reallife IoT/Edge devices such as Raspberry Pis, Jetson Nanos, among others.</p><p>ORBIT <ref type="bibr" target="#b104">[105]</ref> (Open-Access Research Testbed for Next-Generation Wireless Networks) is based on a 20x20 twodimensional grid of programmable radio nodes which can be interconnected into different topologies. ORBIT provides access to: radio resources, including WiFi 802.11a/b/g 802.11n 802.11ac, Bluetooth (BLE), ZigBee, and Software Defined Radio platforms; Software defined networking (SDN) resources; LTE and WiMAX base stations and clients; and Cloud resources such as nodes with Tesla-based GPUs.</p><p>SmartSantander <ref type="bibr" target="#b125">[126]</ref> is a large scale testbed composed of around 2000 IEEE 802.15.4 devices deployed in a 3-tiered architecture (IoT node, repeaters, and gateway node) deployment in the Spanish city of Santander. The testbed allows IoT native experimentation (e.g. wireless sensor network experi-  small scale <ref type="bibr" target="#b168">[169,</ref><ref type="bibr" target="#b76">77,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b85">86,</ref><ref type="bibr" target="#b166">167,</ref><ref type="bibr" target="#b66">67,</ref><ref type="bibr" target="#b150">151,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b127">128,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b59">60,</ref><ref type="bibr" target="#b169">170,</ref><ref type="bibr" target="#b96">97,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b56">57,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b160">161,</ref><ref type="bibr" target="#b61">62,</ref><ref type="bibr" target="#b79">80,</ref><ref type="bibr" target="#b49">50,</ref><ref type="bibr" target="#b75">76,</ref><ref type="bibr" target="#b42">43,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b98">99]</ref>, medium scale <ref type="bibr" target="#b37">[38,</ref><ref type="bibr" target="#b110">111,</ref><ref type="bibr" target="#b126">127,</ref><ref type="bibr" target="#b128">129,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b55">56,</ref><ref type="bibr" target="#b156">157]</ref>, and large scale <ref type="bibr" target="#b65">[66,</ref><ref type="bibr" target="#b122">123,</ref><ref type="bibr">121]</ref> ments) and service provision experiments (e.g. applications using real-time real-world sensor data).</p><p>Fed4FIRE+ <ref type="bibr" target="#b40">[41]</ref> is a project offering the largest federation worldwide of Next Generation Internet (NGI) testbeds. Fed4FIRE aims to provide open, accessible and reliable experimental infrastructures supporting a wide variety of research, such as 5G, IoT, Cloud Computing, Wired and Wireless Computer Networking. The list of testbeds [103] federated with Fed4FIRE are: CityLab <ref type="bibr" target="#b140">[141]</ref>, PlanetLab <ref type="bibr" target="#b54">[55]</ref>, ExoGENI <ref type="bibr" target="#b14">[15]</ref>, Tengu <ref type="bibr" target="#b145">[146]</ref>, NITOS <ref type="bibr" target="#b109">[110]</ref>, w-iLab <ref type="bibr" target="#b21">[22]</ref>, among others.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.3.">Support to Experimental Reproducibility</head><p>A desired feature of any experimental research is that its scientific claims are verifiable by others in order to build upon them. This can be achieved through Repeatability, Replicability, and Reproducibility <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b139">140]</ref>. Find in Table <ref type="table" target="#tab_11">10</ref> the terminology proposed by the ACM Digital Library.</p><p>We evaluate the support to the reproducibility of experiments for each selected article. This evaluation is based on the following three main relevant aspects:</p><p>Access to artifacts: if authors provide access to a public repository with the artifacts used to run the experiments, such as: datasets, codes, applications, systems, configuration files, among others.</p><p>Experimental setup: if authors provide a description of the experimental setup, such as: hardware configuration </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Repeatability</head><p>Same team, same experimental setup: the measurement can be obtained with stated precision by the same team using the same measurement procedure, the same measuring system, under the same operating conditions, in the same location on multiple trials. For computational experiments, this means that a researcher can reliably repeat their own computation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Replicability</head><p>Different team, same experimental setup: the measurement can be obtained with stated precision by a different team using the same measurement procedure, the same measuring system, under the same operating conditions, in the same or a different location on multiple trials. For computational experiments, this means that an independent group can obtain the same result using the author's own artifacts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Reproducibility</head><p>Different team, different experimental setup: the measurement can be obtained with stated precision by a different team, a different measuring system, in a different location on multiple trials. For computational experiments, this means that an independent group can obtain the same result using artifacts which they develop completely independently.</p><p>of physical machines, software or systems used, network configurations, among others. Access to results: if the computed experimental results are available in a public repository, such as: log files, files metric collected during runtime, monitoring data, code to plot charts, among others.</p><p>Figure <ref type="figure" target="#fig_7">6</ref> summarizes the support to the reproducibility of experiments provided by the selected studies. Regarding the access to artifacts, 68% of papers do not provide access to them, and just 24% partially provide (a few artifacts, but not all). Analyzing the description of the experimental setup, 76% of papers describe it in detail in a dedicated section of the paper, while 21% only partially describe it and just 3% do not provide enough information. Lastly, regarding the access to results, 95% of the articles do not provide access and just 5% provide a public repository with the results. In general, we notice a lack of support to the experimental reproducibility in the domain of Edge-to-Cloud experimental research.</p><p>Lastly, Figure <ref type="figure" target="#fig_8">7</ref> presents the size of the testbeds used in the experimental evaluations. As one may note, 70% of papers use small scale setups, composed by at most 5 machines or devices, while 20% of them use testbed setups composed by 6 to 19 nodes, and just 10% experiment in large scale setups with 20 nodes or more.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.4.">Main takeaways</head><p>This section aims to answer the following research question: What are the existing solutions for experimental research and how do the selected studies support the reproducibility of the experiments? We identify and summarize the key characteristics of the main state-of-the-art simulation, emulation, and deployment systems. Furthermore, we discuss the recent efforts and initiatives merging large scale testbeds for enabling more realistic setups for Edge-to-Cloud experiments, such as: Grid'5000 and FIT IoT-Lab; Chameleon and CHI@Edge; and the Fed4FIRE project.</p><p>We also analyze the selected studies regarding their sup- port to the reproducibility of experiments. As a conclusion, the results presented in Figure <ref type="figure" target="#fig_7">6</ref> reinforce the need for rigorous experimental methodologies that provide guidelines to the reproducibility of experiments in the Edge-to-Cloud research domain. At the same time, Figure <ref type="figure" target="#fig_8">7</ref> highlights the need for methodologies and deployment systems guiding researchers to evaluate and validate their proposed approaches in large-scale environments. The development of novel systems, frameworks, or libraries abstracting the complexities of deploying Edge-to-Cloud workflows on large scale testbeds in addition with the management of the whole experimental cycle such as monitoring, gathering of results, and provenance of the experimental setup are extremely relevant. Recent advances in this direction exist, like the EnOSlib <ref type="bibr" target="#b31">[32]</ref> library or the E2Clab <ref type="bibr" target="#b122">[123]</ref> framework, but further advances are still needed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.">Major Findings</head><p>We gained the following insights and learned some lessons from this systematic review:  5. We observed that the articles do not follow systematic experimental methodologies. Hence, most of them do not provide enough support to enable the reproducibility of the experiments by other researches. Despite most of the articles describing the experimental setup in a dedicated section of the paper, most of them do not provide access to public repositories sharing the artifacts used neither the results obtained. It is strongly recommended that future works consider adopting rigorous methodologies in their experimental evaluations. We highlight that relevant conferences and journals on Computer Science are adopting the Reproducibility Initiative <ref type="bibr" target="#b107">[108]</ref>, which consists in assigning reproducibility badges to articles submitting their artifacts for post-publication peer review.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.">Open Challenges and Research Opportunities</head><p>As presented in the previous sections, distributed digital infrastructures for Data Analytics and learning are now evolving towards an interconnected ecosystem allowing complex applications to be executed from IoT Edge devices to the HPC Cloud. Therefore, new challenging application scenarios are emerging from a variety of domains such as healthcare, asset monitoring in industry, precision agriculture and smart cities, where processing can no longer rely only on traditional approaches that send all data to centralized datacenters for Data Analytics and Machine Learning. Next, we present some of the relevant challenges and research opportunities to be addressed to enable the Computing Continuum vision.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.1.">Understanding Performance of Application Workflows on the Edge-to-Cloud Continuum</head><p>Understanding end-to-end performance on the complex Edge-to-Cloud heterogeneous ecosystem is challenging. De-ploying large-scale real-life applications on such infrastructures requires configuring a myriad of system-specific parameters and reconciling many requirements or constraints in terms of hardware capacity, mobility, network efficiency, energy, and data privacy, with low-level infrastructure design choices. One important challenge is to accurately reproduce relevant behaviors of a given application workflow and representative settings of the physical infrastructure underlying this complex continuum.</p><p>A first step towards reducing this complexity and enabling the Computing Continuum vision is to enable a holistic understanding of performance in such environments. That is, finding a rigorous approach to answering questions like: (1) How to identify infrastructure bottlenecks across the whole Edge-to-Cloud Continuum? (2) Which system parameters and network configurations impact on the application performance and how? (3) How Edge-to-Cloud hardware configurations impact on the energy consumption and on the processing latency of the application?</p><p>Approaches based on workflow modeling <ref type="bibr" target="#b123">[124]</ref> and simulation or emulation, as presented in Table <ref type="table" target="#tab_10">9</ref>, raise some important challenges in terms of specification, modeling, and validation in the context of the Computing Continuum <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b142">143]</ref>. For example, it is increasingly difficult to model the heterogeneity and volatility of Edge devices or to assess the impact of the inherent complexity of hybrid Edge-Cloud deployments on performance. At this stage, experimental evaluation remains the main approach to gain accurate insights on performance metrics and to build precise approximations of the expected behavior of large-scale applications on the Computing Continuum, as a first step prior to modeling.</p><p>A key challenge in this context is to be able to reproduce in a representative way the application behavior in a controlled environment, for extensive experiments in a large-enough spectrum of potential configurations of the underlying hybrid Edge-Cloud infrastructure. However, this process is non-trivial due to the multiple combination possibilities of heterogeneous hardware and software resources, as well as, system components for Data Analytics and Machine Learning. Therefore, the Computing Continuum vision calls for novel approaches to map the real-world application components and dependencies to infrastructure resources.</p><p>Further research efforts shall necessarily focus on the design and implementation of novel methodologies and systems for large-scale experimental evaluation covering the characteristics of hybrid Edge-Cloud infrastructure deployments. Novel systems allowing the combination of simulation and emulation systems in addition to supporting the deployment of state-of-the-art systems for Data Analytics and Machine Learning on real-world large-scale testbeds, considering the same experimental evaluation package, would be relevant to accurately reproduce complex application behaviors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.2.">Optimizing the Performance of Edge-to-Cloud Application Workflows</head><p>The optimization of application workflows on highly distributed and heterogeneous resources is challenging. Real-world applications deployed on hybrid Edge-to-Cloud infrastructures (e.g., smart factory <ref type="bibr" target="#b151">[152]</ref>, autonomous vehicles <ref type="bibr" target="#b92">[93]</ref>, among others) typically need to comply with many conflicting constraints related to hardware resource consumption (e.g., GPU memory, CPU power, main memory size, storage size and bandwidth), software components composing the application and requirements such as QoS, security, and privacy <ref type="bibr" target="#b155">[156]</ref>.</p><p>Furthermore, Edge-to-Cloud deployment optimization problems aim at optimizing metrics <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b10">11]</ref> related to performance (e.g., execution time, latency, and throughput), resource usage, energy consumption, financial costs, and quality attributes (e.g., reliability, security, and privacy). Therefore, the parameter settings of the applications and the underlying infrastructure result in a complex multi-infrastructure configuration search space <ref type="bibr" target="#b116">[117]</ref>.</p><p>Therefore, one important challenge is to accurately and efficiently answer questions like: (1) How to configure the hardware and system components to minimize processing latency and energy consumption? <ref type="bibr" target="#b1">(2)</ref> Where should the workflow components be executed across the Edge-to-Cloud Continuum to minimize communication costs and end-to-end latency? (3) How to efficiently autoscale the application resources concerning workload fluctuations and infrastructure changes?</p><p>Such optimization problems are of NP-hard complexity and multi-objective. Furthermore, the environment settings and configuration parameters are extremely vast and their combination of possibilities virtually unlimited <ref type="bibr" target="#b131">[132,</ref><ref type="bibr" target="#b159">160]</ref>. Hence, the process of searching the ideal deployment and configuration of those real-life applications is challenging given the search space complexity: bad choices may result in increased financial expenses during deployment and production phases, decreased processing efficiency and poor user experience <ref type="bibr" target="#b146">[147]</ref>.</p><p>Given these complexities, future research should focus on proposing novel optimization methodologies supporting the parallel deployment and evaluation of such complex application workflows on real-life large scale testbeds. The objective is two fold: speeding up the optimization computations, as well as obtaining more accurate results.</p><p>Novel approaches should also rely on the development of fully automated surrogate model building to mimic and approximate the complex behavior of Edge-to-Cloud workflows and then perform optimization and sensitivity analysis. These new solutions may combine computationally tractable optimization techniques <ref type="bibr" target="#b112">[113]</ref> such as Bayesian Optimization <ref type="bibr" target="#b135">[136]</ref> methods (e.g., Gaussian process (Kriging) <ref type="bibr" target="#b133">[134]</ref>, Decision Trees <ref type="bibr" target="#b152">[153]</ref>, Random Forest <ref type="bibr" target="#b22">[23]</ref>, among others) to build surrogate models; and then combine with techniques such as evolutionary algorithms and swarm intelligence based algorithms (e.g., Genetic Algorithm <ref type="bibr" target="#b94">[95]</ref>, Differential Evolution <ref type="bibr" target="#b34">[35]</ref>, Particle Swarm Optimization <ref type="bibr" target="#b44">[45]</ref>, etc.) to perform and speed up the optimization (e.g., to find the optimal deployment configuration using the built surrogate model).</p><p>Novel contributions are required for workload characteri-zation and prediction, for autoscaling strategies to enable the efficient scaling of distributed application resources across the Edge-to-Cloud continuum, in response to workload fluctuations and infrastructure changes. Contributions in this context, should be aligned to the complex heterogeneous characteristics of the Computing Continuum paradigm, in terms of: computing resources; network constraints; and application requirements.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.3.">Enabling Intelligence on the Highly Heterogeneous Edge-to-Cloud Continuum</head><p>The right selection of Machine Learning techniques for fast and accurate decision making on the highly heterogeneous (in terms of hardware and software) Edge-to-Cloud Continuum requires extensive experiments and evaluations on real-life hybrid infrastructures combining HPC, Cloud, and Edge systems.</p><p>The goal is to understand how: (a) infrastructure design choices, (b) optimized learning algorithms with tunable parameters, and (c) the combination of learning paradigms impact on performance metrics such as memory usage, energy consumption, model accuracy, training time, network overhead, application processing latency, among others <ref type="bibr" target="#b118">[119]</ref>.</p><p>This comes down to answering questions like: (1) How to efficiently deploy complex AI workflows on heterogeneous and distributed infrastructures to reduce training time and improve model accuracy? <ref type="bibr" target="#b1">(2)</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>How to combine Machine Learning paradigms to leverage the massively distributed resources for training across the Edge-to-Cloud Continuum?</head><p>A relevant challenge, worthy of further consideration, is to understand the performance trade-offs at scale of combining a variety of learning paradigms such as Reinforcement Learning <ref type="bibr" target="#b154">[155]</ref>, Deep Learning <ref type="bibr" target="#b58">[59]</ref>, Online Learning <ref type="bibr" target="#b43">[44]</ref>, Stream Learning <ref type="bibr" target="#b83">[84]</ref>, Lifelong Learning <ref type="bibr" target="#b51">[52]</ref>, Transfer Learning <ref type="bibr" target="#b43">[44]</ref>, Federated Learning <ref type="bibr" target="#b8">[9]</ref>, Distributed Learning <ref type="bibr" target="#b163">[164,</ref><ref type="bibr" target="#b165">166]</ref>, Multi-task Learning <ref type="bibr" target="#b167">[168]</ref>, and others.</p><p>Approaches leveraging the incremental evolution of models over time (e.g., instead of reconstructing new models from scratch) should be considered for streaming data (e.g., instead of batch learning, where the whole training data set should be available for training). They are useful for applications that require high speed processing and analysis of data, and also to avoid the concept drift problem, where predictions become less accurate as time passes, or in cases where the accumulation of large volumes of data is impractical (e.g., due to memory, storage, and processing limitations of Edge devices) <ref type="bibr" target="#b159">[160]</ref>.</p><p>Novel approaches should also leverage the transfer of knowledge to/from different domains (e.g., useful when data for training is scarce) and also take advantage of the parallelism and scalability provided by state-of-the-art distributed stream processing systems (e.g., Flink, Spark, etc.) combined with Machine Learning paradigms <ref type="bibr" target="#b51">[52]</ref> in order to speed up the training and inference time.</p><p>Other open challenges <ref type="bibr" target="#b101">[102,</ref><ref type="bibr" target="#b84">85,</ref><ref type="bibr" target="#b113">114]</ref> include: exploring the massively distributed Edge devices for AI training to achieve scalable and distributed deployment of models on Edge-to-Cloud infrastructures; applying Neural Architecture Search <ref type="bibr" target="#b46">[47]</ref> and Hyperparameter Search <ref type="bibr" target="#b32">[33]</ref> to obtain Deep Learning networks that require less resource without losing accuracy; and exploring Knowledge Distillation <ref type="bibr" target="#b29">[30]</ref> (i.e., transferring knowledge from a large model to a smaller model without loss of validity) to leverage model deployment on resource-limited devices.</p><p>Lastly, further research is needed on novel approaches proposing rigorous methodologies and systems for reproducible experimental evaluations to enable the performance comparison of AI models and learning paradigms deployed on large scale and heterogeneous Edge-to-Cloud infrastructures. Such approaches should publish the experimental artifacts on public repositories to allow their reproducibility <ref type="bibr" target="#b29">[30]</ref>.</p><p>These directions are still ongoing and active research areas in the Big Data and AI communities, and as presented in this systematic review, we have not seen reported studies exploring such challenges at large scale on hybrid Edge-to-Cloud infrastructures.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.4.">Supporting Reproducible Analysis of Complex Edge-to-Cloud Workflows</head><p>Given the relevance of experimental reproducibility in scientific research to allow the verification of the scientific claims and also to evolve the studies, in addition to the lack of support to the reproducibility of experiments identified in recent articles, as presented in Subsection 7.3, future research efforts should focus on the design and implementation of rigorous methodologies for experimental reproducibility.</p><p>Supporting reproducibility of experiments carried out on large scale distributed and heterogeneous infrastructures is non-trivial. The experimental methodology, the artifacts used, and the data captured should provide additional context that more accurately explains the experiment execution and results.</p><p>One relevant challenge is to provide mechanisms to allow researchers to repeat, replicate, and reproduce the scientific claims and to help them answer questions like: (1) What machines/devices were used to execute the entire workflow? (2) What steps were invoked during the workflow execution? (3) Which infrastructure configurations and application parameters produced these results?</p><p>Therefore, novel approaches should focus on enabling the repeatability, replicability and reproducibility of experiments. This requires the definition of rigorous experimentation methodologies (e.g. well-defined description of: hardware and software resources required to run the experiments and their configurations, network setups, resource interconnections, and workflow execution logic); the access to the experimental artifacts (e.g. datasets, scripts, libraries, applications, systems, configuration files, among others); and the development of mechanisms to automatically manage the data derived from experiments, including: the data provenance capture (e.g. runtime configuration of physical machines, software and systems setups, network configurations, etc.) and the access to results (e.g. log files, metrics collected during execution, monitoring data, code to plot results, among others).</p><p>In particular, an important challenge is the data provenance capture on such highly heterogeneous and distributed infrastructures. It requires the design and development of novel provenance systems to efficiently capture data from heterogeneous hardware resources ranging from HPC/Cloud servers to resource constrained Edge devices (e.g. requires smart data capture strategies to reduce capture overhead) interconnected by different network capabilities (e.g. requires provenance data transmission balancing to mitigate the network overhead).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="10.">Conclusions</head><p>In this paper, we did a systematic review of the current state-of-the-art methods to enable intelligence on the Edgeto-Cloud Continuum. First, we discussed the main libraries and frameworks for Machine Learning and Deep Learning inference, centralized training, and distributed training with a focus on the Edge and Cloud. We also presented the main methods for data processing on the Edge, as well as the methods for Big Data stream analytics across the Edge-to-Cloud Continuum.</p><p>We reviewed the recent systems, frameworks and architectures that combine Machine Learning and Data Analytics through the main state-of-the-art learning paradigms such as Online Learning, Transfer Learning, Federated Learning, among others, for collaborative Edge-to-Cloud training and decision making. Finally, we discussed experimental research that covers the whole Edge-to-Cloud Continuum with a focus on simulation, emulation, and deployment systems, as well as large-scale experimental testbeds and how the studies included in our systematic review provide support for experiment reproducibility.</p><p>There are several open challenges left to realize the Computing Continuum vision. We highlighted the complexity of a holistic understanding of performance of application workflows deployed on the Continuum, as well as the performance optimization of such applications on highly distributed and heterogeneous environments. Many advances are yet required to enable intelligence across the Edge-to-Cloud Continuum in an efficient way. In particular, there is a need for approaches that allow the optimized deployment of complex AI workflows to reduce training time and improve model accuracy, and novel ideas that leverage the massively distributed Edge-to-Cloud resources for fast decision making. Given the lack of support for reproducibility, there is also a need for approaches that help scientists to repeat, replicate, and reproduce the analysis of complex Edge-to-Cloud workflows in a large scale. These challenges can be addressed through novel methodologies, algorithms, systems and frameworks.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Systematic review methodology.</figDesc><graphic coords="5,51.31,55.28,237.36,257.62" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>RQ1.</head><label></label><figDesc>What are the main state-of-the-art methods for Machine Learning and Data Analytics? RQ2. How are the existing Machine Learning and Data Analytics approaches combined to enable intelligence? RQ3. What are the existing solutions for experimental research and how do the selected studies support the reproducibility of the experiments? RQ4. What are the open challenges and research opportunities in this area?</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>(a) Selected articles by scientific database. (b) Selected articles by year of publication.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Percentage of selected articles per year of publication and per scientific database.</figDesc><graphic coords="6,91.95,55.27,197.06,122.72" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Taxonomy of learning methods on the Edge and Edge-to-Cloud Continuum.</figDesc><graphic coords="7,330.34,55.28,189.89,158.71" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Taxonomy of analytics approaches on the Edge-to-Cloud Continuum.</figDesc><graphic coords="9,330.34,55.28,189.89,119.04" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Taxonomy of approaches combining data analytics and learning on the Edge-to-Cloud Continuum.</figDesc><graphic coords="14,306.60,55.28,237.36,108.22" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Support to the reproducibility of experiments provided by the selected studies.</figDesc><graphic coords="25,63.18,55.27,213.62,124.42" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: Testbed size used in the experimental evaluations: small scale [169, 77, 31, 86, 167, 67, 151, 39, 128, 37, 60, 170, 97, 5, 57, 3, 161, 62, 80, 50, 76, 43, 12, 99], medium scale<ref type="bibr" target="#b37">[38,</ref><ref type="bibr" target="#b110">111,</ref><ref type="bibr" target="#b126">127,</ref><ref type="bibr" target="#b128">129,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b55">56,</ref><ref type="bibr" target="#b156">157]</ref>, and large scale<ref type="bibr" target="#b65">[66,</ref><ref type="bibr" target="#b122">123,</ref> 121]    </figDesc><graphic coords="25,60.80,223.80,218.37,122.57" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>1 .</head><label>1</label><figDesc>The most common AI frameworks and libraries exploited in the articles are: Tensorflow and PyTorch for the Cloud; and MXNet and Caffe2 (now part of PyTorch) for Deep Learning on the Edge. In turn, the most common Data Analytics frameworks used in the articles are: Apache Spark, Apache Flink, and</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1</head><label>1</label><figDesc>Selected articles by area and computing paradigm.</figDesc><table><row><cell>Area</cell><cell cols="3">Percentage Qty. Computing Paradigm</cell><cell cols="3">Percentage Qty. Papers</cell></row><row><cell></cell><cell></cell><cell></cell><cell>Edge</cell><cell>58%</cell><cell>15</cell><cell></cell></row><row><cell>Machine Learning (ML)</cell><cell>35%</cell><cell>24</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>Edge-to-Cloud</cell><cell>42%</cell><cell>9</cell><cell>[144, 31, 128, 170, 97, 85, 57, 67, 119]</cell></row><row><cell></cell><cell></cell><cell></cell><cell>Edge</cell><cell>56%</cell><cell>9</cell><cell>[9, 36, 56, 3, 66, 147, 163, 68, 37]</cell></row><row><cell>Data Analytics (DA)</cell><cell>23%</cell><cell>16</cell><cell>Edge-to-Cloud</cell><cell>44%</cell><cell>7</cell><cell>[148, 39, 161, 38, 132, 123, 73]</cell></row><row><cell></cell><cell></cell><cell></cell><cell>Cloud</cell><cell>36%</cell><cell>10</cell><cell>[4, 88, 118, 145, 109, 101, 84, 12, 99, 157]</cell></row><row><cell>Combining ML and DA</cell><cell>42%</cell><cell>29</cell><cell></cell><cell></cell><cell></cell><cell>[151, 131, 96, 83, 165, 114,</cell></row><row><cell></cell><cell></cell><cell></cell><cell>Edge-to-Cloud</cell><cell>64%</cell><cell>19</cell><cell>72, 5, 160, 164, 60, 44, 111,</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>52, 127, 129, 106, 74, 120]</cell></row></table><note><p><ref type="bibr" target="#b168">[169,</ref><ref type="bibr" target="#b76">77,</ref><ref type="bibr" target="#b85">86,</ref><ref type="bibr" target="#b166">167,</ref><ref type="bibr" target="#b101">102,</ref><ref type="bibr" target="#b74">75,</ref><ref type="bibr" target="#b161">162,</ref><ref type="bibr" target="#b165">166,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b61">62,</ref><ref type="bibr" target="#b41">42,</ref><ref type="bibr" target="#b79">80,</ref><ref type="bibr" target="#b49">50,</ref><ref type="bibr" target="#b75">76,</ref><ref type="bibr" target="#b42">43]</ref> </p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Summary of artifacts, metrics, and hardware exploited in the Machine Learning experiments</figDesc><table><row><cell>Dataset</cell><cell></cell><cell cols="2">Not informed.</cell><cell></cell><cell></cell><cell></cell><cell>Not informed.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">Not informed.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">MNIST</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">Collected</cell><cell cols="2">from a large</cell><cell>EV company</cell><cell>CIFAR10</cell><cell>Pascal Vi-</cell><cell>sual Object</cell><cell>Classes</cell><cell>(VOC) includ-</cell><cell>ing VOC07</cell><cell>and VOC12</cell><cell>SisFall</cell></row><row><cell>Model</cell><cell cols="2">AlexNet and</cell><cell cols="2">SqueezeNet</cell><cell></cell><cell></cell><cell>VGG-16</cell><cell></cell><cell></cell><cell></cell><cell cols="2">Support Vector Ma-</cell><cell cols="2">chines</cell><cell></cell><cell cols="2">four-layered model;</cell><cell cols="2">eight-layer model;</cell><cell cols="2">and VGG16</cell><cell>Random Forest</cell><cell>(RF); Gradient</cell><cell cols="2">Boosting Decision</cell><cell cols="2">Tree (GBDT), and</cell><cell>Long Short-Term</cell><cell>Memory Networks</cell><cell>(LSTMs)</cell><cell>2Conv + 2FC</cell><cell>Lightweight Convo-</cell><cell>lutional Neural Net-</cell><cell>work (L-CNN)</cell><cell>Long Short-Term</cell><cell>Memory Units</cell><cell>(LSTM), Gated Re-</cell><cell>current Unit (GRU),</cell><cell>Support vector ma-</cell><cell>chines (SVM), and</cell><cell>k-nearest neighbors</cell><cell>(kNN)</cell></row><row><cell>Hardware</cell><cell>MacBook Pro, FogNode, Jet-</cell><cell cols="2">son TX2, Raspberry Pi 3 B+,</cell><cell>Nexus 6P</cell><cell>VMs with limited capabilities to</cell><cell>emulate IoT devices (physical</cell><cell>machine: 2x six-core Intel Xeon</cell><cell>2.40 GHz E5-2620 v3 CPUs, 64</cell><cell>GB RAM)</cell><cell>Master: Intel(R) Xeon(R) CPU</cell><cell cols="2">E5-2620 v3 2.40GHz; and</cell><cell cols="2">Workers: MacBook Pro 2.9</cell><cell>GHz Intel Core i5</cell><cell>1x Nvidia K40 GPU and Xeon</cell><cell cols="2">CPU and resource-limited con-</cell><cell cols="2">tainers to emulate Edge devices</cell><cell>(one CPU and 1GB memory)</cell><cell></cell><cell cols="2">1x Intel FogNode (Parameter</cell><cell cols="2">EdgeSever) and 2x Intel FodeN-</cell><cell cols="2">odes and 1x Jetson TX2 (Edge</cell><cell>nodes: vehicles)</cell><cell>4x machines: 2x 24 CPUs; and</cell><cell>2x 8 CPUs</cell><cell>Raspberry Pi 3 B; and Tinker</cell><cell>Board</cell><cell>Raspberry Pi 2 B</cell></row><row><cell>Metrics</cell><cell cols="2">inference time; memory foot-</cell><cell cols="2">print; and energy consumption</cell><cell></cell><cell>inference time considering dif-</cell><cell>ferent computation and network</cell><cell>conditions</cell><cell></cell><cell cols="2">model convergence speed; num-</cell><cell cols="2">ber of computations performed</cell><cell cols="2">per iteration;</cell><cell></cell><cell cols="2">model accuracy and conver-</cell><cell cols="2">gence speed</cell><cell></cell><cell></cell><cell cols="2">training time (from epoch); and</cell><cell cols="2">evaluation scores including: pre-</cell><cell cols="2">cision, recall, accuracy, and F-</cell><cell>measure</cell><cell>training time and model accu-</cell><cell>racy</cell><cell>performance of human-object</cell><cell>detection (performance in FPS,</cell><cell>CPU usage, memory usage, Av-</cell><cell>erage False Positive Rate, Aver-</cell><cell>age False Negative Rate)</cell><cell>model performance: inference</cell><cell>time, accuracy, and precision;</cell><cell>and Edge gateway: CPU, mem-</cell><cell>ory, and power consumption</cell></row><row><cell>Paper Framework/Library Application/Task</cell><cell>TensorFlow, Caffe2,</cell><cell cols="2">[167] MXNet, PyTorch, Inference</cell><cell>and TensorFlow Lite</cell><cell></cell><cell></cell><cell>[169] TensorFlow Inference</cell><cell></cell><cell></cell><cell cols="2">Collaborative pro-</cell><cell cols="2">[77] DeCaf, MOCHA cessing of Support</cell><cell cols="2">Vector Machines</cell><cell cols="2">Training with back</cell><cell cols="2">[31] TensorFlow propagation vs syn-</cell><cell cols="2">thetic gradient</cell><cell></cell><cell></cell><cell cols="2">CLONE, Tensorflow,</cell><cell cols="2">[86] Keras, and Scikit-Model training</cell><cell>Learn</cell><cell>[67] DLion, TensorFlow Model training</cell><cell>[102] MXNet Human-object track-ing (model training)</cell><cell>[128] TensorFlow, Keras Fall detection (infer-ence)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 :</head><label>3</label><figDesc>Quantitative analysis of artifacts, metrics, and hardware exploited in the Machine Learning experiments. Percentages refer to the total number of papers in that domain.</figDesc><table><row><cell></cell><cell>22%</cell><cell>11%</cell><cell>11%</cell><cell>6%</cell><cell>6%</cell><cell>6%</cell><cell>6%</cell><cell>6%</cell><cell>6%</cell><cell>6%</cell><cell>6%</cell><cell>6%</cell><cell>6%</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Dataset</cell><cell>15% CIFAR</cell><cell>9% SisFall</cell><cell>9% MNIST</cell><cell>9% Vehicle</cell><cell>9% VOC</cell><cell>9% RTWhale</cell><cell>6% CUReT</cell><cell>6% ImageNet</cell><cell>6% SQuADv1.1</cell><cell>3% Chars4K</cell><cell>3% WARD</cell><cell>3% USPS</cell><cell>3% Eye</cell><cell>3%</cell><cell>3%</cell><cell>3%</cell><cell>3%</cell></row><row><cell>Framework/Library Metrics Hardware (Edge) Processors Model</cell><cell>TensorFlow 28% model accuracy 31% Emulated 26% CPU 77% SVM</cell><cell>MXNet 10% resource usage 16% Raspberry Pi 22% GPU 18% SqueezeNet</cell><cell>PyTorch 10% inference time 16% NVIDIA Jetson TX2 13% TPU 5% AlexNet</cell><cell>Keras 7% convergence speed 13% Arduino 4% VGG</cell><cell>Scikit-Learn 7% energy consumption 13% Intel FogNode 4% ResNet</cell><cell>Caffe2 6% network 13% Nexus 6P 4% MobileNet</cell><cell>TensorFlow Lite 3% Tinker Board 4% K-NN</cell><cell>DeCaf 3% ODROID XU4 4% LSTM</cell><cell>MOCHA 3% Apple devices 4% RF</cell><cell>CLONE 3% Edge TPU 4% GRU</cell><cell>DLion 3% Samsung S9 4% GBDT</cell><cell>Chainer 3% SPHERE 4% L-CNN</cell><cell>CoreML 3% GoogleNet</cell><cell>Mistify 3% DT</cell><cell>Edgent 3% FFNN</cell><cell>BranchyNet 3% BDT</cell><cell>ANN</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 :</head><label>4</label><figDesc>Summary of artifacts, metrics, and hardware exploited in the Data Analytics experiments.</figDesc><table><row><cell>Hardware</cell><cell>Edge setup: 8-Megapixel camera acted as the CCTV</cell><cell cols="2">source; 3x Raspberry Pi 3; 3x Google Nexus 4. Cloud</cell><cell cols="2">setup: Heroku (Intel Xeon CPU 2.5GHz, 512MB RAM)</cell><cell>and Amazon EC2 (Intel Xeon CPU 2.4GHz, 4GB RAM)</cell><cell></cell><cell>Raspberry Pi 3; 1x machine 2.00 GHz Intel Core i7-</cell><cell>4510U CPU, 16 GB RAM; and Google Compute Engine</cell><cell>n1-standard-1;</cell><cell></cell><cell cols="2">5x VirtualBox instances of Raspberry Pi; Heroku; and</cell><cell cols="2">Amazon Elastic Beanstalk;</cell><cell></cell><cell>Raspberry Pi 3; Samsung Galaxy J5; Amazon EC2</cell><cell></cell><cell>8x Raspberry Pi 3 B; and 1x desktop machine</cell><cell cols="2">Sonoff SC; Raspberry Pi 3 B+; and Amazon EC2 servers</cell><cell>DS12-v2 and DS11-v2 Azure virtual machines</cell><cell>85x Raspberry Pi B</cell><cell cols="2">Edge: Raspberry Pi 3; Cloud: Intel Xeon CPU E5-2640</cell><cell>v3 (2.6 GHz)</cell><cell>35x machines of the Grid5000 testbed</cell></row><row><cell>Metrics</cell><cell cols="2">processing time delay (network la-</cell><cell cols="2">tency + data serialization + queue-</cell><cell cols="2">ing)</cell><cell>time delay: difference between the</cell><cell>moment when sensor data are first</cell><cell>generated and the moment when</cell><cell>valuable insights are drawn based</cell><cell>on these data</cell><cell>processing time delay (image cap-</cell><cell cols="2">ture + face recognition + return</cell><cell>results to the coordinator)</cell><cell>response time (time difference be-</cell><cell>tween an image is first sampled and</cell><cell>the recognition task)</cell><cell>throughput-latency performance</cell><cell>processing delay and network uti-</cell><cell>lization</cell><cell>query latency</cell><cell>query processing throughput</cell><cell>classification time; processing time;</cell><cell>end to end latency; and activity</cell><cell>recognition accuracy</cell><cell>end-to-end latency, processing</cell><cell>throughput</cell></row><row><cell>Paper Framework/Library Application/Task</cell><cell></cell><cell cols="4">[38] NiFi Surveillance System (collab-orative data processing)</cell><cell></cell><cell></cell><cell cols="3">[39] Flink Smart Healthcare (data stream processing)</cell><cell></cell><cell cols="4">[37] Nifi Face detection and recogni-tion</cell><cell></cell><cell>[36] Nifi Stream processing</cell><cell></cell><cell>[56] EdgeWise, Storm Stream processing</cell><cell cols="2">[3] Edgent, FoT-Stream, Kafka Stream processing</cell><cell>[161] Cameo, Flink Stream processing</cell><cell>[66] Fed4Edge Stream processing</cell><cell cols="2">[68] Flink, Kafka Activity recognition (ran-dom forest classifier model)</cell><cell>[123] Flink, Kafka, Edgent video stream processing</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 5</head><label>5</label><figDesc>Quantitative analysis of artifacts, metrics, and hardware exploited in the Data Analytics experiments. Percentages refer to the total number of papers in that domain.</figDesc><table><row><cell cols="2">Framework/Library</cell><cell>Metrics</cell><cell></cell><cell>Hardware (Edge)</cell><cell></cell><cell cols="2">Processors</cell></row><row><cell>Kafka</cell><cell>19%</cell><cell>end to end latency</cell><cell>47%</cell><cell>Raspberry Pi</cell><cell>53%</cell><cell>CPU</cell><cell>100%</cell></row><row><cell>Flink</cell><cell>15%</cell><cell>network</cell><cell>16%</cell><cell>Emulated</cell><cell>18%</cell><cell>GPU</cell><cell>0%</cell></row><row><cell>NiFi</cell><cell>11%</cell><cell>model accuracy</cell><cell>16%</cell><cell>Arduino</cell><cell>12%</cell><cell>TPU</cell><cell>0%</cell></row><row><cell>Storm</cell><cell>11%</cell><cell>throughput</cell><cell>16%</cell><cell>Google Nexus 4</cell><cell>6%</cell><cell></cell><cell></cell></row><row><cell>Hadoop</cell><cell>7%</cell><cell>classification time</cell><cell>5%</cell><cell>Samsung Galaxy J5</cell><cell>6%</cell><cell></cell><cell></cell></row><row><cell>Spark</cell><cell>7%</cell><cell></cell><cell></cell><cell>Sonoff SC</cell><cell>6%</cell><cell></cell><cell></cell></row><row><cell>Edgent</cell><cell>4%</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Flume</cell><cell>4%</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>EdgeWise</cell><cell>4%</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>FoT-Stream</cell><cell>4%</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Cameo</cell><cell>4%</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Fed4Edge</cell><cell>4%</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>MOA</cell><cell>4%</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="4">Besides, authors review Machine Learning algorithms in Big</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="4">Data such as Supervised, Unsupervised, and Semi-supervised</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>learning.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 6</head><label>6</label><figDesc>Quantitative analysis of Learning Paradigms for learning on the Edge-to-Cloud Continuum. Percentages refer to all papers reviewed which are discussing or exploiting in their experiments these learning paradigms.</figDesc><table><row><cell>Paper</cell><cell>Pct.</cell><cell>Learning Paradigm</cell><cell>Main ideas</cell><cell>Characteristics</cell></row><row><cell>[169, 77, 31,</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>67, 127, 67,</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>151, 88, 131, 96, 132, 83, 165, 114, 72, 160, 84, 164,</cell><cell>30%</cell><cell>Distributed Machine/ Deep Learning [130]</cell><cell></cell><cell></cell></row><row><cell>52, 9, 106,</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>119]</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 7 :</head><label>7</label><figDesc>Summary of articles combining Data Analytics and Machine Learning in their experimental evaluations.</figDesc><table><row><cell>Model Dataset</cell><cell></cell><cell>NA NA</cell><cell>Combined Stream</cell><cell>and Neural Network Warsaw tram data (CSaNN), Combined (WAW) Stream and Random</cell><cell>Forest (CSaRF)</cell><cell cols="3">Conditional Re-Floating Car Data stricted Boltzmann (FCD) Machines (CRBM)</cell><cell></cell><cell cols="2">Data Flow and Dis-</cell><cell cols="2">tributed Deep Neu-IoT truck simulator</cell><cell cols="2">ral Network (DF-by Horton works</cell><cell cols="2">DDNN)</cell><cell></cell><cell></cell><cell cols="2">RNN (LSTM/GRU) SisFall</cell><cell></cell><cell></cell><cell cols="3">SVM, Decision Tree, HEPMASS, SUSY, Naive Bayes, Ran-HIGGS, dom Forest, and K-FLIGHT, HETROACT Means</cell><cell>Decision tree heart disease</cell><cell>SVM, Radial Basis</cell><cell>Function Neural</cell><cell>Network (RBFNN), fault pattern</cell><cell>Deep Belief Network</cell><cell>(DBN)</cell><cell>Tiny ImageNet;</cell><cell>and Stanford ve-</cell><cell>MobileNet hicle dataset and</cell><cell>CASIA-Webface</cell><cell>(face recognition)</cell></row><row><cell>Hardware</cell><cell></cell><cell>simulation</cell><cell></cell><cell>Not informed.</cell><cell>Cluster of 8 servers: 2x</cell><cell>Xeon E5-2630v4 (broadwell)</cell><cell>and 128 GB of DDR4-2400</cell><cell>R ECCRAM. Edge devices:</cell><cell>RaspberryPi 3 B</cell><cell>IoT device: 10x Arduino;</cell><cell cols="2">Edge device: 4x Raspberry</cell><cell cols="2">Pi 3; Edge gateway: 2x Intel</cell><cell cols="2">E5645@2.4 GHz and mem-</cell><cell>ory of 24 GB</cell><cell>Edge: Arduino Uno;</cell><cell>Fog: Raspberry Pi 2 B;</cell><cell cols="2">Cloud: 5x Amazon EC2</cell><cell>and 2x T2.micro; and 1x</cell><cell>T2.medium</cell><cell>2x virtual machines with 8</cell><cell>GB 4 vCPUs; and 16 GB 8</cell><cell>vCPUs</cell><cell>1x Intel i5 and 8GB RAM;</cell><cell>and 3x Amazon EC2</cell><cell>18 virtual machines on 6</cell><cell>physical machines</cell><cell>Xeon E5 system with 8 cores</cell><cell>and Nvidia GTX 970 GPU</cell></row><row><cell>Metrics</cell><cell>latency, spectrum efficiency,</cell><cell>energy efficiency, data rates,</cell><cell>reliability, QoS, and load</cell><cell>prediction accuracy</cell><cell>amount of data collected by</cell><cell>the Fog Nodes; impact of</cell><cell>network between Fog Nodes</cell><cell>and Cloud; model accuracy</cell><cell>Edge vs Cloud;</cell><cell></cell><cell></cell><cell cols="2">network latency and service</cell><cell cols="2">latency</cell><cell></cell><cell></cell><cell></cell><cell cols="2">model accuracy, sensitivity,</cell><cell cols="2">and precision</cell><cell></cell><cell></cell><cell>running time</cell><cell></cell><cell>generalization error</cell><cell>classification accuracy, clas-</cell><cell>sification time, convergence</cell><cell>rate</cell><cell>job execution time; and</cell><cell>bandwidth consumed</cell></row><row><cell>Paper Framework/Library Application/Task</cell><cell cols="3">[151] 5G I-IoT framework 5G channel utiliza-tion</cell><cell>[60] Flink, Flume, Kafka, MOA Processing of vehicle location data</cell><cell></cell><cell cols="3">[111] R Traffic forecasting (model training)</cell><cell></cell><cell></cell><cell></cell><cell cols="4">[127] Scikit-learn, Storm, Nifi, Hadoop, Kafka Distributed model training</cell><cell></cell><cell></cell><cell></cell><cell cols="4">[129] Scikit-Learn, Spark, Fall detection system Tensorflow, Keras, (model training) Kafka</cell><cell></cell><cell></cell><cell>[12] Spark, Weka inference</cell><cell></cell><cell>[99] Spark health status predic-tion</cell><cell>[157] Spark, Storm, and Hadoop fault classification</cell><cell>TensorFlow, Spark, Video stream analyt-</cell><cell>[5] Kafka, Storm, ics (deep learning in-</cell><cell>Hadoop ference)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 8 :</head><label>8</label><figDesc>Quantitative analysis of artifacts, metrics, and hardware exploited in the experiments combining Machine Learning and Data Analytics. Percentages refer to the total number of papers in that domain.</figDesc><table><row><cell>Dataset</cell><cell>14% WAW 10%</cell><cell>7% FCD 10%</cell><cell>7% SisFall 10%</cell><cell>7% HEPMASS 10%</cell><cell>7% SUSY 10%</cell><cell>7% HIGGS 10%</cell><cell>7% FLIGHT 10%</cell><cell>7% HETROACT 10%</cell><cell>7% Stanford vehicle 10%</cell><cell>7% CASIA-Webface 10%</cell><cell>7%</cell><cell>7%</cell><cell>7%</cell><cell></cell></row><row><cell>Hardware (Edge) Processors Model</cell><cell>24% Emulated 28% CPU 100% SVM</cell><cell>19% RaspberryPi 21% GPU 0% CSaNN</cell><cell>14% Arduino 10% TPU 0% CSaRF</cell><cell>5% DF-DDNN</cell><cell>5% LSTM</cell><cell>5% GRU</cell><cell>5% kNN</cell><cell>5% MobileNet</cell><cell>5% Decision Tree</cell><cell>5% Naive Bayes</cell><cell>5% Random Forest</cell><cell>5% K-Means</cell><cell>Tiny ImageNet</cell><cell></cell></row><row><cell>Framework/Library Metrics</cell><cell>Spark 19% network</cell><cell>Kafka 15% model accuracy</cell><cell>Storm 11% processing time</cell><cell>Hadoop 11% spectrum efficiency</cell><cell>Scikit-learn 7% energy efficiency</cell><cell>Tensorflow 7% data rates</cell><cell>5G I-IoT 4% reliability</cell><cell>Flink 4% QoS</cell><cell>Flume 4% load</cell><cell>MOA 4% amount of data collected</cell><cell>R 4% generalization error</cell><cell>Nifi 4% convergence rate</cell><cell>Keras 4%</cell><cell>Weka 4%</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 9</head><label>9</label><figDesc>Simulation, Emulation, and Deployment Systems for Experimental Research on the Edgeto-Cloud Continuum.</figDesc><table><row><cell>Simulation Systems</cell><cell>Edge Fog</cell><cell cols="2">Cloud Main Goal</cell><cell>Key Features</cell></row><row><cell></cell><cell></cell><cell></cell><cell>Modeling, simulation,</cell></row><row><cell></cell><cell></cell><cell></cell><cell>and experimentation</cell></row><row><cell>CloudSim [28]</cell><cell></cell><cell>✓</cell><cell>of Cloud infrastruc-</cell></row><row><cell></cell><cell></cell><cell></cell><cell>tures and application</cell></row><row><cell></cell><cell></cell><cell></cell><cell>services.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 10 ACM</head><label>10</label><figDesc>Digital Library Terminology<ref type="bibr" target="#b53">[54]</ref> </figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>Table 11</head><label>11</label><figDesc>Machine Learning frameworks/libraries designed for the Cloud. Marked with a ⋆ are the mostly exploited in the experiments.</figDesc><table><row><cell cols="3">Framework/Library Qty. Paper</cell></row><row><cell></cell><cell></cell><cell>[169, 31, 86, 167, 144, 67, 88,</cell></row><row><cell>⋆ Tensorflow</cell><cell>24</cell><cell>96, 83, 165, 114, 109, 101, 128, 75, 162, 164, 129, 106,</cell></row><row><cell></cell><cell></cell><cell>119, 30, 62, 120, 43]</cell></row><row><cell>⋆ PyTorch</cell><cell>10</cell><cell>[167, 96, 83, 165, 101, 75, 162, 164, 170, 30]</cell></row><row><cell>Caffe</cell><cell>7</cell><cell>[96, 165, 101, 75, 162, 30, 43]</cell></row><row><cell>SAMOA</cell><cell>6</cell><cell>[4, 88, 118, 145, 84, 74]</cell></row><row><cell>Mahout</cell><cell>6</cell><cell>[4, 88, 163, 114, 118, 145]</cell></row><row><cell>⋆ Scikit-Learn</cell><cell>5</cell><cell>[86, 101, 84, 127, 129]</cell></row><row><cell>CNTK</cell><cell>5</cell><cell>[167, 67, 96, 101, 162]</cell></row><row><cell>MOA</cell><cell>5</cell><cell>[4, 88, 84, 60, 74]</cell></row><row><cell>Spark MLlib</cell><cell>5</cell><cell>[4, 118, 73, 145, 101]</cell></row><row><cell>⋆ Keras</cell><cell>4</cell><cell>[86, 101, 128, 129]</cell></row><row><cell>Chainer</cell><cell>4</cell><cell>[96, 101, 162, 80]</cell></row><row><cell>R</cell><cell>3</cell><cell>[4, 88, 111]</cell></row><row><cell>Vowpal Wabbit</cell><cell>3</cell><cell>[88, 101, 74]</cell></row><row><cell>Theano</cell><cell>3</cell><cell>[96, 165, 101]</cell></row><row><cell>Gaia</cell><cell>2</cell><cell>[67, 165]</cell></row><row><cell>Flink ML</cell><cell>2</cell><cell>[118, 101]</cell></row><row><cell>Mistify</cell><cell>1</cell><cell>[62]</cell></row><row><cell>CLONE</cell><cell>1</cell><cell>[86]</cell></row><row><cell>DLion</cell><cell>1</cell><cell>[67]</cell></row><row><cell>Ako</cell><cell>1</cell><cell>[67]</cell></row><row><cell>TUX2</cell><cell>1</cell><cell>[165]</cell></row><row><cell>Weka</cell><cell>1</cell><cell>[12]</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13"><head>Table 12</head><label>12</label><figDesc>Machine Learning frameworks/libraries designed for the Edge. Marked with a ⋆ are the mostly exploited in the experiments.</figDesc><table><row><cell cols="3">Framework/Library Qty. Paper</cell></row><row><cell>⋆ MXNet</cell><cell>11</cell><cell>[167, 67, 96, 83, 165, 101, 102, 162, 164, 170, 30]</cell></row><row><cell>⋆ Caffe2</cell><cell>7</cell><cell>[167, 83, 165, 101, 162, 164, 30]</cell></row><row><cell>TF Lite</cell><cell>5</cell><cell>[167, 83, 162, 164, 85]</cell></row><row><cell>CoreML</cell><cell>4</cell><cell>[83, 165, 162, 97]</cell></row><row><cell>TF Federated</cell><cell>2</cell><cell>[77, 85]</cell></row><row><cell>Neurosurgeon</cell><cell>2</cell><cell>[77, 83]</cell></row><row><cell>MOCHA</cell><cell>1</cell><cell>[77]</cell></row><row><cell>FedProx</cell><cell>1</cell><cell>[77]</cell></row><row><cell>TensorRT</cell><cell>1</cell><cell>[77]</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_14"><head>Table 13</head><label>13</label><figDesc>Data Analytics frameworks designed for the Cloud. Marked with a ⋆ are the mostly exploited in the experiments.</figDesc><table><row><cell cols="3">Framework/Library Qty. Paper</cell></row><row><cell></cell><cell></cell><cell>[144, 4, 88, 148, 131, 96, 163,</cell></row><row><cell>⋆ Spark</cell><cell>22</cell><cell>83, 114, 118, 73, 145, 109, 101, 84, 129, 74, 120, 12, 99,</cell></row><row><cell></cell><cell></cell><cell>157]</cell></row><row><cell></cell><cell></cell><cell>[144, 148, 131, 96, 83, 118,</cell></row><row><cell>⋆ Flink</cell><cell>15</cell><cell>145, 101, 39, 68, 84, 60, 74,</cell></row><row><cell></cell><cell></cell><cell>161, 123]</cell></row><row><cell></cell><cell></cell><cell>[4, 163, 118, 73, 145, 109,</cell></row><row><cell>⋆ Kafka</cell><cell>15</cell><cell>101, 68, 60, 127, 129, 74, 3,</cell></row><row><cell></cell><cell></cell><cell>123]</cell></row><row><cell>Storm</cell><cell>11</cell><cell>[4, 88, 148, 131, 96, 145, 84, 127, 56, 74, 157]</cell></row><row><cell>Hadoop</cell><cell>8</cell><cell>[88, 96, 114, 118, 145, 109, 101, 157]</cell></row><row><cell>Samza</cell><cell>4</cell><cell>[4, 118, 84, 74]</cell></row><row><cell>Flume</cell><cell>3</cell><cell>[118, 145, 60]</cell></row><row><cell>Cameo</cell><cell>1</cell><cell>[161]</cell></row><row><cell>Druid</cell><cell>1</cell><cell>[148]</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_15"><head>Table 14</head><label>14</label><figDesc>Data Analytics frameworks designed for the Edge. Marked with a ⋆ is the mostly exploited in the experiments. . The hardware heterogeneity, regarding Edge devices, is not sufficiently analyzed in the validation phase of the proposed systems, frameworks and architectures designed to enable intelligence on the Edge-to-Cloud Continuum. Evaluations mainly rely on Raspberry Pi's or emulate resource-limited devices. Given the highly heterogeneity characteristic of the Edge-to-Cloud Continuum, it is strongly recommended that future works exploit GPUs and TPUs enabled devices, in addition to CPUs.</figDesc><table><row><cell cols="3">Framework/Library Qty. Paper</cell></row><row><cell>⋆ Nifi</cell><cell>5</cell><cell>[38, 37, 127, 36, 74]</cell></row><row><cell>Edgent</cell><cell>3</cell><cell>[83, 3, 123]</cell></row><row><cell>EdgeWise</cell><cell>1</cell><cell>[56]</cell></row><row><cell cols="3">Apache Kafka for the Cloud; and Apache Nifi for the</cell></row><row><cell cols="3">Edge. Very few open source Data Analytics frame-</cell></row><row><cell cols="3">works designed for the Edge were identified.</cell></row><row><cell cols="3">2. The most cited AI learning paradigms are respectively:</cell></row></table><note><p><p>Distributed ML/DL, Online Learning, Reinforcement Learning, Transfer/Multi-task Learning, and Federated Learning. Although widely used, very few articles are exploring their performance trade-offs at scale and their potential jointly utilization across the Edge-to-Cloud Continuum.</p>3</p></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgments</head><p>This work was funded by <rs type="funder">Inria</rs> through the <rs type="funder">HPC-BigData Inria Challenge (IPL)</rs> and by <rs type="funder">French ANR OverFlow</rs> project (<rs type="grantNumber">ANR-15-CE25-0003</rs>).</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_Z8zdjNU">
					<idno type="grant-number">ANR-15-CE25-0003</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A Comparative Analysis of Simulators for the Cloud to Fog Continuum</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Abreu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Velasquez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Curado</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Monteiro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Simulation Modelling Practice and Theory</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page">102029</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Fit iot-lab: A large scale open experimental iot testbed</title>
		<author>
			<persName><forename type="first">C</forename><surname>Adjih</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Baccelli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Fleury</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Harter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Mitton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Noel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Pissard-Gibollet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Saint-Marcel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Schreiner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Vandaele</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2015 IEEE 2nd World Forum on Internet of Things (WF-IoT)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="459" to="464" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Fotstream: A fog platform for data stream analytics in iot</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">M</forename><surname>Alencar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Rios</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Santana</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Prazeres</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">Computer Communications</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Recent trends in distributed online stream processing platform for big data: Survey</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">H</forename><surname>Ali</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">Z</forename><surname>Abdullah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2018 1st Annual International Conference on Information and Sciences (AiCIS)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="140" to="145" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Res: Real-time video stream analytics using edge enhanced clouds</title>
		<author>
			<persName><forename type="first">M</forename><surname>Ali</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Anjum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Rana</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">R</forename><surname>Zamani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Balouek-Thomert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Parashar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Cloud Computing</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">The fog cloud of things: A survey on concepts, architecture, standards, tools, and applications</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Alli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Alam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Internet of Things</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page">100177</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Recent advances in evolving computing paradigms: Cloud, edge, and fog technologies</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">A</forename><surname>Angel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Ravindran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Vincent</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Srinivasan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">C</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sensors</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page">196</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Security of distributed intelligence in edge computing: Threats and countermeasures, in: The cloud-to-thing continuum</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Ansari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">H</forename><surname>Alsamhi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Qiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Lee</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
			<publisher>Palgrave Macmillan</publisher>
			<biblScope unit="page" from="95" to="122" />
			<pubPlace>Cham</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Staleness control for edge data analytics</title>
		<author>
			<persName><forename type="first">A</forename><surname>Aral</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Erol-Kantarci</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Brandić</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM on Measurement and Analysis of Computing Systems</title>
		<meeting>the ACM on Measurement and Analysis of Computing Systems</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="1" to="24" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Big data and extreme-scale computing: Pathways to convergencetoward a shaping strategy for a future software and data ecosystem for scientific inquiry</title>
		<author>
			<persName><forename type="first">M</forename><surname>Asch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Moore</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Badia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Beck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Beckman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Bidot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Bodin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Cappello</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Choudhary</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>De Supinski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The International Journal of High Performance Computing Applications</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="435" to="479" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Performance evaluation metrics for cloud, fog and edge computing: A review, taxonomy, benchmarks and standards for future research</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Aslanpour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Gill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">N</forename><surname>Toosi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Internet of Things</title>
		<imprint>
			<biblScope unit="page">100273</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Big data machine learning using apache spark mllib</title>
		<author>
			<persName><forename type="first">M</forename><surname>Assefi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Behravesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">P</forename><surname>Tafti</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017. 2017</date>
			<publisher>IEEE</publisher>
			<biblScope unit="page" from="3492" to="3498" />
		</imprint>
	</monogr>
	<note>ieee international conference on big data (big data</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Leveraging deep learning and iot big data analytics to support the smart cities development: Review and future directions</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">B</forename><surname>Atitallah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Driss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Boulila</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">B</forename><surname>Ghézala</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Science Review</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page">100303</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Fog computing for smart cities&apos; big data management and analytics: A review</title>
		<author>
			<persName><forename type="first">E</forename><surname>Badidi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Mahrez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Sabir</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Future Internet</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page">190</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Exogeni: A multi-domain infrastructure-as-a-service testbed</title>
		<author>
			<persName><forename type="first">I</forename><surname>Baldin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chase</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Xin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mandal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Ruth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Castillo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Orlikowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Heermann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Mills</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The GENI Book</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="279" to="315" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Reproducible Research for Computing in Science Engineering</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">A</forename><surname>Barba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">K</forename><surname>Thiruvathukal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computing in Science Engineering</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="85" to="87" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Classification of optimization problems in fog computing</title>
		<author>
			<persName><forename type="first">J</forename><surname>Bellendorf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">Á</forename><surname>Mann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Future Generation Computer Systems</title>
		<imprint>
			<biblScope unit="volume">107</biblScope>
			<biblScope unit="page" from="158" to="176" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Simulating resource management across the cloud-to-thing continuum: A survey and future directions</title>
		<author>
			<persName><forename type="first">M</forename><surname>Bendechache</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Svorobej</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Takako Endo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Lynn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Future Internet</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page">95</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Big data and ai revolution in precision agriculture: Survey and challenges</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Bhat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">F</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Grid&apos;5000: A Large Scale And Highly Reconfigurable Experimental Grid Testbed</title>
		<author>
			<persName><forename type="first">R</forename><surname>Bolze</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Cappello</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Caron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Dayde</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Desprez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Jean-Not</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Jégou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lanteri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Leduc</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Melab</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Mornet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Namyst</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Primet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Quétier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Richard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">G</forename><surname>Talbi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Touche</surname></persName>
		</author>
		<idno type="DOI">10.1177/1094342006070078</idno>
		<ptr target="https://hal.inria.fr/hal-00684943,doi:10.1177/1094342006070078" />
	</analytic>
	<monogr>
		<title level="j">International Journal of High Performance Computing Applications</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="481" to="494" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<author>
			<persName><forename type="first">K</forename><surname>Bonawitz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Eichner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Grieskamp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Huba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ingerman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Ivanov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Kiddon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Konečnỳ</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mazzocchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">B</forename><surname>Mcmahan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1902.01046</idno>
		<title level="m">Towards federated learning at scale: System design</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">The w-ilab. t testbed</title>
		<author>
			<persName><forename type="first">S</forename><surname>Bouckaert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Vandenberghe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Jooris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Moerman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Demeester</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Testbeds and Research Infrastructures</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="145" to="154" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Random forests</title>
		<author>
			<persName><forename type="first">L</forename><surname>Breiman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine learning</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="page" from="5" to="32" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Kubernetes and the path to cloud native</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">A</forename><surname>Brewer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the sixth ACM symposium on cloud computing</title>
		<meeting>the sixth ACM symposium on cloud computing</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="167" to="167" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Qos-aware deployment of iot applications through the fog</title>
		<author>
			<persName><forename type="first">A</forename><surname>Brogi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Forti</surname></persName>
		</author>
		<idno type="DOI">10.1109/JIOT.2017.2701408</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Internet of Things Journal</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="1185" to="1192" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Elasticsim: A toolkit for simulating workflows with cloud resource runtime auto-scaling and stochastic task execution times</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Grid Computing</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="257" to="272" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">About caida</title>
		<author>
			<persName><surname>Caida</surname></persName>
		</author>
		<ptr target="https://www.caida.org/about/" />
		<imprint>
			<date type="published" when="2021-07-28">July 28, 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Cloudsim: a toolkit for modeling and simulation of cloud computing environments and evaluation of resource provisioning algorithms</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">N</forename><surname>Calheiros</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ranjan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Beloglazov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A</forename><surname>De Rose</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Buyya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Software: Practice and experience</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="page" from="23" to="50" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Ecosystem of things: Hardware, software, and architecture</title>
		<author>
			<persName><forename type="first">L</forename><surname>Chao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE</title>
		<meeting>the IEEE</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">107</biblScope>
			<biblScope unit="page" from="1563" to="1583" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Deep learning with edge computing: A review</title>
		<author>
			<persName><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Ran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE</title>
		<meeting>the IEEE</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">107</biblScope>
			<biblScope unit="page" from="1655" to="1674" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Exploring the use of synthetic gradients for distributed deep learning across cloud and edge resources</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2nd {USENIX} Workshop on Hot Topics in Edge Computing (HotEdge 19)</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Enoslib: A library for experiment-driven research in distributed computing</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Cherrueau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Delavergne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Van Kempen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Lebre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Pertin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Balderrama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Simonet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Simonin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Parallel and Distributed Systems</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Hyperparameter search in machine learning</title>
		<author>
			<persName><forename type="first">M</forename><surname>Claesen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>De Moor</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1502.02127</idno>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Fogbed: A rapid-prototyping emulation environment for fog computing</title>
		<author>
			<persName><forename type="first">A</forename><surname>Coutinho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Greve</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Prazeres</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Cardoso</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Communications (ICC)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2018">2018. 2018</date>
			<biblScope unit="page" from="1" to="7" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Recent advances in differential evolution-an updated survey</title>
		<author>
			<persName><forename type="first">S</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Mullick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">N</forename><surname>Suganthan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Swarm and Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="1" to="30" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Stream processing on clustered edge devices</title>
		<author>
			<persName><forename type="first">R</forename><surname>Dautov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Distefano</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Cloud Computing</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Pushing intelligence to the edge with a stream processing architecture</title>
		<author>
			<persName><forename type="first">R</forename><surname>Dautov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Distefano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Bruneo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Longo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Merlino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Puliafito</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Internet of Things (iThings) and IEEE Green Computing and Communications (GreenCom) and IEEE Cyber, Physical and Social Computing (CPSCom) and IEEE Smart Data (SmartData)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2017">2017. 2017</date>
			<biblScope unit="page" from="792" to="799" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Data processing in cyber-physical-social systems through edge computing</title>
		<author>
			<persName><forename type="first">R</forename><surname>Dautov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Distefano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Bruneo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Longo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Merlino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Puliafito</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="29822" to="29835" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Hierarchical data fusion for smart healthcare</title>
		<author>
			<persName><forename type="first">R</forename><surname>Dautov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Distefano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Buyya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Big Data</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="1" to="23" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Cloud and distributed architectures for data management in agriculture 4.0: Review and future trends</title>
		<author>
			<persName><forename type="first">O</forename><surname>Debauche</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mahmoudi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Manneback</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Lebeau</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
		<respStmt>
			<orgName>Journal of King Saud University-Computer and Information Sciences</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Fed4fire: the largest federation of testbeds in europe</title>
		<author>
			<persName><forename type="first">P</forename><surname>Demeester</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Van Daele</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Wauters</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Hrasnica</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Building the future internet through FIRE</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="87" to="109" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Edge intelligence: The confluence of edge computing and artificial intelligence</title>
		<author>
			<persName><forename type="first">S</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Dustdar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">Y</forename><surname>Zomaya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Internet of Things Journal</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="7457" to="7469" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Offloaded execution of deep learning inference at edge: Challenges and insights</title>
		<author>
			<persName><forename type="first">S</forename><surname>Dey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Mondal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mukherjee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Pervasive Computing and Communications Workshops (PerCom Workshops)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019">2019. 2019</date>
			<biblScope unit="page" from="855" to="861" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Data fusion and machine learning for industrial prognosis: Trends and perspectives towards industry 4.0</title>
		<author>
			<persName><forename type="first">A</forename><surname>Diez-Olivan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Del Ser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Galar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Sierra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Fusion</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="page" from="92" to="111" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Particle swarm optimization</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">L</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Swamy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Search and optimization by metaheuristics</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="153" to="173" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Artificial intelligence for decision making in the era of big data-evolution, challenges and research agenda</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Edwards</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">K</forename><surname>Dwivedi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Information Management</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="page" from="63" to="71" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Neural architecture search: A survey</title>
		<author>
			<persName><forename type="first">T</forename><surname>Elsken</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Metzen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Hutter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="1997" to="2017" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">High availability in clouds: systematic review and research challenges</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">T</forename><surname>Endo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Rodrigues</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Gonçalves</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kelner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">H</forename><surname>Sadok</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Curescu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Cloud Computing</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="1" to="15" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<ptr target="https://www.etp4hpc.eu/sra.html" />
		<title level="m">Etp4hpc strategic research agenda</title>
		<imprint>
			<date type="published" when="2020-04-29">April 29, 2020</date>
		</imprint>
	</monogr>
	<note>ETP4HPC</note>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Extending the battery lifetime of wearable sensors with embedded machine learning</title>
		<author>
			<persName><forename type="first">Marchegiani</forename><surname>Fafoutis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Elsts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Pope</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Piechocki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Craddock</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE 4th World Forum on Internet of Things (WF-IoT)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2018">2018. 2018</date>
			<biblScope unit="page" from="269" to="274" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<ptr target="http://www.faredge.eu/" />
		<title level="m">Far-edge vision</title>
		<imprint>
			<publisher>FAR-EDGE</publisher>
			<date type="published" when="2021-07-05">July 5, 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Cps data streams analytics based on machine learning for cloud and fog computing: A survey</title>
		<author>
			<persName><forename type="first">X</forename><surname>Fei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Shah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Verba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">M</forename><surname>Chao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Sanchez-Anguix</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lewandowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>James</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Usman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Future Generation Computer Systems</title>
		<imprint>
			<biblScope unit="volume">90</biblScope>
			<biblScope unit="page" from="435" to="450" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Score: Simulator for cloud optimization of resources and energy consumption</title>
		<author>
			<persName><forename type="first">D</forename><surname>Fernández-Cerero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Fernández-Montes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Jakóbik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kołodziej</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Toro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Simulation Modelling Practice and Theory</title>
		<imprint>
			<biblScope unit="volume">82</biblScope>
			<biblScope unit="page" from="160" to="173" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">SIGIR Initiative to Implement ACM Artifact Review and Badging</title>
		<author>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Kelly</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM SIGIR Forum</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="4" to="10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Planetlab: overview, history, and future directions</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">E</forename><surname>Fiuczynski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM SIGOPS Operating Systems Review</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page" from="6" to="10" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Edgewise: a better stream processing engine for the edge</title>
		<author>
			<persName><forename type="first">X</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Ghaffar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">{USENIX} Annual Technical Conference ({USENIX}{ATC} 19)</title>
		<imprint>
			<date type="published" when="2019">2019. 2019</date>
			<biblScope unit="page" from="929" to="946" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Edge-cloud computing for internet of things data analytics: Embedding intelligence in the edge with deep learning</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Ghosh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Grolinger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Industrial Informatics</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="2191" to="2200" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Transformative effects of iot, blockchain and artificial intelligence on cloud computing: Evolution, vision, trends and open challenges</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Gill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Tuli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">V</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Lindsay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Tuli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Smirnova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Jain</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Internet of Things</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">100118</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<monogr>
		<title level="m" type="main">Deep learning</title>
		<author>
			<persName><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016">2016</date>
			<publisher>MIT press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Hybrid short term prediction to address limited timeliness of public transport data streams</title>
		<author>
			<persName><forename type="first">M</forename><surname>Grzenda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Kwasiborska</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Zaremba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">391</biblScope>
			<biblScope unit="page" from="305" to="317" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><surname>Grzywaczewski</surname></persName>
		</author>
		<ptr target="https://devblogs.nvidia.com/training-self-driving-vehicles-challenge-scale" />
		<title level="m">Training ai for self-driving vehicles: the challenge of scale</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Mistify: Automating dnn model porting for on-device inference at the edge</title>
		<author>
			<persName><forename type="first">P</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NSDI</title>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="705" to="719" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">ifogsim: A toolkit for modeling and simulation of resource man-agement techniques in the internet of things, edge and fog computing environments</title>
		<author>
			<persName><forename type="first">H</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Vahid Dastjerdi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">K</forename><surname>Ghosh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Buyya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Software: Practice and Experience</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="page" from="1275" to="1296" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Edge-computing architectures for internet of things applications: A survey</title>
		<author>
			<persName><forename type="first">S</forename><surname>Hamdan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ayyash</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Almajali</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sensors</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page">6441</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Supporting the evaluation of fog-based IoT applications during the design phase</title>
		<author>
			<persName><forename type="first">J</forename><surname>Hasenburg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Werner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Bermbach</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 5th Workshop on Middleware and Applications for the Internet of Things (M4IoT 2018)</title>
		<meeting>the 5th Workshop on Middleware and Applications for the Internet of Things (M4IoT 2018)</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Autonomous rdf stream processing for iot edge devices</title>
		<author>
			<persName><forename type="first">M</forename><surname>Hauswirth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Le-Phuoc</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Semantic Technology: 9th Joint International Conference</title>
		<meeting><address><addrLine>JIST; Hangzhou, China</addrLine></address></meeting>
		<imprint>
			<publisher>Springer Nature</publisher>
			<date type="published" when="2019-11-25">2020. 2019. November 25-27, 2019</date>
			<biblScope unit="page">304</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Dlion: Decentralized distributed deep learning in micro-clouds</title>
		<author>
			<persName><forename type="first">R</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Chandra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">11th {USENIX} Workshop on Hot Topics in Cloud Computing (HotCloud 19)</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Building edge intelligence for online activity recognition in service-oriented iot systems</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">J</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">L</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">S</forename><surname>Shih</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Future Generation Computer Systems</title>
		<imprint>
			<biblScope unit="volume">87</biblScope>
			<biblScope unit="page" from="557" to="567" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Mininet as software defined networking testing platform</title>
		<author>
			<persName><forename type="first">K</forename><surname>Kaur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">S</forename><surname>Ghumman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Communication, Computing &amp; Systems (ICCCS)</title>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="139" to="142" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Lessons learned from the chameleon testbed</title>
		<author>
			<persName><forename type="first">K</forename><surname>Keahey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Anderson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Riteau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Ruth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Stanzione</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Cevik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Colleran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">S</forename><surname>Gunawi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Hammock</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Mambretti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Barnes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Halbach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rocha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Stubbs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 USENIX Annual Technical Conference (USENIX ATC &apos;20)</title>
		<meeting>the 2020 USENIX Annual Technical Conference (USENIX ATC &apos;20)</meeting>
		<imprint>
			<publisher>USENIX Association</publisher>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<monogr>
		<title level="m" type="main">Guidelines for performing systematic literature reviews in software engineering</title>
		<author>
			<persName><forename type="first">S</forename><surname>Keele</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007">2007</date>
			<publisher>Citeseer</publisher>
		</imprint>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Artificial intelligence and internet of things for autonomous vehicles</title>
		<author>
			<persName><forename type="first">H</forename><surname>Khayyam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Javadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Jalili</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">N</forename><surname>Jazar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Nonlinear approaches in engineering applications</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="39" to="68" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<monogr>
		<title level="m" type="main">High-Performance Modelling and Simulation for Big Data Applications: Selected Results of the COST Action IC1406 cHiPSet</title>
		<author>
			<persName><forename type="first">J</forename><surname>Kołodziej</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>González-Vélez</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
			<publisher>Springer Nature</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">S2ce: a hybrid cloud and edge orchestrator for mining exascale distributed streams</title>
		<author>
			<persName><forename type="first">N</forename><surname>Kourtellis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Herodotou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Grzenda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Wawrzyniak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bifet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 15th ACM International Conference on Distributed and Event-based Systems</title>
		<meeting>the 15th ACM International Conference on Distributed and Event-based Systems</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="103" to="113" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Training on the edge: The why and the how</title>
		<author>
			<persName><forename type="first">N</forename><surname>Kukreja</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Shilova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Beaumont</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Huckelheim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Ferrier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Hovland</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Gorman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Parallel and Distributed Processing Symposium Workshops (IPDPSW)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019">2019. 2019</date>
			<biblScope unit="page" from="899" to="903" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">Resource-efficient machine learning in 2 kb ram for the internet of things</title>
		<author>
			<persName><forename type="first">A</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Varma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1935" to="1944" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">Decaf: Iterative collaborative processing over the edge</title>
		<author>
			<persName><forename type="first">D</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Ramkumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Sindhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Chandra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2nd {USENIX} Workshop on Hot Topics in Edge Computing (HotEdge 19)</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">Industrial ai and predictive analytics for smart manufacturing systems</title>
		<author>
			<persName><forename type="first">J</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Azamfar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Pandhare</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Smart Manufacturing</title>
		<imprint>
			<publisher>Elsevier</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="213" to="244" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main">Yafs: A simulator for iot scenarios in fog computing</title>
		<author>
			<persName><forename type="first">I</forename><surname>Lera</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Guerrero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Juiz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="91745" to="91758" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">Edge ai: On-demand accelerating deep neural network inference via edge computing</title>
		<author>
			<persName><forename type="first">E</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Wireless Communications</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="447" to="457" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<analytic>
		<title level="a" type="main">A fast and accurate online sequential learning algorithm for feedforward networks</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">Y</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">B</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Saratchandran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Sundararajan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on neural networks</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="1411" to="1423" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<monogr>
		<title level="m" type="main">Tune: A research platform for distributed model selection and training</title>
		<author>
			<persName><forename type="first">R</forename><surname>Liaw</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Nishihara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Moritz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Gonzalez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Stoica</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1807.05118</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b82">
	<analytic>
		<title level="a" type="main">A survey on edge computing systems and tools</title>
		<author>
			<persName><forename type="first">F</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE</title>
		<meeting>the IEEE</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">107</biblScope>
			<biblScope unit="page" from="1537" to="1562" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<analytic>
		<title level="a" type="main">Spiking neural networks and online learning: An overview and perspectives</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Lobo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Del Ser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bifet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Kasabov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Networks</title>
		<imprint>
			<biblScope unit="volume">121</biblScope>
			<biblScope unit="page" from="88" to="100" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b84">
	<analytic>
		<title level="a" type="main">The disruptions of 5g on data-driven technologies and applications</title>
		<author>
			<persName><forename type="first">D</forename><surname>Loghin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">T A</forename><surname>Dinh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">C</forename><surname>Ooi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><forename type="middle">T</forename><surname>Ta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on knowledge and data engineering</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="1179" to="1198" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b85">
	<analytic>
		<title level="a" type="main">Collaborative learning on the edges: A case study on connected vehicles</title>
		<author>
			<persName><forename type="first">S</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Shi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2nd {USENIX} Workshop on Hot Topics in Edge Computing (HotEdge 19)</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b86">
	<analytic>
		<title level="a" type="main">Exploring task placement for edge-to-cloud applications using emulation</title>
		<author>
			<persName><forename type="first">A</forename><surname>Luckow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Rattan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Jha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE 5th International Conference on Fog and Edge Computing (ICFEC)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2021">2021. 2021</date>
			<biblScope unit="page" from="79" to="83" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b87">
	<analytic>
		<title level="a" type="main">Machine learning with big data: Challenges and approaches</title>
		<author>
			<persName><forename type="first">A</forename><surname>Grolinger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Elyamany</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">F</forename><surname>Capretz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ieee Access</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="7776" to="7797" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b88">
	<monogr>
		<title level="m" type="main">Fog Computing: Concepts, Frameworks and Technologies</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Mahmood</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b89">
	<analytic>
		<title level="a" type="main">Xfogsim: A distributed fog resource management framework for sustainable iot services</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">W</forename><surname>Malik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Qayyum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">U</forename><surname>Rahman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Khan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Khalid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">U</forename><surname>Khan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Sustainable Computing</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="691" to="702" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b90">
	<analytic>
		<title level="a" type="main">Emufog: Extensible and scalable emulation of large-scale fog computing infrastructures</title>
		<author>
			<persName><forename type="first">R</forename><surname>Mayer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Graser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Saurez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Ramachandran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 IEEE Fog World Congress (FWC)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b91">
	<analytic>
		<title level="a" type="main">Brite: An approach to universal topology generation</title>
		<author>
			<persName><forename type="first">A</forename><surname>Medina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Lakhina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Matta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Byers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">MASCOTS 2001, Proceedings Ninth International Symposium on Modeling, Analysis and Simulation of Computer and Telecommunication Systems</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="346" to="353" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b92">
	<analytic>
		<title level="a" type="main">Multi-objective optimization technique for resource allocation and task scheduling in vehicular cloud architecture: A hybrid adaptive nature inspired approach</title>
		<author>
			<persName><forename type="first">S</forename><surname>Midya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Roy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Majumder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Phadikar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Network and Computer Applications</title>
		<imprint>
			<biblScope unit="volume">103</biblScope>
			<biblScope unit="page" from="58" to="84" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b93">
	<analytic>
		<title level="a" type="main">Resource management techniques for cloud/fog and edge computing: An evaluation framework and classification</title>
		<author>
			<persName><forename type="first">A</forename><surname>Mijuskovic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Chiumento</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Bemthuis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Aldea</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Havinga</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sensors</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page">1832</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b94">
	<monogr>
		<title level="m" type="main">Genetic algorithm, in: Evolutionary algorithms and neural networks</title>
		<author>
			<persName><forename type="first">S</forename><surname>Mirjalili</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
			<publisher>Springer</publisher>
			<biblScope unit="page" from="43" to="55" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b95">
	<analytic>
		<title level="a" type="main">Deep learning for iot big data and streaming analytics: A survey</title>
		<author>
			<persName><forename type="first">M</forename><surname>Mohammadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Al-Fuqaha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sorour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Guizani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Communications Surveys &amp; Tutorials</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="2923" to="2960" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b96">
	<analytic>
		<title level="a" type="main">Fall detection in older adults with mobile iot devices and machine learning in the cloud and on the edge</title>
		<author>
			<persName><forename type="first">D</forename><surname>Mrozek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Koczur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Małysiak-Mrozek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Sciences</title>
		<imprint>
			<biblScope unit="volume">537</biblScope>
			<biblScope unit="page" from="132" to="147" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b97">
	<analytic>
		<title level="a" type="main">Communication-efficient distributed ai strategies for the iot edge</title>
		<author>
			<persName><forename type="first">C</forename><surname>Mwase</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Westerlund</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Tenhunen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Future Generation Computer Systems</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b98">
	<analytic>
		<title level="a" type="main">Applying spark based machine learning model on streaming big data for health status prediction</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">R</forename><surname>Nair</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">D</forename><surname>Shetty</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">D</forename><surname>Shetty</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computers &amp; Electrical Engineering</title>
		<imprint>
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="page" from="393" to="399" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b99">
	<monogr>
		<title level="m" type="main">Iotsim-edge: A simulation framework for modeling the behaviour of iot and edge computing environments</title>
		<author>
			<persName><forename type="first">Nandan</forename><surname>Jha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Alwasel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Alshoshan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Naha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">K</forename><surname>Battula</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">K</forename><surname>Garg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Puthal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>James</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Zomaya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">Y</forename></persName>
		</author>
		<idno>arXiv-1910</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv e-prints</note>
</biblStruct>

<biblStruct xml:id="b100">
	<analytic>
		<title level="a" type="main">Machine learning and deep learning frameworks and libraries for large-scale data mining: a survey</title>
		<author>
			<persName><forename type="first">G</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Dlugolinsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bobák</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Á</forename><forename type="middle">L</forename><surname>García</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Heredia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Malík</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Hluchỳ</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence Review</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="page" from="77" to="124" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b101">
	<analytic>
		<title level="a" type="main">Toward intelligent surveillance as an edge network service (isense) using lightweight detection and tracking algorithms</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">Y</forename><surname>Nikouei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">Y</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">R</forename><surname>Faughnan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Services Computing</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b102">
	<analytic>
		<title level="a" type="main">An overview of fed4fire testbeds-and beyond?</title>
		<author>
			<persName><forename type="first">L</forename><surname>Nussbaum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">GEFI-Global Experimentation for Future Internet Workshop</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b103">
	<analytic>
		<title level="a" type="main">A survey of security in cloud, edge, and fog computing</title>
		<author>
			<persName><forename type="first">A</forename><surname>Ometov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><forename type="middle">L</forename><surname>Molua</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Komarov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Nurmi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sensors</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page">927</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b104">
	<monogr>
		<title level="m" type="main">Open-access research testbed for next-generation wireless networks</title>
		<author>
			<persName><forename type="first">P</forename><surname>Orbit</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b105">
	<analytic>
		<title level="a" type="main">Extending reference architecture of big data systems towards machine learning in edge computing environments</title>
		<author>
			<persName><forename type="first">P</forename><surname>Pääkkönen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Pakkala</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Big Data</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="1" to="29" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b106">
	<analytic>
		<title level="a" type="main">A survey on transfer learning</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on knowledge and data engineering</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="1345" to="1359" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b107">
	<analytic>
		<title level="a" type="main">Eic editorial-advancing reproducibility in parallel and distributed systems research</title>
		<author>
			<persName><forename type="first">M</forename><surname>Parashar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Parallel &amp; Distributed Systems</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="2010" to="2010" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b108">
	<analytic>
		<title level="a" type="main">Construing the big data based on taxonomy, analytics and approaches</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">R</forename><surname>Pathak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Pandey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Rautaray</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Iran Journal of Computer Science</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="237" to="259" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b109">
	<analytic>
		<title level="a" type="main">Nitos testbed: A cloud based wireless experimentation facility</title>
		<author>
			<persName><forename type="first">K</forename><surname>Pechlivanidou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Katsalis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Igoumenos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Katsaros</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Korakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Tassiulas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2014 26th International Teletraffic Congress (ITC)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b110">
	<analytic>
		<title level="a" type="main">A resilient and distributed near real-time traffic forecasting application for fog computing environments</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Pérez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gutierrez-Torre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Berral</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Carrera</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Future Generation Computer Systems</title>
		<imprint>
			<biblScope unit="volume">87</biblScope>
			<biblScope unit="page" from="198" to="212" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b111">
	<analytic>
		<title level="a" type="main">Containernet 2.0: A rapid prototyping platform for hybrid service function chains</title>
		<author>
			<persName><forename type="first">M</forename><surname>Peuster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kampmeyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Karl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2018 4th IEEE Conference on Network Softwarization and Workshops (NetSoft)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="335" to="337" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b112">
	<monogr>
		<title level="m" type="main">Intelligent optimisation techniques: genetic algorithms, tabu search, simulated annealing and neural networks</title>
		<author>
			<persName><forename type="first">D</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Karaboga</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012">2012</date>
			<publisher>Springer Science &amp; Business Media</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b113">
	<monogr>
		<title level="m" type="main">Fog Computing, Deep Learning and Big Data Analytics-Research Directions</title>
		<author>
			<persName><forename type="first">C</forename><surname>Prabhu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b114">
	<analytic>
		<title level="a" type="main">Fognetsim++: A toolkit for modeling and simulation of distributed fog environment</title>
		<author>
			<persName><forename type="first">T</forename><surname>Qayyum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">W</forename><surname>Malik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A K</forename><surname>Khattak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Khalid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">U</forename><surname>Khan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="63570" to="63583" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b115">
	<monogr>
		<author>
			<persName><surname>Radical-Dreamer</surname></persName>
		</author>
		<ptr target="https://github.com/radical-project/radical.dreamer/" />
		<title level="m">Radical-dreamer: Dynamic runtime and execution adaptive middleware emulator (rd)</title>
		<imprint>
			<date type="published" when="2022-02-12">Feb 12, 2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b116">
	<analytic>
		<title level="a" type="main">The next grand challenges: Integrating the internet of things and data science</title>
		<author>
			<persName><forename type="first">R</forename><surname>Ranjan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Rana</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Nepal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Yousif</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>James</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Barr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Watson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">P</forename><surname>Jayaraman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Georgakopoulos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Cloud Computing</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="12" to="26" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b117">
	<analytic>
		<title level="a" type="main">The big data system, components, tools, and technologies: a survey</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">R</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Mitra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Bhatt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Goswami</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Knowledge and Information Systems</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="page" from="1165" to="1245" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b118">
	<analytic>
		<title level="a" type="main">Distributed machine learning for iot applications in the fog</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">F</forename><surname>Rocha Neto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">C</forename><surname>Delicato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">V</forename><surname>Batista</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">F</forename><surname>Pires</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Fog Computing: Theory and Practice</title>
		<imprint>
			<biblScope unit="page" from="309" to="345" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b119">
	<monogr>
		<title level="m" type="main">An edge-cloud collaborative computing platform for building aiot applications efficiently</title>
		<author>
			<persName><forename type="first">G</forename><surname>Rong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Tong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Fan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b120">
	<monogr>
		<author>
			<persName><forename type="first">D</forename><surname>Rosendo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Costan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Antoniu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Simonin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Lombardo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Joly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Valduriez</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2108.04033</idno>
		<title level="m">Reproducible performance optimization of complex applications on the edge-to-cloud continuum</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b121">
	<analytic>
		<title level="a" type="main">E2clab: Reproducible analysis of complex workflows on the edge-to-cloud continuum</title>
		<author>
			<persName><forename type="first">D</forename><surname>Rosendo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Costan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Antoniu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Valduriez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE 35th International Parallel and Distributed Processing Symposium</title>
		<imprint>
			<publisher>IPDS</publisher>
			<date type="published" when="2021">2021. 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b122">
	<analytic>
		<title level="a" type="main">E2clab: Exploring the computing continuum through repeatable, replicable and reproducible edge-to-cloud experiments</title>
		<author>
			<persName><forename type="first">D</forename><surname>Rosendo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Silva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Simonin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Costan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Antoniu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2020 IEEE International Conference on Cluster Computing (CLUSTER)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="176" to="186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b123">
	<analytic>
		<title level="a" type="main">Data Flow and Validation in Workflow Modelling</title>
		<author>
			<persName><forename type="first">S</forename><surname>Sadiq</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Orlowska</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Sadiq</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Foulger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 15th Australasian database conference</title>
		<meeting>the 15th Australasian database conference</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="207" to="214" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b124">
	<analytic>
		<title level="a" type="main">From cloud down to things: An overview of machine learning in internet of things</title>
		<author>
			<persName><forename type="first">F</forename><surname>Samie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Henkel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Internet of Things Journal</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="4921" to="4934" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b125">
	<analytic>
		<title level="a" type="main">Smartsantander: Iot experimentation over a smart city testbed</title>
		<author>
			<persName><forename type="first">L</forename><surname>Sanchez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Muñoz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Galache</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Sotres</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Santana</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Gutierrez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ramdhany</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gluhak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Krco</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Theodoridis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Networks</title>
		<imprint>
			<biblScope unit="volume">61</biblScope>
			<biblScope unit="page" from="217" to="238" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b126">
	<analytic>
		<title level="a" type="main">Data flow and distributed deep neural network based low latency iot-edge computation model for big data environment</title>
		<author>
			<persName><forename type="first">S</forename><surname>Sankaranarayanan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Rodrigues</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Sugumaran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kozlov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Engineering Applications of Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">94</biblScope>
			<biblScope unit="page">103785</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b127">
	<analytic>
		<title level="a" type="main">Efficient deployment of predictive analytics in edge gateways: Fall detection scenario</title>
		<author>
			<persName><forename type="first">D</forename><surname>Sarabia-Jácome</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Lacalle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">E</forename><surname>Palau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Esteve</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE 5th World Forum on Internet of Things (WF-IoT)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019">2019. 2019</date>
			<biblScope unit="page" from="41" to="46" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b128">
	<analytic>
		<title level="a" type="main">Highlyefficient fog-based deep learning aal fall detection system</title>
		<author>
			<persName><forename type="first">D</forename><surname>Sarabia-Jácome</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Usach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">E</forename><surname>Palau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Esteve</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Internet of Things</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page">100185</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b129">
	<monogr>
		<title level="m" type="main">Horovod: fast and easy distributed deep learning in tensorflow</title>
		<author>
			<persName><forename type="first">A</forename><surname>Sergeev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Del Balso</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1802.05799</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b130">
	<analytic>
		<title level="a" type="main">Context-aware computing, learning, and big data in internet of things: a survey</title>
		<author>
			<persName><forename type="first">O</forename><forename type="middle">B</forename><surname>Sezer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Dogdu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Ozbayoglu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Internet of Things Journal</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="1" to="27" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b131">
	<analytic>
		<title level="a" type="main">Live data analytics with collaborative edge and cloud processing in wireless iot networks</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">K</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="4621" to="4635" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b132">
	<monogr>
		<title level="m" type="main">Continual learning with deep generative replay</title>
		<author>
			<persName><forename type="first">H</forename><surname>Shin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kim</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1705.08690</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b133">
	<analytic>
		<title level="a" type="main">Kriging models for global approximation in simulation-based multidisciplinary design optimization</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">W</forename><surname>Simpson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">M</forename><surname>Mauery</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Korte</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Mistree</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AIAA journal</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="2233" to="2241" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b134">
	<monogr>
		<title level="m" type="main">Geca: A global edge computing architecture</title>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">X</forename><surname>Sitton Candanedo</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b135">
	<monogr>
		<title level="m" type="main">Practical bayesian optimization of machine learning algorithms</title>
		<author>
			<persName><forename type="first">J</forename><surname>Snoek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">P</forename><surname>Adams</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1206.2944</idno>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b136">
	<analytic>
		<title level="a" type="main">Edgecloudsim: An environment for performance evaluation of edge computing systems</title>
		<author>
			<persName><forename type="first">C</forename><surname>Sonmez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ozgovde</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Ersoy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions on Emerging Telecommunications Technologies</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page">3493</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b137">
	<analytic>
		<title level="a" type="main">A review of blockchain-enabled fog computing in the cloud continuum context</title>
		<author>
			<persName><forename type="first">A</forename><surname>Spataru</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Scalable Computing: Practice and Experience</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="463" to="468" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b138">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><surname>Sreerangaraju</surname></persName>
		</author>
		<ptr target="https://www.perfecto.io/blog/emulation-vs-simulation" />
		<title level="m">Emulation vs. simulation</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b139">
	<monogr>
		<title level="m" type="main">Best Practices for Computational Science: Software Infrastructure and Environments for Reproducible and Extensible Research</title>
		<author>
			<persName><forename type="first">V</forename><surname>Stodden</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Miguez</surname></persName>
		</author>
		<idno>SSRN 2322276</idno>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b140">
	<analytic>
		<title level="a" type="main">The citylab testbed-large-scale multi-technology wireless experimentation in a city environment: Neural network-based interference prediction in a smart city</title>
		<author>
			<persName><forename type="first">J</forename><surname>Struye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Braem</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Latré</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Marquez-Barja</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE INFOCOM 2018-IEEE Conference on Computer Communications Workshops (INFOCOM WKSHPS)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="529" to="534" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b141">
	<monogr>
		<title level="m" type="main">Reinforcement learning: An introduction</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">S</forename><surname>Sutton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">G</forename><surname>Barto</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
			<publisher>MIT press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b142">
	<analytic>
		<title level="a" type="main">Simulating fog and edge computing scenarios: An overview and research challenges</title>
		<author>
			<persName><forename type="first">S</forename><surname>Svorobej</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Takako Endo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bendechache</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Filelis-Papadopoulos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">M</forename><surname>Giannoutakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">A</forename><surname>Gravvanis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Tzovaras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Byrne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Lynn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Future Internet</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page">55</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b143">
	<analytic>
		<title level="a" type="main">{ECO}: Harmonizing edge and cloud with ml/dl orchestration</title>
		<author>
			<persName><forename type="first">N</forename><surname>Talagala</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sundararaman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Sridhar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Arteaga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Subramanian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ghanta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Khermosh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Roselli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">{USENIX} Workshop on Hot Topics in Edge Computing (HotEdge 18)</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b144">
	<analytic>
		<title level="a" type="main">Open source tools for machine learning with big data in smart cities</title>
		<author>
			<persName><forename type="first">U</forename><forename type="middle">D</forename><surname>Ulusar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">G</forename><surname>Ozcan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Al-Turjman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Smart Cities Performability, Cognition, &amp; Security</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="153" to="168" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b145">
	<analytic>
		<title level="a" type="main">Tengu: An experimentation platform for big data applications</title>
		<author>
			<persName><forename type="first">T</forename><surname>Vanhove</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Van Seghbroeck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Wauters</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>De Turck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Vermeulen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Demeester</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE 35th International Conference on Distributed Computing Systems Workshops</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2015">2015. 2015</date>
			<biblScope unit="page" from="42" to="47" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b146">
	<analytic>
		<title level="a" type="main">Smart healthcare applications and realtime analytics through edge computing</title>
		<author>
			<persName><forename type="first">P</forename><surname>Verma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Fatima</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Internet of Things Use Cases for the Healthcare Industry</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="241" to="270" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b147">
	<analytic>
		<title level="a" type="main">A survey on network methodologies for real-time analytics of massive iot data and open research issues</title>
		<author>
			<persName><forename type="first">S</forename><surname>Verma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Kawamoto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">M</forename><surname>Fadlullah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Nishiyama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Kato</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Communications Surveys &amp; Tutorials</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="1457" to="1477" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b148">
	<analytic>
		<title level="a" type="main">Internet of robotic things intelligent connectivity and platforms</title>
		<author>
			<persName><forename type="first">O</forename><surname>Vermesan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Bahr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ottella</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Serrano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Karlsen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Wahlstrøm</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">E</forename><surname>Sand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ashwathnarayan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">T</forename><surname>Gamba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Frontiers in Robotics and AI</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">104</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b149">
	<analytic>
		<title level="a" type="main">Moving deep learning to the edge</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">P</forename><surname>Véstias</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">P</forename><surname>Duarte</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">T</forename><surname>De Sousa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">C</forename><surname>Neto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Algorithms</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page">125</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b150">
	<analytic>
		<title level="a" type="main">From iot to 5g i-iot: The next generation iot-based intelligent algorithms and 5g technologies</title>
		<author>
			<persName><forename type="first">D</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Guizani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Du</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Communications Magazine</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="page" from="114" to="120" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b151">
	<analytic>
		<title level="a" type="main">Adaptive computing optimization in softwaredefined network-based industrial internet of things with fog computing</title>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sensors</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<date type="published" when="2018">2018. 2509</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b152">
	<analytic>
		<title level="a" type="main">On the optimization of fuzzy decision trees</title>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Ye</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Fuzzy Sets and Systems</title>
		<imprint>
			<biblScope unit="volume">112</biblScope>
			<biblScope unit="page" from="117" to="125" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b153">
	<analytic>
		<title level="a" type="main">Maxinet: Distributed emulation of software-defined networks</title>
		<author>
			<persName><forename type="first">P</forename><surname>Wette</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Dräxler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Schwabe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Wallaschek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">H</forename><surname>Zahraee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Karl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IFIP Networking Conference</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2014">2014. 2014</date>
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b154">
	<monogr>
		<title level="m" type="main">Reinforcement learning. Adaptation, learning, and optimization 12</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Wiering</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Van Otterlo</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b155">
	<analytic>
		<title level="a" type="main">Combining heuristics to optimize and scale the placement of iot applications in the fog</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Etchevers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Letondeur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Lebre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Coupaye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Desprez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE/ACM 11th International Conference on Utility and Cloud Computing (UCC)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2018">2018. 2018</date>
			<biblScope unit="page" from="153" to="163" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b156">
	<analytic>
		<title level="a" type="main">Parallel machine learning algorithm using finegrained-mode spark on a mesos big data cloud computing software framework for mobile robotic intelligent fault recognition</title>
		<author>
			<persName><forename type="first">G</forename><surname>Xian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="131885" to="131900" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b157">
	<analytic>
		<title level="a" type="main">Tux 2 : Distributed graph computation for machine learning</title>
		<author>
			<persName><forename type="first">W</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Miao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">14th {USENIX} symposium on networked systems design and implementation ({NSDI} 17)</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="669" to="682" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b158">
	<analytic>
		<title level="a" type="main">Extend cloud to edge with kubeedge</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Xing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE/ACM Symposium on Edge Computing (SEC)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2018">2018. 2018</date>
			<biblScope unit="page" from="373" to="377" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b159">
	<analytic>
		<title level="a" type="main">A survey on industrial internet of things: A cyber-physical systems perspective</title>
		<author>
			<persName><forename type="first">H</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Griffith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Golmie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="78238" to="78259" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b160">
	<analytic>
		<title level="a" type="main">Move fast and meet deadlines: Fine-grained real-time stream processing with cameo</title>
		<author>
			<persName><forename type="first">L</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Venkataraman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Mai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Potharaju</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">18th {USENIX} Symposium on Networked Systems Design and Implementation ({NSDI} 21)</title>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="389" to="405" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b161">
	<analytic>
		<title level="a" type="main">A first look at deep learning apps on smartphones</title>
		<author>
			<persName><forename type="first">M</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">X</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The World Wide Web Conference</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="2125" to="2136" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b162">
	<analytic>
		<title level="a" type="main">Iot stream processing and analytics in the fog</title>
		<author>
			<persName><forename type="first">S</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Communications Magazine</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="page" from="21" to="27" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b163">
	<analytic>
		<title level="a" type="main">All one needs to know about fog computing and related edge computing paradigms: A complete survey</title>
		<author>
			<persName><forename type="first">A</forename><surname>Yousefpour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Fung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Kadiyala</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Jalali</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Niakanlahiji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Jue</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Systems Architecture</title>
		<imprint>
			<biblScope unit="volume">98</biblScope>
			<biblScope unit="page" from="289" to="330" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b164">
	<analytic>
		<title level="a" type="main">Deep learning in mobile and wireless networking: A survey</title>
		<author>
			<persName><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Patras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Haddadi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Communications surveys &amp; tutorials</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="2224" to="2287" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b165">
	<analytic>
		<title level="a" type="main">Deep learning in the era of edge computing: Challenges and opportunities</title>
		<author>
			<persName><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">D</forename><surname>Lane</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Shu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Fog Computing: Theory and Practice</title>
		<imprint>
			<biblScope unit="page" from="67" to="78" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b166">
	<analytic>
		<title level="a" type="main">pcamp: Performance comparison of machine learning packages on the edges</title>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Shi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">{USENIX} Workshop on Hot Topics in Edge Computing (HotEdge 18)</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b167">
	<monogr>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Yang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1707.08114</idno>
		<title level="m">A survey on multi-task learning</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b168">
	<analytic>
		<title level="a" type="main">Distributing deep neural networks with containerized partitions at the edge</title>
		<author>
			<persName><forename type="first">L</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Teodorescu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">H</forename><surname>Du</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2nd {USENIX} Workshop on Hot Topics in Edge Computing (HotEdge 19)</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b169">
	<analytic>
		<title level="a" type="main">Saface: Towards scenario-aware face recognition via edge computing system</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Luo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">3rd {USENIX} Workshop on Hot Topics in Edge Computing (HotEdge 20)</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
