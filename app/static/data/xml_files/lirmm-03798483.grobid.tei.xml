<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A Data-Driven Model Selection Approach to Spatio-Temporal Prediction *</title>
				<funder>
					<orgName type="full">CAPES</orgName>
				</funder>
				<funder>
					<orgName type="full">CNPq</orgName>
				</funder>
				<funder>
					<orgName type="full">FAPERJ</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Rocío</forename><surname>Zorrilla</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Laboratório Nacional de Computação Científica</orgName>
								<orgName type="institution">LNCC</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Eduardo</forename><surname>Ogasawara</surname></persName>
							<email>eogasawara@ieee.org</email>
							<affiliation key="aff1">
								<orgName type="department">Centro Federal de</orgName>
								<orgName type="institution">Educação Tecnológica Celso Sukow da FonsecaCEFET-RJ</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Patrick</forename><surname>Valduriez</surname></persName>
							<email>patrick.valduriez@inria.fr</email>
							<affiliation key="aff2">
								<orgName type="institution" key="instit1">INRIA</orgName>
								<orgName type="institution" key="instit2">LIRMM</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Fábio</forename><surname>Porto</surname></persName>
							<email>fporto@lncc.br</email>
							<affiliation key="aff0">
								<orgName type="department">Laboratório Nacional de Computação Científica</orgName>
								<orgName type="institution">LNCC</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">A Data-Driven Model Selection Approach to Spatio-Temporal Prediction *</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">9BC51460A1B204DF7BDE5765A6BBB290</idno>
					<idno type="DOI">10.5753/sbbd.2022.224638</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-04-12T14:43+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Spatio-temporal Predictive Queries encompass a spatio-temporal constraint, defining a region, a target variable, and an evaluation metric. The output of such queries presents the future values for the target variable computed by predictive models at each point of the spatio-temporal region. Unfortunately, especially for large spatio-temporal domains with millions of points, training temporal models at each spatial domain point is prohibitive. In this work, we propose a data-driven approach for selecting pre-trained temporal models to be applied at each query point. The chosen approach applies a model to a point according to the training and input time series similarity. The approach avoids training a different model for each domain point, saving model training time. Moreover, it provides a technique to decide on the best-trained model to be applied to a point for prediction. In order to assess the applicability of the proposed strategy, we evaluate a case study for temperature forecasting using historical data and auto-regressive models. Computational experiments show that the proposed approach, compared to the baseline, achieves equivalent predictive performance using a composition of pre-trained models at a fraction of the total computational cost.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Successfully predicting the behavior of spatio-temporal phenomena based on past observations is essential for a wide range of scientific studies and real-life applications like precipitation nowcasting <ref type="bibr" target="#b20">[Souto et al., 2018]</ref>, and climate alert systems <ref type="bibr" target="#b13">[Murat et al., 2018]</ref>. In support of these applications, traditional data processing and time series analysis approaches generate predictive models that aim for predictive accuracy at the cost of high execution time and utilization of computational resources <ref type="bibr" target="#b5">[Hassani and Silva, 2015]</ref>.</p><p>More recently, a new class of systems, known as prediction serving systems, has emerged to support trained models scheduling warranting performance and run-time efficiency <ref type="bibr" target="#b4">[Ghanta et al., 2019;</ref><ref type="bibr" target="#b16">Polyzotis et al., 2018]</ref>. For spatio-temporal phenomena, the focus of this paper, expressing a predictive query, involves specifying spatio-temporal constraints that define a region, a target variable whose values are to be inferred, and an evaluation metric for the performance of the predictive query. The query outcome then exhibits the target variable's future values on the specified region, computed by predictive models that meet the metric evaluation threshold.</p><p>However, we argue that building a query plan to answer a spatio-temporal predictive query is hard from several perspectives. Among them, we are interested in the model selection and allocation problem: for a given spatio-temporal query region, a serving system must automatically build an appropriate plan that chooses between training models or pick pre-trained models for each query region spatial position.</p><p>We adopt a data-driven approach to guide the model selection problem. Considering the availability of historical data, the approach pre-processes the data by grouping sequences of the domain using a shape-based similarity measure, which only considers the temporal dimension. The approach trains time series models at each group's representatives sequence. It uses sequence shape similarity between points in the query region to identify candidate models. Finally, it uses a model recommendation strategy to indicate the ones that meet the metric evaluation criteria.</p><p>Our experiments explore the robustness of the domain partitioning and the predictive performance of the proposed model composition used to answer spatio-temporal predictive queries. Results indicate comparable predictive quality using a model composition based on cluster representatives, with a fraction of the computational cost. Moreover, our experiments show that a single clustering strategy, with a fixed number of partitions, may not fully reflect the spatial variations of time series shape throughout the data domain. We adopt a time series classification approach, using a deep learning model, to further improve the model selection.</p><p>The remaining of this paper is structured as follows. In Section 2, we describe the problem formulation; in Section 3, we introduce our proposal to tackle the problem described; in Section 4, we show the experimental results; in Section 5 we discuss related works; and finally, conclusions and future works are given in Section 6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Problem Formulation</head><p>Let D = {((x, y), s), with (x, y) ∈ R 2 and s = (s 1 , s 2 , . . . , s T ) denote a univariate time series (u.t.s) with T time units }, D represents a spatio-temporal domain. Let G = {g 1 , g 2 , . . .} be a set of predictive models, based on forecasting techniques, that were trained with different u.t.s. s ∈ D. Each model g ∈ G is represented as:</p><formula xml:id="formula_0">g = ⟨s, A, p, E g , Σ g ⟩,<label>(1)</label></formula><p>where:</p><p>• s: input sequence (t.s.) divided in training, validation and test sub-sequences,</p><p>• A: forecasting technique,</p><p>• p: parameters for the forecast technique,</p><p>• E g : in-sample error <ref type="bibr" target="#b6">[Hastie et al., 2009]</ref>,</p><p>• Σ g : implementation/execution quality metrics.</p><p>We use g(s, t p , t f ) = (s T +1 , . . . , s T +t f ) to represent a forecast of t f time units of s, indicating that t p time units were used as validation t.s. to compute E g . In this context, we are interested in processing a spatio-temporal predictive query (STPQ) Q:</p><formula xml:id="formula_1">Q = ⟨R, t p , t f , Q m ⟩,<label>(2)</label></formula><p>where:</p><p>• R: represents the spatial region of interest, • t p : {s T -tp-1 , . . . , s T } validation time units, • t f : {s T +1 , . . . , s T +t f } forecast time units (t f ≥ 1),</p><p>• Q m : evaluation metric for the predictive output.</p><p>We assume ⟨M SE {E g ; s ∈ R} , t train , t eval ⟩ as an evaluation metric, bounded by Q m . Thus, we focus on providing an efficient solution to selecting pre-trained models to compose an answer to a STPQ.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Our Proposal</head><p>Given the problem formulation described in Section 2, a possible solution could be to pre-train a predictive model for each t.s. in D. It is sub-optimal as many points would never be queried, and as the t.s. change, the models need to be re-trained. Another costly option would be to train models at the query region points in run-time.</p><p>We propose a data-driven model selection approach that focuses on grouping historical data representing the behavior of the target variable in the domain. We argue that, by considering only a set of models generated over a t.s. representative, which generalizes the shape similarity of other t.s. in the domain, it is possible to preserve a predictive quality comparable to the baseline approach of using a model for every t.s.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 1. A two phase query processing approach</head><p>The approach is divided into two phases, offline and online (Figure <ref type="figure">1</ref>). The offline phase comprises two steps: (A) the domain partitioning, based on t.s. clustering techniques; (B) the construction of predictive models at each group t.s. representative. The online phase is applied when processing an STPQ, comprises: (C) a process to select a set of pre-trained representative models, to schedule and run them; (D) an approach to compose the query output using forecasts of models allocated to every query region point.</p><p>The offline phase is also responsible for storing the domain partitioning and the pre-trained models for later retrieval in the online phase. This reduces the computational workload if we were to train a model on each point of a query region at run-time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Domain Partitioning</head><p>This step aims to: partition the domain into groups with high shape similarity; and find a representative for each group. The k-medoids clustering algorithm can minimize local dissimilarity of each group, and yields an existing t.s. in the dataset as representative (medoid) <ref type="bibr" target="#b11">[Liao, 2005]</ref>. In this paper, the choice of the number of groups k aims to produce predictive models with accurate forecasts for similar t.s.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Model Representative Construction</head><p>In order to answer STPQ with acceptable predictive error, we consider using a model trained at each medoid. We refer to these k models as representative models and are computed during the offline phase as follows. Let's assume a medoid series has size T . We first train a predictive model using (T -t p ) time units and validate it with the immediate sequence of t p time units, to compute the forecast error E g . This model is then re-trained, including the t p sub-sequence, becoming the representative model that can be used to make predictions of t f time units for all t.s. in its group that fall within a particular query region.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Model Selection for Model Composition</head><p>We define "Model Composition" as the subset of predictive models that can compute the forecast value of each element in a region of interest R of the domain. The justification to implement this step is based on the intrinsic properties of the spatio-temporal data: the consistency and auto-correlation on nearby points in the domain makes difficult the task of finding an 'optimal' number of groups (k) <ref type="bibr" target="#b11">[Liao, 2005]</ref>. Within this step, we hypothesize that, if the representative predictive models manage to adequately predict a group of elements with similar shape patterns, then these models will allow us to obtain a prediction for a region of interest of the domain. We consider a model selection process based on the following strategies:</p><p>• Naive Approach (baseline): for each t.s. s j in each group, we train its model g j and calculate the corresponding forecast error. This costly strategy generates as many models as there are t.s. in the region. • Representative Models: we propose that, given the t.s. representative in each group, we train its corresponding model in order to predict future values for each element in the group and evaluate a corresponding generalization error.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Spatio-Temporal Predictive Query Processing</head><p>The online phase is depicted in Figure <ref type="figure">2</ref>, and described as follows:</p><p>(a) The query region R and the time units t p (past) and t f (future) are parsed from the input query. (b) A [R × t p ] spatio-temporal sub-region is extracted from the original dataset, associating a t.s. of t p time units for each point in R. (c) A model composition is created using data about the domain partitioning from the offline phase. Algorithm 1 considers two strategies for model selection: (i) train a predictive model on each point in R, and (ii) intersect the query region R with the groups to find the representatives for every t.s. and load the pre-trained models. (d) With the model composition of the previous step, the requested forecast for the t f steps for each t.s. in R is computed using its corresponding representative model.</p><p>Here, we highlight that the same model can generate different forecasts for different t.s., provided that the t.s. undergo a data transformation (e.g., normalization). The online procedure takes as input the domain, the query parameters, and the model selection strategy. Then, for each element in the query region, the model composition obtained indicates which model performs the forecast.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments and Results</head><p>We evaluate the following aspects of our proposal: the domain partitioning, the predictive quality of the representative models, the model composition and the query performance.</p><p>Experimental dataset. We use a subset of the Climate Forecast System Reanalysis (CFSR) dataset, which contains four daily air temperature observations from January 1979 to December 2015 covering the space between 8N-54S latitude and 80W-25W longitude <ref type="bibr" target="#b18">[Saha et al., 2011]</ref>. We subset this data to include one year of readings in the Brazilian territory, then transform each t.s. into the tuple (latitude, longitude, daily average temperature values), with dimensions (90, 90, 365). Computational environment. We use a Dell PowerEdge R730 server with 2 Intel Xeon E5-2690 v3 2.60GHz CPUs, 768GB RAM, running Linux CentOS 7.7.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Domain Partitioning Evaluation</head><p>We implemented k-medoids using the DTW similarity measure <ref type="bibr" target="#b19">[Sakoe and Chiba, 1978]</ref>.</p><p>Computing k-medoids requires pairwise distances, which can be calculated beforehand as a 2-d matrix. We perform this expensive computational process only once.</p><p>We vary the number of groups from k = 2 up to k = 150 with a stride of two and calculate the Within-cluster Sum of Squares (WSS) for each value of k, obtaining a monotonically decreasing trend for WSS. This makes the choice of k difficult, a known problem for high volumes of data with low variability throughout neighbor points <ref type="bibr" target="#b11">[Liao, 2005]</ref>. Thus we consider three methods: the elbow method <ref type="bibr" target="#b11">[Liao, 2005]</ref>, silhouette index <ref type="bibr" target="#b17">[Rousseeuw, 1987]</ref> and a fitting of the WSS curve by using a smooth cubic spline. These results are summarized in Table <ref type="table" target="#tab_1">1</ref>. Using a cubic spline, we can find the minimum value for the second derivative by fitting the values. We argue that this method is more appro- priate for our dataset, as the splines smoothed the variations that were preventing to find a higher value for k.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Predictive Quality of Models at Representatives</head><p>Here, we evaluate the accuracy of the forecasts computed on the test sub-sequence (t f ) by comparing them against the observational values available. We consider the Symmetric Mean Absolute Percentage Error (sMAPE) for forecast error evaluation and the Mean Squared Error (MSE) <ref type="bibr" target="#b8">[Hyndman and Koehler, 2006]</ref> for accumulated forecast.</p><p>In this section, we evaluate the predictive quality of Auto-Regressive Integrated Moving Average (ARIMA) models <ref type="bibr" target="#b0">[Box and Jenkins, 1976]</ref>, enhanced with auto.ARIMA <ref type="bibr" target="#b7">[Hyndman and Khandakar, 2008]</ref> for parameter selection. These models fit the description in Section 2 and offer good trade-off between predictive accuracy and computational cost.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1.">Evaluation of sMAPE Forecast Error</head><p>Considering the domain partitioning with k = 8, we have eight groups with 1013 ± 617 t.s. on average, yielding eight representative models. Using scatter plots diagrams of intra-cluster similarity and forecast error, we find that, for the group index zero (Figure <ref type="figure" target="#fig_1">3</ref>.a), the maximum sMAPE value was the lowest among the eight groups. Conversely, for the group index four (Figure <ref type="figure" target="#fig_1">3</ref>.b), the maximum sMAPE value was the highest. We don't observe a clear correlation between the DTW distances and the forecast error: as k increases, there is a tendency to obtain groups with more similarity between their elements (lower DTW distance) and also the predictions tend to be more accurate. It is noteworthy that lower values of k (8, 66) can produce some representatives that offer better predictions than, for example, the 'worst' (highest forecast error) representatives of the partitioning scheme with k = 132. Both these observations indicate that different spatial areas may need more precise partitioning than others.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2.">Evaluation of MSE Forecast Error</head><p>Here we are interested in evaluating the MSE metric computed when forecasting an entire group of domain partitioning. We compare the following approaches:</p><p>• Naive Approach (baseline): for every t.s. in each group, train a model and calculate the forecast error. Then for each group, compute its corresponding MSE. • Representative Models: given the k corresponding models for the representatives in a domain partitioning, use its representative model to forecast future values. Finally, compute the accumulated MSE values.</p><p>Table <ref type="table" target="#tab_2">2</ref> shows the results of the MSE evaluation for k = 8. The columns are as follows: (1) cluster ID; (2) elapsed time to train models for all the t.s. in the group (baseline); (3) elapsed time to forecast t f future units for the t.s. in the group (baseline); (4) accumulated MSE value for the baseline; (5) accumulated MSE value for the Representative Models; (6) percentage change of the MSE values between the approaches. We observe that the MSE of the Representative Models varies significantly between groups and is consistently larger than the MSE of the Naive Approach, by 6.75% to 42.01%. Moreover, we find that 76% of the domain t.s. can be predicted using only five models with a forecast error incremented by at most 20%.These results support our hypothesis that when considering more compact groups, each representative generalizes its elements better, and this generalization can be extended to predictive quality.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.3.">Elapsed Time for Training, Validation and Forecast</head><p>The computational cost for training and forecasting is also relevant. According to Table <ref type="table" target="#tab_2">2</ref>, the total time for training the models over all the t.s. in the Naive Approach is about 31500 seconds (8.75 hours). The average training time of an ARIMA model using a t.s. with 349 time units is then 31500/8100 ≈ 3.9 seconds. In our proposal, we consider re-training models. Thus, the total training time for a given partitioning can be estimated as k × (2 × 3.9) seconds, about a minute for the domain partitioning with k = 8.</p><p>The results in this section support the hypothesis that: (1) the data distribution variation observed in the domain would point to a strategy based on multiple partitioning criteria; (2) model representatives can significantly reduce the model training cost with acceptable accuracy. Experiments in this section were repeated for all values of k considered in Section 4.1, and we found that k = 132 minimized the MSE metric. For these reasons, we will consider k = {8, 66, 132} for multiple domain partitioning criteria.   Here, we evaluate the predictive quality of a Model Composition over a region of interest R when processing an STPQ.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.1.">Predictive Quality of Model Composition</head><p>We consider multiple domain partitioning criteria and a Model Selection approach to be applied on query regions of fixed size R = [10 × 10] distributed uniformly over the domain, with these approaches:</p><p>• Naive Selection: For each t.s. in R, we select its pre-trained ARIMA model.</p><p>• Selection of Representative Models: For each t.s. in R, we determine its corresponding group and select the pre-trained ARIMA Representative Model.</p><p>The predictive quality of the Model Composition forecasts is evaluated using the accumulated MSE over the query region R.</p><p>Figures 4.a 4.b correspond to color maps of the MSE over different regions of the domain for k = 66 and k = 132, respectively, with a dark blue for the highest forecast error. Experimentally, we find that a problematic spatial region near the bottom left. Even there, using k = (8, 66) may yield better results than k = 132 for some slices. This finding triggered the development that follows next.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.2.">Classifier for Model Selection</head><p>This section proposes a Model Selection approach that leverages the predictive quality variation of the Representative Models in domain partitioning. Here, the intuition is that by applying multiple partitioning to a domain, each t.s. would be mapped to a set of groups. Conversely, each domain sequence would be associated with a set of model representatives, and so the question is which one to pick.</p><p>We formulate the model selection proposal as a univariate time series (u.t.s.) classification problem: Given an unlabeled u.t.s. of t p time units, assign it to one or more predefined classes. Then we are able to generate the Time Series Classification Dataset as T SCD = {(s 1 , y 1 ), . . . , (s N , y N )} as a collection of pairs (s i , y i ) where s i is a u.t.s with y i as its corresponding one-hot label vector of the labels for its class [I. <ref type="bibr" target="#b9">Fawaz et al., 2019]</ref>.</p><p>In our context, each of these classes represents one of the available domain partitioning criteria. Considering k = {8, 66, 132}, we obtain 183 classes in total, after accounting for medoid repetition. In order to work with a balanced dataset, we extract for the T SCD approximately 30 samples per class <ref type="bibr" target="#b2">[Du et al., 2018]</ref>. We consider 5000 samples, divided in the percentages 60/20/20 for training, validation, and test, respectively.</p><p>Considering the sequential aspect of time series data requires algorithms that can harness this temporal property to select a class label. In this work, we consider a classifier based on Neural Network models. After considering non-hybrid approaches that provided inferior classification accuracy [I. <ref type="bibr" target="#b9">Fawaz et al., 2019]</ref>, we opted for the hybrid architecture 1D Convolutional Neural Network -Long-Short Term Memory (1DCNN-LSTM) <ref type="bibr" target="#b22">[Xu et al., 2020]</ref>. We considered variations for parameters such as learning rate and batch size, that affect the training time and how fast we achieve convergence in the validation loss function.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.3.">Evaluation of the Classifier for Model Selection</head><p>After training the Classifier presented in the previous section, we repeat the same experiments from Section 4.3.1 using the classifier as a Model Selection approach. For each t.s. in R, the classifier receives a t.s. of length t p as input. As output, we obtain a Representative Label that corresponds to one of the Representative Models. With this model selection process, we repeat the forecast error analysis from Section 4.3.1.</p><p>The experimental results are summarized in Table <ref type="table" target="#tab_4">3</ref>: the first columns correspond to the Naive Composition; the next three columns correspond to the Representative Models Composition with the three values of k; the last column (highlighted) to the Classifier for Model Composition. Due to space restrictions, we omit the resulting colormap of the MSE of the forecast errors using the Classifier for Model Selection. We observed that the Classifier generates a composition with predictive quality comparable to the Naive Approach in some areas. However, the opposite is true for other regions, this can be explained by the limited knowledge of the classifier about the time series, as it receives t.s. of t p time units.</p><p>Finally, we compare the execution of an STPQ using the proposed Model Composition, with the Naive Selection based on ARIMA models, over different query region sizes. Results are shown in Table <ref type="table" target="#tab_5">4</ref>, it is similar to Table <ref type="table" target="#tab_4">3</ref> but with the query regions. We observe that, for the majority of the query regions considered, the forecast error of the Classifier for Model Selection is closer to the ARIMA Naive Selection. Common uses for spatio-temporal predictive queries in spatio-temporal data are predictive analytics to answer complex questions involving missing or future values, correlations, and trends, which can be used to identify opportunities or threats <ref type="bibr" target="#b4">[Ghanta et al., 2019;</ref><ref type="bibr" target="#b16">Polyzotis et al., 2018]</ref>. The predictive functionality can help build introspective services for various resource management and optimization tasks <ref type="bibr" target="#b1">[Crankshaw et al., 2017]</ref>.</p><p>While we do not aim to propose a full Predictive Serving System <ref type="bibr" target="#b1">[Crankshaw et al., 2017]</ref>, it is worth exploring some of these systems to better understand the requirements behind model composition and model selection. The framework Clipper <ref type="bibr" target="#b1">[Crankshaw et al., 2017]</ref> is designed to serve trained models at interactive latency, with two model selection policies based on multi-armed bandit algorithms for a trade-off between accuracy and computation overhead. Rafiki <ref type="bibr" target="#b21">[Wang et al., 2018]</ref> is an inference service based on reinforcement learning that provides an online multi-model selection to compose ensembles.</p><p>Regarding massive data processing and model training, in <ref type="bibr" target="#b12">[Mirzasoleiman, 2021]</ref> are discussed techniques for dataset characterization in a reduced number of representatives elements, with data-efficient methods to extract representative subsets that generalize the full data. Finally, DJEnsemble <ref type="bibr" target="#b15">[Pereira et al., 2021]</ref> investigates the prediction of spatio-temporal phenomena using deep-learning models; leveraging statistical properties of the t.s. to generate tiles in contrast of our shape-based approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusions and Future Works</head><p>The main objective of this work is to develop an approach to make predictions, within some tolerated error margin, about future states of a spatio-temporal region, using carefully selected predictive models that have been trained with limited temporal data. To achieve this, we formulate the problem of model composition to process predictive queries and propose a solution where the model selection is guided by a data-driven approach backed by shape-based domain partitioning. The computational experiments were then designed to evaluate the proposal, considering the case study of temperature forecasting.</p><p>Within our proposal, both the domain partitioning (k-medoids) and the construction of Representative Models can be computed and persisted during an offline phase, quickly retrieved during an online phase, significantly reducing the elapsed time for processing predictive queries. In this regard, the choice of k becomes an important factor for the predictive quality, and three techniques to find optimal values of k were explored. We find that the intuitive choice of a large value of k may not always produce the best results: fewer groups may produce more accurate results for some elements of the query region.</p><p>The previous result motivated the proposal of a neural network classifier for model selection. In the offline phase, we allow the construction of representative predictive models for multiple partitioning criteria (k = {8, 66, 132}). For the online phase, the classifier matches the subset (t p time units) of each u.t.s in the query region to one of the representatives, thus creating the model composition for a given predictive query.</p><p>We show that our proposal can process predictive queries with significantly lower response time, while maintaining comparable predictive quality. To evaluate this experimentally, we used sMAPE forecast errors accumulated over query regions with MSE. Results indicate 20% and 45% relative increases for k = 66 and the Classifier approach, respectively, with a gain in computational efficiency of two orders of magnitude as a trade-off. We recognize that the Classifier needs to be improved, e.g., by considering a domain with a larger volume of data and understanding its classification accuracy.</p><p>Our proposal opens up several research directions. The calculation of pairwise DTW distances can be enhanced by grouping time series with an incremental process for the DTW matrix <ref type="bibr" target="#b14">[Oregi et al., 2017]</ref>. For the domain partitioning task, we could consider non-crisp partitioning techniques <ref type="bibr" target="#b10">[Izakian et al., 2015]</ref>, producing more than one representative for a given element. This work did not focus on forecast time for the online phase as the ARIMA models deliver predictions in milliseconds; however, more complex models would imply significant service times. Therefore, a natural follow-up would include a multi-objective optimization process.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>Figure 2. On-Line STPQ processing.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 .</head><label>3</label><figDesc>Figure 3. Forecast error for: (a) group 0: 0.16 ± 0.07 (b) group 4: 0.72 ± 0.35.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 .</head><label>4</label><figDesc>Figure 4. Model Composition with Representatives for: (a) k = 66; (b) k = 132</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>Algorithm 1 Apply a Model Selection Strategy 1: function SELECT_MODEL_COMPOSITION(D, selection_id, t_p) 2:</figDesc><table><row><cell></cell><cell>model_comp ← ⊥</cell></row><row><cell></cell><cell>/* Model Composition with Naive Approach */</cell></row><row><cell>3:</cell><cell>if is_naive_selection(selection_id) then</cell></row><row><cell></cell><cell>/* Let model at each element predict its own element */</cell></row><row><cell>4:</cell><cell>model_comp ← load_trained_models_each(D, t_p)</cell></row><row><cell>5:</cell><cell>end if</cell></row><row><cell></cell><cell>/* Model Composition with Representative Models */</cell></row><row><cell>6:</cell><cell>if is_representative_selection(selection_id) then</cell></row><row><cell></cell><cell>/* User needs to supply value for k of partitioning scheme */</cell></row><row><cell>7:</cell><cell>k ← get_k_f or_request(selection_id)</cell></row><row><cell></cell><cell>/* Retrieve previously trained models at each representative */</cell></row><row><cell>8:</cell><cell>(medoids_with_models, D_part) ← load_models_at_medoids(D, k, t_p)</cell></row><row><cell>9:</cell><cell>for m ∈ medoids_with_models do</cell></row><row><cell></cell><cell>/* Retrieve the elements associated to current representative</cell></row><row><cell>10:</cell><cell>cluster ← elements_represented_by(m, D_part)</cell></row><row><cell></cell><cell>/* Let model at current representative predict these elements */</cell></row><row><cell>11:</cell><cell>model_comp ← set_predictor(cluster, m, model_comp)</cell></row><row><cell>12:</cell><cell>end for</cell></row><row><cell>13:</cell><cell>end if</cell></row><row><cell>14:</cell><cell>Return model_comp</cell></row><row><cell cols="2">15: end function</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 . Methods to find the optimal value for k.</head><label>1</label><figDesc></figDesc><table><row><cell>Method</cell><cell>Optimal k</cell></row><row><cell>Elbow</cell><cell>4</cell></row><row><cell>Silhouette</cell><cell>8</cell></row><row><cell>Cubic spline for WSS</cell><cell>66</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 .</head><label>2</label><figDesc>Forecast Error Analysis with k = 8 and t f = 8</figDesc><table><row><cell cols="6">cid T. Train.(s) T. For. (s) Naive Repr. Models ∆ (%)</cell></row><row><cell>0</cell><cell>2041.469</cell><cell>1.069</cell><cell>0.170</cell><cell>0.185</cell><cell>8.82</cell></row><row><cell>1</cell><cell>3447.608</cell><cell>1.299</cell><cell>0.689</cell><cell>0.926</cell><cell>34.38</cell></row><row><cell>2</cell><cell>2011.441</cell><cell>0.880</cell><cell>0.581</cell><cell>0.678</cell><cell>16.70</cell></row><row><cell>3</cell><cell>2685.912</cell><cell>1.238</cell><cell>0.413</cell><cell>0.492</cell><cell>19.13</cell></row><row><cell>4</cell><cell>14542.318</cell><cell>5.727</cell><cell>0.785</cell><cell>0.838</cell><cell>6.75</cell></row><row><cell>5</cell><cell>3231.718</cell><cell>1.375</cell><cell>0.407</cell><cell>0.437</cell><cell>7.37</cell></row><row><cell>6</cell><cell>1930.740</cell><cell>0.957</cell><cell>0.157</cell><cell>0.203</cell><cell>29.30</cell></row><row><cell>7</cell><cell>1811.335</cell><cell>0.853</cell><cell>0.388</cell><cell>0.551</cell><cell>42.01</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 . MSE Forecast Error Summary including the Classifier.</head><label>3</label><figDesc></figDesc><table><row><cell>Naive</cell><cell>k = 8</cell><cell>k-Medoids k = 66</cell><cell>k = 132</cell><cell>Classifier</cell></row><row><cell cols="5">0.38 ± 0.61 0.48 ± 0.59 0.47 ± 0.86 0.39 ± 0.62 0.70 ± 0.81</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 4 . MSE Forecast Error for Spatio-Temporal Queries in the domain</head><label>4</label><figDesc>D.In this work, we integrate tools designed for two types of knowledge fields: (i) time series classification and (ii) processing spatio-temporal predictive queries. The former gained attention in the last decade due to the accelerated advancement of deep learning techniques, many are discussed in a thesis aimed at deep learning for TSC [I.<ref type="bibr" target="#b9">Fawaz et al., 2019]</ref>, and the site http://www.timeseriesclassification.com, in efforts to reunite dataset and research papers on this evolving topic.</figDesc><table><row><cell>Query Region</cell><cell>Naive</cell><cell>k = 8</cell><cell>k-Medoids k = 66</cell><cell>k = 132</cell><cell>Classifier</cell></row><row><cell>[0, 20] × [0, 20]</cell><cell>0.158</cell><cell>0.089</cell><cell>0.174</cell><cell>0.160</cell><cell>0.190</cell></row><row><cell>[20, 40] × [35, 55]</cell><cell>0.203</cell><cell>0.335</cell><cell>0.199</cell><cell>0.230</cell><cell>0.330</cell></row><row><cell>[50, 70] × [60, 80]</cell><cell>0.170</cell><cell>0.584</cell><cell>0.203</cell><cell>0.188</cell><cell>0.274</cell></row><row><cell>[15, 35] × [65, 85]</cell><cell>0.034</cell><cell>0.063</cell><cell>0.045</cell><cell>0.038</cell><cell>0.093</cell></row><row><cell>[20, 50] × [50, 80]</cell><cell>0.122</cell><cell>0.203</cell><cell>0.147</cell><cell>0.135</cell><cell>0.202</cell></row><row><cell>[15, 45] × [20, 50]</cell><cell>0.156</cell><cell>0.262</cell><cell>0.155</cell><cell>0.168</cell><cell>0.281</cell></row><row><cell>[40, 55] × [20, 40]</cell><cell>0.483</cell><cell>0.707</cell><cell>0.530</cell><cell>0.541</cell><cell>0.618</cell></row><row><cell>[65, 80] × [50, 70]</cell><cell>0.248</cell><cell>0.470</cell><cell>0.302</cell><cell>0.308</cell><cell>0.343</cell></row><row><cell>[30, 60] × [5, 20]</cell><cell>0.137</cell><cell>0.353</cell><cell>0.205</cell><cell>0.147</cell><cell>0.391</cell></row><row><cell>[10, 40] × [55, 70]</cell><cell>0.095</cell><cell>0.139</cell><cell>0.111</cell><cell>0.098</cell><cell>0.135</cell></row><row><cell>5. Related Works</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
		</body>
		<back>

			<div type="funding">
<div><p>* The authors thanks <rs type="funder">CAPES</rs>, <rs type="funder">CNPq</rs>, and <rs type="funder">FAPERJ</rs> for partially supporting the paper. This work is developed in the context of the <rs type="institution">HPDaSc INRIA-Brazil Associated Team</rs>.</p></div>
			</div>
			<listOrg type="funding">
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<author>
			<persName><forename type="first">G</forename><surname>Box</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">M</forename><surname>Jenkins</surname></persName>
		</author>
		<title level="m">Time Series Analysis: Forecasting and Control</title>
		<imprint>
			<publisher>Holden-Day</publisher>
			<date type="published" when="1976">1976</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Clipper: A low-latency online prediction serving system</title>
		<author>
			<persName><forename type="first">D</forename><surname>Crankshaw</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Franklin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Gonzalez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Stoica</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NSDI&apos;17 -USENIX</title>
		<meeting><address><addrLine>Boston, MA</addrLine></address></meeting>
		<imprint>
			<publisher>USENIX Association</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="613" to="627" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">How many samples are needed to estimate a convolutional neural network?</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Balakrishnan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Singh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Curran</forename><surname>Associates</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Inc</forename></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">ML health monitor: taking the pulse of machine learning algorithms in production</title>
		<author>
			<persName><forename type="first">S</forename><surname>Ghanta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Subramanian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Khermosh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sundararaman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Shah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Goldberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Roselli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Talagala</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Applications of Machine Learning</title>
		<imprint>
			<publisher>SPIE</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">11139</biblScope>
			<biblScope unit="page" from="191" to="202" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Forecasting with big data: A review</title>
		<author>
			<persName><forename type="first">H</forename><surname>Hassani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">S</forename><surname>Silva</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annals of Data Science</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="5" to="19" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">The elements of statistical learning: data mining, inference, and prediction</title>
		<author>
			<persName><forename type="first">T</forename><surname>Hastie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Tibshirani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Friedman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
	<note>2nd Edition</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Automatic time series forecasting: The forecast package for r</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Hyndman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Khandakar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Statistical Software, Articles</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1" to="22" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Another look at measures of forecast accuracy</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Hyndman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">B</forename><surname>Koehler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Forecasting</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="679" to="688" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Deep learning for time series classification: A review</title>
		<author>
			<persName><forename type="first">I</forename><surname>Fawaz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Forestier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Weber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Idoumghar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Muller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P.-A</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Data Min. Knowl. Discov</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="917" to="963" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Fuzzy clustering of time series data using dynamic time warping distance</title>
		<author>
			<persName><forename type="first">H</forename><surname>Izakian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Pedrycz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Jamal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Engineering Applications of Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="235" to="244" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Clustering of time series data: A survey</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">W</forename><surname>Liao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1857" to="1874" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Efficient machine learning from massive datasets</title>
		<author>
			<persName><forename type="first">B</forename><surname>Mirzasoleiman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Forecasting daily meteorological time series using arima and regression models</title>
		<author>
			<persName><forename type="first">M</forename><surname>Murat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Malinowska</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Krzyszczak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Agrophysics</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="253" to="264" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">On-line dynamic time warping for streaming time series</title>
		<author>
			<persName><forename type="first">I</forename><surname>Oregi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Pérez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Del Ser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Lozano</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning and Knowledge Discovery in Databases</title>
		<imprint>
			<publisher>Cham. Springer International Publishing</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="591" to="605" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">DJEnsemble: A Cost-Based Selection and Allocation of a Disjoint Ensemble of Spatio-Temporal Models</title>
		<author>
			<persName><forename type="first">R</forename><surname>Pereira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Souto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Chaves</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Zorrilla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Tsan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Rusu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Ogasawara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ziviani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Porto</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021">2021</date>
			<publisher>ACM</publisher>
			<biblScope unit="page" from="226" to="231" />
			<pubPlace>NY, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Data lifecycle challenges in production machine learning: A survey</title>
		<author>
			<persName><forename type="first">N</forename><surname>Polyzotis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Roy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">E</forename><surname>Whang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zinkevich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIGMOD Rec</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="17" to="28" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Silhouettes: A graphical aid to the interpretation and validation of cluster analysis</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Rousseeuw</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Computational and Applied Mathematics</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="53" to="65" />
			<date type="published" when="1987">1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Ncep climate forecast system version 2 (cfsv2) selected hourly time-series products</title>
		<author>
			<persName><forename type="first">S</forename><surname>Saha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Moorthi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Nadiga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Becker</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Dynamic programming algorithm optimization for spoken word recognition</title>
		<author>
			<persName><forename type="first">H</forename><surname>Sakoe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Chiba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Acoustics, Speech, and Signal Processing</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="43" to="49" />
			<date type="published" when="1978">1978</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">A spatiotemporal ensemble approach to rainfall forecasting</title>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">M</forename><surname>Souto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Porto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>De Carvalho Moura</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Bezerra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCNN</title>
		<imprint>
			<date type="published" when="2018">2018. 2018</date>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Rafiki: Machine learning as an analytics service system</title>
		<author>
			<persName><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">K</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">C</forename><surname>Ooi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Reyad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. VLDB Endow</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="128" to="140" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">A one-dimensional cnn-lstm model for epileptic seizure recognition using eeg signal analysis</title>
		<author>
			<persName><forename type="first">G</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Che</forename></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Frontiers in Neuroscience</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page">1253</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
