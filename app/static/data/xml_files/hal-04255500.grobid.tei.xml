<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="fr">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Generating robust counterfactual explanations</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Victor</forename><surname>Guyomard</surname></persName>
							<email>victor.guyomard@orange.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Orange Innovation</orgName>
								<address>
									<settlement>Lannion</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution" key="instit1">Univ Rennes</orgName>
								<orgName type="institution" key="instit2">Inria</orgName>
								<orgName type="institution" key="instit3">CNRS</orgName>
								<orgName type="institution" key="instit4">IRISA</orgName>
								<address>
									<settlement>Rennes</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Françoise</forename><surname>Fessant</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Orange Innovation</orgName>
								<address>
									<settlement>Lannion</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Thomas</forename><surname>Guyet</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">Inria</orgName>
								<address>
									<settlement>AIstroSight</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Tassadit</forename><surname>Bouadi</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution" key="instit1">Univ Rennes</orgName>
								<orgName type="institution" key="instit2">Inria</orgName>
								<orgName type="institution" key="instit3">CNRS</orgName>
								<orgName type="institution" key="instit4">IRISA</orgName>
								<address>
									<settlement>Rennes</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Alexandre</forename><surname>Termier</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution" key="instit1">Univ Rennes</orgName>
								<orgName type="institution" key="instit2">Inria</orgName>
								<orgName type="institution" key="instit3">CNRS</orgName>
								<orgName type="institution" key="instit4">IRISA</orgName>
								<address>
									<settlement>Rennes</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Generating robust counterfactual explanations</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">AF8BE45BAE5B07BA50D594F7B4F3CA02</idno>
					<note type="submission">Submitted on 24 Oct 2023</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-04-12T14:53+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Counterfactual explanation</term>
					<term>Robustness</term>
					<term>Algorithmic recourse</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>et à la diffusion de documents scientifiques de niveau recherche, publiés ou non, émanant des établissements d'enseignement et de recherche français ou étrangers, des laboratoires publics ou privés.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="fr">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The ever-increasing use of machine learning models in critical decision-making contexts, such as health care, hiring processes or credit allocation, makes it essential to provide explanations for the individual decisions made by these models. To this end, Wachter et al. proposed counterfactual explanation <ref type="bibr" target="#b21">[22]</ref>. A counterfactual is defined as the smallest modification of feature values that changes the prediction of a model to a given output. The counterfactual can provide actions (or recourse) for individuals to attain more desirable outcomes. This is particularly important in areas where decisions made by algorithms can have significant impacts on people's lives such as finance, health care or criminal justice. Many methods have been proposed to generate counterfactuals, focusing on some specific properties such as realism <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b6">7]</ref>, actionability <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b15">16]</ref> or sparsity <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b10">11]</ref>. According to Artelt et al. <ref type="bibr" target="#b0">[1]</ref>, many counterfactual generation methods are vulnerable to small changes, where even a minor change in the value of a counterfactual feature can cause the counterfactual to have a different outcome. Such a situation may arise for example in practical implementation of the counterfactual, due to various factors such as unexpected noise, or adversarial manipulation. As an illustration, a counterfactual may suggest to an individual to raise its salary by 200$ to obtain a credit, but in practice, the salary is increased by 199$ or 201$, potentially resulting in a negative decision (a rejected credit) regarding the decision model. This line of discussions falls into the topic of robustness <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b8">9]</ref>. To address robustness in the context of counterfactual explanation, Pawelcyk et al. <ref type="bibr" target="#b14">[15]</ref> introduce the notion of recourse invalidation rate which represents the probability of obtaining a counterfactual with a different predicted class, when small changes (sampled from a noise distribution) are applied to it. They presented an estimator of the recourse invalidation rate in the context of Gaussian distributions, and also a framework (PROBE) that guarantees the recourse invalidation rate to be no greater than a target specified by the user. A limitation of their approach is that the satisfaction of the user condition is dependent of the estimator quality, which means that in practice, the recourse invalidation rate can be greater than the target fixed by the user. Moreover, PROBE leads in practice to a poor trade-off management between proximity and robustness i.e the counterfactual is robust but far from the example to explain. In this paper, we introduce a framework called CROCO (Cost-efficient RObust COunterfactuals), which is based on a new minimization problem inspired by PROBE <ref type="bibr" target="#b14">[15]</ref>. Our framework introduces the novel concept of soft recourse invalidation rate, as well as an estimator of it. It enables us to derive an upper-bound for the recourse invalidation rate with almost certain probability. This ensures that the user obtains a solution with a recourse invalidation rate lower than the predetermined target. An experimental evaluation on different tabular datasets confirms these theoretical results, and shows that our method better optimizes the two criteria of robustness and proximity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related work</head><p>Since Wachter et al. seminal paper <ref type="bibr" target="#b21">[22]</ref>, a variety of counterfactual explanation technics have been proposed. These methods seek to enhance the quality of counterfactuals by incorporating additional properties, such as constraining the counterfactual to support the data distribution in order to produce realistic examples, freezing immutable features (such as race or gender), producing multiple counterfactuals at once, or even adding causality constraints. We refer the readers to Guidotti et al. <ref type="bibr" target="#b5">[6]</ref> for a detailed review about counterfactual explanation properties and methods. The property of robustness has been studied recently in the context of counterfactual explanations, where the validity of a counterfactual is determined by its ability to maintain the same predicted class in the presence of changes. Mishra et al. <ref type="bibr" target="#b9">[10]</ref> distinguish various types of robustness:</p><p>Robustness to model change refers to the evolution of the validity of the counterfactual explanation when machine learning models are re-trained or when training parameters settings are slightly modified. Rawal et al. <ref type="bibr" target="#b16">[17]</ref> have demonstrated that state-of-the-art counterfactual generation methods have the tendency to produce solutions that are not robust to model retraining.</p><p>To address this problem, Ferrario and Loi <ref type="bibr" target="#b4">[5]</ref> proposed to use counterfactual data augmentation every time machine learning models are retrained. Upadhyay et al. <ref type="bibr" target="#b17">[18]</ref> for their part developed an adversarial training objective that produces counterfactuals that are robust regarding changes in the training data. More specifically, they evaluated the robustness on different types of training data shift which are data correction shift, temporal shift, and geospatial shift. However, the counterfactuals that are generated suffer from a much higher cost of change regarding state-of-the art counterfactual generation methods <ref type="bibr" target="#b14">[15]</ref>. To address this issue they propose to solve an optimization problem that includes a density constraint <ref type="bibr" target="#b0">[1]</ref>. They empirically show that having a counterfactual that lies in a dense area has the effect of improving the robustness. Laugel et al. <ref type="bibr" target="#b7">[8]</ref> pointed out that such a type of robustness issue cannot solely be attributed to the explainer, but also arises from the decision boundary of the classifier, thus increasing the problem complexity. Robustness to counterfactual input changes refers to the ability of a counterfactual explanation to remain valid when small feature changes are applied (two similar counterfactuals should have the same predicted class). In this context, Pawelcyk et al. <ref type="bibr" target="#b14">[15]</ref> presented PROBE a framework to produce robust counterfactuals that is based on an optimization problem. This framework aims to find a trade-off between two criteria that are the recourse invalidation rate and the proximity, i.e. the distance between the counterfactual and the example to explain. From their side, Maragno et al. <ref type="bibr" target="#b8">[9]</ref> introduced an adversarial robust approach that generates counterfactuals that remain valid in an uncertainty set, meaning that for a given example to explain, all the solutions in the set are valid counterfactuals. This approach works for non-differentiable model unlike PROBE. However there is no trade-off between the recourse invalidation rate and the proximity as all the counterfactuals in the uncertainty set are valid. In such a scenario, the robustness constraint cannot be relaxed, then allowing the generation of counterfactuals that are far from the example to explain. Our approach, CROCO, is part of this category of methods. It is inspired by the PROBE framework, and improves its limitations. Indeed, the major criticism that we can make to PROBE is that the guarantees in terms of robustness that it offers to the user are completely dependent on the quality of their estimator (i.e. the guarantee is based on a recourse invalidation rate approximation rather than the true recourse invalidation rate). Our method introduces a new optimiza-tion problem that is proved to induce an almost-sure upper bound on the true recourse invalidation rate. This leads to a significant improvement in the trade-off between the robustness of the counterfactual and the proximity with the example to explain.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Problem statement</head><p>In this section, we define some notations related to the generation of counterfactuals, and we formalize the robustness of counterfactual generation by introducing the notion of recourse invalidation rate.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Generation of counterfactuals</head><p>We consider the generation of counterfactuals for a binary classifier. Let X ⊆ R n represents the n-dimensional feature space. A binary classifier is a function h : X → Y where Y = {0, 1}. We assume that the classification is obtained from a probabilistic prediction i.e. a function f : X → [0, 1] that returns p which is the predicted probability for the class 1. Then, the predicted class is the most likely class according to p. For a given example x, h(x) = g • f (x) where g : [0, 1] → Y is a function that returns the predicted class from the probability vector. We take g(u) = 1 &gt;t (u), where t is the decision threshold. 1 &gt;t (u) equals 1 if u &gt; t and 0 otherwise. In this article, we do post-hoc counterfactual generation, meaning that f (and thus h) are given. And for a given example to explain x ∈ X , whose decision is h(x), we want to generate a counterfactual x ∈ X . A counterfactual is a new example close to the example to explain x, and with a different prediction, i.e. h(x) ̸ = h(x). If it is true that h (x) ̸ = h (x), then x is said to be valid. A counterfactual x is also seen as a change to apply to x: x = x + δ where δ ∈ R n . Thus, a counterfactual is associated to a small change δ that modifies the decision returned by h. Generating a counterfactual is basically solving the following optimization problem:</p><formula xml:id="formula_0">min δ ℓ (f (x + δ) , 1 -h(x)) + λ ∥δ∥ 1<label>(1)</label></formula><p>where ℓ : [0, 1] 2 → R + quantifies the distance between the predicted probability, f (x), and 1 -h(x) that is the opposite of the predicted class for example x.</p><p>For instance, Wachter et al. suggested ℓ as the L 2 distance, so as to produce counterfactuals that are close to the desired decision <ref type="bibr" target="#b21">[22]</ref>. The other term in the optimization problem, constraints the change δ applied to the example x to be small.</p><p>In what follows, we will focus specifically on the generation of counterfactuals in the case of instances that have received a negative decision (which corresponds to instances predicted as class 0). This choice has no limitation and is motivated by the fact that the majority of robustness methods are defined in a recourse context <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b17">18]</ref> where the goal is to provide explanations only for negatively predicted instances. We will also assume that the classifier f is differentiable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Recourse invalidation rate</head><p>In order to quantify the robustness of the counterfactual to an input perturbation, the notion of recourse invalidation rate has been introduced by Pawelczyk et al. <ref type="bibr" target="#b14">[15]</ref>.</p><p>Definition 1 (Recourse invalidation rate). The recourse invalidation rate for a counterfactual x, of an example x predicted as class 0 can be expressed as:</p><formula xml:id="formula_1">Γ (x; p ε ) = E ε∼pϵ [1 -h (x + ε)] where ε ∈ R n is a random variable that follows a probability distribution p ε . Since h (x + ε) ∈ {0, 1}, it ensues Γ (x; p ε ) ∈ [0, 1].</formula><p>Assuming p ε is centered, then p ε defines a region around a counterfactual x for similar counterfactuals x + ε. Intuitively, Γ (x; p ε ) gives the rate of similar counterfactuals that are not valid, i.e. that belong to class 0. Thus, the lower Γ (x; p ε ), the more robust is the counterfactual. If Γ (x; p ε ) = 0, the counterfactual is considered perfectly robust, given that all the perturbed counterfactuals result in positive outcomes (i.e., there are all predicted as class 1). However, if Γ (x; p ε ) = 1, the counterfactual is not at all considered robust, since no noisy counterfactuals lead to positive outcomes (i.e., there are all predicted as class 0).</p><p>Figure <ref type="figure">1</ref> illustrates the intuition of the recourse invalidation rate. Γ (x; p ε ) can be seen as the surface of the neighborhood that overlaps the region, split by the decision frontier, on the side of the example. This neighborhood represents the perturbations on the counterfactuals that we would like to accept without changing its validity. The Figure also shows that finding a robust counterfactual requires to make a trade-off between the robustness and the magnitude of the change.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">The PROBE framework for generating robust counterfactuals</head><p>Pawelczyk et al. <ref type="bibr" target="#b14">[15]</ref> have developed a framework named PROBE that generates robust counterfactuals regarding the recourse invalidation rate. It adapts the minimization problem of equation 1 by adding a new term that enforces the recourse invalidation rate to be under a target value Γ t . This target value is chosen by the user. More formally, generating a counterfactual relies on solving the following minimization problem:</p><formula xml:id="formula_2">min δ max [Γ (x + δ; p ε ) -Γ t , 0] + ℓ (f (x + δ) , 1 -h(x)) + λ ∥δ∥ 1<label>(2)</label></formula><p>There are some difficulties with the additional constraint on recourse invalidation rate. Indeed, the true value of Γ can not be evaluated in practice. Then, PROBE proposes a Monte-Carlo estimator of Γ . This means that it is estimated by computing the mean of a sample of perturbations in p ε :</p><formula xml:id="formula_3">Γ (x; K, p ε ) = 1 K K k=1 (1 -h (x + ε k ))<label>(3)</label></formula><p>Fig. <ref type="figure">1</ref>. Illustration of the recourse invalidation rate with a uniform distribution pε (dashed-red circle). The recourse invalidation rate is figured out by the area of the region in red. In (1) the counterfactual has a low robustness and is at a low distance from the example. In (2) the counterfactual has a medium robustness and is at a medium distance, and in (3) the counterfactual has a perfect robustness but is far from the example (large distance).</p><p>Fig. <ref type="figure">2</ref>. Illustration of the potential problem with PROBE. The red region illustrates the true recourse invalidation rate (see Figure <ref type="figure">1</ref>) while the green region illustrates the approximated recourse invalidation rate through the approximation of the red region. In this case, the approximation under-estimates the red region and misleadingly encourages finding a x that would break the robustness constraint.</p><p>However, Γ is non-differentiable, because h(x) = g • f (x) and g(u) = 1 &gt;t . Then, it can not be part of a loss of an optimization problem. To overcome this limitation, the authors proposed a first-order approximation of the true recourse invalidation rate Γ in the context of a Gaussian distribution noise p ε = N (0, σI), named ΓPROBE .</p><p>Then, the optimization algorithm solves the problem in eq. 2, replacing Γ by ΓPROBE and stops when the approximation of recourse invalidation rate is under the target value, i.e. when ΓPROBE ( x; p ε ) ≤ Γ t .</p><p>Thus, for a given counterfactual x returned by PROBE, the user is guaranteed that ΓPROBE (x; p ε ) ≤ Γ t . However, this means that the guarantee depends on the quality of the estimator. Indeed, it is possible to generate a counterfactual where ΓPROBE (x; p ε ) ≤ Γ t ≤ Γ (x; p ε ) which would then violate the user-selected guarantee. The intuition behind this situation is depicted in Figure <ref type="figure">2</ref>.</p><p>To sum up, PROBE has two limitations: 1) It offers users a guarantee based on the recourse invalidation rate approximation rather than the true recourse invalidation rate; 2) the approximation applies only for Gaussian distribution of counterfactual perturbation. This makes the approach not applicable to dataset with categorical attributes.</p><p>Our contribution overcomes the first limitation by introducing a new estimator that is proved to induce an almost-sure upper bound on the true recourse invalidation rate. Furthermore, our approach is independent to the noise distribution, thus enabling the use of various noise distributions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Our contribution</head><p>In this section, we present our method, named CROCO standing for Cost-efficient RObust COunterfactuals. It improves the generation of robust counterfactuals according to the recourse invalidation rate.</p><p>This method, inspired from PROBE, introduces a new robustness term to the optimization problem presented in Equation <ref type="formula" target="#formula_0">1</ref>. This term is based on an upper-bound of the recourse invalidation rate.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">An upper bound of the recourse invalidation rate</head><p>As it is not feasible to derive a closed-form expression of Γ without making any assumption about the noise distribution, and given that Γ is not differentiable, our idea is to compute an upper-bound of Γ .</p><p>Let x be a counterfactual for an example x ∈ X , then we define the soft recourse invalidation rate, Θ(x) by:</p><formula xml:id="formula_4">Θ(x; p ε ) = E ε∼pε [1 -f (x + ε)] .</formula><p>The proposition 1 states that the soft recourse invalidation rate, Θ, induces an upper-bound of the recourse invalidation rate, Γ . Proposition 1. <ref type="foot" target="#foot_0">4</ref> Let t ∈ [0, 1] be a decision threshold and x be a counterfactual for an example x ∈ X , an upper bound of the true recourse invalidation rate is given by:</p><formula xml:id="formula_5">Γ (x; p ε ) ≤ Θ (x; p ε ) (1 -t)<label>(4)</label></formula><p>Similarly to Γ , Θ can not be evaluated directly. However, we can use the following Monte-Carlo estimator, where K is the number of random samples:</p><formula xml:id="formula_6">Θ (x; K, p ε ) = 1 K K k=1 (1 -f (x + ε k ))<label>(5)</label></formula><p>This quantity can be seen as the mean predicted probability for class 0, computed on perturbed samples that are randomly drawn from the p ϵ distribution. The proposed estimator is close to the recourse invalidation rate estimation outlined in equation 3, but it differs in that it is differentiable as a composition of differentiable functions, thus can be included in an objective function. Moreover, the proposition 2 shows that our estimator, Θ, defines an almostsure upper bound of the true recourse invalidation rate. This means that m+ Θ 1-t has a high probability to be an upper-bound of Γ . Proposition 2. Let t ∈ [0, 1] be a decision threshold, p ε a noise distribution, x be a counterfactual for an example x ∈ X , then an almost-sure upper-bound of the recourse invalidation rate is given by:</p><formula xml:id="formula_7">P Γ (x; p ε ) ≤ m + Θ (x; K, p ε ) 1 -t ≥ 1 -exp -2m 2 K (6)</formula><p>where m &gt; 0 and K is the number of random samples.</p><p>With a high number of random samples and a given value of m, the exponential term of proposition 2 can be arbitrarily small. Then for a given value of our estimator Θ (x; K, p ε ), we have almost surely that the true recourse invalidation rate will be in the worst case equals to m + Θ (x; K, p ε ) 1 -t . It ensues that if we enforce m + Θ (x; K, p ε ) 1 -t to be lower than a given threshold Γt , then we are almost-sure that the true recourse invalidation rate is lower than Γt , i.e. that the counterfactual is more robust than the given threshold. Note that m ∈ R &gt;0 is a parameter that defines the tightness of the upperbound. The lower m, the better the upper-bound. In return, low m requires a higher K (i.e. more computational resource) to keep the confidence in the bound. Section A.2 in supplementary material provides a table to choose the values of m and K with respect to the desired level of confidence.</p><p>For instance, with K = 500 and m = 0.1, and t = 0.5, the inequation of the proposition 2 gives:</p><formula xml:id="formula_8">P Γ (x) ≤ 0.2 + 2 Θ (x) ≥ 0.999 (7)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Generate robust counterfactuals</head><p>We propose a minimization problem for the generation of robust counterfactuals according to the recourse invalidation rate. Given a neighborhood distribution p ε , a number of samples K, a tightness value m &gt; 0 and a target upper-bound Γt , a counterfactual x = x + δ is found by minimizing the following objective function:</p><formula xml:id="formula_9">min δ Θ (x + δ; K, p ε ) + m 1 -t -Γt 2 Robustness + ℓ (f (x + δ) , 1 -h(x)) Validity + λ ∥δ∥ 1 Proximity (8)</formula><p>Algorithm 1 CROCO optimization for counterfactual generation</p><formula xml:id="formula_10">Input: x s.t. f (x) &lt; t, f , λ &gt; 0, α, Γt &gt; 0, K,pε Output: x + δ δ ← 0; Compute Θ (x + δ; K, pε) while f (x + δ) &lt; t and m+ Θ(x+δ;K,pε) 1-t &gt; Γt do δ ← δ -α • ∇ δ L CROCO (x + δ; Θt, pε, λ) ▷ From equation 8 Update Θ (x + δ; K, pε) end while Return: x + δ</formula><p>The last two terms implement the classical trade-off for counterfactual generation. Indeed, the second term pushes the counterfactual class toward a class that differs from the example class (if h(x) = 0 then we want h(x) = 1), while the last term minimizes the distance between the counterfactual and the example to explain.</p><p>The first term encourages our new estimator to be close to a target value Γt , i.e. the target upper-bound of the recourse invalidation rate. This pushes to choose a counterfactual that has an upper bound close to the objective.</p><p>Algorithm 1 describes the optimization process for CROCO. Gradient steps are performed until the counterfactual predicted class is flipped (f (x + δ) ≥ t), and the value of the upper-bound m+ Θ(x+δ;K,pε) 1-t is below the target value Γt . CROCO has several benefits, it allows the user to generate counterfactuals with almost surely a minimal robustness, and this agnostically to the noise distribution. Moreover, our optimization problem relies on an almost-sure upper bound of the true recourse invalidation rate instead of relying on an approximation as Pawelcyk et al. did with PROBE <ref type="bibr" target="#b14">[15]</ref>. Our intuition is that this will in practice improve the trade-off between proximity and robustness.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments and results</head><p>We have divided our experiments into two sections. After experimentally confirming that our approach preserves the validity of the counterfactuals, the purpose of the first section is to demonstrate empirically that CROCO provides an effective management of the trade-off between proximity and robustness in comparison to PROBE. In the second section, we demonstrate experimentally that the counterfactuals returned by CROCO exhibits a lower degree of invalidation with respect to the user-defined target than PROBE do.</p><p>First of all, we describe the datasets that we used for evaluation, along with the metrics we employed as well as the predictive model details.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Experimental setting</head><p>For a fair comparison, we used the CARLA library <ref type="bibr" target="#b12">[13]</ref>, which was also used for evaluating PROBE. It contains three binary classification datasets: Adult, Give Me Some Credit (GSC), and COMPAS. These datasets contain both numerical and categorical features. Both numerical and categorical variables are used to train the classifier, but the counterfactuals are generated by modifying only the numerical variables. The proportion of categorical variables for each dataset are respectively 3/7, 1/12 and 25/40. Additional details about these datasets are available in the section A.4 of the supplementary material. For every dataset, the classification model, f , is the fully connected neural network implemented in the CARLA library <ref type="foot" target="#foot_1">5</ref> . It is composed of 50 hidden layers and ReLU activation functions.</p><p>We used for evaluation the following metrics:</p><p>Validity A counterfactual x of an example x is valid if the classification model predicts different classes for x and x <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b11">12]</ref>. Formally:</p><formula xml:id="formula_11">Validity = 0, if f (x) = f (x) 1, if f (x) ̸ = f (x)</formula><p>The validity measure lies in [0, 1]. The higher it is, the better. Distance The distance is the L 1 distance between an example, x and its counterfactual, x <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b21">22]</ref>.</p><formula xml:id="formula_12">Distance = ∥x -x∥ 1 = ∥δ∥ 1</formula><p>A low value indicates fewer changes of features to apply to the original example to obtain the counterfactual. As the distance decreases, the proximity increases. In the context of counterfactual generation, we assume that the lower the distance, the more actionable the counterfactual, the better. Recourse invalidation rate We used Γ (see equation 3) to evaluate recourse invalidation rate, i.e. the robustness of the counterfactual. This value indicates the risk to have an invalid counterfactual in case the counterfactual is slightly changing wrt to the automatically recommended counterfactual. The lower, the better. The recourse invalidation rate makes the assumption of a neighborhood represented by a distribution, p ε . CROCO makes no hypothesis on this distribution but PROBE requires a Gaussian distribution. For the sake of fairness, we use a centered Gaussian distribution with a parameterized variance σ for the two methods.</p><p>For each dataset, we run PROBE with σ 2 ∈ {0.005, 0.01, 0.015, 0.02} and Γ t ∈ {0.05, 0.10, 0.15, 0.2, 0.25, 0.3, 0.35}. Regarding the setting of CROCO, we choose K = 500, m = 0.1, t = 0.5. λ is found through an iterative procedure that is described in section A.5.2 of supplementary material. For each dataset, we run CROCO with the same parameters as PROBE: σ 2 ∈ {0.005, 0.01, 0.015, 0.02} and Γt ∈ {0.05, 0.10, 0.15, 0.2, 0.25, 0.3, 0.35}.</p><p>We also include the approach of Wachter et al. <ref type="bibr" target="#b21">[22]</ref> (referred to as Wachter ) in our experiment. This counterfactual generation method establishes a baseline for recourse invalidation rate. In our experiments, we generated 500 counterfactuals for each dataset and each parameterized method. We collected their recourse invalidation rate, distance and validity, that are discussed in the following.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Comparisons between PROBE and CROCO</head><p>In this section, the quality of the counterfactuals generated using CROCO, PROBE and Watcher is compared.</p><p>First of all, Watcher and CROCO achieves a perfect validity for all datasets. PROBE achieved a perfect validity on all datasets, except for two counterfactual sets, that corresponds to the COMPAS dataset where σ 2 = 0.005 and Γ t = 0.3 and also the GSC dataset where σ 2 = 0.02 and Γ t = 0.05. As a consequence, in the following, we focus the analysis on the trade-off between the distance and the recourse invalidation rate. The section A.3.1 of the supplementary material contains details regarding the validity obtained for each dataset, and counterfactual sets that are generated.</p><p>Figure <ref type="figure" target="#fig_0">3</ref> compares Watcher, PROBE and CROCO regarding the distance and recourse invalidation rate on the three different datasets. Each point of a given curve corresponds to the mean recourse invalidation rate and the mean distance that is obtained from CROCO or PROBE by fixing a target value. Note that Watcher has only one point as it has no recourse invalidation rate target parameter. The standard-deviation values are provided in section A.3.2 of supplementary material. Note that for a given curve, the points are linked by order of increasing target value.</p><p>For the GSC dataset, CROCO achieves both smaller distances (higher proximities) and lower recourse invalidation rates compared to PROBE, regardless of the value of σ 2 . The same conclusion can be drawn for the COMPAS dataset, except for σ 2 = 0.005 where CROCO achieves smaller recourse invalidation rates but at the cost of higher distances.</p><p>Regarding the Adult dataset, we observe that PROBE is unstable, as it can produce solutions with higher recourse invalidation rate than the target fixed by the user (where Γ ≥ Γ t ). On the other hand, CROCO is stable and achieves both smaller distances (higher proximities) and lower recourse invalidation rates. We also noticed that on all the datasets, distance values increase when σ 2 increased, thus confirming the presence of a trade-off between the two quantities.</p><p>When solutions are closely clustered together in terms of mean distances, both PROBE and CROCO exhibit similar standard deviation values. However, when solutions are more widely dispersed, PROBE tends to have higher standard deviation values compared to CROCO (see section A.3.2 of supplementary material).</p><p>We observed that for all datasets and values of σ 2 , PROBE and CROCO outperform Wachter in terms of recourse invalidation rates. The only exception is the Adult dataset when Γ t = 0.35, where PROBE produces higher recourse invalidation rates due to instability issues.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Target invalidation study</head><p>For each counterfactual that is obtained from PROBE or CROCO, we computed the recourse invalidation rate and compared it with the targeted recourse invalidation rate. 6 The results are provided in Figure <ref type="figure">4</ref>. The graphics figure out the diagonal representing the exact match between the targeted and the recourse invalidation rate. All points that are above this diagonal correspond to counterfactuals that do not achieve the robustness requested by the user. We notice that with PROBE, the recourse invalidation rates frequently exceed the target Comparison between targeted recourse invalidation rate and recourse invalidation rate. Each column corresponds to a dataset and each line to a value of σ 2 ∈ {0.005, 0.01, 0.015, 0.02}. In each subplot, the value of σ 2 is fixed. Each point corresponds to a counterfactual, on the x-axis is presented the target recourse invalidation rate for the counterfactual, and on the y-axis the recourse invalidation rate that is computed.</p><p>fixed by the user. It illustrates that the approximation of Γ made by PROBE is too loose. In contrast, for CROCO, the recourse invalidation rates are typically lower, indicating that the user-specified target is less invalidated. We computed the upper bound value derived in proposition 2 for each counterfactual obtained from CROCO.</p><p>Figure <ref type="figure">5</ref> of section A.3.3 of the supplementary material illustrates the evolution of the upper bound value ( m+ Θ 1-t ) with regard to the recourse invalidation rate for different values of σ 2 . Our analysis show that the theoretical bound is not violated. This means that even in cases where CROCO failed to find a solution that matches the user target (i.e., where m+ Θ 1-t &gt; Γt ), we can still provide the user a guarantee on the true recourse invalidation rate. This guarantee is based on the value of Θ that is obtained at the end of the optimization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>In this paper, we introduce CROCO, a novel framework for generating counterfactuals that are robust to input changes. A robust method guarantees that the slightly perturbed counterfactual is still valid. Our approach leverages a new estimator that provides a theoretical guarantee on the true recourse invalidation rate of the generated counterfactuals. Through experiments comparing CROCO to the state-of-the-art PROBE method, we demonstrate that our approach achieves a better trade-off between recourse invalidation rate and proximity, while also leading to less invalidation regarding the user-specified target. While these initial results are promising, it is necessary to evaluate CROCO on a larger number of datasets to confirm the robustness of the performance obtained. Moving forward, we plan to extend the capabilities of CROCO by adapting it to handle categorical variables. Since our approach is independent to the noise distribution, it seems reasonably possible to generate robust counterfactuals for data with both numerical and categorical variables. CROCO is implemented in the CARLA framework and will be soon available for practical usage.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 3 .</head><label>3</label><figDesc>Fig.3. Trade-off between recourse invalidation rate and distance with Gaussian distribution noises. Each column corresponds to a dataset and each line to a value of σ 2 ∈ {0.005, 0.01, 0.015, 0.02}. In each subplot the value of σ 2 is fixed. Each point of a corresponds to a mean recourse invalidation rate and a mean distance for a given target, we have target ∈ {0.05, 0.10, 0.15, 0.2, 0.25, 0.3, 0.35}. The points are connected by target order.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>Fig. 4. Comparison between targeted recourse invalidation rate and recourse invalidation rate. Each column corresponds to a dataset and each line to a value of σ 2 ∈ {0.005, 0.01, 0.015, 0.02}. In each subplot, the value of σ 2 is fixed. Each point corresponds to a counterfactual, on the x-axis is presented the target recourse invalidation rate for the counterfactual, and on the y-axis the recourse invalidation rate that is computed.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>In the context of slightly changed training settings, Black et al.<ref type="bibr" target="#b1">[2]</ref> achieved robust counterfactual explanations with a regularization method based upon a K-Lipschitz constant.</figDesc><table><row><cell>Robustness to input perturbations refers to how counterfactuals explana-</cell></row><row><cell>tions are sensitive to slight input changes. According to Dominguez-Olmedo</cell></row><row><cell>et al. [4], a counterfactual is said robust if small changes in the example</cell></row><row><cell>to explain result in valid counterfactuals. They proposed an optimization</cell></row><row><cell>problem that applies to linear models and neural networks to generate ro-</cell></row><row><cell>bust counterfactuals in this context. For Artelt et al. [1] robustness means</cell></row><row><cell>that two examples that are close, must result in two similar counterfactuals.</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_0"><p>All proofs are provided in Section A.1 of supplementary material.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_1"><p>Function carla.models.catalog.MLModelCatalog of the CARLA library.</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Evaluating robustness of counterfactual explanations</title>
		<author>
			<persName><forename type="first">A</forename><surname>Artelt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Vaquet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Velioglu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Hinder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Brinkrolf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Schilling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Hammer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Symposium Series on Computational Intelligence (SSCI)</title>
		<meeting>the Symposium Series on Computational Intelligence (SSCI)</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="1" to="09" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Consistent counterfactuals for deep models</title>
		<author>
			<persName><forename type="first">E</forename><surname>Black</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Fredrikson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Learning Representations (ICLR)</title>
		<meeting>the International Conference on Learning Representations (ICLR)</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note>OpenReview.net</note>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Nice: an algorithm for nearest instance counterfactual explanations</title>
		<author>
			<persName><forename type="first">D</forename><surname>Brughmans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Leyman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Martens</surname></persName>
		</author>
		<idno>arXiv v2</idno>
		<ptr target="https://arxiv.org/abs/2104.07411" />
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">On the adversarial robustness of causal algorithmic recourse</title>
		<author>
			<persName><forename type="first">R</forename><surname>Dominguez-Olmedo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">H</forename><surname>Karimi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Schölkopf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 39th International Conference on Machine Learning (ICML)</title>
		<meeting>the 39th International Conference on Machine Learning (ICML)</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">162</biblScope>
			<biblScope unit="page" from="5324" to="5342" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">The robustness of counterfactual explanations over time</title>
		<author>
			<persName><forename type="first">A</forename><surname>Ferrario</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Loi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Access</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="82736" to="82750" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Counterfactual explanations and how to find them: literature review and benchmarking</title>
		<author>
			<persName><forename type="first">R</forename><surname>Guidotti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Data Mining and Knowledge Discovery</title>
		<imprint>
			<biblScope unit="page" from="1" to="55" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">VCNet: A self-explaining model for realistic counterfactual generation</title>
		<author>
			<persName><forename type="first">V</forename><surname>Guyomard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Fessant</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Guyet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases (ECML/PKDD)</title>
		<meeting>the European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases (ECML/PKDD)</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="437" to="453" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<author>
			<persName><forename type="first">T</forename><surname>Laugel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Lesot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Marsala</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Detyniecki</surname></persName>
		</author>
		<idno>arXiv</idno>
		<ptr target="https://arxiv.org/abs/1906.04774" />
		<title level="m">Issues with post-hoc counterfactual explanations: a discussion</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<author>
			<persName><forename type="first">D</forename><surname>Maragno</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kurtz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">E</forename><surname>Röber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Goedhart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">I</forename><surname>Birbil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Hertog</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2301.11113" />
		<title level="m">Finding regions of counterfactual explanations via robust optimization</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">A survey on the robustness of feature importance and counterfactual explanations</title>
		<author>
			<persName><forename type="first">S</forename><surname>Mishra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Dutta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Magazzeni</surname></persName>
		</author>
		<idno>arXiv (v2</idno>
		<ptr target="https://arxiv.org/abs/2111.00358" />
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Explaining machine learning classifiers through diverse counterfactual explanations</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">K</forename><surname>Mothilal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Tan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the conference on Fairness, Accountability, and Transparency (FAccT)</title>
		<meeting>the conference on Fairness, Accountability, and Transparency (FAccT)</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="607" to="617" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A framework and benchmarking study for counterfactual generating methods on tabular data</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M B</forename><surname>De Oliveira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Martens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied Sciences</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">16</biblScope>
			<biblScope unit="page">7274</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">CARLA: A python library to benchmark algorithmic recourse and counterfactual explanation algorithms</title>
		<author>
			<persName><forename type="first">M</forename><surname>Pawelczyk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bielawski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Van Den Heuvel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Richter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Kasneci</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Neural Information Processing Systems (NeurIPS) -Track on Datasets and Benchmarks</title>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page">17</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Learning model-agnostic counterfactual explanations for tabular data</title>
		<author>
			<persName><forename type="first">M</forename><surname>Pawelczyk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Broelemann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Kasneci</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of The Web Conference (WWW&apos;20)</title>
		<meeting>The Web Conference (WWW&apos;20)</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="3126" to="3132" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Probabilistically robust recourse: Navigating the trade-offs between costs and robustness in algorithmic recourse</title>
		<author>
			<persName><forename type="first">M</forename><surname>Pawelczyk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Datta</surname></persName>
		</author>
		<author>
			<persName><surname>Van-Den</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Heuvel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Kasneci</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Lakkaraju</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Learning Representations (ICLR)</title>
		<meeting>the International Conference on Learning Representations (ICLR)</meeting>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note>OpenReview.net</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Face: feasible and actionable counterfactual explanations</title>
		<author>
			<persName><forename type="first">R</forename><surname>Poyiadzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Sokol</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Santos-Rodriguez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>De Bie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Flach</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI/ACM Conference on AI, Ethics, and Society</title>
		<meeting>the AAAI/ACM Conference on AI, Ethics, and Society</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="344" to="350" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Algorithmic recourse in the wild: Understanding the impact of data and model shifts</title>
		<author>
			<persName><forename type="first">K</forename><surname>Rawal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Kamar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Lakkaraju</surname></persName>
		</author>
		<idno>arXiv v3</idno>
		<ptr target="https://arxiv.org/abs/2012.11788" />
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Towards robust and reliable algorithmic recourse</title>
		<author>
			<persName><forename type="first">S</forename><surname>Upadhyay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Lakkaraju</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="16926" to="16937" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Actionable recourse in linear classification</title>
		<author>
			<persName><forename type="first">B</forename><surname>Ustun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Spangher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the conference on Fairness, Accountability, and Transparency (FAccT)</title>
		<meeting>the conference on Fairness, Accountability, and Transparency (FAccT)</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="10" to="19" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Interpretable counterfactual explanations guided by prototypes</title>
		<author>
			<persName><forename type="first">A</forename><surname>Van Looveren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Klaise</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Machine Learning and Knowledge Discovery in Databases (ECML/PKDD)</title>
		<meeting>the European Conference on Machine Learning and Knowledge Discovery in Databases (ECML/PKDD)</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="650" to="665" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">On the robustness of sparse counterfactual explanations to adverse perturbations</title>
		<author>
			<persName><forename type="first">M</forename><surname>Virgolin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Fracaros</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">316</biblScope>
			<biblScope unit="page">103840</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Counterfactual explanations without opening the black box: Automated decisions and the GDPR</title>
		<author>
			<persName><forename type="first">S</forename><surname>Wachter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">D</forename><surname>Mittelstadt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Russell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Harvard Journal of Law and Technology</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="841" to="887" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
