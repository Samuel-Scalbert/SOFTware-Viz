<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="fr">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">DfAnalyzer: Runtime dataflow analysis tool for Computational Science and Engineering applications</title>
				<funder>
					<orgName type="full">CNPq</orgName>
				</funder>
				<funder>
					<orgName type="full">CAPES</orgName>
				</funder>
				<funder ref="#_vwprPEa">
					<orgName type="full">FAPERJ</orgName>
				</funder>
				<funder>
					<orgName type="full">Inria (SciDISC and HPDaSc associated teams)</orgName>
				</funder>
				<funder>
					<orgName type="full">MCTI/RNP-Brazil)</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Vítor</forename><surname>Silva</surname></persName>
							<email>silva@cos.ufrj.br</email>
						</author>
						<author>
							<persName><forename type="first">Vinícius</forename><surname>Campos</surname></persName>
							<email>vinicius.s.campos@poli.ufrj.br</email>
						</author>
						<author>
							<persName><forename type="first">Thaylon</forename><surname>Guedes</surname></persName>
							<email>thaylongs@id.uff.br</email>
						</author>
						<author>
							<persName><forename type="first">José</forename><surname>Camata</surname></persName>
							<email>camata@ice.ufjf.br</email>
						</author>
						<author>
							<persName><forename type="first">Daniel</forename><surname>De Oliveira</surname></persName>
							<email>danielcmo@ic.uff.br</email>
						</author>
						<author>
							<persName><forename type="first">Alvaro</forename><forename type="middle">L G A</forename><surname>Coutinho</surname></persName>
							<email>alvaro@nacad.ufrj.br</email>
						</author>
						<author>
							<persName><forename type="first">Patrick</forename><surname>Valduriez</surname></persName>
							<email>patrick.valduriez@inria.fr</email>
						</author>
						<author>
							<persName><forename type="first">Marta</forename><surname>Mattoso</surname></persName>
						</author>
						<author>
							<persName><forename type="first">/</forename><surname>Coppe</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">COPPE</orgName>
								<orgName type="institution">Federal University of Rio de Janeiro</orgName>
								<address>
									<country key="BR">Brazil</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">COPPE</orgName>
								<orgName type="institution">Federal University of Rio de Janeiro</orgName>
								<address>
									<country key="BR">Brazil</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="institution">Fluminense Federal University</orgName>
								<address>
									<country key="BR">Brazil</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="institution">Federal University of Juiz de Fora</orgName>
								<address>
									<country key="BR">Brazil</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff4">
								<orgName type="institution">Fluminense Federal University</orgName>
								<address>
									<country key="BR">Brazil</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff5">
								<orgName type="institution">Federal University of Rio de Janeiro</orgName>
								<address>
									<country key="BR">Brazil</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff6">
								<orgName type="laboratory">LIRMM</orgName>
								<orgName type="institution" key="instit1">Inria</orgName>
								<orgName type="institution" key="instit2">University of Montpellier</orgName>
								<orgName type="institution" key="instit3">CNRS</orgName>
								<address>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff7">
								<orgName type="department">COPPE</orgName>
								<orgName type="institution">Federal University of Rio de Janeiro</orgName>
								<address>
									<country key="BR">Brazil</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff8">
								<orgName type="institution">Snap Inc</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">DfAnalyzer: Runtime dataflow analysis tool for Computational Science and Engineering applications</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">5CA7E819F06E5C59F5CAB7F1E2DE9E17</idno>
					<idno type="DOI">10.1016/j.softx.2020.100592</idno>
					<note type="submission">Submitted on 26 Sep 2020</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-04-12T14:44+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Computational Science and Engineering (CSE)</term>
					<term>dataflow</term>
					<term>provenance</term>
					<term>computational applications</term>
					<term>data analysis</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>à la diffusion de documents scientifiques de niveau recherche, publiés ou non, émanant des établissements d'enseignement et de recherche français ou étrangers, des laboratoires publics ou privés.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="fr">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Motivation and Significance</head><p>Computational Science and Engineering (CSE) applications rely on complex mathematical models that solve problems typically requiring High-Performance Computing (HPC) <ref type="bibr" target="#b0">[1]</ref>. They can be found in biology, chemistry, geology, several engineering areas, etc. They have the exploratory nature of scientific applications, with large-scale executions that can last for a long time, even using HPC. The software ecosystem for developing these applications involves much more than writing scripts or invoking a chain of legacy scientific codes. Computational scientists develop simulation codes that invoke components of CSE frameworks and libraries. For example, components are invoked to provide: (i) support for Partial Differential Equation (PDE) discretization methods in libraries like libMesh, FEniCS, MOOSE, deal.II, GREENS, OpenFOAM; (ii) algorithms for solving numerical problems with parallel computations, in libraries like PETSc, LAPACK, SLEPc; (iii) runtime visualization, like ParaView Catalyst, VisIt, SENSEI; (iv) parallel graph partitioning, like ParMetis, Scotch; and (v) I/O data management like ADIOS.</p><p>Several parameters have to be set to invoke library components from these frameworks. Often, these parameters are difficult to preset, and thus need monitoring and debugging capabilities for runtime fine-tuning. Computational scientists often use in situ visualization techniques to provide information to help control simulations <ref type="bibr" target="#b1">[2]</ref>. By observing a specific pattern, an experienced interpreter can infer that something is not going well in the simulation, deciding to stop it or change parameters, preferably at runtime, resuming or adapting the simulation. However, to do that, the visualization should be complemented with information regarding the evolution of quantities of interest (QoI), such as residual norms, number of linear and nonlinear iterations, often within a specific time window, not just the current values. To obtain this information, even the experienced interpreter has difficulty in identifying the files related to the time window, opening and parsing them to obtain specific values, filtering, aggregating and tracking their evolution.</p><p>DfAnalyzer addresses the problem of generating simulation data for runtime analysis by integrating in situ visualization data with raw data capture in large-scale parallel CSE applications. One of the challenges is to track data evolution because raw data files are distributed and have implicit data relationships in their file contents. DfAnalyzer identifies these data relationships as a dataflow <ref type="bibr" target="#b2">[3]</ref>. This dataflow is the representation of data resulting from the composition of the CSE application programs that execute data transformations. Each data transformation consumes data from one (or more) dataset(s) as input and produces data in one (or more) dataset(s) as output. Each dataset is composed of a set of data elements. Two data transformations can present a data dependency with relation to a dataset, when the data elements are produced by one data transformation and consumed by another. Another challenge is to preserve the autonomy of the CSE execution control code and not compete with resources allocated for running the CSE applications. The main performance challenge is related to capturing data suitable for runtime analysis that does not interfere with CSE execution control and data management. This data capture has to address data modeling, representation, loading, storage, monitoring and steering, while avoiding replicating file contents and keeping the autonomy of binary files like in HDF5 or other formats.</p><p>DfAnalyzer is a lightweight tool for runtime collection, management, monitoring, and analysis of distributed provenance data generated by CSE applications in HPC environments. It uses provenance data <ref type="bibr" target="#b3">[4]</ref> to help registering parameter choices and associating them with intermediate data and results. Provenance enables the traceability and reproducibility of CSE applications and improves data analysis and adaptation at runtime <ref type="bibr" target="#b4">[5]</ref>. The main contribution of DfAnalyzer is to provide dataflow extraction <ref type="bibr" target="#b5">[6]</ref>, with negligible overhead, as an integrated view of QoI with generation traces based on the W3C PROV standard provenance data representation. DfAnalyzer follows a PROV-compliant data model, for representing relationships between datasets manipulated by computational models, which is agnostic concerning the scientific application domain. DfAnalyzer innovates by extracting and relating raw data (e.g., QoI) from heterogeneous distributed files at runtime. It accesses strategic domain data associated to these files using in situ and in transit raw data extraction approaches. It stores dataflow provenance associated to extracted raw data all in a columnar database, which acts as a global map of the CSE application raw data while the application executes. This dataflow map allows for monitoring queries like what is the average error estimate calculated in all iterations so far. User steering actions with DfAnalyzer are discussed in <ref type="bibr" target="#b6">[7]</ref> with a fluid dynamics application built with libMesh <ref type="bibr" target="#b7">[8]</ref>, in a Python script <ref type="bibr" target="#b8">[9]</ref> with FEnICS <ref type="bibr" target="#b9">[10]</ref>, and in <ref type="bibr" target="#b2">[3]</ref> with Spark in a simple business application.</p><p>DfAnalyzer is used with the following methodology <ref type="bibr" target="#b8">[9]</ref>. Initially the user (CSE application developer) interacts with a database expert to help on the modeling of the raw data that should be extracted. The user identifies data items to be tracked and how they relate to other data along their lineage within the CSE code. The database specialist models the data transformation chain using W3C PROV activities and entities with extensions for the raw data items, QoI and parameters. The result of this data modeling is then mapped to a provenance database. The participation of the user in this data modeling saves a lot of time during data analyses and helps on query formulations. The user selectively chooses only application data of interest to be registered, providing a coarse-grain relevant provenance data and selected raw data. Then, DfAnalyzer library calls are inserted in the CSE application as input, output, task and output followed by an extracted data call. DfAnalyzer has a set of RESTful services (and libraries on C++, Python, and Java) to help plugging the calls into the CSE applications. The components that are invoked capture data asynchronously during CSE application execution. They send all insert/update requests to a columnar database system that runs in computing nodes that are different from the CSE application.</p><p>There are three main approaches to provide runtime data analysis for CSE applications. Unlike DfAnalyzer, they all fail at either preserving the autonomy of the CSE execution control code or competing with resources allocated for running the CSE applications. The first approach is the class of HPC workflow systems <ref type="bibr" target="#b10">[11]</ref>. Workflow systems collect provenance data at runtime, but they must be in control of the execution flow and data transfer. This is in conflict with CSE applications, since they call typical libraries for solving numerical problems with parallel execution control, often with parallel visualizations. Provenance data management systems like noWorkflow <ref type="bibr" target="#b11">[12]</ref> and PROV-Template <ref type="bibr" target="#b12">[13]</ref> do preserve the autonomy of CSE execution control, but they compete with computing resources, thus producing a high overhead and do not run in HPC. The third approach provides for data analysis independent from the CSE application, i.e. unlike workflow systems, the same CSE code can run with or without the data analyzer. This is the most similar approach to DfAnalyzer, with solutions like Spade <ref type="bibr" target="#b13">[14]</ref> and ADIOS <ref type="bibr" target="#b14">[15]</ref>. However, they have limited data analysis, because they do not help on extracting raw data or providing a dataflow view with provenance data. Approaches like FastBit <ref type="bibr" target="#b15">[16]</ref> and PostgresRaw <ref type="bibr" target="#b16">[17]</ref> are helpful for accessing and extracting raw data from heterogeneous files, but they operate in post-processing mode and thus are not aware of the implicit dataflow between raw data files, being complementary to DfAnalyzer. We know of no other solution for dataflow analysis at runtime. In <ref type="bibr" target="#b17">[18]</ref>, we present the main open issues for the exploratory runtime scientific data analysis scenarios. DfAnalyzer's user steering support contributes to the process of scientific discovery and explainability by automatically adding provenance, context and relationships to scientific data native formats.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Software Description</head><p>DfAnalyzer assumes that the CSE programs are white or gray boxes, and works as a data profiling tool, similarly to code profilers. DfA-lib is the library invoked by DfAnalyzer calls. As the CSE application executes, DfA-lib extracts raw data and captures provenance data, at key points of the application, to map the dataflows. DfAnalyzer has a component-based architecture <ref type="bibr" target="#b5">[6]</ref>, which allows registering plug-ins for raw data extraction and indexing. As in software engineering, a plug-in refers to the extension of a component behavior or actions so that users can reuse these plug-ins to minimize efforts of developing CSE application data analyses.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Software Architecture</head><p>The DfAnalyzer architecture has three layers (Figure <ref type="figure" target="#fig_0">1</ref>):</p><p>• Storage, which accesses its database and raw data from files manipulated by the application; • Dataflow, which presents the main components for capturing provenance and raw data, and for registering the dataflow implicit in the application; and • Data Analysis, which provides graphical interfaces to ease dataflow monitoring and querying.</p><p>The Storage layer has the database containing selected raw data and the id of binary files consumed and generated by the application as a provenance dataflow. Execution data related to provenance data are also captured. The database stores both raw data extracted from files and the references to these files, which are registered as pointers (e.g., URIs or file paths).</p><p>The Dataflow layer has four components: Provenance Data Extractor (PDE), Raw Data Extractor (RDE), Raw Data Indexer (RDI), and Query Interface (QI). PDE captures provenance and domain data, RDE invokes ad-hoc programs to extract raw data from files, and RDI applies indexing techniques to minimize the data loading cost in DfAnalyzer's database and improve the performance of query processing on scientific data. QI translates query requests generated by the Query Dashboard, according to the user interactions, to a database query specification. This query runs on DfAnalyzer's database system (currently MonetDB), accessing when necessary, the file contents.</p><p>The Data Analysis layer works as a dashboard with Dataflow Viewer (DfViewer) and Query Dashboard (QD). QD provides raw data analysis interacting with QI and presenting the query results in text tables. DfViewer presents a graphical dataflow specification based on the execution of the CSE application. This dashboard shows data transformations, datasets, attributes, and data dependencies of each dataflow specification stored in the database. The gray and black dotted arrows in Figure <ref type="figure" target="#fig_0">1</ref> represent offline and online operations. Offline operations correspond to the dataflow modeling steps based on the inclusion of DfAnalyzer library calls specifying points of provenance capture and raw data extraction/indexing in CSE applications. Thus, these operations take place before the execution starts. Meanwhile, online operations are associated to the provenance capture, raw data extraction/indexing, and query processing executed by DfAnalyzer's components at runtime.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Software Functionalities</head><p>DfAnalyzer has two components for raw data extraction and indexing, and a RESTful web application that receives different kinds of HTTP requests from CSE applications or web browsers. DfAnalyzer implements plug-ins on the RDE and RDI components for raw data extraction and indexing, respectively. Furthermore, HTTP requests trigger RESTful services for capturing provenance data and running queries, which involve the following components of DfAnalyzer: DfViewer, QD, PDE, and QI. Figure <ref type="figure">2</ref> presents an overview of this design and the following subsections describe the implementation of each component.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 2. Design of DfAnalyzer's implementation considering RESTful services and raw data extraction/indexing components.</head><p>RDE and RDI components are responsible to run ad-hoc programs and third-party tools for accessing, parsing, tokenizing, extracting, and, occasionally, indexing relevant contents from data sources, such as raw data files. Each algorithm or solution for raw data extraction or indexing is implemented respectively as a plug-in in RDE or RDI. RDE presents the PROGRAM plug-in that accesses the relevant contents of raw data files by invoking ad-hoc programs developed by the user, while the CSV plug-in extracts data from CSV files.</p><p>DfA-lib calls, inside the CSE application code, send HTTP requests to the Service Controller with a POST method using DfAnalyzer's RESTful web application. There are two body types in these HTTP requests, with prospective and retrospective provenance data <ref type="bibr" target="#b18">[19]</ref>. A request body with prospective provenance data contains information about the dataflow structure of an application and, consequently, it represents a mapping to the dataflow concepts <ref type="bibr" target="#b17">[18]</ref>. By contrast, a request body with retrospective provenance data corresponds to the execution and raw data generated/extracted by the application at runtime.</p><p>More specifically, once the Service Controller receives HTTP requests for provenance capture, it translates them and creates a service for each request. In this case, a service is created for provenance and raw data loading. Then, it is queued in the Service Handler and waits until all previous services are processed by this handler. To run the analytical queries, a service is created by the Service Handler for submitting and running queries on the database using the QI component.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Illustrative Examples</head><p>Figure <ref type="figure">3</ref> shows a fragment of the FEniCS Python code for solving the Cahn-Hilliard equation, a mathematical model from material science. The Cahn-Hilliard equation leads to a prototype of a transient nonlinear multi-physics code.</p><p>Several parameters have to be set to invoke these components, which are very difficult to preset and need monitoring for runtime fine-tuning. Provenance data can help in registering parameter choices with the results. Thus, associating them as a dataflow, as in Figure <ref type="figure">3</ref>(a), can improve both runtime data analysis and fine-tuning. The corresponding dataflow is extracted by inserting DfA-lib calls on the Python script, as shown in Figure <ref type="figure">3</ref>(b).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 3. Finite element solution of Cahn-Hilliard equation with FEniCS-(a) dataflow and (b) code with library calls in colors.</head><p>The DfA-lib calls (input, output, task, and extracted data) register, as a dataflow, mesh information, variational model, solver parameters (as solver tolerances, number of iterations and residual norms) and visualization. Relating these data allows for filtering and directly accessing them. The dataflow is extracted and inserted in the DBMS while the user can steer the execution with queries like "for all converged steps, show the number of iterations, the corresponding residual norms, and the output visualization". With this query result, the user can fine-tune in runtime, the nonlinear solver tolerance to speed-up the simulation without compromising its accuracy.</p><p>In <ref type="bibr" target="#b6">[7]</ref>, DfAnalyzer is used in a real CSE application, built with libMesh, for the finite element parallel adaptive mesh refinement/coarsening simulation of turbidity currents. DfAnalyzer gathered QoI (residual norms, number of linear and nonlinear iterations); extracted data in memory using ParaView Catalyst, such as velocity, pressure and sediment concentration; gathered provenance data; and relating these simulation data from different files in its database. Users observed intermediate data at different points in time, complemented by visualization files to see if the simulation had already all relevant results and could resume or needed more time. If the decision is to continue, they need to reset the maximum time interval, which is also registered in the database. Examples of queries submitted during this execution are: which are the sediment deposits in a region delimited by x in range <ref type="bibr">[9, 13.5]</ref>; what is the elapsed time spent in the different stages of the iterations; show for each time step and for each of its nonlinear/linear iterations, the residual norm and its convergence status (Table <ref type="table" target="#tab_1">1</ref>). Based on these monitoring and debugging analyses, the user was confident to reset some solver parameters without interrupting the simulation run, which reduced the elapsed time in days. Without the dataflows of DfAnalyzer, they would need to find and parse the related files to extract, relate and analyze raw data, possibly after a failed execution, wasting valuable HPC resources. Our GitLab repository<ref type="foot" target="#foot_0">1</ref> documents DfAnalyzer's components, shows DfA-lib installation steps and provides a Docker image with these two CSE examples<ref type="foot" target="#foot_1">2</ref> presented in this section.</p><p>The adoption of a provenance system in CSE depends on how much execution overhead it adds to the application. In DfAnalyzer, this execution overhead depends on the data identified in the simulation code that needs to be tracked. That is, which input and output data values, for each data transformation, should be extracted and registered to be monitored during the execution. Therefore, the added overhead can be defined as the sum of time costs for extracting/indexing these data from raw data files and monitoring the provenance of all data defined by the user. When using DfAnalyzer with several real CSE applications in large scale, the added overhead has been always below 1% <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b20">21]</ref>. In small scale use cases <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b8">9]</ref>, that run for minutes in desktops, this overhead becomes &lt;3%, since data is generated very fast and does not benefit from DfAnalyzer's asynchronous data extraction. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Impact</head><p>The Interoperable Design of Extreme-scale Application Software (IDEAS) <ref type="bibr" target="#b21">[22]</ref> is a family of projects, involving several institutions in the USA, concerned with the complexity of developing software for CSE applications. IDEAS aims at "enabling a fundamentally different attitude to creating and supporting CSE applications" with desirable features like provenance and reproducibility <ref type="bibr" target="#b4">[5]</ref>. libMesh, FEniCS, and ParaView are softwares considered in the IDEAS project. DfAnalyzer models CSE applications as activities and dataflows represented as provenance data in the W3C standard. This generic standard data model helps the user in identifying data and activities of the CSE dataflow regardless of the application domain.</p><p>The DfAnalyzer approach defines a specific software layer for data analysis, in the same way visualization libraries provide specific components for visualization. Encapsulating all data analysis support in one specific library/component, as DfA-lib, makes the application autonomous and data extraction for analyses can always be switched off. The overhead on raw data capture depends on how much data is to be extracted but an in-situ approach avoids data movements and using indexes reduces this overhead. DfAnalyzer contributes to improve developing software for CSE applications because the developer does not have to write logging code for each data analysis. The same data model can be reused, and the databases associated to all the executions can be further analyzed using AI tools to improve CSE parameter settings and finding correlations among distributed data. The DfAlib can complement data systems in other layers like IO libraries, burst buffers and visualization tools.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>Encapsulating all data analytics support in one specific library/component makes the application autonomous and data analyses can always be switched off. There are several advantages of this data analysis approach. First, simulation data is preserved in their format and not fully replicated in the DBMS. Second, data is related among different files while it is being generated, which might be cumbersome after the simulation ends, as in postprocessing approaches. Third, the history of data generation is registered for further analysis or reproduction through provenance, following W3C PROV. Fourth, efficient data management techniques from column-oriented relational DBMS can be used at runtime. Consequently, DfAnalyzer provides a provenance database enriched with quantities of interest (i.e., domain data) in CSE applications that can be queried at runtime and offline.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Figure 1. DfAnalyzer architecture.</figDesc><graphic coords="5,76.77,106.08,460.35,320.22" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="7,86.20,103.99,456.65,256.86" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>RESTful application Programs for raw data extraction Web application</head><label></label><figDesc></figDesc><table><row><cell></cell><cell>HTTP request</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Web Client</cell><cell>3</cell><cell>Web Controller</cell><cell></cell><cell cols="2">Web Page Handler</cell></row><row><cell></cell><cell>Web page</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>Dataflow</cell><cell>Query</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>Viewer</cell><cell>Dashboard</cell></row><row><cell>Application</cell><cell>HTTP request</cell><cell>Service</cell><cell></cell><cell cols="2">Service</cell></row><row><cell>Client</cell><cell>1</cell><cell>Controller</cell><cell></cell><cell cols="2">Handler</cell></row><row><cell cols="2">DfA-lib</cell><cell></cell><cell></cell><cell></cell></row><row><cell>2</cell><cell>invocation Component</cell><cell></cell><cell></cell><cell>REST Service</cell><cell>REST Service</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>Provenance Data Extractor</cell><cell>Query Interface</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">Database</cell></row><row><cell></cell><cell></cell><cell>Raw Data</cell><cell></cell><cell>Raw Data</cell></row><row><cell></cell><cell></cell><cell>Extractor</cell><cell></cell><cell>Indexer</cell></row><row><cell></cell><cell>raw data files</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>Extracted</cell><cell></cell><cell>Indexed</cell><cell>Labels:</cell></row><row><cell></cell><cell></cell><cell>data</cell><cell>URI</cell><cell>data</cell><cell>URI</cell><cell>Control operations Internal operations</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>External operations</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 . Query results for numerical analysis with libMesh to detect possible misbehavior of nonlinear and linear solvers.</head><label>1</label><figDesc></figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>https://gitlab.com/ssvitor/dataflow_analyzer/-/tree/master/library</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>https://gitlab.com/ssvitor/dataflow_analyzer/-/tree/master/applications</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p>This work has been partially funded by <rs type="funder">Inria (SciDISC and HPDaSc associated teams)</rs>, <rs type="funder">CAPES</rs>, <rs type="funder">CNPq</rs>, <rs type="funder">FAPERJ</rs>, and the <rs type="projectName">HPC4E</rs> project (<rs type="grantNumber">EU H2020</rs> and <rs type="funder">MCTI/RNP-Brazil)</rs>. The <rs type="institution">HPC Center</rs> at <rs type="institution">COPPE/ Federal University of Rio de Janeiro</rs> has provided computing and storage resources.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funded-project" xml:id="_vwprPEa">
					<idno type="grant-number">EU H2020</idno>
					<orgName type="project" subtype="full">HPC4E</orgName>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Required Metadata</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Current code version</head></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<author>
			<persName><forename type="first">U</forename><surname>Rüde</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Willcox</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">C</forename><surname>Mcinnes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">D</forename><surname>Sterck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Biros</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H.-J</forename><surname>Bungartz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Corones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Cramer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Crowley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Ghattas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gunzburger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hanke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Harrison</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Heroux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hesthaven</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">K</forename><surname>Jimack</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">E</forename><surname>Jordan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">E</forename><surname>Keyes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">H</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mayer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Meza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">M</forename><surname>Mørken</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">T</forename><surname>Oden</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">R</forename><surname>Petzold</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Raghavan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Shontz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">E</forename><surname>Trefethen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">R</forename><surname>Turner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">V</forename><surname>Voevodin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">I</forename><surname>Wohlmuth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">S</forename><surname>Woodward</surname></persName>
		</author>
		<idno>CoRR. abs/1610.02608</idno>
		<ptr target="http://arxiv.org/abs/1610.02608" />
		<title level="m">Research and Education in Computational Science and Engineering</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">In Situ Methods, Infrastructures, and Applications on High Performance Computing Platforms</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Abbasi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ahrens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Childs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Geveci</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Klasky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Moreland</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>O'leary</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Vishwanath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Whitlock</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">W</forename><surname>Bethel</surname></persName>
		</author>
		<idno type="DOI">10.1111/cgf.12930</idno>
		<ptr target="https://doi.org/10.1111/cgf.12930" />
	</analytic>
	<monogr>
		<title level="j">Computer Graphics Forum</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="577" to="597" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">DfAnalyzer: Runtime Dataflow Analysis of Scientific Applications using Provenance</title>
		<author>
			<persName><forename type="first">V</forename><surname>Silva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">De</forename><surname>Oliveira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Valduriez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mattoso</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Very Large Data Bases</title>
		<meeting><address><addrLine>Rio de Janeiro, Brazil</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Provenance for Computational Tasks: A Survey</title>
		<author>
			<persName><forename type="first">J</forename><surname>Freire</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Koop</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Santos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">T</forename><surname>Silva</surname></persName>
		</author>
		<idno type="DOI">10.1109/MCSE.2008.79</idno>
		<ptr target="https://doi.org/10.1109/MCSE.2008.79" />
	</analytic>
	<monogr>
		<title level="j">Computing in Science and Engineering</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="11" to="21" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<author>
			<persName><forename type="first">D</forename><surname>Bernholdt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Dubey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Heroux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Klinvex</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">C</forename><surname>Mcinnes</surname></persName>
		</author>
		<title level="m">Improving Reproducibility Through Better Software Practices</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Raw Data Queries during Dataintensive Parallel Workflow Execution</title>
		<author>
			<persName><forename type="first">V</forename><surname>Silva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Leite</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Camata</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Oliveira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">L G A</forename><surname>Coutinho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Valduriez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mattoso</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Special Issue on Workflows for Data-Driven Research in the Future Generation Computer Systems Journal</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">In situ visualization and data analysis for turbidity currents simulation</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Camata</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Silva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Valduriez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mattoso</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">L G A</forename><surname>Coutinho</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.cageo.2017.09.013</idno>
		<ptr target="https://doi.org/10.1016/j.cageo.2017.09.013" />
	</analytic>
	<monogr>
		<title level="j">Computers &amp; Geosciences</title>
		<imprint>
			<biblScope unit="volume">110</biblScope>
			<biblScope unit="page" from="23" to="31" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">libMesh : a C++ library for parallel adaptive mesh refinement/coarsening simulations</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">S</forename><surname>Kirk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">W</forename><surname>Peterson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">H</forename><surname>Stogner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">F</forename><surname>Carey</surname></persName>
		</author>
		<idno type="DOI">10.1007/s00366-006-0049-3</idno>
		<ptr target="https://doi.org/10.1007/s00366-006-0049-3" />
	</analytic>
	<monogr>
		<title level="j">Engineering with Computers</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="237" to="254" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Capturing Provenance for Runtime Data Analysis in Computational Science and Engineering Applications</title>
		<author>
			<persName><forename type="first">V</forename><surname>Silva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Souza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Camata</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Oliveira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">L G A</forename><surname>Coutinho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Valduriez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mattoso</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Provenance and Annotation Workshop (IPAW)</title>
		<meeting><address><addrLine>London, UK</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Archive Of Numerical Software, Archive of Numerical Software: The FEniCS Project Version 1</title>
		<author>
			<persName><forename type="first">M</forename><surname>Alnaes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Blechta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hake</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Johansson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Kehlet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Logg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Richardson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ring</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">E</forename><surname>Rognes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">N</forename><surname>Wells</surname></persName>
		</author>
		<idno type="DOI">10.11588/ans.2015.100.20553</idno>
		<ptr target="https://doi.org/10.11588/ans.2015.100.20553" />
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
		<respStmt>
			<orgName>University Library Heidelberg</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A Survey of Data-Intensive Scientific Workflow Management</title>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Pacitti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Valduriez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mattoso</surname></persName>
		</author>
		<idno type="DOI">10.1007/s10723-015-9329-8</idno>
		<ptr target="https://doi.org/10.1007/s10723-015-9329-8" />
	</analytic>
	<monogr>
		<title level="j">Journal of Grid Computing</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="457" to="493" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">noWorkflow: a tool for collecting, analyzing, and managing provenance from python scripts</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">F</forename><surname>Pimentel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Murta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Braganholo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Freire</surname></persName>
		</author>
		<idno type="DOI">10.14778/3137765.3137789</idno>
		<ptr target="https://doi.org/10.14778/3137765.3137789" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the VLDB Endowment</title>
		<meeting>the VLDB Endowment</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="1841" to="1844" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A Templating System to Generate Provenance</title>
		<author>
			<persName><forename type="first">L</forename><surname>Moreau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">V</forename><surname>Batlajery</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">D</forename><surname>Huynh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Michaelides</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Packer</surname></persName>
		</author>
		<idno type="DOI">10.1109/TSE.2017.2659745</idno>
		<ptr target="https://doi.org/10.1109/TSE.2017.2659745" />
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Software Engineering</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="page" from="103" to="121" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Scaling SPADE to</title>
		<ptr target="https://www.usenix.org/conference/tapp16/workshop-program/presentation/gehani" />
	</analytic>
	<monogr>
		<title level="m">8th USENIX Workshop on the Theory and Practice of Provenance (TaPP 16)</title>
		<meeting><address><addrLine>Washington, D.C.</addrLine></address></meeting>
		<imprint>
			<publisher>USENIX Association</publisher>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note>Big Provenance</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Hello ADIOS: the challenges and lessons of developing leadership class I/O frameworks</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Logan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Abbasi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Podhorszki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">Y</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Klasky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Tchoua</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lofstead</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Oldfield</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Parashar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Samatova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Schwan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Shoshani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Wolf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Yu</surname></persName>
		</author>
		<idno type="DOI">10.1002/cpe.3125</idno>
		<ptr target="https://doi.org/10.1002/cpe.3125" />
	</analytic>
	<monogr>
		<title level="j">Concurrency and Computation: Practice and Experience</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="1453" to="1473" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">FastBit: interactively searching massive data</title>
		<author>
			<persName><forename type="first">K</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ahern</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">W</forename><surname>Bethel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Childs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Cormier-Michel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Geddes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Hagen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Hamann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Koegler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lauret</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Meredith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Messmer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Otoo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Perevoztchikov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Poskanzer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Prabhat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rübel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Shoshani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Sim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Stockinger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W.-M</forename><surname>Weber</surname></persName>
		</author>
		<author>
			<persName><surname>Zhang</surname></persName>
		</author>
		<idno type="DOI">10.1088/1742-6596/180/1/012053</idno>
		<ptr target="https://doi.org/10.1088/1742-6596/180/1/012053" />
	</analytic>
	<monogr>
		<title level="j">Journal of Physics: Conference Series</title>
		<imprint>
			<biblScope unit="volume">180</biblScope>
			<biblScope unit="page">12053</biblScope>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">NoDB: efficient query execution on raw data files</title>
		<author>
			<persName><forename type="first">I</forename><surname>Alagiannis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Borovica-Gajic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Branco</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Idreos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ailamaki</surname></persName>
		</author>
		<idno type="DOI">10.1145/2830508</idno>
		<ptr target="https://doi.org/10.1145/2830508" />
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="page" from="112" to="121" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Analyzing related raw data files through dataflows</title>
		<author>
			<persName><forename type="first">V</forename><surname>Silva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Oliveira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Valduriez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mattoso</surname></persName>
		</author>
		<idno type="DOI">10.1002/cpe.3616</idno>
		<ptr target="https://doi.org/10.1002/cpe.3616" />
	</analytic>
	<monogr>
		<title level="j">CCPE</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="2528" to="2545" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Provenance and Scientific Workflows: Challenges and Opportunities</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">B</forename><surname>Davidson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Freire</surname></persName>
		</author>
		<idno type="DOI">10.1145/1376616.1376772</idno>
		<ptr target="https://doi.org/10.1145/1376616.1376772" />
		<imprint>
			<date type="published" when="2008">2008</date>
			<publisher>ACM</publisher>
			<biblScope unit="page" from="1345" to="1350" />
			<pubPlace>New York, NY, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Situ Data Steering on Sedimentation Simulation with Provenance Data</title>
		<author>
			<persName><forename type="first">V</forename><surname>Silva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Camata</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Oliveira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">L G A</forename><surname>Coutinho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Valduriez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mattoso</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Poster Session of Supercomputing Conference</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Keeping track of user steering actions in dynamic workflows</title>
		<author>
			<persName><forename type="first">R</forename><surname>Souza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Silva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Camata</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Coutinho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Valduriez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mattoso</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Future Generation Computer Systems</title>
		<imprint>
			<biblScope unit="volume">99</biblScope>
			<biblScope unit="page" from="624" to="643" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<ptr target="https://ideas-productivity.org" />
		<title level="m">IDEAS (Interoperable Design of Extreme-scale Application Software)</title>
		<imprint/>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
