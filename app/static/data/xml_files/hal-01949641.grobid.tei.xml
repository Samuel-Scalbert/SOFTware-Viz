<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">SEP2P: Secure and Efficient P2P Personal Data Processing</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Julien</forename><surname>Loudet</surname></persName>
							<email>julien@cozycloud.cc</email>
							<affiliation key="aff0">
								<address>
									<settlement>Cozy Cloud</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">INRIA Saclay</orgName>
								<address>
									<country key="FR">France</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution">University of Versailles</orgName>
								<address>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Iulian</forename><surname>Sandu-Popa</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">INRIA Saclay</orgName>
								<address>
									<country key="FR">France</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution">University of Versailles</orgName>
								<address>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Luc</forename><surname>Bouganim</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">INRIA Saclay</orgName>
								<address>
									<country key="FR">France</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution">University of Versailles</orgName>
								<address>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">SEP2P: Secure and Efficient P2P Personal Data Processing</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">182F647A3FB023D9C24D0A4EFF50B36E</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-04-12T14:52+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Personal Data Management Systems are flourishing allowing an individual to integrate all her personal data in a single place and use it for her benefit and for the benefit of the community. This leads to a significant paradigm shift since personal data become massively distributed. In this context, an important issue needed to be addressed is: how can users/applications execute queries and computations over this massively distributed data in a secure and efficient way, relying exclusively on peer-to-peer (P2P) interactions? In this paper, we motivate and study the feasibility of such a pure P2P personal data management system and provide efficient and scalable mechanisms to reduce the data leakage to its minimum with covert adversaries. In particular, we show that data processing tasks can be assigned to nodes in a verifiable random way, which cannot be influenced by malicious colluding nodes. Then, we propose a generic solution which largely minimizes the verification cost. Our experimental evaluation shows that the proposed protocols lead to minimal private information leakage, while the cost of the security mechanisms remains very low even with a large number of colluding corrupted nodes. Finally, we illustrate our generic protocol proposal on three dataoriented use-cases, namely, participatory sensing, targeted data diffusion and more general distributed aggregative queries.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>The time of individualized management and control over one's personal data is upon us. Thanks to smart disclosure initiatives (e.g., BlueButton <ref type="bibr" target="#b8">[9]</ref> and GreenButton in US, MesInfos <ref type="bibr" target="#b15">[16]</ref> in France, Midata <ref type="bibr" target="#b24">[25]</ref> in UK) and new regulations (e.g., the Europe's new General Data Protection Regulation <ref type="bibr" target="#b26">[27]</ref>), users can access their personal data from the companies or government agencies that collected them. Concurrently, Personal Data Management System (PDMS) solutions are flourishing <ref type="bibr" target="#b3">[4]</ref> both in the academic (e.g., Personal Data Servers <ref type="bibr" target="#b0">[1]</ref>, Personal Information Management Systems, Personal Data Stores <ref type="bibr" target="#b13">[14]</ref>, Personal Clouds <ref type="bibr" target="#b19">[20]</ref>) and industry <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b32">33]</ref>. Their goal is to offer a data platform allowing users to easily store and manage into a single place data directly generated by user devices (e.g., quantified-self data, smart home data, photos, etc.) and data resulting from user interactions (e.g., user preferences, social interaction data, health, bank, telecom, etc.). Users can then leverage the power of their PDMS to benefit from their personal data for their own good and in the interest of the community. Thus, the PDMS paradigm holds the promise of unlocking new innovative usages.</p><p>Let us consider three emblematic distributed applications based on large user communities which could greatly benefit from the PDMS paradigm: (1) mobile participatory sensing apps <ref type="bibr" target="#b35">[36]</ref>, in which mobile users produce sensed geo-localized data (e.g., traffic, © 2019 Copyright held by the owner/author(s). Published in Proceedings of the 22nd International Conference on Extending Database Technology (EDBT), <ref type="bibr">March 26-29, 2019</ref>, ISBN XXX-X-XXXXX-XXX-X on OpenProceedings.org. Distribution of this paper is permitted under the terms of the Creative Commons license CC-by-nc-nd 4.0. air quality, noise, health conditions) to compute spatially aggregated statistics benefiting the whole community; (2) subscriptionbased or profile-based data diffusion apps <ref type="bibr" target="#b37">[38]</ref>, in which PDMS users provide preferences or exhibit profiles in order to selectively receive pertinent information; and (3) distributed query processing over the personal data of large sets of individuals <ref type="bibr" target="#b36">[37]</ref>, in which users contribute with their personal data and issue queries over the globally contributed data (e.g., computing recommendations, participative studies).</p><p>However, these exciting perspectives should not eclipse the security issues raised by the PDMS paradigm. Indeed, each PDMS can store potentially the entire digital life of its owner, thereby proportionally increasing the impact of a leakage. Hence, centralizing all users' data into powerful servers is risky since these data servers become highly desirable targets for attackers: huge amounts of personal data belonging to millions of individuals could be leaked or lost as illustrated by the recent massive attacks (e.g., Facebook, Yahoo or Equifax). Besides, such a centralized solution makes little sense in the PDMS context in which data is naturally distributed at the users' side <ref type="bibr" target="#b18">[19]</ref>.</p><p>Alternatively, recent works <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b32">33]</ref> propose to let the user data distributed on personal trustworthy platforms under users' control. Such platforms can be built thanks to the combination of (1) a Trusted Execution Environment (TEE) (i.e., secure hardware such as smart cards <ref type="bibr" target="#b0">[1]</ref> or secure micro-controllers <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b19">20]</ref>, ARM TrustZone <ref type="bibr" target="#b17">[18]</ref>, or Intel SGX <ref type="bibr" target="#b28">[29]</ref>) and (2) specific software (e.g., minimal Trusted Computing Base and information flow control <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b28">29]</ref>). In this paper, we follow this approach and consider that a PDMS is a dedicated personal device that the user possesses and is secured thanks to TEE hardware.</p><p>In addition, as in many academic and commercial approaches <ref type="bibr" target="#b32">[33]</ref>, we assume that the PDMS personal device offers a rather good connectivity and availability like, for instance, home-cloud solutions <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b32">33</ref>] (e.g., a set-top box or a plug computer <ref type="bibr" target="#b3">[4]</ref>). Thus, PDMSs can establish peer-to-peer (P2P) connections with other PDMSs, and can be used as data processor in order to provide part of the processing required in distributed applications. Hence, our objective is to study solutions based on a full distribution of PDMSs (called nodes interchangeably) which can act as data sources and data processors and communicate in a peer-to-peer fashion. We discard solutions requiring recentralizing the distributed personal data during its processing, since this would dynamically create a personal data concentration leading to a similar risk as with centralized servers.</p><p>Incorporating TEEs considerably increases the protection against malicious PDMS owners. However, since no security measure can be considered as unbreakable, we cannot exclude having some corrupted nodes in the system and, even worse, those corrupted nodes can collude and might very well be undistinguishable from honest nodes, acting as covert adversaries <ref type="bibr" target="#b6">[7]</ref>. Also, since data processing relies exclusively on PDMS nodes, and given the very high scale of the distribution which disqualifies secure multiparty computation (MPC) protocols <ref type="bibr" target="#b30">[31]</ref>, sensitive data leaks are unavoidable in the presence of corrupted nodes, i.e., some data might be disclosed whenever a corrupted node is selected as a data processor.</p><p>The goal of this paper is to assess the feasibility of building a secure and efficient data processing system over a fully distributed network of PDMS housing covert adversaries. To achieve it we provide mechanisms to reduce the data leakage to its minimum, and make the following contributions:</p><p>(1) We propose a P2P architecture of PDMSs, called SEP2P (for Secure and Efficient P2P), based on classical Distributed Hash Tables <ref type="bibr">(DHT)</ref> and analyze potential data leakages of data sources and data processors. We show that (i) data tasks should be assigned to nodes in a verifiable random way, i.e., the assignment cannot be influenced by malicious colluding nodes; and (ii) any data-oriented task, whether it is storage or computation, should be atomic, i.e., reduced to a maximum such that it minimizes the quantity of sensitive data accessible by the task.</p><p>(2) We focus on the verifiable random assignment problem and propose a generic solution (i.e., independent of the distributed computation tasks) which largely minimizes the verification cost (e.g., 8 asymmetric crypto-operations with a SEP2P network of 1M nodes of which 10K are colluding corrupted nodes).</p><p>(3) We experimentally evaluate the quality and efficiency of the proposed protocols. The verifiable random assignment protocol leads to minimal private information leakage, i.e., linear with the number of corrupted nodes, while the cost of the security mechanisms remains very low even with a large number of colluding corrupted nodes.</p><p>(4) We address the task atomicity subproblem by providing sketches of solutions for the three classes of applications indicated above. We do not propose full solutions since task atomicity is dependent on the considered class of distributed computation and as such needs to be studied in detail.</p><p>Sections 2 to 5 present these four contributions respectively. We finally discuss the related work in Section 6 and conclude the paper in Section 7.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">SEP2P ARCHITECTURAL DESIGN 2.1 Base System Architecture</head><p>SEP2P is a peer-to-peer system and only relies on the PDMS nodes to enable the aforementioned applications. Consequently, each node may play several roles for SEP2P applications: Node role 1. Each node is a potential data source. For instance, producing sensed geo-localized data about the local traffic speed, or sharing grades used to compute recommendations.</p><p>Node role 2. Given the fully-decentralized nature of SEP2P, each node is a potential data processor, also called actor, providing part of the required processing.</p><p>Node role 3. The initiator of a distributed processing is called the triggering node (T ). T could be any node with participatory sensing applications, or the query issuer in distributed query or data diffusion applications.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Efficient P2P Data Processing</head><p>Relying on a fully-distributed system induces several problems, e.g., integrating new nodes, maintaining a coherent global state, making nodes that do not know each other interact, handling churn, maintaining some metadata. It thus requires a communication overlay allowing for efficient node discovery, data indexing and search. Fortunately, these problems have already been extensively studied in the literature and the Distributed Hash Tables (DHTs) appear to be the solution reaching consensus. Background 1. A distributed hash table (DHT) <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b33">34]</ref> in a P2P network offers an optimized solution to the problem of locating the node(s) storing a specific data item. The DHT offers a basic interface allowing any node of the network to store data, i.e., store(key, value), or to search for certain data, i.e., lookup(key) → value. DHTs proposals <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b33">34]</ref> share the concepts of keyspace or DHT virtual space (e.g., a 224 bits string obtained by hashing the key or the node ID), space partitioning (mapping space partitions to nodes, using generally a distance function), and overlay network (set of routing tables and strategies allowing reaching a node, given its node ID). For instance, the virtual space is represented as a multi-dimensional space in CAN <ref type="bibr" target="#b29">[30]</ref>, as a ring in Chord <ref type="bibr" target="#b33">[34]</ref> or as a binary tree in Kademlia <ref type="bibr" target="#b22">[23]</ref> and is uniformly divided among the nodes in the network. Thus, each node is responsible for the indexing of all the (key, value) pairs where the key falls in the subspace it manages. Both the data storage and the lookup operations are thus fully distributed in a DHT. DHTs have interesting properties: uniform repartition of the data, scalability, fault tolerance and do not require any central coordination.</p><p>Hence, SEP2P leverages the classical DHT techniques as a basis for communication efficiency and scalability.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Security Considerations</head><p>In this paper, we use the terminology of ARM <ref type="bibr" target="#b34">[35]</ref> to designate the three attack levels on a PDMS node, i.e., hack, shack and lab attacks. A hack attack is a software attack in which the attacker (the PDMS owner or remote attacker) downloads code on the device to control it. A shack attack is a low-budget hardware attack, i.e., using basic equipment and knowledge. Finally, a lab attack is the most advanced, comprehensive and invasive hardware attack for which the attacker has access to laboratory equipment, can perform reverse engineering of a device and monitor analog signals. Note that shack and lab attacks require a physical access to the device and that TEEs are designed to at least resist hack and shack attacks.</p><p>Our threat model considers three security assumptions:</p><p>Assumption 1. Each PDMS is locally secured by using TEE-like technology flourishing nowadays (e.g., <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b28">29]</ref>). This assumption is reasonable considering that a PDMS is supposed to store the entire digital life of its owner. A major security feature of TEE technology is to provide isolation, i.e., strong guarantees that the local computation inside the TEE cannot be spied upon, even in the presence of an untrusted computational environment. Hence, to break to confidentiality barrier of a TEE, a lab attack is mandatory. This has an important consequence: an attacker cannot conduct a successful attack on a remote node, i.e., not under her possession. Assumption 2. Each PDMS device is supplied with a trustworthy certificate attesting that it is a genuine PDMS. Without this assumption, an attacker can easily emulate nodes in the network, and conduct a Sybil attack <ref type="bibr" target="#b10">[11]</ref>, mastering a large proportion of nodes (e.g., playing the role of data processor nodes), thus defeating any countermeasure. Note that this does not require an online PKI (the certificate can be attached to the hardware device and not to the device owner). Assumption 3. Corrupted nodes by a lab attack behave like covert adversaries, i.e., they derive from the protocol to obtain private information only if they cannot be detected <ref type="bibr" target="#b6">[7]</ref>, as detected malicious behavior leads to an exclusion from the system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Threat Model</head><p>The above considered assumptions already offer a certain level of security at the node and system levels. Yet, no hardware security can be described as unbreakable. Therefore, our threat model considers that an attacker (e.g., one or several colluding malicious users) can possess several PDMSs and conduct lab attacks on these devices, thus mastering several corrupted nodes which can collude. For simplicity, we will call them colluding nodes.</p><p>It is important to notice that the worst-case attack is represented by the maximum number of colluding nodes in the system (i.e., controlled by a single entity). Corrupting few nodes can lead to some private data disclosure, but this will be very limited in a well-designed system with a large number of nodes. Therefore, an attacker needs to increase the collusion range to fully benefit from the attack (i.e., access a significant amount of private data).</p><p>Thereby, the remaining question is: how many colluding nodes could an attacker control in the system? The main difficulty for an attacker is that colluding nodes must remain indistinguishable from honest nodes (see Assumption 3). Since PDMSs are associated to "real" individuals (e.g., by delivering the device only to real users proving their identity), collusions between individuals remains possible (hidden groups) but such collusions cannot scale without being minimally advertised, hence breaking the indistinguishability mentioned above. Thus, wide collusions are extremely difficult to build since it requires significant organization between a very large number of users, which in practice requires an extremely powerful attacker as well as extreme discretion, and are thus the equivalent of a state-size attack. Finally, note that considering a large proportion of colluding nodes (e.g., 10%) is vain as it would inexorably lead to large disclosure whatever the protocol having a reasonable overhead (e.g., outside the MPC scope). Hence, in this paper we consider that a very powerful attacker could control up to a small percentage (e.g., 1%) of the nodes, which corresponds to a wide collusion requiring a lab attack on these nodes as well as a highly organized collusion between the owners of those nodes. What does the system protect? The objective of SEP2P is to offer the maximum possible confidentiality protection of the user private data under the above considered threat model. Many other issues related to statistical databases (e.g., inferences from results, determining the authorized queries, query replay, fake data injection, etc.) or to network security (e.g., message drop/delay, routing table poisoning <ref type="bibr" target="#b38">[39]</ref>) are complementary to this work and fall outside of the scope of this paper. Similarly, the problems related to the attestation and integrity of the code executing distributed computations (e.g., against corrupted nodes that maliciously modify the computation results).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">SEP2P Requirements</head><p>Given the considered threat model, we derive in this section the requirements that a SEP2P must address to protect the data privacy of the users. Since we cannot exclude having colluding nodes in the system and since the colluding nodes behave like covert adversaries, private information leakage is unavoidable. Under these conditions, the best countermeasures one can take are: (i) minimize the risk of a data leakage, i.e., reduce at most the probability of a leakage to happen; and (ii) minimize the impact of a data leakage, i.e., reduce at most the leakage size. Obviously, these countermeasures should not generate overheads that render the system unpractical. This leads to: Requirement (security) 1. Random actor selection. Ensure that colluding nodes cannot influence the selection of the data processor nodes.</p><p>Requirement (security) 2. Task atomicity. Data tasks should be atomic, i.e., reduced to a maximum such that it minimizes the required sensitive data to execute the task.</p><p>Requirement (efficiency) 3. Security overheads. Minimize the number of costly operations, e.g., cryptographic signature verifications or communication overheads, and ensure system scalability with an increasing number of nodes or colluding nodes.</p><p>The task atomicity requirement is similar to the principle of compartmentalization in information security, which consists in limiting the information access to the minimum amount allowing an entity to execute a certain task. Typically, a node can execute a subtask without knowing the purpose or the scope of the global task. Dividing a given distributed computation in atomic tasks obviously depends on the precise definition of that computation. Hence, we restrict our analysis in Section 5 to sketches of solutions for the three application classes considered in this paper.</p><p>Independently of the distributed protocol chosen to implement some given application, the system must delegate the dataoriented tasks to randomly selected nodes. Therefore, the random selection protocol is generic and constitutes the security basis of any distributed protocol in our system. However, given the considered threat model, it is challenging to design an actor selection protocol that is both secure and efficient. Section 3 addresses this problem while section 4 evaluates the proposed solution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">SECURE ACTOR SELECTION</head><p>Let us first detail some useful classical cryptographic tools focusing on the properties used in our protocol. Background 2. A cryptographic hash function <ref type="bibr" target="#b23">[24]</ref> is a one-way function that maps a data of arbitrary size to a fixed size bit string (e.g., 224 bits) and is resistant to collision. An interesting property of hash functions is that output distribution is uniform. In the following, hash() refers to cryptographic hash. Background 3. A cryptographic signature <ref type="bibr" target="#b23">[24]</ref> can be used by a node n to prove that a data d was produced by n (authentication) and has not been altered (integrity). The signature is produced by encrypting hash(d) using the private key of n. Any node can verify the signature by decrypting it using the public key of n and comparing the result with hash(d). The signature includes the signer public key certificate, cert n (see Assumption 2). We consider a system of N nodes, in which we want to randomly select A actors, despite a wide collusion attacks from C colluding nodes. The main notations are summarized in Table <ref type="table" target="#tab_1">1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Effectiveness, Cost and Optimal Bounds</head><p>Ideally, we would want to ensure that all A actors are honest, but this is impossible, since colluding nodes are indistinguishable from honest nodes. Therefore, the best achievable protection is obtained when actors are randomly selected and the selection cannot be influenced by C colluding nodes, i.e., the average number of corrupted selected actors in the ideal case is </p><formula xml:id="formula_0">A ideal C = A×C/N</formula><formula xml:id="formula_1">(A ideal C &gt; 0)</formula><p>. Thus, the impact of a collusion attack remains proportional with the number of colluding nodes, which is the best situation given our context. This guarantees that the attacker cannot obtain more private information than what she can passively get from observing the information randomly reaching its colluding nodes.</p><p>The following definitions quantify the security effectiveness and security cost of an actor selection protocol.</p><p>Definition 1. The security effectiveness of an actor selection protocol is defined as the ratio between A ideal C and the average number of corrupted selected actors for the measured protocol (A C ), i.e., security effectiveness = A ideal C /A C . The security effectiveness has maximum value (i.e., 1) when A C = A ideal C and minimum value (i.e. C/N ) when all the actors are corrupted. Definition 2. A verifier node is a node who needs verifying the actor list before delivering sensitive data, e.g., a data source. Definition 3. The security cost of an actor selection protocol is defined as the number of asymmetric cryptographic operations, e.g., signature verification, required by verifier nodes to check the selected actor list.</p><p>Note that the security cost considers only the verification of the actor list and not the cost of building the list. The rationale is that the verification cost has a larger impact on the overall performance since the number of verifier nodes can be high in a large distributed system: data sources need to verify the actor list before delivering their data. Other performance related issues (cost of the actor list generation, load balancing, maintenance costs) are discussed in Section 3.6 and 4.</p><p>Optimal bounds. The best possible case one could expect in terms of security effectiveness and cost in our context can be achieved using an idealized trusted server that knows all the nodes and provides a different random actor list for each system computation. This ideal solution reaches a maximal security effectiveness and a security cost of 1, since any verifier node must only check the signature of the trusted entity.</p><p>Evidently, this solution in not acceptable since it represents a highly desirable target for attackers, i.e., a central point of attack and contradicts the fully distributed nature of SEP2P. Therefore, we need distributed solutions relying only on the nodes. To underline the existing tension between security effectiveness and cost, we discuss two basic distributed protocols for the actor selection, focusing either on the security cost or on the security effectiveness. To simplify the protocols description, we initially assume a full mesh network overlay, i.e., each node knows the complete list of nodes in the system and its evolution over time.</p><p>Baseline cost-optimal protocol. The triggering node (T ) selects randomly the actors. The security effectiveness is minimal:</p><p>A C = min(A, C) sinceT may be corrupted (which is the case when any node can trigger a computation). There is thus no necessity to provide any signature: the security cost is 0.</p><p>Baseline security-optimal protocol. Proposing an optimal protocol in terms of security is challenging in a decentralized architecture (without any supporting trusted party) and considering covert adversaries. This conjunction leads to a situation where no single node in the system can claim to securely provide a list of actors (the provider itself can be corrupted). The work in <ref type="bibr" target="#b7">[8]</ref> proposes the CSAR protocol which provides a secure way to generate a verifiable random value under the condition that there is at least one honest node participating in the distributed protocol. Applying to our context, we can ensure generating a real random value only if there are at least C + 1 participating nodes. Also, once we obtain a verifiable random value, we can derive up to A random values by repeatedly hashing the initial value A -1 times. The final step is to map the set of A random values to the nodes. This can be easily done, e.g., by sorting the nodes on their public key and associating the random value to a rank in the sorted list. This protocol has an optimal security effectiveness, i.e., 1, since the actors are guaranteed to be selected randomly. On the other hand, checking the CSAR results requires one signature verification per participant. Thus, the security cost is C + 1 asymmetric cryptographic operations per verifier node. Since C can be large, such a solution cannot scale with large systems and wide collusion attackers as it would lead to an extreme verification cost.</p><p>Moreover, to achieve these security bounds, both protocols require a full mesh network overlay which is also extremely costly to maintain in practice, especially for large networks. This contradicts the efficiency and scalability requirement formulated in Section 2.5. Using a DHT overlay instead of a full mesh solves the problem of communication efficiency/scalability. However, this will impact the optimal bounds of both protocols. For the first protocol, the security cost increases from 0 to up to A since a verifier node which does not "know" any of the actors has to verify their certificates to be sure that the actors are genuine PDMSs (to avoid Sybil attacks). Similarly, for the second protocol, the security cost increases to 2(C + 1) + A for the same reason, i.e., checking that participant and selected actors are genuine PDMSs. Even worse, the optimal security effectiveness can no longer be guaranteed since with a DHT, there is no secure way of associating the random values to the nodes unless using secure DHT techniques <ref type="bibr" target="#b38">[39]</ref> with a large impact on performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Overview of the proposed solution</head><p>To address all these problems, we propose a protocol that reaches maximal security effectiveness at a verification cost of 2k. k is called the security degree and is very small. Also, our protocol builds directly on a classical, efficient DHT overlay without requiring any modifications. We describe some important features in SEP2P which make this possible and then sketch the protocol.</p><p>Imposed and uniform distribution of node location: the node ID, used when inserting a node in the DHT, is imposed in SEP2P, in a way that leads to a uniformly distributed node location in the DHT virtual space. Consequently, colluding nodes are also evenly distributed in the DHT, thus avoiding spatial clusters. We use extensively this property to drastically reduce the cost of security by taking localized decisions (see below), i.e., limited to the nodes situated in "small" regions in the virtual space. Achieving imposed node location is easy, based on the public key of the certificate of each node. We compute a cryptographic hash of this key, which is, by construction, uniformly distributed, and use this hash for insertion in the DHT virtual space. The advantages of using the public key are (i) its uniqueness; and (ii) the node location can be checked with a single signature verification.</p><p>Probabilistic guarantees: Given the imposed, uniform node location which applies indistinctly to honest and colluding nodes, we can have probabilistic guarantees on the maximum number of colluding nodes in a DHT subspace of a given size, called DHT region hereafter. We can compute the probability of having at least k colluding nodes (see Section 3.3) and choose the DHT region size such that the probability is very close to 0. In our context, we want to have a probability smaller than α, the security threshold. The main idea is to set α so that the probability of having k colluding nodes in the same region becomes so low that we can consider that it "never happens", e.g., α = 10 -6 (see Section 4.1). Such a guarantee is used in the protocol sketched below and then detailed in the following subsection. Sketch of verifiable selection protocol of A actors (see Figure <ref type="figure" target="#fig_0">1</ref>)</p><p>(1) Run a distributed protocol inspired from CSAR <ref type="bibr" target="#b7">[8]</ref> to generate a verifiable random value, i.e., proven to have been truly randomly generated by k nodes if at least one is honest (see Section 3.4). The k nodes are selected in a DHT region R 1 , centered on the triggering node (T ), whose region size r s 1 is set such that we have probabilistic guarantees to "never" (probability &lt; α ) have k or more colluding nodes, i.e., at least one of the k nodes is honest. (2) Map the hash of that random value into coordinates to define a location p in the DHT virtual space and contact through the DHT the node, called execution Setter (S ), managing this location. (3) S then selects k nodes (the actor list builders) in a region R 2 , centered on p, using probabilistic guarantees, such that we "never" have k or more colluding nodes. Given the uniform distribution of the node on the virtual space, we have rs 2 = rs 1 . (4) Each actor list builder then selects A nodes in a region R 3 , centered on p, whose size rs 3 is such that R 3 includes at least A nodes with high probability (see Section 3.6 and Section 4.3 for r s 3 tuning). ( <ref type="formula">5</ref>) Run a distributed verifiable selection protocol in the spirit of <ref type="bibr" target="#b7">[8]</ref> such that the k nodes selected in (3) can: (i) check the validity of the random value generated in (1); (ii) build the actor list securely;</p><p>(iii) sign both the random value and the list of A actors. This step is detailed in Section 3.5.</p><p>The result is a list of A actors that is signed by k nodes, among which at least one is honest. Doing so reduces the verification cost to 2k asymmetric cryptographic operations: k to check the certificate of the k list builders, verifying that they belong to region R 2 , centered on p; and k to check each builder signature.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Providing Probabilistic Guarantees</head><p>To generate verifiable random values or validate the query actor selection, SEP2P employs distributed computations between a small subset of the nodes thanks to the notion of node legitimacy and probabilistic guarantees defined below using the notations in Table <ref type="table" target="#tab_3">2</ref>  To be able to provide probabilistic guarantees as explained in Section 3.2, we need to estimate the number of nodes in a region:</p><p>Lemma. Let R be a DHT region of size rs in a virtual space of a DHT of total size 1 (i.e., normalized) and let N be the total number of network nodes with a uniform distribution of the node location in the virtual space. The probability, PL, of having at least m legitimate nodes in R is:</p><formula xml:id="formula_2">PL(≥ m , N , rs) = N i=m N i • rs i •(1 -rs) N -i<label>(1)</label></formula><p>Proof (sketch): Let us consider a partition of the N nodes into two subsets containing i and Ni nodes. Since the distribution of nodes is uniform in space, the probability of having the i nodes inside R and the Ni nodes outside R is rs i •(1rs) N -i and there are N i possible combinations of generating this node partitioning. The probability of having at least m nodes in R is equal to the probability of having exactly m nodes plus the probability of having exactly m+1 plus. . . the probability of having N , which leads to the equation in <ref type="bibr" target="#b0">(1)</ref>.</p><p>Application to colluding nodes: Let C &lt; N be the maximum number of colluding nodes. We can apply formula 1 to compute the probability, PC of having at least k colluding nodes in R:</p><formula xml:id="formula_3">PC(≥ k , C, rs) = C i=k C i • rs i • (1 -rs) C-i<label>(2)</label></formula><p>We can notice that this probability only depends on C. It does not depend on the region center since we have a uniform distribution of the nodes on the virtual space.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Verifiable Random Generation</head><p>Our goal is to generate a random value, using k nodes and to guarantee that none of the k nodes can choose the final computed random value (or any of its bits). Any node in the system should be able to check the validity of this random value (i.e., to have proofs that it has been correctly generated). This is possible as soon as at least one of the k nodes is honest, this guarantee being obtained thanks to equation ( <ref type="formula" target="#formula_3">2</ref>) by choosing the adequate size for the DHT region R and by using k legitimate nodes w.r.t. R.</p><p>A node T wanting to generate a verifiable random, selecting a region of size rs 1 with PC(rs 1 ) &lt; α centered on itself, executes:</p><p>Verifiable random number generation protocol (1) T contacts any k legitimates nodes</p><formula xml:id="formula_4">TL i (i ∈ [1, k ]) w.r.t. R 1 .</formula><p>(2) Each TL i sends hash(RND i ) to T , where RND i is a random number (on the same domain as the hash function, e.g., 224 bits) TL i generates.</p><p>(3) Once T has received the k hashes, it sends back the list L of hashes to the TL i s; L = (hash</p><formula xml:id="formula_5">(RND i )) i ∈[1,k ] . (<label>4</label></formula><p>) Each TL i checks that hash(RND i ) ∈ L, and, in the positive case, returns sign i (L) and RND i . (5) T gathers the k messages and builds the verifiable random: The above random generation protocol is adapted from <ref type="bibr" target="#b7">[8]</ref> which includes a formal proof. Note that the protocol in <ref type="bibr" target="#b7">[8]</ref> does not include the notion of node legitimacy and thus needs C + 1 participating nodes instead of k. Intuitively, the nodes commit on their selected random value by sending its hash (Step 2), and all the hash values are known by each of the k nodes before providing the final signature (Step 4). Therefore, an attacker controlling k -1 TL i nodes cannot influence the final random value since these nodes cannot change their random values (committed at</p><formula xml:id="formula_6">VRND T = (cert T , (sign i (L), RND i ) i ∈[1,k ] ).</formula><p>Step 2). Thus, the correct random value of a single honest node is enough to obtain a truly random final value RND T .</p><p>To obtain and check the verifiable random value, any node must: (i) check cert T and compute L by hashing all RND i ; (ii) for i ∈ <ref type="bibr">[1, k]</ref>, check cert i , check the legitimacy of TL i using cert T and validate sign i (L). The final random value is</p><formula xml:id="formula_7">RND T = RND 1 ⊕ RND 2 ⊕ • • • ⊕ RND k .</formula><p>In (i), we verify that T is a genuine PDMS, retrieve the center of the region R 1 and compute L, both being necessary for the next verification; (ii) starts by confirming that each TL i is genuine, then it ensures that they are legitimate w.r.t the location of T and R 1 , after which it confirms the hash list by checking the signatures, and finally, it computes RND T .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Distributed Secure Selection Protocol</head><p>The main goal of the proposed protocol is to select the A actors such that this selection cannot be influenced by colluding nodes.</p><p>Definition 5. The execution Setter (S) is chosen randomly based on a verifiable random generated by T . Its role is to coordinate the selection of the computation actors and to setup the execution by sending the appropriate information to each actor.</p><p>In the following, we assume that each node n in SEP2P keeps a node cache, called cache n , of the IP address and certificate of legitimate nodes w.r.t. a region of size rs 3 centered on node n location. The cache size and the cache maintenance cost are discussed in Section 3.6 and evaluated in Section 4.3.</p><p>SEP2P distributed secure actor selection protocol (1) Generates the verifiable random VRND T (see Section 3.4).</p><p>(2) Maps hash(RND T ) into coordinates and contact S through the DHT.</p><p>(3) S contacts any k legitimates nodes w.r.t. R 2 , SL j (j ∈ <ref type="bibr">[1, k]</ref>) and sends to each VRND T (see Section 3.4). ( <ref type="formula" target="#formula_5">4</ref>) Each SL j sends hash(RND j ∥ CL j ) to S , where RND j is a random number SL j generates, and CL j is the set of nodes from Cache j which are legitimate w.r.t. R 3 . ( <ref type="formula">5</ref>) Once S has received the k hashes, it sends back the list L 1 of hashes to all SL j ; L 1 = (hash(RND j ∥ CL j )) j ∈[1, k ] . ( <ref type="formula">6</ref>) Each SL j checks that its own hash(RND j ∥ CL j ) ∈ L 1 and, in the positive case, returns RND j and CL j . (7) S gathers the k messages and sends to all SL j the list The goal of steps 1 and 2 is to displace the DHT region, where actors will be selected, from T to S with three benefits: <ref type="bibr" target="#b0">(1)</ref> T is likely to be corrupted (as any node is allowed to trigger a computation) while S is chosen randomly using the verifiable random protocol; (2) it distributes the potential leaks in a different region for each computation; (3) it balances the load on the whole SEP2P network thus improving the overall performance.</p><formula xml:id="formula_8">L 2 = ((RND j , CL j ) j ∈[1,k ] ).<label>(</label></formula><p>Steps 3 to 6 are similar to steps 1 to 4 of the verifiable random protocol, except that the signature by SL j is delayed to Step 8.g. Delaying the signature allows SL j s to check and attest the validity of VRND T (step 8.a). The protocol cost is increased (since k nodes verify VRND T ) but the verifying cost is reduced accordingly since having k SL j s signing RND T (step 8.g) means that it is correct (remind that at least one of the k SL j s is honest).</p><p>Steps (8.b) to (8.e) are dedicated to the actor list building (AL) based on the candidate list (CL) and deserve a more detailed explanation: in our context, in order to securely build the actor list, the k participants first have to agree on a common basis and then execute, in parallel, a procedure that is unpredictable and gives identical results to all participants. Since it is unpredictable we are certain that the inputs cannot be manipulated beforehand so as to influence the rest of the procedure. Since it gives identical results for all actor list builders, and since at least one node is honest, we are sure that no colluding node can alter the results. By sorting the nodes in CL using a verifiable random number and the public keys of the nodes fulfills both requirements: the random number takes care of the unpredictability, while the commitment of each SL j on their intermediary lists in step 4, coupled with the XOR operation on the public keys of CL nodes, is a simple yet effective way of producing identical results.</p><p>In steps 8.f and 8.g, k SL j s check the validity of the result, i.e., that any actor of AL belongs to R 3 and attest it by signing the results. Note that this check is not necessary for any actor n in AL that was found in k CL j since this fact attests that at least one honest node possesses n in its Cache j . Assuming Cache j contains only genuine nodes (we say that Cache j is valid -see Section 3.6) and since rs 3 &gt; rs 2 , most of the actors in AL will be found in k CL j , thus diminishing drastically the actor list building cost. Actually the validity of Cache j is necessary to ensure that a colluding node selected as SL cannot hide honest nodes with the hope of having a larger proportion of colluding nodes in AL. Indeed, at least one of the SL is honest and will provide its full Cache j that will be thus included in CL. We can observe that Cache j can be actually seen as the relevant part (for node j) of a full mesh network, which offers its benefits without paying the whole maintenance cost.</p><p>Let us now concentrate on the work that must be done by the verifier nodes. To check the verifiable actor list (VAL), any verifier node must do: for j ∈ [1, k], check cert j , check the legitimacy of SL j using RND T and validate sign j (AL). Thus, the verifying cost is limited to k certificate verifications and k signature verifications, i.e., 2k asymmetric crypto-operations. We show in Section 4 that k is generally lower than 6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6">Protocol Implementation Details</head><p>In this section we discuss a few important implementation issues of the proposed actor selection protocol.</p><p>Despite the uniform distribution of nodes on the DHT virtual space, there is no absolute guarantee of not having sparse DHT regions. This can have two negative impacts on the SEP2P protocol: during the selection of k T Ls in R 1 (or k SLs in R 2 ) and A actors in R 3 . Both cases exhibit interesting trade-offs:</p><p>Choosing R 1 (or R 2 ) region size: on the one hand, a small rs leads to a smaller k value, which in turn reduces the protocol verification cost. On the other hand, setting rs too small can lead to situations in which nodes have less than k legitimate nodes in their R region and as such cannot participate in the actor selection protocol (as triggering node or execution setter) which is problematic. For this reason, in SEP2P we provide a table of couples (k i , rs i ), named k-table, which allows any node to find k i legitimate nodes in the region of associated rs i size. The k-table is computed thanks to PL and PC (equations ( <ref type="formula" target="#formula_2">1</ref>) and ( <ref type="formula" target="#formula_3">2</ref>)) to ensure that whatever the couple chosen, the probability of having k or more colluding nodes remains equal. The largest k of the k-table corresponds to the region size allowing any node to find those legitimate nodes with a very high probability, i.e., 1-α, while lower values allow to reduce the security cost in denser network regions. Thus, the k-table optimize the overall cost of the SEP2P protocol and warrant that any node can be selected as triggering node or execution setter.</p><p>Choosing R 3 region size: Choosing a too small rs 3 has a negative impact on the system performance. If the SLs cannot find enough nodes in R 3 , they can attest it (e.g., in Step 8.c in SEP2P protocol) and S can use the k signatures to displace the actor selection to another region (e.g., selected by rehashing the initial RND T ). This mechanism allows the protocol to be executed successfully even if some network regions are sparser. However, there are two drawbacks. First, the cost of the actor selection increases since (part of) SEP2P protocol must be executed twice (or more times). Second, this also introduces an unbalance in the system load since the sparse regions cannot fully take part in data processing. Finally, setting rs 3 to very large values (see Section 4.3) is not an option since the maintenance cost of the cache increases proportionally when nodes join or leave the network.</p><p>Joining the network and Cache j validity: Due to space limitation, we only sketch the joining procedure in the case of a Chord DHT (leaving the network can be easily deduced). As mentioned above, any node must maintain a consistent node cache despite the natural evolution of the network. Thus, a node joining the network must ask its successors and predecessors (Chord DHT) to provide their node cache attested by k legitimate nodes in a region of size rs 1 centered on their location. The new node can then make the union of these caches and keep only legitimate nodes w.r.t R 3 centered on its location. The resulting cache contains only genuine nodes and is thus valid since it has been attested by at least k nodes in a region of size rs 1 centered on the successors or predecessors of the new node (a recurrence proof can be established).</p><p>Reusing an actor list: If there is no mechanism that prevents an attacker from reusing an actor list, then she only has to keep generating such lists until she obtains one she deems satisfying.</p><p>To counter this behavior, we put in place two mechanisms: (i) a timestamp and (ii) a limit to the number of triggered executions a node can make. With (i) we prevent any node from reusing an actor list: T Ls and SLs add a timestamp to their signatures which will respectively be checked by the SLs and the data sources. If the timestamp is too distant, the computation is cancelled. Enforcing (ii) is possible thanks to the node cache and the k-table: the T Ls solicited by T first check if T chose the smallest possible number of T Ls (as their node cache contains, by construction, R 1 centered on T , they are capable of judging), thus forcing T to choose the same T Ls. They then only have to monitor and limit the number of queries T does in a given amount of time.</p><p>Failures and disconnections: In the most complex case of node failures (i.e., unexpected disconnection) of a T L, SL or S, either RND T or AL cannot be computed and the protocol must be restarted (i.e., T generates a new RND T ). However, the probability of failures during the execution of the secure actor selection being low in our context, such restarts do not lead to severe execution limitations as mentioned above. The case of "graceful" disconnections is easier: we can safely force nodes involved in the actor selection process to remain online until its completion, thus avoiding the restarts. If a node, selected as actor wants to disconnect (or fails), the impact will be mainly on the result quality since part of the results will be missing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">EXPERIMENTAL EVALUATION</head><p>This section evaluates the effectiveness, efficiency, scalability and robustness of the SEP2P actor selection protocol.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Experimental Setting</head><p>Reference methods. To better underline our contributions and to provide a comparison basis, we implemented three strategies in addition to the SEP2P actor selection protocol. We discarded the baseline cost-optimal and security-optimal protocols from the evaluation since the former does not provide any security while the latter is much too costly and not scalable (w.r.t. N and C) to be used in practice. Hence, we used for comparison more advanced actor selection strategies based on these protocols but using our verifiable random generation protocol with k participants (see <ref type="bibr">Section 3.4)</ref>.</p><p>The first two strategies use the verifiable random to designate the execution Setter (S) which freely chooses the actor list (as in the cost-optimal protocol). These strategies differ only in the verification process. The first one, ES.NAV (for Execution Setter, No Actor Verification) requires verifying the legitimacy of S but not of the actors. The second one, ES.AV requires, in addition, to verify that actors are genuine PDMSs. ES.AV is expected to provide better security effectiveness than ES.NAV at a higher verification cost. The third strategy, M.Hash (for Multiple Hash) is derived from the security optimal protocol, but uses a DHT instead of a full mesh network. Verifiers must check that actors are genuine PDMSs and that they are "near" the random values determined by the initial verifiable random, hashed as many times as there are actors.  Simulation platform. We identified all the parameters that may impact the security and efficiency of the proposed strategies and considered all the metrics (see Table <ref type="table" target="#tab_5">3</ref>) that are worth evaluating to analyze the strengths and weaknesses of the proposed strategies, i.e., security effectiveness and cost, setup cost, scalability, robustness w.r.t. failure or disconnections. Let us note that a real implementation of the SEP2P distributed system is not very useful if we consider the above listed objectives of the evaluation. Also, measuring the scalability for very large systems (e.g., 10M nodes) with many parameters is practically impossible. Therefore, as in most of the works on distributed systems <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b33">34]</ref>, we base our evaluation on a simulator and objective metrics. That is, the latency is measured as the number of asymmetric cryptooperations and exchanged messages between peers instead of absolute time values. This allows for a more precise assessment of the system performance than time latency, which can greatly vary in our context because of the node heterogeneity (e.g., TEE resources or network performance).</p><p>Our simulator is built on top of a DHT network. Currently, we implemented Chord and CAN as DHT overlays and use Chord for the results presented in this paper. The simulator allows to force choosing a given Execution Setter (by artificially fixing the RND T value). We used this feature to obtain the exhaustive set of cases for a given network setting, each node being the Execution Setter, and then capture the average, maximum and standard deviation values for our metrics. The parameters and metrics of the simulator are described in Table <ref type="table" target="#tab_5">3</ref>. Values in bold are the default choices and their tuning is discussed throughout the Section. Note that (1) the verification cost is given by verifier node; (2) the latency indicates the "duration" of the protocol executed in parallel; (3) the total work indicates the cumulative number of cryptographic operations and communications during the execution of a protocol.</p><p>Security threshold value: Generating several networks and varying the security threshold α, we experimentally observed that for α = 10 -4 , an attacker never controls k or more nodes. However, given the importance of this parameter for the system security, we set α = 10 -6 and show in Figure <ref type="figure" target="#fig_4">6</ref> the impact of choosing α = 10 -10 on a small (10K) and large (10M) network. Indeed, if an attacker could master by chance k colluding nodes in a region of size rs 1 = rs 2 , then she could completely circumvent the security mechanism of SEP2P since, for example, she can obtain k signatures from these regrouped colluding nodes for an actor list of her willing. Note that increasing α reduces the probability accordingly but increases the verification cost in a logarithmic way (as discussed below in Section 4.3).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Security Effectiveness vs. efficiency</head><p>Figure <ref type="figure">3</ref> represents the security effectiveness (Y axis) versus the verification cost (X axis) for the four measured strategies and with C% varying from 0.001% to 10%. Note that the value of 10% is not realistic: it would lead to large disclosure even with an optimal random actor selection protocol, and as mentioned in Section 2.4, is equivalent to state-size attack. We have however run the simulation with 10% to understand its impact on the security effectiveness and cost.</p><p>Security effectiveness: SEP2P achieves an ideal security effectiveness, i.e. as good as a trusted server, independently of the number of colluding nodes. Indeed, the selection of actors is truly random, thus providing the same results as the ideal case. In addition, the verification cost (2k) is also very low (4 to 8 asymmetric crypto-operations for C% ≤ 1%). Not surprisingly ES.NAV has the same verification cost than SEP2P, but the cost of ES.AV or M.Hash is much larger (2k + A + 1 and 2k + A respectively) since both must check the certificate of each actor in the list. This check allows ES.AV to have better security effectiveness than ES.NAV when C is very small (C &lt; A). With respect to security effectiveness, ES.NAV, ES.AV and M.Hash are far from offering an adequate protection. Let us explain the cause for the poor security effectiveness: while RND T value is correctly chosen, an attacker mastering a corrupted node located "sufficiently near" from hash(RND T ) can claim to be the Execution Setter and then select a list of actors including a maximum number of colluding nodes. Here, "sufficiently near" means that it satisfies the check made by the verifiers. Note that we tuned the system parameters such that we can be "sure" to have always a node sufficiently near of any random value to allow executing the actor selection protocol for any RND T . The same problem happens for M.Hash for each new random destination, thus explaining the poor security effectiveness. Hence, increasing the number of verifications or selecting each actor in a different network region does not solve the intrinsic limitation of these strategies. Note also that this behavior does not affect SEP2P. Indeed, even if the Execution Setter is a corrupted node, it cannot influence the actor list selection since it is done by k SLs (S only routes the messages between the SLs).</p><p>Setup costs: Figures <ref type="figure">4</ref> and<ref type="figure">5</ref> show the setup costs (Y axis in log scale) in terms of asymmetric crypto-operations and exchanged messages respectively, once more with respect to the verification cost (X axis). Curves with empty symbols represent latency while plain symbols represent total work. The results show that SEP2P is the slowest in latency and has the higher total setup cost for  crypto-operations. These "bad" results are the consequence of two design choices: (1) to increase the security effectiveness, we run our protocol on k SL nodes thus increasing the total setup cost; and (2) we voluntarily make most of the checks during the setup (e.g., checking the actor certificates or verifying their availability) in order to reduce, as much as possible, the subsequent verification cost. Since this verification process will potentially be performed by a (very) large set of nodes (e.g., data sources), it is in our best interest to reduce it to avoid overloading the entire system. Figures <ref type="figure">4</ref> and<ref type="figure">5</ref> illustrate this aspect: our non-optimal setup cost is balanced by an optimized verification cost (and ideal disclosure in Figure <ref type="figure">3</ref>). Note also that most operations are done in parallel (either by k T Ls or SLs), thus leading to a reasonable setup latency (around 20 crypto-operations and 30 exchanged messages). We can also note in Figure <ref type="figure">5</ref> that M.Hash achieves the worst total work for setup (exchanged messages), because of the A routings in the DHT. Finally, we can remark the almost identical latency of ES.NAV, ES.AV and M.Hash on both metrics. Indeed, they all run the same initial protocol to compute RND T . With respect to communication, the results are also identical because all DHT routings for M.Hash are done in parallel.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Scalability and Robustness</head><p>We now concentrate on SEP2P to study its scalability and its robustness to node failure. Scalability: To study the scalability, we compute the averaged k value varying C and N . Indeed, k is the main factor in the verification cost, setup latency and total work (since everything is done k times). As seen in Section 3.6, depending on C and N , we can compute a k-table which gives several increasing values of k with increasing region size. We have considered small (10K) to very large (10M) networks and four values for C%, leading to eight different SEP2P network configurations. For each configuration, we have computed, for each node, the minimal value for k with respect to the k-table and then averaged the results. Figure <ref type="figure" target="#fig_4">6</ref> shows the average k (Y axis) versus the C% (X Axis in log scale) for several network size considering two values for α: 10 -6 and 10 -10 . We also plot on the same figure the value of k without k-tables (the grey curve) to highlight the benefit brought by ktables (only shown for the large network with α = 10 -10 ). This figure offers many insights. (1) SEP2P is highly scalable w.r.t. N : Indeed, kvalues are identical for small and large networks independently of α if we consider the percentage of colluding nodes and not the absolute value (e.g., 1% colluding nodes is equivalent to absolute values of C = 100 and C = 100K for the small and large networks). Indeed, scaling N and C in the same proportion leads to reduce rs 1 = rs 2 size accordingly. Note that with a single corrupted node, the k optimization is useless (k = C + 1 in that case) regardless of the α value. (2) k increases slowly when C% &lt; 1%: k remains smaller than 6 even with α = 10 -10 . For N = 10M and C% = 1%, the k-optimization reduces the number of participants in the verifiable random generation from 100K to 6. (3) α has a small influences on k: increasing α by four orders of magnitude increases k from 1 unit (e.g., 1K colluding nodes for N = 10M) to 5 units (e.g., 1K colluding nodes for N = 10K or 1M colluding nodes for N = 10M). (4) the ktable optimization is important: k-tables allow reducing k by 1 unit up to 9 units (for 10% colluding nodes).</p><p>Number of actors: We also studied the impact of the variation of the number of actors. Overall, this results in a linear increase in the total work in terms of communications as the k SLs must check for the availability of A legitimate nodes to construct their respective CLs. For the sake of brevity, we omit here the detailed results.</p><p>Node cache size: We now focus on adapting the node cache size to the maximum number of required actors. Our goal is to evaluate the impact of the cache size on the global performances.</p><p>To do so we take a reference network with N = 100K, C% = 1% and A = 32 and vary the average cache size on the whole network (we compute rs3 easily dividing the cache size by N ). Figure <ref type="figure">7</ref> shows the results (Y axis in log-scale). For each cache size, we simulated an execution on each node of the network and computed the average values for our metrics. Our measures show that with a very small cache, the probability of relocating the actor selection process is high (the SLs do not find enough legitimate nodes in their cache w.r.t. R 3 ), which then leads to an increased latency and total work. Choosing a cache size greater than A, the query is almost never relocated (see Figure <ref type="figure">7</ref>), giving better performances. This would lead to choose the largest possible cache. However, constructing such a cache also means maintaining it.</p><p>Maintenance costs: We also evaluated the impact of the cache size in the presence of node disconnections and, more generally, the impact of disconnections. To observe it, we simulated disconnections and measured their cost depending on the size of the node cache (Cache j ) using the default values for C, N , α and resulting k. We then considered those costs as a baseline and computed the global impact in a network where nodes disconnect (and reconnect) every x hours (mean time before failure or MTBF). We represent this cost in terms of asymmetric cryptographic operations (see Figure <ref type="figure" target="#fig_2">8</ref> -Y axis in log scale). The number of exchanged messages is not shown because graphs are very similar. We also computed these metrics for large node cache sizes (up to 32K) to confirm that full mesh networks cannot be an alternative to DHT. Our results show that an overestimated cache is excessively costly even with an MTBF of 5 days: it consumes a large portion of the overall computing power of the entire system just to maintain it up to date. With small MTBFs, the network would be probably not maintainable. Since the number of actors for a computation is likely to be relatively small (e.g., few hundred, see Section 5), we can safely set the node cache size around 512 which leads to a reasonable maintenance cost (less than 1 signature per node per minute on average for MTBF = 1 day) and never trigger relocations (see Figure <ref type="figure">7</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">TASK ATOMICITY 5.1 Proposed Use Cases</head><p>We now focus on requirement 2, illustrating task atomicity on the use cases proposed in Section 1.</p><p>Use case 1: Mobile participatory sensing is used in many smart city applications for urban monitoring such as traffic monitoring (e.g., Waze or Navigon), evaluating the quality of road infrastructures, finding available parking spaces or noise mapping <ref type="bibr" target="#b35">[36]</ref>. In these scenarios, the community members act as mobile probes and contribute to spatial aggregate statistics (density, averaged measures by location and time, spatial interpolation <ref type="bibr" target="#b35">[36]</ref>) which in turn, benefit the whole community. As an alternative to the classical centralized architecture, the distributed PDMS paradigm increases the privacy guarantees for the users, thus encouraging their participation. A mobile user can generate sensing data (e.g., using her smartphone or vehicular systems) which is securely transmitted and recorded into her PDMS (e.g., a home box). This way each PDMS becomes a potential data source in the system. These data can then be aggregated by a small subset of data processor nodes to produce the required spatial aggregate statistics, which can be broadcasted to all the participating nodes.</p><p>Use case 2: Users can subscribe to information flows based on their preference or user profile (e.g., RSS feeds, specific product promotions or ads, etc.). A user profile can be represented by a set of concepts associating metadata terms (e.g., location, age, occupation, income, etc.) to values specific to each user. These associations are traditionally stored at a publication server to allow targeting the interested nodes. Instead, we propose to distributively store and index those profiles in SEP2P, thus greatly improving users' privacy. We call a concept index, an index associating for each concept the list of node addresses having this concept. Storing and searching this concept index is straightforward with a DHT. Each node does a store(concept, IPaddress) for each concept in its profile. To find all the nodes matching a certain target profile (e.g., a logical expression of concepts), a DHT search is launched for each concept in the profile. Then, a set of randomly selected data processors are used to pick up the scattered pieces of the concept index, apply the logical expression of the target profile and compute the matching target nodes (TN ), i.e., their IP addresses. Finally, the information is sent to the selected targets.</p><p>Use case 3: We consider queries over the personal data contributed by a large set of individuals, e.g., to compute recommendations, make participative studies. To achieve a high degree of pertinence and avoid flooding the system, such queries should target only a specific subset of the nodes, i.e., the nodes exposing a given user profile. Query examples are numerous, e.g., get the top-10 ranked movies by academics from Paris, or find the average number of sick leave days of pilots in their forties. The query processing is done in two steps which roughly correspond to the use case 2 combined with use case 1. First, the relevant subset of nodes, which match the query profile, must be discovered (use case 2). Then, the selected subset of target nodes become data sources which supply the required data (e.g., number of sick leave days) to compute the query result (use case 1). The main differences are that only the selected nodes provide data and that the result is transmitted only to the querier node and not to the entire system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Detailed Node Roles</head><p>From the above description, we can define new node roles: Node role 4. A metadata indexer (MI ) stores part of the metadata shared by the nodes, allowing pertinent and efficient distributed data processing.</p><p>Node role 5. A target finder (TF), applies a logical expression on its input to produce a list of target nodes.</p><p>Node role 6. A data aggregator (DA) applies an aggregative function to its input and produces partially aggregated results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Node role 7.</head><p>A main data aggregator (MDA) aggregates its input and produces the final result. These roles allow designing distributed execution plans for the three use cases as shown in Figure <ref type="figure" target="#fig_5">9</ref>. The nodes that must be chosen using the SEP2P protocol are shown in pink, and we used the symbol √ to denote that a node is a verifier (as specified in Section 3.6). This must be done each time a node discloses some sensitive data, thus on data sources and metadata indexers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Towards Task Atomicity</head><p>The node roles and DEP proposed above already provide some task compartmentalization dividing the whole processing in tasks. However, much more can be done to minimize the impact of data leakage. In this section we present a few methods to achieve task atomicity. Our objective is mainly to show that task atomicity can be indeed performed and that it can significantly improve the system security when used in conjunction with the secure random actor selection. Given the space limitation, a detailed study of task atomicity is left for future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Metadata index protection:</head><p>The concept index design already exhibits some form of task atomicity: (1) it is evenly distributed among all the nodes using the DHT mechanisms; (2) the imposed location of nodes in the DHT (see Section 3.2) leads to a randomized association between concepts and MI nodes. Nevertheless, a single corrupted node could disclose all the index information it owns. Further security improvements can be obtained by splitting each concept into s shares using the Shamir's secret sharing technique <ref type="bibr" target="#b31">[32]</ref> which requires knowing at least p (p ≤ s) shares to reconstruct the secret. Disclosing a single concept will now require p colluding nodes randomly selected.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>User data protection:</head><p>We consider here sensed data in use case 1 or the result of queries performed on a single PDMS in use case 2. Considering several DAs already reduces the impact of potential data leakage by a corrupted DA node. A simple way to reduce further this impact is to realize the aggregation on anonymized data (e.g., average traffic speed without user identity) or data without semantics (e.g., averaging data, a salary for instance, without knowing its meaning) or even encrypted data (with deterministic encryption). Note also that aggregation is continuous in the mobile sensing use case and that selected DA node will change at each iteration.</p><p>User identity protection: User's PDMS actively participate in the DEP either by receiving information (use case 1) or queries (use case 3) or by sending information (use cases 2 and 3). They thus communicate with DA nodes or receive messages from TF nodes, both being potentially corrupted. The reception/transmission task should be "isolated" to make one more step towards task atomicity. This can be achieved using the notion of proxy-forwarder that we illustrate for the TN -DA communication in the use case 3. The TN (which is actually a data source) must transmit its local result (e.g., number of sick leave days) to the DA node. TN can choose randomly any node P in the system and send the data, encrypted with the public key of the DA (known from the Verifiable Actor List). P will receive this data and transmit it to the DA. Thus, DA will have the data without knowing the sender, while P will know the sender but not the data. Note that (1) TN has good reasons to choose randomly P since it is the most interested in protecting its data; (2) the probability that both DA and P to be colluding nodes is extremely low (≈ (C/N ) 2 ); and</p><p>(3) we could use several proxies, thus mimicking anonymization network techniques (e.g., Tor).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">RELATED WORK</head><p>DHT security. Several works focus on DHT security <ref type="bibr" target="#b39">[40]</ref> considering the following attacks: (i) Sybil attack: an attacker generates numerous false DHT nodes to outnumber the honest nodes. Introducing an (offline) certificate authority, is deemed to be among the most effective defenses against the Sybil attack <ref type="bibr" target="#b10">[11]</ref>. (ii) Routing table poisoning (eclipse attack): an attacker attempts to control most of the neighbors of honest nodes to isolate them. According to <ref type="bibr" target="#b39">[40]</ref> the best strategy against such attacks is to constrain the DHT node identifiers. Again, using a central authority to provide verifiable identifiers is the simplest yet most effective way of achieving this goal <ref type="bibr" target="#b33">[34]</ref>. (iii) Routing and storage attacks: Sybil and eclipse attacks do not directly impact the DHT, they are mainly necessary means for future attacks, like various denials of service (DoS). For instance, the objectives might be to prevent a lookup request from reaching its destination, denying the existence of a valid key, or impersonating another node to deliver false data. These DoS attacks are usually classified as routing and storage attacks and most of the mechanisms employed to negate them are based on redundancy: at the storage and routing levels <ref type="bibr" target="#b39">[40]</ref>. Thus, none of these works consider the secure and efficient actor selection for distributed processing as in SEP2P.</p><p>Secure Multi-party Computation and differential privacy. Cryptographic protocols have been proposed to protect the users' privacy in distributed computations with a focus on data confidentiality enforcement in personal data aggregation. Examples of computations related to this work are personal time-series clustering <ref type="bibr" target="#b1">[2]</ref>, kNN similarity queries <ref type="bibr" target="#b16">[17]</ref>, and location-based aggregate statistics <ref type="bibr" target="#b27">[28]</ref>. However, MPC raises major scalability issues which in practice limit such protocols to specific types of computations <ref type="bibr" target="#b30">[31]</ref>.</p><p>Although it yields interesting results in privacy protection <ref type="bibr" target="#b14">[15]</ref>, differential privacy generally requires a central trusted aggregating node and ad-hoc adaptations depending on the targeted queries. As we search to provide a generic framework and exclude having a central actor to avoid a single point of failure, both requirements cannot be met by differential privacy. Even though local differential privacy <ref type="bibr" target="#b12">[13]</ref> tries to address our first requirement, the solutions offered until now are still not generic, while the pertinence or the quality of the results may still be problematic with some applications <ref type="bibr" target="#b12">[13]</ref>. Also, differential privacy exhibits intrinsic limitations with applications requiring continuous data flow aggregation (e.g., such as mobile participatory sensing) because of temporal correlation between consecutive data batches <ref type="bibr" target="#b9">[10]</ref>.</p><p>Distributed data aggregation using secure hardware. To overcome the limitations of MPC or differential privacy, several works propose using secure hardware at the user-side. Several secure protocols have been proposed for SQL aggregation <ref type="bibr" target="#b36">[37]</ref>, spatio-temporal aggregation <ref type="bibr" target="#b35">[36]</ref>, top-k full-text search <ref type="bibr" target="#b20">[21]</ref>, or privacy-preserving data publishing <ref type="bibr" target="#b2">[3]</ref>. SEP2P also considers a secure PDMS at the user-side but our attack model considers having many colluding nodes. Moreover, the focus in SEP2P is on the secure and efficient random node selection. Differently, existing work focus on data aggregation or publishing and consider that all the nodes in the network participate in the protocol with their data being thus complementary to SEP2P.</p><p>Secure server-centric approaches. The above cited solutions are based on fully-distributed (P2P) or hybrid architectures. Alternatively, one could envision a solution based on a secured centralized server <ref type="bibr" target="#b5">[6]</ref>. However, this raises important issues. First, users are exposed to sophisticated attacks, whose cost-benefit is high on a centralized database. Second, centralizing all users' data into one powerful server makes little sense in the PDMS context in which data is naturally distributed at the users' side. Hence, users might be reluctant to use such a massively centralized data service. Finally, new legislation such as the European GDPR <ref type="bibr" target="#b26">[27]</ref> may hinder the development of such centralized solutions. Personal Data Management Systems arrive at a rapid pace allowing users to share their personal data within large P2P communities. While the benefits are unquestionable, the important risks of private personal data leakage and misuse represent a major obstacle on the way of the massive adoption of such systems. This paper is one of the first efforts to deal with this important and challenging issue. To this end, we proposed SEP2P, a fully-distributed P2P system laying the foundation for secure, efficient and scalable execution of distributed computations. By considering a realistic threat model, we analyzed the fundamental security and efficiency requirements of such a distributed system. We showed that the secure selection of random actor nodes is the basis of security for any distributed computation. Then, we proposed secure and highly efficient protocols to address the actor selection problem. Our simulation-based experimental evaluation indicates that our protocol leads to minimal private information leakage, i.e., increasing linearly with the number of colluding nodes. At the same time, the cost of the security mechanisms depends only on the maximum number of colluding nodes and remains very low even with wide collusion attacks.</p><p>This work opens the way for several interesting research problems. In particular, to further minimize the impact of a private data leakage, one should complement our random actor selection with task atomicity, i.e., decompose the computation process such that it minimizes the amount of sensitive data the processor nodes have access to. To underline the importance of this requirement, we discussed in this paper three types of representative applications in the PDMS context and provided sketches of solutions to achieve task atomicity. Certainly, this problem deserves a deeper look and constitutes our main objective as future work.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Sketch of verifiable selection</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Verifiable random</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>8 )</head><label>8</label><figDesc>Each SL j does the following: (a) Checks VRND T and computes RND T (see Section 3.4). (b) Checks that each (RND j , CL j ) from L 2 is consistent with the corresponding hash(RND j ∥ CL j ) from L 1 . (c) Computes the union, after removing possible duplicates, of all CL j to obtain a candidate list of legitimate nodes CL. (d) Computes the RND S = RND 1 ⊕ RND 2 ⊕ • • • ⊕ RND k . (e) Sorts CL on kpub n ⊕ RND S (where kpub n is the public key of a node n ∈ CL) and selects the A first candidates to build the actor list AL. (f) Checks the legitimacy of AL nodes w.r.t. R 3 . (g) Signs (RND T , AL) and sends it to S . (9) S gathers k results and builds the verifiable actor lists: VAL = (RND T , AL, (sign j (RND T , AL))) j ∈[1, k ] .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :Figure 4 :Figure 5 :Figure 7 :Figure 8 :</head><label>34578</label><figDesc>Figure 3: Sec. Effectiveness vs Verification Verification cost (Nb of asymmetric crypto-operations)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: k versus C (N and ∝ vary) Nb of colluding corrupted node in the system (log)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 9 :</head><label>9</label><figDesc>Figure 9: Distributed execution plans for the use cases</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>N</head><label></label><figDesc>Total number of nodes in the SEP2P system A Number of actor nodes (data processors) C Maximum number of colluding nodes (C ≥ 1) A CAverage number of corrupted actors for a given protocol A ideal C Average number of corrupted actors for an ideal protocol</figDesc><table><row><cell>T</cell><cell>Triggering node (starting the execution)</cell></row><row><cell>k</cell><cell>Security degree</cell></row><row><cell>α</cell><cell>Security threshold</cell></row><row><cell>S</cell><cell>Execution Setter node, computing actor list</cell></row><row><cell>R i , rs i</cell><cell>DHT region R i of size rs i</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>Main notations for Sections 3.1 and 3.2</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>.</figDesc><table><row><cell>kpub n</cell><cell>Public key of node n</cell></row><row><cell>cert n</cell><cell>Trustworthy certificate of node n</cell></row><row><cell>sign n</cell><cell>Signature by node n (includes cert n )</cell></row><row><cell>TL i</cell><cell>execution Trigger Legitimate node i</cell></row><row><cell>RND i</cell><cell>Random number generated by TL i</cell></row><row><cell cols="2">(V ) RND T (Verifiable) random generated by T</cell></row><row><cell>SL j</cell><cell>execution Setter Legitimate node j</cell></row><row><cell>RND S</cell><cell>Random generated by S</cell></row><row><cell>CL j</cell><cell>Partial candidate list of legitimate nodes w.r.t. R 3</cell></row><row><cell>CL</cell><cell>Candidate List of legitimate nodes</cell></row><row><cell>(V ) AL</cell><cell>(Verifiable) Actor List</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 :</head><label>2</label><figDesc>Main notations for Sections 3.3 -3.5 Definition 4. Legitimate nodes. Given a region R in the virtual space of a DHT, for any node i we say that node i is legitimate w.r.t. R iff hash(kpub i ) ∈ R.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 3 :</head><label>3</label><figDesc>Strategies, parameters and metrics</figDesc><table /></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Secure personal data servers: a vision paper</title>
		<author>
			<persName><forename type="first">Tristan</forename><surname>Allard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicolas</forename><surname>Anciaux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luc</forename><surname>Bouganim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanli</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lionel</forename><forename type="middle">Le</forename><surname>Folgoc</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Philippe</forename><surname>Pucheral</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Indrajit</forename><surname>Ray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Indrakshi</forename><surname>Ray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shaoyi</forename><surname>Yin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the VLDB Endowment</title>
		<meeting>the VLDB Endowment</meeting>
		<imprint>
			<date type="published" when="2010">2010. 2010</date>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="25" to="35" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Chiaroscuro: Transparency and privacy for massive personal time-series clustering</title>
		<author>
			<persName><forename type="first">Tristan</forename><surname>Allard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Georges</forename><surname>Hébrail</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Florent</forename><surname>Masseglia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Esther</forename><surname>Pacitti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 ACM SIGMOD International Conference on Management of Data</title>
		<meeting>the 2015 ACM SIGMOD International Conference on Management of Data</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="779" to="794" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">METAP: revisiting Privacy-Preserving Data Publishing using secure devices</title>
		<author>
			<persName><forename type="first">Tristan</forename><surname>Allard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Philippe</forename><surname>Pucheral</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Distributed and Parallel Databases</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="191" to="244" />
			<date type="published" when="2014">2014. 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Personal Data Management Systems: The security and functionality standpoint</title>
		<author>
			<persName><forename type="first">Nicolas</forename><surname>Anciaux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Philippe</forename><surname>Bonnet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luc</forename><surname>Bouganim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Philippe</forename><surname>Pucheral</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Iulian</forename><surname>Sandu Popa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guillaume</forename><surname>Scerri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Systems</title>
		<imprint>
			<biblScope unit="volume">80</biblScope>
			<biblScope unit="page" from="13" to="35" />
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">MILo-DB: a personal, secure and portable database machine</title>
		<author>
			<persName><forename type="first">Nicolas</forename><surname>Anciaux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luc</forename><surname>Bouganim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Philippe</forename><surname>Pucheral</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanli</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lionel</forename><forename type="middle">Le</forename><surname>Folgoc</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shaoyi</forename><surname>Yin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Distributed and Parallel Databases</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="37" to="63" />
			<date type="published" when="2014">2014. 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Secure database-as-a-service with cipherbase</title>
		<author>
			<persName><forename type="first">Arvind</forename><surname>Arasu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Spyros</forename><surname>Blanas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ken</forename><surname>Eguro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Manas</forename><surname>Joglekar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Raghav</forename><surname>Kaushik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Donald</forename><surname>Kossmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ravi</forename><surname>Ramamurthy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Prasang</forename><surname>Upadhyaya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ramarathnam</forename><surname>Venkatesan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 ACM SIGMOD International Conference on Management of Data</title>
		<meeting>the 2013 ACM SIGMOD International Conference on Management of Data</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="1033" to="1036" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Security against covert adversaries: Efficient protocols for realistic adversaries</title>
		<author>
			<persName><forename type="first">Yonatan</forename><surname>Aumann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yehuda</forename><surname>Lindell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Theory of Cryptography Conference</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="137" to="156" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">CSAR: A Practical and Provable Technique to Make Randomized Systems Accountable</title>
		<author>
			<persName><forename type="first">Michael</forename><surname>Backes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Druschel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andreas</forename><surname>Haeberlen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dominique</forename><surname>Unruh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NDSS</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="341" to="353" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Find Your Health Data</title>
		<author>
			<persName><forename type="first">Blue</forename><surname>Button</surname></persName>
		</author>
		<ptr target="https://www.healthit.gov/topic/health-it-initiatives/blue-button" />
		<imprint>
			<date type="published" when="2010-10-12">2010. 2010. October 12, 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Quantifying Differential Privacy under Temporal Correlations</title>
		<author>
			<persName><forename type="first">Yang</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Masatoshi</forename><surname>Yoshikawa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yonghui</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Li</forename><surname>Xiong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">33rd IEEE International Conference on Data Engineering</title>
		<imprint>
			<date type="published" when="2017">2017. 2017</date>
			<biblScope unit="page" from="821" to="832" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Secure routing for structured peer-to-peer overlay networks</title>
		<author>
			<persName><forename type="first">Miguel</forename><surname>Castro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Druschel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ayalvadi</forename><surname>Ganesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Antony</forename><surname>Rowstron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><forename type="middle">S</forename><surname>Wallach</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM SIGOPS Operating Systems Review</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="299" to="314" />
			<date type="published" when="2002">2002. 2002</date>
			<publisher>SI</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Your digital home</title>
		<ptr target="https://cozy.io/en" />
		<imprint>
			<date type="published" when="2013-10-12">2013. 2013. October 12, 2018</date>
			<publisher>Cozy Cloud</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Privacy at Scale: Local Differential Privacy in Practice</title>
		<author>
			<persName><forename type="first">Graham</forename><surname>Cormode</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Somesh</forename><surname>Jha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tejas</forename><surname>Kulkarni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ninghui</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Divesh</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tianhao</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 International Conference on Management of Data, SIGMOD Conference</title>
		<meeting>the 2018 International Conference on Management of Data, SIGMOD Conference</meeting>
		<imprint>
			<date type="published" when="2018">2018. 2018</date>
			<biblScope unit="page" from="1655" to="1658" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">openpds: Protecting the privacy of metadata through safeanswers</title>
		<author>
			<persName><forename type="first">Yves-Alexandre</forename><surname>De Montjoye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Erez</forename><surname>Shmueli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><forename type="middle">Sandy</forename><surname>Samuel S Wang</surname></persName>
		</author>
		<author>
			<persName><surname>Pentland</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PloS one</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page">98790</biblScope>
			<date type="published" when="2014">2014. 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Collecting Telemetry Data Privately</title>
		<author>
			<persName><forename type="first">Janardhan</forename><surname>Bolin Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sergey</forename><surname>Kulkarni</surname></persName>
		</author>
		<author>
			<persName><surname>Yekhanin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 30: Annual Conference on Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2017">2017. 2017</date>
			<biblScope unit="page" from="3574" to="3583" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">The mesinfos project explores the self data concept in france</title>
		<author>
			<persName><surname>Fing</surname></persName>
		</author>
		<ptr target="http://mesinfos.fing.org/english" />
		<imprint>
			<date type="published" when="2013-07">2013. July 2013. October 12, 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Hide &amp; Share: Landmark-based Similarity for Private KNN Computation</title>
		<author>
			<persName><forename type="first">Davide</forename><surname>Frey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rachid</forename><surname>Guerraoui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anne-Marie</forename><surname>Kermarrec</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Antoine</forename><surname>Rault</surname></persName>
		</author>
		<author>
			<persName><forename type="first">François</forename><surname>Taïani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jingjing</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">45th Annual IEEE/IFIP International Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2015">2015. 2015</date>
			<biblScope unit="page" from="263" to="274" />
		</imprint>
	</monogr>
	<note>Dependable Systems and Networks (DSN)</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">A practical hardware-assisted approach to customize trusted boot for mobile devices</title>
		<author>
			<persName><forename type="first">Javier</forename><surname>González</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Hölzl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Riedl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Philippe</forename><surname>Bonnet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">René</forename><surname>Mayrhofer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Information Security</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="542" to="554" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Want to scale in centralized systems? Think P2</title>
		<author>
			<persName><forename type="first">Anne-Marie</forename><surname>Kermarrec</surname></persName>
		</author>
		<author>
			<persName><forename type="first">François</forename><surname>Taïani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">P. J. Internet Services and Applications</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="16" />
			<date type="published" when="2015">2015. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Supporting secure keyword search in the personal cloud</title>
		<author>
			<persName><forename type="first">Saliha</forename><surname>Lallali</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicolas</forename><surname>Anciaux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Iulian</forename><surname>Sandu Popa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Philippe</forename><surname>Pucheral</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Systems</title>
		<imprint>
			<biblScope unit="volume">72</biblScope>
			<biblScope unit="page" from="1" to="26" />
			<date type="published" when="2017">2017. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Distributed secure search in the personal cloud</title>
		<author>
			<persName><forename type="first">Thi</forename><surname>Bao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thu</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicolas</forename><surname>Anciaux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sébastien</forename><surname>Gilloton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Saliha</forename><surname>Lallali</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Philippe</forename><surname>Pucheral</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Iulian</forename><surname>Sandu Popa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chao</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">19th International Conference on Extending Database Technology (EDBT</title>
		<imprint>
			<date type="published" when="2016">2016. 2016</date>
			<biblScope unit="page" from="652" to="655" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">π Box: A Platform for Privacy-Preserving Apps</title>
		<author>
			<persName><forename type="first">Sangmin</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Edmund</forename><forename type="middle">L</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Deepak</forename><surname>Goel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mike</forename><surname>Dahlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vitaly</forename><surname>Shmatikov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NSDI</title>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="501" to="514" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Kademlia: A peer-to-peer information system based on the xor metric</title>
		<author>
			<persName><forename type="first">Petar</forename><surname>Maymounkov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Mazieres</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Workshop on Peer-to-Peer Systems</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="53" to="65" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<author>
			<persName><forename type="first">Alfred</forename><surname>Menezes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paul</forename><forename type="middle">C</forename><surname>Van Oorschot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Scott</forename><forename type="middle">A</forename><surname>Vanstone</surname></persName>
		</author>
		<title level="m">Handbook of Applied Cryptography</title>
		<imprint>
			<publisher>CRC Press</publisher>
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">The midata vision of consumer empowerment</title>
		<author>
			<persName><surname>Midata</surname></persName>
		</author>
		<ptr target="https://www.gov.uk/government/news/the-midata-vision-of-consumer-empowerment" />
		<imprint>
			<date type="published" when="2011-10-12">2011. 2011. October 12, 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Protecting your data</title>
		<author>
			<persName><surname>Nextcloud</surname></persName>
		</author>
		<ptr target="https://nextcloud.com" />
		<imprint>
			<date type="published" when="2016-06">2016. Jun 2016. October 12, 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title/>
		<ptr target="https://eur-lex.europa.eu/legal-content/EN/TXT/HTML/?uri=CELEX:32016R0679" />
	</analytic>
	<monogr>
		<title level="j">General Data Protection Regulation. Law</title>
		<imprint>
			<date type="published" when="2016-04-27">2016. 27 April 2016. October 12, 2018</date>
			<publisher>European Parliament</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Privacy and accountability for location-based aggregate statistics</title>
		<author>
			<persName><forename type="first">Ada</forename><surname>Raluca</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><forename type="middle">J</forename><surname>Popa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hari</forename><surname>Blumberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Frank</forename><forename type="middle">H</forename><surname>Balakrishnan</surname></persName>
		</author>
		<author>
			<persName><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 18th ACM conference on Computer and communications security</title>
		<meeting>the 18th ACM conference on Computer and communications security</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="653" to="666" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">EnclaveDB: A Secure Database using SGX</title>
		<author>
			<persName><forename type="first">Christian</forename><surname>Priebe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kapil</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Manuel</forename><surname>Costa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EnclaveDB: A Secure Database using SGX</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">0</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">A scalable content-addressable network</title>
		<author>
			<persName><forename type="first">Sylvia</forename><surname>Ratnasamy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paul</forename><surname>Francis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><surname>Handley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Karp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Scott</forename><surname>Shenker</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001">2001</date>
			<publisher>ACM</publisher>
			<biblScope unit="volume">31</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Processing over encrypted data: between theory and practice</title>
		<author>
			<persName><forename type="first">Eyad</forename><surname>Saleh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ahmad</forename><surname>Alsa'deh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ahmad</forename><surname>Kayed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christoph</forename><surname>Meinel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM SIGMOD Record</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="5" to="16" />
			<date type="published" when="2016">2016. 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">How to share a secret</title>
		<author>
			<persName><forename type="first">Adi</forename><surname>Shamir</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Commun. ACM</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="612" to="613" />
			<date type="published" when="1979">1979. 1979</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Solid empowers users and organizations to separate their data from the applications that use it</title>
		<author>
			<persName><surname>Solid</surname></persName>
		</author>
		<ptr target="https://solid.inrupt.com/" />
		<imprint>
			<date type="published" when="2018-10-12">2018. 2018. October 12, 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Chord: A scalable peer-to-peer lookup service for internet applications</title>
		<author>
			<persName><forename type="first">Ion</forename><surname>Stoica</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><surname>Morris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Karger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Frans Kaashoek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hari</forename><surname>Balakrishnan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM SIGCOMM Computer Communication Review</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="149" to="160" />
			<date type="published" when="2001">2001. 2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Building a Secure System using TrustZone Technology</title>
		<imprint>
			<date type="published" when="2008">2008</date>
			<publisher>ARM Security Technology</publisher>
		</imprint>
		<respStmt>
			<orgName>ARM</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">PAMPAS: Privacy-Aware Mobile Participatory Sensing Using Secure Probes</title>
		<author>
			<persName><forename type="first">Dai</forename><surname>Hai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ton</forename><surname>That</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Iulian</forename><surname>Sandu Popa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Karine</forename><surname>Zeitouni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cristian</forename><surname>Borcea</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th International Conference on Scientific and Statistical Database Management</title>
		<meeting>the 28th International Conference on Scientific and Statistical Database Management</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="volume">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Private and scalable execution of SQL aggregates on a secure decentralized architecture</title>
		<author>
			<persName><forename type="first">Quoc-Cuong</forename><surname>To</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Philippe</forename><surname>Pucheral</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Database Systems (TODS)</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">16</biblScope>
			<date type="published" when="2016">2016. 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">RoSeS: a continuous query processor for large-scale RSS filtering and aggregation</title>
		<author>
			<persName><forename type="first">Creus</forename><surname>Jordi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bernd</forename><surname>Tomàs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicolas</forename><surname>Amann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Travers</surname></persName>
		</author>
		<author>
			<persName><surname>Vodislav</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 20th ACM Conference on Information and Knowledge Management</title>
		<meeting>the 20th ACM Conference on Information and Knowledge Management</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="2549" to="2552" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">A survey of DHT security techniques</title>
		<author>
			<persName><forename type="first">Guido</forename><surname>Urdaneta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guillaume</forename><surname>Pierre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maarten</forename><surname>Van Steen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Computing Surveys (CSUR)</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">8</biblScope>
			<date type="published" when="2011">2011. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Octopus: A secure and anonymous DHT lookup</title>
		<author>
			<persName><forename type="first">Qiyan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nikita</forename><surname>Borisov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Distributed Computing Systems (ICDCS)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2012">2012. 2012</date>
			<biblScope unit="page" from="325" to="334" />
		</imprint>
	</monogr>
	<note>IEEE 32nd International Conference on</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
