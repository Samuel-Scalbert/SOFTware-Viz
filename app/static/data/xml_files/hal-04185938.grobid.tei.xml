<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="fr">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">User-friendly exploration of highly heterogeneous data lakes</title>
				<funder ref="#_5NHHPgM #_MPxTJ3a #_cbV8paq">
					<orgName type="full">unknown</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Nelly</forename><surname>Barret</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Inria</orgName>
								<orgName type="institution" key="instit2">Institut Polytechnique de Paris</orgName>
								<address>
									<country key="FR">France</country>
								</address>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Inria</orgName>
								<orgName type="institution" key="instit2">Institut Polytechnique de Paris</orgName>
								<address>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Simon</forename><surname>Ebel</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Inria</orgName>
								<orgName type="institution" key="instit2">Institut Polytechnique de Paris</orgName>
								<address>
									<country key="FR">France</country>
								</address>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Inria</orgName>
								<orgName type="institution" key="instit2">Institut Polytechnique de Paris</orgName>
								<address>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Théo</forename><surname>Galizzi</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Inria</orgName>
								<orgName type="institution" key="instit2">Institut Polytechnique de Paris</orgName>
								<address>
									<country key="FR">France</country>
								</address>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Inria</orgName>
								<orgName type="institution" key="instit2">Institut Polytechnique de Paris</orgName>
								<address>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Ioana</forename><surname>Manolescu</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Inria</orgName>
								<orgName type="institution" key="instit2">Institut Polytechnique de Paris</orgName>
								<address>
									<country key="FR">France</country>
								</address>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Inria</orgName>
								<orgName type="institution" key="instit2">Institut Polytechnique de Paris</orgName>
								<address>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Madhulika</forename><surname>Mohanty</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Inria</orgName>
								<orgName type="institution" key="instit2">Institut Polytechnique de Paris</orgName>
								<address>
									<country key="FR">France</country>
								</address>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Inria</orgName>
								<orgName type="institution" key="instit2">Institut Polytechnique de Paris</orgName>
								<address>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">User-friendly exploration of highly heterogeneous data lakes</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">E1EEC436DA6D9A1EBB9719D76FB19B34</idno>
					<note type="submission">Submitted on 8 Sep 2023</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-04-12T14:50+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Heterogeneous data</term>
					<term>Data lake</term>
					<term>Data exploration</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>niveau recherche, publiés ou non, émanant des établissements d'enseignement et de recherche français ou étrangers, des laboratoires publics ou privés.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="fr">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>1 Outline: highly heterogeneous data lakes</p><p>The past few decades have seen an important rise in the production of digital data. This data spans across multiple domains, e.g., healthcare, environment, finance, administration; it is owned and used by many actors other than the data producers, notably data journalists and researchers for crucial data journalism applications. The heterogeneity poses multiple challenges for data integration, its exploration and understanding of the data. Data lakes <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b9">10]</ref> are centralized repositories designed to store, process, and secure large amounts of structured, semi-structured, and unstructured data. A data lake stores data in its native format and supports various styles of data processing; the data model most often considered in such settings is relational, e.g., <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b10">11]</ref>. ConnectionLens <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b2">3]</ref> is a data lake system integrating such heterogeneous data in a graph format, capturing the fine-granularity structure that (semi-)structured data sources may have. Further, ConnectionLens applies Information Extraction techniques to identify, from any value (leaf) node encountered in the data, entities such as people, places, organizations, emails, URIs, dates, etc. Such entities are very appealing in particular to data journalists, because they are at the heart of their work: analyzing the activity of entities of particular interest, e.g., political leaders, or companies, and finding how those entities may be connected. Con-nectionStudio supports querying this integrated graph using keyword search <ref type="bibr" target="#b3">[4]</ref> and entity path enumeration <ref type="bibr" target="#b4">[5]</ref>. Using keyword search, users submit keywords that interest them, and ConnectionLens returns connecting trees, showing how, in the graph, nodes matching the keywords are connected. When the users know the types of entities of interest (which is the case with data journalists), an efficient entity path enumeration algorithm enumerates and allows visualizing paths that connect entities of interest, e.g., a politician owns shares in a company, or a politician's wife serves in the governing board of a company, etc.</p><p>New requirements for non-expert users Working with journalists, we found that heterogeneous graphs produced by ConnectionLens were still hard for them to comprehend. They found it difficult (α) relating the documents they added to the data lake, to the resulting data graphs; (β) figuring out what keywords to use when searching; (γ) generally, working with the data graph paradigm. It turns out that in their profession, those with digital skills are especially at ease with spreadsheet tools, thus data tables are appealing to them, while data graphs are not. Further, (δ) ConnectionLens graphs interconnect data through extracted entities; like any trained model, our extractors introduce some errors (false positives, false negatives, wrongly typed entities). In some cases, especially when a dataset has some regularity, users can provide guidance on what entities are to be expected in certain parts of the data, thus contribute to increasing the graph quality. To articulate such guidance, they need to be able to inspect the data, and to formulate extraction hints. Moreover, ( ) journalists formulated the need for tangible, intuitive data analysis results (diagrams, graphs, tables) that they can download from our graph data lake and share, for instance, within newsrooms, to convince colleagues or managers of the interest of spending time to analyze complex data.</p><p>Based on these requirements, we built ConnectionStudio, a new platform based on ConnectionLens and extending it in several ways in order to address (α) to ( ) above. Below, after recalling basic information about ConnectionLens to make this paper self-contained, we detail ConnectionStudio's novel extensions, which are the contributions of this work. We believe they may help others devising similar heterogeneous data lakes. ConnectionStudio is available online, together with examples and tutorials at https://connectionstudio.inria.fr/.</p><p>2 Background: graph integration of heterogeneous data ConnectionLens ingests any structured, semi-structured or unstructured data as follows. When ingesting an XML document, each element, attribute, or text node becomes a graph node; parent-child relationships in the XML document lead to corresponding edges in the graph. A JSON document is similarly converted: each map, array, and (leaf) value is converted into a graph node. RDF graphs are most easily ingested: each triple of the form s, p, o leads to two nodes labelled "s" and "o" connected through an p-labelled edge. For CSV and relational data, each tuple and value lead to a node, edges labelled with the column names are connecting those (if the column name is empty, so the edge label). Text documents are segmented into paragraph, each of which is a node, child of a common root. Office and PDF documents are converted into JSON then ingested as above.</p><p>NER (Named Entity Recognition) is applied on every leaf node of the graph, leading to (new) extracted entity nodes. Each entity node is labelled with the recognised named entity (NE, in short) and connected to the leaf value from which it has been extract through an edge (dashed edges in Figure <ref type="figure" target="#fig_0">1</ref>). Moreover, when two NE nodes are identical, i.e. they have the exact same label, they are fused and only one is kept in the integrated graph. This allows to easily find connections across sources, that are (much) harder to find manually. For instance, there is only one node "Thales", extracted from N18 and N43.</p><p>Figure <ref type="figure" target="#fig_0">1</ref> shows the data graph obtained from (i) an XML sample of the large HATVP French transparency dataset (ministers' declarations about their wealth, stocks they own, business interests, etc.), on the left; and (ii) a CSV file listing the 40 most influential French companies (known as CAC40), on the right. Each (black) circle is a data node in the integrated data graph, edges are connecting them accordingly to their relationships in the datasets. Value data nodes are quoted; named entities are highlighted (blue for people, purple for dates and yellow for organizations).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Novel ConnectionStudio modules</head><p>Built on top of ConnectionLens, ConnectionStudio allows users to import datasets into an integrated graph, search the graph via keywords, and find paths connecting entities. Further, ConnectionStudio includes new modules, to answer the requirements stated at the end of Section 1. We describe them below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Global view of the data lake: entity (dataset) statistics</head><p>Users are familiar with the data files they brought (PDF, Office formats, JSON, CSV, etc.), but told us they felt "lost" once the system ingested their data, especially if the latter is large and/or complex. To help them get a first global view of the data lake (or graph, requirement (α)), we present them a set of entity and entity-dataset statistics, as follows:</p><p>-The total numbers of entities of each type (Person, Location, Organization, date, URI, email, hashtag, mention), overall in the graph; -The total number of entities per type and per dataset in which they appear; -A tag cloud of the most frequent entities in the whole graph.</p><p>-A summary of the entity-dataset associations: we show the entity type, label, and datasets where it appears, starting with the entities present in the highest number of datasets. These entities are more interesting, because they allow making connections across datasets (potentially heterogeneous files), saving important manual efforts to journalists combining such data sources for their investigations.</p><p>The above statistics give a first idea of what the datasets contain, and also suggest entity names to use as search keywords (requirement (β)). For instance, Figure <ref type="figure" target="#fig_2">2a</ref> shows the number of different types of extracted entities and the tag cloud in the dataset of Figure <ref type="figure" target="#fig_0">1</ref>. Figure <ref type="figure" target="#fig_2">2b</ref> shows the frequent common entities in the two datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">From the integrated graph to data tables</head><p>In a prior ConnectionLens application <ref type="bibr" target="#b2">[3]</ref>, based on PubMed biomedical literature data, journalists were interested in the paths that connect medical experts with companies that fund their research. We expressed this path as a query over the graph, and exposed its results as a table through an ad-hoc Web interface manually built just for this scenario. In a more general manner, in <ref type="bibr" target="#b4">[5]</ref>, users select a pair of entity types (τ 1 , τ 2 ) of interest to them, e.g., people and organizations, and the system automatically finds and computes the paths connecting such entities in the ConnectionLens graph. Each path leads to a data table, where entities of types τ 1 , τ 2 are in the first, resp., last column, and the other columns are the nodes along the path. As stated in requirement (γ), users requested more support in extracting tabular data from the graph. For instance, in the HATVP dataset, they may want to extract: for each elected politician, their name, elected office, election date, and companies they have stocks in; note that this query is not a path, since it returns many values. Users view the first three fields as required, but the last one is optional, i.e., a politician should be part of the result even if they have no stocks. Optional query fragments correspond to outerjoins in database terms.</p><p>To allow users to easily and intuitively express a much larger set of queries, we proceed as follows.  (1) Upon loading, ConnectionStudio computes, from each dataset, a set of elementary paths that can be seen as "query building blocks". Each path reflects one or more consecutive edges in the data graph. The source of a path is always an internal node, while its destination is either an internal node, a value, or an extracted entity. For instance, in the above example, elementary paths include: declarations, declarations.declaration, declarations.declaration.general.declarer.name#val (this ends in strings comprising politicians' names), declarations.declaration.general.declarer.name#val.extract:p (ending in person entities extracted from the strings), etc.</p><p>(2) Users can select paths from a drop-down list, and add them one by one to compose a query. The first selected path is required; the others can be either optional or required. To each path are associated two variables: one for the source node, and the other for the destination (internal node, value, or entity). Users can edit the paths, and the variables, to adjust them, and specify how they connect. For instance, in the HATVP scenario, a user may:</p><p>-Start by selecting a path ending in declaration; name its starting point (source variable) decls and its end point (target variable) decl. (3) When the user has finished specifying the paths to combine in a query, they can trigger the evaluation of this query on the underlying graph. This leads to tabular results, with a column for each user-specified variable and a line for each result; users can download results in CSV to be further processed, shared etc.</p><p>For instance, Figure <ref type="figure" target="#fig_3">3</ref> shows the result of joining three paths and renaming the variables to obtain the declaration number, the start date, the position and the name of the person. Generating elementary paths As explained above, users can compose queries by "cutting &amp; pasting" elementary paths; here is how ConnectionStudio extracts these from the data. From an XML or JSON document, each path starting from the document root, and ending in an internal node, text node, or extracted entity (child of a text node) is proposed to the user. From CSV data, we propose paths of the form row, row.att#val, row.att#val.extract:τ where row is the label of each node created out of a CSV row (tuple), att is an attribute name, and extract:τ denotes an extraction edge for some entity type τ (such as person, location, email etc., recall Section 2). From RDF, for each property p encountered in an s, p, o triple, we propose simply p as an elementary path, with two variables for the subject and object of the triple; similarly, for each s, rdf:type, c triple, we propose rdf:type c as an elementary path with one variable for the subject.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Correcting and improving the graph through a table view</head><p>The paradigm of path querying also gives us two ways to improve and correct the graph (requirement (δ)).</p><p>Editing value and entity labels As stated above, an elementary path ending in #val returns the set of values encountered in the data in certain positions, while a path ending in #val.extract:τ , for some entity type τ , shows entities extracted by ConnectionLens from the data, using trained language models <ref type="bibr" target="#b2">[3]</ref>. When visualising the result of such a query, users can edit entity or values shown in the query result, and propagate their modifications to the underlying database, thus updating the graph. ConnectionLens implements a set of similarity functions and (very conservatively) unifies entities whose labels are very similar, e.g., "L'Oréal" and "L'OREAL", once they are both recognized as organizations by the entity extractor. The ability to edit the data, offered by ConnectionStudio enables users to further normalize (uniformize) the label of value nodes, and/or of extracted entity nodes. This corresponds to a carefully restricted case of database update through views <ref type="bibr" target="#b0">[1]</ref>. As well known, such updates cannot always be propagated correctly to the underlying database. In ConnectionStudio, we allow updates only on values or entities at the destination end of a path. It is easy to see that such updates can always be propagated to the graph persistently stored in the underlying database.</p><p>For instance, in Figure <ref type="figure" target="#fig_5">4a</ref>, while inspecting the results of a query, when users find multiple versions of the same organization "Alstom", such as "Alsthom", "Als thom" or "Alstom grid", they can correct each of them by hand, then propagate the changes to the underlying database.</p><p>Specifying extraction policies Inspecting results of entity-returning path queries may help users learn what entities are (not) in specific places in the data. Thus, a user noticing the extracted names "Bertrand Martin" and "Julie Dupont" under declaration.general.declarer.name#val.extract:p may conclude that every declaration.general.declarer.name#val contains people, and formulate an extraction policy of the form path τ , specifying that all values found under path are to be interpreted as entities of the given entity type τ . This helps circumvent extractor misses, e.g., for a less usual name such as "Xin Jong" which does not fit the extractor's trained model. Users can also specify that extraction should not be performed on values on some path(s), path NoExtract , if they are not inter-  ested in the entities that may be found there. Extraction policies, both negative and positive, speed up the graph construction, by avoiding the (costly) entity extraction effort during graph loading.</p><p>Extraction policies were first mentioned in <ref type="bibr" target="#b2">[3]</ref>. However, only now, via Con-nectionStudio's path query features, our tool helps non-expert users formulate them. For instance, in Figure <ref type="figure" target="#fig_5">4b</ref>, the user specified that: declarers' names should always be recognized as person entities, and that no extraction should be applied on the values found on the path origine#val. Users can decide this after seeing that all these values are equal (probably a code introduced by anonymization), thus there is no point in searching for entities in them.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Perspectives and conclusion</head><p>Data lakes such as <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b9">10]</ref> and ConnectionLens <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b2">3]</ref> aim to help users explore many heterogeneous data sources. ConnectionLens adopts a graph paradigm for integrating the sources, and extracts entities leading to inter-dataset connection opportunities. In this work, we describe novel data exploration and discovery paradigms we implemented in ConnectionStudio, following requirements expressed by journalists; they allow users to discover the graph, simplify querying for connections across sources, and as-you-go cleaning of the graph. We believe these features are useful additions to next-generation heterogeneous data lakes. Going forward, we plan to conduct an elaborate user-study in order to understand better how ConnectionStudio helps novice users explore graphs and also inculcate the feedback to further improve upon the features provided by Con-nectionStudio.</p><p>grants. We also thank Camille Pettineo who contributed to this paper as a data journalist.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Sample data graph built from HATVP declarations and CAC40 companies.</figDesc><graphic coords="4,134.77,115.84,345.82,118.86" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>(a) Count of entities and tag cloud (b) Frequent entities</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Statistics for the sample dataset.</figDesc><graphic coords="6,221.22,306.89,172.91,133.49" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. The data view for HATVP declarations and CAC40 companies samples.</figDesc><graphic coords="7,152.06,384.09,311.24,175.26" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>(a) Updating values to clean the data. (b) Specify extraction policies before loading data.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Correcting and improving the graph.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>-</head><label></label><figDesc>Select declarations.declaration.general.mandat.label#val as the second elementary path; -Edit (shorten) it into declaration.general.mandat.label#val, going from the variable decl to the variable position. Reusing decl is intuitive since in both paths, this variable denotes the graph nodes labeled declaration. -Similarly, edit other elementary paths to obtain declaration.general.dateDe-butMandat#val.extract:d going from decl to startDate, etc.</figDesc><table /></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><p>Acknowledgments. This work is partially funded by <rs type="grantNumber">DIM RFSI PHD 2020-01</rs>, <rs type="projectName">AI Chair SourcesSay</rs> (<rs type="grantNumber">ANR-20-CHIA-0015-01</rs>) and <rs type="projectName">CQFD</rs> (<rs type="grantNumber">ANR-18-CE23-0003</rs>)</p></div>
			</div>
			<listOrg type="funding">
				<org type="funded-project" xml:id="_5NHHPgM">
					<idno type="grant-number">DIM RFSI PHD 2020-01</idno>
					<orgName type="project" subtype="full">AI Chair SourcesSay</orgName>
				</org>
				<org type="funded-project" xml:id="_MPxTJ3a">
					<idno type="grant-number">ANR-20-CHIA-0015-01</idno>
					<orgName type="project" subtype="full">CQFD</orgName>
				</org>
				<org type="funding" xml:id="_cbV8paq">
					<idno type="grant-number">ANR-18-CE23-0003</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><surname>Abiteboul</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Hull</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Vianu</surname></persName>
		</author>
		<title level="m">Foundations of databases</title>
		<imprint>
			<publisher>Addison-Wesley</publisher>
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Empowering investigative journalism with graph-based heterogeneous data management</title>
		<author>
			<persName><forename type="first">A</forename><surname>Anadiotis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Balalau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Bouganim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE DEBull</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Graph integration of structured, semistructured and unstructured data for data journalism</title>
		<author>
			<persName><forename type="first">A</forename><surname>Anadiotis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Balalau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Conceicao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Inf. Systems</title>
		<imprint>
			<biblScope unit="volume">104</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Integrating Connection Search in Graph Queries</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Anadiotis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Manolescu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mohanty</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICDE</title>
		<imprint>
			<date type="published" when="2023-04">Apr 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Exploring heterogeneous data graphs through their entity paths</title>
		<author>
			<persName><forename type="first">N</forename><surname>Barret</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gauquier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Law</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Manolescu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ADBIS</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Semantics-aware dataset discovery from data lakes with contextualized column-based representation learning</title>
		<author>
			<persName><forename type="first">G</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Miller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PVLDB</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">7</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Leveraging the data lake: Current state and challenges</title>
		<author>
			<persName><forename type="first">C</forename><surname>Giebler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Gröger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Hoos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Schwarz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Mitschang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Big Data Analytics and Knowledge Discovery (DaWaK)</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Modeling data lakes with data vault: Practical experiences, assessment, and lessons learned</title>
		<author>
			<persName><forename type="first">C</forename><surname>Giebler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Gröger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Hoos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Schwarz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Mitschang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">ER. Lecture Notes in Computer Science</title>
		<imprint>
			<biblScope unit="volume">11788</biblScope>
			<date type="published" when="2019">2019</date>
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Constance: An intelligent data lake system</title>
		<author>
			<persName><forename type="first">R</forename><surname>Hai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Geisler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Quix</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016">2016</date>
			<publisher>SIGMOD</publisher>
			<pubPlace>New York, NY, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Data lakes: A survey of functions and systems</title>
		<author>
			<persName><forename type="first">R</forename><surname>Hai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Koutras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Quix</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Jarke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Knowledge and Data Engineering</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">BtrBlocks: Efficient columnar compression for data lakes</title>
		<author>
			<persName><forename type="first">M</forename><surname>Kuschewski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Sauerwein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Alhomssi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Leis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. ACM Manag. Data</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Data lake management: challenges and opportunities</title>
		<author>
			<persName><forename type="first">F</forename><surname>Nargesian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">Q</forename><surname>Pu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">C</forename><surname>Arocena</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the VLDB Endowment</title>
		<meeting>the VLDB Endowment</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
