<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">The Effects of VR in Training Simulators: Exploring Perception and Knowledge Gain</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Aline</forename><surname>Menin</surname></persName>
							<email>aline.menin@inria.fr</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Univ. CÃ´te d&apos;Azur</orgName>
								<orgName type="institution" key="instit2">CNRS</orgName>
								<orgName type="institution" key="instit3">Inria</orgName>
								<address>
									<settlement>Sophia Antipolis</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Rafael</forename><surname>Torchelsen</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">CDTec</orgName>
								<orgName type="institution">Federal University of Pelotas</orgName>
								<address>
									<settlement>Pelotas</settlement>
									<country key="BR">Brazil</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Luciana</forename><surname>Nedel</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Institute of Informatics</orgName>
								<orgName type="institution">Federal University of Rio Grande do Sul</orgName>
								<address>
									<settlement>Porto Alegre</settlement>
									<country key="BR">Brazil</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<address>
									<postCode>2013</postCode>
									<settlement>Blacksburg</settlement>
									<region>VA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">The Effects of VR in Training Simulators: Exploring Perception and Knowledge Gain</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">4120F28F4C471131B951EED3B92DABE9</idno>
					<idno type="DOI">10.1109/TVCG.2015.2391853.</idno>
					<note type="submission">Received October 12, 2021</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-04-12T14:44+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Virtual Reality</term>
					<term>Immersion</term>
					<term>Training Simulators</term>
					<term>User Perception</term>
					<term>Knowledge Gain</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Although immersive virtual environments have been used for years for training and learning purposes (e.g., flight and surgery simulators), the effects of using VR devices on simulation sessions are yet to be understood. In this work, we explore the effects of different VR devices on virtual environments developed for training, focusing on perception and knowledge gain aspects. We performed two user studies to investigate the influence of these devices on users' workload, motion sickness, and performance in the domain of work safety training. The first experiment includes 61 participants and seeks to understand whether and how VR displays providing different fields of view affects the users' ability to search for risks in an office-like virtual environment (i.e. focus on user perception). Subsequently, we conducted a second experiment involving 46 subjects, where we assess whether and how interaction techniques providing different degreesof-freedom influence users' ability to learn procedural tasks (i.e. focus on knowledge gain). From our results, we learned that users' knowledge on the simulation's topic (i.e. work safety) and gaming experience play an important role in VR simulations, and that cybersickness symptoms such as disorientation are likely caused by unawareness of one's surroundings instead of VR content.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction 1</head><p>The low-cost and danger-free aspects of virtual reality (VR) 2 technology enable the design of immersive simulations with 3 game aspects (i.e. gameplay, challenge, interaction, and objec- simulator to train firefighter's skills using a Cave Automatic the cognitive system. These findings were later contradicted by <ref type="bibr">Bowman et al. [11]</ref>, who showed that a higher level of visual fidelity provides better performance in procedure memorization tasks. They also showed that high display fidelity improves spatial knowledge and allows users to use spatial strategies on procedure memorization, leading to better target detection. More recently, Kwon <ref type="bibr">[12]</ref> showed that high fidelity VR setups help users to recognize a virtual experience as the actual experience, while improving their ability to analyze, evaluate, and create questions based on the subject learned during the simulation.</p><p>Ragan et al. <ref type="bibr">[13]</ref> showed that the use of auxiliary spatial information affects mental strategies and improves user performance in terms of cognitive processing and learning-based activities. Moreover, stereoscopic vision has been shown to improve memory recall when objects are consistent with the environmental context <ref type="bibr">[14]</ref>. In another study, Roman et al. <ref type="bibr">[15]</ref> showed that a three-monitor CAVE is more engaging with a 3D first-person shooter game than a single monitor.</p><p>Napieralski et al. <ref type="bibr">[16]</ref> showed that users can locate themselves easier inside a VR environment when the realism of graphics is higher. Furthermore, Ragan et al. <ref type="bibr">[17]</ref> showed that high visual realism improves strategy transfer, but worsen user performance in scanning tasks probably due to the extra information that exists on VR environments simulating real-world scenarios (e.g., trees, people, buildings), which can distract the user from their main task. They also demonstrated that training with higher FOVs lead to better object detection in a serious game using scanning tasks to train military personnel. Although, they did not find any correlation between the user performance on the VR environment and the real-world, their findings suggest that a higher FOV do not improve the real-world task performance more than training with a lower FOV. <ref type="bibr" target="#b1">[18]</ref> also showed that using wide FOV and high resolution provides a less cluttered and more comprehensible VE. McMahan et al. <ref type="bibr">[10]</ref> showed that high display and interaction fidelity affect strategy and user performance in a first-person shooter game in a way that, with high interaction fidelity users took less damage and were less accurate then with low interaction fidelity. The authors showed that users' familiarity with the technology improves user performance, which could explain the high accuracy when interacting with conventional mouse and keyboard devices. In terms of user experience (UX), the authors observed that high display/interaction fidelity increases the users' sense of presence, engagement and the simulator's assessed usability. Krokos et al. <ref type="bibr" target="#b2">[19]</ref> showed that using virtual memory palaces (i.e. placing pieces of information within palace and medieval town environments, and associating them to salient features of the environment) as a spatial mnemonic to support information recall are more effective when delivered via HMDs than desktop displays. Nabioyuni and Bowman <ref type="bibr" target="#b3">[20]</ref> investigated the effects of hyper-natural transfer and biomechanical techniques for navigating inside a VR environment. Their findings suggest that well-designed hyper-natural navigation techniques can be understood and adapted by users, resulting in more speed performance. However, these techniques may still be more difficult to control than real walking when performing complicated, more precise movements. Further, hyper-natural biomechanical techniques do not improve locomotion performance in VR, but instead reduce accuracy and users' comfort <ref type="bibr" target="#b3">[20]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Bowman and McMahan</head><p>Kakoschke et al. <ref type="bibr" target="#b4">[21]</ref> investigated the effects of Approach-Avoidance Training (AAT) delivered via three interfaces (computer, smartphone, and VR) on user experience (flow, immersion, engagement) and performance (accuracy, approach bias).</p><p>Their results showed that VR was a more effective way to deliver the training by providing higher engagement, flow, and immersion than the AAT delivered via a computer or smartphone application, while reducing errors.</p><p>Albus et al. <ref type="bibr" target="#b5">[22]</ref> used signals in the form of textual annotations to support learning in VR simulations. They also investigated its effects on different learning outcomes and cognitive load. Results showed that annotations in VR can help users to process and recall the information, but have no effects in terms of reducing distractions. Gupta et al. <ref type="bibr" target="#b6">[23]</ref> used a VR simulator for condylar plating surgery to show that VR based environments can serve both as skills training and learning tools.</p><p>Di Mascio et al. <ref type="bibr" target="#b7">[24]</ref> evaluated the acceptability, usability, and engagement of two HMDs (i.e. Oculus Rift and Hololens) as tools to provide VR and AR-based treatment for people with Autism Spectrum Disorder (ASD). For both devices, results suggest that initial training is necessary, as well as long-term usage to provide users with freedom to virtually and physically move around the environment. The study showed yet that familiarity with objects in an IVE's (Immersive Virtual Environments) had a higher impact on emotional participation than photo-realism.</p><p>Hasanzadeh et al. <ref type="bibr" target="#b8">[25]</ref> investigated the feasibility and usefulness of providing passive haptics in a mixed-reality (MR) environment to capture the risk-taking behavior of workers. Results showed that MR helps to raise users' sense of presence and to capture their realistic response to safety features for both research and training purposes. Additionally, the study showed that extroverts workers could place themselves more readily within this mental representation and experience higher levels of involvement, higher degrees of presence, and stronger sense of being there.</p><p>Recently, due to the constraints imposed by the COVID-19 pandemics, the use of VR for training and learning has receiving more attention and the influence of aspects such as users' visual attention and behavior are being explored. Simeone et al. <ref type="bibr" target="#b9">[26]</ref> found that the presence of a virtual instructor increases the engagement and accelerate the progress of the user during a learning experience. Bozkir et al. <ref type="bibr" target="#b10">[27]</ref> focused in three different objects-of-interest for measuring attention: peer-learners, instructor, and lecture material. More specifically, they varied sitting positions of students, visualization styles of virtual avatars (realistic or cartoon-like), and hand-raising percentages of peer-learners. Results showed that such manipulations play an important role in students' attention.</p><p>These user studies illustrate the interest and benefits of using VR technologies to provide the user with high fidelity setups to support training procedures through low-cost and danger-free alternatives. A high fidelity VR setup would be built with technologies that provide the closest experience as one would have in the real-world, which means peripheral vision and natural in-58 teraction techniques, such as through mid-air gestures and real 59 walking. Nonetheless, we could see that, depending on the tar-60 get tasks, low interaction fidelity provides better user perfor-61 mance than high fidelity due to the users' familiarity with de-62 vices such as game controllers and mouse devices. The study 63 reported by <ref type="bibr">McMahan et al. [10]</ref> is the closest to the one we 64 present in this paper in terms of comparing different combina-65 tions of low and high interaction/display fidelity devices, which 66 considers for instance the joint use of CAVEs and mouse de-67 vices or display-walls and pointing devices. However, the dis-68 parity in terms of fidelity between one display and interaction 69 devices are quite large.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>70</head><p>In this paper, we extend the understanding of the effects of 71 low/intermediate/high fidelity in user perception and knowl-72 edge retention. We considered different VR devices, interaction 73 and navigation techniques on the outcomes of training simula-74 tions. Few previous studies have considered the effects of mo-75 tion sickness, even though it is known to be a side-effect of 76 VR, or the quantity of work necessary to achieve the task using 77 high fidelity interaction tools, which are quite new to the users. 78 Therefore, we measure motion sickness and workload and eval-79 uate their impact on user engagement, sense of presence and 80 immersion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>81</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Design Rationale</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>82</head><p>Perception and learning are intrinsically connected: in train-83 ing tasks, one cannot learn a new procedure without the ability 84 of perceiving one's surroundings. Thus, this study focuses on 85 investigating the effects of different VR technologies on percep-86 tion and learning aspects of VR simulations. To reduce cogni-87 tive load possibly engendered by the combination of all these 88 technologies, we separated the study in two user experiments: 89 (i) user perception (Section 5) comparing three display devices, 90 and (ii) knowledge gain (Section 6) comparing four combina-91 tions of semi-and non-natural interaction and locomotion tech-92 niques.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>93</head><p>First and foremost, the purpose of a training simulation is to 94 prepare the user for the real-world situation, which has naturally 95 high visual complexity. Thus, the simulators where build on the 96 basis of realistic scenarios, supporting the transfer of what has 97 been learned during the simulation to the real-world situation. 98 We used a simulator for risk perception assessment (Fig. <ref type="figure" target="#fig_1">1a</ref>), 99 which purpose is to train workers on detecting potential risk 100 elements in a normal workplace environment <ref type="bibr" target="#b11">[28]</ref>, and a sim-101 ulator for lightning rod replacement (Fig. <ref type="figure" target="#fig_1">1b</ref>), which intend 102 to train apprentices on basic safety procedures for electrical in-103 stallations on public utility poles.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>104</head><p>The risk perception assessment simulator reinforces users' 105 perception through their ability to see, hear, or become aware 106 of something through the senses to apprehend their surround-107 ings, detecting and avoiding risk hazards. Thus, the simulator 108 train users through perceptual learning, which comprises the 109 ability to detect pieces of information (i.e. events, distinctive 110 features, and affordances) offered by the environment <ref type="bibr" target="#b12">[29]</ref>. <ref type="bibr">Ra</ref>  Further to acquire information, the user should be able to retain the information obtained through training simulations in order to transfer it into the real-world situation. Recalling information is also known as knowledge and can be classified into different categories such as factual, conceptual, procedural and meta-cognitive <ref type="bibr" target="#b13">[30]</ref>. Both simulators require the user to recognize specific details or elements (i.e. factual knowledge). In this paper, we explore knowledge retention through the lighting rod replacement simulator, where we investigate the effects of different navigation and interaction techniques for grabbing and manipulation, which are fundamental in numerous training simulators (e.g., firefighting, military training, etc). In terms of interaction, we use motion tracking to map knowledge retention to the real-world by providing high fidelity experiences to the user.</p><p>In terms of navigation, we considered the use of motion tracking, but the solutions found to track the large physical spaces required for both simulations (Fig. <ref type="figure" target="#fig_1">1</ref>) were too expensive <ref type="bibr" target="#b14">[31]</ref>. Hyper-natural navigation techniques such as Seven</p><p>League Boots <ref type="bibr" target="#b15">[32]</ref> could improve speed performance, but they might be difficult to control when precision is needed <ref type="bibr" target="#b3">[20]</ref>.</p><p>Thus, we focus in less natural navigation techniques such as walking-in-place (WIP) and joystick navigation. Particularly, the Wii balance board has been largely used by researchers to provide low-cost WIP techniques, showing positive effects on user performance in human-scale spaces and spatial orientation, while providing high sense of presence <ref type="bibr" target="#b16">[33]</ref>.</p><p>In terms of grabbing and manipulating objects, motion tracking can also enable natural interaction through mid-air gestures <ref type="bibr" target="#b17">[34]</ref>, which has shown to offer less precise control and require more physical work on the part of the user <ref type="bibr" target="#b18">[35]</ref>. Furthermore, Mine et al. <ref type="bibr" target="#b19">[36]</ref> showed that having a physical reference helps the user to be more precise on memory recall. Thus, we combine physical objects and body movement by using the 41 Razer Hydra controllers, and compare it to conventional game 42 controllers, since users are familiar with these devices.</p><p>43</p><p>The first experiment focuses on perception, using a VE that 44 requires walking around while observing and perceiving haz-45 ardous features in different rooms. In this task, the display de-46 vice impacts the performance more than the interaction tech-47 nique, so we compared three different display devices. The sec-48 ond experiment focused on investigating the effects of interac-49 tion and locomotion techniques on learning. Although it uses a 50 different simulator, the perception skills are as important, since 51 the user should be aware of their surroundings to judge the best 52 way of securing the workplace. Therefore, we chose the display 53 device that has shown the best effects on the first trial, ensuring 54 that the display was not a bias, while showing positive effects 55 in terms of perception.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>56</head><p>Particularly, as shown by previous works (see Section 2), VR 57 devices providing highly immersive and natural experiences 58 can improve user performance. Therefore, we selected a set of 59 VR devices that provide proper levels of immersion (i.e. HMD 60 and display-wall) and naturalness (i.e. Razer Hydra and Wii 61 Balance Boards) while comparing them with traditional and 62 familiar devices (i.e. PC monitor and game controllers), en-63 abling us to investigate their effects the outcomes of the train-64 ing simulations. Furthermore, the selected devices are cheap 65 and therefore accessible to the companies interested on using 66 these types of simulators, thus easing their dissemination since 67 these are intended for use in large-scale training sessions within 68 companies <ref type="bibr" target="#b11">[28]</ref>. Hereafter, we first describe the shared exper-69 iment protocol, measures, and statistical analysis process, then 70 we present both user experiments and their results. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Shared Protocol Between Experiments and Measures</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>72</head><p>Since we focus on learning, we assumed that using a within-73 subjects design could influence the results by allowing users 74 to recycle the information they learned while using a partic-75 ular display/interaction technique. Thus, we used a between-76 subjects design in both experiments, where participants were 77 randomly assigned to each experimental condition.</p><p>In both experiments, the experimental sessions were individ-   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Experiment I: User Perception</head><p>This experiment aims to understand whether different VR display devices influence the user perception in a simulation designed to train workers of an electricity distribution company on detecting risks elements in their work environment. This experiment requires users to leverage their perception skills to detect potential hazards in the virtual environment. Based on previous studies' findings (see Section 2), we believe that the higher the feeling of being "there" in the VE, the better the user can perform the tasks and recall the information acquired during the simulation. Particularly, a high immersive setup would enable them to completely focus on the elements of the virtual world without being distracted by the real-world objects surrounding them. Thus, we hypothesized that (H1) display devices producing higher self-reported sense of presence improve the user performance. Moreover, the existing immersive training simulators have shown overall positive outcomes <ref type="bibr">[7]</ref>, which lead us to hypothesize that (H2) simulator sickness will not worsen the user performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Virtual Environment</head><p>This simulation was designed for assessing the ability of workers to detect potential risk elements in a normal workplace environment. The VE contains a building with a reception room, a parking lot, an office, and a kitchen. Further to the normal objects of an office environment, the scenario has 53 objects defined as potential hazards which can be simple or composite. The former refers to imminent risk items (e.g., wet floor, blocked fire extinguisher), while the latter refers to objects which hazard is triggered by an external situation (e.g., flashing lamp, alarm off). These require higher cognitive effort from the user to be detected.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Experimental Conditions</head><p>We compared three VR display devices: (A) a 23-inch LCD screen with a 120Hz refresh rate and 1920 Ã 1080 pixels resolution desktop display, which we used as our baseline condition, since games and current non-immersive simulations are usually ran on PC desktops; (B) a 3200 Ã 1800 pixels resolution display wall built up from a set of twelve 22-inch LCD screens, with a total dimension of 244 Ã 108 centimeters (Fig. <ref type="figure" target="#fig_6">2b</ref>). This display intends to immerse the user on the simulation while allowing them to be aware of their surroundings; and (C) an HMD device, since it is widely used in VR and provides high self-reported sense of presence, allowing the user to focus on the simulation while avoiding distractions issued from their surroundings. We used the Oculus Rift DK2 device, which has a 960 Ã 1080 pixels resolution per eye and a refresh rate of 75Hz.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.">Participants</head><p>Sixty-one volunteers (15 female) took part in this experiment. They were students, mostly from Computer Science, and University personnel, aged between 19 and 63 years old (M=28.67, SD=10.12). They were all beginners in terms of work safety and VR, and 42% reported to be experienced on 3D video games. All the participants reported normal or correctedto-normal vision. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4.">Task</head><p>The users were assigned with two tasks: (1) to follow the instructions (e.g. "Inside of this building has a kitchen. Go there and get a coffee.") given by a storyteller, while (2) scanning the environment for potential risks objects. The guidance enabled users to go through every room in the building. In each room, they were instructed to reach a target object (flashing in red) by moving back and forward using the game controller's joystick. Users would turn their heads to set the movement direction when using the HMD and the display wall, and use the joystick when using the desktop display. After reaching the target, the system triggers the next instruction, except in the case of two special instructions, when the user should stand in a location and scan the room for potential risks for as long as they would like. These tasks were included as a strategy to reduce the difference among the experimental conditions, demanding users to perform the same movements by either turning their heads with the HMD or using the game controller. Further, it serves also to verify whether users would simply follow what the narrator was telling them to do or they were also attentive to the scanning task. Such as in the real world, the detection of risky situations should be a background task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5.">Measures</head><p>We measured the users' subjective sense of presence using the SUS (Slater-Usoh-Steed) presence questionnaire <ref type="bibr" target="#b24">[41]</ref>, which consists of six statements rated in a 7-point Likert scale used to assess the sense of presence in each room of the VE.</p><p>Further, we asked users to respond the question "how much immersed did you feel?" in a 10-point scale, in order to assess their sense of immersion. Regarding user experience, we asked users to rate in a 5-point Likert scale the following statements: "I believe the simulation achieve the purpose of assessing the user's aptitude on detecting risk hazards in the work environment", "I could perform the simulation easily"; "I enjoyed using the simulator". Finally, we measured user performance by combining three factors: task completion time (the lower the better), traveled distance in the VE (the less the better), and the number of detected risks (the more the better).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.6.">Results</head><p>The virtual path which users were supposed to follow was determined by the audio instructions, which send them to the car at the parking lot, the coffee maker at the kitchen, the desk 42 at the office, and, finally, to meet their co-workers outside the 43 office. Although, we did not observe major differences among 44 the experimental conditions, users wearing the HMD followed 45 a path slightly more straight than the ones in Display-Wall and 46 Desktop conditions.  Overall, users took between 5 and 15 minutes to complete 48 the simulation regardless the display device. We observed sig-49 nificant difference in the mean completion times for the dis-50 play wall and the remaining devices, suggesting that partici-51 pants using the display wall took longer to finish the simu-52 lation (M=12.4, p&lt;0.001). In terms of risk selection, users 53 were able to identify about 21% of potential risk objects in 54 the VE (Fig. <ref type="figure" target="#fig_8">3</ref>). The mean scores show that users found 55 more risk objects using the desktop display than with the re-56 maining, but no statistical difference was observed. Nonethe-57 less, when analyzing the type of risk objects users found, 58 we observed that they detected more simple than composite 59 risks using the display wall (p&lt;0.001) and the desktop display 60 (p&lt;0.05), while there was no significant difference under the 61 HMD condition. We observed that completion time and risk se-62 lection is positively correlated when using the desktop (p&lt;0.02, 63 R=0.5) and HMD (p&lt;0.03, R=0.48) display devices.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>64</head><p>In order to determine whether the devices inflicted cyber-65 sickness on users, we compared the SSQ scores measured be-66 fore and after the trial. We observed statistical difference be-67 tween mean scores for symptoms of nausea (p&lt;0.01), disorien- We did not observe statistical differences in the mean SSQ 7 scores for users using the desktop display and the display wall. 8 However, the users of the HMD appear to perceive the sever-9 ity of symptoms of nausea, disorientation, and the total sever-10 ity significantly higher than the users of other devices (p&lt;0.01) 11 (Fig. <ref type="figure">4</ref>). We have also observed statistical differences in the 12 mean scores of the oculomotor scale between the HMD and 13 the desktop display devices (p&lt;0.05), while no statistical differ-14 ences were observed in regard to the display wall. The highest compared to the maximum score of 97.4 points.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>18</head><p>In terms of immersion, mean scores suggest that participants  Although the assessed sense of presence of users using the HMD was higher than the other devices, the participants' risk selection rate and completion time were similar among devices, which means that we cannot accept H1. Nonetheless, we observed that the mean number of risk selection was quite low, which is most likely a consequence of the users' overall lack of expertise on work safety. The users with the HMD device reported more severe sickness symptoms than the users of display wall and desktop display devices, which latter appear to have reduced the severity of symptoms. Nonetheless, completion time and risk selection rate did not present any difference among users of different display devices. Moreover, we did not observe correlation between SSQ scores and completion time or risk selection rate, which allows us to accept H2. Although the participants did not present high performance, their varied perception of sickness symptoms severity did not impacted the user performance among the different display devices.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Experiment II: Knowledge Gain</head><p>This experiment intends to explore the effects of two different interaction and two locomotion techniques on user experience and knowledge gain in a simulator designed for teaching apprentices the work safety procedures of a lightning rod replacement task. Overall, we believe the devices enabling movements closer to natural ones would improve user experience and, consequently, increase the knowledge gain from the simulation. Therefore, we hypothesized that (H1) the closest the movement is to the natural one, the better will be the user performance; (H2) the devices enabling arms and legs movements will not inflict severe motion sickness; and (H3) high workload inducing techniques will worsen user performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.">Virtual Environment</head><p>This simulation was designed for training apprentices on basic safety procedures for electrical installations on public utility poles. The VE consists of a town street where a lightning rod is being replaced (Fig. <ref type="figure" target="#fig_1">1b</ref>). A storyteller guides the user through audio instructions (e.g. "The workers need to be equipped with scrap gloves, safety belt, and helmet, while carrying the service order. Please, select the objects representing this equipment. They are flashing in red. When you have finished, activate the next instruction."), while teaching them the steps needed to secure the job site for workers and pedestrians. The simulation has three phases: a learning phase, where the user learn the proper placement of safety items, which is indicated via glowing objects and arrows; and two application phases, where the user is asked to perform the safety task using the information they just learned. In the learning phase, users can only grab objects that have been mentioned by the storyteller, which should reinforce their focus on the task. In the application phases, users can grab whichever items they like and follow their own strategy to place them in the scene. We change the initial placement of objects between one phase and another to reduce the bias of already knowing where to start.</p><p>The users were asked to perform a set of five tasks: (1) to ensure that the truck is parked correctly and stuck with shims at the wheels; (2) to equip workers with scrap gloves, safety belt, helmet, and the service order; (3) to place the materials on the protection canvas; (4) to signal the workplace using signposts; and (5) to isolate the workplace, including the vehicle, using cones and ropes. The tasks should be performed according to the users' interpretation. In the assignment to arrange the cones around the workplace, the users had eight available cones to be arranged along a square illustrated by four arrows, so they could either place one cone by each arrow or distribute a number of cones they found necessary in the provided space. Later, they were requested to tie the ropes between the cones previously placed. In this case, there were seven ropes available and they could choose a number of ropes they found necessary to isolate the place. A barrier prevented users from crossing through the rope after it has been tied between two cones, which served to remind them of leaving an opening in the isolated area to allow workers to transit.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.">Experimental Conditions and Apparatus</head><p>In this experiment we compared two interaction and two locomotion techniques. For grabbing and manipulating objects, The equipment worn by the participants consisted of an Oculus Rift DK2 device, a headphone, and a Sixense Razer Hydra.</p><p>To ensure a certain homogeneity among the conditions, users went through the simulation on top of the Wii Balance Boards platform and used the Razer Hydra controllers, regardless of the enabled interaction/locomotion techniques (Fig. <ref type="figure" target="#fig_13">5</ref>). The Razer Hydra device contains a base station with a low-power magnetic field that gets the controller's position and orientation. Although it does not require a line of sight to the controllers, the range area is quite small, introducing noise to the tracking when the user turns its back to the base station. Therefore, we used a band to hold the base station on the user's body (Fig. <ref type="figure" target="#fig_13">5b</ref>). In between, we placed a smartphone to capture the orientation of the user's torso, allowing this way to properly place the virtual hands according to the user's rotational movements. Finally, to provide users with confidence and control when using the WIP technique, we added an EVA mat over the platform with EVA borders around 7.5 centimeters high so the user could sense it, being aware of the platform limits.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4.">Measures</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>68</head><p>Prior to the trial, we established the baseline for cybersick-69 ness and users' knowledge regarding safety procedures. We 70 also assessed users' subjective memory complaints through a 71 10-item memory questionnaire <ref type="bibr" target="#b25">[42]</ref>, which information could 72 support knowledge outcomes. To assess knowledge (before and 73 after the trial), we prepared a 7-question test on the safety pro-74 cedures addressed in the simulation. These were essay ques-75 tions, presented one by one to the user and defined as follows: 76 What do you do to secure a job site for workers and pedestri-77 ans?; What do you do after arriving at the site and parking the 78 vehicle?; What safety equipment do you wear to perform the 79 task?; What extra item(s) do you need?; Where and how do you 80 place the working tools?; What do you do first to secure the site 81 for pedestrians?; How do you isolate the job site?.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>82</head><p>We applied the NASA Task Load Index (TLX) <ref type="bibr" target="#b26">[43]</ref> question-83 naire to assess workload for using the different navigation and 84 interaction techniques. The questionnaire provides an overall 85 workload score based on a weighted average of ratings on six 86 workload factors (scales): Mental Demand (MD), Physical De-87 mand (PD), Temporal Demand (TD), Own Performance (OP), 88 Effort (EF), and Frustration (FR). Additionally, we assess user 89 engagement's factors such as immersion, presence, flow, and 90    when the task required higher mental effort. For users in condition B, we found a -69% correlation between overall workload scores and knowledge gain (p=0.019), suggesting that when users needed higher loads of work their ability to retain knowledge is reduced.</p><p>Figure <ref type="figure" target="#fig_19">8</ref> shows the response accuracy for the knowledge test taken by users before, after, and three weeks after the trial. We observed a statistical difference in the mean accuracy scores for those three measurement times. We did not found statistical difference between scores of tests taken after the trial, which similarity between means suggest that users were capable of recalling the information learned during the simulation. The mean simulation times across conditions varied from 20 minutes in conditions A and B to 32.7 minutes in condition D, which difference of means showed statistical significance (p&lt;0.001). Overall, the completion time reduced between the simulation's phases, which was expected due to users familiarizing with the navigation/interaction techniques, the VE, and the tasks. Users took around 3.6 minutes less time to finish the first application phase than the learning, and the completion time of the second application phase was yet reduced in around 1.1 minutes (no statistical difference was observed among conditions).</p><p>Overall, users could complete the simulation's tasks with 95% of accuracy. Particularly, we noticed that 88% of users could correctly recall the instructions given in the learning phase regarding the objects' placement. In terms of isolating the job site, i.e. by forming a fence with cones and a rope around the area containing the canvas with the tools and the truck, while leaving an opening on it to allow workers to transit, we observed that the 78% of users placed the cones correctly, but only 36% of them left an opening in the fence. We observed statistical difference among conditions in users' accuracy to complete certain tasks. In terms of tools placement on the canvas, participants in condition B performed better than users in condition D (p&lt;0.038). Participants in condition C and D were more accurate in terms of arranging the signposts than users in condition A (p&lt;0.05) and B (p&lt;0.05), respectively. Users in condition C were also more accurate in terms of isolating the job site than participants in condition D (p&lt;0.05). The GEQ mean score was 2.8 across experimental condi-1 tions, which differences were not statistical significant. We 2 have found a 45% correlation between mental demand and en-3 gagement (p&lt;0.01), suggesting that navigation/interaction tech-4 niques demanding higher mental effort also tend to be more en-5 gaging. Overall, users reported to have enjoyed the experience 6 and found it easy to learn and apply the safety procedures. As in 7 the previous experiment, we allow users to walk towards their 8 looking direction to reduce the severity of sickness symptoms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>9</head><p>In this matter, two persons have said that they would like to 10 walk backwards. Selecting objects in the scene was reported 11 to be difficult by some users, particularly regarding the cones.</p><p>12 Participants suggested the addition of a checklist to allow the 13 user to check tasks as done as they progress in the simulation.  gain. In this condition, we also observed that users appear to 33 be more engaging when mental demand increase. Thus, we be-34 lieve that the freedom provided by more natural movements in  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Discussion</head><p>In this work, we performed two empirical studies to investigate the impacts of three different VR displays and four interaction techniques on several VR aspects, such as motion sickness, workload, engagement, sense of presence, user performance, and learning outcomes on training simulations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1.">Main Findings</head><p>Our results showed that participants could perform certain tasks with higher accuracy, such as isolating the job site using the conditions where navigation was supported via the WIP technique, and placing tools over a canvas in conditions where they would grab and manipulate objects using the ray-casting technique. The latter provided a physical reference through a Razer Hydra's controller, which higher accuracy on performing the task suggests that users could better recall the information given during the learning phase, in conformity with previous findings <ref type="bibr" target="#b19">[36]</ref>. Although we did not observe statistical difference in knowledge gain among experimental conditions and replication of these experiments may be necessary to evaluate our hypotheses, our results suggest that semi-natural navigation/interaction techniques could improve user performance.</p><p>Previous studies suggest that semi-natural interfaces, i.e. interfaces that use real walking and body interaction, could be inefficient since they require the user to operate it differently from what they are used to, which adds workload to the process <ref type="bibr" target="#b27">[44]</ref>. However, we observed that users reported higher frustration scores when using the head orientation technique and the joystick to navigate, while they were more engaged with the simulation when moving their arms and legs through the ray-casting and WIP techniques, which were considered high mentally demanding by users. Users also perceived a higher quality on their own performance when using the WIP technique compared to the joystick. Furthermore, we observed a positive correlation between mental demand and knowledge gain in the condition using WIP and ray-casting, which also had the lowest simulator sickness effects. Our results suggest that providing close to natural interaction interfaces can be enjoyable and aid users to transfer the potential mental burden generated from adapting their real-walking expertise to better performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2.">Lessons Learned</head><p>Disorientation is probably a consequence of the user unawareness of their surroundings. As we have hypothesized, techniques providing semi-natural interaction did not increase the severity of sickness symptoms, because users could "move" together with the VE. Nonetheless, we observed that disorientation would be a constant across the experimental conditions in experiment II, which coincides with the disorientation reported by users of the HMD in experiment I, suggesting that disorientation is only the fact that the user is not aware of their surroundings, which seems not to be affected by the different interaction/locomotion techniques. Thus, our findings suggest that better VEs would allow the user to be aware of their surroundings, such as through the use of physical interaction devices and more importantly through haptic interaction, allowing the user to physically feel what they're virtually experiencing. Such physical approaches have been previously explored to increase awareness in VEs and improve user experience (see <ref type="bibr" target="#b28">[45,</ref><ref type="bibr" target="#b29">46]</ref>).</p><p>The use of interaction techniques as natural as possible continue to be the best choice. Simulations designed for VR technology aim to provide a real-world-like experience, where high sense of presence, immersion and realism are essential ingredients. Thus, it is important to allow the use of our wellknown movements to navigate and interact with the VE. While much research is still needed to improve this technology, there are several studies [10, <ref type="bibr" target="#b3">20,</ref><ref type="bibr" target="#b15">32]</ref>, including this one, showing the advantages of natural or semi-natural interaction techniques on user performance and experience. Thus, users could leverage of training simulators employing well-drafted (semi-)natural interaction techniques, which provide the sense of naturally navigating and grabbing objects in the VE, while providing accuracy for effectively dealing with small objects or performing precise tasks, such as painting.</p><p>Perception is more likely to be affected by the user expertise on the simulator subject than by the technology employed. We have observed in experiment I (Section 5) that neither the VR display nor the sickness caused by it affected user perception. However, we noticed that users had a rather poor performance on what refers to the risk scanning task. Users were able to select 20% of risks elements (consistently throughout the devices), which is a low selection rate, likely explained by users' self-reported very low knowledge on work safety procedures. Previous works showed that the familiarity of users with the objects in the environment improves the user experience <ref type="bibr" target="#b7">[24,</ref><ref type="bibr">10]</ref>. Similarly, considering that our simulator have been developed to assess the ability of users to detect hazardous objects in the workplace, we suppose that the knowledge on the subject could have strongly impacted user performance, since one should know what is an hazardous element in the real workplace to be able to identify it in the simulation. Therefore, further studies using the "risk perception assessment" or similar simulations to investigate user perception should recruit target users of the simulation or to provide a training on work safety to the participants before undertaking the simulation.</p><p>Gaming experience plays an important role on VR simulation. We have found a positive correlation between disorientation and knowledge gain in condition A of experiment II (Section 6), which oddly suggests that users improved their scores despite the severity of disorientation's symptoms. However, we noticed that the users in this group reported to have high experience with 3D video games. Thus, we could suppose that users' familiarity with games and the constantly experienced mild cybersickness due 3D graphics allowed them to keep focused on the simulation despite the disorientation experienced in the VE. Further, while studying the impact of narrative in immersive VR games, Weech et al. <ref type="bibr" target="#b30">[47]</ref> also observed differences cybersickness symptoms reported by gamers and non-gamers. While non-gamers reported higher cybersickness when receiving minimal narrative, regular gamers would present similar levels of cybersickness regardless of the narrative context.</p><p>Although our case study focuses on work safety training, our results and lessons learned can assist the choice of VR devices to provide a comfortable and efficient virtual training environ-58 ment in other application domains and, particularly, for simula-59 tions requiring the users to leverage their perception skills. For 60 instance, our observations regarding the effects of users' profile 61 on perception and cybersickness could help designers to con-62 ceive suitable guidance for simulators based on users' profile 63 (e.g., whether they need more pre-training on the simulator's 64 subject or the usage of devices, etc). Likewise, the usage of 65 high fidelity devices to provide a real-world-like experience is 66 independent of the application domain and can be generalized 67 to any type of training simulator. Each user experiment tested multiple independent variables 70 by 107 volunteers in total. Nevertheless, we applied between-71 subjects designs in both experiments due to the learning nature 72 of our dependent variables, reducing the groups to 20 and 12 73 persons, respectively. Thus, these experiments should be repli-74 cated using larger groups, and preferably the simulator's target 75 users, to strengthen our findings. The lack of expertise on work 76 safety may have introduced bias to the results. As suggested by 77 Nazir et al. <ref type="bibr" target="#b31">[48]</ref>, immersive simulators are not effective per se 78 and need guidance of a professional in the field when the task 79 is unfamiliar. We have used VR technology that was available 80 to us at the time of this study. Hence, a new set of experi-81 ments should be performed using novel technology to under-82 stand whether these results are technology independent. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.">Conclusion 84</head><p>We conducted two empirical studies to investigate the effects 85 of VR interface on perceptual learning and knowledge reten-86 tion in simulations designed for worker safety training. We 87 measured simulator sickness, self-reported workload, engage-88 ment, presence and performance. Our objective was to better 89 understand the impacts of different display devices and interac-90 tion techniques on user performance and simulation outcomes. 91 Our results strongly suggest that a setup employing interaction 92 and navigation techniques closest to natural movements can im-93 prove user performance. In our experiments, we observed this 94 improvement through accurately placing objects in the VE, giv-95 ing users the feeling of performing better, and having low ef-96 fects on simulator sickness. However, users still had a phys-97 ical reference for moving the hands in the VE and select ob-98 jects, which is supported by previous studies as a mechanism to 99 improve memory recall. Different VR display devices did not 100 influence the user performance in our risk scanning task, but 101 rather their experience on work safety. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>4</head><label></label><figDesc>tive) for training people in diverse application domains. There 5 are numerous successful examples on the literature on how im-6 mersive VR can improve user performance and game effective-7 ness. Chitarro et al. [1] proposed an immersive simulator for 8 educating passengers on aviation safety through experiencing 9 a serious aircraft emergency situation using a Head-Mounted 10 Display (HMD). In fire service, Backlund et al. [2] present a 11</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 1 :</head><label>1</label><figDesc>Fig. 1: Virtual environments used in the Experiment I -risk perception assessment (a) and Experiment II -lighting rod replacement(b).</figDesc><graphic coords="4,308.10,74.72,249.86,138.64" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>71</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>1</head><label></label><figDesc>ual, accompanied by an experimenter who guided the partic-2 ipant through five steps of a standard protocol consisting of: 3 (1) a Term and Conditions Agreement, where the user is in-4 formed about the risks and benefits of participating in the ex-5 periment, and through which they consent their participation al-6 lowing us to anonymously use their data for research purposes;7(2) a socio-demographic questionnaire, where we gather stan-8 dard profiling information (e.g., age, sex, profession), data re-9 garding their experience with the technologies used (e.g., expe-10 rience with VR, 3D games) and the subject being addressed in 11 each simulation (e.g., work safety); (3) a learning phase, where 12 users were given time to get familiar with the VR setup; (4) 13 a trial phase, where the user carry out the required tasks; and 14 (5) a post-test phase, where we apply a questionnaire gathering 15 users' self-reported engagement, cybersickness, and workload, 16 as well as information specific to each experiment. 17 Particularly, to measure the impact of the VR devices on cy-18 bersickness (i.e. visually induced motion sickness) we admin-19 istered the Simulator Sickness Questionnaire (SSQ) [37]. The 20 questionnaire allows the user to assess the severity with which 21 they experienced sixteen sickness symptoms in a 4-point scale 22 (i.e. from low to high), which allows to determine the user's 23 level of sickness regarding four scales: nausea (N), oculomo-24 tor (O), disorientation (D), and total severity (TS). The highest 25 scores possible are 124 for nausea, 90.9 for oculomotor, 97.4 for 26 disorientation, and 108.6 for total severity. As common prac-27 tice [38], we administrated the SSQ before and after the trial in 28 both experiments to obtain baseline and completion measure-29 ments. This way, we can ensure that the results are not biased 30 by the condition of the participant before the trial, who could be stressed, anxious, or nauseous for unrelated reasons.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>32</head><label></label><figDesc>Regarding statistical analysis, we set the significance level 33 to p = 0.05 to analyze the empirical data. We submitted the 34 data to a mixed design, where the between-subjects variables 35 are the experimental conditions and the user profile, while the 36 within-subjects variables are the simulator sickness scores (ob-37 tained before and after the trial) and other measures specific 38 to each experiment, such as the sense of presence scores (ob-39 tained per room in the VE), and the self-reported workload 40 scores (obtained before and after the trial). We performed a 41 Shapiro-Wilk Normality test of the null hypothesis that the data 42 come from a normal distribution, and a Fligner-Killeen test of 43 the null hypothesis that the variances in each group are the 44 same. If the data passes both tests (p &lt;0.5) we performed a One-Way ANOVA test. Otherwise, the data was submit-46 ted to non-parametric tests, namely Friedman for paired and 47 Kruskal-Wallis for unpaired groups. In tests involving more 48 than two groups, with statistical significance, we ran post-hoc 49 tests: Tukey's range test [39] for One-Way ANOVA, and Ne-50 menyi test [40] for the remaining. We report statistical signifi-51 cance in the difference of means for two or more groups through 52 codes on the charts, if any, as follows: '***' 0.001, '**' 0.01, 53 '*' 0.05, and '.' 0.1.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>54</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 2 :</head><label>2</label><figDesc>Fig. 2: Experimental conditions for the first experiment (user perception).</figDesc><graphic coords="6,42.84,64.75,520.54,126.37" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>47</head><label>47</label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 3 :</head><label>3</label><figDesc>Fig. 3: Mean selection rates per type of risk in each experimental condition of experiment I.</figDesc><graphic coords="6,312.08,314.27,251.31,161.87" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>1</head><label></label><figDesc>Fig. 4: Mean scores per SSQ scale before and after the trial in each experimental condition of Experiment I. A, B and C are the experimental conditions, see section 5.2</figDesc><graphic coords="7,31.88,156.82,251.31,161.87" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>19 using</head><label>19</label><figDesc>the HMD device (M=7.96, SD=1.68) perceived them-20 selves more immersed in the simulation than the users of the 21 display wall (M=5.8, SD=2.63, p&lt;0.001) and the desktop dis-22 play (M=5.45, SD=1.77, p&lt;0.01). Regarding the users' sense 23 of presence, we observed statistical significance in the SUS 24 scores for the HMD and the desktop display (p&lt;0.05), indicat-25 ing that users could feel more present when using the HMD 26 device. No statistical difference was observed in the scores for 27 the display wall and the remaining devices.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>28</head><label></label><figDesc>Overall, users reported to be satisfied with the experience 29 and, particularly the users who experienced it through the HMD 30 and display wall, reported to have felt "really" there. A few 31 participants mentioned that having to only walk towards what 32 they are seeing did not felt natural. However, we believe that, 33 differently from the real world, looking towards one direction 34 and walking towards another can increase disorientation. Users 35 have also appreciated the short duration of the experiment and 36 agreed that the simulation meets its goals.37 5.6.1. Hypotheses Assessment.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head></head><label></label><figDesc>we use (1) a ray-casting technique based on the Razer Hydra controllers used as pointing devices controlled by the user arms' movements. When the object is within view, the user holds the controller's button to grab and drag it, and drop it by releasing the button; and (2) a head orientation technique, which uses the user's head orientation to point out to objects and one of the Hydra's controllers to manipulate them using a button. In terms of locomotion techniques, we use (1) the joystick of a Hydra's controller for moving forward, backward, left, and right in the environment; and (2) a WIP technique supported by a set of four Wii balance boards, which gives the user a 0.80 Ã 1.2 meters platform to "walk". The experimental conditions for this experiment are then resulting from the combination of these techniques: (A) ray-casting and WIP, (B) ray-casting and joystick, (C) head orientation and WIP, and (D) head orientation and joystick.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Fig. 5 :</head><label>5</label><figDesc>Fig. 5: Technical apparatus of experiment II: (a) WIP platform; (b) band to hold the Razer Hydra base station on the user's body; (c) a smartphone to get the user's orientation; (d) Oculus Rift device; (e) headphones.</figDesc><graphic coords="8,312.08,64.76,251.32,200.86" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head></head><label></label><figDesc>67</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head></head><label></label><figDesc>physiological absorption through the Game Engagement Ques-1 tionnaire (GEQ) [10]. The GEQ consists of 15 statements de-2 scribing different feelings, which the user must rate in a 5-point 3 Likert scale to indicate the intensity with which they experi-4 enced that feeling during the simulation. Finally, we measure 5 user performance by combining three information: task com-6 pletion time, accuracy of objects' placement according to the 7 instructions given in the learning phase, and knowledge gain.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_16"><head></head><label></label><figDesc>Fig. 6 presents the mean scores per SSQ scale and experi-</figDesc><graphic coords="9,301.13,64.75,251.30,161.82" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_17"><head>Fig. 6 :</head><label>6</label><figDesc>Fig. 6: Mean scores per SSQ scale before and after the trial in each experimental condition of Experiment II. A, B, C and D are the experimental conditions, see section 6.2</figDesc><graphic coords="9,31.88,388.87,251.31,161.87" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_18"><head>Fig. 7 :</head><label>7</label><figDesc>Fig. 7: Reported workload scores for each scale: mental demand (MD), physical demand (PD), temporal demand (TD), own performance (OP), effort (EF) and frustration (FR) for the experimental conditions on Experiment II.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_19"><head>Fig. 8 :</head><label>8</label><figDesc>Fig. 8: Response accuracy for the knowledge test taken by users before, after, and three weeks after the trial phase of experiment II.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_20"><head>15</head><label></label><figDesc>Due to the lack of statistical significance regarding knowl-16 edge gain, simulation time, and task accuracy across condi-17 tions, we cannot accept not refuse H1. Every experimental 18 condition increased the severity of sickness symptoms in every 19 SSQ scale, except oculomotor. Condition A requires the user 20 to move their arms around to select objects and employs the 21 WIP technique for navigating in the VE. Although the mean 22 SSQ scores in condition A are the lowest in every scale, we 23 could not find statistical significance to support the difference 24 of means among conditions. In terms of knowledge gain, a 25 negative correlation between overall workload and knowledge 26 gain suggests that high demanding navigation/interaction tech-27 niques could distract users from the task, requiring them to 28 place higher attention on how to use the techniques, decreasing 29 knowledge gain. In condition A, we observed a positive corre-30 lation between mental demand and knowledge gain, suggesting 31 that mentally demanding techniques do not affect knowledge</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_21"><head>32</head><label>32</label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_22"><head></head><label></label><figDesc>35condition A allowed users to keep focus on the task, increas-36 ing mental demand and learning. These experiments should be 37 repeated and the sample enlarged to evaluate H2 and H3. How-38 ever, we believe these results favor their acceptance.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_23"><head>39</head><label>39</label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_25"><head></head><label></label><figDesc>83</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_26"><head>103</head><label></label><figDesc>This study was financed in part by the Coordination for the 104 Improvement of Higher Education Personnel, Brazil (CAPES, 105 Finance Code 001). We also acknowledge the support from Na-106 tional Council for Scientific and Technological, Brazil (CNPq), 107 the participants of our experiments for allowing us to borrow 108 their time and knowledge for this study, and the comments of 109 the reviewers that helped us to improve the quality of this paper. 110</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>-111 gan et al. [17] had previously evaluated the effects of different 112</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>Preprint Submitted for review / Computers &amp; Graphics (2021)</p></note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>SSQ score was 45.4 points (SD=53.7) regarding disorientation 16 symptoms while using the HMD device, which is a high score</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title/>
		<idno type="DOI">10.1109/TVCG.2015.2403312</idno>
	</analytic>
	<monogr>
		<title level="j">actions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="794" to="807" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Virtual reality: How much immersion is enough</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">P</forename><surname>Mcmahan</surname></persName>
		</author>
		<author>
			<persName><surname>Bowman</surname></persName>
		</author>
		<author>
			<persName><surname>Da</surname></persName>
		</author>
		<idno type="DOI">10.1109/MC.2007.257</idno>
		<idno>doi:10.1109/ MC.2007.257</idno>
		<ptr target=".ieeecomputersociety.org/10.1109/MC.2007.257" />
	</analytic>
	<monogr>
		<title level="j">Computer</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page" from="36" to="43" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Virtual memory palaces: immersion aids recall</title>
		<author>
			<persName><forename type="first">E</forename><surname>Krokos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Plaisant</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Varshney</surname></persName>
		</author>
		<idno type="DOI">10.1007/s10055-018-0346-3</idno>
		<ptr target="https://doi.org/10.1007/s10055-018-0346-3.doi:10.1007/s10055-018-0346-3" />
	</analytic>
	<monogr>
		<title level="j">Virtual Reality</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">An evaluation of the effects of hypernatural components of interaction fidelity on locomotion performance in virtual reality</title>
		<author>
			<persName><forename type="first">M</forename><surname>Nabioyuni</surname></persName>
		</author>
		<author>
			<persName><surname>Bowman</surname></persName>
		</author>
		<author>
			<persName><surname>Da</surname></persName>
		</author>
		<idno type="DOI">10.2312/egve.20151325</idno>
		<ptr target="http://dx.doi.org/10.2312/egve.20151325.doi:10.2312/egve.20151325" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th International Conference on Artificial Reality and Telexistence and 20th Eurographics Symposium on Virtual Environments. ICAT -EGVE &apos;15</title>
		<meeting>the 25th International Conference on Artificial Reality and Telexistence and 20th Eurographics Symposium on Virtual Environments. ICAT -EGVE &apos;15<address><addrLine>Aire-la-Ville, Switzerland, Switzerland</addrLine></address></meeting>
		<imprint>
			<publisher>Eurographics Association</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="167" to="174" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Brain training with the body in mind: Towards gamified approachavoidance training using virtual reality</title>
		<author>
			<persName><forename type="first">N</forename><surname>Kakoschke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Page</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>De Courten</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Verdejo-Garcia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Mccormack</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Human-Computer Studies</title>
		<imprint>
			<biblScope unit="volume">151</biblScope>
			<biblScope unit="page">102626</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Signaling in virtual reality influences learning outcome and cognitive load</title>
		<author>
			<persName><forename type="first">P</forename><surname>Albus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Vogt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Seufert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computers &amp; Education</title>
		<imprint>
			<biblScope unit="volume">166</biblScope>
			<biblScope unit="page">104154</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A cyber-human based integrated assessment approach for orthopedic surgical training</title>
		<author>
			<persName><forename type="first">A</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Cecil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Pirela-Cruz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2020 IEEE 8th International Conference on Serious Games and Applications for Health (SeGAH)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Immersive virtual environments: a comparison of mixed reality and virtual reality headsets for asd treatment</title>
		<author>
			<persName><forename type="first">Di</forename><surname>Mascio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Tarantino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename></persName>
		</author>
		<author>
			<persName><forename type="first">De</forename><surname>Gasperis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Pino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference in Methodologies and intelligent Systems for Techhnology Enhanced Learning</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="153" to="163" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Presence, mixed reality, and risk-taking behavior: A study in safety interventions</title>
		<author>
			<persName><forename type="first">S</forename><surname>Hasanzadeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">F</forename><surname>Polys</surname></persName>
		</author>
		<author>
			<persName><forename type="first">La</forename><surname>De</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Garza</surname></persName>
		</author>
		<idno type="DOI">10.1109/TVCG.2020.2973055</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="2115" to="2125" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">LIVE: the human role in learning in immersive virtual environments</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">L</forename><surname>Simeone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Speicher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Molnar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Wilde</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Daiber</surname></persName>
		</author>
		<idno type="DOI">10.1145/3357251.3357590</idno>
		<ptr target="https://doi.org/10.1145/3357251.3357590.doi:10.1145/3357251.3357590" />
	</analytic>
	<monogr>
		<title level="m">Symposium on Spatial User Interaction</title>
		<editor>
			<persName><forename type="first">C</forename><forename type="middle">W</forename><surname>Borst</surname></persName>
		</editor>
		<editor>
			<persName><surname>Kulshreshth</surname></persName>
		</editor>
		<editor>
			<persName><surname>Ak</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Bruder</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Serafin</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Sandor</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K</forename><surname>Johnsen</surname></persName>
		</editor>
		<meeting><address><addrLine>SUI; New Orleans, LA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2019-10-19">2019. October 19-20, 2019. 2019</date>
			<biblScope unit="page" from="1" to="5" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Exploiting object-of-interest information to understand attention in VR classrooms</title>
		<author>
			<persName><forename type="first">E</forename><surname>Bozkir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Stark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Hasenbein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hahn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Kasneci</surname></persName>
		</author>
		<idno type="DOI">10.1109/VR50410.2021.00085</idno>
		<ptr target="https://doi.org/10.1109/VR50410.2021.00085.doi:10.1109/VR50410.2021.00085" />
	</analytic>
	<monogr>
		<title level="m">IEEE Virtual Reality and 3D User Interfaces</title>
		<meeting><address><addrLine>VR; Lisbon, Portugal</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2021-03-27">2021. March 27 -April 1, 2021. 2021</date>
			<biblScope unit="page" from="597" to="605" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Using immersive virtual reality to reduce work accidents in developing countries</title>
		<author>
			<persName><forename type="first">L</forename><surname>Nedel</surname></persName>
		</author>
		<author>
			<persName><surname>Souza</surname></persName>
		</author>
		<author>
			<persName><surname>Vc</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Menin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Sebben</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Oliveira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Faria</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE computer graphics and applications</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="36" to="46" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Gibson&apos;s theory of perceptual learning. i</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">E</forename><surname>Adolph</surname></persName>
		</author>
		<author>
			<persName><surname>Kretch</surname></persName>
		</author>
		<author>
			<persName><surname>Ks</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Keller H(Developmental Section red) International Encyclopedia of the Social and Behavioral Sciences</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="127" to="134" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A revision of bloom&apos;s taxonomy: An overview</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">R</forename><surname>Krathwohl</surname></persName>
		</author>
		<idno type="DOI">10.1207/s15430421tip4104_2</idno>
	</analytic>
	<monogr>
		<title level="j">Theory Into Practice</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="212" to="218" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Redirected walking to explore virtual environments: Assessing the potential for spatial interference</title>
		<author>
			<persName><forename type="first">E</forename><surname>Hodgson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Bachmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Waller</surname></persName>
		</author>
		<idno type="DOI">10.1145/2043603.2043604</idno>
		<ptr target="http://doi.acm.org/10.1145/2043603.2043604.doi:10.1145/2043603.2043604" />
	</analytic>
	<monogr>
		<title level="j">ACM Trans Appl Percept</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1" to="22" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Seven league boots: A new metaphor for augmented locomotion through moderately large scale immersive virtual environments</title>
		<author>
			<persName><forename type="first">V</forename><surname>Interrante</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Ries</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Anderson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Symposium on 3D User interfaces</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2007">2007. 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Walking &gt; walking-in-place &gt; flying, in virtual environments</title>
		<author>
			<persName><forename type="first">M</forename><surname>Usoh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Arthur</surname></persName>
		</author>
		<author>
			<persName><surname>Whitton</surname></persName>
		</author>
		<author>
			<persName><surname>Mc</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Bastos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Steed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Slater</surname></persName>
		</author>
		<idno type="DOI">10.1145/311535.311589</idno>
		<ptr target="http://dx.doi.org/10.1145/311535.311589.doi:10.1145/311535.311589" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th Annual Conference on Computer Graph-ics and Interactive Techniques. SIGGRAPH &apos;99</title>
		<meeting>the 26th Annual Conference on Computer Graph-ics and Interactive Techniques. SIGGRAPH &apos;99<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press/Addison-Wesley Publishing Co</publisher>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="359" to="364" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Taking immersive vr leap in training of landing signal officers</title>
		<author>
			<persName><forename type="first">L</forename><surname>Greunke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sadagic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on visualization and computer graphics</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1482" to="1491" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">An Evaluation of Techniques for Grabbing and Manipulating Remote Objects in Immersive Virtual Environments</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Bowman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">F</forename><surname>Hodges</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Symposium on Interactive 3D Graphics</title>
		<meeting>the Symposium on Interactive 3D Graphics<address><addrLine>Providence, RI, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1997">1997</date>
			<biblScope unit="page" from="35" to="38" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Moving objects in space: exploiting proprioception in virtual-environment interaction</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Mine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brooks</forename><surname>Jr</surname></persName>
		</author>
		<author>
			<persName><surname>Fp</surname></persName>
		</author>
		<author>
			<persName><surname>Sequin</surname></persName>
		</author>
		<author>
			<persName><surname>Ch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th annual conference on Computer graphics and interactive techniques</title>
		<meeting>the 24th annual conference on Computer graphics and interactive techniques</meeting>
		<imprint>
			<date type="published" when="1997">1997</date>
			<biblScope unit="page" from="19" to="26" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Simulator sickness questionnaire: An enhanced method for quantifying simulator sickness</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">S</forename><surname>Kennedy</surname></persName>
		</author>
		<author>
			<persName><surname>Lane</surname></persName>
		</author>
		<author>
			<persName><surname>Ne</surname></persName>
		</author>
		<author>
			<persName><surname>Berbaum</surname></persName>
		</author>
		<author>
			<persName><surname>Ks</surname></persName>
		</author>
		<author>
			<persName><surname>Lilienthal</surname></persName>
		</author>
		<author>
			<persName><surname>Mg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The international journal of aviation psychology</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="203" to="220" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Simulator sickness questionnaire: Twenty years later</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Balk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Bertola</surname></persName>
		</author>
		<author>
			<persName><surname>Inman</surname></persName>
		</author>
		<author>
			<persName><surname>Vw</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Seventh International Driving Symposium on Human Factors in Driver Assessment, Training and Vehicle Design</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
		<respStmt>
			<orgName>University of Iowa</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Tukey&apos;s honestly significant difference (hsd) test</title>
		<author>
			<persName><forename type="first">H</forename><surname>Abdi</surname></persName>
		</author>
		<author>
			<persName><surname>Williams</surname></persName>
		</author>
		<author>
			<persName><surname>Lj</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Encyclopedia of research design</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="5" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Distribution-free multiple comparisons</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">B</forename><surname>Nemenyi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1963">1963</date>
		</imprint>
		<respStmt>
			<orgName>Princeton University</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Using presence questionnaires in reality</title>
		<author>
			<persName><forename type="first">M</forename><surname>Usoh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Catena</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Arman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Slater</surname></persName>
		</author>
		<idno type="DOI">10.1162/105474600566989</idno>
	</analytic>
	<monogr>
		<title level="j">Presence</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="497" to="503" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">A 10-item rasch modeled memory selfefficacy scale</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">M</forename><surname>Zelinski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gilewski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Aging &amp; mental health</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="293" to="306" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Development of nasa-tlx (task load index): Results of empirical and theoretical research</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">G</forename><surname>Hart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">E</forename><surname>Staveland</surname></persName>
		</author>
		<idno type="DOI">10.1016/S0166-4115(08)62386-9</idno>
		<ptr target="https://doi.org/10.1016/S0166-4115(08)62386-9" />
	</analytic>
	<monogr>
		<title level="m">Human Mental Workload</title>
		<title level="s">Advances in Psychology</title>
		<editor>
			<persName><forename type="first">P</forename><forename type="middle">A</forename><surname>Hancock</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Meshkati</surname></persName>
		</editor>
		<meeting><address><addrLine>North-Holland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1988">1988</date>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="page" from="139" to="183" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Comparing the performance of natural, semi-natural, and non-natural locomotion techniques in virtual reality</title>
		<author>
			<persName><forename type="first">M</forename><surname>Nabiyouni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Saktheeswaran</surname></persName>
		</author>
		<author>
			<persName><surname>Bowman</surname></persName>
		</author>
		<author>
			<persName><surname>Da</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Karanth</surname></persName>
		</author>
		<idno type="DOI">10.1109/3DUI.2015.7131717</idno>
	</analytic>
	<monogr>
		<title level="m">IEEE Symposium on 3D User Interfaces (3DUI)</title>
		<imprint>
			<date type="published" when="2015">2015. 2015</date>
			<biblScope unit="page" from="3" to="10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Designing a vibrotactile head-mounted display for spatial awareness in 3d spaces</title>
		<author>
			<persName><forename type="first">Jesus</forename><surname>De</surname></persName>
		</author>
		<author>
			<persName><surname>Oliveira</surname></persName>
		</author>
		<author>
			<persName><surname>Va</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Brayda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Nedel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Maciel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on visualization and computer graphics</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1409" to="1417" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Vibro-tactile feedback for real-world awareness in immersive virtual environments</title>
		<author>
			<persName><forename type="first">D</forename><surname>Valkov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Linsen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Virtual Reality and 3D User Interfaces (VR)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019">2019. 2019</date>
			<biblScope unit="page" from="340" to="349" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Narrative and gaming experience interact to affect presence and cybersickness in virtual reality</title>
		<author>
			<persName><forename type="first">S</forename><surname>Weech</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kenny</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lenizky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Barnett-Cowan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Human-Computer Studies</title>
		<imprint>
			<biblScope unit="volume">138</biblScope>
			<biblScope unit="page">102398</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Can immersive virtual environments make the difference in training industrial operators</title>
		<author>
			<persName><forename type="first">S</forename><surname>Nazir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kluge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Manca</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the Human Factors and Ergonomics Society Europe</title>
		<imprint>
			<biblScope unit="page" from="251" to="265" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
