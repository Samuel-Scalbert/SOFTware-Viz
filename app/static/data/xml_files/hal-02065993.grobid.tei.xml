<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Speeding up RDF aggregate discovery through sampling</title>
				<funder ref="#_34EZTtJ">
					<orgName type="full">unknown</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Ioana</forename><surname>Manolescu</surname></persName>
							<email>ioana.manolescu@inria.fr</email>
						</author>
						<author>
							<persName><forename type="first">Mirjana</forename><surname>Mazuran</surname></persName>
							<email>mirjana.mazuran@inria.fr</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="laboratory" key="lab1">Inria and LIX (</orgName>
								<orgName type="laboratory" key="lab2">UMR 7161</orgName>
								<orgName type="institution">Ecole polytechnique)</orgName>
								<address>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="laboratory" key="lab1">Inria and LIX (</orgName>
								<orgName type="laboratory" key="lab2">UMR 7161</orgName>
								<orgName type="institution">Ecole polytechnique)</orgName>
								<address>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Speeding up RDF aggregate discovery through sampling</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">ED04B8E30B34B81C2F3CE9FB22C0351C</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-04-12T14:45+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>RDF graphs can be large and complex; finding out interesting information within them is challenging. One easy method for users to discover such graphs is to be shown interesting aggregates (under the form of two-dimensional graphs, i.e., bar charts), where interestingness is evaluated through statistics criteria. Dagger <ref type="bibr" target="#b4">[5]</ref> pioneered this approach, however its is quite inefficient, in particular due to the need to evaluate numerous, expensive aggregation queries. In this work, we describe Dagger + , which builds upon Dagger and leverages sampling to speed up the evaluation of potentially interesting aggregates. We show that Dagger + achieves very significant execution time reductions, while reaching results very close to those of the original, less efficient system.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>RDF graphs are oftentimes large and complex; first-time users have a hard time to understand them. Exploration methods investigated in the past are based on keyword search, or on RDF summaries, which give users a first idea of a graph's content and structure. A different method of exploring RDF graphs was introduced in Dagger <ref type="bibr" target="#b4">[5]</ref>, based on aggregation. Starting from an RDF graph, a set of agregate queries are automatically identified and evaluated, the most interesting ones (in a sense to be outlined shortly below) are chosen, and shown to human users as two-dimensional plots, in particular, bar charts. Figure <ref type="figure" target="#fig_0">1</ref> shows two examples. Above, we see the distribution of the number of ingredients appearing in food recipes in an RDF version of the foodista.com Web site, going from 1 to 25 with a peak at 8; we consider this distribution interesting as it has a clearly identified peak and quite a narrow interval. The graph below shows the distribution of Nobel prizes between female (left) and male (right) recipients; we find this interesting as it is very unbalanced.</p><p>As these examples illustrate, in Dagger + , we consider an aggregate query interesting if its result set has a high variance (second statistical moment). Other criteria can be considered, e.g., we have experimented also with the third statistical moment (skewness); more generally, while an RDF graph may have many interesting features, we seek to find aggregates over the graph having the highest variance. The running time of Dagger was quite high: it took hours to identify the 10 most interesting aggregates on a dataset of 20 million triples. In this paper, we show how to speed it up, in particular through novel sampling techniques.</p><p>The remainder of this article is organized as follows. Section 2 introduces the state of the art. Section 3 describes the main concepts and algorithms of Dagger <ref type="bibr" target="#b4">[5]</ref>, together with a set of improvements we brought through re-engineering. Then, Section 4 presents our performance-enhancing sampling technique.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">STATE OF THE ART</head><p>The problem of data exploration <ref type="bibr" target="#b7">[8]</ref> has received much attention; the automatic extraction of interesting aggregates is just one among many proposed techniques. Multidimensional data is particularly interesting in this respect, however, most works assume a fixed relational schema, which is not available for RDF graphs. More recent works <ref type="bibr" target="#b1">[2]</ref>, consider graphs, but (unlike Dagger) assume a very regular and simple structure.</p><p>In <ref type="bibr" target="#b8">[9]</ref> the authors show how to automatically extract the top-k insights from multi-dimensional relational data, with fixed dimensions and measures. An insight is an observation derived from aggregation in multiple steps; it is considered interesting when it is remarkably different from others, or it exhibits a rising or falling trend. SeeDB <ref type="bibr" target="#b9">[10]</ref> recommends visualizations in high-dimensional relational data by means of a phased execution framework. The focus is to detect the visualizations with a large deviation with respect to a reference (e.g. another dataset, historical data or the rest of the data) from a database with a snowflake schema. In <ref type="bibr" target="#b5">[6]</ref>, multi-structural databases are proposed; their schema (i.e. possible dimensions) is known and three analytical operations are defined to: (i) determine how data is distributed across a particular set of dimensions, (ii) compare two sets of data with respect to given dimensions and (iii) separate the data into cohesive groups with respect to the known dimensions.</p><p>In contrast, Dagger (and Dagger + ) start directly from RDF, and, lacking schema information, automatically derives dimensions and measures that are good candidates to produce insights.</p><p>There is no universally accepted definition of interestingness; frequently, something unexpected (which differs from a reference) is considered interesting. The reference might be known a-priori, come from historical data, or be the average behavior. So far we have experimented with variance, skewness and kurtosis; we are also working to use the entropy. Many different RDF visualizations techniques can be used, e.g., <ref type="bibr" target="#b0">[1]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">DAGGER OVERVIEW</head><p>We consider three pairwise disjoint sets: the set of URIs U, the set of literals L, and the set of blank nodes B. An RDF graph G is a finite set of triples of the form (s, p, o), called subject, property and object, such that s ∈ (U ∪ B), p ∈ U and o ∈ (U ∪ B ∪ L). The RDF property rdf:type is used to attach types (i.e. classes) to an RDF resource, which can have zero, one or several types. G can have an ontology stating relationships between its classes and properties, e.g., any UndegraduateStudent is a Student; its presence may lead to implicit triples, which are part of G even if they may not appear explicitly. A graph containing all the triples which may be derived from it is said to be saturated. Without loss of generality, we consider that our input graph is saturated.</p><p>Dagger identifies unidimensional aggregate queries to be evaluated in an RDF graph G. However, unlike a traditional relational data warehouse, an RDF graph comes without identified set of facts; nor are dimensions and measures known in advance. Therefore, Dagger must enumerate candidates for each of these roles.</p><p>A set of candidate facts (c f , in short) is a set of G resources which are deemed interesting for the analysis. Dagger considers as c f (i) all the resources of a given class C, e.g., all the Students; (ii) all the resources having a certain set P of properties, e.g., all those having title and author. A simple way to pick such a property set is to compute the support of the properties in G and select property sets whose support is above a certain threshold.</p><p>A candidate dimension (denoted d) is used for grouping the candidate facts. Dagger supports as candidate dimensions (i) properties present on at least a certain fraction t t hr es of resources from c f ; (ii) derived properties, computed by Dagger in order to find potentially interesting insights. The derived properties supported in <ref type="bibr" target="#b4">[5]</ref> are count(p), where p is a property that some c f resources have. For instance, if resources of type Student are stated to takeCourse, Dagger derives the property takeCourse#. Further, Dagger will consider a candidate dimension only the number of distinct values of this property on the c f resources is smaller than t dist × |c f | for a certain ratio 0 &lt; t dist &lt; 1.</p><p>A candidate measure (denoted m) is something to be evaluated or measured for each candidate fact. Dagger considers candidate measures among the (original or derived) properties of candidate facts whose support is above t t hr esh . Dimension-measure combinations such that one is a property a and the other is the count a# of this property are excluded.</p><p>An aggregation function ⊕ is chosen among min, max, avg, sum, count; the first four are considered only if the measure is numeric. Given that RDF data is often untyped or only partially typed, Dagger implements a type detection mechanism by trying to convert the property values to different types.</p><p>A Dagger aggregate aдд is a tuple (c f , d, m, ⊕). To specify how interesting an aggregate is, let f (V ) be a function which inputs a set of numerical values V and returns a number. Given f , the interestingness of aдд is computed as:</p><p>• let d 1 , d 2 , . . . be the distinct values that d may take for a resource in c f ; • for each d i , let c f i be set of c f resources for which d takes the value d i ; observe that the c f i sets may overlap, as a resource with more than one value for d belongs to several such sets. For instance, students can be grouped by the courses they take, and each student takes many courses; • for each c f i , let M i be the set of m values of c f i resources, and</p><formula xml:id="formula_0">m i = ⊕(M i ); • the interestingness of aдд is f ({m 1 , m 2 , . . .}).</formula><p>The problem considered by Dagger is: given a graph G, a set of value thresholds, function f and an integer k, find the k most interesting aggregates. Architecture. Dagger leverages the robust query evaluation capabilities of an RDBMS to store the RDF graph, enumerate and evaluate candidate aggregates. SQL queries are used to: determine the resources part of a candidate fact sets; evaluate the suitability of their properties as dimensions, respectively, measures; compute and aggregate the group measures m i . The remaining operations, e.g., the computation of the interestingness score function, are done in Java. Aggregate recommendation cost. The most expensive computation steps are: (i) finding the candidate dimensions and (ii) evaluating the aggregation operations. Indeed, when looking for candidate dimensions, several queries are issued over c f (e.g., find all distinct properties, count the number of subject that have each property, find the values of the derived properties, etc.). Moreover, many candidate aggregates are generated, also leading to a high number of potentially expensive SQL queries.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">DAGGER + : SPEEDING UP DAGGER</head><p>A set of re-engineering changes were brought to Dagger since the original demonstration. In particular, it has been ported on top of OntoSQL (https://ontosql.inria.fr), a Java-based platform developed at Inria, providing efficient RDF storage, saturation, and query processing algorithms <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b3">4]</ref>. OntoSQL encodes spaceconsuming URIs and literals into compact integers, together with a dictionary table which allows going from one to the other. For a given class c, all triples of the form x type c are stored in a single-column table t c holding the codes of the subjects x; for each property p other than type, a table t p stores (s code, o code) pairs for each (s, p, o) triple in G. This re-engineering has lead to a very significant reduction in Dagger's running time, e.g., on a 20 million triples graph, from several hours to 20 minutes.</p><p>Further, we adapted an optimization previously proposed in <ref type="bibr" target="#b9">[10]</ref>: we evaluate all candidate aggregates that share both dimension and measure by a single SQL query. In a relational context, aggregates can be evaluated together as soon as they have the same dimension (even if the measures are different) because one relational tuple usually contains all the attributes used in the different measures. In contrast, RDF candidate facts need to be joined with the t d table corresponding to the property d chosen as dimension, and with the t m table for the property chosen as measure; distinct measures require distinct joins, thus sharing is more limited. This is not due to the storage model, but to RDF heterogeneity: the candidate facts having the measure property m 1 may be different from those having property m 2 . This forces evaluating (d, m 1 ) aggregates separately from (d, m 2 ) ones.</p><p>Below, we focus on two novel optimization techniques we applied subsequently: using an RDF graph summary to speed up candidate dimension enumeration (Section 4.1), and using sampling to accelerate candidate dimension enumeration, aggregate evaluation and ranking (Section 4.2).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Summary-based dimension enumeration</head><p>RDFQuotient <ref type="bibr" target="#b6">[7]</ref> is a structural RDF graph summarization tool based on graph quotients. Given an equivalence relation over graph nodes, the summary contains one node for each equivalence class in the original graph. Moreover, each edge n a -→ m in the original graph leads to an edge rep(n) a -→ rep(m) in the summary, where rep(n) is the summary representative of node n. A particular equivalence relation groups the nodes by their set of types. Dagger + uses it to find: (i) all the types, (ii) for each type, the number of resources of that type, and (iii) the set of possible properties these resources might have. These questions can be answered exactly directly from the RDFQuotient reducing dimension enumeration time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Sampling-based aggregate selection</head><p>We introduced two sampling strategies to trade some accuracy in aggregate selection for running time:</p><p>• CFSampling: the c f is sampled (draw n 1 samples of size n 2 ), and candidate dimensions and measures are found for each sample independently. For each of the n 1 samples, candidate aggregates are generated, and their interestingness is evaluated on the sample. • ESampling: candidate dimensions and measures are computed on the whole c f as in Dagger. Then, n 1 samples of size n 2 are drawn from the c f , and the candidate aggregates are evaluated on the samples.</p><p>With CFSampling, the aggregates recommended for different sample may be different, e.g., certain properties might be found to be frequent in some sample but not in all of them. After the evaluation, a ranked list of aggregates is obtained for each sample. In ESampling, instead, the set of aggregates is unique as it is derived directly from the original data. However, given that all the aggregates are evaluated on samples, it also yields a ranked list of aggregates for each sample.</p><p>To be able to compare the results found without sampling with those found through sampling, we need to reconcile the results found on different samples into a single ranked list. We can do this by taking (i) the union or (ii) the intersection of the lists obtained from all the samples. Then, we re-rank the aggregates according to a estimation of their global interestingness measure (based on their interestingness on each sample), e.g., through pooled variance; at the end of this process, we obtain a unique ranked list of candidate aggregates.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">EXPERIMENTAL RESULTS</head><p>We measure the run time performances and to test the accuracy of the results obtained with sampling techniques. We used a 2,7 GHz Intel Core i7 with 16 GB of RAM. We describe experiments on the articles from the DBLP dataset 1 ; we use 20.132.491 triples describing information about 888.183 distinct articles. Dagger + without sampling. First, we evaluate how much the use of the summary, and the shared evaluation, improve performance. Figure <ref type="figure" target="#fig_1">2</ref> shows the two main components (finding dimensions and aggregate evaluation), as well as a third, very small bar representing the other operations. Note that the property analysis which allows to select candidate dimensions also enables to select candidate measures (thus candidate measure selection time is negligible and wrapped under "Other").</p><p>Without any optimization ("NoSummary, NoShared" bar in Figure <ref type="figure" target="#fig_1">2</ref>), 21% of the time is spent looking for dimensions, while 78% of the time goes to evaluating aggregates. Summary use introduces a modest performance improvement, while shared aggregate evaluation has a much more significant result (see the "NoSummary, Shared" and "Summary, Shared" bars). Here, 1 http://www.rdfhdt.org/datasets/ Dagger + generates a total of 371 candidate aggregates; without shared evaluation, each of them is evaluated as one query, however, with shared evaluation, only 131 queries are executed as this is the number of distinct pairs of dimension and measure.</p><p>Sampling. We measure the running time and the accuracy of the results by varying 3 parameters: (i) the sampling strategy (CFSampling or ESampling), (ii) the number of samples (2, 3, 4 or 5); and (iii) the sample size, as a ratio of the candidate fact set size (from 1% to 10% of the number of distinct CF resources). Figure <ref type="figure" target="#fig_2">3</ref> shows the running times: one plot for each number of samples (from top to bottom, 2, 3, 4, 5), each of which varies the strategy and the sample size. Ten runs are averaged for each parameter combinations (different samples are drawn in each run).</p><p>Figure <ref type="figure" target="#fig_2">3</ref> shows that ESampling is slower than CFSampling, as the former looks for candidate dimensions on the whole candidate fact set, whereas the latter does this on smaller-size samples. ESampling enumerates all the candidate aggregates also found without sampling, while CFSampling might enumerate a different set of aggregates: some properties that are overall frequent (infrequent) might be found infrequent (frequent) in a specific sample, and thus not be considered (considered) as candidate dimensions and measures. However, even though ESampling enumerates all the no-sampling candidate aggregates, it evaluates them on samples, and may end up considering them interesting (uninteresting) differently from the way they are on the complete CF.</p><p>To evaluate the accuracy of the results obtained through sampling, we compare the Top-5, Top-10 and Top-20 aggregates found without sampling, with those found through sampling. The ranked list of aggregates found with sampling is built by taking the union of all those found across the samples and reranking them according to the interestingness measure (in our experiments we use the pooled variance to rank all the results).    Aggregates whose interestingness is zero are not considered. Notice that we do not break ties, that is: if we search e.g. the Top-5 most interesting aggregates, but find that the sixth element in the list has the same interestingness value as the fifth, we also include it in the Top-5, as we did not find a meaningful way to break such ties. When no sampling is used, Top-5 returned 5 aggregates, respectively, Top-10 returned 11 while the Top-20 returned 20. We compute the accuracy as the percentage of aggregates in the sampling result, that are also in the result without sampling. Table <ref type="table" target="#tab_1">1</ref> shows the precision of CFSampling while Table <ref type="table" target="#tab_2">2</ref> shows that of ESampling. In 57% of the cases the accuracy obtained using ESampling is higher; on average, the two accuracy values differ by 6%. The accuracy is quite low when searching for the the Top-5 aggregates; in contrast, both Top-10 and Top-20 can be well approximated (accuracy above 80% for the Top-20 even with few samples). In general, the bigger the samples, the better the accuracy, however, results show situations where the Top-10 and Top-20 have better accuracy with a lower number of samples; there is a 10% difference in accuracy on average, i.e. the top-Ks differ by 2/3 aggregates. This does not mean that such aggregates were not found though but they have been ranked differently. Clearly, the accuracy increases with K (the amount of top aggregates) and with the size of the samples. The increase in the number of samples does not significantly improve accuracy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">CONCLUSION</head><p>Automatic selection of interesting aggregates in an RDF graph is challenging, as candidate dimensions and measures must be "guessed" from the data, and candidate aggregates must be evaluated to assess their interestingness. After re-engineering Dagger <ref type="bibr" target="#b4">[5]</ref> to exploit an existing efficient RDF platform, we have shown that sharing work and (to a lesser extent) using a graph summary can reduce its running time by a factor of 2. Our main focus has been on sampling, which, for Top-10 and Top-20 search, achieves good accuracy (above 70%) while reducing running time by another factor of 2. Overall, CFSampling appears the most interesting strategy. Our current work stretches in several directions: (i) generalizing Dagger to more complex dimension and measure selection, (ii) adopt more interestingness metrics, (iii) introduce new types of derived properties, e.g., extract meaningful keywords from textual properties to be used as potential dimensions and/or measures.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Sample interesting aggregates.</figDesc><graphic coords="2,53.80,553.65,176.22,87.67" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Impact of summary and sharing.</figDesc><graphic coords="4,53.80,495.00,140.40,108.30" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Running times with sampling.</figDesc><graphic coords="4,309.94,83.69,228.95,291.65" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Accuracy of results (%) with respect to running times (sec).</figDesc><graphic coords="5,87.52,83.68,418.00,152.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4</head><label>4</label><figDesc>plots the accuracy with respect to the running times. Each line of graphs represents the Top-5, Top-10 and Top-20 for a different number of samples; red x's indicate CFsampling, while green +'s indicate ESampling, for different sample dimensions.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>Accuracy of results with CFSampling.</figDesc><table><row><cell cols="3">#samples Top-K 1%</cell><cell>3%</cell><cell>5%</cell><cell>7%</cell><cell>9% 10%</cell></row><row><cell></cell><cell>Top5</cell><cell cols="4">40% 36% 24% 32% 28% 32%</cell></row><row><cell>2</cell><cell cols="5">Top10 49% 55% 63% 57% 63% 71%</cell></row><row><cell></cell><cell cols="5">Top20 65% 69% 81% 84% 89% 93%</cell></row><row><cell></cell><cell>Top5</cell><cell cols="4">28% 28% 32% 24% 16% 28%</cell></row><row><cell>3</cell><cell cols="5">Top10 45% 68% 71% 60% 59% 72%</cell></row><row><cell></cell><cell cols="5">Top20 67% 76% 75% 83% 83% 87%</cell></row><row><cell></cell><cell>Top5</cell><cell cols="4">36% 16% 12% 24% 24% 20%</cell></row><row><cell>4</cell><cell cols="5">Top10 49% 55% 27% 41% 60% 53%</cell></row><row><cell></cell><cell cols="5">Top20 70% 71% 66% 73% 87% 84%</cell></row><row><cell></cell><cell>Top5</cell><cell cols="4">36% 20% 12% 24% 20% 24%</cell></row><row><cell>5</cell><cell cols="5">Top10 50% 49% 38% 45% 52% 60%</cell></row><row><cell></cell><cell cols="5">Top20 68% 63% 68% 77% 80% 88%</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>Accuracy of results with ESampling.</figDesc><table /></figure>
		</body>
		<back>

			<div type="funding">
<div><p>* <rs type="person">M. Mazuran</rs> is supported by the <rs type="programName">H2020 research program</rs> under grant nr. <rs type="grantNumber">800192</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_34EZTtJ">
					<idno type="grant-number">800192</idno>
					<orgName type="program" subtype="full">H2020 research program</orgName>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">LODeX: A Tool for Visual Querying Linked Open Data</title>
		<author>
			<persName><forename type="first">Fabio</forename><surname>Benedetti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sonia</forename><surname>Bergamaschi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Laura</forename><surname>Po</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ISWC 2015 Posters &amp; Demonstrations</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Using entropy metrics for pruning very large graph cubes</title>
		<author>
			<persName><forename type="first">D</forename><surname>Bleco</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Kotidis</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
	<note type="report_type">Information Systems</note>
	<note>To appear</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Optimizing Reformulationbased Query Answering in RDF</title>
		<author>
			<persName><forename type="first">D</forename><surname>Bursztyn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Goasdoué</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Manolescu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EDBT</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Teaching an RDBMS about ontological constraints</title>
		<author>
			<persName><forename type="first">D</forename><surname>Bursztyn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Goasdoué</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Manolescu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PVLDB</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page">12</biblScope>
			<date type="published" when="2016">2016. 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Dagger: Digging for Interesting Aggregates in RDF Graphs</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Diao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Manolescu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Shang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ISWC Posters &amp; Demonstrations Track</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Multi-structural databases</title>
		<author>
			<persName><forename type="first">R</forename><surname>Fagin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">V</forename><surname>Guha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Novak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Sivakumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Tomkins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">PODS. ACM</title>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="184" to="195" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Incremental structural summarization of RDF graphs (demo)</title>
		<author>
			<persName><forename type="first">François</forename><surname>Goasdoué</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pawel</forename><surname>Guzewicz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ioana</forename><surname>Manolescu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EDBT</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Overview of Data Exploration Techniques</title>
		<author>
			<persName><forename type="first">S</forename><surname>Idreos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Papaemmanouil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Chaudhuri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGMOD</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="277" to="281" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Extracting Top-K Insights from Multi-dimensional Data</title>
		<author>
			<persName><forename type="first">B</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">L</forename><surname>Yiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGMOD. ACM</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1509" to="1524" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">SEEDB: Efficient Data-Driven Visualization Recommendations to Support Visual Analytics</title>
		<author>
			<persName><forename type="first">M</forename><surname>Vartak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Rahman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Madden</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">G</forename><surname>Parameswaran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Polyzotis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PVLDB</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">13</biblScope>
			<biblScope unit="page" from="2182" to="2193" />
			<date type="published" when="2015">2015. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
