<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Overview of PlantCLEF 2021: cross-domain plant identification</title>
				<funder ref="#_ZGnxxhu">
					<orgName type="full">European Union</orgName>
				</funder>
				<funder ref="#_3JgrWtp">
					<orgName type="full">Agence Nationale de la Recherche</orgName>
					<orgName type="abbreviated">ANR</orgName>
				</funder>
				<funder ref="#_Qm8fcun">
					<orgName type="full">unknown</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Herv√©</forename><surname>Go√´au</surname></persName>
							<email>herve.goeau@cirad.fr</email>
							<affiliation key="aff0">
								<orgName type="laboratory">CIRAD</orgName>
								<orgName type="institution">UMR AMAP</orgName>
								<address>
									<settlement>Montpellier, Occitanie</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Pierre</forename><surname>Bonnet</surname></persName>
							<email>pierre.bonnet@cirad.fr</email>
							<affiliation key="aff0">
								<orgName type="laboratory">CIRAD</orgName>
								<orgName type="institution">UMR AMAP</orgName>
								<address>
									<settlement>Montpellier, Occitanie</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Alexis</forename><surname>Joly</surname></persName>
							<email>alexis.joly@inria.fr</email>
							<affiliation key="aff1">
								<orgName type="laboratory" key="lab1">Inria</orgName>
								<orgName type="laboratory" key="lab2">LIRMM</orgName>
								<orgName type="institution" key="instit1">Univ Montpellier</orgName>
								<orgName type="institution" key="instit2">CNRS</orgName>
								<address>
									<settlement>Montpellier</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Overview of PlantCLEF 2021: cross-domain plant identification</title>
					</analytic>
					<monogr>
						<idno type="ISSN">1613-0073</idno>
					</monogr>
					<idno type="MD5">AD2A928842873C6812DBB88894D71E1D</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-04-12T14:46+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>LifeCLEF</term>
					<term>PlantCLEF</term>
					<term>plant</term>
					<term>domain adaptation</term>
					<term>cross-domain classification</term>
					<term>tropical flora</term>
					<term>Amazon rainforest</term>
					<term>Guiana Shield</term>
					<term>species identification</term>
					<term>fine-grained classification</term>
					<term>evaluation</term>
					<term>benchmark</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Automated plant identification has improved considerably thanks to recent advances in deep learning and the availability of training data with more and more field photos. However, this profusion of data concerns only a few tens of thousands of species, mainly located in North America and Western Europe, much less in the richest regions in terms of biodiversity such as tropical countries. On the other hand, for several centuries, botanists have systematically collected, catalogued and stored plant specimens in herbaria, especially in tropical regions, and recent efforts by the biodiversity informatics community have made it possible to put millions of digitised records online. The LifeCLEF 2021 plant identification challenge (or "PlantCLEF 2021") was designed to assess the extent to which automated identification of flora in data-poor regions can be improved by using herbarium collections. It is based on a dataset of about 1,000 species mainly focused on the Guiana Shield of South America, a region known to have one of the highest plant diversities in the world. The challenge was evaluated as a cross-domain classification task where the training set consisted of several hundred thousand herbarium sheets and a few thousand photos to allow learning a correspondence between the two domains. In addition to the usual metadata (location, date, author, taxonomy), the training data also includes the values of 5 morphological and functional traits for each species. The test set consisted exclusively of photos taken in the field. This article presents the resources and evaluations of the assessment carried out, summarises the approaches and systems used by the participating research groups and provides an analysis of the main results.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Automated identification of the living world has improved considerably in recent years. In particular, in the LifeCLEF 2017 Plant Identification challenge, impressive identification performances have been measured with recent deep learning models (e.g. up to 90% classification accuracy on 10,000 species), and it was shown in <ref type="bibr" target="#b0">[1]</ref> that automated systems are today not so far from human expertise. However, these conclusions are only valid for species that live predominantly in Europe and North America. Therefore, the LifeCLEF 2019 plant identification challenge focused on tropical countries, where there are generally far fewer observations and images collected and where the flora is much more difficult for human experts to identify. In the meantime, biodiversity informatics initiatives such as iDigBio 1 or e-ReColNat 2 have made millions of digitized herbarium sheets stored in many natural history museums over the world, Despite the very different visual appearances between the two types of images such as light reflection and leaf color, the overall leaf shape, vein structure, and leaf insertion on the branch remain invariant in both domains. available online. Over more than 3 centuries, generations of botanists have systematically collected, catalogued and stored plant specimens in herbaria. These specimens have great scientific value and are regularly used to study species variability, phylogenetic relationships, evolution or phenological trends. In particular, one of the key step in the work of botanists and taxonomists is to find the herbarium sheets that correspond to a new specimen observed in the field. This task requires a high level of expertise and can be very tedious. The development of automated tools to facilitate this work is therefore of crucial importance. Following on from the PlantCLEF challenges held in previous years <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b9">10]</ref>, a new challenge was introduced in 2020 and designed to assess the extent to which automated identification on flora in data-deficient regions can be improved by using natural history collections of herbarium sheets. In tropical countries, many species are not easily available, resulting in a very limited number of field-collected photographs, whereas several hundred or even several thousand herbarium sheets have been collected over the centuries. Herbarium collections potentially represent a large amount of data to train species prediction models, but they also induce a much more difficult problem, usually called cross-domain classification task. Indeed, a plant photographed in the field may have a very different visual appearance than its dried version placed on a herbarium sheet (as illustrated in Figure <ref type="figure" target="#fig_0">1</ref>). The task was based on a dataset of 997 species mainly focused on the Guiana shield and the Northern Amazon rainforest (see Figure <ref type="figure" target="#fig_1">2</ref>), an area known to have one of the greatest diversity of plants and animals in the world. The dataset contains 321,270 herbarium sheets (see Table1 for detailed information). About 12% were collected in French Guyana and hosted in the "Herbier IRD de Guyane" (IRD Herbarium of French Guyana). These herbarium sheets were digitized in the context of the e-ReColNat 2 project. The remaining herbarium sheets come from the iDigBio 1 portal (the US National Resource for Advancing Digitization of Biodiversity Collections).</p><p>In order to enable learning a mapping between the two domains (i.e. between the "source" domain of herbarium sheets and the "target" domain of field photos), a relatively smaller set of 6,316 photos in the field was provided additionally to the large herbarium sheets dataset. About 62 % of them also come from he iDigBio portal and were acquired by various photographers related to numerous institutes and national museums that share their data in iDigBio. Besides, two highly trusted experts of the French Guyana flora, Marie-Fran√ßoise Pr√©vost "Fanchon" <ref type="bibr" target="#b10">[11]</ref> and Jean-Fran√ßois Molino<ref type="foot" target="#foot_0">3</ref> provided the remaining field photos that were divided between the training set and the test set.</p><p>A valuable asset of the training set is that a set of 354 plant observations are provided with both herbarium sheets and field photos for the same individual plant. This potentially allows a more precise mapping between the two domains (see previous Figure <ref type="figure" target="#fig_0">1</ref> as an example). It should also be noted that about half of the species in the training set (495 to be precise) is only represented by herbarium sheets which makes training a model even more difficult without the presence of field photo examples. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2.">Traits metadata</head><p>Additional metadata at the species level expressing functional traits were introduced this year. This is a very valuable information that can potentially help improve prediction models. Indeed, it can be assumed that species which share the same functional traits also share to some extent common visual appearances. This information can then potentially be used to guide the training of a model through auxiliary loss functions for instance. The information was collected through the Encyclopedia of Life API. The 5 most comprehensive traits have been verified and completed by experts in Guyanese flora, so that each species has a value for each trait. Below we list the names of the 5 traits as well as the possible values associated with these traits. Plant growth form: describes which plant growth form can take a species among these 4 possibilities: climber, herb, shrub, tree. It is important to note that a species can sometimes be associated with several forms of growth. For example, a young plant of the species Justicia betonica L. can be considered as an herb while in adulthood it would be described as a shrub.</p><p>Habitat: a set non standardised free tag(s) describing the typical habitats of a given species. As examples, we can indicate the most frequently used tags: tropical, moist, broadleaf, forest, flooded, grassland, rocky, non-wetland, savanna, shrubland, coastal.</p><p>Plant lifeform: refers to the physical support of development used by a species. Below is a list of all possible values and their definitions:</p><p>‚Ä¢ Aquatic plant.</p><p>‚Ä¢ Epiphyte: an organism that grows on the surface of a plant and derives its moisture and nutrients from the air, rain, water (in marine environments) or from debris accumulating around it.</p><p>‚Ä¢ Geophyte: species that develop organs for storing energy (water or carbohydrates).</p><p>‚Ä¢ Helophyte: a plant that grows in or near water and is either emergent, submergent, or floating. ‚Ä¢ Hemiepiphyte: a plant that spends part of its life cycle as an epiphyte.</p><p>‚Ä¢ Hydrophyte: close to helophyte.</p><p>‚Ä¢ Lithophyte: plants that grow in or on rocks.</p><p>‚Ä¢ Pleustophyte: a plant living in the thin surface layer existing at the air-water interface of a body of water which serves as their habitat. ‚Ä¢ Succulent plant: a plant with parts that are thickened, fleshy, and engorged, usually to retain water in arid climates or soil conditions (close to geophyte). ‚Ä¢ Terrestrial plant.</p><p>Trophic guild: can be common to any group of species that exploit the same resources, or that exploit different resources in related ways.</p><p>‚Ä¢ Carnivorous plant.</p><p>‚Ä¢ Parasite: a plant that derives some or all of its nutritional requirement from another living plant. ‚Ä¢ Hemiparasite: partially parasite.</p><p>‚Ä¢ Photoautotroph: a plant that is capable of synthesizing its own food from inorganic substances using light as an energy source ‚Ä¢ Saprotrophic: a plant which secrete digestive juices in dead and decaying matter and convert it into a solution and absorb it.</p><p>Woodiness: expresses whether the species is capable of producing "lignin" (wood). Then, the values are basically herb or woody.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.3.">Test set</head><p>The test set was composed of 3,186 photos in the field related to 638 plant observations (about 5 pictures per plants on average). To avoid bias related to similar pictures coming from neighboring plants in the same observation site, we ensured that all observations of a given species by a given collector were either in the training set or in the test set but never spread over the two sets. For instance, for the observations of J.F. Molino, the 166 species in the test set are different from the 125 species in the training set. Most importantly, plant species in the test set were selected according to the number of field photos illustrating them in the training set. As it can be observed in Figure <ref type="figure" target="#fig_2">3</ref> (a), the priority was given to species with few or no field pictures at all. Such a choice may seem drastic, making the task extremely difficult, but the underlying idea was to encourage and promote methods that are as generic as possible, capable of transferring knowledge between the two domains, even without any examples in the target domain for some classes. The second motivation of this choice, was to impose a mapping between herbarium and field photos and avoid that classical methods based on CNNs perform well because of an abundance of field photos in the training set rather than the use of herbarium sheets. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.4.">External training sets</head><p>Participants to the evaluation were allowed to use complementary training data (e.g. for pretraining purposes) but on the condition that (i) the experiment is entirely reproducible, i.e. that the used external resource is clearly referenced and accessible to any other research group, (ii) the use of external training data or not is clearly mentioned for each evaluated method, and (iii) the additional resource does not contain any of the test observations. External training data was thus allowed but participants had to provide at least one submission that used only the training data provided this year. The organizers suggested two external datasets used in the previous edition PlantCLEF2019 <ref type="bibr" target="#b9">[10]</ref>, <ref type="bibr" target="#b11">[12]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.5.">Task Description</head><p>Evaluation metrics: the goal of the task was to identify the correct species of the 638 plant of the test set. For every plant, the evaluated systems had to return a list of species, ranked without ex-aequo. Each participating group was allowed to submit up to 10 run files built from different methods or systems (a run file is a formatted text file containing the species predictions for all test items).</p><p>The main evaluation measure for the challenge was the Mean Reciprocal Rank (MRR), which is defined as the mean of the multiplicative inverse of the rank of the correct answer:</p><formula xml:id="formula_0">1 ùëÑ ùëÑ ‚àëÔ∏Å ùëû=1 1 rank ùëû</formula><p>where ùëÑ is the number of plant observations and rank ùëû is the predicted rank of the true label for the ùëûth plant observation.</p><p>A second evaluation measure was again the MRR but computed on a subset of observations of difficult species that are rarely photographed in the field. Species were selected based on the most comprehensive estimate of the number of field photos from different data sources (iDigBio, GBIF, Encyclopedia of Life, Bing and Google Image search engines). It is therefore a more challenging metric because it focuses on the species which impose a mapping between herbarium and field photos. Figure <ref type="figure" target="#fig_2">3</ref> (b) revises the previous Figure <ref type="figure" target="#fig_2">3</ref> (a) according to the considered external data sources and shows that many plant observations in the difficult test subset are related to species estimated to have less than 10 field photos.</p><p>Course of the challenge: the training data was publicly shared mid February 2021 through the AICrowd platform <ref type="foot" target="#foot_1">4</ref> . Any research team wishing to participate in the evaluation could register on the platform and download the data. The test data was shared in mid-April but without the species labels, which were kept secret. Each team could then submit up to 10 submissions corresponding to different methods or different settings of the same method. A submission (also called a run) takes the form of a csv file containing the predictions of the method being evaluated for all observations in the test set. For each submission, the calculation of the evaluation metrics is then done automatically and visible to the participant. Once, the submission phase was closed (mid May), the participants could also see the evaluation metric values of the other participants. As a last important step, each participant was asked to provide a working note, i.e. a detailed technical report containing all technical information required to reproduce the results of all submissions. All LifeCLEF working notes are reviewed by at least two members of LifeCLEF organizing committee to ensure a sufficient level of quality and reproducibility.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Participants and methods</head><p>About 30 teams/researchers registered for the PlantCLEF challenge 2021 and 4 of them finally submitted runs. Details of the methods are developed in the individual working notes of the participants (NeuonAI <ref type="bibr" target="#b12">[13]</ref>, Lehigh University <ref type="bibr" target="#b13">[14]</ref>). The other teams did not provide a detailed description of their systems, but some informal descriptions were sometimes provided in the metadata associated with the submissions and partially contributed to the comments below.</p><p>Neuon AI, Malaysia, 7 runs [13]: the method is actually an extension of a previous approach already successfully evaluated last year in PlantCLEF2020 <ref type="bibr" target="#b14">[15]</ref>. It is based on a two-streamed Herbarium-Field Triplet Loss Network (HTFL) to assess the similarity between herbarium and field pairs thus matching species from both herbarium and field domains. This mechanism is better at predicting observations of species with missing field images in the training set than traditional CNNs. The general concept is to train the network with triplet samples (2 samples from the same species and 1 from another species) to minimize the distance between the same species and maximize the distance between different species. Then, an herbarium dictionary is computed: each class (each specie)s is associated with an unique embedding computed as the average of the random herbarium sheets from the class. For inference, a plant observation is then associated with a unique embedding computed as the average of the embeddings of all (augmented) field photos of the observation. Cosine similarity is used as a distance metric between the embeddings of all herbarium classes and the embedding of the tested field observation. It is then transformed with inverse distance weighting into probabilities to rank the classes. The authors introduced this year several novelties to improve the method:</p><p>‚Ä¢ They trained a complementary One-Streamed Mixed network (OSM) by taking both herbarium and field images as input to learn the features of each species irrespective of their domains. The learned features of the OSM network are used as a way to measure the feature similarity between herbarium-field pairs instead of directly classifying them. This mechanism allows for the prediction of classes where field images are missing in a similar way triplet network does. ‚Ä¢ Complementary dictionary for embedding: they showed that by adding field images to the herbarium images for computing the herbarium dictionary, the "HFTL (field)" performs better on difficult "unseen" species without field images in the training set, but worse for species having field images in the training than the initial HTFL approach using only herbarium sheets for computing the dictionary. ‚Ä¢ Ensemble: instead of opposing the two ways of building dictionaries, they combine the two approaches through an ensemble of networks. Finally, the best performances are obtained when combining the HTLF, HTFL(field) and also OSM, all being built and declined with two CNN architectures (Inception-v4 and Inception-ResNet-v2).</p><p>LU, Lehigh University, USA, 9 runs [14]: these participants started from the fact that although many methods are proposed for domain adaptation, most of them are tested on small domain divergence datasets, which may have lower transferability to large-divergence datasets, and the data imbalance problem is not well addressed. To address these challenges, this participant proposes to extend the CORAL loss <ref type="bibr" target="#b15">[16]</ref> designed to align the distribution of the two domains with two contributions:</p><p>‚Ä¢ A weighted cross-entropy loss (optimized on the labeled samples and pseudo-labeled samples) allowing to take into account the imbalance distribution of the classes ‚Ä¢ A filtering of the used pseudo-labels to focus only on the ones with a sufficient degree of confidence. The confidence threshold decreases over time to integrate progressively more difficult test samples.</p><p>Unlike the approach developed by NeuonAI or the organizer's submissions (see below), these participants do not seem to have used external data, which may partially explain the difference in performance despite a promising and interesting approach. Moreover, we can notice that both Neuon and LU teams did not exploit in their approaches the new trait metadata introduced this year.</p><p>Organizer's submissions, 7 runs: the purpose of these submissions was to measure whether or not the functional trait metadata introduced this year could help improve the performance of a system initially exploiting only image data. The submissions are based on the "winning" solution from the previous year designed by Juan Villacis, a former student from the TEC Costa Rica and the Pl@ntNet team <ref type="bibr" target="#b16">[17]</ref>. The method uses a Few Shot Adversarial Domain Adaptation approach <ref type="bibr" target="#b17">[18]</ref> (FSADA) where the purpose is to learn a domain agnostic feature space while preserving the discriminative ability of the features for performing the species classification task. First, a ResNet50 is finetuned in the herbarium sheets only and used then as an encoder to extract features on both herbarium sheets or field photos. Then, given random pairs of extracted features, a discriminator is trained to distinguish 4 categories: (1) different domains and different classes, (2) different domains and same class, (3) same domain and different classes, (4) same domain and same classes. Finally, during a last stage, the encoder, the discriminator and the classifier are trained together. Domain adaptation is achieved once the discriminator is not able to distinguish samples from categories (1) and (2) and categories (3) and ( <ref type="formula">4</ref>), when the discriminator is not able to tell which was the original domain. The best single model was an extension with 3 classifiers and 3 discriminators using 3 taxonomic levels (species, genus, family), while using external datasets (PlantCLEF 2019 <ref type="bibr" target="#b9">[10]</ref> and GBIF <ref type="bibr" target="#b11">[12]</ref>). This previous best solution was retrained and again submitted this year as "Organizer's submission 3" (submissions 1 &amp; 2 didn't use the genus and family levels, and submission 1 didn't use external data). Following the same idea, the organizer's submissions 4, 5, 6 extended the submission 3 by introducing additional discriminators and classifiers related to the traits, respectively "plant lifeform" (10 classes), "woodiness" (2 classes), "plant growthform" (using actually in this specific case 4 independent discriminators and binary classifiers related to the 4 values "climber", "herb", "shrub", "tree"). Submission 7 used a total of 10 discriminators and classifiers exploiting the 3 taxonomic levels and traits mentioned just before.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Results</head><p>We report in Figure <ref type="figure" target="#fig_3">4</ref> and Table <ref type="table" target="#tab_1">2</ref> the performances achieved by the 29 evaluated runs. Figure <ref type="figure" target="#fig_4">5</ref> reorganizes the results according to the second MRR metric focusing on the most difficult species, while Figure <ref type="figure" target="#fig_5">6</ref> adds the organizer's submissions in the initial Figure <ref type="figure" target="#fig_3">4</ref>.</p><p>The main outcomes we can derive from that results are the following ones:  while the organizer's submissions used a GBIF collection <ref type="bibr" target="#b11">[12]</ref> and the PlantCLEF2019 dataset <ref type="bibr" target="#b9">[10]</ref>). The impact of external data can be highlighted when comparing runs 1 &amp; 2 from the organizers for instance where the MRR increases from 0.052 to 0.153. LU team used only used the relatively small number of field photos provided in the PlantCLEF2021 dataset, which may partially explain why their submissions have lower performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Genericity and stability.</head><p>Regarding the difference between the two MRR metrics (whole test set vs. difficult species), the NeuonAI team demonstrated that it is possible to achieve equivalent and quite good performance for all species, even those that have few or no field photos at all in the training dataset. This impressive genericity is mainly obtained by the use of an ensemble of several two-streamed Herbarium-Field Triplet Loss (HFTL) networks and several One-Streamed Mixed (OSM) networks. Rather than focusing on learning a common feature invariant domain as for the other team's submissions, the NeuonAI's approach focuses on a deep metric learning on features embeddings. For the ensemble, they combined through their submissions various combinations of (a) different CNN architectures (Inception-ResNet-v2 and Inception-V4), (b) whether or not to add to the herbarium pictures the field photos for the calculation of class embbedings, and (c) different levels of data augmentation. NeuonAI Run 7, which used 3 HTFL networks, all adding field photos for the class embbedings, and 2 OSM networks, achieved the best scores over the participants, for both MRR metrics. Looking solely at the the second MRR score, this approach seems to be more effective in transferring knowledge to the least frequently photographed species in the field, which was the most difficult goal to achieve.</p><p>Multi-task approaches have a positive impact on performance, especially when using the taxonomy genus, family and some of the species traits. By adding auxiliary tasks to the FSADA approach as mentioned in <ref type="bibr" target="#b16">[17]</ref>, the genus and family information help the discriminators and the classifiers to learn a better domain invariant feature space, and contribute to improve significantly the performance (see Organizer's submissions 2 &amp; 3 where the MRR increases from 0.153 to 0.183). Organizer's submissions 4, 5 and 6 extended this approach by adding an auxiliary task related to the trait species information. This appeared to also contribute to improve performance. All these auxiliary tasks based on traits contributed to improve the performances, even slightly as for the "woodiness" trait.</p><p>The most informative species trait is the "plant growth form". Organizer's submissions 4, 5 and 6 demonstrate that adding auxiliary tasks based on species traits improves performance. As hypothesised, it seems to help gathering and discriminating wide groups of plant species sharing similar visual aspects (such as tendrils for climber plants, typical large leaves for tropical trees against smaller leaves for shrubs or long thin leaves and frequent flowers for herbs). Finally, the last organizer's submission 7 combining a total of 8 auxiliary tasks resulted in the highest score for the primary MRR metric over the challenge, but half as good as the best NeuonAI's submission regarding the second MRR metric focusing on the very difficult species to identify.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Conclusion</head><p>This paper presented the overview and the results of the LifeCLEF 2021 plant identification challenge following the 10 previous editions conducted within CLEF evaluation forum. This year's task was particularly challenging, focusing on species rarely photographed in the field in the northern tropical Amazon. The results revealed that the last advances in domain adaptation enable the use of herbarium data to facilitate the identification of rare tropical species for which no or very few other training photos are available. A mapping domain adaptation technique based on a two-streamed Herbarium-Field triplet loss network reached an impressive genericity by obtaining quite high similar results regardless of whether the species have many or very few field photos in the training set. We believe that the proposed task may be in the future a new baseline dataset in the field of domain adaptation, and motivate new contributions through a realistic and crucial usage for the plant biology research community.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: An herbarium sheet and a field photo of the same individual plant (Unonopsis stipitata Diels).Despite the very different visual appearances between the two types of images such as light reflection and leaf color, the overall leaf shape, vein structure, and leaf insertion on the branch remain invariant in both domains.</figDesc><graphic coords="2,152.05,84.19,110.06,166.67" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Density grid maps by number of species of geolocated plant specimens in the PlantCLEF2021 dataset. Many species have also been collected in other regions outside French Guiana, over a large part of the Americas, but also in Africa for some of them.</figDesc><graphic coords="4,89.29,84.19,416.68,165.13" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Species according to the estimated number of images for each domain in the training set (in blue). Each species is surrounded by an additional orange circle if it is used in the test set, and a red circle if used in the test subset of difficult species (with few field photos according to the PlantCLEF 2021 the training set). The bottom graph revises the positions of the species by including additional training pictures from external datasets that could be used by the participants. It is estimated that most of the species related to the difficult test subset have less than 10 field photos.</figDesc><graphic coords="6,104.71,84.19,383.36,480.06" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: PlantCLEF 2021 evaluation results sorted by the primary evaluation metric, i.e. the Mean Reciprocal Rank over the entire test set.</figDesc><graphic coords="10,89.29,84.19,416.69,375.17" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: PlantCLEF 2021 evaluation results based on the secondary metric, i.e. the Mean Reciprocal Rank over the subset of difficult species with few or no field photos in the training set.</figDesc><graphic coords="12,89.29,84.19,416.69,293.61" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: PlantCLEF 2021 evaluation results sorted by the primary evaluation metric including the organizer's submissions.</figDesc><graphic coords="13,89.29,84.19,416.68,286.61" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1</head><label>1</label><figDesc>Details of the PlantCLEF 2021 dataset according to the origin of the pictures and their domain.</figDesc><table><row><cell>Origin</cell><cell>Domain</cell><cell cols="3">Used as #Pictures #Species</cell></row><row><cell cols="2">Herbier IRD de Guyane Herbarium sheets</cell><cell>Train</cell><cell>38,552</cell><cell>631</cell></row><row><cell>iDigBio</cell><cell>Herbarium sheets</cell><cell>Train</cell><cell>282,718</cell><cell>991</cell></row><row><cell>iDigBio</cell><cell>Field photos</cell><cell>Train</cell><cell>3,935</cell><cell>426</cell></row><row><cell>Fanchon</cell><cell>Field photos</cell><cell>Train</cell><cell>1,130</cell><cell>183</cell></row><row><cell>Molino</cell><cell>Field photos</cell><cell>Train</cell><cell>1,251</cell><cell>125</cell></row><row><cell>Fanchon</cell><cell>Field photos</cell><cell>Test</cell><cell>1,830</cell><cell>271</cell></row><row><cell>Molino</cell><cell>Field photos</cell><cell>Test</cell><cell>1,356</cell><cell>166</cell></row><row><cell>Train (all)</cell><cell>Herbarium sheets</cell><cell>Train</cell><cell>321,270</cell><cell>997</cell></row><row><cell>Train (all)</cell><cell>Field photos</cell><cell>Train</cell><cell>6,316</cell><cell>502</cell></row><row><cell>Test (all)</cell><cell>Field photos</cell><cell>Test</cell><cell>3,186</cell><cell>408</cell></row><row><cell cols="2">1. Datasets and task description</cell><cell></cell><cell></cell><cell></cell></row><row><cell>1.1. Training set</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note><p>1.1.1. Visual content</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2</head><label>2</label><figDesc>Results of the LifeCLEF 2021 Plant Identification Task Traditional classification models based on CNNs perform very poorly on the task. Domain Adaptation methods (DA) based on CNNs perform much better but the task remains difficult even with these dedicated techniques. The best submitted run barely approaches a MRR of 0.2.</figDesc><table><row><cell>Team run</cell><cell cols="2">MRR (whole test set) MRR (difficult species)</cell></row><row><cell>Neuon AI Run 7</cell><cell>0.181</cell><cell>0.158</cell></row><row><cell>Neuon AI Run 10</cell><cell>0.176</cell><cell>0.153</cell></row><row><cell>Neuon AI Run 8</cell><cell>0.169</cell><cell>0.15</cell></row><row><cell>Neuon AI Run 2</cell><cell>0.152</cell><cell>0.117</cell></row><row><cell>Neuon AI Run 9</cell><cell>0.147</cell><cell>0.129</cell></row><row><cell>Neuon AI Run 6</cell><cell>0.143</cell><cell>0.126</cell></row><row><cell>Neuon AI Run 5</cell><cell>0.137</cell><cell>0.116</cell></row><row><cell>Neuon AI Run 4</cell><cell>0.088</cell><cell>0.073</cell></row><row><cell>Neuon AI Run 1</cell><cell>0.071</cell><cell>0.066</cell></row><row><cell>LU Run 9</cell><cell>0.065</cell><cell>0.037</cell></row><row><cell>Domain Run 8</cell><cell>0.065</cell><cell>0.037</cell></row><row><cell>LU Run 8</cell><cell>0.065</cell><cell>0.037</cell></row><row><cell>LU Run 7</cell><cell>0.063</cell><cell>0.04</cell></row><row><cell>Domain Run 4</cell><cell>0.063</cell><cell>0.046</cell></row><row><cell>Neuon AI Run 3</cell><cell>0.06</cell><cell>0.056</cell></row><row><cell>Domain Run 6</cell><cell>0.06</cell><cell>0.039</cell></row><row><cell>LU Run 6</cell><cell>0.057</cell><cell>0.042</cell></row><row><cell>To Be Run 2</cell><cell>0.056</cell><cell>0.038</cell></row><row><cell>LU Run 4</cell><cell>0.051</cell><cell>0.031</cell></row><row><cell>LU Run 3</cell><cell>0.05</cell><cell>0.026</cell></row><row><cell>To Be Run 1</cell><cell>0.045</cell><cell>0.022</cell></row><row><cell>Domain Run 5</cell><cell>0.038</cell><cell>0.011</cell></row><row><cell>LU Run 5</cell><cell>0.037</cell><cell>0.022</cell></row><row><cell>LU Run 1</cell><cell>0.036</cell><cell>0.009</cell></row><row><cell>LU Run 2</cell><cell>0.034</cell><cell>0.013</cell></row><row><cell>Domain Run 3</cell><cell>0.031</cell><cell>0.015</cell></row><row><cell>Domain Run 1</cell><cell>0.019</cell><cell>0.009</cell></row><row><cell>Domain Run 2</cell><cell>0.018</cell><cell>0.009</cell></row><row><cell>Domain Run 7</cell><cell>0.006</cell><cell>0.003</cell></row><row><cell>Organizer's submission 7</cell><cell>0.198</cell><cell>0.093</cell></row><row><cell>Organizer's submission 6</cell><cell>0.192</cell><cell>0.091</cell></row><row><cell>Organizer's submission 4</cell><cell>0.188</cell><cell>0.073</cell></row><row><cell>Organizer's submission 5</cell><cell>0.184</cell><cell>0.077</cell></row><row><cell>Organizer's submission 3</cell><cell>0.183</cell><cell>0.073</cell></row><row><cell>Organizer's submission 2</cell><cell>0.153</cell><cell>0.056</cell></row><row><cell>Organizer's submission 1</cell><cell>0.052</cell><cell>0.042</cell></row><row><cell cols="3">The most difficult PlantCLEF challenge ever. External data improves DA approaches. The best submissions from NeuonAI and the or-</cell></row><row><cell cols="3">ganizers used both complementary external data (the PlantCLEF2017 dataset [8] for NeuonAI</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_0"><p>https://scholar.google.fr/citations?user=xZXYc4kAAAAJ&amp;hl=fr</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_1"><p>https://www.aicrowd.com/challenges/lifeclef-2021-plant</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgments</head><p>This project has received funding from the <rs type="funder">French National Research Agency</rs> under the <rs type="programName">Investments for the Future Program</rs>, referred as <rs type="grantNumber">ANR-16-CONV-0004</rs> and from the <rs type="funder">European Union</rs>'s <rs type="programName">Horizon 2020 research and innovation program</rs> under grant agreement No <rs type="grantNumber">863463</rs> (<rs type="projectName">Cos4Cloud</rs> project). This work was supported in part by the <rs type="programName">Microsoft AI for Earth program</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_3JgrWtp">
					<idno type="grant-number">ANR-16-CONV-0004</idno>
					<orgName type="program" subtype="full">Investments for the Future Program</orgName>
				</org>
				<org type="funded-project" xml:id="_ZGnxxhu">
					<idno type="grant-number">863463</idno>
					<orgName type="project" subtype="full">Cos4Cloud</orgName>
					<orgName type="program" subtype="full">Horizon 2020 research and innovation program</orgName>
				</org>
				<org type="funding" xml:id="_Qm8fcun">
					<orgName type="program" subtype="full">Microsoft AI for Earth program</orgName>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Overview of lifeclef 2018: a large-scale evaluation of species identification and recommendation algorithms in the era of ai</title>
		<author>
			<persName><forename type="first">A</forename><surname>Joly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Go√´au</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Botella</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Glotin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Bonnet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W.-P</forename><surname>Vellinga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>M√ºller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">LNCS of Experimental IR Meets Multilinguality, Multimodality, and Interaction</title>
		<editor>
			<persName><forename type="first">G</forename><forename type="middle">J</forename><surname>Jones</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Lawless</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Gonzalo</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Kelly</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Goeuriot</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename><surname>Mandl</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Cappellato</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<meeting><address><addrLine>Avigon, France</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note>CLEF: Cross-Language Evaluation Forum for European Languages</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">The imageclef 2011 plant images classification task</title>
		<author>
			<persName><forename type="first">H</forename><surname>Go√´au</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Bonnet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Joly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Boujemaa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Barth√©l√©my</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-F</forename><surname>Molino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Birnbaum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Mouysset</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Picard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CLEF: Conference and Labs of the Evaluation Forum</title>
		<meeting><address><addrLine>Amsterdam, Netherlands</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011-09">Sep. 2011. 2011</date>
		</imprint>
	</monogr>
	<note>CLEF task overview 2011</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Imageclef2012 plant images identification task</title>
		<author>
			<persName><forename type="first">H</forename><surname>Go√´au</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Bonnet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Joly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Yahiaoui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Barth√©l√©my</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Boujemaa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-F</forename><surname>Molino</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CLEF: Conference and Labs of the Evaluation Forum</title>
		<meeting><address><addrLine>Rome, Italy; Rome</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012-09">Sep. 2012. 2012</date>
		</imprint>
	</monogr>
	<note>CLEF task overview 2012</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">The imageclef 2013 plant identification task</title>
		<author>
			<persName><forename type="first">H</forename><surname>Go√´au</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Bonnet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Joly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Bakic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Barth√©l√©my</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Boujemaa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-F</forename><surname>Molino</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CLEF: Conference and Labs of the Evaluation Forum</title>
		<meeting><address><addrLine>Valencia, Spain; Valencia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013-09">Sep. 2013. 2013</date>
		</imprint>
	</monogr>
	<note>CLEF task overview 2013</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">The lifeclef 2014 plant images identification task</title>
		<author>
			<persName><forename type="first">H</forename><surname>Go√´au</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Joly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Bonnet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Selmi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-F</forename><surname>Molino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Barth√©l√©my</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Boujemaa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CLEF: Conference and Labs of the Evaluation Forum</title>
		<meeting><address><addrLine>Sheffield, United Kingdom., Sheffield, UK</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014-09">Sep. 2014. 2014</date>
		</imprint>
	</monogr>
	<note>CLEF task overview 2014</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Lifeclef plant identification task</title>
		<author>
			<persName><forename type="first">H</forename><surname>Go√´au</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Joly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Bonnet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CLEF: Conference and Labs of the Evaluation Forum</title>
		<meeting><address><addrLine>Toulouse, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015-09">2015. Sep. 2015. 2015</date>
		</imprint>
	</monogr>
	<note>CLEF task overview 2015</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Plant identification in an open-world (lifeclef 2016)</title>
		<author>
			<persName><forename type="first">H</forename><surname>Go√´au</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Bonnet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Joly</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CLEF: Conference and Labs of the Evaluation Forum</title>
		<meeting><address><addrLine>√âvora, Portugal</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016-09">Sep. 2016. 2016</date>
		</imprint>
	</monogr>
	<note>CLEF task overview 2016</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Plant identification based on noisy web data: the amazing performance of deep learning (lifeclef 2017)</title>
		<author>
			<persName><forename type="first">H</forename><surname>Go√´au</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Bonnet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Joly</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CLEF: Conference and Labs of the Evaluation Forum</title>
		<meeting><address><addrLine>Dublin, Ireland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017-09">Sep. 2017. 2017</date>
		</imprint>
	</monogr>
	<note>CLEF task overview 2017</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Overview of expertlifeclef 2018: how far automated identification systems are from the best experts ?</title>
		<author>
			<persName><forename type="first">H</forename><surname>Go√´au</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Bonnet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Joly</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CLEF: Conference and Labs of the Evaluation Forum</title>
		<meeting><address><addrLine>Avignon, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018-09">Sep. 2018. 2018</date>
		</imprint>
	</monogr>
	<note>CLEF task overview 2018</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Overview of lifeclef plant identification task 2019: diving into data deficient tropical countries</title>
		<author>
			<persName><forename type="first">H</forename><surname>Go√´au</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Bonnet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Joly</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CLEF: Conference and Labs of the Evaluation Forum</title>
		<meeting><address><addrLine>Lugano, Switzerland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019-09">Sep. 2019. 2019</date>
		</imprint>
	</monogr>
	<note>CLEF task overview 2019</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Marie-fran√ßoise pr√©vost &quot;fanchon</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">G</forename><surname>Delprete</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Feuillet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Taxon</title>
		<imprint>
			<biblScope unit="volume">62</biblScope>
			<biblScope unit="page" from="419" to="419" />
			<date type="published" when="1941">1941-2013. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Recognition of the amazonian flora by inception networks with test-time class prior estimation</title>
		<author>
			<persName><forename type="first">L</forename><surname>Picek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sulc</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Matas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CLEF: Conference and Labs of the Evaluation Forum</title>
		<meeting><address><addrLine>Lugano, Switzerland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019-09">Sep. 2019. 2019</date>
		</imprint>
	</monogr>
	<note>CLEF working notes 2019</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Improved herbarium-field triplet network for cross-domain plant identification: Neuon submission to lifeclef 2021 plant</title>
		<author>
			<persName><forename type="first">S</forename><surname>Chulif</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">L</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Working Notes of CLEF 2021 -Conference and Labs of the Evaluation Forum</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Weighted pseudo labeling refinement for plant identification</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">D D</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Working Notes of CLEF 2021 -Conference and Labs of the Evaluation Forum</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Herbarium-field triplets network for cross-domain plant identification -neuon submission to lifeclef 2020 plant</title>
		<author>
			<persName><forename type="first">S</forename><surname>Chulif</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">L</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CLEF: Conference and Labs of the Evaluation Forum</title>
		<meeting><address><addrLine>Thessaloniki, Greece</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020-09">Sep. 2020. 2020</date>
		</imprint>
	</monogr>
	<note>CLEF working notes 2020</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Deep coral: Correlation alignment for deep domain adaptation</title>
		<author>
			<persName><forename type="first">B</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Saenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European conference on computer vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="443" to="450" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Domain adaptation in the context of herbarium collections: a submission to plantclef 2020</title>
		<author>
			<persName><forename type="first">J</forename><surname>Villacis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Go√´au</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Bonnet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Mata-Montero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Joly</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CLEF: Conference and Labs of the Evaluation Forum</title>
		<meeting><address><addrLine>Thessaloniki, Greece</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020-09">Sep. 2020. 2020</date>
		</imprint>
	</monogr>
	<note>CLEF working notes 2020</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Few-shot adversarial domain adaptation</title>
		<author>
			<persName><forename type="first">S</forename><surname>Motiian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Iranmanesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Doretto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="6670" to="6680" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
