<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Efficiently identifying disguised nulls in heterogeneous text data</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Th√©o</forename><surname>Bouganim</surname></persName>
							<email>theo.bouganim@inria.fr</email>
						</author>
						<author>
							<persName><forename type="first">Helena</forename><surname>Galhardas</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">INESC-ID &amp; IST</orgName>
								<orgName type="institution">Univ. Lisboa</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Ioana</forename><surname>Manolescu</surname></persName>
							<email>ioana.manolescu@inria.fr</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Inria &amp; IPP</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Efficiently identifying disguised nulls in heterogeneous text data</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">55F8C064B43D1E6B9943C9F77BE17A0A</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-04-12T14:43+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Digital data is produced in many data models, ranging from highly structured (typically relational) to semi-structured models (XML, JSON) to various graph formats (RDF, property graphs) or text. Most real-world datasets contain a certain amount of null values, denoting missing, unknown or unapplicable information. While some data models allow representing nulls by special tokens, socalled disguised nulls are also frequently encountered: these are values that are not syntactically speaking nulls, but which do, nevertheless, denote the absence, unavailability or unapplicability of the information.</p><p>This paper describes our ongoing work toward detecting disguised nulls in textual data, encountered in ConnectionLens graphs. Driven by journalistic applications, we focus for now on large, semistructured datasets, where most or all data values are freeform text. We show that the state-of-the-art methods for detecting nulls in relational databases, mostly tailored towards numerical data, do not detect disguised nulls efficiently on such data. Then, we present two alternative methods: (i) leveraging Information Extraction, and (ii) text embeddings and classification. We detail their performance-precision trade-offs on real-world datasets.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Digital data is being produced and reused at unprecedented rates. Large datasets are usually processed within data management systems, which model the data according to a given data model, provide means to store it, and to query it using a declarative query language or another form of query API. The database industry has been pioneered by relational database management systems (RDBMSs), whose foundations lay in first-order logic, formalization by E. F. Codd <ref type="bibr" target="#b10">[11]</ref> and subsequent work, e.g., <ref type="bibr" target="#b1">[2]</ref>.</p><p>Where there is data, there are null values Since the early database days, nulls have been identified as a central concept denoting missing, unknown or unapplicable information. The semi-structured data model, first embodied in OEM (the Object Exchange Model) allowed to hope the need for nulls would disappear: missing information is simply not represented at all in the data <ref type="bibr" target="#b14">[15]</ref>. However, standard semi-structured models such as XML and JSON re-introduced, e.g., xsi:nil in tools supporting XML Schema or the special null value in JSON. Presumably, such null tokens were felt needed in practice because "perfect and complete" databases, regardless of their data model, are the exception rather than the norm. At query time, null values are typically handled through the so-called three value logic: a predicate over a null value always evaluates to unknown (neither true nor false), and query results only include tuples on which the query predicates evaluated to true.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Disguised nulls in relational databases</head><p>In practice, it has been noted that relational databases often feature not only null tokens, but also non-null values playing the semantic role of nulls, also called disguised nulls <ref type="bibr" target="#b0">[1]</ref>. For instance, the birth department of all French residents born out of France is coded 99 in public databases such as the Social Security one; 0 or -1 are often used to encode an unknown (but non-zero) number such as a price or a number of items sold; users may enter "none, "-", "unknown" or "N/A" or any other similar phrase or token, in entry forms requiring numbers, names or dates that they are unable or unwilling to fill in. Further, when a value needs to be chosen from a predefined set, such as a state of the U.S., users may forget to set it from the menu, leaving the default value which just happens to be the first, e.g., "Alabama" in a form requiring users to select a state of the USA.</p><p>Data entry forms sometimes prevent null codes by checking the entered value, e.g., "N/A" would not be accepted as a number. However, null codes may still persist: (ùëñ) users replace "N/A" with 0 for an unknown, non-zero number; (ùëñùëñ) if the expected input type is free text, e.g., "List of industrial collaborations in connection with this research", no simple format-driven validation applies; (ùëñùëñùëñ) in cases such as "Alabama" above, the value is in the correct domain.</p><p>Detecting disguised nulls As explained above, null values require special treatment when querying data; this treatment is built in data management systems when the nulls are explicit. However, disguised nulls require dedicated detection methods, and several methods have been proposed for relational databases <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b20">21]</ref>. These methods are based on statistical analysis of the data. They can detect, for instance, when a value such as 0 is suspiciously frequent in a numeric attribute, or when a value of attribute ùëÖ.ùëé is an outlier in the joint distribution of (ùëÖ.ùëé, ùëÖ.ùëè), where we expect the distributions ùëÖ.ùëé, ùëÖ.ùëè to be independent. Detecting disguised nulls is important for data cleaning (users may want to replace them with explicit nulls), and for query correctness: null values should not match any selection predicate, and there should be no join on null values.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Problem statement and outline</head><p>In this work, we consider the detection of disguised nulls in textual, heterogeneous data. The motivation for our work came from ConnectionLens <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b9">10]</ref>, a system capable of integrating structured, semistructured or unstructured data into graphs, which are enriched by adding all the entities (people, organizations, places, URIs, dates etc.) encountered in various text nodes. We have developed ConnectionLens inspired by fact-checking and data journalism applications <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b7">8]</ref>. We encountered many datasets where some fields are free-form text entered by users. For instance, in the French Transparency dataset HATVP, elected officials need to state "their direct financial participation in company capitals"; in the PubMed bibliographic database, free-form texts include the article titles, abstracts, funding statements, and possible acknowledgments. Disguised nulls encountered in such fields range from "N/A" or "-" to "Liz Smith has not received any funding related to this work" or "No conflicts of interest, financial, or otherwise are declared by the authors. " or "There is no conflict of interest relating to Authors. The manuscript was prepared according to scientific and ethical rules." (in this case, the financial acknowledgment question does not apply to the authors). Detecting disguised nulls in ConnectionLens graphs is important:</p><p>(1) First, it allows to avoid unifying nodes with identical or similar labels <ref type="bibr" target="#b4">[5]</ref> if these are disguised nulls, e.g., if two companies are described as having "Unknown" CEO, this should not lead to a connection between the two companies through the node labeled "Unknown"; this can be seen as the graph counterpart of the fact that null values should not join in relational databases. (2) Second, if we know that a string is a disguised null, we can avoid extracting entities from it; this is potentially useful, because entity extraction dominates by far the cost of constructing ConnectionLens graphs <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b5">6]</ref>.</p><p>How to detect such disguised nulls? We describe below alternative methods and simultaneously the structure of the paper.</p><p>(1) We first show that ConnectionLens entity extraction can be leveraged to (manually) establish an entity profile for each set of text attributes in which we want to detect nulls, and consider any value deviating from this profile a disguised null. For instance, the entity profile of financial participation descriptions could be Organization+ to state that it should contain at least one organization, whereas the entity profile of a funding statement could be Person+ Organization+: in a funding acknowledgement, at least an author name and at least a funding organization should appear. This method is quite accurate, however, it incurs a high computational cost, since entity extraction is a complex operation (Section 4). (2) To address this shortcoming, we devised a novel method, which relies on text embeddings and classification, while also leveraging entity extraction on a much smaller portion of the dataset. (3) We demonstrate that this method is much more efficient than the one based on entity profiles, while also being very accurate (Section 5). We perform a set of experiments on the state of the art (FAHES) mostly aimed at numeric data. Our experiments show that they do not perform very well on free texts values and less structured data (Section 6.3).</p><p>We show the impact of our work on the time needed to build a ConnectionLens graph before concluding and providing some perspectives.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head><p>In this section, we recall the main methods for disguised null detection in relational database. To our knowledge, no similar methods have been studied for semi-structured nor graph data. Foundational work in this area was made in <ref type="bibr" target="#b19">[20]</ref>, which introduced and formalized the problem of Disguised Missing Values (DMV), and measured its influence on different data science models. A set of statistical models (mutually disjoint hypothesis) were introduced in <ref type="bibr" target="#b18">[19]</ref> on the existence of missing values (explicit or disguised nulls):</p><p>‚Ä¢ The MCAR (Missing Completely At Random) model posits that the probability of a value to be missing is the same for any value of an attribute, and does not depend on the values of any other attribute. For instance, assuming an attribute is the result of a physical measure made with a device that breaks down, the resulting missing values are not correlated to any other aspect of the data or of the values. ‚Ä¢ The MAR (Missing At Random) model considers that the probability for a value to be missing depends on values encountered in other attributes of the same table (these notions have been defined for tables). For example, in a political poll, let assume young voters are more likely not to declare their political preference. Then, the political preference value is MAR.</p><p>‚Ä¢ MNAR (Missing Not At Random) applies when neither MAR nor MCAR hold, and when the probability for a value to be missing does depend on the actual value that is missing, but not on the values of any other attribute. For instance, assuming supporters of a certain political party generally avoid stating their preference and instead let that information go missing, such values are MNAR.</p><p>Building upon these models, <ref type="bibr" target="#b16">[17]</ref> has proposed a heuristic method for identifying DMVs in relational databases. Under the MAR and MCAR assumptions, the authors assume that a value ùë£ in attribute</p><formula xml:id="formula_0">ùê¥ ùëñ in a table ùëá is a DMV if ùúé ùê¥ ùëñ =ùë£ (ùëá ) contains a subset ùëá *</formula><p>ùê¥ ùëñ =ùë£ that represents a good sampling of ùëá . Such a subset is an Embedded Unbiased Sample (EUS) which means that except for attribute ùê¥ ùëñ , ùëá * ùê¥ ùëñ =ùë£ and ùëá have similar distributions. Then, a MEUS (Maximal EUS) is intuitively an EUS with a good trade-off between size (larger is better) and similarity (in distribution) with ùëá . largest EUS with the highest similarity. The gist of the <ref type="bibr" target="#b16">[17]</ref> heuristics is to find MEUS in a dataset, and consider their associated ùê¥ ùëñ = ùë£ values as DMVs. FAHES <ref type="bibr" target="#b20">[21]</ref> incorporates the method of <ref type="bibr" target="#b16">[17]</ref>, to which the authors add two other methods, in order to distinguish three classes of DMV.</p><p>‚Ä¢ The first class contains syntactic outliers. A syntactic outlier is a value whose syntax is significantly different from that of other values in the same attribute. Two techniques are used to identify them. (ùëñ) Syntactic pattern discovery infers a frequent syntactic pattern (shape) for the values of each attribute, and points out the values that do not fit the pattern as syntactic outliers. For example, if the attribute is "blood type", the recognized pattern could be one or two uppercase letters followed by a + or a -sign; then, "ABO" would be considered a syntactic outlier. (ùëñùëñ) Repeated Pattern Identification singles out values that contain repeated patterns, such as 0101010101 in a 10-digit phone number, or "blablabla" in a text attribute. ‚Ä¢ Second, in numerical attributes, statistical outliers can be found by leveraging common outlier detection methods <ref type="bibr" target="#b15">[16]</ref>. This allows to identify as DMVs, numerical values that do not fit the extent of the other values, e.g., negative values in a distance attribute. ‚Ä¢ Finally, some inlier DMVs, called Random DMVs in <ref type="bibr" target="#b20">[21]</ref> can be identified. These are legal attribute values, which do not stand out as outliers; they are the hardest to find even for an application domain specialist. The "Alabama" example from Section 1 is a typical example. Inlier DMVs are detected in <ref type="bibr" target="#b20">[21]</ref> under the MAR and MCAR hypotheses; the authors state that detecting DMVs under the NMAR model is hard to impossible. The intuition being exploited is that DMVs are frequent values (because the lack of information is assumed to occur more frequently than an actual, correct value). Thus, one must find amongst the most frequent values, those which are DMVs. To this purpose, each frequent value is successively replaced by an actual null. If, by doing this, the (original and introduced) null values follow the MAR or MCAR models, then we consider that value as a good DMV candidate. Then, the MEUS method from <ref type="bibr" target="#b16">[17]</ref> is applied to each candidate to detect the DMVs.</p><p>The FAHES team has developed a tool using these methods to detect all three types of DMV in a relational database.</p><p>Finding disguised nulls is one among the many problems raised by poor data quality, problems which have been traditionally addressed through data cleaning. Data quality raises many real problems, which to this day still needs solutions, Traditional approaches for data cleaning were rule-base <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b21">22]</ref>. Newer techniques are now based on machine learning approaches, e.g., <ref type="bibr" target="#b17">[18]</ref>. Our work is part of this effort to improve data quality. Disguised null detection can be seen as a data cleaning task; it is also related to data profiling <ref type="bibr" target="#b0">[1]</ref>, since DMV detection also allows to characterize a certain attribute (set of nodes) by the percentage of their values which are disguised nulls.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">MOTIVATING EXAMPLE</head><p>We loaded 400.000 PubMed bibliographic notices in a Connec-tionLens graph, out of which we extracted (paper ID, conflict of interest statement) pairs. These CoI statements cover any kind of benefits (funding, personal fees etc.) that authors report with various organizations such as companies, foundations etc.</p><p>In Figure <ref type="figure" target="#fig_0">1</ref>, "Dr. Alice consults for ABCPharma" (in the upper left) is such a conflict of interest, part of the XML bibliographic notice; "Dr. Alice thanks HealthStar... this article" (at the top right) is another one. PubMed data originates from various biomedical journals. Some do not provide CoI information; in this case, the CoI is an empty string. Others provide a default disguised null value, e.g., "The authors report no conflict". Finally, some journals only allow free text, leading to a large variety of disguised nulls.</p><p>ConnectionLens extracts named entities from all text nodes, regardless of the data source they come from, using trained language models. In the figure, blue, green, and orange nodes denote Organization, Location, and Person entities, respectively. Each entity node is connected to the text node it has been extracted from, by an extraction edge, which also records the confidence (between 0 and1) of the extractor. Finally, nodes are compared to find that some may be equivalent (solid red edges) or similar(dashed red edges).The original motivation of this work was to avoid connecting, by such equivalence or similarity edges, two identical or similar values,if one of them is a disguised null, since this would lead to paths in the graph that have no meaning.</p><p>Furthermore, extracting entities is really time consuming and with disguised null values, we are extracting entities over values we cannot exploit, thus losing time unnecessarily.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">DETECTING DISGUISED NULLS WITH ENTITY PROFILES</head><p>ConnectionLens <ref type="bibr" target="#b4">[5]</ref><ref type="bibr" target="#b5">[6]</ref><ref type="bibr" target="#b6">[7]</ref><ref type="bibr" target="#b9">10]</ref> integrates heterogeneous data into a graph. Figure <ref type="figure" target="#fig_0">1</ref> (reused from <ref type="bibr" target="#b4">[5]</ref>) illustrates this in a data journalism scenario proposed by investigative journalists with whom we collaborate: we integrate four datasets (delimited by gray areas) in order to build a comprehensive database of information about conflicts of interest in the biomedical domain. In this example, we use a PubMed XML bibliographic notice, the corresponding medical article (in PDF) transformed into a JSON document, an RDF fragment from Wikidata, and an HTML page such as those set up by journalists on TobaccoTactics, DesmogBlog etc., to share information about organizations such as industry lobby groups.</p><p>After inspecting DS3 and trying to find what distinguishes an actual conflict of interest (CoI, in short) from a disguised null, we made the following observation. An actual CoI (such as those involving Alice in Figure <ref type="figure" target="#fig_0">1</ref>) is either of the form "Researcher A was funded by B", or of the form "The authors acknowledge funding from C". Thus, a person name may be present (in other cases, we just find "The authors"), but an organization is always involved. Thus, we can say that the entity profile of a CoI is: it must contain at least an organization.</p><p>This leads to the following disguised null detection method:</p><p>‚Ä¢ Extract all named entities from the CoI strings (through regular ConnectionLens data ingestion); ‚Ä¢ Declare those CoI strings in which no Organization entity was found, as disguised nulls.</p><p>The accuracy of this method is exactly that of the entity extractor; it has been shown in <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b3">4]</ref> (for English) and in <ref type="bibr" target="#b4">[5]</ref> (for French) that the accuracy is quite high. Its drawback is that extracting entities from all CoI strings is very lengthy. This motivates the search for a faster technique, which, on one hand, could identify the DMVs, while at the same time also reducing the entity extraction (thus, the actual ConnectionLens graph creation) time.</p><p>In practice, of course, we only extract entities once from each distinct string. It turns out that DS3 had a high number of duplicates (especially some very popular disguised nulls). Removing duplicates from DS3 leads to a new dataset we denote DDS3, consisting of 82.388 values. We use this de-duplicated dataset for the DMV detection methods described below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">DISGUISED NULL DETECTION THROUGH EMBEDDING AND CLASSIFICATION</head><p>With entity extraction, we have a good method to detect disguised nulls. However, this method is very time-consuming, so we need to find a faster method.</p><p>Our initial approach has been to cluster the values, in order to obtain DMV cluster(s) separated from non-DMV clusters. In particular, we experimented with the K-means <ref type="bibr" target="#b15">[16]</ref> algorithm, setting the number of clusters to 10. We could indeed see that DMVs "mostly" clustered together, but the separation was not very good.</p><p>Thus, we looked for an alternative method. Our idea is: we could extract entities from a small part of the data, then train a Machine Learning model to recognize DMVs (based on the method from the previous section), and finally use this model to predict whether a yet-unseen value is a DMV or not.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Textual data representation</head><p>To classify our string (text) values, we needed to represent them as multi-dimensional numeric vectors. First, we apply a set of common text pre-processing: suppressing punctuation, normalization and stemming.</p><p>Then, we need to project the pre-processed texts in a multidimensional space. Many techniques can be used for this purpose. Transformers like BERT <ref type="bibr" target="#b11">[12]</ref> have been proven really efficient for many Natural Language Programming (NLP). However, experimenting with BERT and similar tools has shown that obtaining a sentence embedding <ref type="bibr" target="#b22">[23]</ref> is time-consuming, which does not suit our time saving objective.</p><p>Instead, we opted for the well-known TF-IDF (Term-Frequency -Inverse-Document-Frequency) representation, commonly used in Natural Language Processing. TF-IDF weights term frequencies in each document according to the frequency of the term across the corpus. Intuitively, TF denotes that if a word occurs many times in a document, its relevance should be boosted as it must be more meaningful as it appears frequently. Conversely, IDF stands for the fact that if the word appears frequently in many documents, then it is just a frequent word and its relevance should be decreased. We finally keep only the top 20.000 terms with highest TF-IDF score to reduce dimensions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Classification model</head><p>To classify texts as DMVs or non-DMVs, we decided to rely on a Random Forests classifier <ref type="bibr" target="#b8">[9]</ref>. These classifiers are not the fastest, but they are quite efficient over complex data. Other classifiers might work as well; our goal here is to investigate whether the above approach, which trains the classifier on extraction results, can provide a more efficient DMV detection method, by avoiding to extract entities from a certain part of the input.</p><p>As we show in Section 6.5, this is indeed the case; even for small training set sizes (that is, even if entities are fully extracted only from a small part of the data), the classifier learns to predict quite accurately DMVs, while sparing significant entity extraction time. (1) Correctly detected statistical outliers, e.g.: In a human heights attribute, a height of 3 meters. (2) Wrongly detected statistical outliers, e.g.: In a dataset containing salaries of the employees of a company, if the CEO salary is 10 times higher than any of his employees, this could be wrongly detect as a DMV. (3) Correctly detected syntactic ouliers, e.g.: In a blood type attribute, the value 'ABO'. (4) Wrongly detected syntactic outlier, e.g.: In a name attribute, Fran√ßois-No√´l which is a composed name is detected as syntactic outlier because of the '-', whereas it is a valid name. (5) Correctly detected Random DMVs, e.g.: A default value such as Alabama for a state, detected thanks to the MEUS technique. (6) A DMV can be at the same time a syntactic outlier, a random DMV and a statistical outlier, e.g., a default distance value of -1. (7) Wrongly detected random DMVs. In a poll where we ask for favourite colors, blue might come really often. Lacking correlation with other attributes, blue could be wrongly detected as a random DMV. (8) Correctly detected DMV with entity profile technique, e.g.:</p><p>In a conflict of interest paragraph : "The authors report no conflict of interest. " (9) Wrongly detected DMV with entity profile technique. These are errors of the entity extractor when it misses an organization. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">EXPERIMENTAL EVALUATION</head><p>We now describe performance-oriented experiments with the disguised null detection techniques described above.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Datasets</head><p>To conduct our experiments, we have built three ConnectionLens graphs out of real-world datasets:</p><p>(1) We have loaded the most complete HATVP XML transparency dataset (35MB), with data about 270.000 people, in a ConnectionLens graph. From this, we extracted the montant (monetary amount) fields which appeared to contain many disguised nulls<ref type="foot" target="#foot_0">1</ref> . (2) We loaded a smaller HATVP CSV dataset (2.1 MB), containing information about 9.000 people; this dataset is relationallooking, which simplifies processing it through FAHES. (3) We loaded 400.000 PubMed bibliographic notices in a graph, out of which we extracted (paper ID, conflict of interest statement) pairs. These CoI statements cover any kind of benefits (funding, personal fees etc.) that authors report with various organizations such as companies, foundations etc. In Figure <ref type="figure" target="#fig_0">1</ref>, "Dr. Alice consults for ABCPharma" (in the upper left) is such a conflict of interest, part of the XML bibliographic notice; "Dr. Alice thanks HealthStar... this article" (at the top right) is another one. PubMed data originates from various medical journals. Some do not provide CoI information; in this case, the CoI is an empty string. Others provide a default disguised null value, e.g., "The authors report no conflict". Finally, some journals only allow free text, leading to a large variety of disguised nulls. We will denote these datasets DS1, DS2 and DS3, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Settings</head><p>All experiments were performed on a MacBook Pro 16 inches from 2019, with a 2.4 GHz Intel Core i9 8-core processor and 32 GB 2667 MHz DDR4 memory. We used ConnectionLens<ref type="foot" target="#foot_1">2</ref> to build the graphs, including in particular the extraction of named entities using Flair <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b3">4]</ref>, which we had retrained for French <ref type="bibr" target="#b6">[7]</ref>. Connec-tionLens graphs are stored in Postgres 9.6; experiment code was written in Python 3.6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Null detection through FAHES</head><p>We have appplied FAHES <ref type="bibr" target="#b20">[21]</ref> on the three datasets described previously. Next we will comment on the results obtained by the null detection through FAHES. DS2 seems to include no other disguised nulls.</p><p>Results on DS3 Out of the 400.000 values, FAHES correctly identified The authors have declared that no competing interests exist (31.891 occurrences) as a Random DMV. However, visual inspection exhibited many other disguised nulls (we will revisit this below). FA-HES fails to find them because freely written texts rarely coincide, thus FAHES' statistical approach based on value frequencies considers many disguised nulls rare (thus non-null), which is wrong.</p><p>Experiment conclusion FAHES <ref type="bibr" target="#b20">[21]</ref> performs quite well with numbers but is less convincing when it handles textual data. Indeed, DMVs detected as Syntactic outliers are often false positives. With a bit of domain knowledge it is possible to manually discard these DMVs, however, it shows the limits of the methods used to detect DMVs as syntactic outliers. FAHES has also shown its limitations by missing many DMVs on long free text data, which shows the need of new methods to treat these cases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4">Disguised null detection through entity profiles</head><p>To measure performances of the entity profiles technique, we performed 5 experiments with respectively the 500, 5.000, 10.000, 15.000 and 20.000 first values of dataset DDS3 (introduced at the end of Section 4). The objective here is to measure the extraction time as a function of the input size; this gives an indication of the time needed to extract disguised nulls using the Entity Profile </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.5">Disguised null detection through embedding and classification</head><p>The most common training-test split method consists on separating the dataset with 20% used for training and 80% for testing. We know that in our case, the most time-consuming operation is to label the training set with the entity extraction technique. To gain time, we want thus to reduce the training set.</p><p>To evaluate the impact of the training set size on the performance of the model used to detect disguised nulls over DDS3, we have performed 3 experiments. We trained models with respectively 20% (16477 values), 10% (8238 values) and 1% (823 values) of the dataset and report the comparison of the performances of each model in Table <ref type="table" target="#tab_1">2</ref>. In this table, the precision, recall (and thus also F1) are computed using the result of the entity profile method (Section 4) as gold standard; as we have seen, it is a time-consuming technique. Table <ref type="table" target="#tab_1">2</ref> shows that we can attain very good precision, even if the model is trained on a small part of the dataset, while saving significant amounts of time. In the context of our project, recall is more important than precision, since decreasing recall means losing valuable information (potential CoIs) while decreasing precision means extracting entities from useless values (strings which do not contain any), thus losing some time. Our experiments show that in our problem, recall is less sensitive than precision to the reduction of the training-set size which suits our purpose.</p><p>With respect to our motivating example, building the graph for DDS3 took around 11.000 seconds. Using our method with a training-set of 1% of the values (823 values) takes now the time to predict on which values we have to apply the extractor (125 seconds), to which we add the time to extract the valuable values. We have found on our dataset that there are around 45.000 valuable values. We need 5.900 seconds to extract those. That brings us to a total of 6.000 seconds to build our graph instead of 11.000 seconds previously without losing much information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">CONCLUSION</head><p>In this work, we exposed the limits of the existing DMV techniques with textual and heterogeneous data. A first technique we studied is to extract entities from each value of the database and exploit so-called entity profiles (expected entities in a non-null value) to identify disguised nulls. While highly accurate, this is expensive time-wise, because of the extraction. For efficiency, instead, we trained a classification model (Random Forest), only with partial samples of our dataset, labeled it with entity profiles, and predict (classify) the other values as DMVs or not. This technique saves significant extraction time, while also having very good accuracy.</p><p>As part of our future work, we could also try to optimize the hyper-parameters of the classification model, in order to further increase its performance.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Sample ConnectionLens graph.</figDesc><graphic coords="4,53.80,83.68,240.24,154.20" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: DMVs and the scope of each DMV technique 5.3 Discussion Our methods detect types of DMVs that are different from the ones detected by FAHES.Figure 2 represents a diagram showing how each method detects DMVs. FAHES techniques work better over structured data, whereas our techniques work over free-texts. Here we will detail with examples what DMVs or wrongly detected DMVs are in each part of the diagram:</figDesc><graphic coords="5,317.96,124.86,240.25,180.38" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>( 10 )</head><label>10</label><figDesc>Correctly detected DMV with the classification method that was not detected by the entity extraction method. For example, in 'John McDonalds declares no conflict of interest', the entity extractor could detect McDonalds as an Organisation, and classify the value as an actual CoI instead of a DMV. (11) Wrongly detected DMV with the classification method, these are errors of the classifier. (12) Most of the DMV detected by the entity profile technique are as well detected by the classification technique.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Entity extraction method times DS2 In this relational dataset, in an attribute entitled filename, FAHES identified correctly the disguised null dispense (120 occurrences) as a Random DMV. Then, FAHES identified wrongly other values as being disguised nulls, in all cases as Syntactic Outliers DMV. The values falsely flagged as disguised nulls are:‚Ä¢ Fran√ßois-No√´l (3 occurrences) in the attribute given name;‚Ä¢ B√âRIT-D√âBAT (6 occurrences) and K√âCLARD-MOND√âSIR<ref type="bibr" target="#b2">(3)</ref> in the attribute name; ‚Ä¢ di (4480 occurrences) in the attribute document type; this is the acronym for d√©claration d'int√©r√™t; ‚Ä¢ 2A and 2B as departement numbers; they are, in fact, correct numbers of French departments in Corsica; ‚Ä¢ four distinct, correct URLs within the photo_url attribute, probably because their structure did not ressemble the others'.</figDesc><table><row><cell cols="3">Values Total characters Extraction times (s)</cell></row><row><cell>500</cell><cell>163.203</cell><cell>56</cell></row><row><cell>5.000</cell><cell>1.604.141</cell><cell>669</cell></row><row><cell>10.000</cell><cell>3.281.345</cell><cell>1.320</cell></row><row><cell>15.000</cell><cell>5.000.364</cell><cell>2.175</cell></row><row><cell>20.000</cell><cell>6.728.493</cell><cell>2.620</cell></row><row><cell cols="3">DS1 Among the 270.000 values of the numeric amount attribute,</cell></row><row><cell cols="3">FAHES correctly found the disguised null 0 (45.000 occurrences) as</cell></row><row><cell cols="3">Random DMVs (Inliers). It also detected 372.2196 (4 occurrences) as</cell></row><row><cell cols="3">a numerical outlier DMV; this is wrong. All the amount values are</cell></row><row><cell cols="3">numbers, and as far as we could see, there are no other disguised</cell></row><row><cell>nulls.</cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Impact of training set size over the performances of disguised null detection We present the results in Table1. We observe that extracting entities is time consuming and that the extraction time is almost linear to the number of values. For the complete dataset DDS3, we can expect to have an extraction time around 11.000 seconds (183 minutes), which is quite lengthy.</figDesc><table><row><cell cols="3">Values in Training-set 16.477 8.238</cell><cell>823</cell></row><row><cell>Extraction Times (s)</cell><cell cols="2">2.153 1.075</cell><cell>108</cell></row><row><cell>Training Times (s)</cell><cell>54</cell><cell>23</cell><cell>6</cell></row><row><cell>Prediction Times (s)</cell><cell>10</cell><cell>10</cell><cell>11</cell></row><row><cell>Total Times (s)</cell><cell cols="2">2.217 1.108</cell><cell>125</cell></row><row><cell>Precision</cell><cell cols="3">0,939 0,933 0,885</cell></row><row><cell>Recall</cell><cell cols="3">0,948 0,946 0,942</cell></row><row><cell>F1-score</cell><cell cols="3">0,943 0,940 0,913</cell></row><row><cell>method.</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>The transparency entry forms require filling in the worth of participations or ownerships in various companies; companies which have closed or did not make benefits, or pro-bono activity, lead to disguised nulls.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p><ref type="bibr" target="#b1">2</ref> Available from https://gitlab.inria.fr/cedar/connectionlens</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Data Profiling</title>
		<author>
			<persName><forename type="first">Lukasz</forename><surname>Ziawasch Abedjan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Felix</forename><surname>Golab</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thorsten</forename><surname>Naumann</surname></persName>
		</author>
		<author>
			<persName><surname>Papenbrock</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
			<publisher>Morgan and Claypool</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Foundations of Databases</title>
		<author>
			<persName><forename type="first">Serge</forename><surname>Abiteboul</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Hull</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Victor</forename><surname>Vianu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995">1995</date>
			<publisher>Addison-Wesley</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Flair: An easy-to-use framework for state-of-the-art NLP</title>
		<author>
			<persName><forename type="first">Alan</forename><surname>Akbik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tanja</forename><surname>Bergmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Duncan</forename><surname>Blythe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kashif</forename><surname>Rasul</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefan</forename><surname>Schweter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roland</forename><surname>Vollgraf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Contextual string embeddings for sequence labeling</title>
		<author>
			<persName><forename type="first">Alan</forename><surname>Akbik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Duncan</forename><surname>Blythe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roland</forename><surname>Vollgraf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Graph integration of structured, semistructured and unstructured data for data journalism</title>
		<author>
			<persName><forename type="first">Christos</forename><surname>Angelos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oana</forename><surname>Anadiotis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Catarina</forename><surname>Balalau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Helena</forename><surname>Conceicao</surname></persName>
		</author>
		<author>
			<persName><surname>Galhardas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yamen</forename><surname>Mhd</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ioana</forename><surname>Haddad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tayeb</forename><surname>Manolescu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jingmao</forename><surname>Merabti</surname></persName>
		</author>
		<author>
			<persName><surname>You</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
		<respStmt>
			<orgName>Information Systems</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Empowering investigative journalism with graph-based heterogeneous data management</title>
		<author>
			<persName><forename type="first">Christos</forename><forename type="middle">G</forename><surname>Angelos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oana</forename><surname>Anadiotis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Th√©o</forename><surname>Balalau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Francesco</forename><surname>Bouganim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Helena</forename><surname>Chimienti</surname></persName>
		</author>
		<author>
			<persName><surname>Galhardas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yamen</forename><surname>Mhd</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephane</forename><surname>Haddad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ioana</forename><surname>Horel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Youssr</forename><surname>Manolescu</surname></persName>
		</author>
		<author>
			<persName><surname>Youssef</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Data Engineering Bulletin</title>
		<imprint>
			<date type="published" when="2021-09">September 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Graph integration of structured, semistructured and unstructured data for data journalism</title>
		<author>
			<persName><forename type="first">Oana</forename><surname>Balalau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Catarina</forename><surname>Concei√ß√£o</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Helena</forename><surname>Galhardas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ioana</forename><surname>Manolescu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tayeb</forename><surname>Merabti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jingmao</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Youssr</forename><surname>Youssef</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BDA</title>
		<imprint>
			<date type="published" when="2020-10">October 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Mixed-instance querying: a lightweight integration architecture for data journalism</title>
		<author>
			<persName><forename type="first">Rapha√´l</forename><surname>Bonaque</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tien</forename><surname>Duc Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bogdan</forename><surname>Cautis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fran√ßois</forename><surname>Goasdou√©</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Javier</forename><surname>Letelier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ioana</forename><surname>Manolescu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oscar</forename><surname>Mendoza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Swen</forename><surname>Ribeiro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xavier</forename><surname>Tannier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Micha√´l</forename><surname>Thomazo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">VLDB</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Random forests</title>
		<author>
			<persName><forename type="first">Leo</forename><surname>Breiman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine learning</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="5" to="32" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">ConnectionLens: Finding connections across heterogeneous data sources (demonstration)</title>
		<author>
			<persName><forename type="first">Camille</forename><surname>Chanial</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R√©douane</forename><surname>Dziri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Helena</forename><surname>Galhardas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julien</forename><surname>Leblay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Minh-Huong Le</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ioana</forename><surname>Manolescu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PVLDB (also at BDA)</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">12</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A relational model of data for large shared data banks</title>
		<author>
			<persName><forename type="first">F</forename><surname>Edgar</surname></persName>
		</author>
		<author>
			<persName><surname>Codd</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<date type="published" when="1970-06">June 1970</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Bert: Pretraining of deep bidirectional transformers for language understanding</title>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Declaratively cleaning your data with AJAX</title>
		<author>
			<persName><forename type="first">Helena</forename><surname>Galhardas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniela</forename><surname>Florescu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dennis</forename><forename type="middle">E</forename><surname>Shasha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><surname>Simon</surname></persName>
		</author>
		<editor>Anne Doucet</editor>
		<imprint>
			<date type="published" when="2000">2000</date>
			<publisher>BDA</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Declarative data cleaning: Language, model, and algorithms</title>
		<author>
			<persName><forename type="first">Helena</forename><surname>Galhardas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniela</forename><surname>Florescu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dennis</forename><forename type="middle">E</forename><surname>Shasha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><surname>Simon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cristian-Augustin</forename><surname>Saita</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">VLDB</title>
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Information translation, mediation, and mosaic-based browsing in the TSIMMIS system</title>
		<author>
			<persName><forename type="first">Joachim</forename><surname>Hammer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hector</forename><surname>Garcia-Molina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kelly</forename><surname>Ireland</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yannis</forename><surname>Papakonstantinou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeffrey</forename><forename type="middle">D</forename><surname>Ullman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jennifer</forename><surname>Widom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGMOD</title>
		<imprint>
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Data Mining Concepts and Techniques</title>
		<author>
			<persName><forename type="first">Jiawei</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Micheline</forename><surname>Kamber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jian</forename><surname>Pei</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011">2011</date>
			<publisher>Morgan Kaufmann</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Cleaning disguised missing data: A heuristic approach</title>
		<author>
			<persName><forename type="first">Ming</forename><surname>Hua</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jian</forename><surname>Pei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGKDD</title>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Probabilistic Ranking Techniques in Relational Databases</title>
		<author>
			<persName><forename type="first">F</forename><surname>Ihab</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohamed</forename><forename type="middle">A</forename><surname>Ilyas</surname></persName>
		</author>
		<author>
			<persName><surname>Soliman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Synthesis Lectures on Data Management</title>
		<imprint>
			<publisher>Morgan &amp; Claypool Publishers</publisher>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Statistical analysis with missing data</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Roderick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Donald</forename><forename type="middle">B</forename><surname>Little</surname></persName>
		</author>
		<author>
			<persName><surname>Rubin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1987">1987</date>
			<publisher>John Wiley &amp; Sons</publisher>
			<biblScope unit="volume">793</biblScope>
		</imprint>
	</monogr>
	<note>First edition</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">The problem of disguised missing data</title>
		<author>
			<persName><forename type="first">Ronald</forename><forename type="middle">K</forename><surname>Pearson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIGKDD Explor. Newsl</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="83" to="92" />
			<date type="published" when="2006-06">June 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Fahes: A robust disguised missing values detector</title>
		<author>
			<persName><forename type="first">A</forename><surname>Abdulhakim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ahmed</forename><surname>Qahtan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Raul</forename><forename type="middle">Castro</forename><surname>Elmagarmid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mourad</forename><surname>Fernandez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nan</forename><surname>Ouzzani</surname></persName>
		</author>
		<author>
			<persName><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGKDD</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Potter&apos;s wheel: An interactive data cleaning system</title>
		<author>
			<persName><forename type="first">Vijayshankar</forename><surname>Raman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joseph</forename><forename type="middle">M</forename><surname>Hellerstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">VLDB</title>
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Sentence-BERT: Sentence embeddings using siamese bert-networks</title>
		<author>
			<persName><forename type="first">Nils</forename><surname>Reimers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Iryna</forename><surname>Gurevych</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
