<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">GAP: Differentially Private Graph Neural Networks with Aggregation Perturbation</title>
				<funder ref="#_9wDrdpM">
					<orgName type="full">French National Research Agency (ANR)</orgName>
				</funder>
				<funder ref="#_dhQuhys">
					<orgName type="full">European Commission</orgName>
				</funder>
				<funder ref="#_CySBc3t">
					<orgName type="full">Agence Nationale de la Recherche</orgName>
					<orgName type="abbreviated">ANR</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Sina</forename><surname>Sajadmanesh</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Idiap Research Institute</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">EPFL</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Ali</forename><forename type="middle">Shahin</forename><surname>Shamsabadi</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">The Alan Turing Institute</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Aur√©lien</forename><surname>Bellet</surname></persName>
							<affiliation key="aff3">
								<orgName type="institution">Inria</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Daniel</forename><surname>Gatica-Perez</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Idiap Research Institute</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">EPFL</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">GAP: Differentially Private Graph Neural Networks with Aggregation Perturbation</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">6A565EE604444084F26546B6A3D67A20</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-04-12T14:50+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper, we study the problem of learning Graph Neural Networks (GNNs) with Differential Privacy (DP). We propose a novel differentially private GNN based on Aggregation Perturbation (GAP), which adds stochastic noise to the GNN's aggregation function to statistically obfuscate the presence of a single edge (edge-level privacy) or a single node and all its adjacent edges (node-level privacy). Tailored to the specifics of private learning, GAP's new architecture is composed of three separate modules: (i) the encoder module, where we learn private node embeddings without relying on the edge information; (ii) the aggregation module, where we compute noisy aggregated node embeddings based on the graph structure; and (iii) the classification module, where we train a neural network on the private aggregations for node classification without further querying the graph edges. GAP's major advantage over previous approaches is that it can benefit from multi-hop neighborhood aggregations, and guarantees both edge-level and node-level DP not only for training, but also at inference with no additional costs beyond the training's privacy budget. We analyze GAP's formal privacy guarantees using R√©nyi DP and conduct empirical experiments over three real-world graph datasets. We demonstrate that GAP offers significantly better accuracy-privacy trade-offs than state-of-the-art DP-GNN approaches and naive MLP-based baselines. Our code is publicly available at https://github.com/sisaman/GAP.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Real-world datasets are often represented by graphs, such as social <ref type="bibr" target="#b36">[36]</ref>, financial <ref type="bibr" target="#b42">[42]</ref>, transportation <ref type="bibr" target="#b7">[8]</ref>, or biological <ref type="bibr" target="#b24">[25]</ref> networks, modeling the relations (i.e., edges) between a collection of entities (i.e., nodes). Graph Neural Networks (GNNs) have achieved state-of-the-art performance in learning over such relational data in various graph-based machine learning tasks, such as node classification, link prediction, and graph classification <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b47">47,</ref><ref type="bibr" target="#b52">52]</ref>. Due to their superior performance, GNNs are now widely used in many applications, such as recommendation systems, credit issuing, traffic forecasting, drug discovery, and medical diagnosis <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b49">49]</ref>.</p><p>Privacy concerns. Despite their success, real-world deployments of GNNs raise privacy concerns when graphs contain personal data: for instance, social or financial networks involve sensitive information about individuals and their interactions.</p><p>Recent works <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b44">44]</ref> have extended the study of the privacy leakage of standard deep learning models to GNNs, showing the risk of information leakage regarding training data is even higher in GNNs, as they incorporate not only node features and labels but also the graph structure itself <ref type="bibr" target="#b8">[9]</ref>. Consequently, GNNs are vulnerable to various privacy attacks, such as node membership inference <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b32">33]</ref> and edge stealing <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b44">44]</ref>. For example, a GNN trained on a social network for friendship recommendation could reveal the existing relationships between the users via its predictions. As another example, a GNN trained on the social graph of COVID-19 patients can be used by government authorities to predict the spread of the disease, but an adversary may recover private information about the participating patients.</p><p>Problem and motivation. Motivated by these privacy concerns, we investigate the problem of designing privacypreserving GNNs for private, sensitive graphs. Our goal is to protect the sensitive graph structure and other accompanying data using the framework of Differential Privacy (DP) <ref type="bibr" target="#b9">[10]</ref>.In the context of graphs, two different variants of DP have been defined: edge-level and node-level DP <ref type="bibr" target="#b37">[37]</ref>. Informally, an edge-level ùúñ-DP algorithm have roughly the same output (as measured by ùúñ) if one edge is removed from the input graph. This ensures that the algorithm's output does not reveal the existence of a particular edge in the graph. Correspondingly, node-level private algorithms conceal the presence of a particular node together with all its associated edges and attributes. Clearly, node-level DP is a stronger privacy definition, but it is harder to attain because it requires the algorithm's output distribution to hide much larger differences in the input graph.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Challenges.</head><p>As GNNs utilize the structural information in the graph data, protecting data privacy in such models is more At each layer, every node aggregates its neighbors' embedding vectors (initially node features, e.g. X A for node A), which is then updated using a neural net into a new vector (e.g., H A ). Removing an arbitrary edge (here, the edge from node B to F) excludes the source node (B) from the aggregation set of the destination node (F). At the first layer, this will only alter the destination node's embedding, but this change is propagated to the neighboring nodes in the next layer. Node embeddings that are affected by the removal of edge (B,F) are indicated in red.</p><p>challenging than in standard ones. As shown in Figure <ref type="figure" target="#fig_0">1</ref>, one of these challenges is the interdependency between the node embeddings resulting from the GNN's data aggregation mechanism. Specifically, a ùêæ-layer GNN iteratively learns node embeddings by aggregating information from every node's ùêæ-hop neighborhood (i.e., from nodes that are at a distance at most ùêæ in the graph). Hence, the embedding of a node is influenced not only by the node itself but also by all the nodes in its ùêæ-hop proximity. This fact voids the privacy guarantees of standard DP learning paradigms, such as DP-SGD <ref type="bibr" target="#b1">[2]</ref>, as the training loss of GNNs can no longer be decomposed into individual samples. Furthermore, the number of interdependent embeddings grows exponentially with ùêæ, hindering the ability of a DP solution to hide the output differences effectively. Therefore, how to get more representational power from higher-order GNN aggregations while ensuring DP is an important challenge to address.</p><p>Another major challenge is to guarantee inference privacy, i.e., preserving the privacy of graph data not only for training but also at inference time, when the trained GNN model is queried to make predictions for test nodes. Unlike conventional deep learning models, where the training data is not reused at inference time, the inference about any node in a ùêæ-layer GNN requires aggregating data from its ùêæ-hop neighborhood, which can reveal information about the neighboring nodes. Therefore, private graph data can still be leaked at inference time, even with privately trained model parameters. As a result, it is critical to ensure that both the training and inference stages of a GNN satisfy DP. This is illustrated in Figure <ref type="figure" target="#fig_1">2</ref>.</p><p>Our contributions. To address the above challenges, we propose GAP, a privacy-preserving GNN model satisfying edge-level privacy, which is also extensible to node-level privacy if combined with standard private learning algorithms such as DP-SGD. As perturbing an edge in the input graph can practically be viewed as changing a sample in a node's neighborhood aggregation set, GAP preserves edge privacy via aggregation perturbation: we add calibrated Gaussian noise Given the trained model, the inference mechanism of a DNN is independent of the training data, so a DP learning algorithm implies a DP inference mechanism as well. With GNNs however, graph data is queried again at inference time, so the inference step requires specific attention to be made differentially private.</p><p>to the output of the aggregation function, which can effectively hide the presence of a single edge (edge-level privacy) or a group of edges (node-level privacy). To avoid accumulating privacy costs at every model update, we propose a custom GNN architecture (Figure <ref type="figure" target="#fig_2">3</ref>) comprising three individual components: (i) the encoder module, where we pre-train an encoder to extract lower-dimensional node features without relying on the graph structure; (ii) the aggregation module, where we use aggregation perturbation to privately compute multi-hop aggregated node embeddings using the graph edges and the encoded features; and (iii) the classification module, where we train a neural network on the aggregated data for node classification without further querying the graph edges.</p><p>Aggregation perturbation allows us to benefit from higher- The encoded features are given to the aggregation module to compute private ùêæ-hop aggregations (here, ùêæ = 2) using the graph's adjacency matrix (A). (3) The classification module is trained over the private aggregations for label prediction. order, multi-hop aggregations by composing individual noisy aggregations, yet the proposed architecture significantly reduces the privacy costs as the perturbed aggregations are computed once on lower-dimensional embeddings, and reused during training and inference. GAP also provides inference privacy, as the inference of any node relies on the perturbed aggregations, which hide information about neighboring nodes. Due to reusing cached aggregations, the inference step does not incur additional privacy costs beyond that of training.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>MLP</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results.</head><p>We analyze GAP's formal privacy guarantees using R√©nyi Differential Privacy <ref type="bibr" target="#b28">[29]</ref>, and empirically evaluate its accuracy-privacy performance on three medium to large-scale graph datasets, namely Facebook, Reddit, and Amazon. We demonstrate that GAP's accuracy surpasses the competing baselines' at (very) low privacy budgets under both edge-level DP (e.g., ùúñ ‚â• 0.1 on Reddit) and node-level DP (e.g., ùúñ ‚â• 1 on Reddit), and observe that it always performs on par or better than a naive (privately trained) MLP model which does not utilize the graph's structural information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Graph neural networks. Deep learning on graphs has emerged in the past few years to tackle different kinds of graph-based learning tasks. A variety of GNN models and various architectures have been proposed, including Graph Convolutional Networks <ref type="bibr" target="#b25">[26]</ref>, Graph Attention Networks <ref type="bibr" target="#b41">[41]</ref>, GraphSAGE <ref type="bibr" target="#b15">[16]</ref>, Graph Isomorphism Networks <ref type="bibr" target="#b47">[47]</ref>, Jumping Knowledge Networks <ref type="bibr" target="#b48">[48]</ref>, and Gated Graph Neural Networks <ref type="bibr" target="#b27">[28]</ref>. For the latest advances and trends in GNNs, we refer the reader to the available surveys <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b46">46,</ref><ref type="bibr" target="#b53">53,</ref><ref type="bibr" target="#b56">56]</ref>.</p><p>Privacy attacks on GNNs. Several recent works have investigated the possibility of performing privacy attacks against GNNs and quantified the privacy leakage of publicly released GNN models or node embeddings trained on private graph datasets. Zhang et al. <ref type="bibr" target="#b55">[55]</ref> study the information leakage in graph embeddings and propose three different inference attacks against GNNs: inferring graph properties (such as number of nodes and edges), inferring whether a given subgraph is contained in the target graph, and graph reconstruction with similar statistics to the target graph. He et al. <ref type="bibr" target="#b18">[19]</ref> propose a series of black-box link stealing attacks on GNN models, and show that an adversary can accurately infer a link between any pair of nodes in a graph used to train the GNN. Zhang et al. <ref type="bibr" target="#b54">[54]</ref> study the connection between model inversion risk and edge influence, and show that edges with greater influence are more likely to be inferred. Wu et al. <ref type="bibr" target="#b44">[44]</ref> also study the link stealing attack via influence analysis, and propose an effective attack against GNNs based on the node influence information. The feasibility of the membership inference attack against GNNs has also been studied and several attacks with different threat models have been proposed in the literature <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b32">33]</ref>. Overall, these works underline the privacy risks of GNNs trained on sensitive graph data and confirm the vulnerability of these models to various privacy attacks.</p><p>Differentially private GNNs. Recently, there have been attempts to use DP to provide formal privacy guarantees in various GNN learning settings. Sajadmanesh and Gatica-Perez <ref type="bibr" target="#b38">[38]</ref> propose a locally private GNN model by considering a distributed learning setting, where node features and labels are private but training the GNN is federated by a central server with access to graph edges. However, their method cannot be used in applications where the graph edges are private. Wu et al. <ref type="bibr" target="#b44">[44]</ref> propose an edge-level DP learning algorithm for GNNs by perturbing the input graph directly using either randomized response (called E R ) or the Laplace mechanism (called L G</p><p>). Then, a GNN is trained over the resulting noisy graph. However, their method cannot be extended trivially to the node-level privacy setting. Olatunji et al. <ref type="bibr" target="#b31">[32]</ref> consider a centralized learning setting and propose a node-level private GNN by adapting the framework of PATE <ref type="bibr" target="#b33">[34]</ref>. They train the student GNN model using public graph data, which is privately labeled using the teacher GNN models trained exclusively for each query node. However, their dependence on public graph data restricts the applicability of their method. Daigavane et al. <ref type="bibr" target="#b6">[7]</ref> also propose a node-level private approach for training 1-layer GNNs by extending the  standard DP-SGD algorithm and privacy amplification by subsampling results to bounded-degree graph data. However, their approach fails to provide inference privacy and is limited to 1-layer GNNs and thus cannot leverage higher-order aggregations.</p><p>Comparison with existing methods. To our best knowledge, GAP is the first approach providing both edge-level or nodelevel privacy guarantees based on the application requirements. Unlike existing methods, our approach does not rely on public data, can leverage multi-hop aggregations beyond first-order neighbors, and guarantees inference privacy at no additional cost. In Section 7, we also show that GAP outperforms other baselines in terms of accuracy-privacy trade-off.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Background and Problem Formulation</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Graph Neural Networks</head><p>GNNs aim to learn a representation for every node in the input graph by incorporating the initial node features and the graph structure (edges). The learned node representations, or embeddings, can then be used for the downstream machine learning task. In this paper, we focus on node classification, where the embeddings are used to predict the label of the graph nodes. Node-wise prediction problems can be tackled in either transductive or inductive setting. In the transductive setting, both training and testing are performed on the same graph, but different nodes are used for training and testing. Conversely, in the inductive setting, training and testing are performed on different graphs. This is illustrated in Figure <ref type="figure" target="#fig_4">4</ref>.</p><p>Let G = (V, E, X, Y) be an unweighted directed graph dataset consisting of sets of nodes V and edges E represented by a binary adjacency matrix A ‚àà {0, 1} ùëÅ √óùëÅ , where ùëÅ = |V | denotes the number of nodes, and A ùëñ, ùëó = 1 if there is a directed edge (ùëñ, ùëó) ‚àà E from node ùëñ to node ùëó. Nodes are characterized by ùëë-dimensional feature vectors stacked up in an ùëÅ √ó ùëë matrix X, where X ùë£ denotes the feature vector of the ùë£-th GNN Layer GNN Layer</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>GNN Layer</head><p>Figure <ref type="figure">5</ref>: Typical 3-layer GNN for node classification. Each layer ùëñ takes the adjacency matrix A and previous layer's node embedding matrix H (ùëñ-1) (initially, node features X), and outputs a new embedding matrix H (ùëñ) (ultimately, predicted class labels Y). Internally, the input embeddings H (ùëñ-1) are aggregated based on the adjacency matrix A, and then fed to a neural network (U ) to generate new embeddings H (ùëñ) . node. Y ‚àà {0, 1} ùëÅ √óùê∂ represents the labels of the nodes, where Y ùë£ is a ùê∂-dimensional one-hot vector denoting the label of the ùë£-th node, and ùê∂ is the number of classes. Note that in the transductive learning setting, only a subset V ùëá ‚äÇ V of the nodes is labeled, and thus Y ùë£ is a zero vector for all ùë£ ‚àâ V ùëá .</p><p>A typical ùêæ-layer GNN consists of ùêæ sequential graph convolution layers. Layer ùëñ receives node embeddings from layer ùëñ -1 and outputs a new embedding for each node by aggregating the current embeddings of its adjacent neighbors followed by a learnable transformation, as defined below:</p><formula xml:id="formula_0">H (ùëñ) ùë£ = upd agg {H (ùëñ-1) ùë¢ : ‚àÄùë¢ ‚àà ùîë ùë£ } ; ùöØ (ùëñ) ,</formula><p>where ùîë ùë£ = {ùë¢ : A ùë¢,ùë£ ‚â† 0} denotes the set of adjacent nodes to node ùë£ (i.e., nodes with outbound edges toward ùë£), and</p><formula xml:id="formula_1">H (ùëñ-1)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ùë¢</head><p>is the embedding of an adjacent node ùë¢ at layer ùëñ -1. agg(‚Ä¢), is a (sub)differentiable, permutation invariant aggregator function, such as S , M , or M . Finally, upd(‚Ä¢) is a learnable function, such as a multi-layer perceptron (MLP), parameterized by ùöØ (ùëñ) that takes the aggregated vector and outputs the new embedding H (ùëñ)  ùë£ . For convenience, we define the matrix-based version of agg(‚Ä¢) and upd(‚Ä¢) by stacking the corresponding vectors of all the nodes into a matrix as:</p><formula xml:id="formula_2">A (H, A) = [agg ({H ùë¢ : ‚àÄùë¢ ‚àà ùîë ùë£ }) : ‚àÄùë£ ‚àà V] ùëá , U (M; ùöØ) = [upd (M ùë£ ; ùöØ) : ‚àÄùë£ ‚àà V] ùëá ,</formula><p>where we omitted the layer indicator superscripts for simplicity. Initially, we have H (0) = X (i.e., node features) as the input to the GNN's first layer. The last layer generates an output embedding vector for each node, which can be used in different ways depending on the downstream task. For node classification, a softmax layer is applied to the final embeddings H (ùêæ ) to obtain the posterior class probabilities Y. The illustration of a typical 3-layer GNN is depicted in Figure <ref type="figure">5</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Differential Privacy</head><p>Differential privacy (DP) <ref type="bibr" target="#b10">[11]</ref> is the gold standard for formalizing the privacy guarantees of algorithms that process sensitive data. Informally, DP requires that the algorithm's output distribution be roughly the same regardless of the presence of an individual's data in the dataset. As such, an adversary having access to the data of all but the target individual cannot distinguish whether the target's record is among the input data. The formal definition of DP is as follows.</p><p>Definition 1 (Differential Privacy <ref type="bibr" target="#b10">[11]</ref>). Given ùúñ &gt; 0 and ùõø &gt; 0, a randomized algorithm A satisfies (ùúñ, ùõø)-differential privacy, if for all possible pairs of adjacent datasets ùëã and ùëã differing by at most one record, denoted as ùëã ‚àº ùëã , and for any possible set of outputs ùëÜ ‚äÜ ùëÖùëéùëõùëîùëí(A), we have:</p><formula xml:id="formula_3">Pr[A (ùëã) ‚àà ùëÜ] ‚â§ ùëí ùúñ Pr[A (ùëã ) ‚àà ùëÜ] + ùõø.</formula><p>Here, the parameter ùúñ is called the privacy budget (or privacy cost) and is used to tune the privacy-utility trade-off of the algorithm: a lower privacy budget leads to stronger privacy guarantees but reduced utility. The parameter ùõø is informally treated as a failure probability, and is usually chosen to be very small. DP has the following important properties that help us design complex algorithms from simpler ones <ref type="bibr" target="#b9">[10]</ref>:</p><p>‚Ä¢ Robustness to post-processing: Any post-processing of the output of an (ùúñ, ùõø)-DP algorithm remains (ùúñ, ùõø)-DP. ‚Ä¢ Sequential composition: If an (ùúñ, ùõø)-DP algorithm is applied ùëò times on the same data, the result is at most (ùëòùúñ, ùëòùõø)-DP.</p><p>‚Ä¢ Parallel composition: Executing an (ùúñ, ùõø)-DP algorithm on disjoint chunks of data yields an (ùúñ, ùõø)-DP algorithm.</p><p>In this paper, we use an alternative definition of DP, called R√©nyi Differential Privacy (RDP) <ref type="bibr" target="#b28">[29]</ref>, which allows obtaining tighter sequential composition results: Definition 2 (R√©nyi Differential Privacy <ref type="bibr" target="#b28">[29]</ref>). A randomized algorithm A is (ùõº, ùúñ)-RDP for ùõº &gt; 1, ùúñ &gt; 0 if for every adjacent datasets ùëã ‚àº ùëã , we have ùê∑ ùõº (A (ùëã) A (ùëã )) ‚â§ ùúñ, where ùê∑ ùõº (ùëÉ ùëÑ) is the R√©nyi divergence of order ùõº between probability distributions ùëÉ and ùëÑ defined as:</p><formula xml:id="formula_4">ùê∑ ùõº (ùëÉ ùëÑ) = 1 ùõº -1 log E ùë•‚àºùëÑ ùëÉ(ùë•) ùëÑ(ùë•) ùõº .</formula><p>As RDP is a generalization of DP, it can be easily converted back to standard (ùúñ, ùõø)-DP using the following proposition:</p><formula xml:id="formula_5">Proposition 1. If A is an (ùõº, ùúñ)-RDP algorithm, then it also satisfies (ùúñ + log(1/ ùõø) /ùõº-1, ùõø)-DP for any ùõø ‚àà (0, 1).</formula><p>A basic method to achieve RDP is the Gaussian mechanism, where Gaussian noise is added to the output of the algorithm we want to make private. Specifically, let ùëì : X ‚Üí R ùëë be the non-private algorithm taking a dataset as input and outputting a ùëë-dimensional vector. Let the sensitivity of ùëì be the maximum ùêø 2 distance achievable when applying ùëì (‚Ä¢) to adjacent datasets ùëã and ùëã as Œî ùëì = max ùëã ‚àºùëã ùëì (ùëã) -ùëì (ùëã ) 2 . Then, adding Gaussian noise with variance ùúé 2 to ùëì as A (ùëã) = ùëì (ùëã) + N (ùúé 2 I ùëë ), with I ùëë being ùëë √ó ùëë identity matrix, yields an (ùõº, ùúñ)-RDP algorithm for all ùõº &gt; 1 with ùúñ = Œî 2 ùëì ùõº /2ùúé 2 <ref type="bibr" target="#b28">[29]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Problem Definition</head><p>Let Y = F (X, A; ùöØ) be a GNN-based node classification model with parameter set ùöØ that takes node features X and the graph's adjacency matrix A as input, and outputs the corresponding predicted labels Y. To learn the model parameters ùöØ, we minimize a standard classification loss function (e.g., cross-entropy) with respect to ùöØ as follows:</p><formula xml:id="formula_6">ùöØ ‚òÖ = arg min ùöØ ‚àëÔ∏Å ùë£ ‚ààV ùëá ‚Ñì( Y ùë£ , Y ùë£ ),<label>(1)</label></formula><p>where ‚Ñì(‚Ä¢, ‚Ä¢) is the loss function, Y is the ground-truth labels, and V ùëá ‚äÜ V is the set of labeled training nodes. After training, in the transductive setting, the learned GNN is used to infer the labels of unlabeled nodes in G:</p><formula xml:id="formula_7">Y = F (X, A; ùöØ ‚òÖ ),<label>(2)</label></formula><p>Otherwise, in the inductive setting, a new graph dataset G ùë°ùëíùë†ùë° is given to the learned GNN for label inference. The goal of this paper is to preserve the privacy of graph datasets for both the training step (Eq. 1) and the inference step (Eq. 2) using differential privacy. Note that preserving privacy in the inference step is critical as the adjacency information is still used in this step for obtaining the predicted labels.</p><p>However, as graph datasets are different from standard tabular datasets due to the existence of links between data records, one needs to adapt the definition of DP to graphs. As the semantic interpretation of DP relies on the definition of adjacent datasets, we first define two different notions of adjacency in graphs, namely edge-level and node-level adjacent graph datasets <ref type="bibr" target="#b17">[18]</ref>: Definition 3 (Edge-level adjacent graphs). Two graphs G and G are edge-level adjacent if one can be obtained by removing a single edge from the other. Therefore, G and G differ by at most one edge.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Definition 4 (Node-level adjacent graphs). Two graphs G and G are node-level adjacent if one can be obtained by removing a single node (with its features, labels, and all attached edges) from the other. Therefore, G and G differ by at most one node.</head><p>Accordingly, the definition of edge-level and node-level DP follows from the above definitions: an algorithm A is edge-level (respectively, node-level) (ùúñ, ùõø)-DP if for every two edge-level (respectively, node-level) adjacent graph datasets G and G and any set of outputs ùëÜ ‚äÜ ùëÖùëéùëõùëîùëí(A), we have</p><formula xml:id="formula_8">Pr[A (G) ‚àà ùëÜ] ‚â§ ùëí ùúñ Pr[A (G ) ‚àà ùëÜ] + ùõø.</formula><p>Intuitively, edge-level DP protects edges (which could represent connections between people), while node-level DP protects nodes together with their adjacent edges (i.e., all information pertaining to an individual, including features, labels, and connections).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Proposed Method: GAP</head><p>In this section, we explain our proposed differentially private method, called GNN with Aggregation Perturbation (GAP), which guarantees both edge-level and node-level privacy for training and inference on sensitive graph data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Overview</head><p>As mentioned in Section 1, the two primary challenges in the design of private GNNs come from the use of higher-order aggregations and the need to ensure inference privacy. To tackle these challenges, we propose a new architecture for GAP, which is different from the conventional GNN architectures presented in Section 3.1. The key distinction is that GAP decouples the graph-based aggregations from the neural network-based transformations, which is similar in spirit to the Inception model and scalable networks <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b39">39,</ref><ref type="bibr" target="#b45">45]</ref>. As illustrated in Figure <ref type="figure" target="#fig_2">3</ref>, GAP is composed of the following three components:</p><p>(i) Encoder Module (EM): This module encodes the input node features into a lower-dimensional representation without using the private graph structure.</p><p>(ii) Aggregation Module (AM): This module takes the encoded low-dimensional node features and recursively computes private multi-hop aggregations using the aggregation perturbation approach, i.e., by adding noise to the output of each aggregation step.</p><p>(iii) Classification Module (CM): This module takes the privately aggregated node features and predicts the corresponding labels without querying the edges any further.</p><p>GAP's privacy mechanism. Our proposed mechanism for preserving the privacy of graph edges in AM is the aggregation perturbation approach: we use the Gaussian mechanism to add stochastic noise to the output of the aggregation function proportional to its sensitivity. This approach is motivated by the fact that perturbing an edge in the input graph can practically be viewed as changing a sample in the neighborhood aggregation function of the edge's destination node. Therefore, by adding an appropriate amount of noise to the aggregation function, we can effectively hide the presence of a single edge, which ensures edge-level privacy, or a group of edges, which is necessary for node-level privacy. To fully guarantee nodelevel privacy, however, in addition to the edges, we need to also protect node features and labels, which is simply done by training EM and CM using standard DP learning algorithms such as DP-SGD. We discuss this point further in Section 5.</p><p>Challenges addressed. Our GAP method can benefit from multi-hop aggregations by composing individual noisy aggregation steps. As the sensitivity of a single-step aggregation is easily determined, AM applies the Gaussian mechanism immediately after each aggregation step, avoiding the growing interdependency between node embeddings. GAP also provides inference privacy as the inference of a node relies on the aggregated data from its neighbors, which is privately computed by AM. As the subsequent CM only post-processes these private aggregations, GAP ensures inference-time privacy. This is explained in more details in Section 5.</p><p>In the rest of this section, we first discuss each of the GAP's components thoroughly and then describe the inference mechanism.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Encoder Module</head><p>GAP uses a multi-layer perceptron (MLP) model as an encoder to transform the original node features into an intermediate representation given to AM. The main goal of this module is to reduce the dimensionality of AM's input, as the magnitude of the Gaussian noise injected into the aggregations grows with data dimensionality. Therefore, reducing the dimensionality helps achieve better aggregation utility under DP.</p><p>Note that in order to save the privacy budget spent in AM, we do not train the encoder end-to-end with CM. Instead, we attach a linear softmax layer to the encoder MLP for label prediction, and then pre-train this model separately using node features and labels. Specifically, we use the following model:</p><formula xml:id="formula_9">Y = softmax (MLP enc (X; ùöØ enc ) ‚Ä¢ W) ,<label>(3)</label></formula><p>where MLP enc is the encoder MLP with parameter set ùöØ enc , W is the weight matrix of the linear softmax layer, X is the original node features, and Y is the corresponding posterior class probabilities. In order to train this model, we minimize the cross-entropy (or any other classification-related) loss function ‚Ñì(‚Ä¢, ‚Ä¢) with respect to the model parameters ùöØ = {ùöØ enc , W}:</p><formula xml:id="formula_10">ùöØ ‚òÖ = arg min ùöØ ‚àëÔ∏Å ùë£ ‚ààV ùëá ‚Ñì( Y ùë£ , Y ùë£ ),<label>(4)</label></formula><p>where Y is the ground-truth labels and V ùëá ‚äÜ V is the set of training nodes. After pre-training, we use the encoder MLP to extract low-dimensional node features, X (0) , for AM:</p><formula xml:id="formula_11">X (0) = MLP enc (X; ùöØ ‚òÖ enc ).<label>(5)</label></formula><p>Remark. As will be discussed in Section 4.3, this encoder pretraining approach significantly reduces the model's privacy costs as the private aggregations in AM no longer need to be updated with the encoder's parameters. Besides, compared to the original features, this approach provides better node features to AM as the encoded representations incorporate label information as well.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Aggregation Module</head><p>The goal of AM is to privately release multi-hop aggregated node features using the aggregation perturbation method. Algorithm 1 presents our mechanism, the Private Multi-hop Aggregation (PMA). It relies on the S aggregation function, which is simply equivalent to the multiplication of the adjacency matrix A by the input feature matrix X, as A (X, A) = A ùëá ‚Ä¢ X. The PMA mechanism takes X(0) , the row-normalized version of the encoder's extracted features as:</p><formula xml:id="formula_12">X(0) ùë£ = X (0) ùë£ / X (0) ùë£ 2 , ‚àÄùë£ ‚àà V.<label>(6)</label></formula><p>It then outputs a set of ùêæ normalized, privately aggregated node features X(1) to X(ùêæ) corresponding to different hops from 1 to ùêæ. Specifically, given ùúé &gt; 0, the PMA mechanism performs the following steps to recursively compute and perturb the aggregations in ùëò-th hop from (ùëò -1)-th:</p><p>1. Aggregation: First, we compute ùëò-th non-private aggregations using the normalized aggregations at step ùëò -1:</p><formula xml:id="formula_13">X (ùëò) = A ùëá ‚Ä¢ X(ùëò-1) .<label>(7)</label></formula><p>2. Perturbation: Next, we perturb the aggregations using the Gaussian mechanism, i.e., by adding noise with variance ùúé 2 to every row of X (ùëò) independently:</p><formula xml:id="formula_14">X (ùëò) ùë£ = X (ùëò) ùë£ + N (ùúé 2 I), ‚àÄùë£ ‚àà V.<label>(8)</label></formula><p>3. Normalization: Finally, it is essential to bound the effect of each feature vector on the subsequent aggregations. Therefore, we again row-normalize the private aggregated features, such that the L2-norm of each row is 1:</p><formula xml:id="formula_15">X(ùëò) ùë£ = X (ùëò) ùë£ /|| X (ùëò) ùë£ || 2 , ‚àÄùë£ ‚àà V.<label>(9)</label></formula><p>Remark. The recursive computation of aggregations in the PMA mechanism has one advantage: each aggregation step acts as a denoising mechanism, averaging out the DP noise added in the previous step (to some extent). Therefore, part of the injected noise is dampened by the PMA mechanism itself, leading to better aggregation utility. This noise-reducing effect of GNN aggregations is also observed in prior work <ref type="bibr" target="#b38">[38]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Effect of EM.</head><p>Note that EM plays a critical role in improving AM's privacy-utility trade-off: First, it increases the utility of noisy aggregations by reducing the dimensionality of AM's input, resulting in less noise added to the aggregations. Second, its pre-training strategy makes AM agnostic to model training, which remarkably reduces the total privacy costs as the PMA mechanism is called only once and its output is cached to be reused for entire training and inference. Technically, this implies that with ùëá training iterations, the Gaussian mechanism is composed only ùêæ times, which would otherwise be ùêæùëá in the case of end-to-end training. Since ùêæ is small (1 ‚â§ ùêæ ‚â§ 5) compared to ùëá (in the order of hundreds), this leads to a substantial reduction in the privacy budget.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Classification Module</head><p>Given the list of private aggregated features { X(0) , . . . , X(ùêæ) } provided by AM, the goal of CM is to predict node labels</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 1: Private Multi-hop Aggregation</head><p>Input :Graph G = ( V, E) with adjacency matrix A; initial normalized features X(0) ; max hop ùêæ ; noise variance ùúé 2 ; Output :Private aggregated node feature matrices X(1) , . . . , X(ùêæ ) without further relying on the graph edges. To this end, for each ùëò ‚àà {0, 1, . . . , ùêæ }, we first obtain the ùëò-hop representation H (ùëò) using a corresponding base MLP, denoted as MLP (ùëò)  base :</p><formula xml:id="formula_16">1 for ùëò ‚àà {1, . . . , ùêæ } do 2 X (ùëò) ‚Üê A ùëá ‚Ä¢ X(ùëò-1) // aggregate 3 X (ùëò) ‚Üê X (ùëò) + N ( ùúé 2 I) // perturb 4 for ùë£ ‚àà V do 5 X(ùëò) ùë£ ‚Üê X (ùëò) ùë£ / | | X (ùëò) ùë£ | | 2 //</formula><formula xml:id="formula_17">H (ùëò) = MLP (ùëò) base ( X(ùëò) ; ùöØ (ùëò) base ),<label>(10)</label></formula><p>where ùöØ (ùëò) base is the parameters of MLP (ùëò) base . Next, we combine these representations to get an integrated node embedding H:</p><formula xml:id="formula_18">H = C {H (0) , H (1) , . . . , H (ùêæ ) }; ùöØ comb ,<label>(11)</label></formula><p>where C is any differentiable combination strategy, with common choices being summation, concatenation, or attention, potentially with parameter set ùöØ comb . Finally, we feed the integrated representation into a head MLP, denoted as MLP head , to get posterior class probabilities for the nodes:</p><formula xml:id="formula_19">Y = MLP head (H; ùöØ head ),<label>(12)</label></formula><p>where ùöØ head denotes the parameters of MLP head . To train CM, we minimize a similar loss function as Eq. 4 but with respect to CM's parameters: ùöØ = {ùöØ (0) base , . . . , ùöØ (ùêæ ) base , ùöØ comb , ùöØ head }. The overall training procedure of GAP is presented in Algorithm 2.</p><p>Remark. CM independently processes the information encoded in the graph-agnostic node features X(0) and the private, graph-based aggregated features X(1) to X(ùêæ) , combining them together to get an integrated node representation. Therefore, even if the DP noise overwhelms the signal in the higher-level aggregations, the information in the lower-level aggregations and/or the graph-agnostic features is still preserved and exploited for classification. As a result, regardless of the privacy budget, GAP is expected to always perform on par or better than pure MLP-based models that do not rely on the graph structure. We will empirically demonstrate this point in our experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Inference Mechanism</head><p>GAP is compatible with both the transductive and the inductive inference, as discussed below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 2: GAP Training</head><p>Input :Graph G = ( V, E) with adjacency matrix A; node features X; node labels Y; max hop ùêæ ; noise variance ùúé 2 ; Output :Trained model parameters {ùöØ ‚òÖ enc , ùöØ ‚òÖ (0) base , . . . , ùöØ ‚òÖ (ùêæ ) base , ùöØ ‚òÖ comb , ùöØ ‚òÖ head };</p><p>1 Pre-train EM (Eq. 3) to obtain ùöØ ‚òÖ enc . 2 Use the pre-trained encoder (Eq. 5) to obtain encoded features X (0) . 3 Row-normalize the encoded features (Eq. 6) to obtain X(0) . 4 Use Algorithm 1 to obtain private aggregations X(1) , . . . , X(ùêæ ) .</p><p>5 Train CM (Eq. 10-12) to get ùöØ ‚òÖ (0) base , . . . , ùöØ  <ref type="figure" target="#fig_4">4b</ref>). In this case, we first extract low-dimensional node features for the new graph using the pre-trained encoder and then feed them to AM to obtain the private aggregations. Finally, we input the private aggregations to the trained CM to get the node labels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Privacy Analysis</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Edge-Level Privacy</head><p>In the following, we provide a formal analysis of GAP's edge-level privacy guarantees at training and inference stages.</p><p>Training privacy. The following arguments establish the DP guarantees of the PMA mechanism and the GAP training algorithm. The detailed proofs can be found in Appendix A. Proposition 2 shows that the privacy cost grows with the number of hops (ùêæ), but is independent of the number of training steps thanks to our GAP architecture.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Theorem 1. Given the maximum hop</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Inference privacy.</head><p>A major advantage of GAP is that querying the model at inference time preserves DP without consuming additional privacy budget. This is true for both the transductive and the inductive settings:</p><p>‚Ä¢ Transductive setting: In this setting, the inference is performed by feeding the privately trained CM with the cached aggregations of the test nodes, which have already been computed privately at training time. As this computation does not query the private graph structure and only postprocesses the previous DP operations, due to the robustness of DP to post-processing, GAP provides inference privacy with no additional cost.</p><p>‚Ä¢ </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Node-Level Privacy</head><p>Equipped with aggregation perturbation, the proposed GAP architecture guarantees edge-level privacy by default. However, it is readily extensible to provide node-level privacy guarantees as well, providing that we have bounded-degree graphs, i.e., the degree of each node should be bounded above by a constant ùê∑. This allows to bound the sensitivity of the aggregation function in the PMA mechanism when adding/removing a node, as in this case each node can influence at most ùê∑ other nodes. If the input graph has nodes with very high degrees, we can use neighbor sampling (as proposed in <ref type="bibr" target="#b6">[7]</ref>) to randomly sample at most ùê∑ neighbors per node.</p><p>For bounded-degree graphs, adding or removing a node corresponds (in the worst case) to adding or removing ùê∑ edges. Therefore, our PMA mechanism also ensures nodelevel privacy, albeit with increased privacy costs compared to the edge-level setting (see Theorem 2 below).</p><p>However, since the node features and labels are also private under node-level DP, both EM and CM need to be trained privately as they access node features/labels. To this end, we can simply use standard DP-SGD <ref type="bibr" target="#b1">[2]</ref> or any other differentially private learning algorithm for pre-training the encoder as well as training CM with DP. In other words, steps 1 and 5 of Algorithm 2 must be done with DP instead of regular non-private training. This way, since each of the three GAP modules become node-level private, the entire GAP model, as an adaptive composition of several node-level private mechanisms, satisfies node-level DP. The formal node-level privacy Note that in Proposition 3, we cannot optimize ùõº in closed form as we do not know the precise form of ùúñ 1 (ùõº) and ùúñ 5 (ùõº). However, in our experiments, we numerically optimize the choice of ùõº on a per-case basis.</p><p>Inference privacy. The arguments stated for edge-level inference privacy also hold for node-level privacy. Note that in the inductive setting, the test graph should also have bounded degree for the node-level inference privacy guarantees to hold.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Discussion</head><p>Choice of aggregation function. In this paper, we used S as the default choice of aggregation function. Although other choices of aggregation functions are also possible, we empirically found that S is the most efficient choice to privatize, as its sensitivity does not depend on the size of the aggregation set (i.e., number of neighbors), which is itself a quantity that should be computed privately. For example, the calculation of both M and GCN <ref type="bibr" target="#b25">[26]</ref> aggregation functions depend on the node degrees, and thus requires additional privacy budget to be spent on perturbing node degrees. In any case, S is recognized as one of the most expressive aggregation functions in the GNN literature <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b47">47]</ref>.</p><p>Normalization instead of clipping. The PMA mechanism uses normalization to bound the effect of each individual feature on the S aggregation function. While clipping is more common in the private learning literature (e.g., gradient clipping in DP-SGD <ref type="bibr" target="#b1">[2]</ref>), we empirically found that normalization is a better choice for aggregation perturbation: CM is then trained on normalized data, which tends to facilitate learning. Normalizing the node embeddings is actually commonly done in non-private GNNs as well to stabilize training <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b50">50]</ref>.</p><p>Limitations. As the PMA mechanism adds random noise to the aggregation function, its utility naturally depends on the size of the node's aggregation set, i.e., the node's degree. Specifically, with a certain amount of noise, the more inbound neighbors a node has, the more accurate its noisy aggregated vector will be. This implies that graphs with higher average degree per node can tolerate larger noise in the aggregation function, and thus GAP can achieve a better privacy-accuracy trade-off on such graphs. Conversely, GAP's performance will suffer if the average degree of the graph is too low, requiring higher privacy budgets to achieve acceptable accuracy. Note however that this is an expected behavior: nodes with fewer inbound neighbors are more easily influenced by a change in their neighborhood compared to nodes with higher degrees, and thus the privacy of low-degree nodes is harder to preserve than high-degree ones. Furthermore, this limitation is not specific to GAP: it is shared by all DP algorithms, whose performance generally suffer from lack of sufficient data.</p><p>Edge-level vs. node-level privacy. While GAP can work in either edge-level or node-level privacy settings, it must be emphasized that the former setting is suitable only for the use cases where the node-level information (e.g, features or labels) is not sensitive or is publicly available (e.g., the vertically partitioned graph setting described in <ref type="bibr" target="#b44">[44]</ref>). Whenever nodelevel information is private as well (e.g., user profiles in a social network), however, edge-level privacy fails to provide appropriate privacy protection, and thus node-level privacy setting has to be enforced.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Experiments</head><p>In this section, we conduct extensive experiments to empirically evaluate GAP's privacy-accuracy performance and its resilience under privacy attacks. As GAP's privacy guarantees are the same under both transductive and inductive settings, we only focus on the former, which has also more pertinent use cases (e.g., social networks).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1">Datasets</head><p>We evaluate the proposed method on three publicly available node classification datasets, which are medium to large scale in terms of the number of nodes and edges:</p><p>Facebook <ref type="bibr" target="#b40">[40]</ref>. This dataset contains the anonymized Facebook social network between UIUC students collected in September 2005. Nodes represent Facebook users and edges indicate friendship. Each node (user) has the following attributes: student/faculty status, gender, major, minor, and housing status, and the task is to predict the class year of users.</p><p>Reddit <ref type="bibr" target="#b15">[16]</ref>. This dataset consist of a set of posts from the Reddit social network, where each node represents a post and an edge indicates if the same user commented on both posts. Node features are extracted based on the embedding of the post contents, and the task is to predict the community (subreddit) that a post belongs to.</p><p>Amazon <ref type="bibr" target="#b4">[5]</ref>. The largest dataset used in this paper represents Amazon product co-purchasing network, where nodes represent products sold on Amazon and an edge indicates if two products are purchased together. Node features are bag-of-words vectors of the product description followed by PCA, and the task is to predict the category of the products.</p><p>We preprocess the datasets by limiting the classes to those having 1k, 10k, and 100k nodes on Facebook, Reddit, and Amazon, respectively. We then randomly split the remaining nodes into training, validation, and test sets with 75/10/15% ratios, respectively. Table <ref type="table" target="#tab_4">1</ref> summarizes the statistics of the datasets after preprocessing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2">Competing Methods</head><p>Edge-level private methods. The following methods are evaluated under edge-level privacy:</p><p>‚Ä¢ GAP-EDP: Our proposed edge-level DP algorithm.</p><p>‚Ä¢ SAGE-EDP: This is the method of Wu et al. <ref type="bibr" target="#b44">[44]</ref> that uses the graph perturbation approach, with the popular Graph-SAGE architecture <ref type="bibr" target="#b15">[16]</ref> as its backbone GNN model. We perturb the graph's adjacency matrix using the Asymmetric Randomized Response (ARR) <ref type="bibr" target="#b20">[21]</ref>, which performs better than E R <ref type="bibr" target="#b44">[44]</ref> by limiting the output sparsity. ‚Ä¢ MLP: A simple MLP model that does not use the graph edges, and thus provides perfect edge-level privacy (ùúñ = 0).</p><p>Node-level private methods. We compare the following nodelevel private algorithms:</p><p>‚Ä¢ GAP-NDP: Our proposed node-level DP approach.</p><p>‚Ä¢ SAGE-NDP: This is the method of Daigavane et al. <ref type="bibr" target="#b6">[7]</ref> that adapts the standard DP-SGD method for 1-layer GNNs, with the same GraphSAGE architecture as its backbone model. Since this method does not inherently ensure inference privacy, as suggested by its authors, we add noise to the aggregation function based on its node-level sensitivity at test time and account for the additional privacy cost. ‚Ä¢ MLP-DP: Similar to MLP, but trained with DP-SGD so as to provide node-level DP without using the graph edges. We do not consider the approach of <ref type="bibr" target="#b31">[32]</ref> as it requires public graph data and is thus not directly comparable to the others.</p><p>Non-private methods. To quantify the accuracy loss of private approaches, we use the following non-private methods (ùúñ = ‚àû):</p><p>‚Ä¢ GAP-‚àû: a non-private counterpart of the GAP method, where we do not perturb the aggregations. ‚Ä¢ SAGE-‚àû: a non-private GraphSAGE model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.3">Experimental Setup</head><p>Model implementation details. For our GAP models (GAP-EDP, GAP-NDP, and GAP-‚àû), we set the number of MLP enc , MLP base , and MLP head layers to be 2, 1, and 1, respectively. We use concatenation as the C function (Eq. 11) and tune the number of hops ùêæ in {1, 2, . . . , 5}. For the GraphSAGE models (SAGE-EDP, SAGE-NDP, and SAGE-‚àû), we use the S aggregation function and tune the number of messagepassing layers in {1, 2, . . . , 5}, except for SAGE-NDP that only supports one message-passing layer. We use a 2-layer and a 1-layer MLP as preprocessing and post-processing before and after the message-passing layers, respectively. For the MLP baselines (MLP and MLP-DP), we set the number of layers to 3. In addition, for both the GAP-NDP and SAGE-NDP methods, we use randomized neighbor sampling to bound the maximum degree ùê∑ and search for the best ùê∑ within {100, 200, 300, 400}. For all methods, we set the number of hidden units to 16 (including the dimension of GAP's encoded representation) and use the SeLU activation function <ref type="bibr" target="#b26">[27]</ref> at every layer. Batch-normalization is used for all methods except the node-level private ones (GAP-NDP, SAGE-NDP, and MLP-DP), for which batch-normalization is not supported.</p><p>Training and evaluation details. We train the non-private and edge-level private methods using the Adam optimizer over 100 epochs with full-sized batches. For the node-level private algorithms (GAP-NDP, SAGE-NDP, MLP-DP), we use DP-Adam <ref type="bibr" target="#b14">[15]</ref> with maximum gradient norm set to 1, and train each model for 10 epochs with a batch size of 256, 2048, 4096 on Facebook, Reddit, and Amazon, respectively. For our GAP models (GAP-‚àû, GAP-EDP, and GAP-NDP), we use the same parameter setting for training both the encoder and classification modules. We train all the methods with a learning rate of 0.01 and repeat each combination of possible hyperparameter values 10 times. We pick the best performing model based on validation accuracy, and report the average test accuracy with 95% confidence interval calculated by bootstrapping with 1000 samples.</p><p>Privacy accounting and calibration. Privacy budget accounting is done via the Analytical Moments Accountant <ref type="bibr" target="#b43">[43]</ref>. We numerically calibrate the noise scale (i.e., the noise standard deviation ùúé divided by the sensitivity) of PMA (for GAP-EDP and GAP-NDP), ARR (for SAGE-EDP), DP-SGD (for GAP-NDP, SAGE-NDP, and MLP-DP) and the Gaussian mechanism (for inference privacy in SAGE-NDP) to achieve the desired (ùúñ, ùõø)-DP. We report results for several values of ùúñ, while ùõø is set to be smaller than the inverse number of private entities (i.e., edges for edge-level privacy, nodes for node-level privacy). For both GAP-NDP and SAGE-NDP, we use the same noise scale for perturbing the gradients (in DP-SGD) and the aggregations (in PMA and Gaussian mechanisms). Software and hardware. All the models are implemented in PyTorch <ref type="bibr" target="#b34">[35]</ref> using PyTorch-Geometric (PyG) <ref type="bibr" target="#b11">[12]</ref>. We use </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.4">Experimental Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.4.1">Trade-offs between Privacy and Accuracy</head><p>We first compare the accuracy of our proposed methods against the non-private, edge-level private, and node-level private baselines. We fix the privacy budget to ùúñ = 8 for the node-level private methods and ùúñ = 4 for the edge-level private ones (except for MLP, which does not use the graph structure and thus achieves ùúñ = 0). The results are presented in Table <ref type="table" target="#tab_5">2</ref>. We observe that in the non-private setting, the proposed GAP architecture is competitive with SAGE, with only a slight decrease in accuracy on Facebook and Amazon. Under both edge-level and node-level privacy settings, however, our proposed methods GAP-EDP and GAP-NDP significantly outperform their competitors. Particularly, under edge-level privacy, GAP-EDP's accuracy is roughly 26, 14, and 15 points higher than the best competitor over Facebook, Reddit, and Amazon, respectively. Under node-level privacy, our proposed GAP-NDP method outperforms the best performing competitor by approximately 13, 13, and 4 accuracy points, respectively. Next, to investigate how different methods perform under different privacy budgets, we vary ùúñ from 0.1 to 8 for edgelevel private methods and from 1 to 16 for node-level private algorithms and report the accuracy of the methods under each privacy budget. The result for both edge-level and node-level privacy settings is depicted in Figure <ref type="figure" target="#fig_6">6</ref>.</p><p>Under edge-level privacy (Figure <ref type="figure" target="#fig_6">6</ref>, left side), we observe that GAP-EDP consistently outperforms its direct competitor, SAGE-EDP, especially at lower privacy costs. The relative gap between GAP-EDP and SAGE-EDP is influenced by the average degree of the dataset. For example, on Facebook and https://github.com/yuxiangw/autodp Reddit with higher average degrees, SAGE-EDP requires a high privacy budget of ùúñ ‚â• 8 to achieve reasonable accuracy, but on Amazon, which has the lowest average degree, it cannot even beat the MLP baseline. In comparison, the accuracy of GAP-EDP approaches the non-private GAP-‚àû at much lower privacy budgets, and always performs better than a vanilla MLP. This is because SAGE-EDP perturbs the adjacency matrix, which is extremely high-dimensional and sparse, while GAP-EDP perturbs the aggregated node embeddings, which has much lower dimensions and is not sparse compared to the adjacency matrix. The amount of accuracy loss with respect to the non-private method also depends on the average degree of the graph. For example, on Reddit at ùúñ = 2, GAP-‚àû's accuracy is only 1 point higher than GAP-EDP's, while on Amazon at ùúñ = 8, GAP-EDP's accuracy fall behind GAP-‚àû by around 5 points. These observations are in line with our discussion of Section 6.</p><p>We can observe similar trends under node-level privacy (Figure <ref type="figure" target="#fig_6">6</ref>, right side). We see that our GAP-NDP method always performs on par or better than the MLP-DP baseline, and also significantly outperforms SAGE-NDP under all the considered privacy budgets. We attribute this to two factors: first, SAGE-NDP is limited to 1-layer models and thus cannot exploit higher-order aggregations; second, the naive noisy aggregation patch for supporting inference privacy severely hurts the performance of SAGE-NDP. As expected, since the node-level private GAP-NDP hides more information (e.g., node features, labels, and all the adjacent edges to a node) than the edge-level private GAP-EDP, it requires larger privacy budgets to achieve a reasonable accuracy. Still, the accuracy loss with respect to the non-private method is higher in the node-level private method as we have further information loss due to neighborhood sampling (to bound the graph's maximum degree) and gradient clipping (to bound the sensitivity in DP-SGD/Adam).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.4.2">Resilience Against Privacy Attacks</head><p>As mentioned above, the node-level private methods require a higher privacy budget than the edge-level private ones as they attempt to hide much more information. In order to assess the practical implications of choosing rather large privacy budgets (e.g., ùúñ = 8 in Table <ref type="table" target="#tab_5">2</ref>), we empirically measure the privacy guarantees of GAP-NDP and other node-level private methods by conducting node-level membership inference attack <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b32">33]</ref> as the most relevant adapted privacy attack to GNNs.</p><p>Attack overview. The attack is modeled as a binary classification task, where the goal is to infer whether an arbitrary node ùë£ is a member of the training set V ùëá of the target GNN. The key intuition is that due to overfitting, GNNs give more confident probability scores to training nodes than to test ones, which can be exploited by the attacker to distinguish members of the training set. Having access to a shadow graph dataset coming from the same distribution as the target graph, the attacker first trains a shadow GNN to mimic the behavior of the target GNN, but for which the membership ground truth is known. Then, the attacker trains an attack model over the probability scores of the shadow graph nodes and their corresponding membership labels. Finally, the attacker uses the trained attack model to infer the membership of the target graph nodes.</p><p>Attack settings. We follow the TSTF (train on subgraph, test on full graph) approach of <ref type="bibr" target="#b32">[33]</ref> for the node-level membership inference attack. Specifically, we consider a strong adversary with access to a shadow graph dataset with 1000 nodes per class, which are sampled uniformly at random from the target dataset. For the shadow model, we use the same architecture and hyperparameters as the target model (described in Section 7.3). Similar to prior work <ref type="bibr" target="#b32">[33]</ref>, we use a 3-layer MLP with 64 hidden units as the attack model, and use the area under the receiver operating characteristic curve (AUC) averaged over 10 runs as the evaluation metric.</p><p>Results. Table <ref type="table" target="#tab_6">3</ref> reports the mean AUC of the attack on different node-level private methods trained with the same setting as in Figure <ref type="figure" target="#fig_6">6</ref> (right). As we see, the attack is quite effective on the non-private methods (ùúñ = ‚àû), especially on Facebook and Amazon datasets. The success of the attack on each method mainly depends on its generalization gap (the difference between the training and test accuracy): the higher the generalization gap, the more confident the model is on the training nodes and the easier it is to distinguish them from the test nodes. Hence, the lower attack performance on the nonprivate SAGE method is due to its lower generalization gap compared to the other methods. Nevertheless, for all private GNN methods, we observe that DP with privacy budgets as large as ùúñ = 16 can effectively defend against the attack, reducing the AUC to about 50% (random baseline) on all datasets. This result is in line with the work of <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b30">31]</ref>,</p><p>showing that DP with large privacy budgets can still effectively mitigate realistic membership inference attacks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.4.3">Ablation Studies</head><p>Effectiveness of the encoder module (EM). In this experiment, we investigate the effect of EM on the accuracy/privacy performance of the proposed methods, GAP-EDP and GAP-NDP. We compare the case in which EM is used as usual with the case where we remove EM and just input the original node features to the aggregation module. The results under different privacy budgets are given in Figure <ref type="figure" target="#fig_7">7</ref>. We can observe that in all cases, the accuracy of GAP-EDP and GAP-NDP is higher with EM than without it. For example, leveraging EM results in a gain of around 20, 2, and 5 accuracy points for GAP-EDP with ùúñ = 1 on Facebook, Reddit, and Amazon datasets, respectively. GAP-NDP with EM also benefits from a gain of more than 10, 10, and 5 points with ùúñ = 4 on Facebook, Reedit, and Amazon datasets, respectively. As discussed in Section 4.2, the improved performance with EM is mainly due to the reduced dimensionality of the aggregation module's input, which leads to adding less noise to the aggregations. Also, the effect of EM is more significant on GAP-NDP, as the amount of noise injected into the aggregations is generally larger for node-level privacy, hence dimensionality reduction becomes more critical to mitigate the impact of noise.</p><p>Effect of the number of hops. In this experiment, we investigate how changing the number of hops ùêæ affects the accuracy/privacy performance of our proposed methods, GAP-EDP and GAP-NDP. We vary ùêæ within {1, 2, 3, 4, 5} and report the accuracy under different privacy budgets: ùúñ ‚àà {1, 4} for GAP-EDP and ùúñ ‚àà {8, 16} for GAP-NDP. The result is depicted in Figure <ref type="figure" target="#fig_8">8</ref>. We observe that both of our methods can effectively benefit from allowing multiple hops, but there is a trade-off in increasing the number of hops. As we increment ùêæ, the accuracy of both GAP-EDP and GAP-NDP method increase up to a point and then steady or decrease in almost  all cases. The reason is that with a larger ùêæ the model is able to utilize information from more distant nodes (all the nodes within the ùêæ-hop neighborhood of a node) for prediction, which can increase the final accuracy. However, as more hops are involved, the amount of noise in the aggregations is also increased, which adversely affects the model's accuracy. We can see that with the lower privacy budgets where the noise is more severe, both GAP-EDP and GAP-NDP achieve their peak accuracy at smaller ùêæ values. But as the privacy budget increases, the magnitude of the noise is reduced, enabling the models to benefit from larger ùêæ values.</p><p>Effect of the maximum degree. We now analyze the effect of ùê∑ on the performance of our node-level private method. We vary ùê∑ from 10 to 400 and report GAP-NDP's accuracy under two different privacy budgets ùúñ ‚àà {4, 16}. Figure <ref type="figure" target="#fig_9">9</ref> shows that the accuracy keeps growing with ùê∑ on Reddit (which has a high average degree), while on Facebook and Amazon (lower average degrees) the accuracy increases with ùê∑ up to a peak point, and drops afterwards. This is due to the trade-off between having more samples for aggregation and the amount of noise injected: the larger ùê∑, the fewer neighbors are excluded from the aggregations (i.e., less information loss), but on the other hand, the larger the sensitivity of the aggregation function, leading to more noise injection. We also observe that the accuracy gain as a result of increasing ùê∑ gets bigger as the privacy budget is increased from 5 to 20, since a higher privacy budget compensates for the higher sensitivity by reducing the amount of noise.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Conclusion</head><p>In this paper, we presented GAP, a privacy-preserving GNN architecture that ensures both edge-level and node-level differential privacy for training and inference over sensitive graph data. We used aggregation perturbation, where the Gaussian mechanism is applied to the output of the GNN's aggregation function, as a fundamental technique to achieve DP in our approach. We proposed a new GNN architecture tailored to the specifics of private learning over graphs, aiming to achieve better privacy-accuracy trade-offs while tackling the intricate challenges involved in the design of differentially private GNNs. Experimental results over real-world graph datasets showed that our approach achieves favorable privacy/accuracy trade-offs and significantly outperforms existing methods. Promising future directions include: (i) investigating robust aggregation functions that provide specific benefits for private learning; (ii) exploiting the redundancy of information in recursive aggregations to achieve tighter composition when the number of hops ùêæ gets large, which might prove useful for specific applications; (iii) extending the framework to other tasks and scenarios, such as link-wise prediction or learning over dynamic graphs; and (iv) conducting an extended theoretical analysis of differentially private GNNs, such as proving utility bounds and characterizing their expressiveness.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>FFigure 1 :</head><label>1</label><figDesc>Figure1: Schema of an unfolded 2-layer GNN taking an example graph as input. At each layer, every node aggregates its neighbors' embedding vectors (initially node features, e.g. X A for node A), which is then updated using a neural net into a new vector (e.g., H A ). Removing an arbitrary edge (here, the edge from node B to F) excludes the source node (B) from the aggregation set of the destination node (F). At the first layer, this will only alter the destination node's embedding, but this change is propagated to the neighboring nodes in the next layer. Node embeddings that are affected by the removal of edge (B,F) are indicated in red.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Comparison of DP learning with (a) conventional deep neural networks, and (b) graph neural networks.Given the trained model, the inference mechanism of a DNN is independent of the training data, so a DP learning algorithm implies a DP inference mechanism as well. With GNNs however, graph data is queried again at inference time, so the inference step requires specific attention to be made differentially private.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>CacheFigure 3 :</head><label>3</label><figDesc>Figure 3: Overview of GAP's architecture: (1) The encoder is trained using only node features (X) and labels (Y). (2)The encoded features are given to the aggregation module to compute private ùêæ-hop aggregations (here, ùêæ = 2) using the graph's adjacency matrix (A). (3) The classification module is trained over the private aggregations for label prediction.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: (a) Transductive learning: training and inference steps are conducted on the same graph, but different nodes are used for training and testing. Here, the blue nodes (A, D, and E) are used for training and the red nodes (B, C, and F) for inference. (b) Inductive learning: training and inference steps are performed on different graphs. Here, the left and right graphs are used for training and inference, respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Theorem 2 .Proposition 3 .</head><label>23</label><figDesc>analysis of GAP's training and inference is provided below. Training privacy. The node-level privacy guarantees of the PMA mechanism and the GAP training algorithm are as follows. Detailed proofs are deferred to Appendix A. Given the maximum degree ùê∑ ‚â• 1, maximum hop ùêæ ‚â• 1, and noise variance ùúé 2 , Algorithm 1 (PMA mechanism) satisfies node-level (ùõº, ùê∑ùêæ ùõº /2ùúé 2 )-RDP for any ùõº &gt; 1. For any ùõº &gt; 1, let encoder pre-training (Step 1 of Algorithm 2) and CM training (Step 5 of Algorithm 2) satisfy (ùõº, ùúñ 1 (ùõº))-RDP and (ùõº, ùúñ 5 (ùõº))-RDP, respectively. Then, for any 0 &lt; ùõø &lt; 1, maximum hop ùêæ ‚â• 1, maximum degree ùê∑ ‚â• 1, and noise variance ùúé 2 , Algorithm 2 satisfies node-level (ùúñ, ùõø)-DP with ùúñ = ùúñ 1 (ùõº) + ùúñ 5 (ùõº) + ùê∑ùêæ ùõº /2ùúé 2 + log(1/ ùõø) /ùõº-1.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Accuracy vs. privacy cost (ùúñ) of edge-level private algorithms (left) and node-level private methods (right).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: Effect of the encoder module (EM) on the accuracy/privacy performance of the edge-level private GAP-EDP (top) and the node-level private GAP-NDP (bottom).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 8 :</head><label>8</label><figDesc>Figure 8: Effect of the number of hops ùêæ on the accuracy/privacy performance of the edge-level private GAP-EDP (top) and the node-level private GAP-NDP (bottom).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 9 :</head><label>9</label><figDesc>Figure 9: Effect of the degree bound ùê∑ on the accuracy/privacy performance of the node-level private GAP-NDP method.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>normalize</figDesc><table><row><cell>6</cell><cell>end</cell></row><row><cell>7 end</cell><cell></cell></row><row><cell cols="2">8 return X(1) , . . . , X(ùêæ )</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>Inductive setting: In this case, first the new graph's node features are given to the encoder to obtain low-dimensional features, which are fed to AM to compute private aggregations. Then, the private aggregations are given to CM to obtain the final predictions. The only part where the private graph structure is queried is the AM, in which the PMA mechanism is applied to the new graph data, and thus the output is private. Furthermore, since the training and test graphs are disjoint, this application of the PMA mechanism is subject to the parallel composition of differentially private mechanisms, and thus it does not increase the privacy costs beyond that of training's. The other parts, the encoder and CM, perform graph-agnostic computations and only post-process previous DP outputs, leading to GAP ensuring inference privacy without extra privacy costs.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 1 :</head><label>1</label><figDesc>Overview of dataset statistics.</figDesc><table><row><cell>D</cell><cell>N</cell><cell>E</cell><cell>D</cell><cell>F</cell><cell>C</cell></row><row><cell>F</cell><cell>26,406</cell><cell>2,117,924</cell><cell>62</cell><cell>501</cell><cell>6</cell></row><row><cell>R</cell><cell>116,713</cell><cell>46,233,380</cell><cell>209</cell><cell>602</cell><cell>8</cell></row><row><cell>A</cell><cell>1,790,731</cell><cell>80,966,832</cell><cell>22</cell><cell>100</cell><cell>10</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 2 :</head><label>2</label><figDesc>Test accuracy of different methods on the three datasets. The best performing method in each category -noneprivate, edge-level DP and node-level DP -is highlighted.</figDesc><table><row><cell></cell><cell>M</cell><cell>ùúñ</cell><cell>F</cell><cell>R</cell><cell>A</cell></row><row><cell></cell><cell>GAP-‚àû</cell><cell>‚àû</cell><cell>80.0 ¬± 0.48</cell><cell>99.4 ¬± 0.02</cell><cell>91.2 ¬± 0.07</cell></row><row><cell>N</cell><cell>SAGE-‚àû</cell><cell>‚àû</cell><cell>83.2 ¬± 0.68</cell><cell>99.1 ¬± 0.01</cell><cell>92.7 ¬± 0.09</cell></row><row><cell>DP</cell><cell>GAP-EDP</cell><cell>4</cell><cell cols="3">76.3 ¬± 0.21 98.7 ¬± 0.03 83.8 ¬± 0.26</cell></row><row><cell></cell><cell>SAGE-EDP</cell><cell>4</cell><cell cols="3">50.4 ¬± 0.69 84.6 ¬± 1.63 68.3 ¬± 0.99</cell></row><row><cell>E</cell><cell>MLP</cell><cell>0</cell><cell cols="3">50.8 ¬± 0.17 82.4 ¬± 0.10 71.1 ¬± 0.18</cell></row><row><cell>DP</cell><cell>GAP-NDP</cell><cell>8</cell><cell cols="3">63.2 ¬± 0.35 94.0 ¬± 0.14 77.4 ¬± 0.07</cell></row><row><cell></cell><cell>SAGE-NDP</cell><cell>8</cell><cell cols="3">37.2 ¬± 0.96 60.5 ¬± 1.10 27.5 ¬± 0.83</cell></row><row><cell>N</cell><cell>MLP-DP</cell><cell>8</cell><cell cols="3">50.2 ¬± 0.25 81.5 ¬± 0.12 73.6 ¬± 0.05</cell></row><row><cell cols="6">the autodp library which implements analytical moments</cell></row><row><cell cols="6">accountant, and utilize Opacus [51] for training the node-level</cell></row><row><cell cols="6">private models with differential privacy. Experiments are</cell></row><row><cell cols="6">conducted on Sun Grid Engine with NVIDIA GeForce RTX</cell></row><row><cell cols="6">3090 and NVIDIA Tesla V100 GPUs, Intel Xeon 6238 CPUs,</cell></row><row><cell cols="2">and 32 GB RAM.</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 3 :</head><label>3</label><figDesc>Mean AUC of node membership inference attack. ùúñ = 2 ùúñ = 4 ùúñ = 8 ùúñ = 16 ùúñ = ‚àû</figDesc><table><row><cell>D</cell><cell cols="2">M ùúñ = 1 GAP-NDP 50.16 50.25 50.61 51.11 52.66 81.67</cell></row><row><cell>F</cell><cell cols="2">SAGE-NDP 50.25 50.20 50.23 50.17 50.20 62.49</cell></row><row><cell></cell><cell>MLP-DP</cell><cell>50.32 50.72 52.13 53.44 54.77 81.57</cell></row><row><cell></cell><cell cols="2">GAP-NDP 50.04 50.39 51.20 52.23 52.54 54.97</cell></row><row><cell>R</cell><cell cols="2">SAGE-NDP 49.97 49.97 49.95 50.00 49.98 50.05</cell></row><row><cell></cell><cell>MLP-DP</cell><cell>51.25 53.09 55.13 56.72 58.32 71.35</cell></row><row><cell></cell><cell cols="2">GAP-NDP 50.06 50.23 50.54 51.53 51.72 66.68</cell></row><row><cell>A</cell><cell cols="2">SAGE-NDP 49.93 49.93 49.93 49.92 49.97 59.41</cell></row><row><cell></cell><cell>MLP-DP</cell><cell>50.30 50.58 51.43 52.31 53.34 72.97</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgments</head><p>This work was supported by the <rs type="funder">European Commission</rs>'s <rs type="programName">Horizon 2020 Program ICT</rs><rs type="grantNumber">-48-2020</rs>, under grant number <rs type="grantNumber">951911</rs>, <rs type="projectName">AI4Media</rs> project. It was also supported by the <rs type="funder">French National Research Agency (ANR)</rs> through grant <rs type="grantNumber">ANR-20-CE23-0015</rs> (Project <rs type="projectName">PRIDE</rs>). <rs type="person">Ali Shahin Shamsabadi</rs> acknowledges support from <rs type="funder">The Alan Turing Institute</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_dhQuhys">
					<idno type="grant-number">-48-2020</idno>
					<orgName type="program" subtype="full">Horizon 2020 Program ICT</orgName>
				</org>
				<org type="funded-project" xml:id="_9wDrdpM">
					<idno type="grant-number">951911</idno>
					<orgName type="project" subtype="full">AI4Media</orgName>
				</org>
				<org type="funded-project" xml:id="_CySBc3t">
					<idno type="grant-number">ANR-20-CE23-0015</idno>
					<orgName type="project" subtype="full">PRIDE</orgName>
				</org>
			</listOrg>

			<div type="availability">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Availability</head><p>Our open-source implementation is publicly available on GitHub at https://github.com/sisaman/GAP.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Deferred Theoretical Arguments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.1 Proof of Theorem 1</head><p>To prove Theorem 1, we first establish the following lemma. Lemma 1. Let A (X, A) = A ùëá ‚Ä¢ X be the summation aggregation function. Assume that the input feature matrix X is row-normalized, such that ‚àÄùë£ ‚àà V : X ùë£ 2 = 1. Then, the edge-level sensitivity of the aggregation function is Œî A = 1.</p><p>Proof. Let A and A be the adjacency matrices of two arbitrary edge-level adjacent graphs. Therefore, there exist two nodes ùë¢ and ùë£ such that:</p><p>Without loss of generality, we can assume that A ùë£,ùë¢ = 1 and A ùë£,ùë¢ = 0. The goal is to bound the following quantity:</p><p>Let M = A (X, A) be the aggregation function output on A, and</p><p>be the ùëñ-th row of M corresponding to the aggregated vector for the ùëñ-th node. Analogously, let M = A (X, A ). Then:</p><p>2 )</p><p>which concludes the proof.</p><p>We can now prove Theorem 1.</p><p>Proof. The PMA mechanism applies the Gaussian mechanism on the output of the summation aggregation function A (X, A) = A ùëá ‚Ä¢ X. Based on Lemma 1, the edge-level sensitivity of A (‚Ä¢) is 1. Therefore, according to Corollary 3 of <ref type="bibr" target="#b28">[29]</ref>, each individual application of the Gaussian mechanism is (ùõº, ùõº /2ùúé 2 )-RDP. As PMA can be seen as an adaptive composition of ùêæ such mechanisms, based on Proposition 1 of <ref type="bibr" target="#b28">[29]</ref>, the total privacy cost is (ùõº, ùêæ ùõº /2ùúé 2 )-RDP.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2 Proof of Proposition 2</head><p>Proof. Under edge-level DP, only the adjacency information is protected. In Algorithm 2, the only step where the graph's adjacency is used is the application of the PMA mechanism (step 4), which according to Theorem 1 is (ùõº, ùêæ ùõº /2ùúé 2 )-RDP.</p><p>Since EM does not use the graph's edges and the classification module only post-process the private aggregated features without accessing the edges again, the total privacy cost remains (ùõº, ùêæ ùõº /2ùúé </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.3 Proof of Theorem 2</head><p>We first prove Lemma 2 and Lemma 3, and then prove Theorem 2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Lemma 2. Given any graph</head><p>be the summation aggregation function over the neighborhood ùîë ùë£ of any arbitrary node ùë£ ‚àà V. Assume that the input feature matrix X is row-normalized, such that ‚àÄùë£ ‚àà V :</p><p>Then, the node-level sensitivity of agg(.) is Œî agg = 1.</p><p>Proof. Consider a node-level adjacent graph G = (V , E , X ) formed by adding a single node ùëû to G. Hence, we have V = V ‚à™ {ùëû}, and X ùë£ = X ùë£ for every node ùë£ ‚àà V. Let A and A be the adjacency matrices of G and G respectively. The goal is to bound the following:</p><p>where ùîë ùë£ = {ùë¢ : A ùë¢,ùë£ = 1} and ùîë ùë£ = {ùë¢ : A ùë¢,ùë£ = 1} are the adjacent nodes to ùë£ in G and G , respectively. Fixing any arbitrary node ùë£ ‚àà V, we have the following two cases:</p><p>1. If ùëû ‚àà ùîë ùë£ , then we have ùîë ùë£ = ùîë ùë£ \ {ùëû}. Therefore:</p><p>2. If ùëû ‚àâ ùîë ùë£ , then we have ùîë ùë£ = ùîë ùë£ . Therefore:</p><p>Eq. 14 follows from the above two cases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Lemma 3.</head><p>Given any graph G = (V, E, X) with adjacency matrix A and maximum degree bounded above by some constant ùê∑ &gt; 0, assume that the feature matrix X is row-normalized, such that ‚àÄùë£ ‚àà V :</p><p>ùë¢ ‚ààùîë ùë£ X ùë¢ be the summation aggregation function over the neighborhood ùîë ùë£ of any arbitrary node ùë£ ‚àà V, and A (X, A) be a noisy aggregation mechanism which applies the Gaussian mechanism independently on the aggregated vector of every individual node as:</p><p>Proof. According to Lemma 2, the node-level sensitivity of agg ({X ùë¢ : ‚àÄùë¢ ‚àà ùîë ùë£ }) is 1, and thus each individual noisy aggregation query is (ùõº, ùõº /2ùúé 2 )-RDP. Although A is composed of ùëÅ = |V | such queries in total (one noisy aggregation per node), as G's maximum degree is bounded above by ùê∑, the embedding X ùë¢ of each node ùë¢ only contributes to maximum ùê∑ out of ùëÅ queries. As these ùëÅ queries are chosen non-adaptively and the noise of the Gaussian mechanism is independently drawn for each query, the maximum privacy cost of A (.) is equivalent to ùê∑ compositions of (ùõº, ùõº /2ùúé 2 )-RDP mechanisms, which based on Proposition 1 of <ref type="bibr" target="#b28">[29]</ref> is (ùê∑ùõº, ùõº /2ùúé 2 )-RDP. Now, we prove Theorem 2.</p><p>Proof. At each step of the PMA mechanism, the Gaussian mechanism is applied on every output row of the summation aggregation function A (X, A) = A ùëá ‚Ä¢ X. Based on Lemma 3, this mechanism is (ùõº, ùõºùê∑ /2ùúé 2 )-RDP. As PMA can be seen as an adaptive composition of ùêæ such mechanisms, based on Proposition 1 of <ref type="bibr" target="#b28">[29]</ref>, the total privacy cost is (ùõº, ùõºùê∑ùêæ /2ùúé 2 )-RDP.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.4 Proof of Proposition 3</head><p>Proof. Under node-level DP, all the information pertaining to an individual node, including its features, label, and edges, are private. The first step of Algorithm 2 privately processes the node features and labels so as to satisfy (ùõº, ùúñ 1 (ùõº))-RDP.</p><p>Steps 2 and 3 of the algorithm, however, expose the private node features, but then they are processed by steps 4 and 5, which are (ùõº, ùê∑ùêæ ùõº /2ùúé 2 )-RDP (according to Theorem 2) and (ùõº, ùúñ 5 (ùõº))-RDP, respectively. As a result, Algorithm 2 can be seen as an adaptive composition of an (ùõº, ùúñ 1 (ùõº))-RDP mechanism, an (ùõº, ùê∑ùêæ ùõº /2ùúé 2 )-RDP mechanism, and an (ùõº, ùúñ 5 (ùõº))-RDP mechanism. Therefore, based on Proposition 1 of <ref type="bibr" target="#b28">[29]</ref>, the total node-level privacy cost of Algorithm 2 is (ùõº, ùúñ 1 (ùõº) + ùê∑ùêæ ùõº /2ùúé 2 + ùúñ 5 (ùõº))-RDP, which ensures (ùúñ 1 (ùõº) + </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Computing graph neural networks: A survey from algorithms to accelerators</title>
		<author>
			<persName><forename type="first">Akshay</forename><surname>Sergi Abadal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jorge</forename><surname>Guirado</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eduard</forename><surname>L√≥pez-Alonso</surname></persName>
		</author>
		<author>
			<persName><surname>Alarc√≥n</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Computing Surveys (CSUR)</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1" to="38" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Deep learning with differential privacy</title>
		<author>
			<persName><forename type="first">Martin</forename><surname>Abadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andy</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ian</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Brendan Mcmahan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Mironov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kunal</forename><surname>Talwar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Li</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 ACM SIGSAC conference on computer and communications security</title>
		<meeting>the 2016 ACM SIGSAC conference on computer and communications security</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="308" to="318" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Adapting membership inference attacks to gnn for graph classification: Approaches and implications</title>
		<author>
			<persName><forename type="first">Wu</forename><surname>Bang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yang</forename><surname>Xiangwen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pan</forename><surname>Shirui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuan</forename><surname>Xingliang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2021 IEEE International Conference on Data Mining (ICDM)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Graph neural networks for covid-19 drug discovery</title>
		<author>
			<persName><forename type="first">Mark</forename><surname>Cheung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">F</forename><surname>Jos√©</surname></persName>
		</author>
		<author>
			<persName><surname>Moura</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2020 IEEE International Conference on Big Data (Big Data)</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="5646" to="5648" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Cluster-gcn: An efficient algorithm for training deep and large graph convolutional networks</title>
		<author>
			<persName><forename type="first">Wei-Lin</forename><surname>Chiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xuanqing</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Si</forename><surname>Si</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Samy</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cho-Jui</forename><surname>Hsieh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</title>
		<meeting>the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="257" to="266" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Principal neighbourhood aggregation for graph nets</title>
		<author>
			<persName><forename type="first">Gabriele</forename><surname>Corso</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luca</forename><surname>Cavalleri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dominique</forename><surname>Beaini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pietro</forename><surname>Li√≤</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Petar</forename><surname>Veliƒçkoviƒá</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Node-level differentially private graph neural networks</title>
		<author>
			<persName><forename type="first">Ameya</forename><surname>Daigavane</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gagan</forename><surname>Madan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aditya</forename><surname>Sinha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abhradeep</forename><surname>Guha Thakurta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gaurav</forename><surname>Aggarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Prateek</forename><surname>Jain</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2111.15521</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Dynamic spatial-temporal graph convolutional neural networks for traffic forecasting</title>
		<author>
			<persName><forename type="first">Zulong</forename><surname>Diao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dafang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yingru</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kun</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shaoyao</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI conference on artificial intelligence</title>
		<meeting>the AAAI conference on artificial intelligence</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="890" to="897" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Quantifying privacy leakage in graph embedding</title>
		<author>
			<persName><forename type="first">Vasisht</forename><surname>Duddu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Antoine</forename><surname>Boutet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Virat</forename><surname>Shejwalkar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">MobiQuitous 2020 -17th EAI International Conference on Mobile and Ubiquitous Systems: Computing, Networking and Services, MobiQuitous &apos;20</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="76" to="85" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Differential privacy: A survey of results</title>
		<author>
			<persName><forename type="first">Cynthia</forename><surname>Dwork</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on theory and applications of models of computation</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="1" to="19" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Calibrating noise to sensitivity in private data analysis</title>
		<author>
			<persName><forename type="first">Cynthia</forename><surname>Dwork</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Frank</forename><surname>Mcsherry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kobbi</forename><surname>Nissim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Theory of cryptography conference</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="265" to="284" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Fast graph representation learning with PyTorch Geometric</title>
		<author>
			<persName><forename type="first">Matthias</forename><surname>Fey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jan</forename><forename type="middle">E</forename><surname>Lenssen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR Workshop on Representation Learning on Graphs and Manifolds</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Sign: Scalable inception graph neural networks</title>
		<author>
			<persName><forename type="first">Emanuele</forename><surname>Fabrizio Frasca</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Davide</forename><surname>Rossi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Eynard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Chamberlain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Federico</forename><surname>Bronstein</surname></persName>
		</author>
		<author>
			<persName><surname>Monti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML 2020 Workshop on Graph Representation Learning and Beyond</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Objectgraphs: Using objects and a graph convolutional network for the bottom-up recognition and explanation of events in video</title>
		<author>
			<persName><forename type="first">Nikolaos</forename><surname>Gkalelis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andreas</forename><surname>Goulas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Damianos</forename><surname>Galanopoulos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vasileios</forename><surname>Mezaris</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="3375" to="3383" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Differentially private optimization algorithms for deep neural networks</title>
		<author>
			<persName><forename type="first">Roan</forename><surname>Gylberth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Risman</forename><surname>Adnan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Setiadi</forename><surname>Yazid</surname></persName>
		</author>
		<author>
			<persName><surname>Basaruddin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Advanced Computer Science and Information Systems (ICACSIS)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2017">2017. 2017</date>
			<biblScope unit="page" from="387" to="394" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Inductive representation learning on large graphs</title>
		<author>
			<persName><forename type="first">Rex</forename><surname>William L Hamilton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jure</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 31st International Conference on Neural Information Processing Systems</title>
		<meeting>the 31st International Conference on Neural Information Processing Systems</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1025" to="1035" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Representation learning on graphs: Methods and applications</title>
		<author>
			<persName><forename type="first">Rex</forename><surname>William L Hamilton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jure</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Data Engineering Bulletin</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Accurate estimation of the degree distribution of private networks</title>
		<author>
			<persName><forename type="first">Michael</forename><surname>Hay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gerome</forename><surname>Miklau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Jensen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Ninth IEEE International Conference on Data Mining</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2009">2009. 2009</date>
			<biblScope unit="page" from="169" to="178" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Stealing links from graph neural networks</title>
		<author>
			<persName><forename type="first">Xinlei</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jinyuan</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Backes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Neil</forename><surname>Zhenqiang Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yang</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">30th {USENIX} Security Symposium ({USENIX} Security 21)</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Node-level membership inference attacks against graph neural networks</title>
		<author>
			<persName><forename type="first">Xinlei</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rui</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yixin</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Backes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yun</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yang</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2102.05429</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Communication-Efficient triangle counting under local differential privacy</title>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Imola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Takao</forename><surname>Murakami</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kamalika</forename><surname>Chaudhuri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">31st USENIX Security Symposium (USENIX Security 22)</title>
		<meeting><address><addrLine>Boston, MA</addrLine></address></meeting>
		<imprint>
			<publisher>USENIX Association</publisher>
			<date type="published" when="2022-08">August 2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Auditing differentially private machine learning: How private is private sgd</title>
		<author>
			<persName><forename type="first">Matthew</forename><surname>Jagielski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><forename type="middle">R</forename><surname>Ullman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alina</forename><surname>Oprea</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Advances in Neural Information Processing (NeurIPS), Virtual Event</title>
		<meeting>the Advances in Neural Information Processing (NeurIPS), Virtual Event</meeting>
		<imprint>
			<date type="published" when="2020-12">December 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Evaluating differentially private machine learning in practice</title>
		<author>
			<persName><forename type="first">Bargav</forename><surname>Jayaraman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Evans</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">28th USENIX Security Symposium (USENIX Security 19)</title>
		<meeting><address><addrLine>Santa Clara, CA</addrLine></address></meeting>
		<imprint>
			<publisher>USENIX Association</publisher>
			<date type="published" when="2019-08">August 2019</date>
			<biblScope unit="page" from="1895" to="1912" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Graph neural network for traffic forecasting: A survey</title>
		<author>
			<persName><forename type="first">Weiwei</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiayun</forename><surname>Luo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Expert Systems with Applications</title>
		<imprint>
			<biblScope unit="page">117921</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Molecular graph convolutions: moving beyond fingerprints</title>
		<author>
			<persName><forename type="first">Steven</forename><surname>Kearnes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Mccloskey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marc</forename><surname>Berndl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vƒ≥ay</forename><surname>Pande</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Patrick</forename><surname>Riley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of computer-aided molecular design</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="595" to="608" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Semi-supervised classification with graph convolutional networks</title>
		<author>
			<persName><forename type="first">Thomas</forename><forename type="middle">N</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Max</forename><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Self-normalizing neural networks</title>
		<author>
			<persName><forename type="first">G√ºnter</forename><surname>Klambauer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Unterthiner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andreas</forename><surname>Mayr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sepp</forename><surname>Hochreiter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 31st international conference on neural information processing systems</title>
		<meeting>the 31st international conference on neural information processing systems</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="972" to="981" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Gated graph sequence neural networks</title>
		<author>
			<persName><forename type="first">Yujia</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Zemel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marc</forename><surname>Brockschmidt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Tarlow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICLR&apos;16</title>
		<meeting>ICLR&apos;16</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">R√©nyi differential privacy</title>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Mironov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE 30th Computer Security Foundations Symposium (CSF)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2017">2017. 2017</date>
			<biblScope unit="page" from="263" to="275" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Graphto-graph transformer for transition-based dependency parsing</title>
		<author>
			<persName><forename type="first">Alireza</forename><surname>Mohammadshahi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Henderson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: Findings</title>
		<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing: Findings</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2020-11">November 2020</date>
			<biblScope unit="page" from="3278" to="3289" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Adversary instantiation: Lower bounds for differentially private machine learning</title>
		<author>
			<persName><forename type="first">Milad</forename><surname>Nasr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shuang</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abhradeep</forename><surname>Thakurta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicolas</forename><surname>Papernot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicholas</forename><surname>Carlini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Symposium on Security and Privacy (S&amp;P)</title>
		<meeting>the IEEE Symposium on Security and Privacy (S&amp;P)<address><addrLine>San Francisco, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2021-05">May 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Releasing graph neural networks with differential privacy guarantees</title>
		<author>
			<persName><forename type="first">Thorben</forename><surname>Iyiola E Olatunji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Megha</forename><surname>Funke</surname></persName>
		</author>
		<author>
			<persName><surname>Khosla</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2109.08907</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Membership inference attack on graph neural networks</title>
		<author>
			<persName><forename type="first">Wolfgang</forename><surname>Iyiola E Olatunji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Megha</forename><surname>Nejdl</surname></persName>
		</author>
		<author>
			<persName><surname>Khosla</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Third IEEE International Conference on Trust, Privacy and Security in Intelligent Systems and Applications (TPS-ISA)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2021">2021. 2021</date>
			<biblScope unit="page" from="11" to="20" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Semi-supervised knowledge transfer for deep learning from private training data</title>
		<author>
			<persName><forename type="first">Nicolas</forename><surname>Papernot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mart√≠n</forename><surname>Abadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ulfar</forename><surname>Erlingsson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ian</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kunal</forename><surname>Talwar</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1610.05755</idno>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Pytorch: An imperative style, high-performance deep learning library</title>
		<author>
			<persName><forename type="first">Adam</forename><surname>Paszke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sam</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Francisco</forename><surname>Massa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Lerer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Bradbury</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gregory</forename><surname>Chanan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Trevor</forename><surname>Killeen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zeming</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Natalia</forename><surname>Gimelshein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luca</forename><surname>Antiga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alban</forename><surname>Desmaison</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andreas</forename><surname>Kopf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Edward</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zachary</forename><surname>Devito</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Martin</forename><surname>Raison</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alykhan</forename><surname>Tejani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sasank</forename><surname>Chilamkurthy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benoit</forename><surname>Steiner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lu</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junjie</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Soumith</forename><surname>Chintala</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>
			<persName><forename type="first">H</forename><surname>Wallach</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Beygelzimer</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><surname>Alch√©-Buc</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">E</forename><surname>Fox</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Garnett</surname></persName>
		</editor>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="8024" to="8035" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title/>
		<author>
			<persName><surname>Curran Associates</surname></persName>
		</author>
		<author>
			<persName><surname>Inc</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Deepinf: Social influence prediction with deep learning</title>
		<author>
			<persName><forename type="first">Jiezhong</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jian</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hao</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuxiao</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kuansan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jie</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</title>
		<meeting>the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="2110" to="2119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Differentially private analysis of graphs</title>
		<author>
			<persName><forename type="first">Sofya</forename><surname>Raskhodnikova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Encyclopedia of Algorithms</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Locally private graph neural networks</title>
		<author>
			<persName><forename type="first">Sina</forename><surname>Sajadmanesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Gatica-Perez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 ACM SIGSAC Conference on Computer and Communications Security</title>
		<meeting>the 2021 ACM SIGSAC Conference on Computer and Communications Security</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="2130" to="2145" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Going deeper with convolutions</title>
		<author>
			<persName><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yangqing</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pierre</forename><surname>Sermanet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Scott</forename><surname>Reed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dragomir</forename><surname>Anguelov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dumitru</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vincent</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Rabinovich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Social structure of facebook networks</title>
		<author>
			<persName><forename type="first">Amanda</forename><forename type="middle">L</forename><surname>Traud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><forename type="middle">J</forename><surname>Mucha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mason</forename><forename type="middle">A</forename><surname>Porter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physica A: Statistical Mechanics and its Applications</title>
		<imprint>
			<biblScope unit="volume">391</biblScope>
			<biblScope unit="issue">16</biblScope>
			<biblScope unit="page" from="4165" to="4180" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Graph attention networks</title>
		<author>
			<persName><forename type="first">Petar</forename><surname>Veli ƒå Kovi ƒÜ</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guillem</forename><surname>Cucurull</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arantxa</forename><surname>Casanova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adriana</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pietro</forename><surname>Lio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1710.10903</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">A review on graph neural network methods in financial applications</title>
		<author>
			<persName><forename type="first">Jianian</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanghua</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rui</forename><surname>Song</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2111.15367</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Subsampled renyi differential privacy and analytical moments accountant</title>
		<author>
			<persName><forename type="first">Yu-Xiang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Borja</forename><surname>Balle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shiva</forename><surname>Prasad Kasiviswanathan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Second International Conference on Artificial Intelligence and Statistics</title>
		<editor>
			<persName><forename type="first">Kamalika</forename><surname>Chaudhuri</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Masashi</forename><surname>Sugiyama</surname></persName>
		</editor>
		<meeting>the Twenty-Second International Conference on Artificial Intelligence and Statistics</meeting>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2019-04">Apr 2019</date>
			<biblScope unit="volume">89</biblScope>
			<biblScope unit="page" from="16" to="18" />
		</imprint>
	</monogr>
	<note>Proceedings of Machine Learning Research</note>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">Linkteller: Recovering private edges from graph neural networks via influence analysis</title>
		<author>
			<persName><forename type="first">Fan</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yunhui</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ce</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bo</forename><surname>Li</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2108.06504</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Simplifying graph convolutional networks</title>
		<author>
			<persName><forename type="first">Felix</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amauri</forename><surname>Souza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tianyi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Fifty</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tao</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kilian</forename><surname>Weinberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on machine learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="6861" to="6871" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">A comprehensive survey on graph neural networks</title>
		<author>
			<persName><forename type="first">Zonghan</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shirui</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fengwen</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guodong</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chengqi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Philip</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural Networks and Learning Systems</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">How powerful are graph neural networks</title>
		<author>
			<persName><forename type="first">Keyulu</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weihua</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefanie</forename><surname>Jegelka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Representation learning on graphs with jumping knowledge networks</title>
		<author>
			<persName><forename type="first">Keyulu</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chengtao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yonglong</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tomohiro</forename><surname>Sonobe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ken-Ichi</forename><surname>Kawarabayashi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefanie</forename><surname>Jegelka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 35th International Conference on Machine Learning</title>
		<editor>
			<persName><forename type="first">Jennifer</forename><surname>Dy</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Andreas</forename><surname>Krause</surname></persName>
		</editor>
		<meeting>the 35th International Conference on Machine Learning<address><addrLine>Stockholmsm√§ssan, Stockholm Sweden</addrLine></address></meeting>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2018-07-15">10-15 Jul 2018</date>
			<biblScope unit="volume">80</biblScope>
			<biblScope unit="page" from="5453" to="5462" />
		</imprint>
	</monogr>
	<note>Proceedings of Machine Learning Research</note>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Graph convolutional neural networks for web-scale recommender systems</title>
		<author>
			<persName><forename type="first">Rex</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruining</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kaifeng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pong</forename><surname>Eksombatchai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><forename type="middle">L</forename><surname>Hamilton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</title>
		<meeting>the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="974" to="983" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Design space for graph neural networks</title>
		<author>
			<persName><forename type="first">Jiaxuan</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhitao</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<title level="m" type="main">Opacus: Userfriendly differential privacy library in PyTorch</title>
		<author>
			<persName><forename type="first">Ashkan</forename><surname>Yousefpour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Igor</forename><surname>Shilov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexandre</forename><surname>Sablayrolles</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Davide</forename><surname>Testuggine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Karthik</forename><surname>Prasad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mani</forename><surname>Malek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sayan</forename><surname>Ghosh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Akash</forename><surname>Bharadwaj</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jessica</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Graham</forename><surname>Cormode</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Mironov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2109.12298</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Link prediction based on graph neural networks</title>
		<author>
			<persName><forename type="first">Muhan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yixin</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="5165" to="5175" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Deep learning on graphs: A survey</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Knowledge &amp; Data Engineering</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">01</biblScope>
			<biblScope unit="page" from="249" to="270" />
			<date type="published" when="2022-01">jan 2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Graphmi: Extracting private graph data from graph neural networks</title>
		<author>
			<persName><forename type="first">Zaixi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qi</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhenya</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chengqiang</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chuanren</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Enhong</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Thirtieth International Joint Conference on Artificial Intelligence, ƒ≤CAI-21</title>
		<editor>
			<persName><forename type="first">Zhi-Hua</forename><surname>Zhou</surname></persName>
		</editor>
		<meeting>the Thirtieth International Joint Conference on Artificial Intelligence, ƒ≤CAI-21</meeting>
		<imprint>
			<date type="published" when="2021">8 2021</date>
			<biblScope unit="page" from="3749" to="3755" />
		</imprint>
	</monogr>
	<note>ternational Joint Conferences on Artificial Intelligence Organization</note>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Inference attacks against graph neural networks</title>
		<author>
			<persName><forename type="first">Zhikun</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Min</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Backes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yun</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yang</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">31st USENIX Security Symposium (USENIX Security 22)</title>
		<meeting><address><addrLine>Boston, MA</addrLine></address></meeting>
		<imprint>
			<publisher>USENIX Association</publisher>
			<date type="published" when="2022-08">August 2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Graph neural networks: A review of methods and applications</title>
		<author>
			<persName><forename type="first">Jie</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ganqu</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shengding</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhengyan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cheng</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhiyuan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lifeng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Changcheng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maosong</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AI Open</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="57" to="81" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
