<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Ontology population with deep learning-based NLP: a case study on the Biomolecular Network Ontology</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Ali</forename><surname>Ayadi</surname></persName>
							<email>ali.ayadi@unistra.fr</email>
							<affiliation key="aff0">
								<orgName type="laboratory" key="lab1">ICUBE/SDC Team</orgName>
								<orgName type="laboratory" key="lab2">UMR CNRS 7357)</orgName>
								<address>
									<addrLine>-Pole API BP 10413</addrLine>
									<postCode>67412</postCode>
									<settlement>Illkirch</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="laboratory" key="lab1">ICUBE/SDC Team</orgName>
								<orgName type="laboratory" key="lab2">UMR CNRS 7357)</orgName>
								<address>
									<addrLine>-Pole API BP 10413</addrLine>
									<postCode>67412</postCode>
									<settlement>Illkirch</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="laboratory" key="lab1">ICUBE/SDC Team</orgName>
								<orgName type="laboratory" key="lab2">UMR CNRS 7357)</orgName>
								<address>
									<addrLine>-Pole API BP 10413</addrLine>
									<postCode>67412</postCode>
									<settlement>Illkirch</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="laboratory" key="lab1">ICUBE/SDC Team</orgName>
								<orgName type="laboratory" key="lab2">UMR CNRS 7357)</orgName>
								<address>
									<addrLine>-Pole API BP 10413</addrLine>
									<postCode>67412</postCode>
									<settlement>Illkirch</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Ahmed</forename><surname>Samet</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory" key="lab1">ICUBE/SDC Team</orgName>
								<orgName type="laboratory" key="lab2">UMR CNRS 7357)</orgName>
								<address>
									<addrLine>-Pole API BP 10413</addrLine>
									<postCode>67412</postCode>
									<settlement>Illkirch</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="laboratory" key="lab1">ICUBE/SDC Team</orgName>
								<orgName type="laboratory" key="lab2">UMR CNRS 7357)</orgName>
								<address>
									<addrLine>-Pole API BP 10413</addrLine>
									<postCode>67412</postCode>
									<settlement>Illkirch</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="laboratory" key="lab1">ICUBE/SDC Team</orgName>
								<orgName type="laboratory" key="lab2">UMR CNRS 7357)</orgName>
								<address>
									<addrLine>-Pole API BP 10413</addrLine>
									<postCode>67412</postCode>
									<settlement>Illkirch</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="laboratory" key="lab1">ICUBE/SDC Team</orgName>
								<orgName type="laboratory" key="lab2">UMR CNRS 7357)</orgName>
								<address>
									<addrLine>-Pole API BP 10413</addrLine>
									<postCode>67412</postCode>
									<settlement>Illkirch</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">François</forename><surname>De Bertrand De Beuvron</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Cecilia</forename><surname>Zanni-Merk</surname></persName>
							<affiliation key="aff1">
								<orgName type="laboratory" key="lab1">LITIS Laboratory</orgName>
								<orgName type="laboratory" key="lab2">Fédération CNRS Norm@STIC FR 3638</orgName>
								<orgName type="institution" key="instit1">INSA de Rouen Normandie</orgName>
								<orgName type="institution" key="instit2">Avenue de l&apos;Université</orgName>
								<address>
									<postCode>76801</postCode>
									<settlement>Saint-Etienne-du Rouvray</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="laboratory" key="lab1">LITIS Laboratory</orgName>
								<orgName type="laboratory" key="lab2">Fédération CNRS Norm@STIC FR 3638</orgName>
								<orgName type="institution" key="instit1">INSA de Rouen Normandie</orgName>
								<orgName type="institution" key="instit2">Avenue de l&apos;Université</orgName>
								<address>
									<postCode>76801</postCode>
									<settlement>Saint-Etienne-du Rouvray</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="laboratory" key="lab1">LITIS Laboratory</orgName>
								<orgName type="laboratory" key="lab2">Fédération CNRS Norm@STIC FR 3638</orgName>
								<orgName type="institution" key="instit1">INSA de Rouen Normandie</orgName>
								<orgName type="institution" key="instit2">Avenue de l&apos;Université</orgName>
								<address>
									<postCode>76801</postCode>
									<settlement>Saint-Etienne-du Rouvray</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="laboratory" key="lab1">LITIS Laboratory</orgName>
								<orgName type="laboratory" key="lab2">Fédération CNRS Norm@STIC FR 3638</orgName>
								<orgName type="institution" key="instit1">INSA de Rouen Normandie</orgName>
								<orgName type="institution" key="instit2">Avenue de l&apos;Université</orgName>
								<address>
									<postCode>76801</postCode>
									<settlement>Saint-Etienne-du Rouvray</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">¸ois</forename><surname>De Bertrand De Beuvron</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory" key="lab1">ICUBE/SDC Team</orgName>
								<orgName type="laboratory" key="lab2">UMR CNRS 7357)</orgName>
								<address>
									<addrLine>-Pole API BP 10413</addrLine>
									<postCode>67412</postCode>
									<settlement>Illkirch</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="laboratory" key="lab1">ICUBE/SDC Team</orgName>
								<orgName type="laboratory" key="lab2">UMR CNRS 7357)</orgName>
								<address>
									<addrLine>-Pole API BP 10413</addrLine>
									<postCode>67412</postCode>
									<settlement>Illkirch</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="laboratory" key="lab1">ICUBE/SDC Team</orgName>
								<orgName type="laboratory" key="lab2">UMR CNRS 7357)</orgName>
								<address>
									<addrLine>-Pole API BP 10413</addrLine>
									<postCode>67412</postCode>
									<settlement>Illkirch</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="laboratory" key="lab1">ICUBE/SDC Team</orgName>
								<orgName type="laboratory" key="lab2">UMR CNRS 7357)</orgName>
								<address>
									<addrLine>-Pole API BP 10413</addrLine>
									<postCode>67412</postCode>
									<settlement>Illkirch</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Ontology population with deep learning-based NLP: a case study on the Biomolecular Network Ontology</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">1CAB05B38EDCF922F902DD26F968E8CC</idno>
					<idno type="DOI">10.1016/j.procs.2019.09.212</idno>
					<note type="submission">Submitted on 15 Oct 2019</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-04-12T14:51+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Ontology population</term>
					<term>Knowledge acquisition</term>
					<term>Natural language processing</term>
					<term>Deep learning</term>
					<term>Biomolecular Network Ontology Ontology population</term>
					<term>Knowledge acquisition</term>
					<term>Natural language processing</term>
					<term>Deep learning</term>
					<term>Biomolecular Network Ontology</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>come from teaching and research institutions in France or abroad, or from public or private research centers. L'archive ouverte pluridisciplinaire</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Complex biomolecular networks include a series of networked complex systems ranging from genomic and transcriptomic to proteomic and metabolomic ones <ref type="bibr" target="#b0">[1]</ref>. For studying these complex biomolecular systems, we represent them as networks in which the nodes represent the entities of the complex system (genes, proteins, metabolites, etc.),</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Complex biomolecular networks include a series of networked complex systems ranging from genomic and transcriptomic to proteomic and metabolomic ones <ref type="bibr" target="#b0">[1]</ref>. For studying these complex biomolecular systems, we represent them as networks in which the nodes represent the entities of the complex system (genes, proteins, metabolites, etc.), and the edges represent the possible interactions among them (physical interactions or chemical transformations, etc.). These complex networks are considered as systems that dynamically evolve from a state to another so that the cell can adapt itself to changes in its environment <ref type="bibr" target="#b1">[2]</ref>. This issue has already been addressed in our previous works <ref type="bibr" target="#b1">[2]</ref>, where we develop an ontology, the Biomolecular Network Ontology (BNO) <ref type="foot" target="#foot_0">1</ref> , for modeling all the necessary biological knowledge to study and reason on complex biomolecular networks.</p><p>The BNO ontology has been built manually and under expert guidance, a process known as ontology learning. Indeed, we have already defined the concepts and relations of the BNO ontology, which represent the TBox of the ontology. This TBox consists of twenty-five classes and twelve properties. However, what we really need now is how to instantiate the BNO ontology from biological documents. In other words, how to populate the BNO ontology automatically (enrich its ABox). This process is called ontology population.</p><p>Moreover, with recent advances in high throughput biology techniques, intense research in molecular biology has led to major discoveries in cellular components, producing an important volume of knowledge about these components <ref type="bibr" target="#b1">[2]</ref>. This biological documents can be considered as a vital source of knowledge for understanding the behaviour of complex biomolecular networks. It would, therefore, be helpful to exploit this 'omic' knowledge to populate our ontology and more contribute to the understanding of the behaviour of complex biomolecular networks. However, this process is greatly dependent on the knowledge captured in the documents by the expert and professional biologists. Manual processing of biological documents is extremely expensive in time and resources, and prone to human error.</p><p>This paper investigates the problem of ontology population by proposing an ontology population system for knowledge acquisition from textual 'omic' resources, and automatically populate the BNO ontology. This system aims to identify and extract useful textual terms and assign them with respect to the predefined concepts (classes), instances (individuals), attributes (data properties) and relationships (object properties) of the BNO ontology. Our proposed ontology population system combines NLP techniques and deep learning. The originality of our proposal is to jointly exploit deep learning and natural language processing techniques to identify, extract and integrate new instances that populate our ontology from textual data. The preliminary results highlight the efficiency of our proposal for ontology population. Indeed, we have recently observed the emergence of deep learning techniques that provide significant and rapid progress in several domains, in particular in the process of deriving high-quality information from text. Despite its significant progress in recent years, deep learning is still not commonly used in the ontology population process.</p><p>The remaining of this paper is organised as follows. In Section 2 we present a brief introduction to existing studies that tackle the same problem but with different approaches. Then, we describe our proposed approach in Section 3. In section 4, we compare the obtained results with the proposed approach to those obtained with the user-centric method and evaluates its efficiency. Finally, we provide the conclusion and prospects of our work in Section 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related work</head><p>The purpose of this section is to provide a thorough and comprehensive overview of existing works that address the ontology population process.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Acquiring contextual information</head><p>Knowledge acquisition from raw input resources is required by ontology enrichment and ontology population. According to Ksiksi A. and Amiri H. <ref type="bibr" target="#b2">[3]</ref> and Harb et al. <ref type="bibr" target="#b3">[4]</ref>, we distinguish two types of methods for extracting domain specific terms, concepts and associations among them, linguistic techniques and statistical techniques. The first type considers the hypothesis that the grammatical structure reflects semantic dependencies. They aim to determine the semantic dependencies of the terms within a sentence. They use the grammatical function of a word within a sentence. These methods have the capacity to extract terms and the relations among them <ref type="bibr" target="#b3">[4]</ref>. The second type identifies the terms according to their distribution in the texts (using mutual information, tf-idf measurements). These statistical techniques are provided from data mining, machine learning and information retrieval. These techniques have the capacity to identify new candidate terms for the ontology population and enrichment, but cannot place them in the ontology, without a tiresome human intervention <ref type="bibr" target="#b2">[3]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Ontology population</head><p>Ontology population from texts has been widely used in the community of knowledge engineering. According to a comprehensive study in <ref type="bibr" target="#b4">[5]</ref>, we can distinguish three main categories of ontology population systems: (i) rulebased ontology population systems, (ii) ontology population systems that use machine learning, and (iii) ontology population systems that use statistical approaches. This classification is based on the techniques used to perform the task of extracting domain specific terms presented above.</p><p>-Rule-based ontology population systems: The rule-based ontology population systems use lexico-syntactic patterns to locate concept and relation instances in the text. Indeed, they use a set of rules (e.g. syntactic, grammatical, orthographic features) in combination with a list of dictionaries (e.g. the list of genes, cells, etc.) that are manually predefined by experts. In the era of systems biology, we can cite the works of Finkelstein M. et al. <ref type="bibr" target="#b5">[6]</ref>, Yangarber et al. <ref type="bibr" target="#b6">[7]</ref>, Ibrahim et al. <ref type="bibr" target="#b7">[8]</ref>, Harith et al. <ref type="bibr" target="#b8">[9]</ref>, Makki et al. <ref type="bibr" target="#b9">[10]</ref>, Ananiadou et al. <ref type="bibr" target="#b10">[11]</ref>, Ravikumar et al. <ref type="bibr" target="#b11">[12]</ref>, and Eftimov et al. <ref type="bibr" target="#b12">[13]</ref>. However, these methods require manual effort to build the extraction rules and validate the patterns. Moreover, the extracted patterns can be incorrect because of the lack of deep linguistic analysis. These semi-automatic systems do not provide solutions for consistency problems.</p><p>-Ontology population systems that use statistical approaches: This kind of ontology population systems uses statistical approaches, such as the works of Yoon et al. <ref type="bibr" target="#b13">[14]</ref>, Maynard et al. <ref type="bibr" target="#b14">[15]</ref>, and Tanev et al. <ref type="bibr" target="#b15">[16]</ref>. They are based on semantic similarity measurements and fitness functions for computing the textual similarity between the extracted terms and instances in the ontology. However, these approaches are not appropriate for all situations, for example, they cannot treat terms not covered by synonym dictionaries or are not suitable for understanding abbreviations, etc.</p><p>-Machine learning ontology population systems: These machine learning ontology population systems employ a classification model to identify candidate instances (supervised or unsupervised). They use machine learning algorithms to extract instances from unstructured text. Most of these approaches are based on the Learning Pattern by Language Processing (LP 2 ) algorithm for supervised learning based Support Vector Machine or on Lazy-NLP and First Order Inductive Learning (FOIL) algorithms. Among these works, Celjuska et al. <ref type="bibr" target="#b16">[17]</ref>, Etzioni et al. <ref type="bibr" target="#b17">[18]</ref>, Chun et al. <ref type="bibr" target="#b18">[19]</ref>, Jiang et al. <ref type="bibr" target="#b19">[20]</ref>, and Souili et al. <ref type="bibr" target="#b20">[21]</ref>.</p><p>-Deep learning ontology population systems: Only a few deep learning ontology population systems have been proposed in the literature. Most of them are based on some form of recurrent neural networks (RNN), such the works of Zeng et al. <ref type="bibr" target="#b21">[22]</ref>, Chen et al. <ref type="bibr" target="#b22">[23]</ref>, and Liu et al. <ref type="bibr" target="#b23">[24]</ref>. These systems are domain-dependent and require domainspecific tagged resources. However, in these techniques, no expert intervention is required and none of them performs consistency or redundancy checks. These systems are extensively discussed in <ref type="bibr" target="#b4">[5]</ref>.</p><p>There are also some other hybrid approaches of ontology population systems, such as those proposed by Torri et al. <ref type="bibr" target="#b24">[25]</ref> who combine both rule-based and ML methods, have shown good performance on gene-name recognition tasks, and the works of Specia et al. <ref type="bibr" target="#b25">[26]</ref> which employ knowledge-based and corpus-based methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Proposed methodology</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Architecture of the proposed methodology</head><p>Figure <ref type="figure" target="#fig_0">1</ref> shows a schematic representation of the steps involved in the proposed ontology population system and the diverse methods used in each step. The initial step describes the input of the proposed ontology population system which consists of two major components, (i) the set of biological documents representing the knowledge resources and (ii) the Biomolecular Network Ontology which is a domain ontology for describing the behaviour of complex biomolecular networks. The second step represents the knowledge extraction process which aims to identify the useful knowledge from the input biological documents and extract the candidate instances of concept, relations and attributes using the join help of the BNO ontology and the deep learning-based NLP techniques to successfully perform the extraction task. Finally, the last step aims to verify the redundancy and consistency of the extracted instances in relation to the existing stored knowledge in the BNO ontology. This step is ensured through expert intervention. Then, the filtered instances migrate to populate the BNO ontology. These steps are discussed in the following sections. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">The data acquisition process</head><p>This first step consists of searching web documents and local files related to the domain of our ontology. As our goal is to populate the BNO ontology, we use biological documents related to complex biomolecular networks. This initial step aims to prepare the biological documents for processing by the next phase, the preprocessing phase using NLP techniques. Thus, the two main components of this step are the Biomolecular Network Ontology which contains instances in each concept, and a set of heterogeneous documents related to the topic of our domain ontology.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">The knowledge extraction process</head><p>The knowledge extraction process consists of two main steps, the preprocessing data to analyse and identify the knowledge source, and the extraction process for the classification and of the candidate terms to the ontology population task. These steps are ensured by the natural language techniques.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.1.">Text preprocessing</head><p>The preprocessing step aims to transform raw data into an understandable format. In our context, this step aims to make the input biological documents easier to work with and present them into a form that is more predictable and analysable for the next deep learning task. In this step, we use basic natural language processing (NLP) tasks, such as, (i) the tokenization which covers the text segmentation and its lexical analysis. This task aims to split longer strings of text into smaller pieces. Larger paragraphs of text are converted into sentences, sentences are also converted into words, etc. This task relies on two pre-trained algorithms, the Punkt sentence tokenizer and Penn Treebank word tokenizer from NLTK <ref type="foot" target="#foot_1">2</ref> . And (ii) the normalisation which is an important task consisting of a series of related tasks for converting all text to the same case (lower or upper), removing punctuation, converting numbers to their word equivalents, removing the general stop words ("the", "a", etc.), etc. This task is done using a simple technique, the Min-Max normalization, which allows to specifically fit the data in a pre-defined boundary. It is often known as feature scaling where the values of a numeric range of a feature of data (a property) are reduced to a scale between 0 and 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.2.">Deep learning step</head><p>To accomplish this step, we draw inspiration from the works of Albukhita et al. <ref type="bibr" target="#b26">[27]</ref>. The preprocessing textual data are processed to produce a language model based on word embedding for all provided corpus. We use the Word2vec which is a popular algorithm to learn word embeddings using a shallow neural network. This technique allows representing words as vectors, usually in a space of a few hundred dimensions. The vector representing each word is obtained through an iterative algorithm starting from a large amount of text. The algorithm tries to place the vectors in space in order to approximate semantically close words and to move away semantically distant words.</p><p>The Word2vec algorithm <ref type="bibr" target="#b27">[28]</ref> can be described as follows: The first phase of Word2vec is to associate each word w of the prepared data with a randomly initialised vector denoted by v w ∈ R n . For each word w within each sentence of the training corpus, a window of words called context and denoted by c around the word w is considered. In our case, the size of this context is around 5 to 10 words. We define P(D = 1|c, w) the probability that a word c is in the context of another word w. This probability P(D = 1|c, w) is defined as the sigmoid <ref type="foot" target="#foot_2">3</ref> of the scalar product of the vectors of the two words as defined by equation <ref type="bibr" target="#b0">(1)</ref>.</p><formula xml:id="formula_0">P(D = 1|c, w) = 1 1 + e v c .v w (1)</formula><p>Conversely, we define P(D = 0|c, w), the probability that a word c do not belong to the context of another word w. P(D = 0|c, w) is defined by equation <ref type="bibr" target="#b1">(2)</ref>.</p><formula xml:id="formula_1">P(D = 1|c, w) = 1 -P(D = 0|c, w)<label>(2)</label></formula><p>Then, we define the optimization objective function L(V ) using equation <ref type="bibr" target="#b2">(3)</ref>.</p><formula xml:id="formula_2">L(V ) = arg max ∑ (w,c)∈A log P(D = 1|c, w) + ∑ (w,c )∈B P(D = 0|c , w)<label>(3)</label></formula><p>V denotes the set of all vectors v of the words w that describe our model and for which we are trying to find the optimal values in order to maximise the objective function L(V ). We have used the stochastic gradient descent which is the dominant method used to train deep learning models. This simple optimization procedure works by having the model make predictions on training data and using the error on the predictions to update the model in such a way as to reduce the error. The goal of the algorithm is to find model parameters (coefficients) that minimise the error of the model on the training dataset. It does this by making changes to the model that move it along a gradient or slope of errors down toward a minimum error value. This gradient descent approach is used to determine the optimal values of all the vectors v corresponding to the words w. More details about this gradient descent approach can be found in this post <ref type="foot" target="#foot_3">4</ref> . This algorithm provides vectors that bring together words that are semantically close ('are embedded nearby each other') and move away from words that are semantically distant. Indeed, semantically related words are frequently in the same context. Consequently, these vectors model the word embeddings. To do this, we used the Python open source Gensim<ref type="foot" target="#foot_4">5</ref> library for the implementation of the Word2vec algorithm. More details about this algorithm can be found in <ref type="bibr" target="#b27">[28]</ref>.</p><p>The candidate words embedding are obtained with the trained Word2vec algorithm are compared with the concept classes and properties of the BNO ontology. For each ontology terms (concept, property or attribute), a number of candidate vectors are computed using the vector embedding vectors of the instances. Indeed, this Word2vec is able to model and provide the relationship between predictive variables (input words) and a target variable (the target ontological terms). The recognition consists in computing the probability of each group of words and automatically aggregate it according to the target ontological terms. In other words, the seed concepts of the BNO ontology are used to organise the results of the Word2vec algorithm. This method considers also the inter-class similarities.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Ontology population process</head><p>The ontology population process has two main phases. The first one consists of the expert ontologist interventions for checking and controlling the redundancy and consistency of the suitable words embedding from the precedent deep learning-based NLP technique. During this phase, the ontologist evaluates the candidate terms and expresses his intention to modify the resulting propositions by applying some corrections (accept, reject, move, delete, create, split, merge, group, etc.). This task contributes to training our deep learning based-NLP method to better adapt its results to the ontologist's feedback. The second phase is the insertion of the new terms in their appropriate location in the domain ontology. This step consists of placing the candidate terms while preserving the coherence of the preestablished concepts and relations in the BNO ontology. This step is also based on the results provided by the above deep learning-based NLP technique. Indeed, the insertion of the new terms respects the classification done by the deep learning-based NLP technique. To perform this task, we use the Jean-Baptiste Lamy's packages <ref type="bibr" target="#b28">[29]</ref>. These packages, Owlready and Pythonskos, provide a large variety of methods for treating ontologies, in particular for the insertion of instances in the ontology.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Preliminary results</head><p>The experiment process is done by following the steps of the proposed approach. The first step is preparation for a set of textual documents related to complex biomolecular networks. The second one is the preparation of these biological texts and generate an instance classification. Then, the last one is to populate the BNO ontology and evaluate our proposed approach. It is important to note that the results presented in this section are preliminary results since the study is still underway.</p><p>Training and test data. To prepare a test set for checking our approach, we have adopted a small corpus consisting of 15 textual documents which have the characteristics needed for our work. These documents belong to the PubMed Central<ref type="foot" target="#foot_5">6</ref> (PMC), a free full-text archive of biomedical and life sciences journal literature. Indeed, the PubMed Central archive covers a large number of articles treating complex biomolecular networks. By doing the first search, i.e. typing "transittabilitty complex biomolecular networks", we obtain 16301 articles. Among them, we only select 15 articles in order to facilitate the manual selection of instances. This test set of 15 articles and the BNO ontology containing 18 instances represent the input of our approach. Furthermore, we treat also this small corpus so that humans can easily treat it by hand. We treat these different articles in order to obtain a set of structured information related to the domain of the transittability of complex biomolecular networks. Indeed, sentences in selected biological papers are sometimes long and may contain more than 400 words. Moreover, not all the information contained in these articles are useful for us. Some information may also be duplicated. Therefore, we did not select all the papers, but we treat them to only extract relevant sections related to our ontology topic necessary. Table <ref type="table" target="#tab_0">1</ref> shows an extract of the training corpus. For the sake of space, we did not cite the articles' references. Experiments. After selecting the test set, we implement our approach for identifying the candidate terms (future instances) from this corpus to populate the BNO ontology. The proposed approach was implemented in Python using the Natural Language Toolkit 7 (NLTK), and the Pandas, Mat plotlib, Seaborn and Numpy packages for performing the preprocessing and NLP tasks. The Word2vec algorithm is coded also in Python and is a part of the gensim package.</p><p>Our experiment was performed on a computer equipped by a processor Intel Core i5-4460 CPU @ 3.20GHz × 4 and a 15,5 Gb main memory. For training the SKIP-G model of the proposed deep learned-based NLP approach, we set the parameters as follows: the vector size is fixed at 250 for modeling the size of the generated vectors, the window is fixed at 7 words for representing the context around the keyword in the training model, the sample size is fixed to 10 -3 which is a threshold for occurrence of words.</p><p>To evaluate this proposed approach, we compare it with a user-centric ontology population that includes human at both processes of "Identification of instances" and "Classification of instances" with the same corpus. Therefore, we manually identified the candidate instances within the training corpus and also manually classify the obtained candidate instances according to the BNO ontology concepts. The number of identified instances is 1136 instances. All these steps have been performed by hand and with the assistance of an expert. Consequently, we divided our evaluation into two steps, the evaluation of the "Identification of instances" and the evaluation of the "Classification of instances". The effectiveness of both processes is evaluated by comparing the obtained results of our proposed approach with those generated manually with the user-centric method.</p><p>The measures of Precision and Recall from the information retrieval domain are used for performance evaluation <ref type="bibr" target="#b29">[30]</ref> considering the number of instances rightly classified. Precision measures the ratio between the number of instances correctly identified and the number of instances identified, in the process of "Identification of instances", and measures the ratio between the number of instances correctly classified and the number of instances classified in the second process of "Classification of instances". We compute it using equation <ref type="bibr" target="#b3">(4)</ref>.</p><formula xml:id="formula_3">Precision = Number o f candidate instance correctly identi f ied / classi f ied Number o f instance identi f ied / classi f ied (4)</formula><p>7 http://www.nltk.org/ Then, we use the Recall to measure the ratio between the number of instances correctly identified and the number of instances in the corpus, in the process of "Identification of instances", and the ratio between the number of instances correctly classified and the number of instances in the corpus,in the second process of "Classification of a instances". The Recall of the system is computed using equation <ref type="bibr" target="#b4">(5)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Recall =</head><p>Number o f candidate instance correctly identi f ied / classi f ied Number o f instance identi f ied in the corpus <ref type="bibr" target="#b4">(5)</ref> Using equation ( <ref type="formula">6</ref>), we compute the F-measure of both processes. This metric gives an harmonic mean of the Precision and Measure metrics.</p><formula xml:id="formula_4">F -measure = (2 * Precision * Recall) (Precision + Recall) (6)</formula><p>Evaluation and validation. The goal of this evaluation is to show the capabilities of the proposed approach to correctly identify and classify the candidate instances. To do this, we follow the evaluation of the ontology population from Faria et al. <ref type="bibr" target="#b29">[30]</ref>. This evaluation consists of computing the Precision and Recall measures of our proposed approach according to the user-centric experiment, for both processes of "Identification of instances" and "Classification of instances" using the same corpus.</p><p>1 -Identification of instances: Table <ref type="table" target="#tab_1">2</ref> illustrates the results of the evaluation of the "Identification of instances process" of our proposed approach corresponding to the first line of the Table (Automatic identification) with respect to the user-centric ontology population corresponding to the second line of the Table (Manual identification). The first row of the table shows the performance of instances identified by the proposed approach: the terms identified as instances are 960, those correctly identified are 656 from the 1250 instances in the corpus. These values correspond to a precision of 68.33%, a recall of 52.48% and an F-measure of 59.36%. The second experiment is conducted manually, the terms identified as instances are 1136, those correctly identified are 710 from the 1250 instances in the corpus. These values correspond to a precision of 62.50%, a recall of 56.80% and an F-measure of 59.51%. 2 -Classification of candidate instances: Table <ref type="table" target="#tab_2">3</ref> summarises the results of the evaluation of the Classification of candidate instances process. Manually, the number of instances classified are 550, those correctly classified are 500 from the 710 instances in the corpus (corresponding to the instances correctly identified from the first process). These values correspond to a precision of 90.90%, a recall of 70.42% and an F-measure of 79.36%. In the second experiment corresponding to our proposed approach, the number of instances classified are 484, those correctly classified are 435 from the 656 instances in the corpus (corresponding to the instances correctly identified from the first process). These values correspond to a precision of 89.87%, a recall of 66.31% and an F-measure of 76.31%.</p><p>The analysis of document contents in the testing corpus showed that it contains a lot of "unusable words", words that are often repeated and do not have important weight but have an adverse impact on our classification approach. Table <ref type="table" target="#tab_3">4</ref> presents some examples of instances classified incorrectly by the proposed approach and their key concepts. For example, the instance "TH" is interpreted by the proposed approach as a protein, however by definition the "TH" <ref type="foot" target="#foot_6">8</ref>is a gene that codes for the enzyme tyrosine hydroxylase. In this case, the proposed approach confounded tyrosine hydroxylase gene abbreviated as "TH" by tyrosine hydroxylase enzyme abbreviated as "TH-HZ" considering it as a protein rather than a gene. Another example is the "Cdx", which is manually classified as a transcription factor, is neither recognised as "Protein" or "Transcription factor". This is due to the "vague" and fuzzy properties of the candidate instance. The proposed approach cannot classify this instance because it is a particular case of protein family having some properties very close to both types of classes ("Protein" and "Transcription factor") and therefore it is not possible for our approach to distinguish between them. This is due to the fuzzy definition of the properties of the classes. To avoid these cases, additional properties have to be included or existing properties have to be omitted.  Based on the Precision, Recall and F-measure metrics, we can note that these first results are encouraging. Indeed, the approach we have proposed has been defined to facilitate the automatic population of the BNO ontology, while avoiding the manual efforts of document annotation and, instances identification and extraction. The proposed method can perform the population process from heterogeneous unstructured documents, and without manually tagging or annotating the documents by hand. This proposed approach automatically identified and classified new instances to populate the BNO ontology. These instances are coherent and were also validated by expert biologists. The proposed method may allow treating large corpus so we can benefit from measures of semantic relatedness. However, we need to test our approach using a more large dataset to enhance the performance and quality of the proposed approach. Indeed, choosing a large number of biological documents may impact the proposed approach performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusions and future work</head><p>Diverse ontology population systems have been proposed in the literature. Their limitations come from the fact that they cannot perform the population process from heterogeneous unstructured documents, and without manually tagging or annotating the documents by hand. However, the annotation is usually time-consuming and therefore generally expensive. In this paper, we presented a deep learning-based NLP method for ontology population from biological texts and apply it to instantiate the Biomolecular Network Ontology. The originality of our approach is that it mutually exploits the expressibility and trainability of deep learning and natural language processing techniques to identify, extract, classify and integrate new concepts and specialisations of relationships to enrich the BNO ontology from textual data. So, in contrast to traditional NLP methods which focus on the syntactic representation, the contribution of deep learning allows them to focus on semantic representation which enables him to distinguish certain contexts.</p><p>Our current work focuses on implementing a system prototype for providing the user with sophisticated interfaces to simplify the interaction among the different approach modules. These interfaces will facilitate the selection of corpus, the choice of the appropriate preprocessing techniques and the setting of the deep learning parameters. Our future work aims at improving the deep learning-based NLP approach in order to obtain more performance.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Architecture of the proposed methodology.</figDesc><graphic coords="5,61.22,74.31,419.64,270.13" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>The training corpus. Given are the title of the selected article, its authors, its printing year, and the number of retained words for training and evaluation.</figDesc><table><row><cell>Title</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 .</head><label>2</label><figDesc>Results of the evaluation of the identification of candidate instances process.</figDesc><table><row><cell>Task</cell><cell cols="4">Inst. in the corpus Inst. identified Inst. correctly identified Precision</cell><cell>Recall</cell><cell>F-measure</cell></row><row><cell>Automatic identification</cell><cell>1250</cell><cell>960</cell><cell>656</cell><cell>68.33%</cell><cell>52.48%</cell><cell>59.36%</cell></row><row><cell>Manual identification</cell><cell>1250</cell><cell>1136</cell><cell>710</cell><cell>62.50%</cell><cell>56.80%</cell><cell>59.51%</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 .</head><label>3</label><figDesc>Results of the evaluation of the classification of instances process.</figDesc><table><row><cell>Task</cell><cell cols="4">Inst. in the corpus Inst. classified Inst. correctly classified Precision</cell><cell>Recall</cell><cell>F-measure</cell></row><row><cell>Manual classification</cell><cell>710</cell><cell>550</cell><cell>500</cell><cell>90.90%</cell><cell>70.42%</cell><cell>79.36%</cell></row><row><cell>Automatic classification</cell><cell>656</cell><cell>484</cell><cell>435</cell><cell>89.87%</cell><cell>66.31%</cell><cell>76.31%</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 .</head><label>4</label><figDesc>Examples of instances missclassified by the proposed approach: the instance identifier, its predicted concept and its key concept corresponding to its correct BNO class.</figDesc><table><row><cell cols="2">Instance ID instance</cell><cell cols="2">Predicted concept Key concept</cell></row><row><cell>11</cell><cell>TH</cell><cell>Protein</cell><cell>Gene</cell></row><row><cell>25</cell><cell>Cdx</cell><cell>-</cell><cell>Transcription factor</cell></row><row><cell>67</cell><cell cols="2">DNA damage DNA</cell><cell>Stimuli</cell></row><row><cell>71</cell><cell>oncogene</cell><cell>Gene</cell><cell>-</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>https://github.com/AliAyadi/BNO-ontology-version-1.0</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>https://www.kaggle.com/nltkdata/punkt</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2"><p>https://en.wikipedia.org/wiki/Sigmoid function</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3"><p>https://machinelearningmastery.com/gradient-descent-for-machine-learning/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_4"><p>https://radimrehurek.com/gensim/about.html</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_5"><p>https://www.ncbi.nlm.nih.gov/pmc/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8" xml:id="foot_6"><p>https://ghr.nlm.nih.gov/gene/TH</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Complex biomolecular networks: challenges and opportunities</title>
		<author>
			<persName><forename type="first">Ernesto</forename><surname>Estrada</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Briefings in Functional Genomics</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="417" to="419" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">BNO-An ontology for understanding the transittability of complex biomolecular networks</title>
		<author>
			<persName><forename type="first">Ali</forename><surname>Ayadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cecilia</forename><surname>Zanni-Merk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Franc</forename><surname>De Beuvron</surname></persName>
		</author>
		<author>
			<persName><surname>¸ois De Beuvron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julie</forename><surname>Thompson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Saoussen</forename><surname>Krichen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Web Semantics</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Using Association Rules to Enrich Arabic Ontology</title>
		<author>
			<persName><forename type="first">Asma</forename><surname>Ksiksi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hamid</forename><surname>Amiri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Engineering, Technology and Applied Science Research</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="2914" to="2918" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Competence mining for collaborative virtual enterprise</title>
		<author>
			<persName><forename type="first">Ali</forename><surname>Harb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kafil</forename><surname>Hajlaoui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xavier</forename><surname>Boucher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Working Conference on Virtual Enterprises</title>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="351" to="358" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Text feature extraction based on deep learning: a review</title>
		<author>
			<persName><forename type="first">Hong</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiao</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yunlei</forename><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">EURASIP journal on wireless communications and networking</title>
		<imprint>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">211</biblScope>
			<date type="published" when="2017">2017. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Extracting semantic relationships between terms: Supervised vs. unsupervised methods</title>
		<author>
			<persName><forename type="first">Michal</forename><surname>Finkelstein-Landau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Emmanuel</forename><surname>Morin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Workshop on Ontological Engineering on the Global Information Infrastructure</title>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="71" to="80" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Description of the Proteus/PET system as used for MUC-7 ST</title>
		<author>
			<persName><forename type="first">Roman</forename><surname>Yangarber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ralph</forename><surname>Grishman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Seventh Message Understanding Conference (MUC-7): Proceedings of a Conference Held in Fairfax</title>
		<meeting><address><addrLine>Virginia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1998">1998. 1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Rules for ontology population from text of Malaysia medicinal herbs domain</title>
		<author>
			<persName><forename type="first">Zaharudin</forename><surname>Ibrahim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shahrul</forename><surname>Noah</surname></persName>
		</author>
		<author>
			<persName><surname>Azman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mahanem</forename><surname>Noor</surname></persName>
		</author>
		<author>
			<persName><surname>Mat</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Rough Sets and Knowledge Technology</title>
		<meeting><address><addrLine>Berlin, Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="386" to="394" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Automatic ontology-based knowledge extraction and tailored biography generation from the web</title>
		<author>
			<persName><forename type="first">Alani</forename><surname>Harith</surname></persName>
		</author>
		<author>
			<persName><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><surname>Sanghee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">E</forename><surname>Millard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><forename type="middle">J</forename><surname>Weal</surname></persName>
		</author>
		<author>
			<persName><surname>Hall</surname></persName>
		</author>
		<author>
			<persName><surname>Wendy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paul</forename><forename type="middle">H</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nigel</forename><forename type="middle">R</forename><surname>Shadbolt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Intelligent Systems</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="14" to="21" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Ontology population via NLP techniques in risk management</title>
		<author>
			<persName><forename type="first">Jawad</forename><surname>Makki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anne-Marie</forename><surname>Alquier</surname></persName>
		</author>
		<author>
			<persName><surname>Prince</surname></persName>
		</author>
		<author>
			<persName><surname>Violaine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Humanities and Social Science (IJHSS)</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="212" to="217" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Event extraction for systems biology by text mining the literature</title>
		<author>
			<persName><forename type="first">Sophia</forename><surname>Ananiadou</surname></persName>
		</author>
		<author>
			<persName><surname>Pyysalo</surname></persName>
		</author>
		<author>
			<persName><surname>Sampo</surname></persName>
		</author>
		<author>
			<persName><surname>Tsujii</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">B</forename><surname>Kell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trends in biotechnology</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="381" to="390" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Towards pathway curation through literature mining-a case study using PharmGKB</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">E</forename><surname>Ravikumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">B</forename><surname>Wagholikar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biocomputing</title>
		<imprint>
			<biblScope unit="volume">2014</biblScope>
			<biblScope unit="page" from="352" to="363" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A rule-based named-entity recognition method for knowledge extraction of evidence-based dietary recommendations</title>
		<author>
			<persName><forename type="first">Tome</forename><surname>Eftimov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Barbara</forename><surname>Seljak</surname></persName>
		</author>
		<author>
			<persName><surname>Koroušić</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Korošec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PloS one</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page">179488</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Ontology population from unstructured and semi-structured texts</title>
		<author>
			<persName><forename type="first">Hee</forename><forename type="middle">-</forename><surname>Yoon</surname></persName>
		</author>
		<author>
			<persName><surname>Geun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yong</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><surname>Park</surname></persName>
		</author>
		<author>
			<persName><surname>Seong-Bae</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Se-Young</forename><surname>Park</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Sixth International Conference on Advanced Language Processing and Web Information Technology (ALPIT 2007)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="135" to="139" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">NLP Techniques for Term Extraction and Ontology Population</title>
		<author>
			<persName><forename type="first">Diana</forename><surname>Maynard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yaoyong</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wim</forename><surname>Peters</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Weakly supervised approaches for ontology population</title>
		<author>
			<persName><forename type="first">Hristo</forename><surname>Tanev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bernardo</forename><surname>Magnini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">11th Conference of the European Chapter of the Association for Computational Linguistics</title>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Ontosophie: A semi-automatic system for ontology population from text</title>
		<author>
			<persName><forename type="first">David</forename><surname>Celjuska</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maria</forename><surname>Vargas-Vera</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Natural Language Processing (ICON)</title>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="volume">60</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Unsupervised namedentity extraction from the web: An experimental study</title>
		<author>
			<persName><forename type="first">Oren</forename><surname>Etzioni</surname></persName>
		</author>
		<author>
			<persName><surname>Cafarella</surname></persName>
		</author>
		<author>
			<persName><surname>Michael</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Doug</forename><surname>Downey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Popescu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Shaked</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Soderland</surname></persName>
		</author>
		<author>
			<persName><forename type="first">.</forename><forename type="middle">.</forename><surname>Yates</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial intelligence</title>
		<imprint>
			<biblScope unit="volume">165</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="91" to="134" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Extraction of gene-disease relations from Medline using domain dictionaries and machine learning</title>
		<author>
			<persName><forename type="first">Chun</forename><surname>Chun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hong</forename><forename type="middle">-</forename><surname>Woo</surname></persName>
		</author>
		<author>
			<persName><surname>Tsuruoka</surname></persName>
		</author>
		<author>
			<persName><surname>Yoshimasa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jin</forename><forename type="middle">-</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Shiba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Nagata</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Hishiki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">I</forename><surname>Tsujii</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Biocomputing 2006</title>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="4" to="15" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">A study of machine-learning-based approaches to extract clinical entities and their assertions from summaries</title>
		<author>
			<persName><forename type="first">M</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">T</forename><surname>Rosenbloom</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Denny</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Medical Informatics Association</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="601" to="606" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Natural Language Processing (NLP)-A Solution for Knowledge Extraction from Patent Unstructured Data</title>
		<author>
			<persName><surname>Souili</surname></persName>
		</author>
		<author>
			<persName><surname>Achille</surname></persName>
		</author>
		<author>
			<persName><surname>Cavalucci</surname></persName>
		</author>
		<author>
			<persName><surname>Denis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Franc</forename><surname>Rousselot</surname></persName>
		</author>
		<author>
			<persName><surname>¸ois</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Procedia engineering</title>
		<imprint>
			<biblScope unit="volume">131</biblScope>
			<biblScope unit="page" from="635" to="643" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Relation classification via convolutional deep neural network</title>
		<author>
			<persName><forename type="first">Daojian</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><surname>Kang</surname></persName>
		</author>
		<author>
			<persName><surname>Lai</surname></persName>
		</author>
		<author>
			<persName><surname>Siwei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhao</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Exploring deep belief network for chinese relation extraction</title>
		<author>
			<persName><forename type="first">Yu</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><surname>Li</surname></persName>
		</author>
		<author>
			<persName><surname>Wenjie</surname></persName>
		</author>
		<author>
			<persName><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIPS-SIGHAN Joint Conference on Chinese Language Processing</title>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Convolution neural network for relation extraction</title>
		<author>
			<persName><forename type="first">Chunyang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><surname>Wenbo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenhan</forename><surname>Chao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Che</forename></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Advanced Data Mining and Applications</title>
		<meeting><address><addrLine>Berlin, Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="231" to="242" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">BioTagger-GM: a gene/protein name recognition system</title>
		<author>
			<persName><forename type="first">Manabu</forename><surname>Torii</surname></persName>
		</author>
		<author>
			<persName><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><surname>Zhangzhi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cathy</forename><forename type="middle">H</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Medical Informatics Association</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="247" to="255" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">A hybrid approach for extracting semantic relations from texts</title>
		<author>
			<persName><forename type="first">Lucia</forename><surname>Specia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Enrico</forename><surname>Motta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2nd Workshop on Ontology Learning and Population: Bridging the Gap between Text and Knowledge</title>
		<meeting>the 2nd Workshop on Ontology Learning and Population: Bridging the Gap between Text and Knowledge</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="57" to="64" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Arabic ontology learning using deep learning</title>
		<author>
			<persName><forename type="first">Saeed</forename><surname>Albukhitan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tarek</forename><surname>Helmy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ahmed</forename><surname>Alnazer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Web Intelligence</title>
		<meeting>the International Conference on Web Intelligence</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1138" to="1142" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Distributed representations of words and phrases and their compositionality</title>
		<author>
			<persName><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><surname>Ilya</surname></persName>
		</author>
		<author>
			<persName><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><surname>Kai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="3111" to="3119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Owlready: Ontology-oriented programming in Python with automatic classification and high level constructs for biomedical ontologies</title>
		<author>
			<persName><forename type="first">Jean-Baptiste</forename><surname>Lamy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial intelligence in medicine</title>
		<imprint>
			<biblScope unit="volume">80</biblScope>
			<biblScope unit="page" from="11" to="28" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">A domain-independent process for automatic ontology population from text</title>
		<author>
			<persName><forename type="first">Carla</forename><surname>Faria</surname></persName>
		</author>
		<author>
			<persName><surname>Serra</surname></persName>
		</author>
		<author>
			<persName><surname>Ivo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rosario</forename><surname>Girardi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science of Computer Programming</title>
		<imprint>
			<biblScope unit="volume">95</biblScope>
			<biblScope unit="page" from="26" to="43" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
