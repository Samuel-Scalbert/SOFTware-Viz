<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Probabilistic forecasting of seasonal time series Combining clustering and classification for forecasting</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Colin</forename><surname>Leverger</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">IRISA</orgName>
								<address>
									<postCode>F-35042</postCode>
									<settlement>Rennes Cedex</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Orange Labs</orgName>
							</affiliation>
							<affiliation key="aff4">
								<orgName type="institution" key="instit1">Inria</orgName>
								<orgName type="institution" key="instit2">IRISA</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Thomas</forename><surname>Guyet</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution" key="instit1">Institut Agro</orgName>
								<orgName type="institution" key="instit2">IRISA</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Simon</forename><surname>Malinowski</surname></persName>
							<affiliation key="aff3">
								<orgName type="institution">Université Rennes</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Vincent</forename><surname>Lemaire</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Orange Labs</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Alexis</forename><surname>Bondu</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Orange Labs</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Laurence</forename><surname>Rozé</surname></persName>
							<affiliation key="aff5">
								<orgName type="institution" key="instit1">INSA/Inria</orgName>
								<orgName type="institution" key="instit2">IRISA</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Alexandre</forename><surname>Termier</surname></persName>
							<affiliation key="aff3">
								<orgName type="institution">Université Rennes</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Régis</forename><surname>Marguerie</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Orange Labs</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Probabilistic forecasting of seasonal time series Combining clustering and classification for forecasting</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">3C7851AEAE90EE145F44CD63E303B216</idno>
					<note type="submission">Submitted on 26 Aug 2021</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-04-12T14:49+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Time series</term>
					<term>Probabilistic forecasting</term>
					<term>Seasonality</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>published or not. The documents may come from teaching and research institutions in France or abroad, or from public or private research centers. L'archive ouverte pluridisciplinaire</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Forecasting the evolution of a temporal process is a critical research topic, with many challenging applications. In this work, we focus on time series forecasting and on data-driven forecasting models. A time series is a timestamped sequence of numerical values, and the goal of forecasting is, at a given point of time, to predict the next values of the time series based on previously observed values and possibly on other linked exogenous observations. Data-driven algorithms are used to predict future time series values from past data, with models that are able to adapt automatically to any type of incoming data. The data science challenge is to learn accurate and reliable forecasting models with as few human interventions as possible. Time series forecasting has many applications in medicine (for instance, to forecast blood glucose of a patient <ref type="bibr" target="#b0">[1]</ref>), in economy (for instance, to forecast macroeconomic variable changes <ref type="bibr" target="#b1">[2]</ref>), in the financial domain (forecasting financial time series <ref type="bibr" target="#b2">[3]</ref>), in electricity load <ref type="bibr" target="#b3">[4]</ref> or in industry (for instance, to forecast the server load <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b5">6]</ref>).</p><p>Time series forecasting algorithms provide information about possible situations in the future, and can be used to anticipate crucial decisions. Taking correct decisions requires anticipation and accurate forecasts. Unfortunately, these objectives are often contradictory. Indeed, the larger the forecasting horizon, the wider the range of expectable situations. In such case, a probabilistic forecasting algorithm is a powerful decision support tool, because it handles the uncertainty of the predictions. Probabilistic or density forecasting is a class of forecasting that provides intervals or probability distributions as outcomes of the forecasting. It is claimed in <ref type="bibr" target="#b6">[7]</ref> that, in recent years, probabilistic forecasts have become widely used. For instance, fan charts <ref type="bibr" target="#b7">[8]</ref>, highest density regions <ref type="bibr" target="#b8">[9]</ref> or functional data analysis <ref type="bibr" target="#b9">[10]</ref> enable to forecast ranges for possible values of future data.</p><p>We are particularly interested in time series that have some periodic regularities in their values. This kind of time series is said to be seasonal. For instance, time series related to human activities or natural phenomena are often seasonal, because they often exhibit daily regularities (also known as the circadian cycle). Knowing that a time series is seasonal is a valuable information that can help for forecasting. More specifically, learning the seasonal structures can help to generate longer-term predictions as it provides information about several seasons ahead.</p><p>Furthermore, seasonality of a time series gives a natural midterm forecasting horizon. Classical forecasting models (e.g., SARIMA <ref type="bibr" target="#b10">[11]</ref>) predict the future values of a given time series stepwise. The predicted values are used by further steps. At each step, there is then a risk of the error to be accumulated due to the recursive nature of the forecasts. The prediction of a whole season at once aims at spreading the forecasting error all along the season. Thus, we expect to forecast more accurately the salient part of a season that may lie in the middle of the season. More practically, the prediction of a whole season at once allows applications where such prediction is required to plan actions (e.g., to plan electricity production a day ahead, it is necessary to predict the consumption for the next 24 hours).</p><p>A second limitation of usual seasonal forecasting methods is the assumption that the seasons have the same shape, i.e., the values evolve in the same way over the season. The differences are with each other are due to noise and an additive constant. Nevertheless, most of the real seasonal time series often contain more than just one periodic pattern. For instance, daily connections to a given website exhibit different patterns for a weekday or for a Sunday for instance. This kind of structure cannot be well captured by classical forecasting methods.</p><p>In this article, we propose a generic framework called P-F2C (which stands for "Probabilistic Forecasting with Clustering and Classification") for seasonal time series forecasting. This approach extends the F2C framework <ref type="bibr" target="#b5">[6]</ref> (which stands for "Forecasting with Clustering and Classification"). P-F2C predicts future values for a complete season ahead at once, and this in a probabilistic manner. The P-F2C predictions may be used for supporting decision-making about the next season, handling the uncertainty in the future through the probabilistic presentation of the result.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Probabilistic seasonal time series forecasting</head><p>In this section, we introduce the notations and the problem of seasonal time series forecasting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Seasonal time series</head><p>A time series Y is an ordered sequence of values y 0:n = y 0 , . . . , y n-1 , where ∀i ∈ [0, n -1], y i ∈ R (univariate time series). n denotes the length of the observed time series.</p><p>Y is said to be (ideally) seasonal with season length s if there exists S = {S 1 , . . . , S p } a finite collection of p sub-series (of length s) called typical seasons</p><formula xml:id="formula_0">such that ∀i ∈ [0, m -1] , y (s×i):s×(i+1) = p j=1 σ i,j S j + ε i (<label>1</label></formula><formula xml:id="formula_1">)</formula><p>where m is the number of seasons in the time series, ε i ∈ R s represents a white noise and j σ i,j = 1 for all j. In other words, it means that for a seasonal time series Y , every season in Y is a weighted linear combination of typical seasons. Intuitively, this modelling of a typical season corresponds to additive measurements (e.g., consumption or traffic) for which the observed measure at time t is the sum of individual behaviours. In this case, a typical season corresponds to a typical behaviour of individuals, and the σ ,j represents the proportion of individuals of type j contributing to the observed measure.</p><p>In the following y i = y (s×i):s×(i+1) ∈ R s denotes the i-th season of Y .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Seasonal probabilistic forecasting</head><p>Let Y = y 0 , . . . , y n-1 be a seasonal time series, an s be its season length. Note that the season length of a time series (s) is estimated using Fisher's g-statistics <ref type="bibr" target="#b11">[12]</ref>. Without loss of generality, we assume that the length of a time series is a multiple of the season length, i.e., n = m×s. m denotes the number of seasons in the observed time series. The goal of seasonal probabilistic forecasting is to estimate</p><formula xml:id="formula_2">Pr(y * n:n+s | y (n-γ×s):n ) = Pr(y * m | y (m-γ):m )<label>(2)</label></formula><p>where y * m = y * n:n+s are the forecasts of the s next values (next season) of the observed time series, and y (m-γ):m = y (n-γ×s):n are the observed values of the last γ seasons. γ is a parameter given by the user.</p><p>We now propose an equivalent formulation of this problem considering our hypothesis on seasonal time series and we denote S = {S 1 , . . . , S p } the set of p typical seasons. Thus, Equation 2 can be rewritten as follows: The problem formulation given by Eq. 3 turns the difficult problem of Eq. 2 into two well-known tasks in time series analysis:</p><formula xml:id="formula_3">Pr(y * m | y (m-γ):m ) = S∈S Pr(y * m | S). Pr(S | y (m-γ):m )<label>(3)</label></formula><p>estimating the first term, Pr(y * m | S) leads to a problem of time series clustering. The problem is to both define the typical seasons, S, and to have the distributions of the season values. A clustering of the seasons (y i ) i=0:m of the observed time series identifies the typical seasons (clusters) and gives the required empirical distributions Pr(y, S).</p><p>estimating the second Pr(S | y m-γ:m ) is a probabilistic time series classification problem. This distribution can be empirically learnt from the past observations (y i-γ:i , S * i+1 ) i=γ:m where S * i denotes the empirical type of the i-th season obtained from the clustering assignment above. This problem formulation and remarks sketch the principles of a probabilistic seasonal time series forecasting. P-F2C is an implementation of these principles with a specific time series clustering.</p><p>3 The P-F2C forecaster P-F2C is composed of a clusterer that models the latent typical seasons and a classifier that predicts the next season type given the recent data. The forecaster is fit on the historical data of a time series. Then, the forecaster can be applied on the time series to predict the next season(s).</p><p>P-F2C clusterer is based on a probabilistic co-clustering model that is presented in the next section. In Section 3.2, we present how to use classical classifiers to predict the next seasons.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Coclustering of time series: a probabilistic model</head><p>Coclustering is a particular type of unsupervised algorithm which differs from regular clustering approaches by creating co-clusters. The objective of coclustering approaches consists in simultaneously partitioning the lines and the columns of an input data table. Thus, a co-cluster is defined as a set of examples belonging to both a group of rows and a group of columns. In <ref type="bibr" target="#b12">[13]</ref>, Boullé proposed an extension of co-clustering to tri-clustering in order to cluster time series. In this approach, a time series with an identifier C is seen as a set of couples (T, V ), where T is a timestamp and V a value of a measurement. Thus, the whole set of time series is a large set of points represented by triples (C, T, V ). The tri-clustering approach handles the three variables (C is categorical and T , V are numerical) to create homogeneous groups. A co-cluster gathers time series (group of identifiers) that have similar values during a certain interval of time. Contrary to the classical clustering approaches (e.g., KMeans, K-shape, GAK) <ref type="bibr" target="#b13">[14]</ref> that are based on the entire time series, the coclustering approach uses a local criterion. This difference is illustrated in Figure <ref type="figure" target="#fig_0">1:</ref> A distance based clustering (on the left) evaluates the distance between whole time series, in the co-clustering approaches, the distance is based on subintervals of the seasons. This enables to identify which parts of the season are the most discriminant. Besides, tri-clustering is robust to missing values in time series.</p><p>The tri-clustering approach of Boullé is based on the MODL framework <ref type="bibr" target="#b9">[10]</ref>. The MODL framework makes a constant piecewise assumption to estimate the joint distribution Pr(C, T, V ) by jointly discretising the variables T , V and grouping the time series identifiers of the variable C. The resulting model consists of the Cartesian product<ref type="foot" target="#foot_0">6</ref> of the three partitions of the variables C, T , V . This model can be represented as a 3D grid (see Figure <ref type="figure">2</ref>, on the left). In this 3D grid, if one considers a given group of time series (i.e., a given group of C), the model provides a bivariate discretisation which estimates Pr(T,</p><formula xml:id="formula_4">V | C) = Pr(C,T,V ) Pr(C)</formula><p>as a 2D grid (see Figure <ref type="figure">2</ref>, on the right). This 2D grid gives the probability to have a given range of values during a given interval of time. Therefore knowing that a time series belongs to a given cluster the corresponding 2D grid may then be used for crafting forecasts (see next section).</p><p>In the MODL approach, finding the most probable tri-clustering model is turning into a model selection problem. To do so, a Bayesian approach called Maximum A Posteriori (MAP) is used to select the most probable model given the data. Details about how this 3D grid model is learned may be found in <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b14">15]</ref>. The main idea could be summarised as finding the grid which maximises the contrast compared to a grid based on the assumption that T, V and C are independent (i.e., Pr(V, T, C) compared to Pr(V ) Pr(T ) Pr(C)). Therefore the estimation of this MAP model outputs:</p><formula xml:id="formula_5">(i) ν intervals of values V i = [v l i , v u i ] for i = 1, . . . , ν, (ii) τ intervals of times T i = [t l i , t u i ] for i = 1, .</formula><p>. . , τ , (iii) groups of time series. These groups of time series corresponds to the typical seasons, Fig. <ref type="figure">2</ref>: Illustration of a trivariate coclustering model where a slice referred to forecasting "grid" is extracted.</p><p>denoted S in the above model. |S| is the number of clusters at the finer level that is optimal in the sense of the MODL framework.</p><p>In the time series forecasting approach proposed in this paper, the right number of (tri-)clusters is optimised regarding to the forecasting task. More precisely, this number is optimised according to the performance of the model at prediction time, using the validation ensemble. This value could differ from |S|. Therefore the MODL coclustering approach allows applying a hierarchical </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Predict the next type of seasons</head><p>The problem is here to estimate empirically Pr(S i+1 | y (i-γ):i ) the probability of having a type of season S i+1 ∈ S for the (i + 1)-th season given the observations over the γ past seasons. We consider two different sets of features to represent the γ previous seasons. The first approach consists in having only the time series values y (i-γ):i as features. The second approach uses the time series values and the types of the previous seasons as features.</p><p>Then, the next season prediction problem consists in learning a probabilistic classifier (Naive-Bayes classifier, logistic regression, decision tree or random forests) or a time series classifiers (TSForest <ref type="bibr" target="#b15">[16]</ref>, Rocket <ref type="bibr" target="#b16">[17]</ref>). Note that time series classifiers can use only the time series values.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Select the best parameters (Portfolio)</head><p>The P-F2C forecaster is parameterised by the number of seasons in the past (γ) used for learning next season type, a maximum number of typical seasons to detect in a non-supervised way, and the type of classifier. The γ parameter is introduced in the problem definition and its choice is left to the user who specifies what is the forecasting task. On the other hand, the other parameters may be difficult to be set by the user, and we do not think that one of the classifiers will outperform the others for all the time series. For these reasons, the portfolio approach (denoted PP-F2C) implements a grid search for the best parameters by splitting the dataset into a training (75%) and a validation dataset (25%) to identify the best value of the parameters. Once the best values have been set, the clusterer and the classifier are fitted on the entire dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Illustration on a synthetic dataset</head><p>This section shows results with synthetic data. The goal is to illustrate the probabilistic grid used in P-F2C method, and to give intuitions behind probabilistic forecasting that are provided by P-F2C. We compare the output of P-F2C against the output of DeepAR <ref type="bibr" target="#b17">[18]</ref>, a state-of-the-art probabilistic time series forecaster.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">The data generated</head><p>Generating data is a good strategy for checking assumptions before launching experiments at scale. Indeed, the shape of the generated data is often simpler, and completely controlled. Experiments may be executed with various parameters, to plot understandable results and to validate basic expectations.</p><p>The seasonal data generated for this section follows some well-established seasonal sequences. Three different time series patterns are defined for three different latent types of season of length 10. In the Figure <ref type="figure" target="#fig_2">3</ref>, one type of season (s 1 in orange) with always increasing values is observed, one type of season (s 2 in green) with two peaks is observed, etc. Those three different types of season are then repeated 50 times in a defined order (s 1 , s 1 , s 0 , s 2 , s 1 , s 1 , s 2 , s 0 , as observed in Figure <ref type="figure" target="#fig_2">3</ref>, on the right, which shows the entire sequence that is being repeated), and noise is added to the final time series to make the forecasting process less straightforward.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Grid probabilistic forecasts</head><p>Once trained, we apply the P-F2C forecaster at the end of the time series illustrated in Figure <ref type="figure" target="#fig_2">3</ref> on the right. Knowing the sequence of patterns, we can guess that a season of type s 2 is coming ahead. Indeed, the last three patterns seems to follow the sequence [s 1 , s 1 , s 0 ].</p><p>The Figure <ref type="figure" target="#fig_3">4</ref> shows two examples of forecasts with different values of γ.</p><p>The real values of the predicted time series are in blue (noisy version of the s 2 pattern). The probabilistic forecasts are shown in a red overlay. It is a set of rectangles that visualise the homogeneous regions that have been identified by MODL coclustering. The darker the red, the more probable next season ahead lay in this (T , V ) interval.</p><p>The Figure <ref type="figure" target="#fig_3">4</ref> on the left is the forecast obtained with γ = 1. It illustrates a probabilistic forecast with a lot of uncertainty. Indeed, light red cells are observed in the figure where the data are predicted to lay (with a low probability). In this case, the classifier is unable to predict accurately the next type of season. With γ = 1 the classifier has only the information of the preceding season (of type s 0 ). In this case, the forecaster encountered two types of season after a s 0 season: s 1 or s 2 with the same probability. Then, the predicted grid is a mixture of the two types of grids. For the first half of the season, the forecast is confident in predicting the linear increase of the value (darker red cells), but for the second half, the forecast suggests two possible behaviours: continue the linear increase (s 1 ) or a decrease (s 2 ). Note that the grids of all typical seasons share the same squaring. MODL necessarily creates the same cuttings of a dimension (V or T ) along the others (C).</p><p>The Figure <ref type="figure" target="#fig_3">4</ref> on the middle is the forecast obtained with γ = 3. It illustrates a good probabilistic forecast. The real values (in blue) often appear in the red boxes where the red is very dark. It means that the season type was both well described by MODL and well predicted by the classifier. In this case, a larger memory of the forecaster disentangles the two possible choices it had above. After a [s 1 , s 1 , s 0 ], the forecaster always observed seasons of type s 2 . Thus, the grid of this pattern is predicted.</p><p>It is worth noting that, for γ = 1, the use of the MODL probabilistic grid suggests two distinct possible evolution of the time series, but there is an uncertainty on which evolution will actually occur. In the classical probabilistic forecasts, probabilities are distributed around a mean time series. This is illustrated on the Figure <ref type="figure" target="#fig_3">4</ref> on the right with DeepAR using the 7 seasons in the past to predict the next season. On the second half of the season, the predicted probabilistic distribution suggests a behaviour in between s 1 and s 2 with a larger uncertainty. Such model makes confusion between uncertainty of behaviour and imprecise forecast. In the case of seasonal time series with different types of season, the mean time series has no meaning for an analyst.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments</head><p>This section presents experiments to assess the accuracy of P-F2C. We start by introducing the experimental settings, then we investigate some parameters of our model and finally we present the result of an intensive comparison of P-F2C to competitors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Experimental protocol</head><p>The framework has been developed in Python 3.5. The MODL coclustering is performed by the Khiops tool <ref type="bibr" target="#b18">[19]</ref>. The classification algorithms are borrowed from the sklearn library <ref type="bibr" target="#b19">[20]</ref>.</p><p>In our experiments, we used 36 datasets<ref type="foot" target="#foot_1">7</ref> , from various sources and nature: technical devices, human activities, electricity consumption, natural processes, etc. All these datasets have been selected because seasonality was identified and validated with a Fisher g-test <ref type="bibr" target="#b11">[12]</ref>. Each time series is normalised using a znormalisation prior to data splitting, in order to have comparable results. For the experiments, 90% of the time series are used to train the forecaster (this train test is internally split in training and valid datasets) and 10% of the original time series are used to evaluate the accuracy. P-F2C and PP-F2C are compared with classical deterministic time-series forecasters (AR, ARIMA, SARIMA, HoltWinters), with LSTM <ref type="bibr" target="#b20">[21]</ref>, Prophet <ref type="bibr" target="#b21">[22]</ref> and with the F2C method <ref type="bibr" target="#b5">[6]</ref> which uses the principles as P-F2C but with Kmeans clustering algorithm and random forest classifiers to learn the structure in the season sequence. P-F2C being a probabilistic methodology, we also compare it with DeepAR <ref type="bibr" target="#b17">[18]</ref>.</p><p>We use Mean Absolute Error (MAE) and Continuous Ranked Probability Score (CRPS) to compare the forecasts to the real time series. The MAE is dedicated to deterministic forecasts while CRPS is to probabilistic ones. It is worth noting that the CRPS is analogous to MAE for deterministic forecasts. Therefore, comparing MAE measure for deterministic forecasts against CRPS values for probabilistic forecasts is technically sound <ref type="bibr" target="#b22">[23]</ref>. The CRPS is used for DeepAR and P-F2C. All the other approaches forecast crisp time series and their accuracy is evaluated through MAE. For each experiment, we illustrate the results with critical difference diagrams. A critical difference diagram represents the mean rank of the methods that have been obtained on the set of the 36 times series. The lower the better. In addition, the representation shows horizontal bars that group some methods. In a same group, the methods are not statistically different according to the Nemenyi test.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Parameters sensitivity</head><p>In this section, an analysis of the alternative settings of the P-F2C methodology is conducted. We investigate the effect of two choices: the choice of the γ value, i.e., the number of seasons to consider in the history; and the choice of the classifier to predict the next type of season in case we do not use the portfolio optimisation. q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q DeepAR win: 5 PP_F2C win: 27 p-value=4.597e-06  Figure <ref type="figure" target="#fig_4">5</ref> on the left shows a critical diagram that compares the ranking of P-F2C with different values of γ (1, 2 or 3). For this experiment, the classifier is the RandomForestClassifier (and we had the same results with the other classifiers). We notice that the larger γ, the lower the error. Indeed, as seen in Section 4, larger γ improves the accuracy of the forecast of the next season type. Nonetheless, we observed that for some time series, lower γ may be better. We explain this counter-intuitive results by the small length of some of the time series. In the cases, the number of seasons in the training set is too small to fit the numerous parameters of a classifier with γ × s features.</p><p>Figure <ref type="figure" target="#fig_4">5</ref> on the right shows a critical diagram that compares the classifiers used to predict the next type of season. It shows that time series forest classifier <ref type="bibr" target="#b15">[16]</ref> is on average in first position. This classifier has been designed specifically for time series classification, it explains why it outperforms the other approaches. Nonetheless, the differences with Logistic Regression and Random Forest are not statistically significant. Their capability to use extra-information, such as the type of seasons, may be an interesting advantage to improve performances.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">P-F2C and PP-F2C vs opponents</head><p>The critical diagram of Figure <ref type="figure" target="#fig_7">6</ref> compares the performances of the methods. P-F2C denotes our approach configured with the best parameters on average found in Section 5.2. PP-F2C denotes P-F2C that is optimised on the valid test for each dataset (portfolio). It shows that rank-wise, the seasonal forecaster F2C, P-F2C and PP-F2C are performing better than the others. We can first notice that the portfolio actually improve the performances of P-F2C. Nonetheless, the non-probabilistic approach outperform PP-F2C.</p><p>We also notice that F2C outperforms PP-F2C. Even if a PP-F2C forecast fits the time series (see Figure <ref type="figure" target="#fig_3">4</ref>), the piece-wise approximation generates a spread of the probabilistic distribution that penalises the CRPS. Nonetheless, it is worth noting that the rank difference with F2C is not statistically significant, and that probabilistic forecast convey meaningful information to trust the forecasts.</p><p>Then, we compared PP-F2C with another probabilistic forecaster, i.e. DeepAR. The critical diagram of Figure <ref type="figure" target="#fig_7">6</ref> shows that PP-F2C outperforms DeepAR significantly (p &lt; 10 -6 ). The win/tie/lose graph on the right shows how many times PF2C won against DeepAR (points below the diagonal) and the relative values of CRPS. The point positions illustrate that PP-F2C outperforms DeepAR significantly on most of the datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>P-F2C is a probabilistic forecaster for seasonal time series. It assumes that seasons are a mixture of typical seasons to transform the forecasting problem into both a clustering and a classification of time series. The P-F2C applies parameterless coclustering approach that generates grid forecasts, each typical grid being a typical seasonal behaviour. In addition we proposed PP-F2C that adjust P-F2C parameters for each time series. PP-F2C outperforms on average the competitors except F2C on various seasonal time series. F2C is based on the same principle as PP-F2C but is not probabilistic and parameterless. Nonetheless, we illustrated the interest of probabilistic grid forecasting to give information about uncertain distinct mean behaviours. Indeed, the probabilistic grid mixture is more interpretable than combining probabilistic distribution around a mean.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 :</head><label>1</label><figDesc>Fig. 1: Difference between clustering (on the left), which matches the entire time series, with coclustering (on the right), which is able to match subintervals of the time series of various other time series.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>clustering to the finer level to have a coarse level with a lower number of clusters called C * , C * &lt; |S|. A grid search selects the C * value based on the forecast accuracy on the valid dataset. Let us now come back to the formalisation of probabilistic time series forecasting: Pr(y * m | S) is estimated by the MODL model from the conditional probabilities Pr(V, T | C = S) where S denotes one of the time series groups, i.e. a typical season. In practice, the grid is used to estimate the distribution of values at each time point of a season. With MODL, the distribution is a piecewise constant function.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 :</head><label>3</label><figDesc>Fig. 3: At the top: typical seasons of length 10 used for generating the time series, at the bottom: examples of generated time series with white noise (7 seasons).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 4 :</head><label>4</label><figDesc>Fig. 4: One season ahead grid forecasts for the generated time series with γ = 1 at the top left and γ = 3 at the top right, and DeepAR at the bottom.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 5 :</head><label>5</label><figDesc>Fig.5: Critical diagrams used to find the best parameters for the P-F2C implementation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>in terms of CRPS error.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 6 :</head><label>6</label><figDesc>Fig. 6: At the top: Critical diagram of the comparison between different prediction approaches (acronyms of method are detailed in the text). At the bottom: Win-Tie-Loose graph between PP-F2C and DeepAR.</figDesc></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_0"><p>The Cartesian product of the three partitions is used as a constant piecewise estimator -i.e., a 3D histogram.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_1"><p>Datasets details can be downloaded here: https://tinyurl.com/4kffdwhc (temporary link). It includes the sources of time series.</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Longterm glucose forecasting using a physiological model and deconvolution of the continuous glucose monitoring signal</title>
		<author>
			<persName><forename type="first">C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Vehí</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Avari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Reddy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Oliver</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Georgiou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Herrero</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sensors</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">19</biblScope>
			<biblScope unit="page">4338</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Forecasting macroeconomic time series: Lasso-based approaches and their forecast combinations with dynamic factor models</title>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Forecasting</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="996" to="1015" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Application of support vector machines in financial time series forecasting</title>
		<author>
			<persName><forename type="first">F</forename><surname>Tay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Cao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Omega</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="309" to="317" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Density-based unsupervised ensemble learning methods for time series forecasting of aggregated or clustered electricity consumption</title>
		<author>
			<persName><forename type="first">P</forename><surname>Laurinec</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lóderer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lucká</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Rozinajová</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Intelligent Information Systems</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="219" to="239" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Automating Datacenter Operations Using Machine Learning</title>
		<author>
			<persName><forename type="first">P</forename><surname>Bodìk</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
		<respStmt>
			<orgName>UC Berkeley</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Toward a framework for seasonal time series forecasting using clustering</title>
		<author>
			<persName><forename type="first">C</forename><surname>Leverger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Malinowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Guyet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Lemaire</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bondu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Termier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Intelligent Data Engineering and Automated Learning</title>
		<meeting>the International Conference on Intelligent Data Engineering and Automated Learning</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="328" to="340" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">25 years of time series forecasting</title>
		<author>
			<persName><forename type="first">J</forename><surname>De Gooijer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Hyndman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International journal of forecasting</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="443" to="473" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Asymmetric density forecasts of inflation and the bank of england&apos;s fan chart</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">F</forename><surname>Wallis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">National Institute Economic Review</title>
		<imprint>
			<biblScope unit="volume">167</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="106" to="112" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Highest-density forecast regions for nonlinear and non-normal time series models</title>
		<author>
			<persName><forename type="first">R</forename><surname>Hyndman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Forecasting</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="431" to="441" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Data grid models for preparation and modeling in supervised learning</title>
		<author>
			<persName><forename type="first">M</forename><surname>Boullé</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Hands-On Pattern Recognition: Challenges in Machine Learning</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="99" to="130" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Monthly peak-load demand forecasting for sulaimany governorate using SARIMA</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Kareem</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">R</forename><surname>Majeed</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Transmission &amp; Distribution Conference and Exposition</title>
		<meeting>the International Conference on Transmission &amp; Distribution Conference and Exposition</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="1" to="5" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Identifying periodically expressed transcripts in microarray time series data</title>
		<author>
			<persName><forename type="first">S</forename><surname>Wichert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Fokianos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Strimmer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="5" to="20" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Functional data clustering via piecewise constant nonparametric density estimation</title>
		<author>
			<persName><forename type="first">M</forename><surname>Boullé</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="4389" to="4401" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Fast and accurate time-series clustering</title>
		<author>
			<persName><forename type="first">J</forename><surname>Paparrizos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Gravano</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Database Systems (TODS)</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1" to="49" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Symbolic representation of time series: A hierarchical coclustering formalization</title>
		<author>
			<persName><forename type="first">A</forename><surname>Bondu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Boullé</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Cornuéjols</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Workshop on Advanced Analysis and Learning on Temporal Data</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="3" to="16" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A time series forest for classification and feature extraction</title>
		<author>
			<persName><forename type="first">H</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Runger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Tuv</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Vladimir</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Sciences</title>
		<imprint>
			<biblScope unit="volume">239</biblScope>
			<biblScope unit="page" from="142" to="153" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Rocket: Exceptionally fast and accurate time series classification using random convolutional kernels</title>
		<author>
			<persName><forename type="first">A</forename><surname>Dempster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Petitjean</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">I</forename><surname>Webb</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1910.13051</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Deepar: Probabilistic forecasting with autoregressive recurrent networks</title>
		<author>
			<persName><forename type="first">D</forename><surname>Salinas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Flunkert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gasthaus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Januschowski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Forecasting</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1181" to="1191" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Khiops: Outil d&apos;apprentissage supervisé automatique pour la fouille de grandes bases de données multi-tables</title>
		<author>
			<persName><forename type="first">M</forename><surname>Boullé</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Actes de la conférence Extraction et Gestion des Connaissances</title>
		<imprint>
			<biblScope unit="page" from="505" to="510" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Scikit-learn: Machine learning in python</title>
		<author>
			<persName><forename type="first">F</forename><surname>Pedregosa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Varoquaux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gramfort</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Michel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Thirion</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Grisel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Blondel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Prettenhofer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Dubourg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of machine Learning research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2825" to="2830" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Learning to forget: Continual prediction with LSTM</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">A</forename><surname>Gers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Cummins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 9th International Conference on Artificial Neural Networks (ICANN)</title>
		<meeting>the 9th International Conference on Artificial Neural Networks (ICANN)</meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="850" to="855" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Forecasting at scale</title>
		<author>
			<persName><forename type="first">S</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Letham</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The American Statistician</title>
		<imprint>
			<biblScope unit="volume">72</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="37" to="45" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Decomposition of the continuous ranked probability score for ensemble prediction systems</title>
		<author>
			<persName><forename type="first">H</forename><surname>Hersbach</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Weather and Forecasting</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="559" to="570" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
