<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">AI-based Identification of Plant Photographs from Herbarium Specimens</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2021-08-31">31 Aug 2021</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Hervé</forename><forename type="middle">H G</forename><surname>Goëau</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Pierre</forename><surname>Bonnet</surname></persName>
						</author>
						<author role="corresp">
							<persName><forename type="first">Alexis</forename><forename type="middle">A J</forename><surname>Joly</surname></persName>
							<email>alexis.joly@inria.fr</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">CIRAD</orgName>
								<address>
									<settlement>Montpellier</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="laboratory">UMR AMAP</orgName>
								<orgName type="institution">CIRAD</orgName>
								<address>
									<settlement>Montpellier</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="institution">| Inria</orgName>
								<address>
									<settlement>Montpellier</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">AI-based Identification of Plant Photographs from Herbarium Specimens</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2021-08-31">31 Aug 2021</date>
						</imprint>
					</monogr>
					<idno type="MD5">7F5BA77612DA9DD8B2CE9F8E86F6FF17</idno>
					<idno type="DOI">10.3897/biss.5.73751</idno>
					<note type="submission">Received: 31 Aug 2021</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-04-12T14:47+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Automated plant identification has recently improved significantly due to advances in deep learning and the availability of large amounts of field photos. As an illustration, the classification accuracy of 10K species measured in the LifeCLEF challenge (Goëau et al.  2018) reached 90%, very close to that of human experts. However, the profusion of field images only concerns a few tens of thousands of species, mainly located in North America and Western Europe. Conversely, the richest regions in terms of biodiversity, such as tropical countries, suffer from a shortage of training data (Pitman 2021). Consequently, the identification performance of the most advanced models on the flora of these regions is much lower (Goëau et al. 2019).</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Nevertheless, for several centuries, botanists have systematically collected, catalogued, and stored plant specimens in herbaria. Considerable recent efforts by the biodiversity informatics community, such as DiSSCo <ref type="bibr">(Addink et al. 2018</ref>) and iDigBio <ref type="bibr">(Matsunaga et al. 2013)</ref>, have made millions of digitized specimens from these collections available online. A key question is therefore whether these digitized specimens could be used to improve the identification performance of species for which we have very few (if any) photos. However, this is a very difficult problem from a machine learning point of view. The visual appearance of a herbarium specimen is actually very different from a field photograph because the specimens are dried and crushed on a herbarium sheet before being digitized (Fig. <ref type="figure" target="#fig_1">1</ref>).</p><p>To advance research on this topic, we built a large dataset that we shared as one of the challenges of the LifeCLEF 2020 (Goëau et al. 2020) and 2021 evaluation campaigns <ref type="bibr">( Goëau et al. 2021)</ref>. It includes more than 320K herbarium specimens collected mostly from the Guiana Shield and the Northern Amazon Rainforest, focusing on about 1K plant species of the French Guiana flora. A valuable asset of this collection is that some of the specimens are accompanied by a few photos of the same specimen, allowing for more precise machine learning. In addition to this training data, we also built a test set for model evaluation, composed of 3,186 field photos collected by two of the best experts on Guyanese flora.</p><p>Based on this dataset, about ten research teams have developed deep learning methods to address the challenge (including the authors of this abstract as the organizing team). A detailed description of these methods can be found in the technical notes written by the participating teams <ref type="bibr">(Goëau et al. 2020</ref><ref type="bibr">, Goëau et al. 2021)</ref>. The methods can be divided into two categories: metric learning to maximize inter-species distances and minimize intra-species distances in the representation space In Table <ref type="table">1</ref>, we report the results achieved by the different methods evaluated during the 2020 edition of the challenge. The evaluation metric used is the mean reciprocal rank (MRR), i.e., the average of the inverse of the rank of the correct species in the list of the predicted species. In addition to this main score, a second MRR score is computed on a subset of the test set composed of the most difficult species, i.e., the ones that are the least frequently photographed in the field. The main outcomes we can derive from these results are the following: Domain adaptation methods provide significant improvement but the task remains challenging. The best MRR score (0.180) was achieved by using adversarial regularization <ref type="bibr">(FSDA Motiian et al. 2017)</ref>. This is much better than the classical CNN models but there is still a lot of progress to be made to reach the performance of a truly functional identification system (the MRR score on classical plant identification tasks can be up to 0.9).</p><p>No method fits all. As shown in Table <ref type="table">1</ref>, the metric learning method has a significantly better MRR score on the most difficult species (0.107). However, the performance of this method on the species with more photos is much lower than the adversarial technique.</p><p>In 2021, the challenge was run again but with additional information provided to train the models, i.e., species traits (plant life form, woodiness and plant growth form). The use of the species traits allowed slight performance improvement of the best adversarial adaptation method (with a MRR equal to 0.198).</p><p>In conclusion, the results of the experiments conducted are promising and demonstrate the potential interest of digitized herbarium data for automated plant identification. However, Table <ref type="table">1</ref>.</p><p>Synthesis of the obtained results.</p><p>AI-based Identification of Plant Photographs from Herbarium Specimens</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>•</head><label></label><figDesc>those based on classical convolutional neural networks (CNN) trained simply by mixing digitized specimens and photos and • those based on advanced domain adaptation techniques with the objective of learning a joint representation space between field and herbarium representations. The domain adaptation methods themselves were of two types, those based on 1. adversarial regularization (Motiian et al. 2017) to force herbarium specimens and photos to have the same representations, 2.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 .</head><label>1</label><figDesc>Figure 1. A herbarium sheet (left) and a field photo (right) of the same individual plant (Unonopsis stipitata Diels).</figDesc><graphic coords="3,53.19,57.44,274.50,168.09" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Classical deep learning models fail to identify plant photos from digitized herbarium specimens</head><label></label><figDesc></figDesc><table><row><cell></cell><cell>MRR</cell><cell>MRR on most difficult species</cell></row><row><cell>Best classical CNN</cell><cell>0.011</cell><cell>0.004</cell></row><row><cell>Best classical CNN with additional training</cell><cell>0.039</cell><cell>0.007</cell></row><row><cell>data</cell><cell></cell><cell></cell></row><row><cell>Best domain adaptation method based on</cell><cell>0.121</cell><cell>0.107</cell></row><row><cell>metric learning</cell><cell></cell><cell></cell></row><row><cell>Best domain adaptation method based on</cell><cell>0.180</cell><cell>0.052</cell></row><row><cell>adversarial regularization</cell><cell></cell><cell></cell></row></table><note><p>. The best classical CNN trained on the provided data resulted in a very low MRR score (0.011). Even with the of use additional training data (e.g. photos and digitized herbarium from GBIF) the MRR score remains very low (0.039).</p></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>‡ § | © Goëau H et al. This is an open access article distributed under the terms of the Creative Commons Attribution License (CC BY 4.0), which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</p></note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>progress is still needed before integrating this type of approach into production applications.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Keywords</head><p>plant, identification, photos, herbarium, domain adaptation</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Presenting author</head><p>Hervé Goëau </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Presented at</head></div>			</div>
			<div type="references">

				<listBibl/>
			</div>
		</back>
	</text>
</TEI>
