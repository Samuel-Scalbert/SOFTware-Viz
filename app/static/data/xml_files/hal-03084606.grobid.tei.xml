<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="fr">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Fast and Exact Rule Mining with AMIE 3</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Jonathan</forename><surname>Lajus</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Télécom Paris</orgName>
								<orgName type="institution" key="instit2">Institut Polytechnique de Paris</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Luis</forename><surname>Galárraga</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">INRIA Rennes</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Fabian</forename><surname>Suchanek</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Télécom Paris</orgName>
								<orgName type="institution" key="instit2">Institut Polytechnique de Paris</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Fast and Exact Rule Mining with AMIE 3</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">4D524C1826A18EBF4D307E6BED87139E</idno>
					<idno type="DOI">10.1007/978-3-030-49461-2_3</idno>
					<note type="submission">Submitted on 21 Dec 2020</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-04-12T14:44+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>come from teaching and research institutions in France or abroad, or from public or private research centers. L'archive ouverte pluridisciplinaire HAL, est destinée au dépôt et à la diffusion de documents scientifiques de niveau recherche, publiés ou non, émanant des établissements d'enseignement et de recherche français ou étrangers, des laboratoires publics ou privés.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="fr">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Recent years have seen the rise of large knowledge bases (KBs) such as Wikidata, YAGO, DBpedia, and many others. These are large collections of knowledge about the real world in the form of entities (such as organizations, movies, people, and locations) and relations between them (such as wasBornIn, actesIn, etc.). Today's KBs contain millions of entities and facts about them. They find applications in Web search, text analysis, and chat bots.</p><p>Rule mining is the task of automatically finding logical rules in a given KB. For example, a rule mining approach can find that "If X and Y are married, and X lives in Z, then Y also lives in Z". Such rules usually come with confidence scores that express to what degree a rule holds. The rules can serve several purposes: First, they serve to complete the KB. If we do not know the place of residence of a person, we can propose that the person lives where their spouse lives. Second, they can serve to debug the KB. If the spouse of someone lives in a different city, then this can indicate a problem. Finally, rules are useful in downstream applications such as fact prediction <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b17">18]</ref>, data and ontology alignment <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b9">10]</ref>, fact checking <ref type="bibr" target="#b1">[2]</ref>, and error detection <ref type="bibr" target="#b0">[1]</ref>.</p><p>The difficulty in finding such rules lies in the exponential size of the search space: every relation can potentially be combined with every other relation in a rule. This is why early approaches (such as AMIE <ref type="bibr" target="#b7">[8]</ref>) were unable to run on large KBs such as Wikidata in less than a day. Since then, several approaches have resorted to sampling or approximate confidence calculations <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b3">4]</ref>. The more the approach samples, the faster it becomes, but the less accurate the results will be. Another common technique <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b15">16]</ref> (from standard inductive logic programming) is to mine not all rules, but only enough rules to cover the positive examples. This, likewise, speeds up the computation, but does not mine all rules that hold in the KB.</p><p>In this paper, we present AMIE 3, a successor of AMIE <ref type="bibr" target="#b7">[8]</ref> and AMIE+ <ref type="bibr" target="#b8">[9]</ref>. Our system employs a number of sophisticated strategies to speed up rule mining: pruning strategies, parallelization, and a lazy computation of confidence scores. This allows our system to scale effortlessly to large KBs. At the same time, the system still computes the exact confidence and support values for each rule, without resorting to approximations. Furthermore, unlike her predecessor <ref type="bibr" target="#b8">[9]</ref> and other systems, AMIE 3 exhaustively computes all rules that hold in the KB for a given confidence and support threshold.</p><p>Our experiments show that AMIE 3 beats the state of the art by a factor of 15 in terms of runtime. We believe that the techniques that we have discovered can be of use for other systems as well -no matter whether they compute the exhaustive set of rules or not.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>First Generation Rule Mining. Inductive Logic Programming (ILP) is the task of learning rules from positive and negative examples. The first of these systems <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b15">16]</ref> appeared before the rise of large KBs. Hence, they are generally unsuitable for today's KBs for two reasons: (i) they were not designed to scale to millions of facts, and (ii) they do not account for the Open World Assumption (OWA) made by current KBs. For example, FOIL <ref type="bibr" target="#b15">[16]</ref> (as well as its optimized successor <ref type="bibr" target="#b18">[19]</ref>) cannot be applied directly to KBs because it assumes the user can provide explicit counter-examples for the rules. Alas, KBs do not store negative statements. In contrast, WARMR <ref type="bibr" target="#b10">[11]</ref> generates negative evidence by assuming the KB is complete, i.e., by making a closed world assumption (CWA), whereas <ref type="bibr" target="#b12">[13]</ref> uses a positives-only learning function that generates negative evidence from random facts (a similar, but more systematic mechanism is proposed in <ref type="bibr" target="#b14">[15]</ref>). It was shown <ref type="bibr" target="#b7">[8]</ref> that these strategies work less well on KBs than the partial completeness assumption (PCA), which was explicitly designed for KBs. Second Generation Rule Mining. AMIE (and its successor AMIE+) <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b8">9]</ref> was the first approach to explicitly target large KBs. While AMIE+ is at least 3 orders of magnitude faster than the first-generation systems, it can still take hours, even days, to find rules in very large KBs such as Wikidata. On these grounds, more recent approaches <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b14">15]</ref> have proposed new strategies (parallelism, approximations, etc.) to speed up rule mining on the largest KBs. The Ontological Pathfinding method (OP) <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b3">4]</ref> resorts to a highly concurrent architecture based on Spark 3 to calculate the support and the confidence of a set of candidate rules. The candidates are computed by enumerating all conjunctions of atoms that are allowed by the schema. Like AMIE, OP calculates the exact scores of the rules and supports both the CWA and the PCA for the generation of counter-evidence. At the same time, the system supports only path rules of up to 3 atoms. Other types of rules require the user to implement a new mining procedure. We will see in our experiments that AMIE 3 is both more general and faster than OP.</p><p>RudiK <ref type="bibr" target="#b14">[15]</ref> is a recent rule mining method that applies the PCA to generate explicit counter-examples that are semantically related. For example, when generating counter-facts for the relation hasChild and a given person x, RudiK will sample among the non-children of x who are children of someone else (x = x). Rudik's strategy is to find all rules that are necessary to predict the positive examples, based on a greedy heuristic that at each step adds the most promising rule (in terms of coverage of the examples) to the output set. Thus, differently from exhaustive rule mining approaches <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b10">11]</ref>, Rudik aims to find rules that make good predictions, not all rules above a given confidence threshold. This non-exhaustivity endows RudiK with comparable performance to AMIE+ and OP. Nevertheless, we show that AMIE 3 outperforms RudiK in terms of runtime while still being exhaustive.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Preliminaries</head><p>Knowledge Bases. We assume a set I of entities (such as Paris), a set P of binary relations (such as locatedIn), and a set L of literal values (strings or numbers) <ref type="foot" target="#foot_1">4</ref> . We model a knowledge base (KB) K as a set of assertions r(s, o), also called facts, with a subject s ∈ I, a relation r ∈ P and an object o ∈ I ∪ L. An example of a fact is locatedIn(Paris, France). Whenever K is clear from the context, we write r(s, o) to mean r(s, o) ∈ K.</p><p>Relations &amp; Functions. The inverse of a relation r, denoted r -, is the relation consisting of all the facts of the form r -(o, s) such that r(s, o) ∈ K. A relation r is a function in K, if r has at most one object for each subject. Some relations (e.g., isCitizenOf ) are quasi-functions, i.e. they rarely associate multiple objects to a given subject. Hence, the notion of functions has been generalized to the functionality score <ref type="bibr" target="#b16">[17]</ref> of a relation r:</p><formula xml:id="formula_0">fun(r) = |{s : ∃o : r(s, o) ∈ K}| |{(s, o) : r(s, o) ∈ K}|<label>(1)</label></formula><p>The functionality score is always between 0 and 1 (incl.). It is exactly 1 for strict functions such as hasBirthPlace, it is close to 1 for quasi-functions, and it is smaller for relations that have many objects (such as actedInMovie).</p><p>Atoms and Rules. An atom is an expression of the form r(X, Y ), where r is a relation and X, Y are either constants or variables. From now on, we denote variables by lowercase letters, whereas constants (entities) are always capitalized. An atom is instantiated if at least one of its arguments is a constant, as in livesIn(x, Berlin). If both arguments are constants, the atom is grounded and it is tantamount to a fact. We define the operator var (A) so that it returns the set of variables of an atom A. A (conjunctive) query is a conjunction of atoms: B 1 ∧ ... ∧ B n . A substitution σ is a partial mapping from variables to constants. Substitutions can be straightforwardly extended to atoms and conjunctions. A result of a query B 1 ∧ ... ∧ B n on a KB K is a substitution σ that (i) maps all variables and (ii) that entails σ(B i ) ∈ K ∀i ∈ {1, ..., n}. A (Horn) rule is a formula of the form B ⇒ H, where the B is a query of body atoms B 1 , ..., B n , and H is the head atom. Two atoms A, A are connected if var (A)∩var (A ) = ∅, i.e., they have common variables. It is common <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b14">15]</ref> to impose that all atoms in a rule are transitively connected and that rules are closed. A rule is closed if all variables appear in at least two atoms. A closed rule is always safe, i.e. all head variables appear also in at least one body atom. Predictions. Given a rule R = B 1 ∧ ... ∧ B n ⇒ H and a substitution σ, we call σ(R) an instantiation of R. If σ(B i ) ∈ K ∀i ∈ {1, ..., n}, we call σ(H) a prediction of R from K, and we write K ∧ R |= σ(H). If σ(H) ∈ K, we call σ(H) a true prediction.</p><p>A false prediction of a rule is a prediction of a counter-example of the rule. There are different approaches to define these counter-examples: Under the Closed World Assumption (CWA), any assertion that is not in the KB is considered a counter-example. However, KBs are usually incomplete, and thus the CWA penalizes rules that predict new facts. Under the Open World Assumption (OWA), facts that are not in the KB are not necessarily wrong, and hence there are no counter-examples. This entails that a rule mining algorithm will report arbitrary rules as long as these rules make enough true predictions (such as "All people play the violin"). Therefore, AMIE <ref type="bibr" target="#b7">[8]</ref> has proposed the Partial Completeness Assumption (PCA): If we have r(s, o) in the KB K, and if fun(r) ≥ fun(r -), then we assume that all r(s, o') ∈ K do not hold in the real world. If fun(r) &lt; fun(r -), then the PCA says that all r(s', o) ∈ K do not hold in the real world. These assertions can thus serve as counter-examples. There are a number of other approaches to generate counter-examples in the literature <ref type="bibr" target="#b17">[18]</ref>. Support and Confidence. The support of a rule R in a KB K is the number of true predictions p (of the form r(X, Y )) that the rule makes in the KB:</p><formula xml:id="formula_1">support(R) = |{p : (K ∧ R |= p) ∧ p ∈ K}|<label>(2)</label></formula><p>The head-coverage is the proportional variant of the support: It is the ratio of instantiations of the head atom that are predicted by the rule:</p><formula xml:id="formula_2">hc(B ⇒ r(x, y)) = support(B ⇒ r(x, y)) |{(x, y) : r(x, y) ∈ K}|</formula><p>The confidence of a rule R in a KB K is the proportion of true predictions out of the true predictions and false predictions:</p><formula xml:id="formula_3">confidence(R) = support(R) support(R) + |{p : (K ∧ R |= p) ∧ p ∈ cex(R)}|<label>(3)</label></formula><p>Here, cex(R) denotes the set of counter-examples of R. If the counter-examples are chosen by the PCA, we refer to the confidence as the PCA confidence and denote it by pca-conf (analogously for the CWA).</p><p>In general, the support of the rule quantifies its relevance, whereas the confidence quantifies its accuracy. Rule mining is the task of finding all rules in a KB that fulfill certain confidence and support thresholds. It is a relaxation of inductive logic programming (ILP), in the sense that it finds also rules that predict some limited number of counter-examples (see <ref type="bibr" target="#b17">[18]</ref> for a discussion).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">AMIE 3</head><p>In this section, we first recap the original AMIE algorithm <ref type="bibr" target="#b7">[8]</ref> (Section 4.1). Then we present a series of optimizations that give rise to AMIE 3 (Section 4.2). Finally, we show different quality metrics that AMIE 3 can compute (Section 4.3).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">The AMIE Approach</head><p>The AMIE algorithm <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b8">9]</ref> is a method to mine closed Horn rules on large KBs. AMIE (Algorithm 1) takes as input a knowledge base K, and thresholds l for the maximal number of atoms per rule, minHC for the minimum head coverage, and minC for the minimum PCA confidence. AMIE uses a classical breadth-first search: Line 1 initializes a queue with all possible rules of size 1, i.e., rules with an empty body. The search strategy then dequeues a rule R at a time and adds it to the output list (Line 6) if it meets certain criteria (Line 5), namely, (i) the rule is closed, (ii) its PCA confidence is higher than minC, and (iii) its PCA confidence is higher than the confidence of all previously mined rules with the same head atom as R and a subset of its body atoms. If the rule R has less than l atoms and its confidence can still be improved (Line 7), AMIE refines it. The refinement operator refine (Line 8) derives new rules from R by considering all possible atoms that can be added to the body of the rule, and creating one new rule for each of them.</p><p>AMIE iterates over all the non-duplicate refinements of rule R and adds those with enough head coverage (Lines 10-11). The routine finishes when the queue runs out of rules. The AMIE algorithm has been implemented in Java with multi-threading. By default, AMIE sets minHC=0.01, minC=0.1, and l = 3. AMIE+ <ref type="bibr" target="#b8">[9]</ref> optimized this algorithm by a number of pruning strategies, but did not change the main procedure.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">AMIE 3</head><p>We now present the optimizations of Algorithm 1 that constitute AMIE 3, the successor of AMIE+.</p><p>Existential Variable Detection. In order to decide whether to output a rule, AMIE has to compute its confidence (Lines 5 and 7 of Algorithm 1), i.e., it has to evaluate Equation 3. If the PCA confidence is used, this equation becomes:</p><formula xml:id="formula_4">pca-conf(B ⇒ r(x, y)) = support(B ⇒ r(x, y)) |{(x, y) : ∃y : B ∧ r(x, y )}| . (<label>4</label></formula><formula xml:id="formula_5">)</formula><p>Algorithm 1: AMIE Input: a KB: K, maximum rule length: l, head coverage threshold: minHC , confidence threshold: minC Output: set of Horn rules: rules</p><formula xml:id="formula_6">1 q = [ ⇒ r1(x, y), ⇒ r2(x, y) . . . ⇒ rm(x, y)] 2 rules = 3 while |q| &gt; 0 do 4 R = q.dequeue() 5 if closed (R) ∧ pca-conf(R) ≥ minC ∧ betterThanParents(R, rules) then 6 rules.add (r) 7 if length(R) &lt; l ∧ pca-conf(Rc) &lt; 1.0 then 8 for each rule Rc ∈ refine(R) do 9 if hc(Rc) ≥ minHC ∧ Rc / ∈ q then 10 q.enqueue(rc)</formula><p>11 return rules This is for the case where fun(r) ≥ fun(r -). If fun(r) &lt; fun(r -), the denominator becomes |{(x, y) : ∃x : B ∧ r(x , y)}|. To evaluate this denominator, AMIE first finds every possible value of x. This is the purpose of Algorithm 2: We find the most restrictive atom in the query, i.e., the atom A * with the relation with the least number of facts. If x appears in this atom, we select the possible instantiation of x in the atom for which the rest of the query is satisfiable (Lines 3 and 4). Otherwise, we recursively find the values of x for each instantiation of this most restrictive atom and add them to the result set X . Once AMIE has found the set of possible values for x with Algorithm 2, it determines, for each value of x, the possible values of y -again by Algorithm 2. This is necessary because we cannot keep in memory all values of y encountered when we computed the values of x, because this would lead to a quadratic memory consumption. This method can be improved as follows: Assume that our rule is simply r 1 (x, z) ∧ r 2 (z, y) ⇒ r h (x, y). Then AMIE will compute the number of distinct pairs (x, y) for the following query (the denominator of Equation <ref type="formula" target="#formula_4">4</ref>):</p><formula xml:id="formula_7">r 1 (x, z) ∧ r 2 (z, y) ∧ r h (x, y )</formula><p>AMIE will use Algorithm 2 to select the possible values of x. Assume that the most restrictive atom is r 2 (z, y). Then AMIE will use all possible instantiations σ : {z ← Z, y ← Y } of this atom, and find the possible values of x for the following query (Lines 5 and 6 of Algorithm 2):</p><formula xml:id="formula_8">r 1 (x, Z) ∧ r 2 (Z, Y ) ∧ r h (x, y )<label>(5)</label></formula><p>However, we do not have to try out all possible values of y, because for a fixed instantiation z ← Z all assignments y ← Y lead to the same value for x. Rather, y can be treated as an existential variable: once there is a single Y with r 2 (Z, Y ), we do not need to try out the others. Thus, we can improve Algorithm 2 as Algorithm 2: DistinctValues</p><formula xml:id="formula_9">Input: variable x, query q = A1 ∧ ... ∧ An, KB K, Output: set of values X 1 X := ∅ 2 A * := argmin A (|{(x, y) : A = r(x, y), A ∈ q}|) 3 if x appears in A * then 4 return {x : x ∈ σ(A * ) ∧ σ(q \ A * ) is satisfiable} 5 for each σ : σ(A * ) ∈ K do 6 X := X ∪ DistinctValues(x, σ(q \ A * ), K) 7 return X</formula><p>follows: If a variable y of A * = r(x, y) does not appear elsewhere in q, then Line 5 iterates only over the possible values of x in A * . Lazy Evaluation. The calculation of the denominator of Equation 4 can be computationally expensive, most notably for "bad" rules such as:</p><formula xml:id="formula_10">R : directed (x, z) ∧ hasActor (z, y) ⇒ marriedTo(x, y).<label>(6)</label></formula><p>In such cases, AMIE spends a lot of time computing the exact confidence, only to find that the rule will be pruned away by the confidence threshold. This can be improved as follows: Instead of computing first the set of values for x, and then for each value of x the possible values of y, we compute for each value of x directly the possible values of y -and only then consider the next value of x. Following the principle "If you know something is bad, do not spend time to figure out how bad exactly it is", we stop this computation as soon as the set size reaches the value support(R) × minC -1 . If this occurs, we know that pca-conf(R) &lt; minC , and hence the rule will be pruned in Line 5 of Algorithm 1.</p><p>Variable Order. To compute the PCA confidence (Equation <ref type="formula" target="#formula_4">4</ref>), we have to count the instantiations of pairs of variables x, y. AMIE counts these asymmetrically: It finds the values of x and then, for each value of x, the values of y. We could as well choose to start with y instead. The number of pairs is the same, but we found that the choice impacts the runtime: Once one variable is fixed, the computation of the other variable happens on a rule that has fewer degrees of freedom than the original rule, i.e., it has fewer instantiations. Thus, one has an interest in fixing first the variable that appears in as many selective atoms as possible. Alas, it is very intricate to determine which variable restricts more efficiently the set of instantations, because the variables appear in several atoms, and each instantiation of the first variable may entail a different number of instantiations of the second variable. Therefore, estimating the exact complexity is unpractical. We use the following heuristic: Between x and y, we choose to start with the variable that appears in the head atom of the rule in the denominator of Equation 4. The reason is that this variable appears in at least two atoms already, whereas the other variable appears only in at least one atom. We show in our experiments that this method improves the runtime by several orders of magnitude for some rules.</p><p>Parallel Computation for Overlap Tables. AMIE implements an approximation of Equation <ref type="formula" target="#formula_4">4</ref>. This approximation misses only a small percentage of rules (maximally 5% according to <ref type="bibr" target="#b8">[9]</ref>), but speeds up the calculation drastically. In AMIE 3, this feature can be switched off (to have exact results) or on (to have faster results). Here, we show how to further speed up this heuristic. The method finds an efficient approximation of the denominator of Equation 4 for a rule R, denoted by d(R). AMIE will compute first d(R), and then discard the rule altogether if the approximated PCA confidence, support(R) × d(R) -1 , is smaller than the user threshold minC. For a rule R = r 1 (x, z) ∧ r 2 (z, y) ⇒ r h (x, y), the approximation d(R) is computed as:</p><formula xml:id="formula_11">d(R) := ov (r h , r 1 ) • ov (r - 1 , r 2 ) • fun(r - 2 ) fun(r 1 ) • |dom(r - 1 )| • fun(r 2 )</formula><p>.</p><p>Here, fun(r) is the functionality score of r; dom(r) = {s : r(s, o)} is the domain of r, i.e., the set of distinct subject values of r; and ov (r, r ) = dom(r) ∩ dom(r ) is the overlap between the domains of r and r . The approximation d(R) uses the join structure of the query in combination with the functionality scores and the overlaps to estimate the total number of examples (both positive and negative) of a rule. The expressions fun(r), dom(r), and ov (r, r ) are pre-computed for all relations. This pre-calculation can be significant for large KBs with many predicates. In our experiments with DBpedia, e.g., precomputing ov takes twice as much time as the mining. In AMIE 3, we exploit the fact that this task is easy parallelizable, and start as many threads as possible in parallel, each treating one pair of relations. This reduces the precomputation time linearly with the number of threads (by a factor of 40 in our experiments).</p><p>Integer-based in-memory database. AMIE uses an in-memory database to store the entire KB. Each fact is indexed by subject, by object, by relation, and by pairs of relation/subject and relation/object. In order to be able to load also large KBs into memory, AMIE compresses strings into custom-made ByteStrings, where each character takes only 8 bits. AMIE makes sure that ByteString variables holding equivalent ByteStrings point to the same physical object (i.e., the ByteString exists only once). This not just saves space, but also makes hashing and equality tests trivial. Still, we incur high costs of managing these objects and the indexes: ByteStrings have to be first created, and then checked for duplicity; unused ByteStrings have to be garbage-collected; equality checks still require casting checks; and HashMaps create a large memory overhead. Built-in strings suffer from the same problems. Therefore, we migrated the in-memory database to an integer-based system, where entities and relations are mapped to an integer space and represented by the primitive datatype int. This is in compliance with most RDF engines and popular serialization formats such as <ref type="bibr" target="#b5">[6]</ref>. We use the fastutil library<ref type="foot" target="#foot_2">5</ref> to store the indexes. This avoids the overhead of standard HashMaps. It also reduces the number of objects that the garbage collector has to treat, leading to a significant speedup.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Quality Metrics</head><p>AMIE is a generic exhaustive rule miner, and thus its output consists of rules. These rules can serve as input to other applications, for example, to approaches that predict facts <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b14">15]</ref>. Such downstream applications may require different quality metrics. These can be implemented on top of AMIE, as shown here:</p><p>Support &amp; head coverage. Support is a standard quality metric that indicates the significance of a rule. Due to the anti-monotonicity property, most approaches use support to prune the search space of rules. AMIE <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b8">9]</ref> uses by default the head coverage (the relative variant of support) for pruning. PCA Confidence. By default, AMIE uses the PCA confidence to assess the quality of a rule, because it has been shown to rank rules closer to the quality of their predictions than classical metrics such as the CWA confidence <ref type="bibr" target="#b7">[8]</ref>. CWA confidence. This confidence is used in OP <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b3">4]</ref>. Many link prediction methods are evaluated under the closed world assumption as well <ref type="bibr" target="#b17">[18]</ref>. GPRO confidence. The work of <ref type="bibr" target="#b4">[5]</ref> noted that the PCA confidence can underestimate the likelihood of a prediction in the presence of non-injective mappings. Therefore, the authors propose a refinement of the PCA confidence, the GPRO confidence, which excludes instances coming from non-injective mappings in the confidence computation. To judge the quality of a predicted fact, the approach needs the GPRO confidence both on the first and second variable of the head atom. AMIE is not designed to judge the quality of a predicted fact, but can compute the GPRO confidence on both variables. GRANK confidence. This refinement of the GPRO metric is proposed by <ref type="bibr" target="#b4">[5]</ref> in order to take into account the number of instances of the variables of the rule that are not in the head atom.</p><p>These metrics are implemented in AMIE 3 and can be enabled by command line switches.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments</head><p>We conducted two series of experiments to evaluate AMIE 3: In the first series we study the impact of our optimizations on the system's runtime. In the second series, we compare AMIE 3 with two scalable state-of-the-art approaches, namely RudiK <ref type="bibr" target="#b14">[15]</ref> and Ontological Pathfinding (OP) <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b3">4]</ref> (also known as ScaleKB) on 6 different datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Experimental Setup</head><p>Data. We evaluated AMIE 3 and its competitors on YAGO (2 and 2s), DBpedia (2.0 and 3.8) and a dump of Wikipedia from December 2014. These datasets were used in evaluations of AMIE+ <ref type="bibr" target="#b8">[9]</ref>, OP <ref type="bibr" target="#b2">[3]</ref> and Rudik <ref type="bibr" target="#b14">[15]</ref>. In addition, we used a recent dump of Wikidata from July 1st, 2019 <ref type="foot" target="#foot_3">6</ref> . Table <ref type="table" target="#tab_0">1</ref> shows the numbers of facts, relations, and entities of our experimental datasets.  Unless otherwise noted, the experiments were run using the default settings of AMIE: We used the PCA confidence, computed lazily with a threshold of 0.1, with all the lossless optimizations (no approximations). The threshold on the head coverage is 0.01 and the maximal rule length is 3 <ref type="bibr" target="#b7">[8]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Effect of our optimizations</head><p>In-memory database. Table <ref type="table" target="#tab_1">2</ref> shows the performance with the new integerbased in-memory database and the old ByteString database. The change reduces the memory footprint by around 3 GB in most cases, and by 50% in Wikidata. Moreover, the new database is consistently faster, up to 8-fold for the larger KBs such as DBpedia 3.8. Laziness. As explained in Section 4.2, AMIE can invest a lot of time in calculating the PCA confidence of low-confident rules. The lazy evaluation targets exactly this problem. Table <ref type="table" target="#tab_2">3</ref> shows that this strategy can reduce the runtime by a factor of 4. We also show the impact of laziness when the PCA confidence approximation is switched on. We observe that the parallel calculation of the overlap tables reduces drastically the contribution of this phase to the total runtime when compared to AMIE+ -where it could take longer than the mining itself. We also note that the residual impact of the confidence approximation is small, so that this feature is now dispensable: We can mine rules exhaustively.</p><p>Count variable order. To measure the impact of the count variable order, we ran AMIE 3 (with the lazy evaluation activated) on Yago2s and looked at the runtimes when counting with the variable that appears in the head atom versus the runtime when counting with the other variable. For every rule with three atoms and a support superior to 100, we timed the computation of the PCA confidence denominator (Equation <ref type="formula" target="#formula_4">4</ref>) in each case. The y-axis of Figure <ref type="figure">1</ref> shows the runtime when we first instantiate the variable that occurs in the head atom, whereas the x-axis shows the runtime when using the other variable.</p><p>We see that every query can be run in under 10 seconds and that most of the queries would run equally fast independently of the order of the variables. However, for some rules, instantiating first the variable that does not appear in the head atom can be worse than the contrary by several orders of magnitude. Some queries would take hours (days in one case) to compute, even with lazy evaluation. In Yago2s, these rules happen to be pruned away by the AMIE+ confidence upper bound (a lossless optimization), but this may not be the case for all KBs. The problematic rules all have bodies of the following shape:</p><formula xml:id="formula_12">hasGender (x, g) ∧ hasGender (y, g) isLocatedIn(x, l) ∧ isLocatedIn(y, l)</formula><p>Both hasGender and isLocatedIn are very large relations as they apply to any person and location, respectively. While early pruning of those "hard rules" is the purpose of the confidence approximations and upper bounds of AMIE+, these strategies may fail in a few cases, leading to the execution of expensive queries. Finally, we show the overall impact of the count variable order heuristic in Table <ref type="table" target="#tab_3">4</ref>. The results suggest that our heuristic generally yields lower runtimes. Impact of existential variable detection. Last but not least, the on-the-fly detection of existential variables reduces the number of recursive calls made to Algorithm 2. Table <ref type="table" target="#tab_4">5a</ref> shows the performances of AMIE 3 with and without this Other variable</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Head variable</head><p>Fig. <ref type="figure">1</ref>: Impact of the variable order on Yago2s. Each point is a rule. Cross points: pruned by the confidence approximation. Red line: same performance. Dashed lines: relative speedup of 10×. optimization. This optimization is critical for AMIE 3 on most datasets. This is less important for DBpedia 2.0 as it contains mostly small relations.</p><p>Metrics. Table <ref type="table" target="#tab_4">5b</ref> shows the impact of different quality metrics on the runtime, with iPCA being the PCA with injective mappings. The metrics run slower than the PCA confidence, because we cannot use the PCA upper bound optimization. The GRank metric, in particular, is very sensitive to the number of facts per relation, which explains its performance on Yago2s and DBpedia 3.8. For all other metrics, however, the numbers are very reasonable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Comparative Experiments</head><p>In this section, we compare the performance of AMIE 3 with two main state-ofthe-art algorithms for rule mining in large KBs, RuDiK and OP. AMIE 3. We ran AMIE 3 in its default settings. In order to compare the improvements to previous benchmarks of AMIE, we had AMIE compute the standard CWA confidence for each rule, in addition to the PCA confidence (except for Wikidata 2019, where no such previous benchmark exists).</p><p>RuDiK. We set the number of positive and negative examples to 500, as advised on the project's github page <ref type="foot" target="#foot_4">7</ref> . We tried to run the system in parallel for different head relations. However, the graph generation phase of the algorithm already runs in parallel and executes a lot of very selective SPARQL queries in parallel. Hence, the additional parallelization flooded the SPARQL endpoint, which rejected any new connection at some point. For this reason, we mined the rules for every possible relation sequentially, using only the original parallelization mechanism. RuDiK also benefits from information on the taxonomic types of the variables. While the built-in method to detect the types of the relations works out-of-the-box for DBpedia (which has a flat taxonomy), it overgeneralizes on the other datasets, inverting the expected benefits. Therefore, we ran RuDiK without the type information on the other datasets.</p><p>Ontological Pathfinding. This system first builds a list of candidate rules (Part 5.1 of <ref type="bibr" target="#b3">[4]</ref>). Unfortunately, the implementation of this phase of the algorithm is not publicly available. Hence, we had to generate candidate rules ourselves. The goal is to create all rules that are "reasonable", i.e., to avoid rules with empty joins such as birthPlace(x, y) ∧ hasCapital(x, z). The original algorithm discards all rules where the domain and range of joining relations do not match. However, it does not take into account the fact that an entity can be an instance of multiple classes. Thus, if the domain of actedIn is Actor, and the domain of directed is Director, the original algorithm would discard any rule that contains actedIn(x, y) ∧ directed(x, z) -even though it may have a non-empty support. Hence, we generated all candidate rules where the join between two connected atoms is not empty in the KB. This produces more candidate rules than the original algorithm (around 10 times more for Yago2s, i.e., 29762), but in return OP can potentially mine all rules that the other systems mine.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>It is not easy to compare the performance of OP, AMIE 3, and Rudik, because the systems serve different purposes, have different prerequisites, and mine different rules. Therefore, we ran all systems in their default configurations, and discuss the results (Table <ref type="table" target="#tab_5">6</ref>) qualitatively in detail. Ontological Pathfinding. We ran OP both with a domain-based candidate generation (which finds fewer rules) and with our candidate generation. In general, OP has the longest running times, but the largest number of rules. This is inherent to the approach: OP will prune candidate rules using a heuristic <ref type="bibr" target="#b2">[3]</ref> that is similar to the confidence approximation of AMIE+. After this step, it will compute the support and the exact CWA confidence of any remaining candidate. However, it offers no way of pruning rules upfront by support and confidence. This has two effects: First, the vast majority (&gt; 90%) of rules found by OP have very low confidence (&lt; 10%) or very low support (&lt; 100). Second, most of the time will be spent computing the confidence of these low-confidence rules, because the exact confidence is harder to compute for a rule with low confidence.</p><p>To reproduce the result of OP with AMIE, we ran AMIE 3 with a support threshold of 100 and a CWA confidence threshold of 10%. This reproduces the rules of OP (and 8 more because AMIE does not use the OP functionality heuristics) in less than two minutes. If we set our support threshold to 1, and our minimal CWA confidence to 10 -5 , then we mine more rules than OP on Yago2s (as shown in Table <ref type="table" target="#tab_5">6</ref>) in less time (factor 25×). If we mine rules with AMIE's default parameters, we mine rules in less than two minutes (factor 90×).</p><p>The large search space is even more critical for OP on DBpedia 3.8 and Wikidata 2019, as the number of candidate rules grows cubically with the number of relations. We generated around 9 million candidate rules for DBpedia and around 114 million candidates for Wikidata. In both cases, OP mined all rules of size 2 in 1h 20min (≈ 21k candidates) and 14 hours (≈ 100k candidates) respectively. However, it failed to mine any rule of size 3 in the remaining time. If we set the minimal support again to 1 and the CWA confidence threshold to 10 -5 , AMIE can mine twice as many rules as OP on DBpedia 3.8 in 33 minutes. RuDiK. For RuDiK, we found that the original parallelization mechanism does not scale well to 40 cores. The load average of our system, Virtuoso included, never exceeded 5 cores used. This explains the similar results between our benchmark and RuDiK's original experiments on Yago2s with fewer cores. On DBpedia, we could run the system also with type information -although this did not impact the runtime significantly. The loss of performance during the execution of the SPARQL queries is more noticeable due to the multitude of small relations in DBpedia compared to Yago. In comparison, AMIE was more than 20× faster on both datasets. This means that, even if RuDiK were to make full use of the 40 cores, and speed up 4-fold, it would still be 5 times slower. AMIE also found more rules than RuDiK. Among these are all rules that RuDiK found, except two (which were clearly wrong rules; one had a confidence of 0.001).</p><p>In our experiment, RuDiK mined rules in Wikidata in 23 hours. However, RuDiK was not able to mine rules for 22 of the relations as Virtuoso was not able to compute any of the positive or the negative examples RuDiK requires to operate. This is because RuDiK would timeout any SPARQL query after 20 seconds of execution 8 . Virtuoso failed to compute the examples during this time frame on the 22 relations, which are the largest ones in our Wikidata dataset: They cover 84% of the facts. Interestingly, RuDiK did also not find rules that contain these relations in the body (except one, which covered 0.5% of the KB).</p><p>In comparison, AMIE mined 1703 rules with at least one of these relations, computing the support, confidence and PCA confidence exactly on these huge relations -in less time. For example, it found the rule inRegion(x, y) ∧ inCountry(y, z) ⇒ inCountry(x, z), which is not considered by RuDiK, but has a support of over 7 million and a PCA confidence of over 99%. AMIE 3 outperformed both OP and RuDiK in terms of runtime and the number of rules. Moreover, it has the advantage of being exact and complete. Then again, the comparisons have to be seen in context: RuDiK, e.g., is designed to run on a small machine. For this, it uses a disk-based database and sampling. AMIE, in contrast, loads all data into memory, and thus has a large memory footprint (the 500GB were nearly used up for the Wikidata experiment). In return, it computes all rules exactly and is fast. 8 Increasing the timeout parameter is not necessarily a good solution for two reasons:</p><p>First, we cannot predict the optimal value so that all queries finish. Second, it would increase the runtime of queries succeeding with partial results thanks to Virtuoso's Anytime Query capability. This would largely increase RuDiK's runtime with no guarantee to solve the issue.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>We have presented AMIE 3, the newest version of the rule mining system AMIE.</p><p>The new system uses a range of optimization and pruning strategies, which allow scaling to large KBs that were previously beyond reach. In particular, AMIE 3 can exhaustively mine all rules above given thresholds on support and confidence, without resorting to sampling or approximations. We hope that the optimizations and subtleties exposed in this paper can carry over to other types of databases, and potentially other systems. AMIE is openly available at https://github.com/lajus/amie/.</p><p>Acknowledgements. Partially supported by the grant ANR-16-CE23-0007-01.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Experimental datasets</figDesc><table><row><cell>Dataset</cell><cell cols="2">Facts Relations</cell><cell>Entities</cell></row><row><cell>Yago2</cell><cell>948 358</cell><cell>36</cell><cell>834 750</cell></row><row><cell>Yago2s</cell><cell>4 484 914</cell><cell>37</cell><cell>2 137 469</cell></row><row><cell>DBpedia 2.0</cell><cell>6 601 014</cell><cell>1 595</cell><cell>2 275 327</cell></row><row><cell>DBpedia 3.8</cell><cell>11 024 066</cell><cell>650</cell><cell>3 102 999</cell></row><row><cell>Wikidata 12-2014</cell><cell>8 397 936</cell><cell>430</cell><cell>3 085 248</cell></row><row><cell cols="2">Wikidata 07-2019 386 156 557</cell><cell cols="2">1 188 57 963 264</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Old ByteString database vs. the new integer-based database.</figDesc><table><row><cell>Dataset</cell><cell>Loading time</cell><cell cols="4">Wall time Integer ByteString Integer ByteString Memory used</cell></row><row><cell>Yago2</cell><cell>7s</cell><cell>26.40s</cell><cell>29.69s</cell><cell>6Go</cell><cell>9Go</cell></row><row><cell>Yago2s</cell><cell cols="2">45s 1min 55s</cell><cell>4min 10s</cell><cell>16Go</cell><cell>19Go</cell></row><row><cell>DBpedia 2.0</cell><cell cols="2">55s 7min 32s</cell><cell>34min 06s</cell><cell>29Go</cell><cell>32Go</cell></row><row><cell>DBpedia 3.8</cell><cell cols="2">1min 20s 7min 49s</cell><cell>52min 10s</cell><cell>40Go</cell><cell>42Go</cell></row><row><cell>Wikidata 2014</cell><cell cols="2">59s 5min 44s</cell><cell>6min 01s</cell><cell>27Go</cell><cell>54Go</cell></row><row><cell cols="6">Configurations. All experiments were run on a Ubuntu 18.04.3 LTS with 40</cell></row><row><cell cols="6">processing cores (Intel Xeon CPU E5-2660 v3 at 2.60GHz) and 500Go of RAM.</cell></row><row><cell cols="6">AMIE 3 and RudiK are implemented in Java 1.8. AMIE 3 uses its own in-</cell></row><row><cell cols="6">memory database to store the KB, whereas RudiK relies on Virtuoso Open</cell></row><row><cell cols="6">Source 06.01.3127, accessed via a local endpoint. OP was implemented in Scala</cell></row><row><cell cols="2">2.11.12 and Spark 2.3.4.</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 :</head><label>3</label><figDesc>Impact of laziness and of switching on the confidence approximation. Ov. tables is the time needed to compute the overlap tables.</figDesc><table><row><cell>Dataset</cell><cell cols="2">Conf. Approx. off Non-lazy Lazy</cell><cell cols="3">Confidence Approximation on Non-lazy Lazy Ov. tables</cell></row><row><cell>Yago2</cell><cell>24.12s</cell><cell>26.40s</cell><cell>24.39s</cell><cell>21.41s</cell><cell>0.2s</cell></row><row><cell>Yago2s</cell><cell>4min 28s</cell><cell>1min 55s</cell><cell>1min 42s</cell><cell>2min 03s</cell><cell>2.4s</cell></row><row><cell>DBpedia 2.0</cell><cell>10min 14s</cell><cell>7min 32s</cell><cell>7min 42s</cell><cell>8min 13s</cell><cell>23.5s</cell></row><row><cell>DBpedia 3.8</cell><cell>14min 50s</cell><cell cols="3">7min 49s 11min 07s 10min 18s</cell><cell>15.2s</cell></row><row><cell>Wikidata 2014</cell><cell>19min 27s</cell><cell>5min 44s</cell><cell>5min 45s</cell><cell>4min 36s</cell><cell>12s</cell></row><row><cell>Wikidata 2019</cell><cell cols="4">&gt; 48h 16h 43min 17h 06min 16h 31min</cell><cell>41.4s</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 :</head><label>4</label><figDesc>Impact of the variable order: variable that appears in the head atom (new AMIE 3 heuristic); variable that does not appear in the head atom; variable that appears first in the head atom of the original rule (old AMIE method).</figDesc><table><row><cell>Dataset</cell><cell>Head</cell><cell cols="2">Non-head Always first</cell></row><row><cell>Yago2</cell><cell>26.40s</cell><cell>25.64s</cell><cell>23.59s</cell></row><row><cell>Yago2s</cell><cell>1min 55s</cell><cell>4min 32s</cell><cell>4min 30s</cell></row><row><cell>DBpedia 2.0</cell><cell>7min 32s</cell><cell>12min 46s</cell><cell>6min 36s</cell></row><row><cell>DBpedia 3.8</cell><cell>7min 49s</cell><cell>21min 12s</cell><cell>8min 53s</cell></row><row><cell>Wikidata 2014</cell><cell>5min 44s</cell><cell>36min 09s</cell><cell>9min 50s</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 5 :</head><label>5</label><figDesc>Performance with different features.</figDesc><table><row><cell cols="3">(a) Existential variable detection (ED)</cell><cell cols="4">(b) Different metrics (Section 4.3)</cell></row><row><cell>Dataset</cell><cell>AMIE 3</cell><cell>No ED</cell><cell>CWA</cell><cell>iPCA</cell><cell cols="2">GPro GRank</cell></row><row><cell>Yago2</cell><cell>26.40s</cell><cell>24.84s</cell><cell>22.54s</cell><cell>38.42s</cell><cell>37.47s</cell><cell>33.36s</cell></row><row><cell>Yago2s</cell><cell>1min 55s</cell><cell>&gt; 2h</cell><cell cols="3">1min 56s 3min 30s 2min 45s</cell><cell>&gt; 2h</cell></row><row><cell>DBpedia 2.0</cell><cell>7min 32s</cell><cell>9min 10s</cell><cell cols="4">7min 26s 12min 31s 11min 53s 1h 16min</cell></row><row><cell>DBpedia 3.8</cell><cell>7min 49s</cell><cell>&gt; 2h</cell><cell cols="3">6min 49s 15min 22s 23min 31s</cell><cell>&gt; 2h</cell></row><row><cell>Wikidata 2014</cell><cell>5min 44s</cell><cell>&gt; 2h</cell><cell cols="3">5min 48s 7min 04s 11min 50s</cell><cell>&gt; 2h</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 6 :</head><label>6</label><figDesc>Performances and output of Ontological Pathfinding (OP), RuDiK and AMIE 3. *: rules with support ≥ 100 and CWA confidence ≥ 0.1.</figDesc><table><row><cell>Dataset</cell><cell>System</cell><cell>Rules</cell><cell>Runtime</cell></row><row><cell></cell><cell>OP (their candidates)</cell><cell>429 (52*)</cell><cell>18min 50s</cell></row><row><cell></cell><cell>OP (our candidates)</cell><cell>1 348 (96*)</cell><cell>3h 20min</cell></row><row><cell>Yago2s</cell><cell>RuDiK</cell><cell>17</cell><cell>37min 30s</cell></row><row><cell></cell><cell>AMIE 3</cell><cell>97</cell><cell>1min 50s</cell></row><row><cell></cell><cell>AMIE 3 (support=1)</cell><cell>1 596</cell><cell>7min 6s</cell></row><row><cell></cell><cell>OP (our candidates)</cell><cell>7 714 (220*)</cell><cell>&gt; 45h</cell></row><row><cell>DBpedia 3.8</cell><cell>RuDiK RuDiK + types</cell><cell>650 650</cell><cell>12h 10min 11h 52min</cell></row><row><cell></cell><cell>AMIE 3</cell><cell>5 084</cell><cell>7min 52s</cell></row><row><cell></cell><cell>AMIE 3 (support=1)</cell><cell>132 958</cell><cell>32min 57s</cell></row><row><cell></cell><cell cols="2">OP (our candidates) 15 999 (326*)</cell><cell>&gt; 48h</cell></row><row><cell>Wikidata 2019</cell><cell>RuDiK</cell><cell>1 145</cell><cell>23h</cell></row><row><cell></cell><cell>AMIE 3</cell><cell>8 662</cell><cell>16h 43min</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_0"><p>https://spark.apache.org</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_1"><p>In line with the other works<ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b14">15]</ref>, we do not consider blank nodes.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_2"><p>http://fastutil.di.unimi.it/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_3"><p>Selecting only facts between two Wikidata entities, and excluding literals.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_4"><p>https://github.com/stefano-ortona/rudik</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Mining Expressive Rules in Knowledge Graphs</title>
		<author>
			<persName><forename type="first">N</forename><surname>Ahmadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">P</forename><surname>Huynh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Meduri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ortona</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Papotti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JDIQ</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Explainable Fact Checking with Probabilistic Answer Set Programming</title>
		<author>
			<persName><forename type="first">N</forename><surname>Ahmadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Papotti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Saeed</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference for Truth and Trust online</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Ontological Pathfinding</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Goldberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Johri</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016">2016</date>
			<publisher>SIG-MOD</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">ScaLeKB: Scalable Learning and Inference over Large Knowledge Bases</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Goldberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">VLDB Journal</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">6</biblScope>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Graph Pattern Entity Ranking Model for Knowledge Graph Completion</title>
		<author>
			<persName><forename type="first">T</forename><surname>Ebisu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ichise</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL-HLT</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Binary RDF Representation (HDT)</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Fernández</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Martínez-Prieto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Gutiérrez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Polleres</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Arias</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Web Semantics</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Canonicalizing Open Knowledge Bases</title>
		<author>
			<persName><forename type="first">L</forename><surname>Galárraga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Heitz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Suchanek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIKM</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">AMIE: Association Rule Mining Under Incomplete Evidence in Ontological Knowledge Bases</title>
		<author>
			<persName><forename type="first">L</forename><surname>Galárraga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Teflioudi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Hose</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Suchanek</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013">2013</date>
			<publisher>WWW</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Fast Rule Mining in Ontological Knowledge Bases with AMIE+</title>
		<author>
			<persName><forename type="first">L</forename><surname>Galárraga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Teflioudi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Hose</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">M</forename><surname>Suchanek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">VLDB Journal</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">6</biblScope>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Mining rules to align knowledge bases</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">A</forename><surname>Galárraga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Preda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">M</forename><surname>Suchanek</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013">2013</date>
			<publisher>AKBC</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Relational Association Rules: Getting WARMER</title>
		<author>
			<persName><forename type="first">B</forename><surname>Goethals</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Van Den Bussche</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Detection and Discovery</title>
		<imprint>
			<biblScope unit="volume">2447</biblScope>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Discovering meta-paths in large heterogeneous information networks</title>
		<author>
			<persName><forename type="first">C</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Maniu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Senellart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zhang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015">2015</date>
			<publisher>WWW</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Learning from Positive Data</title>
		<author>
			<persName><forename type="first">S</forename><surname>Muggleton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ILP</title>
		<imprint>
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Tuffy: Scaling up Statistical Inference in Markov Logic Networks using an RDBMS</title>
		<author>
			<persName><forename type="first">F</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Ré</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Doan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Shavlik</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1104.3216</idno>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Robust Discovery of Positive and Negative Rules in Knowledge Bases</title>
		<author>
			<persName><forename type="first">S</forename><surname>Ortona</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">V</forename><surname>Meduri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Papotti</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
			<publisher>ICDE</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Learning Logical Definitions from Relations</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Quinlan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine Learning</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="1990-08">Aug 1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">PARIS: Probabilistic Alignment of Relations, Instances, and Schema</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">M</forename><surname>Suchanek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Abiteboul</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Senellart</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PVLDB</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Knowledge Representation and Rule Mining in Entity-Centric KBs</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">M</forename><surname>Suchanek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lajus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Boschin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Weikum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Reasoning Web Summer School</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">QuickFOIL: Scalable Inductive Logic Programming</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Patel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Page</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">VLDB</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2014-11">Nov 2014</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
