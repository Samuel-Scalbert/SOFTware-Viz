<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Towards Extraction of Theorems and Proofs in Scholarly Articles</title>
				<funder ref="#_3znq7R7">
					<orgName type="full">Agence Nationale de la Recherche</orgName>
					<orgName type="abbreviated">ANR</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Shrey</forename><surname>Mishra</surname></persName>
							<email>shrey.mishra@ens.psl.eu</email>
						</author>
						<author>
							<persName><forename type="first">Pierre</forename><surname>Senellart</surname></persName>
							<email>pierre@senellart.com</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="laboratory">DI ENS</orgName>
								<orgName type="institution" key="instit1">ENS</orgName>
								<orgName type="institution" key="instit2">CNRS</orgName>
								<orgName type="institution" key="instit3">PSL University &amp; Inria Paris</orgName>
								<address>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="laboratory">DI ENS</orgName>
								<orgName type="institution" key="instit1">ENS</orgName>
								<orgName type="institution" key="instit2">CNRS</orgName>
								<orgName type="institution" key="instit3">PSL University &amp; Inria Paris</orgName>
								<address>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="laboratory">DI ENS</orgName>
								<orgName type="institution" key="instit1">ENS</orgName>
								<orgName type="institution" key="instit2">CNRS</orgName>
								<orgName type="institution" key="instit3">PSL University &amp; Inria &amp; IUF Paris</orgName>
								<address>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Towards Extraction of Theorems and Proofs in Scholarly Articles</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">F35962D12532EEC74F771327B2AD07C3</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-04-12T14:54+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Information systems ‚Üí Digital libraries and archives;</term>
					<term>Computing methodologies ‚Üí Artificial intelligence information extraction</term>
					<term>scholarly articles</term>
					<term>theorems</term>
					<term>proofs</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Scholarly articles in mathematical fields often feature mathematical statements (theorems, propositions, etc.) and their proofs. In this paper, we present preliminary work for extracting such information from PDF documents, with several types of approaches: vision (using YOLO), natural language (with transformers), and styling information (with linear conditional random fields). Our main task is to identify which parts of the paper to label as theorem-like environments and proofs. We rely on a dataset collected from arXiv, with L A T E X sources of research articles used to train the models.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Mathematical statements (theorems, propositions, definitions, etc.) and their proofs form some of the most important parts of scholarly articles in mathematical fields (e.g., mathematics, theoretical computer science, mathematical physics), and are usually of independent interest for scientists. However, scientific articles are often only available as PDF documents with no specific structure outlining statements and their proofs. We deal in this paper with the automatic extraction of such information.</p><p>We rely on machine learning techniques, and in this preliminary work explore several different approaches, based on computer vision, natural language, and document styles. The task is to automatically extract mathematical statements (generically referred to in the following as theorems) and their proofs and label them.</p><p>There is a rich literature on information extraction from scholarly articles <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b14">15]</ref> though none on extraction of theorems and proofs.</p><p>One of the closest work might be <ref type="bibr" target="#b5">[6]</ref> which identifies tables, lines, and formulas formulated as an object detection task using CNNs and a hybrid CRF model. This approach faces two major challenges: first, structured ordering of elements in scholarly articles is different from regular images that are the use case of popular object detection frameworks such as YOLO <ref type="bibr" target="#b10">[11]</ref> or Faster R-CNN <ref type="bibr" target="#b11">[12]</ref>, with in particular a smooth transition of pixel values around objects; second, spacing between objects in an article vary. For the specific task of table detection, it appears that vision-based approaches can nevertheless be very successful, as demonstrated using YOLO v3 <ref type="bibr" target="#b5">[6]</ref> and masked R-CNNs <ref type="bibr" target="#b9">[10]</ref> with nearly perfect F 1 scores on the ICDAR2013 and 2017 datasets.</p><p>In our setting, however, theorems and proofs are often differentiated by styling information such as special fonts or special characters such as the QED symbol at the end of the proof (see Figure <ref type="figure" target="#fig_0">1</ref>), which are hard to capture using vision-based techniques. Object detection techniques are also poorly adapted to the understanding of the sequencing of text and mathematics, which has a crucial impact on their semantics. Still, as a representative of a vision-based technique, we employ in this work YOLO v4 <ref type="bibr" target="#b2">[3]</ref> which shows significant performance gains over YOLO v3.</p><p>We also consider approaches based on natural language processing, in particular attention-based mechanisms readily exploited by transformer language models. These language models help to understand context information, including for longer text lengths, which can be lost by simpler models relying on, e.g., LSTM networks <ref type="bibr" target="#b0">[1]</ref>. The language models that we do use in this work (namely, BERT <ref type="bibr" target="#b4">[5]</ref>, DistilBERT <ref type="bibr" target="#b13">[14]</ref>, and SciBERT <ref type="bibr" target="#b1">[2]</ref>) have been pre-trained to understand the general language rules (English here). SciBERT, in particular, has been pretrained on 1.14 million papers in the scientific corpus (18% from computer science, 82% from biomedicine), which may make the vocabulary learned more useful for our task than that of language models trained on other corpora; SciBERT <ref type="bibr" target="#b1">[2]</ref> shows for instance better performance in sentence classification over scientific articles (ACL-ARC) in Computer Science than BERT. All these language models can be fine-tuned for a specific task, which is what we do in this work.</p><p>Even though language models can retain semantic information, they lack styling-based information. For example, knowing that a line starts with a "Theorem" word in bold is a very strong indicator that the line is the start of a theorem. One work that uses such information is <ref type="bibr" target="#b12">[13]</ref>, where a deep learning network is trained on features built out of the content and style of scientific articles to extract metadata of algorithms contained in the paper, reaching 78.5% accuracy (using RMSprop). In the same line, we also explore in this work a classifier trained from simple content and stylebased features. Specifically, we use a conditional random field (CRF) classifier to exploit the dependency of labeling from one line to the next, without requiring too many hyperparameters as with LSTMs.</p><p>We present in Section 2 our three different approaches, then the dataset and experiments in Section 3 before discussing the results and potential for future research in Section 4. All code and a description on how to acquire the data used in this article are made available at https://github.com/PierreSenellart/theoremkb.</p><p>Collecting and Labeling Data. Since there is no publicly available dataset for our task of interest, we collected publicly available articles from arXiv, using arXiv's bulk data access 1 . To automatically label this corpus, we focused on articles for which a L A T E X source is available (the vast majority of articles on arXiv in mathematical sciences, see <ref type="bibr" target="#b8">[9]</ref>). Indeed, when such source material is present, and when this source material uses standard L A T E X practices (\newtheorem to define theorem-like environments as well as the proof environment), it is possible to automatically label lines belonging to theorems and proofs by instrumenting a L A T E X run and producing PDF annotations corresponding to these labels. We use this as a way to obtain ground truth, however this might not be completely accurate if the source code contains a different way of initializing proofs/theorems see <ref type="bibr" target="#b8">[9]</ref> for more details; on the other hand, all information extraction techniques work on the unannotated PDF version of the papers, without access to the source material, which reflects the fact that L A T E X sources are rarely available outside arXiv.</p><p>Some post-processing is required on the result of the L A T E X-based extraction of theorems and proofs (see Figure <ref type="figure">2</ref>), in particular to filter out footers or empty annotation boxes which are an artifact of the L A T E X instrumentation. This is currently done with a hard-coded threshold that discards boxes with textual content such as page numbers, empty boxes generated (due to the rendering process) see Figure <ref type="figure">2</ref>.</p><p>Depending on the approach used, PDF articles are then either converted to bitmap images (for vision-based approaches) or processed using pdfalto 2 , which turns a PDF document into an XML file formed of a spatial index of all characters of the document organized into hierarchical blocks of text (pages, vertical blocks of lines, lines) along with styling information, as well as annotations (hyperlinks, etc.), as shown on Figure <ref type="figure">3</ref>.</p><p>Vision-Based Approach. Each page of the PDF image is rendered as a PNG bitmap image with line-based annotations of the ground truths corresponding to boxes. We then feed these bitmap images with (upscaled) boxes labeling objects corresponding to theorems and proofs to YOLOv4.</p><p>Previous versions of YOLO used Darknet53 as backbone network along with residual layers after every few blocks of convolution operations alongside batch normalization after every layer to combat gradient vanishing and internal covariance shift in the network. However, in YOLOv4 the authors have identified and grouped a range of different techniques that significantly increase the performance of the network into categories described as either bag of freebies (Cutmix, DropBlock, Mosaic Data Augmentation, label smoothing): applying these techniques increase the mAP of the model without compromising on the inference time; or bag of specials (Mish activation, Cross Stage Partial Connections, multi weighted input residual connections): these techniques increase the accuracy of detection with a small increase in the inference time.</p><p>The Intersection-over-Union (IoU) threshold kept for the selection of the boxes is 0.7. The problem is posed as a binary classification problem dealing with the object of interest in either proofs or 1 https://arxiv.org/help/bulk_data 2 https://github.com/kermitt2/pdfalto Language-Based Approaches. Textual information from each of the lines is extracted and prepared for a binary classification task of sequence prediction. We access and evaluate the performance of several autoencoding-based models such as Bert base <ref type="bibr" target="#b4">[5]</ref>, Distil-BERT base <ref type="bibr" target="#b13">[14]</ref> and SciBERT <ref type="bibr" target="#b1">[2]</ref>. These autoencoding-based models are trained using a word masking mechanism (masking 15% of the tokens), which we believe are well adapted to the task of theorem and proof identification.</p><p>The success of transformer-based models is heavily dependent on many crucial factors, some of them being: the quantity of data used for pretraining the model, which can be extremely large for, e.g., BERT; the number of data samples fed in for finetuning the model; the nature of content provided (e.g., SciBERT was specifically trained on a scientific corpus of papers, mostly in the biomedical domain); the size of the Encoder-Decoder stacks (BERT comes in three variants: base/small/large); the type of pretraining used (e.g., GPT-based models see everything before the next token as part of pretraining thus making them relevant for text generation tasks).</p><p>To contrast with these language models, we also trained a simple LSTM model based on parallel positional encoding, using 100 cells. This model serves as a baseline to evaluate the transformer-based models in the task of identifying proofs and theorems.</p><p>Styling-and Sequence-Based Approaches. From the pdfalto output we extract features that describe the document at different hierarchical levels. &lt;Page&gt;-level features simply include the global position in the document (begin, inside, end). &lt;TextBlock&gt; also has spacing information: the distance with the last and next blocks are computed, as well as the horizontal paddings. &lt;TextLine&gt; features are used to detect the presence of tabulations (horizontal spacing from the side of the container block) and patterns (a pre-existing sequence of text, meaning that it occurred often in the document, such as in the header or the footer section). &lt;String&gt; features include the normalized word, word-wise spacing information, detect if the font is in italic or bold, font size, word-position in the sentence, and the presence of digits and special characters. This small set of features is normalized and standardized across the document so that the model can focus on changes instead of values and become robust to global style changes. We also expand the features by computing for each token the difference between the current value and the previous/next one: this is important to detect local changes. Then, for a target resolution we derive the linear sequence of features for the chosen document, meaning that coarser-grained features are simply copied for each item (i.e., for each line in a page, the page-level features are copied along with the individual linelevel features) and finer-grained features are aggregated using the following methods: minimum value, maximum value, first value, last value, mean value.</p><p>As we obtain a tagged linear sequence of features, it can be used to train a linear-chain CRF. This class of probabilistic graphical models is very good for model sequences and has efficient inference algorithms. We use sklearn-crfsuite to perform the training. However, when dealing with a large number of features, the training time can remain high, and contrary to neural networks does not   All results for natural language techniques were run on under-sampled versions of the input (to avoid class imbalance), unless "unbalanced" is stated.</p><p>The learning rate used is 2 ‚Ä¢ 10 -5 . Finally, we also implemented a simple baseline that used some simple information from the document, along with sequential information, referred to in the following as the na√Øve algorithm: simply look for a set of target words ("Proof", "Theorem", etc.) in bold or italic at the beginning of a line and set the label of this line and all subsequent lines until the end of a "block" accordingly.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">DATASET AND EXPERIMENTS</head><p>The dataset<ref type="foot" target="#foot_0">3</ref> is formed of 4,400 PDF articles from the CS-CC category of arXiv (namely, Computer Science -Computational Complexity) category from 2010 to 2020.</p><p>In experiments, we compare the training time (see Table <ref type="table" target="#tab_0">1</ref>) and performance (see Tables <ref type="table" target="#tab_1">2,</ref><ref type="table" target="#tab_2">3</ref>, 4) of our various approaches.</p><p>We stress that those are preliminary experiments with the goal to simply explore what kind of performance levels can be reached by straightforward methods. In particular, note that none of the approaches based on computer vision or natural language can capture real sequence-based information (i.e., that the label of a line is heavily correlated with that of the previous and the following line) but attempt to label visual objects or individual lines separately. Also, note that each class of approaches exploits a different segment of understanding to decide on labels. A robust classifier would make a cumulative decision based on all features including vision, text, and styling information while also utilizing the sequence information across multiple lines.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">DISCUSSION &amp; FUTURE WORK</head><p>Discussion of results. By far the most effective approach tested in this work is training the linear-chain CRF classifier, even though this approach only utilizes sequence-based styling information at every line level. Results from Table <ref type="table" target="#tab_3">4</ref> clearly indicates that stylingbased semantics such as the font used and the ratio of bold or italic characters are alone a very strong indicator along with other styling-based features and sequence information. Another strong indicator of this fact is the not-too-bad performance of the na√Øve algorithm.</p><p>It may be surprising to see (Table <ref type="table" target="#tab_2">3</ref>) that language models such as Bert and SciBERT taking only information at an individual line level and disregarding any information about lines in the sequence can maintain a validation accuracy around 0.63 on undersampled data. Their main disadvantage however is the huge training time and space associated (see Table <ref type="table" target="#tab_0">1</ref>). A popular alternative we explored in this paper is DistilBERT <ref type="bibr" target="#b13">[14]</ref> which is 40% smaller in size while retaining 97% of its language processing capabilities and being 60% faster than Bert. In our model experimentation, we find very similar performance while detecting theorems and proofs to Bert-based models. Casing (distinguishing between lowercase and uppercase characters) seems to have little effect. Usage of the Scibert specific vocabulary generally improves the performance on scientific corpora, though this is fairly marginal even though special vocabulary adds an extra layer of information for the classifiers. Due to the large amount of training time required for each model, a single epoch of fine-tuning was run; continuing the evaluation on more epochs could improve accuracy.</p><p>The least desirable results are generated from using a computervision based approach; though raw results as observed by a human being are sometimes acceptable, these techniques suffer from the evaluation metric, where the IoU score plays an important role in determining the mAP; for the line identification task, this means precisely identifying the exact edges around proofs and theorems.</p><p>Perspectives. This work is an initial step made in the direction of extracting mathematical structures from scientific articles in PDF form. We plan to perform a more comprehensive study investigating the following future directions leading to potential performance improvements: Capturing sequential information based on several text lines instead of considering independently every individual line; Cumulatively building classifiers on the features extracted by each of the three approaches; Further training models for a large number of epochs to ensure convergence. Finally, note that, in vision-based approaches, building ensembles <ref type="bibr" target="#b3">[4]</ref> of several different types of techniques each acting as an individual weak learner can enhance mean average precision significantly especially with transformerbased vision techniques <ref type="bibr" target="#b6">[7]</ref> topping the leaderboards on object detection datasets.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Example proof excerpt, end-of-proof (QED) symbol</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :Figure 3 :</head><label>23</label><figDesc>Figure 2: Raw annotations resulting from the L A T E X processing of theorems and proofs</figDesc><graphic coords="3,351.92,83.68,170.08,236.98" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Loss function after 2000 iterations of YOLOv4</figDesc><graphic coords="4,122.87,83.69,102.11,148.67" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Inference time All trainings were made on a Tesla P100 GPU on Google Colaboratory with 15 GB of memory except for the CRF, trained on commodity hardware.</figDesc><table><row><cell>Approach</cell><cell cols="2">Training time (h) Model size (MB)</cell></row><row><cell>YOLOv4</cell><cell>6.42 (2000 Epochs)</cell><cell>244</cell></row><row><cell>LSTM</cell><cell>0.05 (4 Epochs)</cell><cell>19.9</cell></row><row><cell>LSTM (unbalanced)</cell><cell>0.12 (4 Epochs)</cell><cell>19.9</cell></row><row><cell>DistilBERT-base cased</cell><cell>3.47 (1 Epoch)</cell><cell>263.3</cell></row><row><cell>SciBERT-base cased</cell><cell>6.07 (1 Epoch)</cell><cell>440.1</cell></row><row><cell>BERT-base cased</cell><cell>6.27 (1 Epoch)</cell><cell>438.2</cell></row><row><cell cols="2">DistilBERT-base uncased 3.44 (1 Epoch)</cell><cell>263.3</cell></row><row><cell>SciBERT-base uncased</cell><cell>4.24 (1 Epoch)</cell><cell>440.1</cell></row><row><cell>BERT-base uncased</cell><cell>6.23 (1 Epoch)</cell><cell>438.2</cell></row><row><cell>Linear-chain CRF</cell><cell>5 (300 iterations)</cell><cell>0.24</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Performance: Computer vision</figDesc><table><row><cell cols="3">Approach Loss mAP/Accuracy</cell></row><row><cell>YOLOv4</cell><cell>8.68</cell><cell>0.416</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 :</head><label>3</label><figDesc>Performance: Natural language</figDesc><table><row><cell>Approach</cell><cell>Loss</cell><cell>mAP/Accuracy</cell></row><row><cell>LSTM</cell><cell>0.9620</cell><cell>0.4625</cell></row><row><cell>LSTM (unbalanced)</cell><cell>1.2571</cell><cell>0.4183</cell></row><row><cell>BERT-base cased</cell><cell>0.8232</cell><cell>0.6316</cell></row><row><cell>SciBERT-base cased</cell><cell>0.8165</cell><cell>0.6327</cell></row><row><cell>DistilBERT-base cased</cell><cell>0.8267</cell><cell>0.6302</cell></row><row><cell>Bert base-uncased</cell><cell>0.8222</cell><cell>0.6313</cell></row><row><cell>SciBERT-base uncased</cell><cell>0.8151</cell><cell>0.6357</cell></row><row><cell cols="2">DistilBERT-base uncased 0.8275</cell><cell>0.6287</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 :</head><label>4</label><figDesc>Performance: Styling</figDesc><table><row><cell>Approach</cell><cell cols="2">Precision Recall</cell><cell>F 1</cell></row><row><cell>Linear-chain CRF</cell><cell>0.800</cell><cell>0.834</cell><cell>0.816</cell></row><row><cell>Naive Algorithm</cell><cell>0.832</cell><cell>0.370</cell><cell>0.487</cell></row><row><cell cols="4">yet benefit from GPU acceleration. Feature selection methods (such</cell></row><row><cell cols="4">as L1-regularization) are therefore mandatory to reduce training</cell></row><row><cell>time and reduce overfitting.</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_0"><p>See https://github.com/PierreSenellart/theoremkb for links to individual papers; we cannot redistribute the entire dataset publicly because of licensing issues.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>ACKNOWLEDGEMENTS</head><p>This work has been funded by the <rs type="funder">French government</rs> under management of ANR as part of the "<rs type="programName">Investissements d'avenir" program</rs>, <rs type="grantNumber">ANR-19-P3IA-0001</rs> (<rs type="projectName">PRAIRIE 3IA Institute</rs>).</p></div>
			</div>
			<listOrg type="funding">
				<org type="funded-project" xml:id="_3znq7R7">
					<idno type="grant-number">ANR-19-P3IA-0001</idno>
					<orgName type="project" subtype="full">PRAIRIE 3IA Institute</orgName>
					<orgName type="program" subtype="full">Investissements d&apos;avenir&quot; program</orgName>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Neural Machine Translation by Jointly Learning to Align and Translate</title>
		<author>
			<persName><forename type="first">Dzmitry</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">SciBERT: A pretrained language model for scientific text</title>
		<author>
			<persName><forename type="first">Iz</forename><surname>Beltagy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kyle</forename><surname>Lo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arman</forename><surname>Cohan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP/IJCNLP</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">YOLO v4: Optimal Speed and Accuracy of Object Detection</title>
		<author>
			<persName><forename type="first">Alexey</forename><surname>Bochkovskiy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chien-Yao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hong-Yuan Mark</forename><surname>Liao</surname></persName>
		</author>
		<idno>CoRR 2004.10934</idno>
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Ensemble methods for object detection</title>
		<author>
			<persName><forename type="first">√Ångela</forename><surname>Casado</surname></persName>
		</author>
		<author>
			<persName><forename type="first">-</forename><surname>Garc√≠a</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J√≥nathan</forename><surname>Heras</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECAI</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">BERT: Pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL-HLT</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Page object detection from PDF document images by deep structured prediction and supervised clustering</title>
		<author>
			<persName><forename type="first">Xiao-Hui</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fei</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cheng-Lin</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICPR</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Swin transformer: Hierarchical vision transformer using shifted windows</title>
		<author>
			<persName><forename type="first">Ze</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yutong</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yue</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Han</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yixuan</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephen</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Baining</forename><surname>Guo</surname></persName>
		</author>
		<idno>CoRR 2103.14030</idno>
		<imprint>
			<date type="published" when="2021">2021. 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">GROBID: Combining automatic bibliographic data recognition and term extraction for scholarship publications</title>
		<author>
			<persName><forename type="first">Patrice</forename><surname>Lopez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">TPDL</title>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<author>
			<persName><forename type="first">Lucas</forename><surname>Pluvinage</surname></persName>
		</author>
		<ptr target="https://hal.inria.fr/hal-02956526" />
		<title level="m">A knowledge base of mathematical results</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
		<respStmt>
			<orgName>ENS, PSL University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Master&apos;s thesis</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">CascadeTabNet: An approach for end to end table detection and structure recognition from image-based documents</title>
		<author>
			<persName><forename type="first">Devashish</forename><surname>Prasad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ayan</forename><surname>Gadpal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kshitij</forename><surname>Kapadni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Manish</forename><surname>Visave</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kavita</forename><surname>Sultanpure</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR Workshops</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">YOLOv3: An incremental improvement</title>
		<author>
			<persName><forename type="first">Joseph</forename><surname>Redmon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ali</forename><surname>Farhadi</surname></persName>
		</author>
		<idno>CoRR 1804.02767</idno>
		<imprint>
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Faster R-CNN: towards real-time object detection with region proposal networks</title>
		<author>
			<persName><forename type="first">Kaiming</forename><surname>Shaoqing Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ross</forename><forename type="middle">B</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jian</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page">6</biblScope>
			<date type="published" when="2017">2017. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Deep Learning-based Extraction of Algorithmic Metadata in Full-Text Scholarly Documents</title>
		<author>
			<persName><forename type="first">Iqra</forename><surname>Safder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Saeed-Ul</forename><surname>Hassan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anna</forename><surname>Visvizi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thanapon</forename><surname>Noraset</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Raheel</forename><surname>Nawaz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Suppawong</forename><surname>Tuarob</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Processing &amp; Management</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page">102269</biblScope>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Dis-tilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter</title>
		<author>
			<persName><forename type="first">Victor</forename><surname>Sanh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lysandre</forename><surname>Debut</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julien</forename><surname>Chaumond</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Wolf</surname></persName>
		</author>
		<idno>CoRR 1910.01108</idno>
		<imprint>
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Scholarly big data information extraction and integration in the citeseer ùúí digital library</title>
		<author>
			<persName><forename type="first">Kyle</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jian</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sagnik</forename><forename type="middle">Ray</forename><surname>Choudhury</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Madian</forename><surname>Khabsa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">Lee</forename><surname>Giles</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICDE workshops</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
