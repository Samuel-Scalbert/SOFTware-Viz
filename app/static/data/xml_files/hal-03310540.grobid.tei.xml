<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Reproducible Performance Optimization of Complex Applications on the Edge-to-Cloud Continuum</title>
				<funder>
					<orgName type="full">HPC-BigData Inria Challenge (IPL)</orgName>
				</funder>
				<funder ref="#_PvTmqTM">
					<orgName type="full">Agence Nationale de la Recherche</orgName>
					<orgName type="abbreviated">ANR</orgName>
				</funder>
				<funder>
					<orgName type="full">Inria</orgName>
				</funder>
				<funder>
					<orgName type="full">CNRS</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Daniel</forename><surname>Rosendo</surname></persName>
							<email>daniel.rosendo@inria.fr</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">University of Rennes</orgName>
								<orgName type="institution" key="instit2">Inria</orgName>
								<orgName type="institution" key="instit3">CNRS</orgName>
								<orgName type="institution" key="instit4">IRISA -Rennes</orgName>
								<address>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Alexandru</forename><surname>Costan</surname></persName>
							<email>alexandru.costan@inria.fr</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">University of Rennes</orgName>
								<orgName type="institution" key="instit2">Inria</orgName>
								<orgName type="institution" key="instit3">CNRS</orgName>
								<orgName type="institution" key="instit4">IRISA -Rennes</orgName>
								<address>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Gabriel</forename><surname>Antoniu</surname></persName>
							<email>gabriel.antoniu@inria.fr</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">University of Rennes</orgName>
								<orgName type="institution" key="instit2">Inria</orgName>
								<orgName type="institution" key="instit3">CNRS</orgName>
								<orgName type="institution" key="instit4">IRISA -Rennes</orgName>
								<address>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Matthieu</forename><surname>Simonin</surname></persName>
							<email>matthieu.simonin@inria.fr</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">University of Rennes</orgName>
								<orgName type="institution" key="instit2">Inria</orgName>
								<orgName type="institution" key="instit3">CNRS</orgName>
								<orgName type="institution" key="instit4">IRISA -Rennes</orgName>
								<address>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jean-Christophe</forename><surname>Lombardo</surname></persName>
							<email>jean-christophe.lombardo@inria.fr</email>
							<affiliation key="aff1">
								<orgName type="institution" key="instit1">University of Montpellier</orgName>
								<orgName type="institution" key="instit2">Inria</orgName>
								<orgName type="institution" key="instit3">CNRS</orgName>
								<orgName type="institution" key="instit4">LIRMM -Montpellier</orgName>
								<address>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Alexis</forename><surname>Joly</surname></persName>
							<email>alexis.joly@inria.fr</email>
							<affiliation key="aff1">
								<orgName type="institution" key="instit1">University of Montpellier</orgName>
								<orgName type="institution" key="instit2">Inria</orgName>
								<orgName type="institution" key="instit3">CNRS</orgName>
								<orgName type="institution" key="instit4">LIRMM -Montpellier</orgName>
								<address>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Patrick</forename><surname>Valduriez</surname></persName>
							<email>patrick.valduriez@inria.fr</email>
							<affiliation key="aff1">
								<orgName type="institution" key="instit1">University of Montpellier</orgName>
								<orgName type="institution" key="instit2">Inria</orgName>
								<orgName type="institution" key="instit3">CNRS</orgName>
								<orgName type="institution" key="instit4">LIRMM -Montpellier</orgName>
								<address>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Reproducible Performance Optimization of Complex Applications on the Edge-to-Cloud Continuum</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">EDF42A1B16DFD58CFF177D44C1BB9EF3</idno>
					<idno type="DOI">10.1109/Cluster48925.2021.00043</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-04-12T14:45+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Reproducibility</term>
					<term>Methodology</term>
					<term>Computing Continuum</term>
					<term>Optimization</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In more and more application areas, we are witnessing the emergence of complex workflows that combine computing, analytics and learning. They often require a hybrid execution infrastructure with IoT devices interconnected to cloud/HPC systems (aka Computing Continuum). Such workflows are subject to complex constraints and requirements in terms of performance, resource usage, energy consumption and financial costs. This makes it challenging to optimize their configuration and deployment.</p><p>We propose a methodology to support the optimization of reallife applications on the Edge-to-Cloud Continuum. We implement it as an extension of E2Clab, a previously proposed framework supporting the complete experimental cycle across the Edge-to-Cloud Continuum. Our approach relies on a rigorous analysis of possible configurations in a controlled testbed environment to understand their behaviour and related performance tradeoffs. We illustrate our methodology by optimizing Pl@ntNet, a world-wide plant identification application. Our methodology can be generalized to other applications in the Edge-to-Cloud Continuum.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>The continuous increase of IoT devices and captured data requires rethinking where to process data. Instead of the traditional data center compute model, one main approach used in big data is to leverage compute resources distributed at multiple processing points in the system -from endpoint devices at the edge of the network to data centers or HPC systems at its core. This distributed infrastructure, referred to as the Computing Continuum <ref type="bibr" target="#b0">[1]</ref> (or Digital Continuum), combines heterogeneous computing resources that generate and process data across geographically distributed Edge, Fog, and Cloud/HPC infrastructures.</p><p>Real-world applications deployed on such hybrid infrastructure (e.g., smart factory <ref type="bibr" target="#b1">[2]</ref>, autonomous vehicles <ref type="bibr" target="#b2">[3]</ref>, among others) typically need to comply with many constraints related to resource consumption (e.g., GPU, CPU, memory, storage and bandwidth capacities), software components composing the application and requirements such as QoS, security, and privacy <ref type="bibr" target="#b3">[4]</ref>. Furthermore, optimizing application workflows on distributed and heterogeneous resources (i.e., minimizing processing latency, energy consumption, financial costs, etc.) is challenging. The parameter settings of the applications and the underlying infrastructure result in a complex multiinfrastructure configuration search space <ref type="bibr" target="#b4">[5]</ref>.</p><p>The intricacies of these configurations require, prior to production-level deployment, analysis in a controlled testbed environment in order to understand their performance tradeoffs (i.e., latency and energy consumption, throughput and resource usage, cost and service availability, etc.) <ref type="bibr" target="#b5">[6]</ref>, <ref type="bibr" target="#b6">[7]</ref>.</p><p>Let us illustrate this problem with Pl@ntNet <ref type="bibr" target="#b7">[8]</ref>, a largescale participatory application for botanical data and AI-based plant identification. Pl@ntNet's main feature is a mobile app that allows smartphone users to identify plants from photos and share their observations (Figure <ref type="figure" target="#fig_7">1</ref>). It has more than 10 million users all around the world and processes about 400K plant images per day. One main challenge faced by Pl@ntNet engineers is to anticipate the necessary evolution of the infrastructure to pass the upcoming spring peak (Figure <ref type="figure" target="#fig_0">2</ref>) and adapt the system configuration to some expected evolution of application usage (e.g., an increase of its number of users).</p><p>There are simulation and emulation tools for the Cloud, Fog, Edge, Fog-to-Cloud, Edge-to-Fog <ref type="bibr" target="#b8">[9]</ref>- <ref type="bibr" target="#b11">[12]</ref>. However, there is no solution for large-scale deployment and evaluation of reallife applications on testbeds that cover the entire Computing Continuum as a whole and guide application optimization (i.e., minimizing costs, latency, resource consumption, among others) of the entire application workflow.</p><p>In this paper, we propose a methodology to support the optimization of real-life applications on the Edge-to-Cloud Continuum. This methodology is useful to help decide on application configurations to optimize relevant metrics (e.g., performance, resource usage, energy consumption, etc.) by means of computationally tractable optimization techniques <ref type="bibr" target="#b12">[13]</ref>. It eases the configuration of the system components distributed on Edge, Fog, and Cloud infrastructures as well as the decision where to execute the application workflow components to minimize communication costs and end-to-end latency.</p><p>We implemented this methodology as an extension of the E2Clab <ref type="bibr" target="#b13">[14]</ref> framework for automatic application deployment and reproducible experimentation. This paper has the following main contributions: 1) A methodology to optimize the performance of reallife applications on the Computing Continuum, lever-Fig. <ref type="figure" target="#fig_7">1</ref>: The Pl@ntNet application.</p><p>aging computationally tractable optimization techniques (Section III). 2) An implementation of this optimization methodology as an extension of the E2Clab framework for reproducible analysis of applications on the Edge-to-Cloud continuum. For this purpose, we enhanced E2Clab with an optimization layer. To the best of our knowledge, this enhanced version of E2Clab is the first framework to support the complete deployment and analysis cycle of a complex workflow executed on the Computing Continuum (Section III-D). 3) A large scale experimental validation of the proposed approach with the Pl@ntNet application on 42 nodes of the Grid'5000 testbed <ref type="bibr" target="#b14">[15]</ref>. Our approach helps optimizing Pl@ntNet software configurations across the continuum to minimize user response time (Section IV).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. BACKGROUND</head><p>Application workflows that need to be deployed across Edge-to-Cloud infrastructures usually have to configure their software components while considering various infrastructure constraints. For instance, in the Cloud, configurations can include compute and storage configurations, the number of topics in a data ingestion system, reserved memory in data processing frameworks, the inter-cloud network latency, etc. In the Fog, they can include the streaming window size on gateways, the network latency and bandwidth between Fog devices, among others. In the Edge we can refer to device capabilities, the frequency of data emission, the power consumption, among others. These environment settings and configuration parameters are extremely vast and their combination of possibilities virtually unlimited. Hence, the process of searching the ideal deployment and configuration of those real-life applications is challenging given the search space complexity: bad choices may result in increased financial expenses during deployment and production phases, decreased processing efficiency and poor user experience. A. A real-life application: Pl@ntNet Pl@ntNet is a participatory application and platform dedicated to the production of botanical data and plant identification. Currently, the data consists of +35K plant species collected from more than 200 countries. As illustrated in Figure <ref type="figure" target="#fig_7">1</ref>, using the Pl@ntNet mobile application, users (located in the Edge) may identify plants from pictures taken by their phones. Before sending these pictures, some preprocessing is done to reduce the image size.</p><p>Then, the Pl@ntNet Identification Engine (located in the Cloud), subject to analysis in this work, is responsible for the automatic identification of species through Deep Learning. In a nutshell, the Identification Engine performs two main activities: (1) Species prediction: refers to the feature extraction and classification of user images; and (2) Similarity Search: searches for the images of the botanical databases that are the most similar to the user images. At the end of the processing, the Identification Engine returns the ranked list of most probable species with their respective, most similar plant pictures, allowing interactive validation by the users.</p><p>The processing performance of the Identification Engine strongly depends on the thread pool size configured to process the various tasks involved during the identification of users images. Table <ref type="table" target="#tab_0">I</ref> presents the execution order of all tasks, the thread pool they belong to, and in which hardware they take place. Table <ref type="table" target="#tab_1">II</ref> describes the role of each thread pool and an example of configuration currently used in the Pl@ntNet production servers. This configuration was defined by Pl@ntNet engineers based on their best practical experience with the Pl@ntNet system considering mainly the following: (a) for thread pools using CPU: a machine with 40 CPU cores available; and (b) for the GPU thread pool: the maximum number of threads which fit in GPU memory.</p><p>The main performance metric for this application is the user response time. A preliminary analysis <ref type="bibr" target="#b15">[16]</ref> showed that to achieve a 4 seconds response time (the maximum tolerated by users) the thread pool and hardware configurations can not serve more than 120 simultaneous requests (3.86±0.13), as shown in Figure <ref type="figure">3</ref>. In this context, meaningful questions that arise are: Is there a better thread pool allocation that minimizes the user response time? How many more users can the system serve if we find a better thread pool configuration?  The answers to those questions and more analytical insights will be presented in Section IV through the use of our proposed methodology and its implementation in the E2Clab framework.</p><p>Let us highlight that Pl@ntNet is representative of other applications in the context of the Computing Continuum. As illustrated in Figure <ref type="figure" target="#fig_7">1</ref>, it consists of many geographically distributed devices (over 10 million users) that collect and send data (about 400K plant images per day), and perform preprocessing at the Edge, followed by extensive processing (e.g., species prediction, similarity search, etc.) in centralized Cloud/HPC infrastructures.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Formalizing deployment optimization on the Edge-to-Cloud Continuum</head><p>We describe our optimization problem by defining: the optimization variables, the objective function, and the constraints (Equation <ref type="formula" target="#formula_0">1</ref>).</p><formula xml:id="formula_0">min/max x fm(x), m = 1, 2, . . . , M subject to gj (x) ≤ 0, j = 1, 2, . . . , J Inequality constraints. h k (x) = 0, k = 1, 2, . . . , K Equality constraints. x L i ≤ xi ≤ x U i , i = 1, 2, . . . , I Bounds on variables.<label>(1)</label></formula><p>Typically, Edge-to-Cloud deployment optimization problems aim at optimizing metrics <ref type="bibr" target="#b5">[6]</ref>, <ref type="bibr" target="#b16">[17]</ref> related to: performance (e.g., execution time, latency, and throughput), resource usage (e.g., GPU, CPU, memory, storage, and network), energy consumption, financial costs, and quality attributes (e.g., reliability, security, and privacy). Therefore, regarding the formulation of an optimization problem and its mathematical representation in Equation 1, the optimization variables x refer to the variables associated with the optimization problem Fig. <ref type="figure">3</ref>: Pl@ntNet Engine: user response time. (e.g., storage capacity of Edge devices, or number of cores on Fog nodes).</p><p>The objective function refers to the optimization objective, such as minimizing or maximizing a given metric or set of metrics (e.g., performance, energy consumption). The objective function maps the values of the optimization variables onto real numbers and may be classified as single-objective (such as minimizing Edge-to-Cloud processing latency) or multiobjective (e.g., minimizing energy consumption of Fog nodes and maximize throughput).</p><p>Finally, the constraints refer to requirements that a given solution must satisfy. Constraints may refer to a specific optimization variable (e.g., number of cores on Fog nodes between 10 and 20) and the metrics to be optimized by the objective function (e.g., the maximum response time must be less than 3 seconds).</p><p>Figure <ref type="figure" target="#fig_1">4</ref> depicts some examples of optimization problems. Left, one would like to answer the question: how to configure the system components to minimize processing latency? To reduce complexity, the optimization problem is divided into three sub-problems each one with the objective of minimizing the task processing time on the Edge, Fog, and Cloud infrastructures, under specific constraints. The right-hand example aims at answering the question: where should the workflow components be executed to minimize communication costs and end-to-end latency? This translates into a single multiobjective optimization problem (minimizing communication costs and end-to-end latency), as opposed to the previous example (several single-objective optimization problems). In order to model and solve such optimization problems, one may find multiple methods and packages in the literature. For instance, packages and libraries such as Scikit-Optimize <ref type="bibr" target="#b17">[18]</ref>, Scikit-Learn <ref type="bibr" target="#b18">[19]</ref>, Surrogate Modeling Toolbox (SMT) <ref type="bibr" target="#b19">[20]</ref>, DeepHyper <ref type="bibr" target="#b20">[21]</ref>, etc., may be used to build surrogate models and then use those model to explore the search space of the optimization problem.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. E2Clab: reproducible Edge-to-Cloud experiments</head><p>E2Clab <ref type="bibr" target="#b13">[14]</ref> is a framework that implements a rigorous methodology for designing experiments with real-world workloads on the Edge-to-Cloud Computing Continuum. This methodology, illustrated in Figure <ref type="figure" target="#fig_4">6</ref>, provides guidelines to move from real-world use cases to the design of relevant testbed setups for experiments enabling researchers to understand performance and to support the reproducibility of the experiments.</p><p>E2Clab architecture is described in Figure <ref type="figure" target="#fig_5">7</ref>. The idea is that experiments can accurately reproduce relevant behaviors of a given application workflow on representative settings of the physical infrastructure underlying this application.</p><p>The key features provided by E2Clab are: (1) reproducible experiments; (2) the mapping of applications parts executed across the computing continuum with the physical testbed; (3) the support for experiment variation and transparent scaling of the scenario; (4) network emulation to define Edge-to-Cloud communication constraints; and (5) experiment deployment, monitoring and backup of results. E2Clab is open source and is available at <ref type="bibr" target="#b21">[22]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. A METHODOLOGY FOR OPTIMIZING THE PERFORMANCE OF APPLICATIONS ON THE EDGE-TO-CLOUD CONTINUUM</head><p>Our optimization methodology supports reproducible parallel optimization of application workflows on large-scale testbeds. It consists of three main phases illustrated in Figure <ref type="figure" target="#fig_2">5</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Phase I: Initialization</head><p>This phase, depicted at the top of Figure <ref type="figure" target="#fig_2">5</ref>, consists in defining the optimization problem. The user must specify: the optimization variables that compose the search space to be explored (e.g., GPUs used for processing, Fog nodes in the scenario, network bandwidth, etc.); the objective (e.g., minimize end-to-end latency, maximize Fog gateway throughput, etc.); and constraints (e.g. the upper and lower bounds of optimization variables, budget, response time latency, etc.).</p><p>One may focus the optimization on: (1) specific parts of the infrastructure (e.g., only on geographically distributed Edge sites, or only on Fog-to-Cloud resources) by defining multiple, per infrastructure, optimization problems, as presented in the left side of Figure <ref type="figure" target="#fig_1">4</ref>. This approach reduces the search space complexity (in case of use cases with large search spaces) and hence the computing time; <ref type="bibr" target="#b1">(2)</ref> or the whole Edge-to-Cloud infrastructure as a single optimization problem, as presented in the right side of Figure <ref type="figure" target="#fig_1">4</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Phase II: Evaluation</head><p>This phase aims at defining the mathematical methods and optimization techniques used in the optimization cycle (presented in the middle of Figure <ref type="figure" target="#fig_2">5</ref>) to explore the search space. Such optimization cycle consists in: (1) parallel deployment of the application workflow in a large-scale testbed; (2) their simultaneous execution; (3) asynchronous model optimization; and (4) reconfiguration of the application workflow for a new evaluation.</p><p>This cycle continues until model convergence. Depending on the run time characteristics of the application workflows, their evaluations may be performed differently.</p><p>1) Long-time Running Applications: refer to experiments or simulations for which the evaluation of a single point in the search space requires a lot of time to complete (e.g., hours, or even days). Furthermore, since application workflows in the context of the Computing Continuum typically consist of cross-infrastructure parameter configurations resulting in a myriad of configuration possibilities, their optimization problem presents a complex and large search space.</p><p>For those long-time running applications, a variety of Bayesian Optimization <ref type="bibr" target="#b22">[23]</ref> methods (e.g., surrogate models as: Gaussian process (Kriging) <ref type="bibr" target="#b23">[24]</ref>, Decision Trees <ref type="bibr" target="#b24">[25]</ref>, Random Forest <ref type="bibr" target="#b25">[26]</ref>, Gradient Boosting Regression Trees <ref type="bibr" target="#b26">[27]</ref>, Support Vector Machine <ref type="bibr" target="#b27">[28]</ref>, Polynomial Regression <ref type="bibr" target="#b28">[29]</ref>, among others) may be applied as candidates to explore the search space. Their generation is described below.</p><p>Surrogate Model Building: this consists of three steps: (a) a few sample points are generated, respecting the upper and lower limits of each optimization variable that composes the search space. Sampling methods such as Latin Hypercube Sample <ref type="bibr" target="#b29">[30]</ref> or Low Discrepancy Sample <ref type="bibr" target="#b30">[31]</ref>   generated, it is used to explore the optimization search space by deciding the subsequent application configurations to be evaluated in parallel. As soon as the evaluations finish, the model is retrained and optimized asynchronously, then new points are suggested to be evaluated.</p><p>2) Short-time Running Applications: refer to the case when a few minutes are enough to evaluate a single point in the search space. Such applications also follow the optimization cycle previously presented. Besides, they may also use surrogate models to explore the search space. However, differently from Long-time Running Use Cases, they can use other optimization techniques such as evolutionary algorithms and swarm intelligence based algorithms (e.g., Genetic Algorithm <ref type="bibr" target="#b31">[32]</ref>, Differential Evolution <ref type="bibr" target="#b32">[33]</ref>, Simulated Annealing <ref type="bibr" target="#b33">[34]</ref>, Particle Swarm Optimization <ref type="bibr" target="#b34">[35]</ref>, etc.).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Phase III: Finalization</head><p>For reproducibility purposes, this last phase illustrated at the bottom of Figure <ref type="figure" target="#fig_2">5</ref> provides a summary of computations. Therefore, it provides: the definition of the optimization problem (optimization variables, objective, and constraints); the sample selection method; the surrogate models or search algorithms with their hyperparameters used to explore the search space of the optimization problem; and finally the best application configuration found. Providing all this information at the end of computations allows other researches to reproduce the research results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Implementation as an extension of the E2Clab framework</head><p>To validate our optimization approach, we enhanced the E2Clab framework for reproducible experimentation across the Edge-to-Cloud Continuum. We extended <ref type="bibr" target="#b21">[22]</ref> the E2Clab framework <ref type="bibr" target="#b35">[36]</ref> with support for the performance optimization of application workflows. Figure <ref type="figure" target="#fig_4">6</ref> shows a holistic view of our enhanced methodology containing the extensions highlighted in dashed lines colored in red. As one may note, we have added a new sub-process named Define Optimization (detailed in Figure <ref type="figure" target="#fig_2">5</ref>) inside the Define the Experimental Environment process.</p><p>Figure <ref type="figure" target="#fig_5">7</ref> illustrates the E2Clab architecture. We designed a new manager named Optimization Manager (which implements the optimization approach in Figure <ref type="figure" target="#fig_2">5</ref>). Its role is to: interpret the user-defined optimization setup defined in the optimizer conf configuration file and then automate the optimization cycle (1. parallel deployment of the application workflow in a large-scale testbed; 2. simultaneous application workflow execution; 3. asynchronous model optimization; and 4. reconfiguration of the application workflow for a new evaluation) in order to optimize the application workflow. Laslty, the Optimization Manager provides a summary of computations for reproducibility purposes.</p><p>The Optimization Manager takes advantage of Ray <ref type="bibr" target="#b36">[37]</ref> to run parallel application workflows on the Grid'5000 largescale testbed. Ray Tune <ref type="bibr" target="#b37">[38]</ref>   Ax <ref type="bibr" target="#b39">[40]</ref>, HEBO <ref type="bibr" target="#b40">[41]</ref>, among others). Next, users define in the run objective() function (Listing 1 line 28) their optimization logic, which runs in parallel to train the model. To do so, the Optimization class provides the following three methods: i) prepare(): for reproducibility of optimization evaluations, it generates a dedicated optimization directory for each model evaluation (Listing 1 line 30). ii) launch(): deploys the application on a large-scale testbed to perform a model evaluation (Listing 1 line 32). For reproducibility, deployment-related information are captured, such as physical machines, network constraints, and application configurations. iii) finalize(): for reproducibility purposes, it stores the optimization computations for a given model evaluation in the optimization directory created in the prepare() phase (Listing 1 line 34). Saved information refers to intermediate models throughout training and points evaluated. Listing 1 shows how one may define an optimization problem (e.g., Pl@ntNet problem in Eq. 2). A detailed example may be found on the E2Clab documentation Web page <ref type="bibr" target="#b35">[36]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. EXPERIMENTAL VALIDATION</head><p>In this section we illustrate our proposed optimization methodology by showing how it can be used to analyze the performance of the Pl@ntNet botanical application and to find its thread pool configurations. The goal of our experiments is to answer the following research questions:</p><p>1) What is the software configuration, for a given hardware configuration, that minimizes the user response time? 2) How does the number of simultaneous users accessing the system impact on the user response time? 3) How do the Extraction and Similarity Search thread pool configurations impact the processing time and user response time?</p><p>The experimental setup is defined as follows: a) Scenario Configuration: the experiments are carried out on 42 nodes of the Grid'5000 <ref type="bibr" target="#b14">[15]</ref> testbed (clusters chifflot, chiclet, chetemi, chifflet, and gros). Since the Pl@ntNet Identification Engine requires GPU, it is deployed on the chifflot machines (model Dell PowerEdge R740), which are equipped with Nvidia Tesla V100-PCIE-32GB GPUs, Intel Xeon Gold 6126 (Skylake, 2.60GHz, 2 CPUs/node, 12 cores/CPU), 192GB of memory, 480GB SSD, and 25Gbps Ethernet interface. The clients submitting requests to the Pl@ntNet Identification Engine are deployed on the chiclet, chetemi, chifflet, and gros clusters. The network connection is configured with 10Gb.</p><p>b) Workloads: we defined three categories of workloads, according to the number of simultaneous requests (i.e., 80, 120, and 140) submitted to the Pl@ntNet Identification Engine during the whole experiment execution. c) Configuration Parameters: Table <ref type="table" target="#tab_1">II</ref> presents the parameters used to configure the thread pool size of the Pl@ntNet Engine. As presented in Equation <ref type="formula" target="#formula_1">2</ref>, these parameters refer to the optimization variables of the optimization problem.</p><p>d) Performance Metrics: the metric of interest is the user response time. In Equation 2, this metric is to be minimized as the optimization objective. The user response time refers to the average time that a user waits for the response to a request. Besides this metric, we also analyze the identification processing time, which refers to the average time to process a user request. The identification processing is divided into multiple tasks running in parallel, as described in Table <ref type="table" target="#tab_0">I</ref>.</p><p>We compare and analyze the user response time and identification processing time with respect to two thread pool configurations: baseline and preliminary optimum. The baseline refers to the current Pl@ntNet configuration used in the production servers. This configuration was defined by Pl@ntNet engineers based on their best practical experience with the Pl@ntNet system, as explained in Subsection II-A and presented in Table <ref type="table" target="#tab_1">II</ref>.</p><p>The preliminary optimum configuration is the one found using our methodology. We named it preliminary since the optimization problem may have multiple minima and one may find other application configurations if a different technique is used (e.g., Gaussian Process (Kriging) <ref type="bibr" target="#b23">[24]</ref>, Gradient Boosting Regression Trees <ref type="bibr" target="#b26">[27]</ref>, among others). Besides, changes in the hardware configuration (e.g., size of GPU memory, number of CPU cores, among others) running the Pl@ntNet application will require a new search for the thread pool sizes since their configuration strongly depends on the hardware. In this case, our optimization methodology should be applied again. In a subsequent step, we further refine the preliminary optimum In order to obtain accurate measurements we run each experiment (each thread pool configuration) 7 times and each experiment has a duration of 23 minutes (1380 seconds). Besides, during the execution of each experiment we collect the metric values every 10 seconds. Therefore, the user response time is presented with the mean and standard deviation regarding 966 measurements (138 * 7).</p><p>We highlight that, since through experiments we identified variations between measurements, we decided to repeat each configuration 6 times (7 experiments) to reduce the standard deviation of measurements. Besides, we run each experiment for 23 minutes with an interval of metric collection of 10 seconds to also minimize the standard deviation of the metrics collected. Furthermore, thanks to the repeatability feature provided in E2Clab, one may repeat those experiments easily by issuing the following command: e2clab optimize -repeat 6 -duration 1380 path/to/backup/experiments/ path/to/artifacts/.</p><p>A. What is the software configuration that minimizes the user response time?</p><p>The optimization problem to be solved can be stated as follows:</p><p>Find (http, download, simsearch, extract), in order to Minimize U serResponseT ime Subject to 20 ≤ (http, download, simsearch) ≤ 60, P ool Size.</p><p>3 ≤ (extract) ≤ 9, P ool Size.</p><p>(</p><formula xml:id="formula_1">)<label>2</label></formula><p>The function UserResponseTime is given by the parallel execution of the Pl@ntNet workflow on the Grid'5000 testbed, as described in Phase II of our methodology.</p><p>In order to define the search space dimensions we run experiments to identify the maximum upper bounds of variables that do not increase the user response time compared to the baseline Pl@ntNet configuration. Therefore, the lower and upper bounds of variables (see Equation <ref type="formula" target="#formula_1">2</ref>) are ±50% of the baseline configuration (recall Table <ref type="table" target="#tab_1">II</ref>), respectively.</p><p>The workload uses 80 simultaneous requests to the Pl@ntNet Identification engine. We highlight that this number has to be bigger than the upper bound of the HTTP thread pool size since the HTTP pool refers to the simultaneous requests being processed. We leverage Bayesian Optimization since it is typically used for global optimization of black-box functions that are expensive to evaluate <ref type="bibr" target="#b41">[42]</ref>. Extra Trees regressor is used as surrogate model <ref type="bibr" target="#b17">[18]</ref> to model our expensive function. This surrogate model is improved by evaluating the User-ResponseTime function at the next points. The goal is to find the minimum of UserResponseTime function with as few evaluations as possible. Listing 1 lines 6 to 11 detail the search algorithm parameters. The minimization has converged after 9 evaluations and the results are presented in Table <ref type="table" target="#tab_2">III</ref> (considering a workload of 80 simultaneous requests). As one may note, the preliminary optimum configuration reduces the user response time by 7% and can serve 35% more simultaneous users (54 against 40, see the HTTP thread pool).</p><p>From the results, we highlight that thanks to our optimization methodology implemented in E2Clab, one may easily find an optimized application configuration. E2Clab abstracts all the complexities to: define the whole optimization problem (recall to Listing 1); deploy the application; run parallel evaluations of the optimization in a large-scale testbed; and collect all the experiments results. In the next subsections we enhance our analysis in order to: (a) understand the performance of both configurations for different workloads; and (b) better understand the performance results and their correlation with the resource usage.</p><p>B. How does the number of simultaneous users accessing the system impact on the user response time?</p><p>In order to understand the impact of different workloads on the user response time, we defined three workloads that represent simultaneous requests submitted to the Pl@ntNet system. The goal of these experiments is to compare the performance gains of the preliminary optimum thread pool configuration (found using our methodology) against the baseline (current Pl@ntNet configuration). Lastly, we exploit the maximum number of simultaneous requests that each configuration can handle considering the 3-4 seconds user response time constraint.</p><p>As presented in Figure <ref type="figure" target="#fig_8">8</ref>, we scale up the workloads as follows: 80, 120, and 140 simultaneous requests. As one may note, in Figure <ref type="figure" target="#fig_8">8</ref> the preliminary optimum configuration outperforms the baseline for all workloads. We highlight that, the difference between them varied as follows: 6.9%, 2.2%, and 6.7% for 80, 120, and 140 simultaneous requests, respectively.</p><p>The main observation is that the preliminary optimum configuration (found using our methodology) outperforms the baseline thanks to a better thread pool allocation that allows  the Pl@ntNet system to serve simultaneously 35% more requests (54 against 40) with a smaller user response time when compared to the baseline. We also highlight that, thanks to the transparent scaling feature provided by E2Clab, one may easily scale up the workloads to analyze their impact on the application performance.</p><p>C. How do the Extraction and Similarity Search thread pool configurations impact the processing and user response times?</p><p>Since the extraction and similarity search tasks are the most time consuming compared to the remaining ones, we zoom our analysis on them in an attempt to improve even more the thread pool configuration and also to identify possible bottlenecks on the Pl@ntNet identification engine. The experiment aims to understand how variations in the preliminary optimum thread pool configuration of the extraction and similarity search tasks impact the user response time and the processing time of the identification tasks.</p><p>We apply Sensitivity Analysis techniques to explore the impact of such variations. From the existing Sensitivity Analysis methods we decided to use One-at-a-time (OAT) <ref type="bibr" target="#b42">[43]</ref>. OAT is a simple and common approach that consists in varying a single parameter at a time to identify the effect on the output.</p><p>In our case, the parameters are extract and simsearch thread pool sizes. We vary the extract pool size in ±2 from the current size (7 threads), while the simsearch in ±3 (current size is 53 and for simplification, we do not present in Figure <ref type="figure" target="#fig_12">10a</ref> the times for 50 and 51 since they are bigger than 52). These variations result in 10 new thread pool configurations to be evaluated. Therefore, we take advantage of E2Clab to automatically run them in a reproducible way, following E2Clab's methodology.</p><p>Figure <ref type="figure" target="#fig_10">9</ref> shows the impact of extraction threads on: (a) the user response time and (b) the time to process each task. Furthermore, we also analyze their impact on resource usage, such as: (c) CPU usage (d) GPU memory, (e) system memory, (f) extract pool busy time, and (g) simsearch pool busy time.</p><p>In Figure <ref type="figure" target="#fig_10">9a</ref>, we observe that the preliminary optimum configuration with 7 extract threads does not produce the minimum user response time, since using 6 extract threads reduces it by 8.5%. Decreasing to 5 threads or increasing it to 8 or 9 threads impacts negatively when compared to 6 threads. The explanation for this behaviour is given next.   Regarding the processing time (Figure <ref type="figure" target="#fig_10">9b</ref>), as expected, the wait-extract time reduces as we increase the number of extract threads, while the simsearch task time increases. This time increase in the simsearch task can be explained by Figure <ref type="figure" target="#fig_10">9c</ref>, since using 8 and 9 extract tasks results in a CPU usage of 100% during the whole application execution, so as those tasks compete for processing resources, allocating more extract threads impacts negatively on the simsearch task time. As for the remaining sizes, they varied between 85% and 100%. This behaviour explains the results observed for the user response time presented in Figure <ref type="figure" target="#fig_10">9a</ref>. Furthermore, differently from the wait-extract time, the extract task time was not reduced when increasing the extract thread pool size.</p><p>By analyzing the impact on the GPU memory usage (Figure <ref type="figure" target="#fig_10">9d</ref>), we observe that it increases as we allocate more threads to the extract thread pool and it remains constant during the application execution. The GPU utilization for all thread pool sizes is between 35% and 60% most of the time, while the GPU power draw is between 50 Watts and 80 Watts. As the GPU memory usage, the system memory usage (Figure <ref type="figure" target="#fig_10">9e</ref>) of the Docker container running the Pl@ntNet Engine also increases with the extract thread pool size.</p><p>Lastly, the extract thread pool busy time (Figure <ref type="figure" target="#fig_10">9f</ref>) is 100% during the whole application execution for thread pool sizes Fig. <ref type="figure" target="#fig_7">11</ref>: User response time: baseline vs optimums. of 5, 6, and 7, and between 80% and 100% for sizes of 8 and 9. This explains the higher and lower values, respectively, of the wait-extract times observed in Figure <ref type="figure" target="#fig_10">9b</ref>. For the similarity search (Figure <ref type="figure" target="#fig_10">9g</ref>), the thread pool busy time is between 80% and 100% for a size of 8 and 9. For the 5, 6, and 7 thread pool sizes it is 50%, 55%, and 60% busy in average, respectively. This also explains the higher values of wait-simsearch for sizes 8 and 9 compared to 5, 6, and 7 in Figure <ref type="figure" target="#fig_10">9b</ref>.</p><p>Following our analysis, Figure <ref type="figure" target="#fig_12">10</ref> shows the impact of the thread pool size for similarity search on: (a) user response time and (b) processing time. Besides, in Figure <ref type="figure" target="#fig_12">10c</ref> and Figure <ref type="figure" target="#fig_12">10d</ref> we show the thread pool busy time for the similarity search and extract thread pools, respectively.</p><p>In Figure <ref type="figure" target="#fig_12">10a</ref>, as one may note, the preliminary optimum configuration with 53 threads may be increased to 55 threads in order to reduce by about 4% the user response time. Regarding the processing time (Figure <ref type="figure" target="#fig_12">10b</ref>), the simsearch task time confirms what was observed with the user response time, that is, adding more than 55 threads is not worth to decrease the execution time of the simsearch task.</p><p>Figure <ref type="figure" target="#fig_12">10c</ref> shows the correlation of the similarity search pool busy time with the simsearch task time observed in Figure <ref type="figure" target="#fig_12">10b</ref> and explains its variation. Using 52 threads it is busy between 90% and 100%, while for 53 to 55 it is below 60%, and increases to about 80% with 56 threads. The impact of the similarity search thread pool variation on extract task (Figure <ref type="figure" target="#fig_12">10b</ref>) can be explained by Figure <ref type="figure" target="#fig_12">10d</ref>. Lower times in wait-extract for sizes 52 and 56 is due to a busy time between 90% and 100%. For sizes from 53 to 55, the busy time is 100%.</p><p>Since we observed a lower user response time after analyzing the impact of variations of the extract and simsearch thread pool configurations on the user response time, we exploit this configuration (named refined optimum) with all the previously defined workloads. As presented in Table <ref type="table" target="#tab_3">IV</ref> and Figure <ref type="figure" target="#fig_7">11</ref>, we observed even better results for all workloads.</p><p>Let us note that for all workloads the refined optimum presents the best results, outperforming both baseline and preliminary optimum. Compared with the baseline, the difference between configurations varied with the workloads as follows: from 6.9% to 7.2%; from 2.2% to 6.3%; and from 6.7% to 9.8% for 80, 120, and 140 simultaneous requests, respectively.</p><p>In summary, the analysis presented in this section backed by our optimisation methodology helped to understand how variations in the thread pool configuration of the Pl@ntNet engine impact on the processing times (user response time and identification processing steps) by correlating them with the resource usage. Furthermore, this analysis helps to improve the performance of the application by supporting 35% more simultaneous users (54 against 40) and presenting a smaller user response time for different workloads (80, 120, and 140 simultaneous requests) and 30% less GPU memory utilization (7GB against 10GB), when compared to the baseline.</p><p>Let us also highlight that, despite our evaluations focusing on the Pl@ntNet as a use case, our methodology and its implementation in E2Clab can be used to analyze other applications in the context of the Edge-to-Cloud Computing Continuum (more details in Section V-C).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. DISCUSSION</head><p>The enhanced E2Clab exhibits a series of features that make it a promising platform for future performance optimization of applications on the Edge-to-Cloud Continuum through reproducible experiments. We briefly discuss them here.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Reproducible application optimization</head><p>Our optimization methodology is aligned with the Open Science <ref type="bibr" target="#b43">[44]</ref> goal to make scientific research processes more transparent and results more accessible. As presented in Section III, it is implemented as an extension of the E2Clab framework for reproducible experimentation across the Edgeto-Cloud Continuum. It provides guidelines to systematically define the whole optimization cycle, such as: (Phase-I) defines the optimization problem and the application-related parameters to optimize; (Phase-II) defines the sampling methods and the optimization techniques and hyperparameters; and (Phase-III) provides access to the optimization results.</p><p>The whole optimization cycle is defined through a configuration file (Listing 1). This file was designed to be easy to use and to understand, and it can be easily adapted to different optimization problems (find out more in the documentation Web page <ref type="bibr" target="#b35">[36]</ref>). At the end of each optimization cycle, E2Clab provides an archive of the generated data. Such archive consists of data from Phases I and II, needed to allow other researches to reproduce the research results. Regarding this work, the access to the experimental artifacts; definition of the experimental environment; and experimental results are publicly available at <ref type="bibr" target="#b44">[45]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Scalable and parallel application optimization on largescale testbeds</head><p>The proposed optimization methodology enables scalable (on large-scale testbeds), parallel (through asynchronous model training) and reproducible (by following a rigorous experimental methodology) application optimization. This approach speeds up the search of application parameters thanks to parallel and asynchronous application deployments on largescale testbeds which helps to significantly reduce the application optimization time from days to hours compared to a sequential optimization approach.</p><p>The parallel evaluation of the application configuration has the potential to scale to hundreds of machines in a large-scale testbed. Therefore, one may compute simultaneously 10, 20, or even more (depending on the testbed limits and the hardware requirements of the application) evaluations of the objective function to speed-up the computations. We plan to explore this potential in future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Optimizing other applications</head><p>Our approach is generic: the optimization of other applications may be achieved by describing the application optimization problem in the optimization configuration file. It allows one to define the optimization cycle and easily adapt it to different optimization application-specific problems.</p><p>Furthermore, users may easily apply our methodology to their applications thanks to the Services abstraction provided by E2Clab. Services represent any system or a group of systems that provide a specific functionality or action in the scenario workflow. For instance, such services may refer to Flink, Spark or Kafka clusters, among others.</p><p>In order to support their applications, users have to implement their User-Defined Services. For this purpose, E2Clab provides a Service class in which users have to override a deploy method to define the deployment logic of their services, such as: the distribution of services to the physical machines; and to install the required software to run these services. Next, E2Clab's Service class provides a method to register the user services. Lastly, E2Clab managers will be able to deploy each service on the testbed. Therefore, in the work described in this paper, we had to implement the Pl@ntNet service.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. RELATED WORK</head><p>With the popularity of complex application workflows requiring hybrid execution infrastructures, the holistic analysis of such applications combining IoT Edge devices and Cloud/HPC systems has been a very active field of research in the last few years.</p><p>Existing solutions focus on the simulation and emulation of parts of the Edge-to-Cloud infrastructure. Edge-CloudSim <ref type="bibr" target="#b10">[11]</ref> is an environment for performance evaluation of Edge computing systems that provides simulation for Edge-based scenarios. Users may run experiments considering computational and networking resources. EmuFog <ref type="bibr" target="#b11">[12]</ref> is an extensible emulation framework for Fog-based scenarios that allows the emulation of real applications and workloads. However, they focus on the Edge and Fog layers separately, not on the Edge-to-Cloud Continuum as a whole.</p><p>In <ref type="bibr" target="#b45">[46]</ref>, the authors proposed an approach for automated deployment (using Kubernetes <ref type="bibr" target="#b46">[47]</ref>) of Cloud applications in the Edge-to-Cloud Continuum. This approach explores methods for selection of the optimal infrastructure, satisfying QoS requirements of Cloud applications. While, A3-E <ref type="bibr" target="#b47">[48]</ref> provides a unified model for managing the life cycle of continuum applications (mobile, Edge, and Cloud resources). A3-E focuses on the placement of computation along the continuum based on the specific context and user requirements. However, both works fail on providing configuration control of the parameters of the application and of the underlying Edgeto-Cloud infrastructure; it is widely known and demonstrated that configuration strongly impacts performance. Thus, that support is essential for performing reproducible experiments.</p><p>In contrast, our optimization methodology integrates reproducibility by design, and its implementation within E2Clab enables instrumentation of real-life applications on large-scale testbeds across the entire Edge-to-Cloud Continuum.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VII. CONCLUSIONS</head><p>The optimization methodology proposed in this paper has proven useful for understanding and improving the performance of a real-life application used in production at largescale. Thanks to the extension presented in this work, E2Clab becomes, to the best of our knowledge, the first framework to support the complete deployment and analysis cycle of application workflows executed on the Computing Continuum, including deployment, configuration, monitoring, and gathering of results, and now performance optimization.</p><p>We have validated our proposed optimization methodology at large scale on 42 nodes of the Grid 5000 testbed. We have shown how it can be used to analyze and optimize the performance of the Pl@ntNet botanical application, used by more than 10 million users in 180 countries.</p><p>The thread pool allocation found using our methodology increases the number of simultaneous requests processed in parallel by 35% compared to the baseline; it reduces user response time for different workloads; and consumes 30% less GPU memory. Despite our focus on Pl@ntNet, the methodology can be generalized to other applications in the Edge-to-Cloud Continuum.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 2 :</head><label>2</label><figDesc>Fig. 2: Exponential growth of new users every spring (peaks in May-June).</figDesc><graphic coords="3,340.85,50.54,193.32,123.28" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 4 :</head><label>4</label><figDesc>Fig. 4: Edge-to-Cloud Continuum optimization problems.</figDesc><graphic coords="4,311.98,175.15,251.05,163.15" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 5 :</head><label>5</label><figDesc>Fig. 5: Our proposed optimization methodology.</figDesc><graphic coords="5,48.96,50.54,251.04,174.14" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>may be applied; (b) then, from the generated sample, parallel experiments (deployment of application workflows) are run for each parameter set; (c) lastly, the surrogate model is trained on the dataset generated in the previous step. Model Retraining &amp; Application Optimization: once the surrogate model is trained on the sample points previously</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 6 :</head><label>6</label><figDesc>Fig. 6: Extended E2Clab experimental methodology.</figDesc><graphic coords="6,53.98,50.54,241.02,251.67" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 7 :</head><label>7</label><figDesc>Fig. 7: Extended E2Clab architecture.</figDesc><graphic coords="6,335.83,50.54,203.35,251.21" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>23 " 33 # backup the optimization computations 34 self.finalize() 35 #</head><label>23333435</label><figDesc>provides state of the art search algorithms; manages model checkpoints and logging; and methods for analyzing training. User-defined optimization (i.e., how to setup an optimization?): the Optimization Manager offers a class-based API that allows researchers to setup and control the model training. Users have to inherit the Optimization class and define in the run() function (Listing 1 line 5) the optimization configuration through several state of the art single-objective and multi-objective Bayesian Optimization search algorithms (e.g., from libraries such as Scikit-Optimize [18], Dragonfly [39], 1 from e2clab.optimizer import Optimization 2 3 class UserDefinedOptimization(Optimization): http": tune.randint(20, 60), 24 "download": tune.randint(20, 60), 25 "simsearch": tune.randint(20, 60), 26 "extrac": tune.randint(3, 9)}) 27 28 def run_objective(self, _config): 29 # create an optimization directory 30 self.prepare() 31 # deploy the configs on the testbed 32 self.launch() report the metric value to Ray Tune</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Listing 1 :</head><label>1</label><figDesc>Example of a user-defined optimization in E2Clab.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 8 :</head><label>8</label><figDesc>Fig. 8: User response time: baseline vs preliminary.</figDesc><graphic coords="8,61.52,50.54,225.95,106.38" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head></head><label></label><figDesc>(a) user response time. (b) processing time. (c) CPU usage. (d) GPU memory usage. (e) system memory usage.(f) extract pool busy time.(g) simsearch pool busy time.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Fig. 9 :</head><label>9</label><figDesc>Fig. 9: Impact of extract thread variability.</figDesc><graphic coords="9,54.10,301.99,251.89,101.68" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head></head><label></label><figDesc>(a) user response time. (b) processing time. (c) simsearch pool busy time.(d) extract pool busy time.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Fig. 10 :</head><label>10</label><figDesc>Fig. 10: Impact of similarity search thread variability.</figDesc><graphic coords="10,54.10,155.82,251.89,100.70" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>TABLE I :</head><label>I</label><figDesc>Identification processing steps.</figDesc><table><row><cell>Task</cell><cell>Description</cell><cell>Thread pool</cell><cell>Hardware</cell></row><row><cell>pre-process</cell><cell>Decoding the query parame-ters.</cell><cell>HTTP</cell><cell>CPU</cell></row><row><cell>wait-download</cell><cell>Wait for an available download thread.</cell><cell>HTTP, Download</cell><cell>CPU</cell></row><row><cell>download</cell><cell>Download images.</cell><cell>Download</cell><cell>CPU</cell></row><row><cell>wait-extract</cell><cell>Wait for an available extractor thread.</cell><cell>HTTP, Extract</cell><cell>CPU, GPU</cell></row><row><cell>extract</cell><cell>DNN inference of the image.</cell><cell>Extract</cell><cell>GPU</cell></row><row><cell></cell><cell>Process classification and sim-</cell><cell></cell><cell></cell></row><row><cell>process</cell><cell>ilarity search output at query</cell><cell>HTTP</cell><cell>CPU</cell></row><row><cell></cell><cell>level.</cell><cell></cell><cell></cell></row><row><cell>wait-simsearch</cell><cell>Wait for an available similarity search thread.</cell><cell>HTTP, Simsearch</cell><cell>CPU</cell></row><row><cell>simsearch</cell><cell>Search the most similar images in our database.</cell><cell>Simsearch</cell><cell>CPU</cell></row><row><cell>post-process</cell><cell>Check processed query results and format the response.</cell><cell>HTTP</cell><cell>CPU</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>TABLE II :</head><label>II</label><figDesc>Thread pool configuration of Pl@ntNet Engine.</figDesc><table><row><cell>Thread pool</cell><cell>Size (# threads)</cell><cell>Description</cell><cell>Hardware</cell></row><row><cell>HTTP</cell><cell>40</cell><cell># simultaneous requests being processed.</cell><cell>CPU</cell></row><row><cell>Download</cell><cell>40</cell><cell># simultaneous images being downloaded.</cell><cell>CPU</cell></row><row><cell>Extract</cell><cell>7</cell><cell># simultaneous inferences in a single GPU.</cell><cell>GPU</cell></row><row><cell>Simsearch</cell><cell>40</cell><cell># simultaneous similarity search.</cell><cell>CPU</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>TABLE III :</head><label>III</label><figDesc>Baseline vs preliminary optimum configurations.</figDesc><table><row><cell>Thread pool</cell><cell>baseline</cell><cell>preliminary optimum</cell></row><row><cell>HTTP</cell><cell>40</cell><cell>54</cell></row><row><cell>Download</cell><cell>40</cell><cell>54</cell></row><row><cell>Extract</cell><cell>7</cell><cell>7</cell></row><row><cell>Simsearch</cell><cell>40</cell><cell>53</cell></row><row><cell cols="3">User response time 2.657 (±0.0914) 2.484 (±0.0912)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>TABLE IV :</head><label>IV</label><figDesc>Comparison of the three Pl@ntNet configurations.</figDesc><table><row><cell>Thread pool</cell><cell>baseline</cell><cell>preliminary optimum</cell><cell>refined optimum</cell></row><row><cell>HTTP</cell><cell>40</cell><cell>54</cell><cell>54</cell></row><row><cell>Download</cell><cell>40</cell><cell>54</cell><cell>54</cell></row><row><cell>Extract</cell><cell>7</cell><cell>7</cell><cell>6</cell></row><row><cell>Simsearch</cell><cell>40</cell><cell>53</cell><cell>53</cell></row><row><cell>User response</cell><cell>2.657</cell><cell>2.484</cell><cell>2.476</cell></row><row><cell>time</cell><cell>(±0.0914)</cell><cell>(±0.0912)</cell><cell>(±0.0826)</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>ACKNOWLEDGMENTS</head><p>This work was funded by <rs type="funder">Inria</rs> through the <rs type="funder">HPC-BigData Inria Challenge (IPL)</rs> and by <rs type="funder">French ANR OverFlow</rs> project (<rs type="grantNumber">ANR-15-CE25-0003</rs>). Experiments presented in this paper were carried out using the Grid'5000 testbed, supported by a scientific interest group hosted by <rs type="funder">Inria</rs> and including <rs type="funder">CNRS</rs>, RENATER and several Universities as well as other organizations. We also would like to thank <rs type="person">Romain Egele</rs>, <rs type="person">Jaehoon Koo</rs>, <rs type="person">Prasanna Balaprakash</rs>, and <rs type="person">Orcun Yildiz</rs> from <rs type="affiliation">Argonne National Laboratory</rs> for their support.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_PvTmqTM">
					<idno type="grant-number">ANR-15-CE25-0003</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<author>
			<persName><forename type="first">P</forename><surname>Beckman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Dongarra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Ferrier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Fox</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Moore</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Reed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Beck</surname></persName>
		</author>
		<title level="m">Harnessing the Computing Continuum for Programming Our World</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="215" to="230" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Adaptive computing optimization in softwaredefined network-based industrial internet of things with fog computing</title>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sensors</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page">2509</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Multi-objective optimization technique for resource allocation and task scheduling in vehicular cloud architecture: A hybrid adaptive nature inspired approach</title>
		<author>
			<persName><forename type="first">S</forename><surname>Midya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Roy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Majumder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Phadikar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Network and Computer Applications</title>
		<imprint>
			<biblScope unit="volume">103</biblScope>
			<biblScope unit="page" from="58" to="84" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Combining heuristics to optimize and scale the placement of iot applications in the fog</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Etchevers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Letondeur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Lebre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Coupaye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Desprez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE/ACM 11th International Conference on Utility and Cloud Computing (UCC)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2018">2018. 2018</date>
			<biblScope unit="page" from="153" to="163" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">The next grand challenges: Integrating the internet of things and data science</title>
		<author>
			<persName><forename type="first">R</forename><surname>Ranjan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Rana</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Nepal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Yousif</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>James</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Barr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Watson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">P</forename><surname>Jayaraman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Georgakopoulos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Cloud Computing</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="12" to="26" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Classification of optimization problems in fog computing</title>
		<author>
			<persName><forename type="first">J</forename><surname>Bellendorf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">Á</forename><surname>Mann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Future Generation Computer Systems</title>
		<imprint>
			<biblScope unit="volume">107</biblScope>
			<biblScope unit="page" from="158" to="176" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A survey on industrial internet of things: A cyber-physical systems perspective</title>
		<author>
			<persName><forename type="first">H</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Griffith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Golmie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="78" to="238" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A look inside the pl@ntnet experience</title>
		<author>
			<persName><forename type="first">A</forename><surname>Joly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Bonnet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Goëau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Barbe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Selmi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Champ</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Dufour-Kowalski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Affouard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Carré</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-F</forename><surname>Molino</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Multimedia Systems</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="751" to="766" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Cloudsim: a toolkit for modeling and simulation of cloud computing environments and evaluation of resource provisioning algorithms</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">N</forename><surname>Calheiros</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ranjan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Beloglazov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A</forename><surname>De Rose</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Buyya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Software: Practice and experience</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="23" to="50" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">ifogsim: A toolkit for modeling and simulation of resource management techniques in the internet of things, edge and fog computing environments</title>
		<author>
			<persName><forename type="first">H</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Vahid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">K</forename><surname>Dastjerdi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ghosh</surname></persName>
		</author>
		<author>
			<persName><surname>Buyya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Software: Practice and Experience</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1275" to="1296" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Edgecloudsim: An environment for performance evaluation of edge computing systems</title>
		<author>
			<persName><forename type="first">C</forename><surname>Sonmez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ozgovde</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Ersoy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions on Emerging Telecommunications Technologies</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page">3493</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Emufog: Extensible and scalable emulation of large-scale fog computing infrastructures</title>
		<author>
			<persName><forename type="first">R</forename><surname>Mayer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Graser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Saurez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Ramachandran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 IEEE Fog World Congress (FWC)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Intelligent optimisation techniques: genetic algorithms, tabu search, simulated annealing and neural networks</title>
		<author>
			<persName><forename type="first">D</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Karaboga</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012">2012</date>
			<publisher>Springer Science &amp; Business Media</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">E2clab: Exploring the computing continuum through repeatable, replicable and reproducible edge-to-cloud experiments</title>
		<author>
			<persName><forename type="first">D</forename><surname>Rosendo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Silva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Simonin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Costan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Antoniu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2020 IEEE International Conference on Cluster Computing (CLUSTER)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="176" to="186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Grid&apos;5000: a large scale and highly reconfigurable experimental grid testbed</title>
		<author>
			<persName><forename type="first">R</forename><surname>Bolze</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Cappello</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Caron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Daydé</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Desprez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Jeannot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Jégou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lanteri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Leduc</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Melab</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The International Journal of High Performance Computing Applications</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="481" to="494" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<author>
			<persName><surname>Appdynamics</surname></persName>
		</author>
		<ptr target="https://www.appdynamics.com/media/uploaded-files/1432066155/white-paper-16-metrics-every-mobile-team-should-monitor.pdf" />
		<title level="m">16 metrics to ensure mobile app success</title>
		<imprint>
			<date type="published" when="2015-01">2015, jan</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Performance evaluation metrics for cloud, fog and edge computing: A review, taxonomy, benchmarks and standards for future research</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Aslanpour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Gill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">N</forename><surname>Toosi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Internet of Things</title>
		<imprint>
			<biblScope unit="page">100273</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<ptr target="https://scikit-optimize.github.io/stable/" />
		<title level="m">Sequential model-based optimization</title>
		<imprint>
			<publisher>Scikit-Optimize</publisher>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Scikit-learn: Machine learning in python</title>
		<author>
			<persName><forename type="first">F</forename><surname>Pedregosa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Varoquaux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gramfort</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Michel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Thirion</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Grisel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Blondel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Prettenhofer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Dubourg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">the Journal of machine Learning research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2825" to="2830" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">A python surrogate modeling framework with derivatives</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Bouhlel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">T</forename><surname>Hwang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Bartoli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Lafage</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Morlier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R R A</forename><surname>Martins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Engineering Software</title>
		<imprint>
			<biblScope unit="page">102662</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Deephyper: Asynchronous hyperparameter search for deep neural networks</title>
		<author>
			<persName><forename type="first">P</forename><surname>Balaprakash</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Salim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">D</forename><surname>Uram</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Vishwanath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Wild</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2018 IEEE 25th international conference on high performance computing (HiPC)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="42" to="51" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">E2clab source code</title>
		<ptr target="https://gitlab.inria.fr/E2Clab/e2clab" />
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Practical bayesian optimization of machine learning algorithms</title>
		<author>
			<persName><forename type="first">J</forename><surname>Snoek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">P</forename><surname>Adams</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1206.2944</idno>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Kriging models for global approximation in simulation-based multidisciplinary design optimization</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">W</forename><surname>Simpson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">M</forename><surname>Mauery</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Korte</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Mistree</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AIAA journal</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2233" to="2241" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">On the optimization of fuzzy decision trees</title>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Ye</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Fuzzy Sets and Systems</title>
		<imprint>
			<biblScope unit="volume">112</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="117" to="125" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Random forests</title>
		<author>
			<persName><forename type="first">L</forename><surname>Breiman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine learning</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="5" to="32" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Greedy function approximation: a gradient boosting machine</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Friedman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annals of statistics</title>
		<imprint>
			<biblScope unit="page" from="1189" to="1232" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Support vector machines</title>
		<author>
			<persName><forename type="first">I</forename><surname>Steinwart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Christmann</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008">2008</date>
			<publisher>Springer Science &amp; Business Media</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Modelling using polynomial regression</title>
		<author>
			<persName><forename type="first">E</forename><surname>Ostertagová</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Procedia Engineering</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="page" from="500" to="506" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Latin hypercube sampling and the propagation of uncertainty in analyses of complex systems</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Helton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">J</forename><surname>Davis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Reliability Engineering &amp; System Safety</title>
		<imprint>
			<biblScope unit="volume">81</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="23" to="69" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Computational investigations of lowdiscrepancy sequences</title>
		<author>
			<persName><forename type="first">L</forename><surname>Kocis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">J</forename><surname>Whiten</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Mathematical Software (TOMS)</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="266" to="294" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Genetic algorithm</title>
		<author>
			<persName><forename type="first">S</forename><surname>Mirjalili</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Evolutionary algorithms and neural networks</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="43" to="55" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Recent advances in differential evolution-an updated survey</title>
		<author>
			<persName><forename type="first">S</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Mullick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">N</forename><surname>Suganthan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Swarm and Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="1" to="30" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Simulated annealing</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Van Laarhoven</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">H</forename><surname>Aarts</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Simulated annealing: Theory and applications</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1987">1987</date>
			<biblScope unit="page" from="7" to="15" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Particle swarm optimization</title>
		<author>
			<persName><forename type="first">K.-L</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Swamy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Search and optimization by metaheuristics</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="153" to="173" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<ptr target="https://kerdata.gitlabpages.inria.fr/Kerdata-Codes/e2clab/" />
		<title level="m">Welcome to e2clab&apos;s documentation!</title>
		<imprint>
			<date type="published" when="2020-02">2020, feb</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<author>
			<persName><surname>Ray</surname></persName>
		</author>
		<ptr target="https://docs.ray.io/en/latest/index.html" />
		<title level="m">What is ray</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Tune: A research platform for distributed model selection and training</title>
		<author>
			<persName><forename type="first">R</forename><surname>Liaw</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Nishihara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Moritz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Gonzalez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Stoica</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1807.05118</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Tuning hyperparameters without grad students: Scalable and robust bayesian optimisation with dragonfly</title>
		<author>
			<persName><forename type="first">K</forename><surname>Kandasamy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">R</forename><surname>Vysyaraju</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Neiswanger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Paria</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">R</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schneider</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Poczos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">P</forename><surname>Xing</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1903.06694</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">BoTorch: A Framework for Efficient Monte-Carlo Bayesian Optimization</title>
		<author>
			<persName><forename type="first">M</forename><surname>Balandat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Karrer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">R</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Daulton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Letham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">G</forename><surname>Wilson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Bakshy</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/1910.06403" />
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">33</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Hebo: Heteroscedastic evolutionary bayesian optimisation</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">I</forename><surname>Cowen-Rivers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Lyu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Tutunov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Jianye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">B</forename><surname>Ammar</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2012.03826</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>winning submission to the NeurIPS 2020 Black Box Optimisation Challenge</note>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">A tutorial on bayesian optimization</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">I</forename><surname>Frazier</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1807.02811</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">A comparison of sensitivity analysis techniques</title>
		<author>
			<persName><forename type="first">D</forename><surname>Hamby</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Health physics</title>
		<imprint>
			<biblScope unit="volume">68</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="195" to="204" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Open science: one term, five schools of thought</title>
		<author>
			<persName><forename type="first">B</forename><surname>Fecher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Friesike</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Opening science</title>
		<imprint>
			<biblScope unit="page" from="17" to="47" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<ptr target="https://gitlab.inria.fr/E2Clab/Paper-Artifacts/plantnet" />
		<title level="m">E2clab experimental artifacts</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">An architecture and stochastic method for database container placement in the edge-fog-cloud continuum</title>
		<author>
			<persName><forename type="first">P</forename><surname>Kochovski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Sakellariou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bajec</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Drobintsev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Stankovski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2019 IEEE International Parallel and Distributed Processing Symposium (IPDPS)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="396" to="405" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Containers and cloud: From lxc to docker to kubernetes</title>
		<author>
			<persName><forename type="first">D</forename><surname>Bernstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Cloud Computing</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="81" to="84" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">A unified model for the mobile-edge-cloud continuum</title>
		<author>
			<persName><forename type="first">L</forename><surname>Baresi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">F</forename><surname>Mendonc ¸a</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Garriga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Guinea</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Quattrocchi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Internet Technology (TOIT)</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1" to="21" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
