<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">ProvLight: Efficient Workflow Provenance Capture on the Edge-to-Cloud Continuum</title>
				<funder>
					<orgName type="full">FAPERJ</orgName>
				</funder>
				<funder ref="#_CtBjUYq">
					<orgName type="full">Agence Nationale de la Recherche</orgName>
					<orgName type="abbreviated">ANR</orgName>
				</funder>
				<funder>
					<orgName type="full">CNPq</orgName>
				</funder>
				<funder>
					<orgName type="full">Universities</orgName>
				</funder>
				<funder>
					<orgName type="full">HPC-BigData Inria Challenge (IPL)</orgName>
				</funder>
				<funder ref="#_BRZFTXR">
					<orgName type="full">Office of Science of the U.S. Department of Energy</orgName>
				</funder>
				<funder>
					<orgName type="full">HPDaSc</orgName>
				</funder>
				<funder>
					<orgName type="full">Inria</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Daniel</forename><surname>Rosendo</surname></persName>
							<email>daniel.rosendo@inria.fr</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">University of Rennes</orgName>
								<orgName type="institution" key="instit2">Inria</orgName>
								<orgName type="institution" key="instit3">CNRS</orgName>
								<orgName type="institution" key="instit4">IRISA -Rennes</orgName>
								<address>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Marta</forename><surname>Mattoso</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Federal University of Rio de Janeiro</orgName>
								<address>
									<country key="BR">Brazil</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Alexandru</forename><surname>Costan</surname></persName>
							<email>alexandru.costan@inria.fr</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">University of Rennes</orgName>
								<orgName type="institution" key="instit2">Inria</orgName>
								<orgName type="institution" key="instit3">CNRS</orgName>
								<orgName type="institution" key="instit4">IRISA -Rennes</orgName>
								<address>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Renan</forename><surname>Souza</surname></persName>
							<email>souzar@ornl.gov</email>
							<affiliation key="aff2">
								<orgName type="laboratory">Oak Ridge National Laboratory</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">DÃ©bora</forename><surname>Pina</surname></persName>
							<email>dbpina@cos.ufrj.br</email>
							<affiliation key="aff1">
								<orgName type="institution">Federal University of Rio de Janeiro</orgName>
								<address>
									<country key="BR">Brazil</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Patrick</forename><surname>Valduriez</surname></persName>
							<email>patrick.valduriez@inria.fr</email>
							<affiliation key="aff3">
								<orgName type="institution" key="instit1">University of Montpellier</orgName>
								<orgName type="institution" key="instit2">Inria</orgName>
								<orgName type="institution" key="instit3">CNRS</orgName>
								<orgName type="institution" key="instit4">LIRMM -Montpellier</orgName>
								<address>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Gabriel</forename><surname>Antoniu</surname></persName>
							<email>gabriel.antoniu@inria.fr</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">University of Rennes</orgName>
								<orgName type="institution" key="instit2">Inria</orgName>
								<orgName type="institution" key="instit3">CNRS</orgName>
								<orgName type="institution" key="instit4">IRISA -Rennes</orgName>
								<address>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">ProvLight: Efficient Workflow Provenance Capture on the Edge-to-Cloud Continuum</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">3BAA0D53661D6BDF9CE7DD0370E76586</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-04-12T14:50+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Provenance</term>
					<term>Lineage</term>
					<term>Workflows</term>
					<term>Edge</term>
					<term>IoT</term>
					<term>Computing Continuum</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Modern scientific workflows require hybrid infrastructures combining numerous decentralized resources on the IoT/Edge interconnected to Cloud/HPC systems (aka the Computing Continuum) to enable their optimized execution. Understanding and optimizing the performance of such complex Edgeto-Cloud workflows is challenging. Capturing the provenance of key performance indicators, with their related data and processes, may assist in understanding and optimizing workflow executions. However, the capture overhead can be prohibitive, particularly in resource-constrained devices, such as the ones on the IoT/Edge.</p><p>To address this challenge, based on a performance analysis of existing systems, we propose ProvLight, a tool to enable efficient provenance capture on the IoT/Edge. We leverage simplified data models, data compression and grouping, and lightweight transmission protocols to reduce overheads. We further integrate ProvLight into the E2Clab framework to enable workflow provenance capture across the Edge-to-Cloud Continuum. This integration makes E2Clab a promising platform for the performance optimization of applications through reproducible experiments.</p><p>We validate ProvLight at a large scale with synthetic workloads on 64 real-life IoT/Edge devices in the FIT IoT LAB testbed. Evaluations show that ProvLight outperforms state-of-the-art systems like ProvLake and DfAnalyzer in resource-constrained devices. ProvLight is 26-37x faster to capture and transmit provenance data; uses 5-7x less CPU; 2x less memory; transmits 2x less data; and consumes 2-2.5x less energy. ProvLight [1] and E2Clab <ref type="bibr" target="#b1">[2]</ref> are available as open-source tools.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>Data processing and Artificial Intelligence (AI) workflows can no longer rely on traditional approaches (due to resource usage, latency, and privacy constraints) <ref type="bibr" target="#b2">[3]</ref> that send all data to centralized and distant Cloud datacenters for processing or AI model training <ref type="bibr" target="#b3">[4]</ref>. Instead, they need to leverage hybrid (decentralized) approaches that take advantage of the numerous resources close to the data generation sites (i.e., on the edge of the network) to promptly extract insights <ref type="bibr" target="#b4">[5]</ref> and satisfy the ultra-low latency requirements of applications.</p><p>This hybrid approach contributes to the emergence of the Computing Continuum <ref type="bibr" target="#b5">[6]</ref> (or the Edge-to-Cloud Continuum or the Transcontinuum). It seamlessly combines resources and services at the center of the network (e.g., in Cloud datacenters), at its edge, and in-transit, along the data path. Typically, data is first generated and preprocessed (e.g., model training with local data) on IoT/Edge devices. Then, data is transferred to (HPC-enabled) Clouds for Big Data analytics, AI model training, and global simulations. For instance, in Federated Learning (FL) model training, a central Cloud server collects data (model updates) from multiple decentralized Edge devices, then it generates a single accurate global inference model.</p><p>Due to the complexity incurred by application deployments on such highly distributed and heterogeneous Edge-to-Cloud infrastructures, realizing the Computing Continuum vision in practice is challenging. Deploying, analyzing, and reproducing performance trade-offs and optimizing large-scale, real-life applications on such infrastructures is difficult <ref type="bibr" target="#b2">[3]</ref>. It requires configuring a myriad of system-specific parameters (e.g., from AI and Big Data systems) and reconciling many requirements or constraints in terms of energy consumption, network efficiency, and hardware resource usage, to cite a few <ref type="bibr" target="#b6">[7]</ref>. In recent works, these challenges have been mainly explored by systems like Pegasus <ref type="bibr" target="#b7">[8]</ref>, E2Clab <ref type="bibr" target="#b8">[9]</ref>, Delta <ref type="bibr" target="#b9">[10]</ref>.</p><p>The process of understanding, optimizing, and reproducing complex Edge-to-Cloud workflows may be assisted by provenance data capture. "Provenance data" refer to a record trail that accounts for the origin of a piece of data together with descriptions of the computational processes that assist in explaining how and why it was generated <ref type="bibr" target="#b10">[11]</ref>. Capturing provenance data during workflow execution helps users in tracking inputs, outputs, and processing history, allowing them to steer workflows precisely <ref type="bibr" target="#b11">[12]</ref>.</p><p>For instance, considering a Federated Learning model training workflow executed on distributed devices on the Edge, the captured data during model training helps answer questions like: (i) What are the elapsed time and the training loss in the latest epoch for each hyperparameter combination? <ref type="bibr" target="#b12">[13]</ref>, <ref type="bibr" target="#b13">[14]</ref> or (ii) Retrieve the hyperparameters which obtained the 3 best accuracy values for model m? <ref type="bibr" target="#b13">[14]</ref>, <ref type="bibr" target="#b14">[15]</ref>. Answering such queries helps to analyze hyperparameter values related to the training stages and to adjust them for better-quality results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Challenges and Novelty</head><p>Overhead in provenance systems is a critical problem that must be assessed <ref type="bibr" target="#b15">[16]</ref>. Many other contributions in provenance systems evaluate the overhead, such as <ref type="bibr" target="#b16">[17]</ref>, <ref type="bibr" target="#b17">[18]</ref>. Overhead is even more critical in edge devices because of resource constraints and power consumption. For this reason, we decided to focus on evaluating overhead in our work. In <ref type="bibr" target="#b18">[19]</ref>, leading database researchers discussed the challenges of deploying services considering disaggregation and high heterogeneity of resources in hybrid cloud infrastructures. In <ref type="bibr" target="#b19">[20]</ref>, the authors describe challenges related to capturing provenance on the Edge-to-Cloud Continuum.</p><p>The main state-of-the-art provenance systems were designed to run on Cloud/HPC infrastructures. We highlight that we have not found in the literature reference systems tailored for IoT/Edge devices. Therefore, this work refers to systems well-known for their low provenance capture overhead in Cloud/HPC, such as DfAnalyzer <ref type="bibr" target="#b17">[18]</ref>, ProvLake <ref type="bibr" target="#b16">[17]</ref>, and PROV-IO <ref type="bibr" target="#b20">[21]</ref>. We also include Komadu <ref type="bibr" target="#b21">[22]</ref> in our analysis, as it is also compared within the aforementioned works.</p><p>Enabling provenance data capture with low overhead in resource-constrained IoT/Edge devices cannot be easily achieved by existing provenance systems, calling for practical solutions beyond the state-of-the-art. For instance, it requires the design and development of novel capture approaches focusing on the hardware limitations of IoT/Edge devices, as proposed in this work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Contributions</head><p>We make the following contributions: 1) The first research question we aim to answer is: How Do the Existing Provenance Systems Perform in IoT/Edge Devices? We address this research question by providing an experimental evaluation of existing provenance systems along with a detailed discussion in Section III. 2) As our experiments concluded that the state-of-the-art systems present high overheads to capture provenance data in IoT/Edge devices, we propose a novel workflow provenance data capture approach tailored for resource-limited IoT/Edge devices, that addresses the limitations found in the state of the art (Section IV).</p><p>ProvLight is an open-source implementation of this approach (available at <ref type="bibr" target="#b0">[1]</ref>), following the W3C PROV-DM recommendations. 3) An integration of ProvLight within the E2Clab automatic deployment and performance optimization framework. This enables provenance data capture across the Computing Continuum for hybrid workflows deployed on both IoT/Edge and Cloud/HPC infrastructures. To the best of our knowledge, this enhanced version of E2Clab is the first framework to support the end-toend provenance data capture of complex workflows Fig. <ref type="figure">1</ref>: PROV-DM: The W3C PROV Data Model <ref type="bibr" target="#b27">[28]</ref>.</p><p>executed on the Edge-to-Cloud Continuum (Section V). This integration with E2Clab is an open-source tool available at <ref type="bibr" target="#b1">[2]</ref>. We highlight that, ProvLight may be easily integrated into other deployment and performance optimization systems/frameworks. 4) A large-scale experimental validation of ProvLight with synthetic workloads on 64 real-life IoT devices (from the FIT IoT LAB <ref type="bibr" target="#b22">[23]</ref> testbed) and Cloud resources (from the Grid'5000 <ref type="bibr" target="#b23">[24]</ref> testbed). Experimental evaluations show that ProvLight outperforms (i.e., lower capture overhead) DfAnalyzer and ProvLake systems in terms of capture time, CPU and memory usage, network usage, and power consumption (Section VI).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. BACKGROUND</head><p>This work focuses on provenance systems leveraging the user-defined capture approach <ref type="bibr" target="#b24">[25]</ref>, <ref type="bibr" target="#b25">[26]</ref>. This approach allows users to define what to capture by workflow script instrumentation through capture libraries. We highlight that script instrumentation (e.g., adding logging calls) is a common practice in distributed systems, particularly to assist debugging. In provenance capture, many other approaches rely on script instrumentation <ref type="bibr" target="#b16">[17]</ref>, <ref type="bibr" target="#b25">[26]</ref>, <ref type="bibr" target="#b26">[27]</ref>. A good practice to promote data interoperability is that such libraries should follow provenance specifications like the PROV-DM recommendation, as an example. Finally, the provenance capture of Edge-to-Cloud workflows is a new topic that requires automatic deployment tools like E2Clab.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. PROV-DM: The PROV Data Model</head><p>PROV <ref type="bibr" target="#b28">[29]</ref> is a specification to interchange provenance information. PROV-DM <ref type="bibr" target="#b27">[28]</ref> is the data model for the W3C provenance family of specifications. It aims to promote data interoperability from provenance management systems. Provenance systems such as DfAnalyzer <ref type="bibr" target="#b17">[18]</ref>, ProvLake <ref type="bibr" target="#b16">[17]</ref>, PROV-IO <ref type="bibr" target="#b20">[21]</ref>, Komadu <ref type="bibr" target="#b21">[22]</ref>, among many others, follow the PROV-DM model.</p><p>Figure <ref type="figure">1</ref> illustrates the core elements of PROV-DM and their relationships. PROV-DM provides an abstract representation of provenance data derivations. Briefly described, the core elements are: (i) Agent: refers to tools invoked on behalf of users (e.g., software); (ii) Activity: refers to tasks (e.g., processing steps); and (i) Entity: refers to data objects (e.g., files, input parameters, etc.). Our capture approach also follows the PROV-DM recommendation.</p><p>B. Capturing Provenance for Edge-to-Cloud Workflows 1) Edge-to-Cloud Computing Continuum: Edge infrastructures refer to computing and storage resources located where the data originated. They consist of numerous smart devices sensing "what" is happening in the environment and generating potentially huge data streams at potentially high rates <ref type="bibr" target="#b2">[3]</ref>. The Edge computing paradigm aims to push intelligence to those devices and extract value from data in real-time to improve response times while preserving privacy and security (critical data is analyzed locally).</p><p>Cloud infrastructures provide virtually "unlimited" computing and storage resources used essentially for backup and data analytics for global insight extraction in centralized data centers. Data is first ingested at high rates through dedicated systems (e.g., Apache Kafka <ref type="bibr" target="#b29">[30]</ref>) and analyzed by Big Data processing frameworks (e.g., Spark <ref type="bibr" target="#b30">[31]</ref>). They perform stream and batch analytics on vast historical data, AI model training, and complex simulations. The goal is to help understand "why" the phenomena sensed at the Edge are happening.</p><p>2) Federated Learning Training Use Case: To illustrate an Edge-to-Cloud application workflow, we refer to Federated Learning model training. Federated Learning <ref type="bibr" target="#b31">[32]</ref> is a collaborative machine learning paradigm that trains a centralized model on decentralized and private data.</p><p>The Federated Learning architecture is composed of a central server (typically deployed on the Cloud) and various devices (deployed on the Edge). Edge devices first download a global model from the cloud server and train it for several epochs with their local data. After multiple rounds of model updates, the results are sent to the cloud server for global model aggregation. This training loop continues until the global model achieves the desired accuracy <ref type="bibr" target="#b32">[33]</ref>.</p><p>Capturing provenance data of Federated Learning model training at runtime helps scientists to track model training inputs (e.g., hyperparameters), outputs (e.g., accuracy), and processing history (e.g., training epochs). In this context, captured data from each training epoch may refer to the hyperparameters (input data) followed by the respective accuracy obtained from the training (output data). The goal is to allow users to answer queries like the ones presented in Section I). Analyzing hyperparameters along the model training allows for adapting the training data and fine-tuning the model. Provenance data traces also help in the interpretation and reproducibility of the training results <ref type="bibr" target="#b13">[14]</ref>, <ref type="bibr" target="#b33">[34]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. E2Clab: Reproducible Edge-to-Cloud Experiments</head><p>E2Clab <ref type="bibr" target="#b34">[35]</ref> is an open-source framework (available at <ref type="bibr" target="#b1">[2]</ref>) that allows researchers to reproduce the application behavior in a controlled environment to understand and to optimize performance <ref type="bibr" target="#b8">[9]</ref>. It sits on top of EnOSlib <ref type="bibr" target="#b35">[36]</ref> and implements a rigorous methodology (illustrated in Figure <ref type="figure">2</ref>) for designing Software, algorithms Dataset Fig. <ref type="figure">2</ref>: E2Clab experiment methodology <ref type="bibr" target="#b34">[35]</ref>.</p><p>experiments with real-world workloads on the Edge-to-Cloud Computing Continuum. Section V details how we extend E2Clab to enable provenance data capture of Edge-to-Cloud workflows. Figure <ref type="figure" target="#fig_4">4</ref> illustrates the extended architecture.</p><p>High-level features provided by E2Clab are (i) reproducible experiments; (ii) mapping application parts (executed on Edge, Fog, and Cloud/HPC) and physical testbeds; (iii) experiment variation and transparent scaling of scenarios; (iv) defining Edge-to-Cloud network constraints; (v) automatic experiment deployment, execution, and monitoring (e.g., on various testbeds like Grid'5000 <ref type="bibr" target="#b23">[24]</ref>, Chameleon <ref type="bibr" target="#b36">[37]</ref>, and FIT IoT LAB <ref type="bibr" target="#b22">[23]</ref>); (vi) workflow optimization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. PROVENANCE SYSTEMS IN IOT/EDGE</head><p>In the literature, to the best of our knowledge, we have not found provenance data capture tools tailored for IoT/Edge devices. Capturing provenance data in such devices requires using tools designed for Cloud/HPC resources. Therefore, in this section, we assess their overhead for capturing data in resource-limited computing resources.</p><p>A. Experimental Setup a) Selected provenance systems.: Due to the limitations of the PROV-IO and Komadu systems, shown in Table <ref type="table" target="#tab_3">IV</ref>, they were excluded from our performance analysis. We choose ProvLake and DfAnalyzer because we have access to their data capture components as open-source software. Since we are limited to testing with the open-source version of these systems, we cannot experiment with features that might deliver lower overhead but are not open-source. For instance, ProvLake reports being able to use a different communication protocol other than HTTP 1.1 for machine learning provenance capture with low overhead in an HPC environment <ref type="bibr" target="#b13">[14]</ref>, but this system version is not available as open-source.  The main analyzed metric is the capture time overhead, which refers to the relative difference of the workflow execution time with and without data capture. We repeat the experiment 10 times for each provenance system and for each synthetic workload and report the mean followed by the 95% confidence interval.</p><p>c) Overhead levels.: In the literature, the reference to low overhead or negligible overhead, in terms of provenance capture time in Cloud/HPC environments, differs between application domains. For instance: &lt;2% for blockchains <ref type="bibr" target="#b37">[38]</ref>;</p><p>4% for I/O-centric workflows <ref type="bibr" target="#b20">[21]</ref>; 4% for AI model training <ref type="bibr" target="#b12">[13]</ref>; 12% for security applications <ref type="bibr" target="#b38">[39]</ref>; to cite a few. Regarding provenance capture on resource-limited IoT/Edge devices, prohibitive overhead levels may vary depending on the application use case. For instance, in latency-sensitive applications such as autonomous vehicles <ref type="bibr" target="#b39">[40]</ref>, real-time monitoring in smart energy grids <ref type="bibr" target="#b40">[41]</ref>, and virtual and augmented reality <ref type="bibr" target="#b41">[42]</ref>, to cite a few, a &gt; 3% processing time overhead is considered high (i.e., enough to exceed the acceptable latency thresholds) as it can introduce delays that disrupt the realtime nature of the application, leading to inaccuracies, missed targets, or compromised safety.</p><p>d) Synthetic workload.: We use a synthetic workload to evaluate the provenance capture overhead because doing it in real workloads is much more complicated, costly, and may not make sense for the real application. The reason is that we cannot precisely control and isolate variables such as elapsed time, number of tasks, and number of attributes. A similar situation happens when scientists need to rely on simulations instead of real phenomena to test and evaluate their hypotheses. Unfortunately, there are no well-established benchmarks in the community to evaluate overhead in provenance systems. Therefore, like related work <ref type="bibr" target="#b16">[17]</ref>, <ref type="bibr" target="#b17">[18]</ref>, we decided to focus our analysis on synthetic workload configurations. Such configurations are based on real-life workloads <ref type="bibr" target="#b42">[43]</ref>- <ref type="bibr" target="#b44">[45]</ref>, and we refined the configuration space of our workloads with preliminary experiments on real-life edge devices.</p><p>Table <ref type="table" target="#tab_0">I</ref> presents the 8 synthetic workload configurations used to analyze the data capture overhead. We chose these values to cover combinations of application characteristics. The idea of these configurations is to mimic the characteristics of the various real-life workloads that IoT/Edge devices typically execute, such as AI model training (e.g., the Federated Learning use case we presented earlier), image pre-processing, and sensor data aggregation, among others. Such workloads are composed of various tasks (number of tasks), each one with a different number of attributes (attributes per task) and with different processing times (task duration).</p><p>We consider workloads with 5 chained transformations, which is an approximate number of transformations in many applications. In the Federated Learning application, for example, one of the transformations is model training, which has many epoch executions. We consider each epoch execution as a task of the model training transformation and each epoch has associated features (considered input attributes) and performance metrics (considered output attributes) <ref type="bibr" target="#b13">[14]</ref>. Other transformations include data preparation and the evaluation of the trained model. To generate our synthetic workload, we consider 100 tasks. In the Federated Learning example, it would represent a training with 100 epochs. For each task, we represent applications that manipulate a few (about 10) or more (about 100) attributes per task. Besides, to represent various classes of applications, we also consider four different task duration: shorter (e.g., 0.5 or 1 seconds) and longer (e.g., 3.5 or 5 seconds).</p><p>We run preliminary experiments to refine the synthetic workload configurations. We observe that there is no significant impact on the capture overhead when varying the number of tasks from 10, 50 to 100. In addition, since the data capture and transmission is measured per task, mainly variations in the number of attributes per task (amount of data transmitted) and task duration (data capture frequency) impact the capture time overhead (calculated as the relative difference). e) Hardware.: Each workload configuration runs on a single A8-M3 <ref type="bibr" target="#b45">[46]</ref> IoT device (ARM Cortex-A8 microprocessor, 600Mhz, 256MB; radio: 802.15.4, 2.4 GHz; power: 3.7V LiPo battery, 650 mAh) available at the FIT IoT LAB testbed <ref type="bibr" target="#b22">[23]</ref>. We instrument the synthetic workloads (code available at <ref type="bibr" target="#b46">[47]</ref>) with the capture libraries provided by ProvLake and DfAnalyzer systems. The libraries transmit the data to the provenance system running on a remote Cloud/HPC server <ref type="bibr" target="#b47">[48]</ref> (Intel Xeon Gold 5220, 2.20GHz, 18 cores; 96GB RAM; Ethernet) available at the Grid'5000 <ref type="bibr" target="#b23">[24]</ref> testbed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Overhead Analysis</head><p>Table <ref type="table" target="#tab_1">II</ref> presents the capture time overhead of ProvLake and DfAnalyzer in IoT/Edge devices, and Table <ref type="table" target="#tab_2">III</ref> shows the analysis of a feature provided by ProvLake, which consists of grouping the captured data, i.e., messages, before transmitting them to the server, i.e., provenance system. In addition, we analyze how low-bandwidth networks may impact such data grouping strategy.</p><p>Results in Table <ref type="table" target="#tab_1">II</ref> show that both systems present high overhead (&gt;39%) for tasks with a duration of 0.5 seconds. For the remaining task duration, the overhead is still high (&gt;3%). Varying the number of attributes per task from 10 to 100 slightly increases the overhead.</p><p>Regarding Table <ref type="table" target="#tab_2">III</ref>, we observe low overhead (&lt;3%) when grouping 50 messages for a task duration of 0.5 seconds, and grouping from 20 messages for a task duration of 1 second, for 1Gbit bandwidth. While for 25Kbit bandwidth, we observe high overhead (&gt;43%) for all workloads.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Design-level Limitations of Existing Systems</head><p>Table <ref type="table" target="#tab_3">IV</ref> presents the takeaways of our performance analysis and exposes the main limitations of the existing provenance systems. In summary, the evaluation shows that the existing systems present high overheads (&gt;3%) when capturing on IoT/Edge devices.</p><p>ProvLake and DfAnalyzer rely on HTTP over TCP, instead of IoT-based messaging and transmission protocols such as MQTT <ref type="bibr" target="#b48">[49]</ref>, CoAP <ref type="bibr" target="#b49">[50]</ref>, AMQP <ref type="bibr" target="#b50">[51]</ref>, UDP <ref type="bibr" target="#b51">[52]</ref>, RPL <ref type="bibr" target="#b52">[53]</ref>, to cite a few. In resource-constrained devices, they make a relevant impact on performance, resource usage, and power consumption, as explored by existing works <ref type="bibr" target="#b53">[54]</ref>- <ref type="bibr" target="#b55">[56]</ref>.</p><p>The experiment results reinforce the need for capture approaches tailored to the constraints imposed by IoT devices. In addition, simplified data models to represent the provenance data help to reduce overheads.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. PROVLIGHT DESIGN</head><p>This section introduces ProvLight, a tool <ref type="bibr" target="#b0">[1]</ref> for the efficient provenance data capture of Edge-to-Cloud workflows. Prov-Light is designed to capture provenance in IoT/Edge devices with low overhead in terms of capture time, CPU and memory usage, network usage, and power consumption.</p><p>Subsection IV-A presents the ProvLight provenance model. Next, the architectural details are given in Subsection IV-B, while Subsection IV-C describes its implementation. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>PROV-IO</head><p>Does not send the captured data over the network to another machine hosting the provenance system. Instead, it periodically dumps the in-memory provenance graph to disk. This approach is not suitable for IoT/Edge devices.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Komadu</head><p>Komadu does not follow a clear separation between a client library and a backend provenance server. Therefore, the capture and the processing of the captured information run in the same machine. This approach is not suitable for capturing on IoT/Edge devices.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Data Exchange Model</head><p>ProvLight provenance data exchange model follows the W3C PROV-DM <ref type="bibr" target="#b27">[28]</ref> recommendation. The goal is to have a data exchange schema (domain-agnostic PROV modeling) for capturing data in the IoT/Edge and making sure these captured data are compatible with W3C PROV-based workflow provenance systems, such as ProvLake, DfAnalyzer, PROV-IO, among many others. Table V describes ProvLight classes and their relationships and maps them to PROV-DM core elements.</p><p>The main classes of our model are Workflow, Task, and Data. These classes are derived from the Agent, Activity, and Entity PROV-DM types, respectively. ProvLight classes aim to provide a simplified abstraction allowing users to track workflow (Workflow class), input and output parameters (Data class), and processing history (Task class).</p><p>The Workflow class may be used to refer to the application workflow (e.g., Federated Learning training). The Task class refers to the tasks executed in the workflow (e.g., each epoch or model update of the model training). Finally, the Data class represents the input data attributes and values (e.g., hyperparameters of the learning algorithm) or the output attributes (e.g., training time and loss of each epoch).</p><p>To represent PROV-DM relationships, we use the id attribute of each class. We link the Task and Data classes with the workflow they belong to (wasAssociatedWith and wasAttributedTo, respectively). The links between a Task and its respective Data inputs and the generated outputs are represented by the used and wasGeneratedBy relationships, respectively. The dependencies attribute in the Task class links tasks (wasInformedBy) with dependencies (e.g., task B starts after task A ends). Finally, the derivations attribute in the Data class links (wasDerivedFrom) chained data (e.g., data D A was used in task A to generate data D B ).  Defining such relations aims to provide users with the data processing history: Where did the data come from? How was the data transformed? and Who acted upon it? For instance, capturing provenance data of Federated Learning model training workflows may help users to interpret results. Tracking model training at runtime and fine-tuning hyperparameters is helpful, especially when the training process takes a long time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Architecture</head><p>Figure <ref type="figure" target="#fig_2">3</ref> presents the ProvLight architecture. It follows a client/server model where the server receives the captured data from clients and then translates it and sends it to provenance systems. We highlight that ProvLight may integrate with existing provenance systems like DfAnalyzer, ProvLake, and PROV-IO, among others (e.g., through their APIs and ProvLight data translator), as a solution for capturing data of workflows running on IoT/Edge devices, as illustrated in Figure <ref type="figure" target="#fig_2">3</ref>. Table VI summarizes how the ProvLight architecture design differs from the systems analyzed in Section III. This integration may be achieved by using: 1) Server: The ProvLight server is composed of a broker and a provenance data translator. Both may be parallelized to scale the data capture for scenarios with various IoT/Edge devices. We describe the main roles of each one.</p><p>(i) Broker: refers to an MQTT-SN broker (MQTT for Sensor Networks <ref type="bibr" target="#b56">[57]</ref>). During workflow execution, clients subscribe to the broker and then start to transmit the captured data. Next, this data is forwarded to the provenance data translator, which is subscribed to the broker.</p><p>(ii) Provenance Data Translator: translates the captured data to the respective format used by the provenance system. The provenance data translator may be extended, by users, to translate to a particular data model of a provenance system. After translating, it sends the data to the provenance system service (e.g., typically available at an ip:port). It allows seamless integration with existing systems.</p><p>2) Client: The ProvLight client aims to efficiently capture provenance data on resource-limited devices. ProvLight provides a client library that follows the W3C PROV-DM provenance model (as presented in Table <ref type="table" target="#tab_4">V</ref>). This library allows users to instrument their workflow code to decide what data to capture. A client is configured to transmit, at runtime, the captured data to the remote broker (e.g., ip:port). This allows users to track workflow execution at runtime (e.g., started and finished tasks, input and output data, etc.) through provenance systems supporting data ingestion at runtime.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Implementation 1) Server:</head><p>The Broker is implemented based on the Eclipse RSMB server <ref type="bibr" target="#b57">[58]</ref> (Really Small Message Broker). RSMB builds on top of Mosquitto <ref type="bibr" target="#b58">[59]</ref> and implements the MQTT-SN protocol.</p><p>The Provenance Data Translator is a Python service that may be extended to translate captured data (from the ProvLight data format) to a particular provenance system (e.g., DfAnalyzer, ProvLake, Komadu, etc.). In our repository <ref type="bibr" target="#b0">[1]</ref>, we provide an implementation showing how to translate from the ProvLight data format to DfAnalyzer. Such translation is possible since the aforementioned systems follow the W3C PROV-DM provenance model. For the translator-to-broker communication, we use the MQTT-SN Python client library <ref type="bibr" target="#b59">[60]</ref> based on Eclipse RSMB. Finally, for the translator-to-provenancesystem communication, users are free to use any Python library compatible with the provenance system (e.g., Requests <ref type="bibr" target="#b60">[61]</ref>).</p><p>2) Client: The ProvLight client library is implemented in Python and provides a series of features targeting resourcelimited IoT/Edge devices:</p><p>â¢ provenance data representation: simplified classes for provenance modeling that allow users to represent workflows, data derivations (e.g., input/output data from tasks) and tasks (e.g., status, dependencies, data derivations); â¢ payload compression: compresses the bytes in captured data before transmitting over the network; and</p><p>â¢ data capture grouping: allow users to optionally group data just from ended tasks, so users may still track at workflow runtime the tasks that have already started. As shown later in the evaluation section, grouping and compressing captured data help reduce capture time overhead, especially in IoT/Edge devices.</p><p>How to capture provenance data from the workflows? Listing 1 illustrates an example of application code instrumentation with the ProvLight library highlighted in blue color. Lines 6, 7, and 23 instantiate the workflow, start, and finalize it, respectively. Line 16 instantiates a task, linking it to the workflow, input data derivation, and dependent task. Lines 18 and 21 capture data from the initialization and finalization of the task. Before starting a task, line 17 instantiates Data and adds it as input data (line 18) to the task. Following the same logic, line 20 instantiates and adds the output data from the task. We highlight that the begin() and end() methods of Workflow and Task transmit the captured data over the network to the broker. Finally, line 19 is where the workflow task runs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. PROVENANCE CAPTURE OF EDGE-TO-CLOUD WORKFLOWS</head><p>This section presents the integration of ProvLight as a key system in the E2Clab <ref type="bibr" target="#b34">[35]</ref> framework for reproducible experimentation across the Edge-to-Cloud Continuum. This integration allows users to capture end-to-end provenance data of Edge-to-Cloud workflows. Figure <ref type="figure" target="#fig_4">4</ref> shows the extended E2Clab architecture with the new components in the red color.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Provenance Manager</head><p>We design a new manager named Provenance Manager. Figure <ref type="figure" target="#fig_4">4</ref> illustrates the integrated view of the two main elements that compose the Provenance Manager:</p><p>(i) ProvLight: to efficiently capture provenance data of workflows running on IoT devices. It also allows users to capture provenance in Cloud/HPC environments. ProvLight translates the captured data to the DfAnalyzer data model.</p><p>(ii) DfAnalyzer: to store and query provenance captured by ProvLight during workflow runtime (e.g., compare provenance of multiple workflow evaluations to understand how they impact on performance). Furthermore, it allows users to visualize dataflow specifications (i.e., data attributes of each dataset).</p><p>In addition to the characteristics of the provenance systems analyzed in Table <ref type="table" target="#tab_3">IV</ref>, and due to ProvLake being proprietary within IBM, while DfAnalyzer is open source <ref type="bibr" target="#b61">[62]</ref>, in this work we decide to use DfAnalyzer. As the data capture component of DfAnalyzer presents high overhead, we just use its data analysis and storage components. Finally, the Provenance Manager could replace DfAnalyzer with other provenance systems (e.g., PROV-IO, Komadu, etc.). It requires extending ProvLight to translate the provenance data to the data model of the provenance system and using their APIs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Provenance Capture</head><p>Through the E2Clab framework, users may easily enable provenance data capture across the Edge-to-Cloud continuum through simple configuration files, as illustrated in Listing 2. Listing 2 refers to the E2Clab layers services.yaml configuration file used to setup the experimental environment (e.g., testbeds, services that compose workflows, etc.). Lines 2 and 3 request resources from Grid'5000 and FIT IoT LAB testbeds, respectively. Line 8 requests a single server (e.g., Federated Learning server) on the Cloud layer; while line 11 requests 64 clients (e.g., to train the model with their local data) on the Edge layer. Finally, line 4 setups the provenance data capture (the ProvenanceManager service). After that, users may instrument their application code to capture data, as presented in Listing 1.</p><p>The ProvenanceManager service starts a Docker <ref type="bibr" target="#b62">[63]</ref> container with the DfAnalyzer provenance system and a ProvLight container allowing clients to send their provenance data. Df-Analyze exhibits at workflow runtime the captured data on its Web interface. The ProvenanceManager service may be easily plugged into other provenance systems by just using their Docker images and extending the provenance data translator. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. EVALUATION</head><p>We aim to answer the following research questions: how does ProvLight perform in IoT/Edge devices? while initially targeting resource-constrained Edge devices, can ProvLight be efficiently used also in the Cloud? We answer these questions in subsections A-D and E, respectively, by comparing ProvLight against ProvLake and DfAnalyzer.</p><p>The main performance metric is the capture overhead in terms of: (i) data capture time; (ii) CPU and memory usage; (iii) network usage; and (iv) power consumption. The experimental setup is the same as presented in Subsection III-A, with synthetic workloads generated based on the Federated Learning use case. The deployment is shown in Figure <ref type="figure" target="#fig_5">5</ref>. Results in Figure <ref type="figure" target="#fig_11">6</ref> are the mean of 10 runs with their 95% confidence interval.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Capture Time Overhead</head><p>Table VII presents the capture time overhead comparison for the 8 synthetic workloads. In summary, ProvLight presents low capture overhead (&lt;3%) for all workloads analyzed. Regarding tasks with a duration of 3.5 seconds or more, the capture overhead of ProvLight is below 0.5%. Varying the number of attributes per task from 10 to 100 does not significantly increase the capture time. We highlight that ProvLight is about 37x and 26x faster than ProvLake and DfAnalyzer, respectively.  Similarly to Table <ref type="table" target="#tab_2">III</ref>, Table VIII zooms our analysis in order to understand the impact of bandwidth variations and the grouping strategy on the data capture time. Results show that, differently from ProvLake, ProvLight presents low capture time overhead in low-bandwidth scenarios for task durations of 0.5 and 1 second. We highlight that, especially in lowbandwidth scenarios (25Kbit), the ProvLight grouping strategy presents low overhead (&lt;2%), while ProvLake presents high overhead (&gt;43%), see Table <ref type="table" target="#tab_2">III</ref>.</p><p>Scalability analysis. Table <ref type="table" target="#tab_8">IX</ref> presents the capture time overhead of ProvLight when scaling the number of IoT/Edge devices and considering 100 tasks of 0.5s each and 100 attributes per task. We scale the scenario with 8, 16, 32, and 64 devices capturing provenance data in parallel and sending the data to the cloud server. As illustrated in Figure <ref type="figure" target="#fig_5">5</ref>, each client sends its data to its respective topic in the Broker and we parallelized the number of translators accordingly. Lastly, provenance systems (i.e., DfAnalyzer in our case) can handle parallel requests and store the provenance data in a database system (e.g., MonetDB <ref type="bibr" target="#b63">[64]</ref> used in DfAnalyzer). Results show that by scaling up to 64 devices, the capture overhead is low (&lt;3%) and does not significantly impact the capture time. This is expected because devices (clients) asynchronously publish their messages to their respective topics in the MQTT-SN Broker. For 8 and 64 devices, the capture time overhead is 1.54% and 1.57%, respectively.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. CPU and Memory Overhead</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Network Usage Overhead</head><p>As presented in Figure <ref type="figure" target="#fig_11">6c</ref>, ProvLight transmits about 2x less data than ProvLake and DfAnalyzer. ProvLight network usage is around 3.7 KB/sec during data capture. The application layer protocol used in ProvLight (e.g., MQTT-SN), which compresses captured data before transmitting it, especially for tasks with many attributes per task (e.g., 100 in this case), explains such difference (2x less data) when compared to the other capture approaches.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Power Consumption Overhead</head><p>Finally, results in Figure <ref type="figure" target="#fig_11">6d</ref> (error bar omitted because we use the maximum power consumption for capturing provenance data) show that ProvLight power consumption overhead is 2.1x and 2.6x less than ProvLake and Dfanalyzer. We highlight that ProvLight overhead is 2.58% (considered low, &lt;3%), against 5.46% (ProvLake) and 6.8% (DfAnalyzer). The power consumption (in watts) for capturing and transmitting the data is on average 1.43W, 1.47W, and 1.49W for ProvLight, ProvLake, and DfAnalyzer, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Performance in Cloud Servers</head><p>We compare the capture time overhead of ProvLight against ProvLake and DfAnalyzer in Cloud servers (i.e., data capture on a server <ref type="bibr" target="#b47">[48]</ref> available in Grid'5000). Experiment results in Table <ref type="table" target="#tab_9">X</ref> show that the three approaches present low capture overhead (&lt;3%) for all task durations. Similarly to IoT/Edge devices, ProvLight also outperforms ProvLake and DfAnalyzer in Cloud servers. ProvLight is 7x and 5x faster than ProvLake and DfAnalyzer, respectively. ProvLight capture time overhead is very low (&lt;0.25%) for all task durations.     </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VII. DISCUSSION</head><p>The integration of ProvLight as a key system within the E2Clab framework exhibits a series of features that make E2Clab a promising platform for future performance optimization of applications on the Edge-to-Cloud Continuum through efficient provenance capture and reproducible experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. ProvLight Design Choices Impact on Performance</head><p>As presented in Table <ref type="table" target="#tab_5">VI</ref>, the combination of ProvLight design choices on the server and client sides contributed to the low capture overhead. The ProvLight client library keeps the connection to the remote server open while capturing data (i.e., when capturing data from different tasks, the connection is reused). Additionally, the library is based on the publish/subscribe asynchronous communication model and it uses MQTT-SN (application layer protocol) over UDP (transport layer protocol) instead of HTTP over TCP. Despite TCP being more reliable (e.g., uses acknowledgment messages for data delivery), the ProvLight client sends data using QoS level 2, which guarantees that each message is received exactly once by the recipient. Such design choices help to reduce connection overheads while data transmission handshakes/acknowledgments require less bandwidth.</p><p>Another important feature is that ProvLight compresses data (using binary format) before transmitting. Through preliminary experiments, we analyzed the performance trade-offs of compressing the data on the IoT/Edge devices to make sure it is worth adding that feature. The time required to compress data (e.g., tasks with 100 attributes) on the edge device is negligible, around 0.001s on average.</p><p>Our analysis considered low-bandwidth scenarios and also the data grouping strategy, resulting in fewer and larger messages to reduce the number of transmissions. We also observe that the overhead of decompressing and translating such data on the Cloud server is negligible, around 0.005s.</p><p>Data communication is key to performance efficiency in IoT/Edge workloads, especially for low bandwidth networks. ProvLight design choices such as simplified capture library for provenance data exchange (see Table <ref type="table" target="#tab_4">V</ref>), asynchronous MQTT-SN over UDP, data grouping, and data compression, explain the positive effects on performance and costs (e.g., lower overheads in terms of data capture time, and CPU, memory, network usage, and energy consumption).</p><p>In summary, the lightweight asynchronous protocol (MQTT-SN over UDP) has a major impact on the capture time overhead, energy consumption, and CPU and network usage. Our simplified data model has a major impact on memory consumption, and it helps to reduce even more the capture time overhead and CPU usage by 1.7% and 1.4%, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Impact of ProvLight on Real-life Use-Cases</head><p>To illustrate how real-life use cases could benefit from ProvLight and its integration in the E2Clab framework, we consider the training of Neural Networks presented in <ref type="bibr" target="#b14">[15]</ref> and <ref type="bibr" target="#b12">[13]</ref>. In these articles, the authors use the storage and query components of DfAnalyzer to store captured data during model training executed on Cloud/HPC infrastructure and then query the data. They demonstrate how provenance data may be used to answer queries like the ones we presented in Section I.</p><p>Since modern AI workflows are being executed on hybrid infrastructures, we may instantiate this use-case (Neural Network training on the Cloud/HPC) to the context of hybrid Edge-to-Cloud Federated Learning Neural Network training. In this hybrid context, the model is now trained on various resource-limited Edge devices. Thanks to the efficient capture approach of ProvLight, users may still track the model training by capturing provenance data. Without ProvLight, capturing provenance data of this use-case on the IoT/Edge is prohibitive due to the high overheads imposed by the existing approaches, as presented in Section III.</p><p>Finally, thanks to the E2Clab framework, users may easily set up the Federated Learning Neural Network training and deploy it on distributed Edge devices (to train the model) and on the Cloud server (to update the global model). Furthermore, the E2Clab Provenance Manager allows users to store data captured with ProvLight and query them using DfAnalyzer. Therefore, through the E2Clab Provenance Manager, users may answer the same queries mentioned earlier. We highlight that this Neural Network use case is just one example from various that could benefit from this work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Integration with Existing Systems</head><p>ProvLight is designed to be easily integrated with existing provenance systems (e.g., ProvLake, DfAnalyzer, PROV-IO, among others) and workflow management systems and deployment frameworks (e.g., Pegasus, E2Clab, among others). Such integration would enable these systems to capture provenance data (with low capture overheads) in IoT/Edge devices.</p><p>As presented in Subsection IV-B, this is possible thanks to the ProvLight provenance data translator. It translates from the ProvLight data format to the data format of the target system. This requires users to extend the ProvLight translator. In this work, we demonstrate in Section V: (i) the integration of ProvLight with the open-source DfAnalyzer provenance system as a solution for provenance capture on the IoT/Edge; and then (ii) we integrate this capture solution within the E2Clab framework (the Provenance Manager) to enable provenance capture of Edge-to-Cloud workflows.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Reproducibility and Artifact Availability</head><p>The experimental evaluations presented in this work follow a rigorous methodology <ref type="bibr" target="#b34">[35]</ref> to support reproducible Edgeto-Cloud experiments on large-scale testbeds (e.g., Grid'5000 and FIT IoT LAB used in our experiments). This guided us to systematically define the experimental environment (e.g., computing resources, services/systems, network, and application execution) through well-structured configuration files. The experiment artifacts and results are available at <ref type="bibr" target="#b46">[47]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VIII. RELATED WORK</head><p>Tanaka et al. <ref type="bibr" target="#b7">[8]</ref> extend the Pegasus <ref type="bibr" target="#b64">[65]</ref> Workflow Management System to support Edge-to-Cloud workflows. The paper explores performance trade-offs in managing and executing Edge-to-Cloud workloads. Pegasus provides provenance data collection capabilities to capture performance metrics during workflow execution. We highlight that Pegasus (and other systems like Kepler <ref type="bibr" target="#b65">[66]</ref>, Taverna <ref type="bibr" target="#b66">[67]</ref>, etc.) explores the predefined provenance capture approach. Pegasus automatically logs provenance data about the local execution of the application codes, such as launching them and capturing the exit status and runtime information <ref type="bibr" target="#b67">[68]</ref>. While ProvLight and the systems we compared with (see Table <ref type="table" target="#tab_3">IV</ref>) explore the userdefined capture approach, i.e., the user defines what to capture by workflow code instrumentation. Furthermore, unlike Prov-Light, Pegasus does not explore IoT/Edge protocols to transfer the captured data nor provides features like simplified data models and compressing and grouping messages. This may result in higher overheads compared to ProvLight, as presented in Section III. Finally, the authors do not analyze the energy consumption of their capture approach.</p><p>A provenance collection framework for the IoT/Edge devices is proposed in <ref type="bibr" target="#b68">[69]</ref>. The proposed framework follows PROV-DM recommendations and provides provenance collection capabilities for IoT/Edge devices. Unlike our work, the authors do not validate their approach on real-life Edge devices. Also, no performance evaluations are presented to understand capture overheads.</p><p>Genoma, a distributed provenance-as-a-service system across IoT/Edge devices and Cloud servers, is proposed in <ref type="bibr" target="#b69">[70]</ref>. Genoma transmits provenance data to the Cloud using the MQTT protocol. Data is transmitted based on storage availability on the Edge device and the frequency of data communication. The authors do not evaluate the performance of Genoma. Capture overheads regarding capture time, network usage, energy consumption, and CPU and memory usage are left for future work. In contrast, ProvLight is evaluated on all the metrics mentioned above.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IX. CONCLUSION</head><p>The integration of ProvLight within E2Clab makes the latter, to the best of our knowledge, the first framework to support the end-to-end provenance capture of Edge-to-Cloud workflows with low overheads across the Computing Continuum. Prov-Light and E2Clab are available as open-source tools. In future work, we will enable the provenance capture of workflows developed in C/C++ (not only in Python) and secure the data transmission from the Edge devices to the provenance system.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>b)</head><label></label><figDesc>Performance metrics.:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 :</head><label>3</label><figDesc>Fig. 3: ProvLight Architecture.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>1 15 d a t a i d += 1 16 t</head><label>1516</label><figDesc>from p r o v l i g h t i m p o r t Workflow , Task , D a t a 2 a t t r i b u t e s = 100 3 c h a i n e d t r a n s f o r m a t i o n s = 5 4 n u m b e r o f t a s k s = 100 5 # A p p l i c a t i o n Workflow 6 w o r k f l o w = Workflow ( 1 ) 7 w o r k f l o w . b e g i n ( ) 8 # T a s k s and d a t a d e r i v a t i o n s 9 d a t a i d = 0 10 p r e v i o u s t a s k = [ ] 11 i n d a t a = { ' i n ' : [ 1 f o r i n r a n g e ( a t t r i b u t e s ) ]} 12 o u t d a t a = { ' o u t ' : [ 2 f o r i n r a n g e ( a t t r i b u t e s ) ]} 13 f o r t r a n s f i d i n r a n g e ( c h a i n e d t r a n s f o r m a t i o n s ) : 14 f o r t a s k i d i n r a n g e ( i n t ( n u m b e r o f t a s k s / c h a i n e d t r a n s f o r m a t i o n s ) ) : a s k = Task ( t r a n s f i d -t a s k i d , workflow , t r a n s f i d , d e p e n d e n c i e s = p r e v i o u s t a s k ) 17 d a t a i n = D a t a ( i n { d a t a i d } , w o r k f l o w . i d , i n d a t a ) 18 t a s k . b e g i n ( [ d a t a i n ] ) 19 # ### ADD YOUR TASK HERE #### 20 d a t a o u t = D a t a ( o u t { d a t a i d } , w o r k f l o w . i d , o u t d a t a ) 21 t a s k . end ( [ d a t a o u t ] ) 22 p r e v i o u s t a s k = [ t a s k . i d ] 23 w o r k f l o w . end ( ) Listing 1: ProvLight: user-defined provenance capture.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 4 :</head><label>4</label><figDesc>Fig. 4: Extended E2Clab: Provenance Data Manager.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 5 :</head><label>5</label><figDesc>Fig. 5: Experimental setup.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figures</head><label></label><figDesc>Figures 6a and 6b present the CPU and memory overhead for capturing provenance data with ProvLake, DfAnalyzer, and ProvLight (from left to right). Regarding the CPU overhead,</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Fig. 6 :</head><label>6</label><figDesc>Fig.6: Provenance data capture overhead with respect to: CPU, memory, network usage, and power consumption.</figDesc><graphic coords="10,433.39,50.54,131.51,98.63" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>TABLE I :</head><label>I</label><figDesc>Synthetic workload configurations.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>TABLE II :</head><label>II</label><figDesc>Capture overhead of ProvLake and DfAnalyzer.</figDesc><table><row><cell></cell><cell>overhead</cell><cell>low</cell><cell>high</cell><cell></cell><cell></cell></row><row><cell></cell><cell>level</cell><cell>3%</cell><cell>&gt;3%</cell><cell></cell><cell></cell></row><row><cell>attributes per task</cell><cell>Provenance System</cell><cell></cell><cell cols="2">Capture Overhead (%)</cell><cell></cell></row><row><cell>10</cell><cell>ProvLake</cell><cell>56.9% Â±0.08</cell><cell>29.9% Â±0.29</cell><cell>8.56% Â±0.01</cell><cell>6.02% Â±0.01</cell></row><row><cell>10</cell><cell>DfAnalyzer</cell><cell>39.8% Â±0.06</cell><cell>21.2% Â±0.34</cell><cell>6.12% Â±0.07</cell><cell>4.26% Â±0.01</cell></row><row><cell>100</cell><cell>ProvLake</cell><cell>57.3% Â±0.10</cell><cell>30.1% Â±0.41</cell><cell>8.57% Â±0.01</cell><cell>6.04% Â±0.04</cell></row><row><cell>100</cell><cell>DfAnalyzer</cell><cell>40.5% Â±0.20</cell><cell>21.3% Â±0.06</cell><cell>6.12% Â±0.01</cell><cell>4.31% Â±0.01</cell></row><row><cell></cell><cell>task dur. (s)</cell><cell>0.5</cell><cell>1</cell><cell>3.5</cell><cell>5</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>TABLE III :</head><label>III</label><figDesc>ProvLake: impact of bandwidth and grouping strategy on the capture overhead.</figDesc><table><row><cell cols="3"># of messages grouped Bandwidth 1Gbit</cell><cell cols="2">Bandwidth 25Kbit</cell></row><row><cell>0</cell><cell>57.3% Â±0.10</cell><cell>30.1% Â±0.27</cell><cell>321% Â±1.05</cell><cell>161% Â±1.14</cell></row><row><cell>10</cell><cell>6.83% Â±0.02</cell><cell>3.58% Â±0.20</cell><cell>102.5% Â±3.89</cell><cell>49.8% Â±2.92</cell></row><row><cell>20</cell><cell>3.87% Â±0.01</cell><cell>1.99% Â±0.01</cell><cell>100.8% Â±3.78</cell><cell>51.16% Â±1.03</cell></row><row><cell>50</cell><cell>2.37% Â±0.01</cell><cell>1.24% Â±0.01</cell><cell>95.04% Â±0.10</cell><cell>43.23% Â±0.28</cell></row><row><cell>task duration (s)</cell><cell>0.5</cell><cell>1</cell><cell>0.5</cell><cell>1</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>TABLE IV :</head><label>IV</label><figDesc>Limitations of existing provenance systems.</figDesc><table><row><cell>System</cell><cell>Limitation</cell></row><row><cell>DfAnalyzer</cell><cell>Presents high (&gt;3%) capture overhead for all synthetic workloads.</cell></row><row><cell></cell><cell>Presents high (&gt;3%) overhead for all work-</cell></row><row><cell></cell><cell>loads. However, ProvLake allows grouping</cell></row><row><cell>ProvLake</cell><cell>captured data to reduce transmission fre-quency, enabling lower overhead, but it still</cell></row><row><cell></cell><cell>suffers high overhead in low bandwidth net-</cell></row><row><cell></cell><cell>works.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>TABLE V :</head><label>V</label><figDesc>The ProvLight provenance data exchange model follows PROV-DM.</figDesc><table><row><cell>PROV-DM</cell><cell>ProvLight</cell><cell>ProvLight</cell><cell></cell><cell cols="2">ProvLight Attribute Description</cell><cell>ProvLight</cell></row><row><cell>Type</cell><cell>Class</cell><cell cols="2">Class Attributes</cell><cell cols="2">and PROV-DM Relationships</cell><cell>Class Description</cell></row><row><cell>Agent</cell><cell>Workflow</cell><cell>id</cell><cell></cell><cell>Workflow id.</cell><cell>Refers to application workflows.</cell></row><row><cell></cell><cell></cell><cell>id</cell><cell></cell><cell>Task id.</cell></row><row><cell></cell><cell></cell><cell>workflow</cell><cell></cell><cell cols="2">Links tasks with the workflow they belong to (wasAssociatedWith).</cell><cell>Represents the processing</cell></row><row><cell>Activity</cell><cell>Task</cell><cell>dependencies data</cell><cell></cell><cell cols="2">Dependencies between tasks (wasInformedBy). Data used (used) and generated (wasGeneratedBy) by a task.</cell><cell>steps of tasks (and their dependencies) that compose</cell></row><row><cell></cell><cell></cell><cell>time</cell><cell></cell><cell cols="2">Task start and end time.</cell><cell>workflows.</cell></row><row><cell></cell><cell></cell><cell>status</cell><cell></cell><cell cols="2">Task status: running or finished.</cell></row><row><cell>Entity</cell><cell>Data</cell><cell>id workflow id derivations attributes</cell><cell></cell><cell cols="2">Data id. Links data with the workflow they belong to (wasAttributedTo). Links chained data (wasDerivedFrom). Data attributes and values.</cell><cell>Represents data derivations along the workflow execution.</cell></row><row><cell>Server</cell><cell></cell><cell>broker translator</cell><cell cols="2">Client library</cell><cell>IoT/Edge device</cell></row><row><cell></cell><cell cols="2">HPC/Cloud</cell><cell></cell><cell cols="2">IoT/Edge</cell></row><row><cell cols="2">Provenance</cell><cell></cell><cell></cell><cell cols="2">Provlight</cell></row><row><cell cols="2">Systems</cell><cell></cell><cell></cell><cell cols="2">Client</cell></row><row><cell></cell><cell></cell><cell cols="2">ProvLight</cell><cell cols="2">Library</cell></row><row><cell cols="2">ProvLake</cell><cell cols="2">Server</cell><cell></cell></row><row><cell cols="2">DfAnalyzer</cell><cell cols="2">services</cell><cell></cell></row><row><cell cols="2">PROV-IO</cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="2">Komadu â¦</cell><cell>Provenance data translator</cell><cell>broker</cell><cell></cell><cell>â¦</cell></row><row><cell>others</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>TABLE VI :</head><label>VI</label><figDesc>How does ProvLight differ from state-of-the-art systems in terms of data capture?</figDesc><table><row><cell></cell><cell>ProvLight</cell><cell>DfAnalyzer</cell><cell>ProvLake</cell></row><row><cell>application layer protocol</cell><cell>MQTT-SN QoS 2: Exactly once</cell><cell>HTTP 1.1</cell><cell>HTTP 1.1</cell></row><row><cell>transport layer protocol</cell><cell>UDP</cell><cell>TCP</cell><cell>TCP</cell></row><row><cell>Communication</cell><cell>Publish/</cell><cell>Request/</cell><cell>Request/</cell></row><row><cell>model</cell><cell>Subscribe</cell><cell>Response</cell><cell>Response</cell></row><row><cell>Server side</cell><cell>MQTT-SN Broker</cell><cell>HTTP Server</cell><cell>HTTP Server</cell></row><row><cell></cell><cell>provenance data</cell><cell></cell><cell></cell></row><row><cell>Client side features</cell><cell>representation &amp; payload compression &amp;</cell><cell>N/A</cell><cell>grouping data captured</cell></row><row><cell></cell><cell>grouping data captured</cell><cell></cell><cell></cell></row><row><cell>Provenance data model</cell><cell>PROV-DM</cell><cell>PROV-DM</cell><cell>PROV-DM</cell></row><row><cell>Capture library language</cell><cell>Python</cell><cell>Python, C++</cell><cell>Python</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>TABLE VII :</head><label>VII</label><figDesc>ProvLight: capture overhead in IoT/Edge devices. Refer to Table II to compare with DfAnalyzer and ProvLake.</figDesc><table><row><cell>Attributes per task</cell><cell></cell><cell cols="2">Capture Overhead (%)</cell><cell></cell></row><row><cell>10</cell><cell>1.45% Â±0.01</cell><cell>1.02% Â±0.01</cell><cell>0.31% Â±0.01</cell><cell>0.23% Â±0.01</cell></row><row><cell>100</cell><cell>1.54% Â±0.01</cell><cell>1.11% Â±0.01</cell><cell>0.37% Â±0.01</cell><cell>0.29% Â±0.01</cell></row><row><cell>task duration (s)</cell><cell>0.5</cell><cell>1</cell><cell>3.5</cell><cell>5</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>TABLE VIII :</head><label>VIII</label><figDesc>ProvLight: impact of bandwidth and grouping strategy on the capture overhead. Refer to TableIIIto compare with ProvLake.</figDesc><table><row><cell cols="3"># of messages grouped Bandwidth 1Gbit</cell><cell cols="2">Bandwidth 25Kbit</cell></row><row><cell>0</cell><cell>1.54% Â±0.01</cell><cell>1.10% Â±0.01</cell><cell>1.56% Â±0.01</cell><cell>1.04% Â±0.01</cell></row><row><cell>10</cell><cell>1.37% Â±0.01</cell><cell>0.75% Â±0.01</cell><cell>1.37% Â±0.01</cell><cell>0.74% Â±0.01</cell></row><row><cell>20</cell><cell>1.32% Â±0.01</cell><cell>0.72% Â±0.01</cell><cell>1.34% Â±0.01</cell><cell>0.73% Â±0.01</cell></row><row><cell>50</cell><cell>1.31% Â±0.01</cell><cell>0.72% Â±0.01</cell><cell>1.31% Â±0.01</cell><cell>0.72% Â±0.01</cell></row><row><cell>task duration (s)</cell><cell>0.5</cell><cell>1</cell><cell>0.5</cell><cell>1</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>TABLE IX :</head><label>IX</label><figDesc>ProvLight scalability analysis.</figDesc><table><row><cell>System</cell><cell></cell><cell cols="2">Capture Overhead (%)</cell><cell></cell></row><row><cell>ProvLight</cell><cell>1.54% Â±0.01</cell><cell>1.54% Â±0.01</cell><cell>1.56% Â±0.01</cell><cell>1.57% Â±0.02</cell></row><row><cell># of devices</cell><cell>8</cell><cell>16</cell><cell>32</cell><cell>64</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>TABLE X :</head><label>X</label><figDesc>Capture overhead in Cloud servers.</figDesc><table><row><cell></cell><cell>System</cell><cell></cell><cell cols="2">Capture Overhead (%)</cell><cell></cell></row><row><cell>100</cell><cell>ProvLake</cell><cell>1.71% Â±0.03</cell><cell>0.92% Â±0.01</cell><cell>0.34% Â±0.01</cell><cell>0.26% Â±0.01</cell></row><row><cell>attributes per task</cell><cell>DfAnalyzer</cell><cell>1.17% Â±0.02</cell><cell>0.63% Â±0.01</cell><cell>0.25% Â±0.01</cell><cell>0.21% Â±0.01</cell></row><row><cell></cell><cell>ProvLight</cell><cell>0.24% Â±0.01</cell><cell>0.17% Â±0.01</cell><cell>0.12% Â±0.01</cell><cell>0.11% Â±0.01</cell></row><row><cell></cell><cell>task duration (s)</cell><cell>0.5</cell><cell>1</cell><cell>3.5</cell><cell>5</cell></row><row><cell cols="6">ProvLight uses 7x and 5x less CPU than ProvLake and</cell></row><row><cell cols="6">DfAnalyzer, respectively. Capturing with ProvLight, the CPU</cell></row><row><cell cols="6">overhead is low (&lt;3%), and CPU usage varies between 1.7%</cell></row><row><cell cols="6">and 2%. Regarding the memory overhead, ProvLight memory</cell></row><row><cell cols="6">usage is &lt;4%. It uses about 2x less memory than ProvLake</cell></row><row><cell cols="2">and DfAnalyzer.</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>ACKNOWLEDGMENTS</head><p>This work was funded by <rs type="funder">Inria</rs> through the <rs type="funder">HPC-BigData Inria Challenge (IPL)</rs>, by the <rs type="funder">French ANR OverFlow</rs> project (<rs type="grantNumber">ANR-15-CE25-0003</rs>), and the <rs type="funder">HPDaSc</rs> associate team with <rs type="person">Brazil</rs>. <rs type="person">Marta Mattoso</rs> and <rs type="person">DÃ©bora Pina</rs> are funded by <rs type="funder">CNPq</rs> and <rs type="funder">FAPERJ</rs><rs type="person">. Renan</rs> is at the <rs type="institution">Oak Ridge Leadership Computing Facility</rs> at the <rs type="institution">Oak Ridge National Laboratory</rs>, which is supported by the <rs type="funder">Office of Science of the U.S. Department of Energy</rs> under Contract No. <rs type="grantNumber">DE-AC05-00OR22725</rs>. Experiments presented in this paper were carried out using the Grid'5000 and <rs type="institution">FIT IoT LAB</rs> testbeds, supported by a scientific interest group hosted by several <rs type="funder">Universities</rs> and organizations.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_CtBjUYq">
					<idno type="grant-number">ANR-15-CE25-0003</idno>
				</org>
				<org type="funding" xml:id="_BRZFTXR">
					<idno type="grant-number">DE-AC05-00OR22725</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<ptr target="https://gitlab.inria.fr/provlight/provlight" />
		<title level="m">Provlight tool: Provenance capture for iot/edge devices</title>
		<imprint>
			<date type="published" when="2023-01">2023, jan</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">E2clab source code</title>
		<ptr target="https://gitlab.inria.fr/E2Clab/e2clab" />
		<imprint>
			<date type="published" when="2019-01">2019. jan</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Distributed intelligence on the Edge-to-Cloud Continuum: A systematic literature review</title>
		<author>
			<persName><forename type="first">D</forename><surname>Rosendo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Costan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Valduriez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Antoniu</surname></persName>
		</author>
		<ptr target="https://hal.archives-ouvertes.fr/hal-03654722" />
	</analytic>
	<monogr>
		<title level="j">Journal of Parallel and Distributed Computing</title>
		<imprint>
			<biblScope unit="volume">166</biblScope>
			<biblScope unit="page" from="71" to="94" />
			<date type="published" when="2022-08">Aug. 2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Edge intelligence: The confluence of edge computing and artificial intelligence</title>
		<author>
			<persName><forename type="first">S</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Dustdar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">Y</forename><surname>Zomaya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Internet of Things Journal</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="7457" to="7469" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Big data and extremescale computing: Pathways to convergence -toward a shaping strategy for a future software and data ecosystem for scientific inquiry</title>
		<author>
			<persName><forename type="first">M</forename><surname>Asch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Moore</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Badia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Beck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Beckman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Bidot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Bodin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Cappello</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Choudhary</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>De Supinski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The International Journal of High Performance Computing Applications</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="435" to="479" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<ptr target="https://www.etp4hpc.eu/sra.html" />
		<title level="m">Etp4hpc strategic research agenda</title>
		<imprint>
			<date type="published" when="2020-04-29">April 29, 2020</date>
		</imprint>
	</monogr>
	<note>ETP4HPC</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Combining heuristics to optimize and scale the placement of iot applications in the fog</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Etchevers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Letondeur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Lebre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Coupaye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Desprez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE/ACM 11th International Conference on Utility and Cloud Computing (UCC)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2018">2018. 2018</date>
			<biblScope unit="page" from="153" to="163" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Automating edge-to-cloud workflows for science: Traversing the edge-to-cloud continuum with pegasus</title>
		<author>
			<persName><forename type="first">R</forename><surname>Tanaka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Papadimitriou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">C</forename><surname>Viswanath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Lyons</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Thareja</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Esquivel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Deelman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2022 22nd IEEE International Symposium on Cluster, Cloud and Internet Computing (CCGrid)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="826" to="833" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Reproducible Performance Optimization of Complex Applications on the Edge-to-Cloud Continuum</title>
		<author>
			<persName><forename type="first">D</forename><surname>Rosendo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Costan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Antoniu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Simonin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-C</forename><surname>Lombardo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Joly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Valduriez</surname></persName>
		</author>
		<ptr target="https://hal.archives-ouvertes.fr/hal-03310540" />
	</analytic>
	<monogr>
		<title level="m">Cluster 2021 -IEEE International Conference on Cluster Computing</title>
		<meeting><address><addrLine>Portland, OR, United States</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2021-09">Sep. 2021</date>
			<biblScope unit="page" from="23" to="34" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Coding the computing continuum: Fluid function execution in heterogeneous computing environments</title>
		<author>
			<persName><forename type="first">R</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Baughman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Chard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Babuji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Foster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Chard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2021 IEEE International Parallel and Distributed Processing Symposium Workshops (IPDPSW)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="66" to="75" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Encyclopedia of database systems</title>
		<author>
			<persName><forename type="first">L</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">T</forename><surname>Ãzsu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
			<publisher>Springer</publisher>
			<biblScope unit="volume">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Keeping track of user steering actions in dynamic workflows</title>
		<author>
			<persName><forename type="first">R</forename><surname>Souza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Silva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Camata</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">L G A</forename><surname>Coutinho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Valduriez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mattoso</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Future Generation Computer Systems</title>
		<imprint>
			<biblScope unit="volume">99</biblScope>
			<biblScope unit="page" from="624" to="643" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Capturing provenance to improve the model training of pinns: first handon experiences with grid5000</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Silva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Pina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Kunstmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Oliveira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Valduriez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">L</forename><surname>Coutinho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mattoso</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CILAMCE-PANACM 2021-Proceedings of the joint XLII Ibero-Latin-American Congress on Computational Methods in Engineering and III Pan-American Congress on Computational Mechanics</title>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="1" to="7" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Workflow provenance in the lifecycle of scientific machine learning</title>
		<author>
			<persName><forename type="first">R</forename><surname>Souza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">G</forename><surname>Azevedo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Lourenc Â¸o</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Soares</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Thiago</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>BrandÃ£o</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Civitarese</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Brazil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Moreno</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Valduriez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mattoso</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Cerqueira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A S</forename><surname>Netto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Concurrency and Computation: Practice and Experience</title>
		<imprint>
			<biblScope unit="volume">6544</biblScope>
			<biblScope unit="page" from="1" to="21" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Provenance supporting hyperparameter analysis in deep neural networks</title>
		<author>
			<persName><forename type="first">D</forename><surname>Pina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Kunstmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Oliveira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Valduriez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mattoso</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Provenance and Annotation of Data and Processes: 8th and 9th International Provenance and Annotation Workshop, IPAW 2020+ IPAW 2021</title>
		<meeting><address><addrLine>Virtual Event</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2021">July 19-22, 2021. 2021</date>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="20" to="38" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A survey on provenance: What for? what form? what from?</title>
		<author>
			<persName><forename type="first">M</forename><surname>Herschel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>DiestelkÃ¤mper</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Ben Lahmar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The VLDB Journal</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="881" to="906" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Efficient runtime capture of multiworkflow data using provenance</title>
		<author>
			<persName><forename type="first">R</forename><surname>Souza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Azevedo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Thiago</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Soares</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Nery</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Netto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Vital</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Cerqueira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Valduriez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mattoso</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2019 15th International Conference on eScience (eScience)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="359" to="368" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Dfanalyzer: runtime dataflow analysis tool for computational science and engineering applications</title>
		<author>
			<persName><forename type="first">V</forename><surname>Silva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Campos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Guedes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Camata</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Oliveira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">L</forename><surname>Coutinho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Valduriez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mattoso</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SoftwareX</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page">100592</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">The next 5 years: what opportunities should the database community seize to maximize its impact?</title>
		<author>
			<persName><forename type="first">M</forename><surname>Balazinska</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Chaudhuri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ailamaki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Freire</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Krishnamurthy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Stonebraker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 ACM SIGMOD International Conference on Management of Data</title>
		<meeting>the 2020 ACM SIGMOD International Conference on Management of Data</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="411" to="414" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">F</forename><surname>Da Silva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Badia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Bala</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Bard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P.-T</forename><surname>Bremer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Buckley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Caino-Lores</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Chard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Goble</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Jha</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2304.00019</idno>
		<title level="m">Workflows community summit 2022: A roadmap revolution</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Prov-io: An i/ocentric provenance framework for scientific data on hpc systems</title>
		<author>
			<persName><forename type="first">R</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Byna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 31st International Symposium on High-Performance Parallel and Distributed Computing</title>
		<meeting>the 31st International Symposium on High-Performance Parallel and Distributed Computing</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="213" to="226" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">An approach to standalone provenance systems for big social provenance data</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Tas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Baeth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Aktas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2016 12th International Conference on Semantics, Knowledge and Grids (SKG)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="9" to="16" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Fit iot-lab: A large scale open experimental iot testbed</title>
		<author>
			<persName><forename type="first">C</forename><surname>Adjih</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Baccelli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Fleury</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Harter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Mitton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Noel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Pissard-Gibollet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Saint-Marcel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Schreiner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Vandaele</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2015 IEEE 2nd World Forum on Internet of Things (WF-IoT)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="459" to="464" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Grid&apos;5000: A Large Scale And Highly Reconfigurable Experimental Grid Testbed</title>
		<author>
			<persName><forename type="first">R</forename><surname>Bolze</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Cappello</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Caron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Dayde</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Desprez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Jeannot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>JÃ©gou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lanteri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Leduc</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Melab</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Mornet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Namyst</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Primet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>QuÃ©tier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Richard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E.-G</forename><surname>Talbi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Touche</surname></persName>
		</author>
		<ptr target="https://hal.inria.fr/hal-00684943" />
	</analytic>
	<monogr>
		<title level="j">International Journal of High Performance Computing Applications</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="481" to="494" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Proml: A decentralised platform for provenance management of machine learning software systems</title>
		<author>
			<persName><forename type="first">N</forename><surname>Khoi Tran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Sabir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Babar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Abolhasan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lipman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Software Architecture: 16th European Conference, ECSA 2022</title>
		<meeting><address><addrLine>Prague, Czech Republic</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2022">September 19-23, 2022. 2022</date>
			<biblScope unit="page" from="49" to="65" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Active provenance for data-intensive workflows: engaging users and developers</title>
		<author>
			<persName><forename type="first">A</forename><surname>Spinuso</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Atkinson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Magnoni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2019 15th International Conference on eScience (eScience)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="560" to="569" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Survey on the analysis of user interactions and visualization provenance</title>
		<author>
			<persName><forename type="first">K</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ottley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Walchshofer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Streit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wenskovitch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics Forum</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="757" to="783" />
			<date type="published" when="2020">2020</date>
			<publisher>Wiley Online Library</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Prov-dm: The prov data model</title>
		<author>
			<persName><forename type="first">K</forename><surname>Belhajjame</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>B'far</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Cheney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Coppens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Cresswell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Gil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Groth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Klyne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Lebo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Mccusker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">W3C Recommendation</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="15" to="16" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">The w3c prov family of specifications for modelling provenance metadata</title>
		<author>
			<persName><forename type="first">P</forename><surname>Missier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Belhajjame</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Cheney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 16th International Conference on Extending Database Technology</title>
		<meeting>the 16th International Conference on Extending Database Technology</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="773" to="776" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<author>
			<persName><forename type="first">N</forename><surname>Garg</surname></persName>
		</author>
		<title level="m">Apache kafka</title>
		<meeting><address><addrLine>Birmingham, UK</addrLine></address></meeting>
		<imprint>
			<publisher>Packt Publishing</publisher>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Spark: Cluster Computing with Working Sets</title>
		<author>
			<persName><forename type="first">M</forename><surname>Zaharia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Chowdhury</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Franklin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Shenker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Stoica</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2Nd USENIX Conference on Hot Topics in Cloud Computing, ser. HotCloud&apos;10</title>
		<meeting>the 2Nd USENIX Conference on Hot Topics in Cloud Computing, ser. HotCloud&apos;10<address><addrLine>Berkeley, CA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>USENIX Association</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="10" to="10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Communication-efficient learning of deep networks from decentralized data</title>
		<author>
			<persName><forename type="first">B</forename><surname>Mcmahan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Moore</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Ramage</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Hampson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">A</forename><surname>Arcas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Artificial intelligence and statistics</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1273" to="1282" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Edgefed: Optimized federated learning based on edge computing</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="209" to="191" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Provenance supporting hyperparameter analysis in deep neural networks</title>
		<author>
			<persName><forename type="first">D</forename><surname>Pina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Kunstmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Oliveira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Valduriez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mattoso</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Provenance and Annotation of Data and Processes</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="20" to="38" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">E2Clab: Exploring the Computing Continuum through Repeatable, Replicable and Reproducible Edge-to-Cloud Experiments</title>
		<author>
			<persName><forename type="first">D</forename><surname>Rosendo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Silva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Simonin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Costan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Antoniu</surname></persName>
		</author>
		<ptr target="https://hal.archives-ouvertes.fr/hal-02916032" />
	</analytic>
	<monogr>
		<title level="m">Cluster 2020 -IEEE International Conference on Cluster Computing</title>
		<meeting><address><addrLine>Kobe, Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020-09">Sep. 2020</date>
			<biblScope unit="page" from="1" to="11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">EnosLib: A Library for Experiment-Driven Research in Distributed Computing</title>
		<author>
			<persName><forename type="first">R.-A</forename><surname>Cherrueau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Delavergne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Van Kempen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Lebre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Pertin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Rojas Balderrama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Simonet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Simonin</surname></persName>
		</author>
		<ptr target="https://hal.inria.fr/hal-03324177" />
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Parallel and Distributed Systems</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1464" to="1477" />
			<date type="published" when="2022-06">Jun. 2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Lessons learned from the chameleon testbed</title>
		<author>
			<persName><forename type="first">K</forename><surname>Keahey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Anderson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Riteau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Ruth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Stanzione</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Cevik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Colleran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">S</forename><surname>Gunawi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Hammock</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2020 USENIX Annual Technical Conference (USENIX ATC 20)</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="219" to="233" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Lineagechain: a fine-grained, secure and efficient data provenance system for blockchains</title>
		<author>
			<persName><forename type="first">P</forename><surname>Ruan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">T A</forename><surname>Dinh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">C</forename><surname>Ooi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The VLDB Journal</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="3" to="24" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Runtime analysis of whole-system provenance</title>
		<author>
			<persName><forename type="first">T</forename><surname>Pasquier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Moyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bates</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Hermant</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Eyers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bacon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Seltzer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 ACM SIGSAC conference on computer and communications security</title>
		<meeting>the 2018 ACM SIGSAC conference on computer and communications security</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="1601" to="1616" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">The trade-offs between fog processing and communications in latency-sensitive vehicular fog computing</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">F</forename><surname>De Mendonc Â¸a Junior</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Kokkinogenis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">L</forename><surname>Dias</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">M</forename><surname>Orey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Rossetti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pervasive and Mobile Computing</title>
		<imprint>
			<biblScope unit="volume">84</biblScope>
			<biblScope unit="page">101638</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Iot-enabled smart energy grid: Applications and challenges</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A A</forename><surname>Abir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Anwar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kayes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE access</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="50" to="961" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Edge-assisted rendering of 360 videos streamed to head-mounted virtual reality</title>
		<author>
			<persName><forename type="first">W.-C</forename><surname>Lo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-Y</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-H</forename><surname>Hsu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2018 IEEE International Symposium on Multimedia (ISM)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="44" to="51" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Federated learning for internet of things</title>
		<author>
			<persName><forename type="first">T</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Avestimehr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 19th ACM Conference on Embedded Networked Sensor Systems</title>
		<meeting>the 19th ACM Conference on Embedded Networked Sensor Systems</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="413" to="419" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Deep anomaly detection for time-series data in industrial iot: A communication-efficient on-device federated learning approach</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Garg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Hossain</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Internet of Things Journal</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="6348" to="6358" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">An on-device federated learning approach for cooperative model update between edge devices</title>
		<author>
			<persName><forename type="first">R</forename><surname>Ito</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Tsukada</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Matsutani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="92" to="986" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<ptr target="https://www.iot-lab.info/docs/boards/iot-lab-a8-m3/" />
		<title level="m">Iot-lab a8-m3 board</title>
		<imprint>
			<date type="published" when="2023-01-02">January 2, 2023</date>
		</imprint>
	</monogr>
	<note>IoT-LAB</note>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<ptr target="https://gitlab.inria.fr/E2Clab/examples/provenance-iot-edge" />
		<title level="m">Provenance capture iot/edge: experiment artifacts</title>
		<imprint>
			<date type="published" when="2023-01">2023, jan</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<author>
			<persName><surname>G5k</surname></persName>
		</author>
		<ptr target="https://www.grid5000.fr/w/Nancy:Hardware#gros" />
		<title level="m">Grid&apos;5000: a large-scale and flexible testbed for experimentdriven research</title>
		<imprint>
			<date type="published" when="2023-01-02">January 2, 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<ptr target="https://mqtt.org/" />
		<title level="m">Mqtt: The standard for iot messaging</title>
		<imprint>
			<date type="published" when="2023-07">2023, jul</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<ptr target="https://datatracker.ietf.org/doc/html/rfc7252" />
		<title level="m">Coap: The constrained application protocol</title>
		<imprint>
			<date type="published" when="2023-07">2023, jul</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<title level="m" type="main">Amqp: Advanced message queuing protocol</title>
		<ptr target="http://docs.oasis-open.org/amqp/core/v1.0/os/amqp-core-overview-v1.0-os.html" />
		<imprint>
			<date type="published" when="2023-07">2023, jul</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<ptr target="https://datatracker.ietf.org/doc/html/rfc768" />
		<title level="m">Udp: User datagram protocol</title>
		<imprint>
			<date type="published" when="2023-07">2023, jul</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<ptr target="https://datatracker.ietf.org/doc/html/rfc6550" />
		<title level="m">Rpl: Ipv6 routing protocol for low-power and lossy networks</title>
		<imprint>
			<date type="published" when="2023-07">2023, jul</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Evaluating the performance of coap, mqtt, and http in vehicular scenarios</title>
		<author>
			<persName><forename type="first">R</forename><surname>Morabito</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Laaroussi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>JimÃ©nez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Standards for Communications and Networking</title>
		<imprint>
			<publisher>CSCN</publisher>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Comparison with http and mqtt in internet of things (iot)</title>
		<author>
			<persName><forename type="first">B</forename><surname>Wukkadada</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Wankhede</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Nambiar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Nair</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2018 International Conference on Inventive Research in Computing Applications (ICIRCA)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="249" to="253" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">A comparative evaluation of amqp, mqtt and http protocols using real-time public smart city data</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">B</forename><surname>Gemirter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">Â¸</forename></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">Â¸</forename><surname>Baydere</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2021 6th International Conference on Computer Science and Engineering (UBMK)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="542" to="547" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Mqtt for sensor networks (mqtt-sn) protocol specification</title>
		<author>
			<persName><forename type="first">A</forename><surname>Stanford-Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">L</forename><surname>Truong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International business machines (IBM) Corporation version</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1" to="28" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
		<ptr target="https://github.com/eclipse/mosquitto.rsmb" />
		<title level="m">Rsmb: Really small message broker</title>
		<imprint>
			<date type="published" when="2013-01">2013, jan</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<monogr>
		<ptr target="https://github.com/eclipse/mosquitto" />
		<title level="m">Eclipse mosquitto: An open source mqtt broker</title>
		<imprint>
			<date type="published" when="2017-01">2017, jan</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<monogr>
		<ptr target="https://github.com/luanguimaraesla/mqttsn" />
		<title level="m">Python client for mqtt-sn brokers</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<monogr>
		<ptr target="https://github.com/psf/requests" />
		<title level="m">Requests: Http for humans</title>
		<imprint>
			<date type="published" when="2018-01">2018, jan</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<monogr>
		<ptr target="https://gitlab.com/ssvitor/dataflowanalyzer" />
		<title level="m">Dfanalyzer tool</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<monogr>
		<author>
			<persName><surname>Docker</surname></persName>
		</author>
		<ptr target="https://www.docker.com/" />
		<title level="m">What is in a docker container?</title>
		<imprint>
			<date type="published" when="2023-01-02">January 2, 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Monetdb/x100: Hyperpipelining query execution</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">A</forename><surname>Boncz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zukowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Nes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cidr</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="225" to="237" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Pegasus, a workflow management system for science automation</title>
		<author>
			<persName><forename type="first">E</forename><surname>Deelman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Vahi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Juve</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Rynge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Callaghan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Maechling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Mayani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">F</forename><surname>Da Silva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Livny</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Future Generation Computer Systems</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="page" from="17" to="35" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Scientific workflow management and the kepler system</title>
		<author>
			<persName><forename type="first">B</forename><surname>LudÃ¤scher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Altintas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Berkley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Higgins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Jaeger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">A</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Concurrency and computation: Practice and experience</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1039" to="1065" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Taverna: lessons in creating a workflow environment for the life sciences</title>
		<author>
			<persName><forename type="first">T</forename><surname>Oinn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Greenwood</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Addis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">N</forename><surname>Alpdemir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ferris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Glover</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Goble</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Goderis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Hull</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Marvin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Concurrency and computation: Practice and experience</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1067" to="1100" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Managing large-scale workflow execution from resource provisioning to provenance tracking: The cybershake example</title>
		<author>
			<persName><forename type="first">E</forename><surname>Deelman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Callaghan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Field</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Francoeur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">H</forename><surname>Jordan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Kesselman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Maechling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Second IEEE International Conference on e-Science and Grid Computing (e-Science&apos;06)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2006">2006. 2006</date>
			<biblScope unit="page" from="14" to="14" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Towards a provenance collection framework for internet of things devices</title>
		<author>
			<persName><forename type="first">E</forename><surname>Nwafor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Campbell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Bloom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 IEEE SmartWorld, Ubiquitous Intelligence &amp; Computing, Advanced &amp; Trusted Computed, Scalable Computing &amp; Communications, Cloud &amp; Big Data Computing, Internet of People and Smart City Innovation</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Genoma: Distributed provenance as a service for iot-based systems</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">C</forename><surname>Narendra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Shukla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Nayak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Jagadish</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Kalkur</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2019 IEEE 5th World Forum on Internet of Things (WF-IoT)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="755" to="760" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
