<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Comparing Automated Methods to Detect Explicit Content in Song Lyrics</title>
				<funder ref="#_bJNhHHS">
					<orgName type="full">Agence Nationale de la Recherche</orgName>
					<orgName type="abbreviated">ANR</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Michael</forename><surname>Fell</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Université Côte d&apos;Azur</orgName>
								<orgName type="institution" key="instit2">CNRS</orgName>
								<orgName type="institution" key="instit3">Inria</orgName>
								<address>
									<region>I3S</region>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Elena</forename><surname>Cabrio</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Université Côte d&apos;Azur</orgName>
								<orgName type="institution" key="instit2">CNRS</orgName>
								<orgName type="institution" key="instit3">Inria</orgName>
								<address>
									<region>I3S</region>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Michele</forename><surname>Corazza</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Université Côte d&apos;Azur</orgName>
								<orgName type="institution" key="instit2">CNRS</orgName>
								<orgName type="institution" key="instit3">Inria</orgName>
								<address>
									<region>I3S</region>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Fabien</forename><surname>Gandon</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Université Côte d&apos;Azur</orgName>
								<orgName type="institution" key="instit2">CNRS</orgName>
								<orgName type="institution" key="instit3">Inria</orgName>
								<address>
									<region>I3S</region>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Comparing Automated Methods to Detect Explicit Content in Song Lyrics</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">DBB09F68C28E675E4E771FE0C12D5F9E</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-04-12T14:46+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The Parental Advisory Label (PAL) is a warning label that is placed on audio recordings in recognition of profanity or inappropriate references, with the intention of alerting parents of material potentially unsuitable for children. Since 2015, digital providers -such as iTunes, Spotify, Amazon Music and Deezer -also follow PAL guidelines and tag such tracks as "explicit". Nowadays, such labelling is carried out mainly manually on voluntary basis, with the drawbacks of being time consuming and therefore costly, error prone and partly a subjective task. In this paper, we compare automated methods ranging from dictionary-based lookup to state-of-the-art deep neural networks to automatically detect explicit contents in English lyrics. We show that more complex models perform only slightly better on this task, and relying on a qualitative analysis of the data, we discuss the inherent hardness and subjectivity of the task.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>All content is not always appropriate for all ages and music is no exception. Content industries have been actively searching for means to help adults determine what is and is not appropriate for children. In USA, in 1985, the Recording Industry Association of America (RIAA) introduced the Parental Advisory label (PAL) in order to alert parents of content unsuitable for children because of profanity or inappropriate references<ref type="foot" target="#foot_0">1</ref> . PAL is "a notice to consumers that recordings identified by this mark may contain strong language or depictions of violence, sex or substance abuse"<ref type="foot" target="#foot_1">2</ref> and that parental discretion is advised. In UK, the British Phonographic Industry (BPI) adds to this list "racist, homophobic, misogynistic or other discriminatory language or behavior; or dangerous or criminal behavior"<ref type="foot" target="#foot_2">3</ref> .</p><p>In the case of a song, the explicit logo is applied when the lyrics or content of a song matches one of these criteria, raising the problem of detecting and labelling explicit songs in a scalable way.</p><p>Within the Natural Language Processing (NLP) community, there have been several efforts to deal with the problem of online abusive language detection, since the computational analysis of language can be used to quickly identify offenses and ease the removal of abusive messages. Several workshops <ref type="bibr" target="#b11">(Park and Fung, 2017;</ref><ref type="bibr" target="#b6">Fišer et al., 2018)</ref> and evaluation campaigns <ref type="bibr" target="#b5">(Fersini et al., 2018;</ref><ref type="bibr" target="#b2">Bosco et al., 2018;</ref><ref type="bibr" target="#b15">Wiegand et al., 2018)</ref> have been recently organized to discuss existing approaches to abusive language detection, propose shared tasks and foster the development of benchmarks for system evaluation. These have led to the creation of a number of datasets for abusive language detection in different languages, that have been shared within the NLP research community. The SemEval 2019 tasks <ref type="bibr">HatEval (Basile et al., 2019)</ref> and OffensEval <ref type="bibr" target="#b16">(Zampieri et al., 2019)</ref> have aimed at the multilingual detection of hate speech against women or immigrants and the categorization of hate speech, respectively.</p><p>In this direction, and given the similarity with the abusive language detection task, this paper addresses the problem of explicit content detection in song lyrics as a binary classification task: a song can be labelled either as explicit or clean (=not explicit). To this end, we first compare a range of classification methods for the task of explicit lyrics detection, from dictionary lookup to deep neural networks. We then attempt the comparison to the available related works and shed light on the inherent hardness and subjectivity of the task at hand.</p><p>The paper is organized as follows: in Section 2 we survey the state of the art in explicit lyrics detection. In Sections 3 and 4 we introduce the classification methods we apply, and the comparative experimentation. Conclusions end the paper.</p><p>NOTE: This paper contains examples of language which may be offensive to some readers. They do not represent the views of the authors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Only a few works on the problem of explicit lyrics detection exist. <ref type="bibr" target="#b1">(Bergelid, 2018)</ref> consider a dataset of English lyrics (see Table <ref type="table" target="#tab_0">1</ref>, B18) to which they apply classical machine learning algorithms such as Support Vector Machine (SVM) and Random Forest (RF). As features they extract either (i) tfidf weighted bag-of-word (BOW) representations of each song text or (ii) represent the lyrics with paragraph vectors <ref type="bibr" target="#b8">(Le and Mikolov, 2014)</ref>. The explicit labels are obtained from Soundtrack Your Brand<ref type="foot" target="#foot_3">4</ref> . They find the RF with tf-idf BOW to perform best, especially in combination with a random undersampling strategy to the highly imbalanced dataset. They also experiment with adding lyrics metadata to the feature set, such as the artist name, the release year, the music energy level, and the valence/positiveness of a song. This results in marginal improvements for some of their models. <ref type="bibr" target="#b3">(Chin et al., 2018)</ref> apply explicit lyrics detection to Korean song texts. They also use tf-idf weighted BOW as lyrics representation and aggregate multiple decision trees via boosting and bagging to classify the lyrics for explicit content. On their corpus (see Figure <ref type="figure">1</ref>, C18) they report 78% F 1 using the bagging method. Note, that bagging with decision trees is similar to the Random Forest method used by <ref type="bibr" target="#b1">(Bergelid, 2018)</ref>. Interestingly, they also report a baseline for dictionary lookup, i.e. given a profanity dictionary the song text is classified as explicit if and only if one of its words occurs in the profanity dictionary. With such a baseline they obtain 61% F 1 .</p><p>More recently, <ref type="bibr" target="#b7">(Kim and Mun, 2019)</ref> proposed a method to create explicit words dictionaries automatically by weighting a vocabulary according to all words' frequencies in the explicit class vs. the clean class, accordingly. For instance the word "fuck" is typical for explicit lyrics and atypical for clean lyrics. They compare different methods to generate such a lexicon. The achieved performances using solely dictionary lookup range from 49% F 1 for a man-made dictionary to 75.6% F 1 when using relative class frequencies. Note, that the latter performance is achieved with a dictionary of only 25 words. They work with a corpus of Korean lyrics (see Figure <ref type="figure">1,</ref><ref type="figure">K19</ref>). Unlike previous work, they apply a recursive neural network, resulting in 76.6% F 1 , slightly higher than the simple dictionary lookup. They find performance to increase to 78.1% when combining the vector representation of the RNN with a one-hot vector indicating for each profane word from the dictionary if the lyric contains it. They argue to use the RNN to find such cases where the expliciteness arises from the context and not from a dictionary check. However, no examples of finding this phenomenon are presented.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Methods for Explicit Lyrics Detection</head><p>In this work, we compare a range of classification methods for the task of explicit lyrics detection. Common to all methods is that they classify a full song into one of two mutually exclusive classesexplicit or clean (=not explicit). This means, the decision if a song text is explicit is taken globally. We assess the performance of different classification methods ranging from simple dictionary lookup / lexicon checking to general purpose deep learning language understanding models. We try to identify contextual effects by applying a method that outputs the "importance" for each word (see Section 3.4).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Dictionary-Based Methods</head><p>The most straightforward way to implement an automated explicit content detection method, is checking against a dictionary of explicit words. The dictionary can be man-made or automatically created from example explicit and clean lyrics. Then, a classifier uses this dictionary to predict the class of an unseen song text.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.1">Dictionary Creation</head><p>It is possible to use handcrafted dictionaries such as Noswearing<ref type="foot" target="#foot_4">5</ref> . Performance using an automatically created lexicon has previously been shown <ref type="bibr" target="#b7">(Kim and Mun, 2019)</ref> to improve over the manually created dictionary. We therefore consider only the case of the machine-made dictionary in this work. We generate a dictionary of words that are indicative of explicit lyrics. We define the importance I of a word w for explicit lyrics by the frequency f (w, ex) of w in explicit lyrics compared to its frequency f (w, cl) in clean lyrics:</p><formula xml:id="formula_0">I(w) = f (w, ex)/f (w, cl)</formula><p>We filter out unique and too common words and restrict the number of terms to 1,000 to avoid overreliance on terms that are very corpus specific. The dictionary D n of the n words most important for explicit lyrics, is now straightforwardly defined as containing the n words with the highest I score.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.2">Dictionary Lookup</head><p>Given a dictionary D n , this method simply checks if a song text S contains any of the explicit terms defined in D n . Then, S is classified as explicit iff it contains at least one explicit term from D n .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.3">Dictionary Regression</head><p>This method uses BOW made from D n as the feature set of a classifier. We used a logistic regression, but RF or SVM have been used alike in <ref type="bibr" target="#b1">(Bergelid, 2018)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Tf-idf BOW Regression</head><p>Similar to the Dictionary Regression, but the BOW contains the whole vocabulary of a training sample instead of only the explicit terms. The word features are weighted with the well-known tf-idf weighting scheme.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Transformer Language Model</head><p>Recently, approaches based on self-attention <ref type="bibr" target="#b13">(Vaswani et al., 2017)</ref> have been proposed and have proven effective for natural language understanding tasks. These models are structured as an encoder-decoder, and they are trained on unsupervised tasks (such as masked language modelling) in order to learn dense representations of sentences or documents. These models differ from more traditional recurrent neural networks in different aspects. In particular, while recurrent models can process sequences (in NLP, typically word embeddings) in order, transformers use a joint model of the right and left context of each word in order to encode an entire sequence or document. Additionally, transformers are typically less computationally expensive than recurrent models, especially when trained on a GPU accelerator.</p><p>One of the most successful transformer-based models proposed in the last few years is BERT <ref type="bibr" target="#b4">(Devlin et al., 2018)</ref>. This model is composed of multiple transformers connected by residual connections. Pre-trained models are provided by the authors, and they are used in our work to perform explicit language detection in lyrics, without retraining the full model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Textual Deconvolution Saliency</head><p>We use the Textual Deconvolution Saliency (TDS) model of <ref type="bibr" target="#b12">(Vanni et al., 2018)</ref>, which is a Convolutional Neural Network (CNN) for text classification. It is a simple model containing an embedding layer for word representations, a convolutional layer with max pooling and two fully connected layers. The interesting part about this model is that they manage to reverse the convolution. Given the learned feature map (the output of the convolution before max pooling) of the CNN, they upsample it to obtain a 3-dimensional sample with dimensions (#words, embedding size, #filters). The TDS for each word is now defined as the sum along the embedding axes of the output of the deconvolution. The TDS represents the importance of each word of the input with respect to the learned feature maps. We use this model with the goal to find local explanations for the global decision of the classification as explicit or clean. Such explanations can arise from contexts or phrases that the model assigns a high importance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experimental Setting and Evaluation</head><p>We compare the different methods as introduced in the previous section to the task of explicit lyrics detection. We attempt a comparison to the related work as well, although due to different datasets comparing the reported scores directly is problematic. We finally analyze the classification qualitatively with examples, and demonstrate the intrinsic hardness and subjectivity of the explicit lyrics detection task. Abbreviations used: to refer to related works in Table <ref type="table" target="#tab_0">1</ref> and 3, we use the following abbreviations. B18 stands for <ref type="bibr" target="#b1">(Bergelid, 2018)</ref>, C18 is <ref type="bibr" target="#b3">(Chin et al., 2018)</ref>, K19 means <ref type="bibr" target="#b7">(Kim and Mun, 2019)</ref>, while Ours is this work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Dataset</head><p>The WASABI database <ref type="bibr" target="#b9">(Meseguer-Brocal et al., 2017)</ref>  such as explicit, unknown, no advice available, or clean (=not explicit). These labels are provided by the music streaming service Deezer<ref type="foot" target="#foot_5">6</ref> . We selected a subset of English song texts from the corpus which are tagged as either explicit or clean. We filtered out duplicate lyrics and such that contain less than 10 tokens. Finally, our dataset (WAS) comprises of 179k lyrics, with a ratio of explicit lyrics of 9.9%. The details and comparison with related works datasets are depicted in Table <ref type="table" target="#tab_0">1</ref>.</p><p>For training any of the models described in the previous section, we once randomly split the data into training-development-test sets with the common 60%-20%-20% ratio. We tuned the hyperparameters of the different classification algorithms on the development set to then test with the best performing parameters on the test set. As evaluation metrics we use precision (P), recall (R), and f-score (F 1 ). Unless stated otherwise, the scores are macro-averaged over the two possible classes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Hyperparameters</head><p>For the dictionary-based methods, we found the ideal dictionary size to be 32 words for the lookup and 128 words for the regression. The Tf-idf BOW regression performed best when the full vocabulary of unigrams and bigrams was used. We used the sklearn implementation of logistic regression with the class weighting scheme 'balanced' to account for the class imbalance in the dataset. We used TDS with max sequence length 512 and dropout probability 50%. As is the default with TDS, corpus-specific word vectors were trained using Word2Vec <ref type="bibr" target="#b10">(Mikolov et al., 2013)</ref> with dimensionality 128. The BERT model comes pretrained and no further pre-training was performed. We used the smaller of the two published models. BERT then was finetuned to our task using max sequence length 256 and batch size 16, otherwise default parameters for text classification task learning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Results</head><p>Overall, the results of the different classification methods we tried are all close to each other. The simple dictionary lookup with 32 words performs comparably to the deep neural network with 110M parameters (BERT base model). As baseline, we include the majority class classifier that always predicts the clean class. Furthermore, all related works show similar tendencies of performance on their respective datasets. The results of all the different methods we applied are depicted in Table <ref type="table" target="#tab_1">2</ref> and described in the following.</p><p>The majority class classifier delivers a performance of 47.4% F 1 , which is the only outlier in the sense that this is far below any other model. The dictionary lookup with a vocabulary of the 32 most indicative explicit words obtains a balanced performance as precision and recall are close to each other, the overall performance is 77.3% F 1 . The dictionary regression performs somewhat better in terms of f-score (78.5% F 1 ), achieving this with the highest overall recall of 81.5%, but it has lower precision. The tf-idf BOW regression performs very similarly to the dictionary regression. This proves that a limited number of words influences the overall performance of the models, and that they do not need to consider the whole vocabulary, just the most offensive words. The increased vocabulary of 929k unigrams and bigrams is gigantic compared to the explicit words dictionary (32 words). As most of these n-grams may be noise to the classifier, this could explain the slight decrease in performance over the dictionary regression. Finally, the neural-network-based methods behave a bit differently: the BERT language model is clearly better in precision (84.4%) over all other models -the second best is TDS with 81.2%. However, BERT performs the worst in recall with only 73.7%. The overall performance of BERT is average with 77.7% F 1 . Finally, TDS performs best in terms of 79.6% F 1 . We tested if TDS outperforming BERT was due to TDS using domainspecific word vectors trained on our corpus (BERT is trained on books and Wikipedia). This was not the case as TDS performed almost identically, when using generic word vectors (GloVe, 200d): 80.4% P, 78.7% R, 79.5% F 1 .</p><p>A closer look at the classification performance shows that the F 1 scores for the minority class (explicit lyrics) is highest with TDS (63%) and lowest with the dictionary lookup (58.9% class (clean lyrics) on the other hand is best detected by BERT (96.3% F 1 ) and worst with the tf-idf BOW (95.1% F 1 ). We attempt a comparison of the different approaches used in the different related works as well as ours. While the scores achieved (see Table <ref type="table">3</ref>) are not strictly comparable, we can see clear tendencies. According to K19, a man-made dictionary is inferior to an automatically generated one. This is supported by the man-made lexicon in C18 performing subpar to their tf-idf BOW. An appropriate lexicon of explicit terms, on the other hand, can compete with a tf-idf BOW model, as we showed with both the dictionary lookup and the regression performance. This is further supported by the generated dictionary of K19 which competes with the deep HAN model. Optimizations to the standard tf-idf BOW models are marked with the + sign. Restricting the POS tags to more likely ones found in explicit terms (C18) improves performance slighly. Using random undersampling to fight the imbalanced class problem (B18) increases performance drastically, however makes the problem somewhat different from the imbalanced problem. The final takeaway is that deep models do not necessarily outperform shallow models. Neither HAN, TDS, nor BERT deliver much higher scores than the dictionary-based or the BOW method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Qualitative Analysis</head><p>In this section we analyze examples of explicit content lyrics and point to the inherent hardness and subjectivity in classifying and even labelling such data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.1">Explicitness in Context?</head><p>The highest difference in model performance we measured between the deep TDS model (79.6% F 1 ) and the dictionary lookup (77.3% F 1 ). We analyzed why the TDS method performed better than the dictionary lookup by inspecting those examples that (i) were explicit, (ii) were tagged as clean by the dictionary lookup, and (iii) were detected as explicit by TDS with high confidence. <ref type="foot" target="#foot_6">7</ref>From the 13 examples analyzed, we found three main phenomena: (1) Four texts contained explicit terms that were not contained in the dictionary of explicit terms. Words such as f**kin', motherf**kers were too rare to be included in the generated lexicon and other words like fucking, cunt, cum, shit were not uniquely contained in explicit lyrics. The reason why this is the case can be traced back to problems in the annotations or the fact that these words are relatively frequently used in lyrics. (2) Five texts whose explicitness arises in context rather than on a word level. Examples with violent context found were "organization with horns of satan performs the ancient rituals" or "bombin on mc's, crushin crews with ease". There were also instances of sexual content such as "give it to him down in the parking lot in the backseat, in the backseat of the car". Note that the words {give, it, to, him} in isolation do not belong to an explicit terms list and the sexuality arises from the context. Similarly in "(turn the lights on) so i can see that ass work". Also here, putting "ass" in an explicit terms dictionary is tempting but may not be ideal, as its meaning is not necessarily explicit. (3) Four texts appeared to have been mislabelled since no explicitness could be found. We found for three of them that the album the song is contained in is tagged as explicit. In cases as these, inheriting the label from the album is wrong, but it seems this is exactly what had happened here. In one Raggae lyric, in particular, we found no explicit content, so we suspect the song was mislabelled.</p><p>Since we found some annotation to be problematic, we will discuss difficulties that arise from annotating explicitness in lyrics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.2">How Hard is this Task?</head><p>As stated in the introduction, the explicit label is voluntary and we will argue that it is also somewhat subjective in its nature. There are lyrics which are not tagged as explicit although they have profanity in them. Consider for example the song Bitch by Meredith Brooks. While it already contains profanity in the title, it does not carry the explicit label and one can argue that in the context of the song, the term "bitch" is used as a contrastive term and to raise attention to the struggle the songwriter sees in her life, torn between potentially conflicting expectations of society ("I'm a little bit of everything -All rolled into one -I'm a bitch, I'm a lover -I'm a child, I'm a mother -I'm a sinner, I'm a saint -I do not feel ashamed").</p><p>Another example is Check Your Head by Buckcherry where it says "Ooh and you still bitch about your payments" where "bitch" is used as a verb and one can argue that the acceptance in this verb form is higher than in the noun form. A similar case where the part of speech influences the perceived level of profanity is Hail Hail Rock 'n' Roll by Discipline. It contains the line "the band starts to play loud as fuck".</p><p>We encounter a different kind of problem when dealing with substance abuse or other drug-related content. It is evident that the legal status of the substances mentioned plays a major role in how such content is labelled. This is further complicated by the fact that legislation about substances can vary wildly between different countries. The labels applied to this content are not culture-invariant, and furthermore changes in the societal view can lead to labels that are not relevant anymore. This, like other examples, shows why the labels applied to lyrics are subject to change in different cultures and time periods.</p><p>Another aspect that is very sensitive to time pe-riods and cultures comes from words themselves: an inoffensive word can become offensive in slang or common language. One such example can be found in Johnny Cash's The Christmas Guest: "When the cock was crowing the night away -The Lord appeared in a dream to me". Here, cock means male chicken, as opposed to the offensive meaning that is now arguably more common. We finally want to raise attention to the problem of genre confounding. We found that the genre Hip Hop contributed by far the most to all explicit lyrics -33% of all Hip Hop lyrics. Since only about 5% of the whole corpus are tagged as Hip Hop, this genre is highly overrepresented. This raises the question in how far our task is confounded with genre classification. When inspecting the explicit terms dictionaries we have created, we clearly see that genre bias reflected. The dictionary of 32 terms that we used for the dictionary lookup method consists approximately half of terms that are quite specific to the Rap genre, such as glock, gat, clip (gun-related), thug, beef, gangsta, pimp, blunt (crime and drugs). Finally, the terms holla, homie, and rapper are arguably no causes for explicit lyrics, but highly correlated with explicit content lyrics. Biasing an explicit lyrics detection model away from genres is an interesting future direction of work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>Classifying song lyrics as explicit or clean is an inherently hard task to accomplish since what is considered offensive strongly depends on cultural aspects that can change over time. We showed that shallow models solely based on a dictionary of profane words achieve a performance comparable to deep neural networks. We argued that even the hand-labelling is highly subjective, making it problematic to automatically detect if a song text should be tagged as explicit or clean.</p><p>We propose as a possible simplification and objectification to study the local detection of explicit content. If we present an authority a report on found trigger words, found contextual sexual content, and alike, they can come to their own subjective conclusion about the final label of the text.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>contains song-wise labels for explicit lyrics, Overview of our dataset WAS (# songs) and comparison to the related works.</figDesc><table><row><cell>Work</cell><cell>total</cell><cell cols="3">explicit ratio language</cell></row><row><cell>B18</cell><cell>25,441</cell><cell cols="3">3,310 13.0% English</cell></row><row><cell>C18</cell><cell>27,695</cell><cell>1,024</cell><cell>3.7%</cell><cell>Korean</cell></row><row><cell>K19</cell><cell>70,077</cell><cell cols="3">7,468 10.7% Korean</cell></row><row><cell cols="4">WAS 179,391 17,808 9.9%</cell><cell>English</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>). The majority Performances of our different models on the WAS dataset. Values in percent.</figDesc><table><row><cell>Model</cell><cell></cell><cell>P</cell><cell>R</cell><cell>F 1</cell></row><row><cell cols="2">Majority Class</cell><cell cols="3">45.0 50.0 47.4</cell></row><row><cell cols="2">Dictionary Lookup</cell><cell cols="3">78.3 76.4 77.3</cell></row><row><cell cols="2">Dictionary Regression</cell><cell cols="3">76.2 81.5 78.5</cell></row><row><cell cols="5">Tf-idf BOW Regression 75.6 81.2 78.0</cell></row><row><cell cols="2">TDS Deconvolution</cell><cell cols="3">81.2 78.2 79.6</cell></row><row><cell cols="5">BERT Language Model 84.4 73.7 77.7</cell></row><row><cell cols="2">Work Model</cell><cell></cell><cell>F 1</cell></row><row><cell cols="3">Ours Dictionary Lookup</cell><cell cols="2">77.3</cell></row><row><cell cols="3">Ours Dictionary Regression</cell><cell cols="2">78.5</cell></row><row><cell>C18</cell><cell cols="2">Man-made Dictionary</cell><cell cols="2">61.0</cell></row><row><cell>K19</cell><cell cols="2">Man-made Dictionary</cell><cell cols="2">49.0</cell></row><row><cell>K19</cell><cell cols="2">Dictionary Lookup</cell><cell cols="2">75.6</cell></row><row><cell cols="5">Ours Tf-idf BOW Regression 78.0</cell></row><row><cell>C18</cell><cell>Tf-idf BOW</cell><cell></cell><cell cols="2">78.0</cell></row><row><cell>C18</cell><cell>Tf-idf BOW+</cell><cell></cell><cell cols="2">80.0</cell></row><row><cell>B18</cell><cell>Tf-idf BOW</cell><cell></cell><cell cols="2">67.5</cell></row><row><cell>B18</cell><cell>Tf-idf BOW+</cell><cell></cell><cell cols="2">82.6</cell></row><row><cell cols="3">Ours TDS Deconvolution</cell><cell cols="2">79.6</cell></row><row><cell cols="5">Ours BERT Language Model 77.7</cell></row><row><cell>K19</cell><cell>HAN</cell><cell></cell><cell cols="2">76.7</cell></row><row><cell>K19</cell><cell cols="2">HAN + Dictionary</cell><cell cols="2">78.1</cell></row><row><cell cols="5">Table 3: Performances of dictionary-based methods</cell></row><row><cell cols="5">(top), tf-idf BOW models (middle) and deep mod-</cell></row><row><cell cols="5">els (below). Note that different works use different</cell></row><row><cell cols="5">datasets. Ours always uses the WAS dataset. Values</cell></row><row><cell>in percent.</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>Parental Advisory https://en.wikipedia.org/ wiki/Parental_Advisory</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>RIAA PALhttps://www.riaa.com/ resources-learning/pal-standards/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2"><p>BPI Parent Advisory https://www.bpi.co.uk/ media/1047/parental-advisory-guidelines. pdf</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3"><p>https://www.soundtrackyourbrand.com</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_4"><p>https://www.noswearing.com/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_5"><p>https://www.deezer.com</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_6"><p>The last layer of TDS outputs probabilities for the input text being explicit or clean. We looked at examples where the explicit class was predicted with at least</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_7"><p>80% probability.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgement</head><p>This work is partly funded by the <rs type="funder">French Research National Agency (ANR)</rs> under the <rs type="projectName">WASABI</rs> project (contract <rs type="grantNumber">ANR-16-CE23-0017-01</rs>).</p></div>
			</div>
			<listOrg type="funding">
				<org type="funded-project" xml:id="_bJNhHHS">
					<idno type="grant-number">ANR-16-CE23-0017-01</idno>
					<orgName type="project" subtype="full">WASABI</orgName>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Semeval-2019 task 5: Multilingual detection of hate speech against immigrants and women in twitter</title>
		<author>
			<persName><forename type="first">Cristina</forename><surname>Valerio Basile</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elisabetta</forename><surname>Bosco</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Debora</forename><surname>Fersini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Viviana</forename><surname>Nozza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Francisco</forename><surname>Patti</surname></persName>
		</author>
		<author>
			<persName><surname>Manuel Rangel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paolo</forename><surname>Pardo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Manuela</forename><surname>Rosso</surname></persName>
		</author>
		<author>
			<persName><surname>Sanguinetti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th International Workshop on Semantic Evaluation</title>
		<meeting>the 13th International Workshop on Semantic Evaluation</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="54" to="63" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Classification of explicit music content using lyrics and music metadata</title>
		<author>
			<persName><forename type="first">Linn</forename><surname>Bergelid</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Overview of the EVALITA 2018 hate speech detection task</title>
		<author>
			<persName><forename type="first">Cristina</forename><surname>Bosco</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Felice</forename><surname>Dell'orletta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fabio</forename><surname>Poletto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Manuela</forename><surname>Sanguinetti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maurizio</forename><surname>Tesconi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Sixth Evaluation Campaign of Natural Language Processing and Speech Tools for Italian. Final Workshop (EVALITA 2018) co-located with the Fifth Italian Conference on Computational Linguistics (CLiC-it 2018)</title>
		<meeting>the Sixth Evaluation Campaign of Natural Language Processing and Speech Tools for Italian. Final Workshop (EVALITA 2018) co-located with the Fifth Italian Conference on Computational Linguistics (CLiC-it 2018)<address><addrLine>Turin, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Explicit content detection in music lyrics using machine learning</title>
		<author>
			<persName><forename type="first">Hyojin</forename><surname>Chin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jayong</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoonjong</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jinseop</forename><surname>Shin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mun Y</forename><surname>Yi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Big Data and Smart Computing (BigComp)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2018">2018. 2018</date>
			<biblScope unit="page" from="517" to="521" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Bert: Pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.04805</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Overview of the task on automatic misogyny identification at ibereval 2018</title>
		<author>
			<persName><forename type="first">Elisabetta</forename><surname>Fersini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paolo</forename><surname>Rosso</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maria</forename><surname>Anzovino</surname></persName>
		</author>
		<ptr target="CEUR-WS.org" />
	</analytic>
	<monogr>
		<title level="m">IberEval@SEPLN</title>
		<title level="s">CEUR Workshop Proceedings</title>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">2150</biblScope>
			<biblScope unit="page" from="214" to="228" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Proceedings of the 2nd workshop on abusive language online (alw2)</title>
		<author>
			<persName><forename type="first">Darja</forename><surname>Fišer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruihong</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vinodkumar</forename><surname>Prabhakaran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rob</forename><surname>Voigt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zeerak</forename><surname>Waseem</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jacqueline</forename><surname>Wernimont</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2nd Workshop on Abusive Language Online (ALW2)</title>
		<meeting>the 2nd Workshop on Abusive Language Online (ALW2)</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A hybrid modeling approach for an automated lyrics-rating system for adolescents</title>
		<author>
			<persName><forename type="first">Jayong</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yi Mun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Information Retrieval</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="779" to="786" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Distributed representations of sentences and documents</title>
		<author>
			<persName><forename type="first">Quoc</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on machine learning</title>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="1188" to="1196" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">WASABI: a Two Million Song Database Project with Audio and Cultural Metadata plus WebAudio enhanced Client Applications</title>
		<author>
			<persName><forename type="first">Gabriel</forename><surname>Meseguer-Brocal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Geoffroy</forename><surname>Peeters</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guillaume</forename><surname>Pellerin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michel</forename><surname>Buffa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elena</forename><surname>Cabrio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Catherine</forename><forename type="middle">Faron</forename><surname>Zucker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alain</forename><surname>Giboin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Isabelle</forename><surname>Mirbel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Romain</forename><surname>Hennequin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Manuel</forename><surname>Moussallam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Francesco</forename><surname>Piccoli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Fillon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Web Audio Conference 2017 -Collaborative Audio #WAC2017</title>
		<meeting><address><addrLine>London, United King</addrLine></address></meeting>
		<imprint>
			<publisher>Queen Mary University of London</publisher>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<author>
			<persName><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Greg</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeffrey</forename><surname>Dean</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1301.3781</idno>
		<title level="m">Efficient estimation of word representations in vector space</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">One-step and twostep classification for abusive language detection on twitter</title>
		<author>
			<persName><forename type="first">Ji</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Park</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Pascale</forename><surname>Fung</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/W17-3006</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First Workshop on Abusive Language Online</title>
		<meeting>the First Workshop on Abusive Language Online</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="41" to="45" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Textual deconvolution saliency (tds): a deep tool box for linguistic analysis</title>
		<author>
			<persName><forename type="first">Laurent</forename><surname>Vanni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mélanie</forename><surname>Ducoffe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carlos</forename><surname>Aguilar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Frederic</forename><surname>Precioso</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Damon</forename><surname>Mayaffre</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 56th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="548" to="557" />
		</imprint>
	</monogr>
	<note>Long Papers</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aidan</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ł Ukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Illia</forename><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">Advances in Neural Information Processing Systems</title>
		<editor>
			<persName><forename type="first">I</forename><surname>Guyon</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">U</forename><forename type="middle">V</forename><surname>Luxburg</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Bengio</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Wallach</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Fergus</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Vishwanathan</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Garnett</surname></persName>
		</editor>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="5998" to="6008" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Curran</forename><surname>Associates</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Inc</forename></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Overview of the germeval 2018 shared task on the identification of offensive language</title>
		<author>
			<persName><forename type="first">Michael</forename><surname>Wiegand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Melanie</forename><surname>Siegel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Josef</forename><surname>Ruppenhofer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of GermEval 2018, 14th Conference on Natural Language Processing</title>
		<meeting>GermEval 2018, 14th Conference on Natural Language Processing<address><addrLine>KONVENS</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Semeval-2019 task 6: Identifying and categorizing offensive language in social media (offenseval)</title>
		<author>
			<persName><forename type="first">Marcos</forename><surname>Zampieri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shervin</forename><surname>Malmasi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Preslav</forename><surname>Nakov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sara</forename><surname>Rosenthal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noura</forename><surname>Farra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ritesh</forename><surname>Kumar</surname></persName>
		</author>
		<idno>CoRR, abs/1903.08983</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
