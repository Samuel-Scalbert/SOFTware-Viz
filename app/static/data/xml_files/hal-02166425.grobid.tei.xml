<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Escaping the Curse of Dimensionality in Similarity Learning: Efficient Frank-Wolfe Algorithm and Generalization Bounds</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Kuan</forename><surname>Liu</surname></persName>
							<email>liukuan@google.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Google Inc</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Aur√©lien</forename><surname>Bellet</surname></persName>
							<email>aurelien.bellet@inria.fr</email>
							<affiliation key="aff1">
								<orgName type="institution">INRIA</orgName>
								<address>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="department">Information Sciences Institute</orgName>
								<orgName type="institution">University of Southern California</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Escaping the Curse of Dimensionality in Similarity Learning: Efficient Frank-Wolfe Algorithm and Generalization Bounds</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">C081B1B705033854BC91C29498D024CB</idno>
					<idno type="DOI">10.1016/j.neucom.2018.12.060</idno>
					<note type="submission">Preprint submitted to Neurocomputing January 6, 2019</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-04-12T14:53+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Metric learning</term>
					<term>Frank-Wolfe algorithm</term>
					<term>Generalization bounds</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Similarity and metric learning provides a principled approach to construct a task-specific similarity from weakly supervised data. However, these methods are subject to the curse of dimensionality: as the number of features grows large, poor generalization is to be expected and training becomes intractable due to high computational and memory costs. In this paper, we propose a similarity learning method that can efficiently deal with high-dimensional sparse data. This is achieved through a parameterization of similarity functions by convex combinations of sparse rank-one matrices, together with the use of a greedy approximate Frank-Wolfe algorithm which provides an efficient way to control the number of active features. We show that the convergence rate of the algorithm, as well as its time and memory complexity, are independent of the data dimension. We further provide a theoretical justification of our modeling choices through an analysis of the generalization error, which depends logarithmically on the sparsity of the solution rather than on the number of features. Our experiments on datasets with up to one million features demonstrate the ability of our approach to generalize well despite the high dimensionality as well as its superiority compared to several competing methods.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>High-dimensional and sparse data are commonly encountered in many applications of machine learning, such as computer vision, bioinformatics, text mining and behavioral targeting. To classify, cluster or rank data points, it is important to be able to compute semantically meaningful similarities between them. However, defining an appropriate similarity measure for a given task is often difficult as only a small and unknown subset of all features are actually relevant. For instance, in drug discovery studies, chemical compounds are typically represented by a large number of sparse features describing their 2D and 3D properties, and only a few of them play in role in determining whether the compound will bind to a particular target receptor <ref type="bibr" target="#b39">(Leach and Gillet, 2007)</ref>. In text classification and clustering, a document is often represented as a sparse bag of words, and only a small subset of the dictionary is generally useful to discriminate between documents about different topics. Another example is targeted advertising, where ads are selected based on fine-grained user history <ref type="bibr" target="#b15">(Chen et al., 2009)</ref>.</p><p>Similarity and metric learning <ref type="bibr">(Bellet et al., 2015)</ref> offers principled approaches to construct a task-specific similarity measure by learning it from weakly supervised data, and has been used in many application domains. The main theme in these methods is to learn the parameters of a similarity (or distance) function such that it agrees with task-specific similarity judgments (e.g., of the form "data point x should be more similar to y than to z"). To account for correlations between features, similarity and metric learning typically estimates a number of parameters which is quadratic in the data dimension d. When data are high-dimensional, these methods are thus particularly affected by the so-called "curse of dimensionality", which manifests itself at both the algorithmic and generalization levels. On the one hand, training the similarity quickly becomes infeasible due to a quadratic or cubic complexity in d. In fact, the O(d 2 ) parameters may not even fit in memory. On the other hand, putting aside the training phase, learning so many parameters would lead to severe overfitting and poor generalization performance (especially for sparse data where some features are rarely observed). Simple workarounds have been used to address this limitation, such as projecting the data into a low-dimensional space before learning the similarity (see e.g. <ref type="bibr" target="#b19">Davis et al., 2007;</ref><ref type="bibr" target="#b57">Weinberger and Saul, 2009;</ref><ref type="bibr" target="#b28">Guillaumin et al., 2009)</ref>. However, such heuristics do not provide satisfactory solutions: they often hurt the performance and make the resulting similarity function difficult to interpret.</p><p>In this paper, we propose a novel method to learn a bilinear similarity function S M (x, x ) = x T M x directly in the original high-dimensional space while escaping the curse of dimensionality. This is achieved by combining three ingredients: the sparsity of the data, the parameterization of M as a convex combination of rank-one matrices with a special sparsity structure, and an approximate Frank-Wolfe procedure <ref type="bibr" target="#b23">(Frank and Wolfe, 1956;</ref><ref type="bibr" target="#b33">Jaggi, 2013)</ref> to learn the similarity parameters. The resulting algorithm greedily incorporates one pair of features at a time into the learned similarity, providing an efficient way to filter out irrelevant features as well as to guard against overfitting through early stopping. Remarkably, the convergence rate of the algorithm as well as its time and memory complexity are all independent of the dimension d. The resulting similarity functions are extremely sparse, which makes them fast to compute and easier to interpret.</p><p>We provide strong theoretical and empirical evidence of the usefulness of our approach. On the theory part, we perform a generalization analysis of the solution returned by our algorithm after a given number of iterations. We derive excess risk bounds with respect to the minimizer of the expected risk which confirm that our modeling choices as well as our Frank-Wolfe algorithm and early stopping policy provide effective ways to avoid overfitting in high dimensions. A distinctive feature of the generalization bound we obtain is the adaptivity of its model class complexity term to the actual sparsity of the approximate solution found by our algorithm, again removing the dependence on the dimension d. We also evaluate the proposed approach on several synthetic and real datasets with up to one million features, some of which have a large proportion of irrelevant features. To the best of our knowledge, it is the first time that a full similarity or distance metric is learned directly on such high-dimensional datasets without first reducing dimensionality. Our experiments show that our approach is able to generalize well despite the high dimensionality, and even to recover the ground truth similarity function when the training similarity judgments are sufficiently informative. Furthermore, our approach clearly outperforms both a diagonal similarity learned in the original space and a full similarity learned in a reduced space (after PCA or random projections). Finally, we show that our similarity functions can be extremely sparse (in the order of 0.0001% of nonzero entries), thereby drastically reducing the dimension while also providing an opportunity to analyze the importance of the original features and their pairwise interactions for the problem at hand.</p><p>The present work extends a previously published conference paper <ref type="bibr">(Liu et al., 2015a)</ref> by providing additional technical and experimental results. Firstly, we present a novel generalization analysis which further backs up our approach from a statistical learning point of view. Secondly, we conduct experiments on high-dimensional synthetic data showing that our approach generalizes well as the dimensionality increases and can even accurately recover the ground truth notion of similarity. Finally, we extend the discussion of the related work and provide additional details on algorithms and proofs.</p><p>The paper is organized as follows. Section 2 introduces some background and related work on similarity learning and Frank-Wolfe algorithms. Section 3 describes our problem formulation, the proposed algorithm and its analysis. Generalization bounds are established in Section 4. Finally, Section 5 describes our experimental results, and we conclude in Section 6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Background and Related Work</head><p>In this section, we review some background and related work in metric and similarity learning (Section 2.1) and the Frank-Wolfe algorithm (Section 2.2).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Metric and Similarity Learning</head><p>Metric and similarity learning has attracted a lot of interest over the past ten years. The great majority of work has focused on learning either a Mahalanobis distance d M (x, x ) = (x -x ) T M (x -x ) where M is a symmetric positive semi-definite (PSD) matrix, or a bilinear similarity S M (x, x ) = x T M x where M is often taken to be an arbitrary d √ó d matrix. A comprehensive survey of existing approaches can be found in <ref type="bibr" target="#b5">(Bellet et al., 2013)</ref>. We focus below on the two topics most relevant to our work: (i) efficient algorithms for the high-dimensional setting, and (ii) the derivation of generalization guarantees for metric and similarity learning.</p><p>Metric learning in high dimensions. Both Mahalanobis distance metric learning and bilinear similarity learning require estimating O(d 2 ) parameters, which is undesirable in the high-dimensional setting for the reasons mentioned earlier.</p><p>In practice, it is thus customary to resort to dimensionality reduction (such as PCA, SVD or random projections) to preprocess the data when it has more than a few hundred dimensions (see e.g., <ref type="bibr" target="#b19">Davis et al., 2007;</ref><ref type="bibr" target="#b57">Weinberger and Saul, 2009;</ref><ref type="bibr" target="#b28">Guillaumin et al., 2009;</ref><ref type="bibr" target="#b60">Ying and Li, 2012;</ref><ref type="bibr" target="#b56">Wang et al., 2012;</ref><ref type="bibr" target="#b41">Lim et al., 2013;</ref><ref type="bibr" target="#b47">Qian et al., 2014;</ref><ref type="bibr">Liu et al., 2015b;</ref><ref type="bibr" target="#b58">Yao et al., 2018)</ref>. Although this strategy can be justified formally in some cases <ref type="bibr">(Liu et al., 2015b;</ref><ref type="bibr" target="#b46">Qian et al., 2015)</ref>, the projection may intertwine useful features and irrelevant/noisy ones and thus hurt the performance of the resulting similarity function. It also makes it hard to interpret and use for data exploration, preventing the discovery of knowledge that can be valuable to domain experts.</p><p>There have been very few satisfactory solutions to this essential limitation. The most drastic strategy is to learn a diagonal matrix M <ref type="bibr" target="#b49">(Schultz and Joachims, 2003;</ref><ref type="bibr" target="#b25">Gao et al., 2014)</ref>, which is very restrictive as it amounts to a simple weighting of the features. Instead, some approaches assume an explicit low-rank decomposition M = L T L and learn L ‚àà R r√ód in order to reduce the number of parameters <ref type="bibr" target="#b26">(Goldberger et al., 2004;</ref><ref type="bibr" target="#b57">Weinberger and Saul, 2009;</ref><ref type="bibr" target="#b36">Kedem et al., 2012)</ref>. This results in nonconvex formulations with many local optima <ref type="bibr" target="#b37">(Kulis, 2012)</ref>, and requires to tune r carefully. Moreover, the training complexity still depends on d and can thus remain quite large. Another direction is to learn M as a combination of rank-one matrices. In particular, <ref type="bibr" target="#b53">Shi et al. (2014)</ref> generate a set of rank-one matrices from the training data and then learn a metric as a sparse combination. However, as the dimension increases, a larger dictionary is needed and can be expensive to generate. Some other work has studied sparse and/or low-rank regularization to reduce overfitting in high dimensions <ref type="bibr" target="#b48">(Rosales and Fung, 2006;</ref><ref type="bibr" target="#b45">Qi et al., 2009;</ref><ref type="bibr" target="#b59">Ying et al., 2009)</ref> but this does not in itself reduce the training complexity of the algorithm. <ref type="bibr" target="#b61">Zhang and Zhang (2017)</ref> proposed a stochastic gradient descent solver together with low-rank regularization in an attempt to keep the intermediate solutions lowrank. The complexity per iteration of their approach is linear in d but cubic in the rank of the current solution, which quickly becomes intractable unless the regularization is very strong.</p><p>Finally, some greedy algorithms for metric learning have been proposed in the literature to guarantee a tighter bound on the rank of intermediate solutions. <ref type="bibr" target="#b1">Atzmon et al. (2015)</ref> use a block coordinate descent algorithm to update the metric one feature at a time. <ref type="bibr" target="#b52">Shen et al. (2012)</ref> selects rank-one updates in a boosting manner, while DML-eig <ref type="bibr" target="#b60">(Ying and Li, 2012)</ref> and its extension DML-œÅ <ref type="bibr">(Cao et al., 2012b)</ref> rely on a greedy Frank-Wolfe algorithm to optimize over the set of PSD matrices with unit trace. However, these greedy methods still suffer from a computational cost of O(d<ref type="foot" target="#foot_0">2</ref> ) per iteration and are thus unsuitable for the high-dimensional setting we consider in this work. In contrast, we will propose an algorithm which is linear in the number of nonzero features and can thus be efficiently applied to high-dimensional sparse data.</p><p>Generalization bounds for metric learning. The derivation of generalization guarantees for metric and similarity learning has been investigated in the supervised setting, where the metric or similarity is learned from a labeled dataset of n points by (regularized) empirical risk minimization. For a given family of loss functions, the results generally bound the maximal deviation between the expected risk (where the expectation is taken over the unknown data distribution) and the empirical risk of the learned metric.  <ref type="bibr">Bellet and Habrard (2015)</ref> obtain bounds which hold also for sparsity-inducing regularizers but with a covering number term that can be exponential in the dimension. <ref type="bibr" target="#b7">Bian and Tao (2011)</ref> rely on assumptions on the data distribution and do not show an explicit dependence on the dimension. <ref type="bibr">Cao et al. (2012a)</ref> derive bounds based on Rademacher complexity and maximal deviation results for U -statistics <ref type="bibr" target="#b18">(Cl√©men√ßon et al., 2008)</ref>. Depending on the regularization used, the dependence on the dimension d ranges from logarithmic to linear. <ref type="bibr" target="#b55">Verma and Branson (2015)</ref> show that the ‚àö d factor of <ref type="bibr" target="#b35">Jin et al. (2009)</ref> is in fact unavoidable in the worst case without some form of regularization (or restriction of the hypothesis class). They derive bounds which do not depend on the dimension d but on the Frobenius norm of the optimal parameter M . Note however that their analysis assumes that the metrics are learned from a set of i.i.d. pairs or triplets, which is rarely seen in practice.</p><p>In all the above work, generalization in metric learning is studied independently of the algorithm used to solve the empirical risk minimization problem, and none of the bounds are adaptive to the actual sparsity of the solution. In contrast, we will show that one can use early stopping in our algorithm to control the complexity of the hypothesis class so as to make the bounds independent of the dimension d, effectively balancing the empirical (optimization) error and the generalization error.</p><p>Algorithm 1 Standard Frank-Wolfe algorithm</p><formula xml:id="formula_0">Input: Initial point M (0) ‚àà D for k = 0, 1, 2, . . . do S (k) ‚Üê arg min S‚ààD S, ‚àáf (M (k) ) Œ≥ (k) ‚Üê 2 k+2 (or determined by line search) M (k+1) ‚Üê (1 -Œ≥ (k) )M (k) + Œ≥ (k) S (k) end for</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Frank-Wolfe Algorithms</head><p>The Frank-Wolfe (FW) algorithm was originally introduced by <ref type="bibr" target="#b23">Frank and Wolfe (1956)</ref> and further generalized by <ref type="bibr" target="#b16">Clarkson (2010)</ref> and <ref type="bibr" target="#b33">Jaggi (2013)</ref>. FW aims at solving constrained optimization problems of the following general form:</p><formula xml:id="formula_1">min M ‚ààD f (M ), (<label>1</label></formula><formula xml:id="formula_2">)</formula><p>where f is a convex and continuously differentiable function, and the feasible domain D is a convex and compact subset of some Hilbert space equipped with inner product ‚Ä¢, ‚Ä¢ .</p><p>Starting from a feasible initial point M (0) ‚àà D, the standard FW algorithm iterates over the following steps. First, it finds the feasible point S (k) ‚àà D which minimizes the linearization of f at the current point M (k) :</p><formula xml:id="formula_3">S (k) ‚àà arg min S‚ààD S, ‚àáf (M (k) ) .</formula><p>(2)</p><p>The next iterate M (k+1) is then constructed as a convex combination of M (k)  and S (k) , where the relative weight of each component is given by a step size Œ≥ (k) . The step size can be decreasing with the iteration number k or set by line search. The overall algorithm is summarized in Algorithm 1. FW is guaranteed to converge to an optimal solution of (1) at rate O(1/k), see for instance <ref type="bibr" target="#b33">(Jaggi, 2013)</ref> for a generic and concise proof. Unlike projected gradient, FW is a projection-free algorithm: each iterate M (k) is feasible by construction since it is a convex combination of elements of D. Instead of computing projections onto the feasible domain D, FW solves the linear optimization subproblem (2). The linearity of the objective (2) implies that a solution S (k) always lies at an extremal point of D. This leads to the interpretation of FW as a greedy algorithm which adds an extremal point to the current solution at each iteration <ref type="bibr" target="#b16">(Clarkson, 2010)</ref>. In other words, M (k) can be written as a sparse convex combination of extremal points: k) , where</p><formula xml:id="formula_4">M (k) = S (k) ‚ààS (k) Œ± (k) S (k) S (</formula><formula xml:id="formula_5">S (k) ‚ààS (k) Œ± (k) S (k) = 1 and Œ± (k) S (k) ‚â• 0, (<label>3</label></formula><formula xml:id="formula_6">)</formula><p>where S (k) denotes the set of "active" extremal points that have been added up to iteration k. When the extremal points of D have specific structure (such as sparsity, or low-rankness), this structure can be leveraged to compute a solution Algorithm 2 Frank-Wolfe algorithm with away steps</p><formula xml:id="formula_7">Input: Initial point M (0) ‚àà D for k = 0, 1, 2, . . . do S (k) F ‚Üê arg min S‚ààD S, ‚àáf (M (k) ) , D<label>(k)</label></formula><formula xml:id="formula_8">F = S (k) F -M (k) // forward direction S (k) A ‚Üê arg max S‚ààS (k) S, ‚àáf (M (k) ) , D (k) A = M (k) -S (k) A // away direction if D (k) F , ‚àáf (M (k) ) ‚â§ D (k) A , ‚àáf (M (k) ) then D (k) ‚Üê D (k) F and Œ≥ max ‚Üê 1 // choose forward step else D (k) ‚Üê D (k)</formula><p>A and Œ≥ max ‚Üê Œ±</p><formula xml:id="formula_9">(k) S (k) A /(1 -Œ± (k) S (k) A ) // choose away step end if Œ≥ (k) ‚Üê 2 k+2 (or determined by line search) M (k+1) ‚Üê M (k) + Œ≥ (k) D (k)</formula><p>end for of (2) much more efficiently than the projection operator, see <ref type="bibr" target="#b32">Jaggi (2011</ref><ref type="bibr" target="#b33">Jaggi ( , 2013) )</ref> for compelling examples.</p><p>A drawback of the standard FW algorithm is that "removing" an extremal point S (k) from the current iterate (or significantly reducing its weight Œ± (k)</p><formula xml:id="formula_10">S (k) )</formula><p>can only be done indirectly by adding (increasing the weight of) other extremal points. The variant of FW with away steps <ref type="bibr" target="#b27">(Gu√©lat and Marcotte, 1986)</ref> addresses this issue by allowing the algorithm to choose between adding a new extremal point (forward step) or reducing the weight of an existing one (away step), as shown in Algorithm 2. This can lead to sparser solutions <ref type="bibr" target="#b27">(Gu√©lat and Marcotte, 1986;</ref><ref type="bibr" target="#b16">Clarkson, 2010;</ref><ref type="bibr" target="#b32">Jaggi, 2011)</ref> and faster convergence in some cases <ref type="bibr" target="#b27">(Gu√©lat and Marcotte, 1986;</ref><ref type="bibr" target="#b38">Lacoste-Julien and Jaggi, 2015)</ref>.</p><p>In the present work, we will introduce a FW algorithm with away steps to efficiently perform similarity learning for high-dimensional sparse data. One of our key ingredients will be the design of a feasible domain with appropriate sparsity structure.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Proposed Approach</head><p>This section introduces hdsl (High-Dimensional Similarity Learning), the approach proposed in this paper. We first describe our problem formulation (Section 3.1), then derive and analyze an efficient FW algorithm to solve it in Section 3.2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Problem Formulation</head><p>In this work, our goal is to learn a similarity function for high-dimensional sparse data. We assume the data points lie in some space X ‚äÜ R d , where d is large (d &gt; 10 4 ) but points are s-sparse on average (s d). In other words, their number of nonzero entries is typically much smaller than d. We focus on learning a similarity function S M : X √ó X ‚Üí R of the form</p><formula xml:id="formula_11">S M (x, x ) = x T M x = xx , M ,</formula><p>where M ‚àà R d√ód and ‚Ä¢, ‚Ä¢ denotes the Frobenius inner product. Notice that for any M , S M can be computed in O(s 2 ) time on average if data points are stored in a sparse format.</p><p>Feasible domain. We will derive an algorithm to learn a very sparse M with time and memory requirements that depend on s but not on d. To this end, given a scale Œª &gt; 0 which will play the role of a regularization parameter, we parameterize M as a convex combination of rank-one, 4-sparse d √ó d bases:</p><formula xml:id="formula_12">M ‚àà D Œª = conv(B Œª ), with B Œª = ij P (ij) Œª , N (ij) Œª ,</formula><p>where for any pair of features i, j ‚àà {1, . . . , d}, i = j,</p><formula xml:id="formula_13">P (ij) Œª = Œª(e i + e j )(e i + e j ) T = Ô£´ Ô£≠ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ Œª ‚Ä¢ Œª ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ Œª ‚Ä¢ Œª ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ Ô£∂ Ô£∏ , N (ij) Œª = Œª(e i -e j )(e i -e j ) T = Ô£´ Ô£≠ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ Œª ‚Ä¢ -Œª ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ -Œª ‚Ä¢ Œª ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ Ô£∂ Ô£∏ .</formula><p>The use of such sparse matrices was first suggested by <ref type="bibr" target="#b32">Jaggi (2011)</ref>. Besides the fact that they are instrumental to the efficiency of our algorithm (see Section 3.2), we give some additional motivation for their use in the context of similarity learning.</p><p>First, any M ‚àà D Œª is a convex combination of symmetric PSD matrices and is thus also symmetric PSD. Unlike many metric learning algorithms, we thus avoid the O(d 3 ) cost of projecting onto the PSD cone. Constraining M to be symmetric PSD provides useful regularization to prevent overfitting <ref type="bibr" target="#b14">(Chechik et al., 2009)</ref> and ensures that S M can be interpreted as a dot product after a linear transformation of the inputs:</p><formula xml:id="formula_14">S M (x, x ) = x T M x = (Lx) T (Lx ),</formula><p>where M = LL T with L ‚àà R d√ók . Because the bases in B Œª are rank-one, the dimensionality k of the transformed space is at most the number of bases composing M .</p><p>Second, each basis operates on two features only. In particular, S P (ij) Œª (x, x ) = Œª(x i x i + x j x j + x i x j + x j x i ) assigns a higher similarity score when feature i appears jointly in x and x (likewise for j), as well as when feature i in x and feature j in y co-occur (and vice versa). Conversely, S N (ij) Œª penalizes the crossoccurrences of features i and j. In the context of text data represented as bags-of-words (or other count data), the semantic behind the bases in B Œª is quite natural: they can be intuitively thought of as encoding the fact that a term i or j present in both documents makes them more similar, and that two terms i and j are associated with the same/different class or topic.</p><p>Optimizing over the convex hull D Œª of B Œª will allow us to easily control the number of active features, thereby learning a very compact representation with efficient similarity computations.</p><p>Optimization problem. We now describe the optimization problem to learn the similarity parameters. Following previous work (see for instance <ref type="bibr" target="#b49">Schultz and Joachims, 2003;</ref><ref type="bibr" target="#b57">Weinberger and Saul, 2009;</ref><ref type="bibr" target="#b14">Chechik et al., 2009)</ref>, our training data consists of weak supervision in the form of triplet constraints: T = {x t should be more similar to y t than to z t } T t=1 .</p><p>Such constraints can be built from a labeled training sample (see Section 4), provided directly by domain experts or crowdsourcing campaign, or obtained through implicit feedback such as clicks on search engine results. For notational convenience, we denote</p><formula xml:id="formula_15">A t = x t (y t -z t ) T ‚àà R d√ód for each constraint t = 1, . . . , T so that we can concisely write S M (x t , y t ) -S M (x t , z t ) = A t , M .</formula><p>We measure the degree of violation of each constraint t with the smoothed hinge loss : R ‚Üí R + defined as</p><formula xml:id="formula_16">A t , M = Ô£± Ô£≤ Ô£≥ 0 if A t , M ‚â• 1 1 2 -A t , M if A t , M ‚â§ 0 1 2 (1 -A t , M ) 2 otherwise</formula><p>.</p><p>This convex loss is a continuously differentiable version of the standard hinge loss which tries to enforce a margin constraint of the form S M (x t , y t ) ‚â• S M (x t , z t )+ 1. When this constraint is satisfied, the value of the loss is zero. On the other hand, when the margin is negative, i.e. S M (x t , y t ) ‚â§ S M (x t , z t ), the penalty is linear in the margin violation. A quadratic interpolation is used to bridge between these two cases to ensure that the loss is differentiable everywhere.</p><p>Remark 1 (Choice of loss). One may use any other convex and continuously differentiable loss function in our framework, such as the squared hinge loss, the logistic loss or the exponential loss.</p><p>Given Œª &gt; 0, our similarity learning formulation aims at finding the matrix M ‚àà D Œª that minimizes the average margin penalty (as measured by ) over the triplet constraints in T : min</p><formula xml:id="formula_17">M ‚ààR d√ód f (M ) = 1 T T t=1 A t , M s.t. M ‚àà D Œª .<label>(4)</label></formula><p>Due to the convexity of the smoothed hinge loss, (4) involves minimizing a convex function over the convex domain D Œª . Note that the gradient of the Algorithm 3 Frank Wolfe algorithm for problem (4)</p><formula xml:id="formula_18">1: initialize M (0) to an arbitrary B ‚àà B Œª 2: for k = 0, 1, 2, . . . do 3: B (k) F ‚Üê arg min B‚ààB Œª B, ‚àáf (M (k) ) , D (k) F ‚Üê B (k) F -M (k) // forward dir. 4: B (k) A ‚Üê arg max B‚ààS (k) B, ‚àáf (M (k) ) , D (k) A ‚Üê M (k) -B (k) A // away dir. 5: if D (k) F , ‚àáf (M (k) ) ‚â§ D (k) A , ‚àáf (M (k) ) then 6: D (k) ‚Üê D (k)</formula><p>F and Œ≥ max ‚Üê 1 // choose forward step 7: else 8:</p><formula xml:id="formula_19">D (k) ‚Üê D (k) A and Œ≥ max ‚Üê Œ± (k) B (k) A /(1 -Œ± (k) B (k) A ) // choose away step 9: end if 10: Œ≥ (k) ‚Üê arg min Œ≥‚àà[0,Œ≥max] f (M (k) + Œ≥D (k) ) // perform line search 11: M (k+1) ‚Üê M (k) + Œ≥ (k) D (k)</formula><p>// update iterate towards direction 12: end for objective is given by</p><formula xml:id="formula_20">‚àáf (M ) = 1 T T t=1 G t (M ), with G t (M ) = Ô£± Ô£≤ Ô£≥ 0 if A t , M ‚â• 1 -A t if A t , M ‚â§ 0 ( A t , M -1) A t otherwise . (5)</formula><p>In the next section, we propose a greedy algorithm to efficiently find sparse approximate solutions to this problem.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Algorithm 3.2.1. Exact Frank-Wolfe Algorithm</head><p>We propose to use a Frank-Wolfe algorithm with away steps (see Section 2.2) to learn the similarity. We will exploit the fact that in our formulation (4), the extremal points (vertices) of the feasible domain D Œª are the elements of B Œª and have special structure. Our algorithm is shown in Algorithm 3. During the course of the algorithm, we explicitly maintain a representation of each iterate M (k) as a convex combination of basis elements as previously discussed in Section 2.2:</p><formula xml:id="formula_21">M (k) = B‚ààB Œª Œ± (k) B B,</formula><p>where</p><formula xml:id="formula_22">B‚ààB Œª Œ± (k) B = 1 and Œ± (k) B ‚â• 0.</formula><p>We denote the set of active basis elements in</p><formula xml:id="formula_23">M (k) as S (k) = {B ‚àà B Œª : 250 Œ± (k) B &gt; 0}.</formula><p>The algorithm goes as follows. We initialize M (0) to a random basis element. Then, at each iteration, we greedily choose between moving towards a (possibly) new basis (forward step) or reducing the weight of an active one (away step). The extent of the step is determined by line search. As a result, 10 Algorithm 3 adds only one basis (at most 2 new features) at each iteration, which provides a convenient way to control the number of active features and maintains a compact representation of M (k) for a memory cost of O(k). Furthermore, away steps provide a way to reduce the importance of a potentially "bad" basis element added at an earlier iteration (or even remove it completely when Œ≥ (k) = Œ≥ max ). Recall that throughout the execution of the FW algorithm, all iterates M (k) remain convex combinations of basis elements and are thus feasible. The following proposition shows that the iterates of Algorithm 3 converge to an optimal solution of (4) with a rate of O(1/k).</p><p>Proposition 1. Let Œª &gt; 0, M * be an optimal solution to (4) and L =</p><formula xml:id="formula_24">1 T T t=1 A t 2 F . At any iteration k ‚â• 1 of Algorithm 3, the iterate M (k) ‚àà D Œª satisfies f (M (k) ) -f (M * ) ‚â§ 16LŒª 2 /(k + 2).</formula><p>Furthermore, it has at most rank k + 1 with 4(k + 1) nonzero entries, and uses at most 2(k + 1) distinct features.</p><p>Proof. We first show that ‚àáf is L-Lipschitz continuous on D Œª with respect to the Frobenius norm, i.e. for any</p><formula xml:id="formula_25">M 1 , M 2 ‚àà D Œª , ‚àáf (M 1 ) -‚àáf (M 2 ) F ‚â§ L M 1 -M 2 F (6)</formula><p>for some L ‚â• 0. Note that</p><formula xml:id="formula_26">‚àáf (M 1 ) -‚àáf (M 2 ) F = 1 T T t=1 G t (M 1 ) - 1 T T t=1 G t (M 2 ) F ‚â§ 1 T T t=1 G t (M 1 ) -G t (M 2 ) F .</formula><p>Let t ‚àà {1, . . . , T }. We will now bound</p><formula xml:id="formula_27">‚àÜ t = G t (M 1 ) -G t (M 2 ) F for any M 1 , M 2 ‚àà D Œª .</formula><p>The form of the gradient (5) requires to consider several cases:</p><formula xml:id="formula_28">(i) If A t , M 1 ‚â• 1 and A t , M 2 ‚â• 1, we have ‚àÜ t = 0. (ii) If A t , M 1 ‚â§ 0 and A t , M 2 ‚â§ 0, we have ‚àÜ t = 0. (iii) If 0 &lt; A t , M 1 &lt; 1 and 0 &lt; A t , M 2 &lt; 1, we have: ‚àÜ t = A t , M 1 -M 2 A t F = A t F | A t , M 1 -M 2 | ‚â§ A t 2 F M 1 -M 2 F . (iv) If A t , M 1 ‚â• 1 and A t , M 2 ‚â§ 0, we have ‚àÜ t = A t F ‚â§ A t F | A t , M 1 -M 2 | ‚â§ A t 2 F M 1 -M 2 F . (v) If A t , M 1 ‚â• 1 and 0 &lt; A t , M 2 &lt; 1, we have: ‚àÜ t = ( A t , M 2 -1)A t F = A t F (1 -A t , M 2 ) ‚â§ A t F (1 -A t , M 2 ) + A t F ( A t , M 1 -1) = A t F A t , M 1 -M 2 ‚â§ A t 2 F M 1 -M 2 F . (vi) If A t , M 1 ‚â§ 0 and 0 &lt; A t , M 2 &lt; 1, we have: ‚àÜ t = -A t -( A t , M 2 -1)A t F = A t A t , M 2 F = A t F A t , M 2 ‚â§ A t F A t , M 2 -A t F A t , M 1 = A t F A t , M 2 -M 1 ‚â§ A t 2 F M 1 -M 2 F .</formula><p>The remaining cases are also bounded by</p><formula xml:id="formula_29">A t 2 F M 1 -M 2 F by symmetry to cases (iv)-(v)-(vi). Hence ‚àáf is L-Lipschitz continuous with L = A t 2 F . It is easy to see that diam ‚Ä¢ F (D Œª ) = ‚àö 8Œª.</formula><p>The convergence rate then follows from the general analysis of the FW algorithm <ref type="bibr" target="#b33">(Jaggi, 2013)</ref>.</p><p>The second part of the proposition follows directly from the structure of the bases and the greedy nature of the algorithm.</p><p>Note that the optimality gap in Proposition 1 is independent of d. Indeed, A t has O(s 2 ) nonzero entries on average, hence the term</p><formula xml:id="formula_30">A t 2 F in the Lipschitz constant L can be bounded by s 2 A t ‚àû , where A ‚àû = max d i,j=1 |A i,j |. This</formula><p>means that Algorithm 3 is able to find a good approximate solution based on a small number of features in only a few iterations, which is very appealing in the high-dimensional setting we consider.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2.">Complexity Analysis</head><p>We now analyze the time and memory complexity of Algorithm 3. The form of the gradient (5) along with the structure of the algorithm's updates are crucial to its efficiency. Since M (k+1) is a convex combination of M (k) and a 4-sparse matrix B (k) , we can efficiently compute most of the quantities of interest through careful book-keeping.</p><p>In particular, storing M (k) at iteration k requires O(k) memory. We can also recursively compute A t , M (k+1) for all constraints in only O(T ) time and O(T ) memory based on A t , M (k) and A t , B (k) . This allows us, for instance, to efficiently compute the objective value as well as to identify the set of satisfied constraints (those with A t , M (k) ‚â• 1) which are ignored in the computation of the gradient. Finding the away direction at iteration k can be done in O(T k) time. For the line search, we use a bisection algorithm to find a root of the gradient of the 1-dimensional function of Œ≥, which only depends on A t , M (k) and A t , B (k) , both of which are readily available. Its time complexity is O(T log 1 ) where is the precision of the line-search, with a memory cost of O(1).</p><p>The bottleneck is to find the forward direction. Indeed, sequentially considering each basis element is intractable as it takes O(T d 2 ) time. A more efficient strategy is to sequentially consider each constraint, which requires O(T s 2 ) time and O(T s 2 ) memory. The overall iteration complexity of Algorithm 3 is given in Table <ref type="table" target="#tab_1">1</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Variant Time complexity Memory complexity</head><formula xml:id="formula_31">Exact (Algorithm 3) √ï(T s 2 + T k) √ï(T s 2 + k) Mini-batch √ï(M s 2 + T k) √ï(T + M s 2 + k) Mini-batch + heuristic √ï(M s + T k) √ï(T + M s + k)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.3.">Approximate Forward Step</head><p>Finding the forward direction can be expensive when T and s are both large. We propose two strategies to alleviate this cost by finding an approximately optimal basis (see Table <ref type="table" target="#tab_1">1</ref> for iteration complexity).</p><p>Mini-batch approximation. Instead of finding the forward and away directions based on the full gradient at each iteration, we can estimate it on a mini-batch of M T constraints drawn uniformly at random (without replacement). The complexity of finding the forward direction is thus reduced to O(M s 2 ) time and O(M s 2 ) memory. Consider the deviation between the "value" of any basis element B ‚àà B Œª on the full set of constraints and its estimation on the minibatch, namely 1</p><formula xml:id="formula_32">M t‚ààM B, G t - 1 T T t=1 B, G t ,<label>(7)</label></formula><p>where M is the set of M constraint indices drawn uniformly and without replacement from the set {1, . . . , T }. Under mild assumptions, concentration bounds such as Hoeffding's inequality for sampling without replacement <ref type="bibr" target="#b50">(Serfling, 1974;</ref><ref type="bibr" target="#b2">Bardenet and Maillard, 2015)</ref> can be used to show that the probability of (7) being larger than some constant decreases exponentially fast with M . The FW algorithm is known to be robust to inexact gradients, and convergence guarantees similar to Proposition 1 can be obtained directly from <ref type="bibr" target="#b33">(Jaggi, 2013;</ref><ref type="bibr" target="#b24">Freund and Grigas, 2013)</ref>.</p><p>Fast heuristic. To avoid the quadratic dependence on s, we propose to use the following heuristic to find a good forward basis. We first pick a feature i ‚àà [d] uniformly at random, and solve the linear problem over the restricted set</p><formula xml:id="formula_33">j {P (ij) Œª , N<label>(ij)</label></formula><p>Œª }. We then solve it again over the set k {P</p><formula xml:id="formula_34">(kj) Œª , N<label>(kj) Œª</label></formula><p>} and use the resulting basis for the forward direction. This can be done in only O(M s) time and O(M s) memory and gives good performance in practice, as we shall see in Section 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Generalization Analysis</head><p>In this section, we derive generalization bounds for the proposed method. Our main goal is to give a theoretical justification of our approach, in particular by (i) showing that our choice of feasible domain D Œª helps to reduce overfitting in high dimensions, and (ii) showing that the proposed greedy Frank-Wolfe algorithm provides a simple way to balance between optimization and generalization errors through early stopping.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Setup and Notations</head><p>As in previous work on generalization bounds for metric learning, we consider the supervised learning setting where the training sample is a set of labeled points S = {z i = (x i , y i )} n i=1 drawn i.i.d. from a probability distribution ¬µ over the space Z = X √ó Y, where X ‚äÜ R d and Y = {1, . . . , C} is the label set. We assume that B X = sup x,x ,x ‚ààX x(xx ) T is bounded for some convenient matrix norm ‚Ä¢ .</p><p>For simplicity, we assume that the univariate loss function : R ‚Üí R + is 1-Lipschitz, which is the case for the smoothed hinge loss used in our algorithm.</p><p>Given a triplet (z, z , z ) ‚àà Z 3 , we say that it is admissible if y = y = y . Since we only want to consider admissible triplets, we will use the triplet-wise loss function</p><formula xml:id="formula_35">L M (z, z , z ) = I[y = y = y ] ‚Ä¢ ( x(x -x ) T , M ) indexed by M ‚àà D Œª ,</formula><p>which is equal to zero for non-admissible triplets.</p><p>Given a matrix M ‚àà D Œª , we define its empirical risk associated on the training set S as follows:</p><formula xml:id="formula_36">L S (M ) = 1 n(n -1)(n -2) i =j =k L M (z i , z j , z k ).<label>(8)</label></formula><p>Similarly, its expected risk is defined as</p><formula xml:id="formula_37">L(M ) = E z,z ,z ‚àº¬µ [L M (z, z , z )] .<label>(9)</label></formula><p>In contrast to the standard supervised classification setting, note that the empirical risk (8) takes the form of an average of dependent terms known as a U -statistic <ref type="bibr" target="#b40">(Lee, 1990)</ref>.</p><p>From our feasible domain D Œª = conv(B Œª ), we can define a sequence of nested sets as follows: <ref type="figure" target="#fig_3">2d(d -1</ref>). ( <ref type="formula">10</ref>  <ref type="figure" target="#fig_2">(d-1</ref>)) Œª = D Œª . Note also that since is 1-Lipschitz, by Holder's inequality we have ‚àÄk:</p><formula xml:id="formula_38">D (k) Œª = k i=1 Œ± i B i : B i ‚àà B Œª , Œ± i ‚â• 0, k i=1 Œ± i = 1 , k = 1, . . . ,</formula><formula xml:id="formula_39">Œª ‚äÇ D (2) Œª ‚äÇ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚äÇ D (2d</formula><formula xml:id="formula_40">sup z,z ,z ‚ààZ,M ‚ààD (k) Œª |L M (z, z , z )| ‚â§ sup x,x ,x ‚ààX ,M ‚ààD (k) Œª | ( x(x -x ) T , M )| ‚â§ B X sup M ‚ààD (k) Œª M * ,<label>(11)</label></formula><p>where ‚Ä¢ * is the dual norm of ‚Ä¢ .</p><p>In the following, we derive theoretical results that take advantage of the structural properties of our algorithm, namely that the matrix M (k) returned after k ‚â• 1 iterations of Algorithm 3 belongs to D Œª . We then use these results to derive bounds on the excess risk L(M (k) ) -L(M * ), where M * ‚àà arg min M ‚ààD Œª L(M ) is the expected risk minimizer. All proofs can be found in the appendix.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Main Results</head><p>We first characterize the Rademacher complexity of the loss functions indexed by elements of D (k) Œª . Given k ‚àà {1, . . . , 2d(d -1)}, consider the family</p><formula xml:id="formula_41">F (k) = {L M : M ‚àà D (k)</formula><p>Œª } of functions mapping from Z 3 to R + . We will consider the following definition of the Rademacher complexity of F (k) with respect to distribution ¬µ and sample size n ‚â• 3, adapted from <ref type="bibr" target="#b18">(Cl√©men√ßon et al., 2008;</ref><ref type="bibr">Cao et al., 2012a)</ref>:</p><formula xml:id="formula_42">R n F (k) = E œÉ,S‚àº¬µ n sup M ‚ààD (k) Œª 1 n/3 n/3 i=1 œÉ i L M (z i , z i+ n/3 , z i+2√ó n/3 ) ,<label>(12)</label></formula><p>where œÉ = (œÉ 1 , . . . , œÉ n/3 ) are independent uniform random variables taking values in {-1, 1}. The following lemma gives a bound on the above Rademacher complexity.</p><p>Lemma 1 (Bounded Rademacher complexity). Let n ‚â• 3, Œª &gt; 0 and 1 ‚â§ k ‚â§ 2d(d -1). We have</p><formula xml:id="formula_43">R n (F (k) ) ‚â§ 8ŒªB X 2 log k n/3 .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Proof. See Appendix B.</head><p>There are two important consequences to Lemma 1. First, restricting the set of feasible matrices M to D Œª = D (2d(d-1)) Œª instead of R d√ód leads to a Rademacher complexity with a very mild O( ‚àö log d) dependence in the dimension. This validates our design choice for the feasible domain in the highdimensional setting we consider. Second, the Rademacher complexity can actually be made independent of d by further restricting the number of bases k.</p><p>Using this result, we derive a bound for the deviation between the expected risk L(M ) and the empirical risk L S (M ) of any M ‚àà D (k) Œª . Theorem 1 (Maximal deviations). Let S be a set of of n points drawn i.i.d. from ¬µ, Œª &gt; 0 and 1 ‚â§ k ‚â§ 2d(d -1). For any Œ¥ &gt; 0, with probability 1 -Œ¥ we have</p><formula xml:id="formula_44">sup M ‚ààD (k) Œª [L(M ) -L S (M )] ‚â§ 16ŒªB X 2 log k n/3 + 3B X B D (k) Œª 2 ln (2/Œ¥) n ,<label>(13)</label></formula><p>where</p><formula xml:id="formula_45">B D (k) Œª = sup M ‚ààD (k) Œª M * . Proof. See Appendix C.</formula><p>The generalization bounds given by Theorem 1 exhibit a standard O(1 ‚àö n) rate. They also confirm that restricting the number k of bases is a good strategy to guard against overfitting when the feature dimension d is high. Interestingly, note that due to the convex hull structure of our basis set,</p><formula xml:id="formula_46">B D (k) Œª = sup M ‚ààD (k)</formula><p>Œª M * can be easily bounded by a quantity independent of d for any k ‚â• 1 and any dual norm ‚Ä¢ * . We thus have complete freedom to choose the primal norm ‚Ä¢ so as to make B X = sup x,x ,x ‚ààX x(x -x ) T as small as possible. A good choice of primal norm is the infinity norm</p><formula xml:id="formula_47">A ‚àû = max d i,j=1 |A i,j |, which is independent of d. For instance, if X = [0, 1] d we have B X = 1.</formula><p>The dual norm of the infinity norm being the L 1 norm, we then have for any k ‚â• 1:</p><formula xml:id="formula_48">B D (k) Œª = sup M ‚ààD (k) Œª M 1 = sup M ‚ààD (k) Œª d i,j=1 |M i,j | ‚â§ 4Œª. (<label>14</label></formula><formula xml:id="formula_49">)</formula><p>Theorem 1 is directly comparable to the results of <ref type="bibr">Cao et al. (2012a)</ref>, who derived generalization bounds for similarity learning under various norm regularizers. Their bounds have a similar form, but exhibit a dependence on the feature dimension d which is at least logarithmic (sometimes even linear, depending on the norm used to regularize the empirical risk). In contrast, our bounds depend logarithmically on k d. This offers more flexibility in the high-dimensional setting because k can be directly controlled by stopping our algorithm after k d iterations to guarantee that the output is in</p><formula xml:id="formula_50">D (k)</formula><p>Œª . This is highlighted by the following corollary, which combines the generalization bounds of Theorem 1 with the O(1/k) convergence rate of our Frank-Wolfe optimization algorithm (Proposition 1).</p><p>Corollary 1 (Excess risk bound). Let S be a set of n points drawn i.i.d. from ¬µ, Œª &gt; 0. Given k ‚àà {1, . . . , 2d(d -1)}, let M (k) be the solution returned after k iterations of Algorithm 3 applied to the problem min M ‚ààD Œª L S (M ), and let M * ‚àà arg min M ‚ààD Œª L(M ) be the expected risk minimizer over D Œª . For any Œ¥ &gt; 0, with probability 1 -Œ¥ we have</p><formula xml:id="formula_51">L(M (k) ) -L(M * ) ‚â§ 16LŒª 2 k + 2 + 16ŒªB X 2 log k n/3 + 5B X B D (k) Œª ln (4/Œ¥) n .</formula><p>Proof. See Appendix D.</p><p>Corollary 1 shows that the excess risk with respect to the expected risk minimizer M * depends on a trade-off between optimization error and complexity of the hypothesis class. Remarkably, this trade-off is ruled by the number k of iterations of the algorithm: as k increases, the optimization error term decreases but the Rademacher complexity terms gets larger. We thus obtain an excess risk bound which adapts to the actual sparsity of the solution output by our algorithm. This is in accordance with our overall goal of reducing overfitting by allowing a strict control on the complexity of the learned similarity, and justifies an early-stopping strategy to achieve a good reduction in empirical risk by selecting the most useful bases while keeping the solution complexity small enough. Again, the excess risk is independent of the feature dimension d, suggesting that in the high-dimensional setting it is possible to find sparse solutions with small excess risk. To the best of our knowledge, this is the first result of this nature for metric or similarity learning.</p><p>Remark 2 (Approximation of empirical risk by subsampling). The empirical risk (8) is a sum of O(n 3 ) term, which can be costly to minimize in the largescale setting. To reduce the computational cost, an alternative to the mini-batch strategy described in Section 3.2.3 is to randomly subsample M terms of the sum (e.g., uniformly without replacement) and to solve the resulting approximate empirical risk minimization problem. For general problems involving U -statistics, <ref type="bibr" target="#b17">Cl√©men√ßon et al. (2016)</ref> showed that sampling only M = O(n) terms is sufficient to maintain the O(1/ ‚àö n) rate. These arguments can be adapted to our setting to obtain results similar to Theorem 1 and Corollary 1 for this subsampled empirical risk.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Experiments</head><p>In this section, we present experiments to evaluate the performance and robustness of hdsl. In Section 5.1, we use synthetic data to study the performance of our approach in terms of similarity recovery and generalization in high dimensions in a controlled environment. Section 5.2 evaluates our algorithm against competing approaches on classification and dimensionality reduction using realworld datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Experiments on Synthetic Data</head><p>We first conduct experiments on synthetic datasets in order to address two questions:</p><p>1. Is the algorithm able to recover the ground truth sparse similarity function from (potentially weak) similarity judgments?</p><p>2. How well does the algorithm generalize as the dimensionality increases? </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.1.">Similarity Recovery</head><p>To investigate the algorithm's ability to recover the underlying similarity, we generate a ground truth similarity metric M ‚àà R d√ód where d = 2000. M is constructed as a convex combination of 100 randomly selected rank-one 4-sparse bases as specified in Section 3.1. The combination coefficients are drawn from a Dirichlet distribution with shape parameter 9 and scale parameter 0.5. Without loss of generality, we choose the metric to be block structured by restricting the basis selection from two blocks. This makes the resulting matrix easier to visualize, as show in Figure <ref type="figure" target="#fig_3">2(a)</ref>.</p><p>We then generate 5000 training samples from the uniform distribution on [0, 1] with 2% sparsity. From this sample, we create 30, 000 training triplets {(x 1 , x 2 , x 3 )} where x 1 is randomly picked and x 2 (or x 3 ) is sampled among x 1 's top Œ±% similar (or dissimilar) samples as measured by the ground truth metric M . The parameter Œ± controls the "quality" of the triplet constraints: a larger Œ± leads to less similar (or dissimilar) samples in the triplets, thereby providing a weaker signal about the underlying similarity. We experiment with various Œ± (10%, 20%, 25%, 30%) to investigate the robustness of hdsl to the quality of the supervision. In all our experiments, we use Œª = 100.</p><p>Results. We aim to measure how accurately we recover the entries (i.e., pairs of features) that are active in the ground truth similarity as training proceeds. To do so, at each iteration k of hdsl, we rank each pair of features by descending order of the absolute value of the corresponding entry in the current matrix M (k) . We then compute the Area under the ROC Curve (AUC) of the ranking induced by the similarity with respect to the list of active entries in the ground truth similarity. The AUC is well-suited to the imbalanced setting (as active entries in the ground truth are a small subset of all entries). It can be interpreted as the probability that a random entry that is active in the ground truth is ranked higher than a random inactive one. Following a similar process, we also compute an AUC score for individual features: this is done by ranking each feature by the L 1 norm of its associated row in the matrix.</p><p>The AUC scores for feature and entry recovery along the iterations are reported in Figure <ref type="figure" target="#fig_2">1</ref> for different values of Œ±. When the quality of the triplet constraints is high (Œ± =10%,20%), the AUC increases quickly to converge very close to 1.0, indicating an almost perfect recovery of relevant features/entries. This confirms that hdsl is able to accurately identify the small number of correct features and pairs of features. As Œ± increases (i.e., the similarity constraints become noisy and less informative), the AUC increases at a slower pace and the final value decreases. This is expected as the quality of the information carried by the similarity judgments is key to recover the ground truth similarity. Yet, even for Œ± =30%, the final AUC score is still very high (above 0.85 for both feature and entry recovery). This good recovery behavior is confirmed by the visual representations of the ground truth and learned similarity matrices shown in Figure <ref type="figure" target="#fig_3">2</ref>. We observe that the learned similarity (when Œ± = 20%) clearly recovers the block structure of the true similarity, and is able to correctly identify most individual entries with very few false positives.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.2.">Link Prediction</head><p>We now investigate the ability of our algorithm to generalize well as the feature dimensionality increases by conducting a signed link prediction experiment, which is the task of distinguishing positive and negative interactions in a network (see e.g. <ref type="bibr" target="#b0">Agrawal et al., 2013)</ref>.</p><p>We generate 500 samples with different number of features d ranging from 5, 000 to 1, 000, 000. As the dimension d increases, we decrease the average sparsity of data (from 0.02 to 0.002) to limit running time. In real high-dimensional datasets, features typically do not appear in a uniform frequency: instead, a small portion of features tends to dominate the others. Following this observation, we generate features whose frequency follow a power law style distribution, as shown in Figure <ref type="figure">3</ref>(a). The ground truth similarity is then a convex combination of randomly selected bases as in the previous experiment, except that we restrict the selected bases to those involving features that are frequent enough (a frequency of at least 0.1 was chosen for this experiment). This is needed to ensure that the features involved in the ground truth similarity will occur at least a few times in our small dataset, but we emphasize that the algorithm is exposed to the entire feature set and does not know which features are relevant.</p><p>Based on the samples and the ground truth similarity, we generate signed link observations of the form {x i 1 , x i 2 , y i } N i (y i ‚àà {-1, 1}). We associate the label y i = 1 (positive link) to pairs for which the similarity between x 1 and x 2 ranks in the top 5% of x 1 's (or x 2 's) neighbors according to the ground truth similarity measure. On the other hand, y i = -1 (negative link) indicates that the similarity ranks in the bottom 5% of x 1 's (or x 2 's) neighbors. We split these link observations into training, validation and test sets of 1, 000 observations each. Triplets constraints are generated from training links -given a pair x 1 , x 2 , y, we randomly sample x 3 as a similar (if y = -1) or dissimilar (if y = 1) node. The validation set is used to tune the hyperparameter Œª and for early stopping.</p><p>Results. We measure the generalization ability of hdsl by the AUC score of link prediction on the test set. Figure <ref type="figure">3</ref>(b) reports these AUC scores across different dimensions. We also show results for different numbers of constraints per training link. The results are averaged over 5 random runs. As one would expect, the task becomes increasingly difficult as the dimension becomes larger, since the size of the training set is fixed (1, 000 training links generated from 500 nodes). However, the performance decreases slowly (roughly logarithmically) with the dimension, and we achieve very high AUC scores (larger than 0.9)  even for one million features. We also see that training from more constraints tends to improve the prediction performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Experiments on Real Datasets</head><p>We now present comparative experiments on several high-dimensional real datasets, evaluating our approach against several baselines and competing methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.1.">Setup</head><p>Datasets. We report experimental results on several real-world classification datasets with up to 100,000 features. Dorothea and dexter come from the NIPS 2003 feature selection challenge <ref type="bibr" target="#b30">(Guyon et al., 2004)</ref> and are respectively pharmaceutical and text data with predefined splitting into training, validation and test sets. They both contain a large proportion of noisy/irrelevant features. Reuters CV1 is a popular text classification dataset with bag-of-words representation. We use the binary classification version from the LIBSVM dataset collection<ref type="foot" target="#foot_1">3</ref> (with 60%/20%/20% random splits) and the 4-classes version (with 40%/30%/30% random splits) introduced by <ref type="bibr" target="#b8">Cai and He (2012)</ref>. Detailed information on the datasets and splits is given in Table <ref type="table" target="#tab_3">2</ref>. All datasets are normalized such that each feature takes values in [0, 1].</p><p>Competing methods. We compare the proposed approach (hdsl) to several methods:</p><p>‚Ä¢ dot: The standard dot product, which is equivalent to setting M = I.</p><p>‚Ä¢ diag: Diagonal similarity learning (i.e., a weighting of the features), as done in <ref type="bibr" target="#b25">Gao et al. (2014)</ref>. We obtain it by minimizing the same loss as in hdsl with 2 and 1 regularization, i.e., min</p><formula xml:id="formula_52">w‚ààR d f (w) = 1 T T t=1 A t , diag(w) + Œª‚Ñ¶(w),</formula><p>where ‚Ñ¶(w) ‚àà { w 2 2 , w 1 } and Œª is the regularization parameter. Optimization was done using (proximal) gradient descent.</p><p>‚Ä¢ rp+oasis: Similarity learning in random projected space. Given r d, let R ‚àà R d√ór be a matrix where each entry r ij is randomly drawn from N (0, 1). For each data instance x ‚àà R d , we generate x = 1 ‚àö r R T x ‚àà R r and use this reduced data in OASIS <ref type="bibr" target="#b14">(Chechik et al., 2009)</ref>, a fast online method to learn a bilinear similarity from triplet constraints.</p><p>‚Ä¢ pca+oasis: Similarity learning in PCA space. Same as rp+oasis, except that PCA is used instead of random projections to project the data into R r .</p><p>‚Ä¢ svm: Support Vector Machines. We use linear SVM, which is known to perform well for sparse high-dimensional data <ref type="bibr" target="#b11">(Caruana et al., 2008)</ref>, with 2 and 1 regularization. We also use nonlinear SVM with the polynomial kernel (2nd and 3rd degree) popular in text classification <ref type="bibr" target="#b13">(Chang et al., 2010)</ref>. The SVM models are trained using liblinear <ref type="bibr" target="#b20">(Fan et al., 2008)</ref> and libsvm <ref type="bibr" target="#b12">(Chang and Lin, 2011)</ref> with 1vs1 paradigm for multiclass.</p><p>We have also tried to compare our method with Comet <ref type="bibr" target="#b1">(Atzmon et al., 2015)</ref>, which also learns a bilinear similarity in a greedy fashion with rank-1 updates. However, as mentioned in Section 2.1 their coordinate descent algorithm has a time complexity of O(d 2 ) per iteration, as well as overall memory complexity of O(d 2 ). We run the sparse version of code provided by the authors 4 on a machine with a 2.3GHz Intel Core i7 and 16GB memory. On the dexter dataset (which has the smallest dimensionality in our benchmark), a single pass over the features took more than 4 hours, while the authors reported that about 10 passes are generally needed for Comet to converge <ref type="bibr" target="#b1">(Atzmon et al., 2015)</ref>. On the dorothea dataset, Comet returned a memory error. As a result, we did not include Comet to our empirical comparison. In contrast, on the same hardware, our approach hdsl takes less than 1 minute on dexter and less than 1 hour on dorothea.</p><p>Training Procedure. For all similarity learning algorithms, we generate 15 training constraints for each instance by identifying its 3 target neighbors (nearest neighbors with same label) and 5 impostors (nearest neighbors with different label), following <ref type="bibr" target="#b57">Weinberger and Saul (2009)</ref>. Due to the very small number of training instances in dexter, we found that better performance is achieved across all methods when using 20 training constraints per instance, drawn at random based on its label. All parameters are tuned using the accuracy on the validation set. For hdsl, we use the fast heuristic described in Section 3.2.3 and tune the scale parameter Œª ‚àà {1, 10, . . . , 10 9 }. The regularization parameters of diag and svm are tuned in {10 -9 , . . . , 10 8 } and the "aggressiveness" parameter of OASIS is tuned in {10 -9 , . . . , 10 2 }.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.2.">Results</head><p>Classification Performance. We first investigate the performance of each similarity learning approach in k-NN classification (k was set to 3 for all experiments). For rp+oasis and pca+oasis, we choose the dimension r of the reduced space based on the accuracy of the learned similarity on the validation set, limiting our search to r ‚â§ 2000 because OASIS is extremely slow beyond this point.<ref type="foot" target="#foot_3">5</ref> Similarly, we use the performance on validation data to do early stopping in hdsl, which also has the effect of restricting the number of features used by the learned similarity.</p><p>Table <ref type="table" target="#tab_5">3</ref> shows the k-NN classification performance. We can first observe that rp+oasis often performs worse than dot, which is consistent with previous observations showing that a large number of random projections may be needed to obtain good performance <ref type="bibr" target="#b22">(Fradkin and Madigan, 2003)</ref>. pca+oasis gives much better results, but is generally outperformed by a simple diagonal similarity learned directly in the original high-dimensional space. hdsl, however, outperforms all other algorithms on these datasets, including diag. This shows the good generalization performance of the proposed approach, even though the number of training samples is sometimes very small compared to the number of features, as in dexter and dorothea. It also shows the relevance of encoding "second order" information (pairwise interactions between the original features) in the similarity instead of considering a simple weighting of features as in diag.</p><p>Table <ref type="table" target="#tab_6">4</ref> shows the comparison with SVMs. Interestingly, hdsl outperforms all SVM variants on dexter and dorothea, both of which have a large proportion of irrelevant features. This shows that its greedy strategy and early stopping mechanism achieves better feature selection and generalization than the 1 version of linear SVM. On the other two datasets, hdsl is competitive with SVM, although it is outperformed slightly by one variant (svm-poly-3 on rcv1 2 and svm-linear-2 on rcv1 4), both of which rely on all features.</p><p>Feature selection and sparsity. We now focus on the ability of hdsl to perform feature selection and more generally to learn sparse similarity functions. To better understand the behavior of hdsl, we show in Figure <ref type="figure" target="#fig_5">4</ref> the number of selected features as a function of the iteration number for two of the datasets. Remember that at most two new features can be added at each iteration. Figure <ref type="figure" target="#fig_5">4</ref> shows that hdsl incorporates many features early on but tends to eventually converge to a modest fraction of features (the same observation holds for the other two datasets). This may explain why hdsl does not suffer much from overfitting even when training data is scarce as in dexter.</p><p>Another attractive characteristic of hdsl is its ability to learn a matrix that is sparse not only on the diagonal but also off-diagonal (the proportion of nonzero entries is in the order of 0.0001% for all datasets). In other words, the learned similarity only relies on a few relevant pairwise interactions between features. Figure <ref type="figure" target="#fig_6">5</ref> shows two examples, where we can see that hdsl is able to exploit the product of two features as either a positive or negative contribution to the similarity score. This opens the door to an analysis of the importance of pairs of features (for instance, word co-occurrence) for the application at hand. Finally, the extreme sparsity of the matrices allows very fast similarity computation. Together with the superior accuracy brought by hdsl, it makes our approach potentially useful in a variety of contexts (k-NN, clustering, ranking, etc).</p><p>Finally, it is also worth noticing that hdsl uses significantly less features than diag-1 (see numbers in brackets in Table <ref type="table" target="#tab_5">3</ref>). We attribute this to the extra modeling capability brought by the non-diagonal similarity observed in  Dimension reduction. We now investigate the potential of hdsl for dimensionality reduction. Recall that hdsl learns a sequence of PSD matrices M (k) . We can use the square root of M (k) to project the data into a new space where the dot product is equivalent to S M (k) in the original space. The dimension of the projection space is equal to the rank of M (k) , which is upper bounded by k + 1 (see Section 3.1). A single run of hdsl can thus be seen as incrementally building projection spaces of increasing dimensionality.</p><p>To assess the dimensionality reduction quality of hdsl (measured by k-NN classification error on the test set), we plot its performance at various iterations during the runs that generated the results of Table <ref type="table" target="#tab_5">3</ref>. We compare it to two standard dimensionality reduction techniques: random projection and PCA. We also evaluate rp+oasis and pca+oasis, i.e., learn a similarity with OASIS on top of the RP and PCA features.<ref type="foot" target="#foot_5">7</ref> Note that OASIS was tuned separately for each projection size, making the comparison a bit unfair to hdsl. The results are shown in Figure <ref type="figure">6</ref>. As observed earlier, random projection-based approaches achieve poor performance. When the features are not too noisy (as in rcv1 2 and rcv1 4), PCA-based methods are better than hdsl at compressing the space into very few dimensions, but hdsl eventually catches up. On the other hand, PCA suffers heavily from the presence of noise (dexter and dorothea), while hdsl is able to quickly improve upon the standard similarity in the original space. Finally, on all datasets, we observe that hdsl converges to a stationary dimension without overfitting, unlike pca+oasis which exhibits signs of overfitting on dexter and rcv1 4 especially.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Concluding Remarks 640</head><p>In this work, we proposed an efficient approach to learn similarity functions from high-dimensional sparse data. This is achieved by forming the similarity as a combination of simple sparse basis elements that operate on only two features and the use of an (approximate) Frank-Wolfe algorithm. Our algorithm is completed by a novel generalization analysis which validates the design choices 645 and highlights the robustness of our approach to high dimensions. Experiments on synthetic and real datasets confirmed the good practical behavior of our method for classification and dimensionality reduction. The learned similarity may be applied to other algorithms that rely on a similarity function (clustering, ranking), or as a way to preprocess the data before applying another learning algorithm. We also note that <ref type="bibr" target="#b54">St.Amand and Huan (2017)</ref> have recently extended our hdsl algorithm to learn local metrics for different regions of the space in addition to the global metric.</p><p>We leave several fundamental questions for future work. In particular, our framework could be extended to optimize a loss function related to a linear classification objective. We could then attempt to adapt our analysis to obtain generalization bounds directly for the classification error. Such bounds exist in the literature (see <ref type="bibr" target="#b4">Bellet et al., 2012;</ref><ref type="bibr" target="#b29">Guo and Ying, 2014)</ref> but exhibit a classic dependence on the data dimension that could be avoided with our approach. Another interesting, though challenging direction is to formally study the conditions under which a sparse ground truth similarity can be accurately recovered from similarity judgments. Inspiration could be drawn from the related problem of sparse recovery in the compressed sensing literature <ref type="bibr" target="#b21">(Foucart and Rauhut, 2013)</ref>.  <ref type="bibr">Lemma 4 (McDiarmid, 1989)</ref>. Let Z be some set and let f : Z n ‚Üí R be a function of n variables such that for some c &gt; 0, for all i ‚àà {1, . . . , n} and for all z 1 , . . . , z n , z i ‚àà Z, we have |f (z 1 , . . . , z i-1 , z i , z i+1 , . . . , , z n ) -f (z 1 , . . . , z i-1 , z i , z i+1 , . . . , z n )| ‚â§ c.</p><p>Let Z 1 , . . . , Z n be n independent random variables taking values in Z. Then, with probability at least 1 -Œ¥, we have Let S = {z 1 , . . . , z q-1 , z q , z q+1 , . . . , z n } and S = {z 1 , . . . , z q-1 , z q , z q+1 , . . . , z n } 830 be two samples differing by exactly one point. We have:</p><formula xml:id="formula_53">Œ¶(S ) -Œ¶(S) ‚â§ sup M ‚ààD (k) Œª [L S (M ) -L S (M )] ‚â§ 1 n(n -1)(n -2) sup M ‚ààD (k) Œª i =j =k |L M (z i , z j , z k ) -L M (z i , z j , z k )| ‚â§ 1 n(n -1)(n -2) 6(n -1)(n -2)B X B D (k) Œª = 6 n B X B D (k) Œª .</formula><p>The first inequality comes from the fact that the difference of suprema does not exceed the supremum of the difference. The last inequality makes use of (11). Similarly, we can obtain Œ¶(S) -Œ¶(S ) ‚â§ 6B X B D  (k) ).</p><p>We have thus shown:</p><formula xml:id="formula_54">E S sup M ‚ààD (k) Œª [L(M ) -L S (M )] ‚â§ 2R n (F (k) ). (C.2)</formula></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Œª</head><label></label><figDesc>consists of all d √ó d matrices which can be decomposed as a convex combination of at most k elements of the basis set B Œª . Clearly, we have D</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Œª</head><label></label><figDesc>and derive bounds on the maximal deviation between L(M ) and L S (M ) for any M ‚àà D (k)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Similarity recovery experiment on synthetic data. Figure 1(a) and Figure 1(b) show the AUC scores (for feature recovery and entry recovery respectively) along the iterations of the algorithm for different values of Œ±.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Similarity recovery experiment on synthetic data. Figure 2(a) shows the underlying ground truth similarity, where blue dots represent positive entries and red dots represent negative entries (combination coefficients are not displayed). Figure 2(b) shows the similarity learned by hdsl (Œ± =20%), which is visually very close to the ground truth.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>Figure3: Link prediction experiment on synthetic data. Figure3(a)shows the feature frequency distribution, which follows a power law as in many real high-dimensional datasets. Figure3(b)shows AUC scores on the test set for different number of features (in log scale) and number of training constraints per link.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Number of active features learned by hdsl as a function of the iteration number.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Sparsity structure of the matrix M learned by hdsl. Positive and negative entries are shown in blue and red, respectively (best seen in color).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure</head><label></label><figDesc>Figure 5. 6</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head></head><label></label><figDesc>Figure 6: k-NN test error as a function of the dimensionality of the space (in log scale). Best seen in color.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head></head><label></label><figDesc>Acknowledgments. This work was partially supported by a grant from CPER Nord-Pas de Calais/FEDER DATA Advanced data science and technologies 2015-2020. It was also supported in part by the Intelligence Advanced Research Projects Activity (IARPA) via Department of Defense U.S. Army Research Laboratory (DoD / ARL) contract number W911NF-12-C-0012, a NSF IIS-1065243, an Alfred. P. Sloan Research Fellowship, DARPA award D11AP00278, and an ARO YIP Award (W911NF-12-1-0241). The U.S. Government is authorized to reproduce and distribute reprints for Governmental purposes notwithstanding any copyright annotation thereon. The views and conclusions contained herein are those of the authors and should not be interpreted as necessarily representing the official policies or endorsements, either expressed or implied, of IARPA, DoD/ARL, or the U.S. Government.Lemma 3. Let Q be a set of functions from Z 3 to R. If z 1 , z 2 , ..., z n ‚àà Z are i.i.d., then we haveE[sup q‚ààQ 1 n(n -1)(n -2) i =j =k q(z i , z j , z k )] i , z i+ n/3 , z i+2√ó n/3 )].Proof. From Lemma 2, we observe that œÄ(i) , z œÄ(i+ n/3 ) , z œÄ(i+2√ó n/3 ) )] œÄ(i) , z œÄ(i+ n/3 ) , z œÄ(i+2√ó n/3 ) œÄ(i) , z œÄ(i+ n/3 ) , z œÄ(i+2√ó n/3 ) i , z i+ n/3 , z i+2√ó n/3 )], which proves the result.Finally, we recall McDiarmid's inequality.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>(</head><label></label><figDesc>|f (Z 1 , . . . , Z n ) -E[f (Z 1 , . . . , Z n )]| ‚â§ c n log(2/Œ¥) 2 .and let m = |A S | ‚â§ n/3 . We have:R n (F (k) ) = E œÉ,S‚àº¬µ n sup x i (x i+ n/3 -x i+2√ó n/3 ) T , M ) ‚â§ E œÉ,S‚àº¬µ n sup i (x i+ n/3 -x i+2√ó n/3 ) T , M œÉ i x i (x i+ n/3 -x i+2√ó n/3 ) T , U = {u œÑ ‚àà R m : œÑ = 1, . . . , k, (u œÑ ) i = x Œ≥(i) (x Œ≥(i)+ n/3x Œ≥(i)+2√ó n/3 ) T , B œÑ , Œ≥ : {1, . . . , m} ‚Üí A S is bijective, B œÑ ‚àà B Œª },and ≈´ = 1 k k œÑ =1 u œÑ . The inequality (B.1) follows from the contraction property (see Shalev-Shwartz and Ben-David, 2014, Lemma 26.9). The inequality (B.2) follows from the fact M is a convex combination of set of k bases combined with 825 the properties in Shalev-Shwartz and Ben-David (2014, Lemma 26.7, 26.8). Finally, inequality (B.3) follows from the sparsity structure of the bases and the fact that x i (x j -x k ) T has no entries with absolute value greater than B X . Appendix C. Proof of Theorem 1 Proof. Let us consider the function Œ¶(S) = sup M ‚ààD (k) Œª [L(M ) -L S (M )].</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head></head><label></label><figDesc>thus we have |Œ¶(S) -Œ¶(S )| ‚â§ 6B X B D (k) Œª /n. We can therefore apply McDiarmid's inequality (see Lemma 4 in Appendix A) to Œ¶(S): for any Œ¥ &gt; 0, with probability at least 1 -Œ¥ we have: to boundE S sup M ‚ààD (k) Œª [L(M ) -L S (M )]. Applying Lemma 3 (see Appendix A) with q M (z, z , z ) = L(M ) -L M (z, z , z ) gives E S sup M ‚ààD (k) Œª [L(M ) -L S (M )] ‚â§ E S sup M ‚ààD (k) Œª [L(M ) -LS (M )],where LS (M ) = 1 n/3 n/3 i=1 L M (z i , z i+ n/3 , z i+2√ó n/3 ). Let S = {z 1 , ..., zn } be an i.i.d. sample independent of S. Then (M ) -LS (M )].Let œÉ 1 , . . . , œÉ n 3 ‚àà {-1, 1} be a collection of i.i.d. Rademacher variables. By standard symmetrization techniques, we have that E S, S sup M ( zi , zi+ n/3 , zi+2√ó n/3 ) -L M (z i , z i+ n/3 , z i+2√ó n/3 ) M (z i , z i+ n/3 , z i+2√ó n/3 M (z i , z i+ n/3 , z i+2√ó n/3 ) = 2R n (F</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>Complexity of iteration k (ignoring logarithmic factors) for different variants of the algorithm.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 :</head><label>2</label><figDesc>Datasets used in the experiments</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 3 :</head><label>3</label><figDesc>k-NN test error (%) of the similarities learned with each method. The number of features used by each similarity (when smaller than d) is given in brackets. Best accuracy on each dataset is shown in bold.</figDesc><table><row><cell>Dataset</cell><cell cols="4">svm-poly-2 svm-poly-3 svm-linear-2 svm-linear-1</cell><cell>hdsl</cell></row><row><cell>dexter</cell><cell>9.4</cell><cell>9.2</cell><cell>8.9</cell><cell>8.9 [281]</cell><cell>6.5 [183]</cell></row><row><cell>dorothea</cell><cell>7</cell><cell>6.6</cell><cell>8.1</cell><cell>6.6 [366]</cell><cell>6.5 [731]</cell></row><row><cell>rcv1 2</cell><cell>3.4</cell><cell>3.3</cell><cell>3.5</cell><cell>4.0 [1915]</cell><cell>3.4 [2126]</cell></row><row><cell>rcv1 4</cell><cell>5.7</cell><cell>5.7</cell><cell>5.1</cell><cell>5.7 [2770]</cell><cell>5.7 [1888]</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 4 :</head><label>4</label><figDesc>Test error (%) of several SVM variants compared to hdsl. As in Table3, the number of features is given in brackets and best accuracies are shown in bold.</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_0"><p>This is in contrast to a different line of work, inspired by the problem of ordinal embedding, which aims to learn a metric which correctly orders a fixed set of known points (see for instance<ref type="bibr" target="#b34">Jain et al., 2017)</ref> </p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_1"><p>http://www.csie.ntu.edu.tw/ ~cjlin/libsvmtools/datasets/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_2"><p>https://github.com/yuvalatzmon/COMET</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_3"><p>Note that the number of PCA dimensions is at most the number of training examples. Therefore, for dexter and dorothea, r is at most 300 and 800 respectively.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_4"><p>Note that hdsl uses roughly the same number of features as svm-linear-1 (Table4), but it is difficult to draw any solid conclusion because the objective and training data for each method are different, and SVM is a combination of binary models.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_5"><p>Again, we were not able to run OASIS beyond a certain dimension due to computational complexity.</p></note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix A. Technical Lemmas</head><p>The following classic result, known as the first Hoeffding's decomposition, allows to represent a U -statistic as a sum of i.i.d. blocks.</p><p>Lemma 2 <ref type="bibr" target="#b31">(Hoeffding, 1948)</ref>. Let q : Z √ó Z √ó Z ‚Üí R be a real-valued function. Given the i.i.d. random variables z 1 , z 2 , ..., z n ‚àà Z, we have</p><p>Proof. Observe that ‚àÄi = j = k, q(z i , z j , z k ) appears once on the left hand side and U n (q) has 1 n(n-1)(n-2) of its value, while on the right hand side it appears (n -3)! √ó n/3 times, because for each of the n/3 positions there are (n -3)! possible permutations. Thus the right hand side also has Proof. The excess risk of M (k) with respect to M * can be decomposed as follows:</p><p>where M S ‚àà arg min M ‚ààD Œª L S (M ) is an empirical risk minimizer.</p><p>The generalization error term in (D.1) can be bounded using Theorem 1 (recalling that M (k) ‚àà D (k) Œª by construction), while the optimization error term is bounded by the convergence rate of our Frank-Wolfe algorithm (Proposition 1). In the last term, M * does not depend on S, hence we can use Hoeffding's inequality together with ( <ref type="formula">11</ref>) and ( <ref type="formula">14</ref>) to obtain that for any Œ¥ &gt; 0, with probability at least 1 -Œ¥/2:</p><p>We get the corollary by combining the above results using the union bound.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Link label prediction in signed social networks</title>
		<author>
			<persName><forename type="first">P</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">K</forename><surname>Garg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Narayanam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="2591" to="2597" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Learning sparse metrics, one feature at a time</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Atzmon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Shalit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Chechik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS 2015 Workshop on Feature Extraction: Modern Questions and Challenges</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Concentration inequalities for sampling without replacement</title>
		<author>
			<persName><forename type="first">R</forename><surname>Bardenet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><forename type="middle">A</forename><surname>Maillard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bernoulli</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="1361" to="1385" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Robustness and Generalization for Metric Learning</title>
		<author>
			<persName><forename type="first">A</forename><surname>Bellet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Habrard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">151</biblScope>
			<biblScope unit="page" from="259" to="267" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Similarity Learning for Provably Accurate Sparse Linear Classification</title>
		<author>
			<persName><forename type="first">A</forename><surname>Bellet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Habrard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sebban</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="1871" to="1878" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">A Survey on Metric Learning for Feature Vectors and Structured Data</title>
		<author>
			<persName><forename type="first">A</forename><surname>Bellet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Habrard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sebban</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1306.6709</idno>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Metric Learning</title>
		<author>
			<persName><forename type="first">A</forename><surname>Bellet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Habrard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sebban</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015">2015</date>
			<publisher>Morgan &amp; Claypool Publishers</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Learning a Distance Metric by Empirical Loss Minimization</title>
		<author>
			<persName><forename type="first">W</forename><surname>Bian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Tao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="1186" to="1191" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Manifold Adaptive Experimental Design for Text Categorization</title>
		<author>
			<persName><forename type="first">D</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Knowledge and Data Engineering</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="707" to="719" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Generalization Bounds for Metric and Similarity Learning</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">C</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ying</surname></persName>
		</author>
		<idno>ArXiv:1207.5437</idno>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
		<respStmt>
			<orgName>University of Exeter</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Distance Metric Learning Revisited</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECML/PKDD</title>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="283" to="298" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">An empirical evaluation of supervised learning in high dimensions</title>
		<author>
			<persName><forename type="first">R</forename><surname>Caruana</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Karampatziakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Yessenalina</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="96" to="103" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">LIBSVM : a library for support vector machines</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">C</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Intelligent Systems and Technology</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="27" to="27" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Training and Testing Low-degree Polynomial Data Mappings via Linear SVM</title>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J</forename><surname>Hsieh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ringgaard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="1471" to="1490" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">An online algorithm for large scale image similarity learning</title>
		<author>
			<persName><forename type="first">G</forename><surname>Chechik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Shalit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="306" to="314" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Large-scale behavioral targeting</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Pavlov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">F</forename><surname>Canny</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
			<publisher>KDD</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Coresets, sparse greedy approximation, and the Frank-Wolfe algorithm</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">L</forename><surname>Clarkson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Algorithms</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="1" to="30" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Scaling-up Empirical Risk Minimization: Optimization of Incomplete U-statistics</title>
		<author>
			<persName><forename type="first">S</forename><surname>Cl√©men√ßon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Colin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bellet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="1" to="36" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Ranking and Empirical Minimization of U-statistics</title>
		<author>
			<persName><forename type="first">S</forename><surname>Cl√©men√ßon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Lugosi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Vayatis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annals of Statistics</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="844" to="874" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Information-theoretic metric learning</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">V</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Kulis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">S</forename><surname>Dhillon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="209" to="216" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">LIBLIN-EAR: A Library for Large Linear Classification</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J</forename><surname>Hsieh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><forename type="middle">R</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="1871" to="1874" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">A Mathematical Introduction to Compressive Sensing</title>
		<author>
			<persName><forename type="first">S</forename><surname>Foucart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Rauhut</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013">2013</date>
			<publisher>Birkha√ºser</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Experiments with random projections for machine learning</title>
		<author>
			<persName><forename type="first">D</forename><surname>Fradkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Madigan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD</title>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="517" to="522" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">An algorithm for quadratic programming</title>
		<author>
			<persName><forename type="first">M</forename><surname>Frank</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Wolfe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Naval Research Logistics Quarterly</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="95" to="110" />
			<date type="published" when="1956">1956</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">New Analysis and Results for the Conditional Gradient Method</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Freund</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Grigas</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1307.0873</idno>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">SOML: Sparse Online Metric Learning with Application to Image Retrieval</title>
		<author>
			<persName><forename type="first">X</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">C</forename><surname>Hoi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="1206" to="1212" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Neighbourhood Components Analysis</title>
		<author>
			<persName><forename type="first">J</forename><surname>Goldberger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Roweis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="513" to="520" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Some comments on Wolfe&apos;s away step</title>
		<author>
			<persName><forename type="first">J</forename><surname>Gu√©lat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Marcotte</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mathematical Programming</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="110" to="119" />
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Is that you? Metric learning approaches for face identification</title>
		<author>
			<persName><forename type="first">M</forename><surname>Guillaumin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Verbeek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Schmid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="498" to="505" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Guaranteed Classification via Regularized Similarity Learning</title>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">C</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ying</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="497" to="522" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Result Analysis of the NIPS 2003 Feature Selection Challenge</title>
		<author>
			<persName><forename type="first">I</forename><surname>Guyon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">R</forename><surname>Gunn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ben-Hur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Dror</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004">2004</date>
			<publisher>NIPS</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">A Class of Statistics with Asymptotically Normal Distribution</title>
		<author>
			<persName><forename type="first">W</forename><surname>Hoeffding</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Annals of Mathematical Statistics</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="293" to="325" />
			<date type="published" when="1948">1948</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Sparse Convex Optimization Methods for Machine Learning</title>
		<author>
			<persName><forename type="first">M</forename><surname>Jaggi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
		<respStmt>
			<orgName>ETH Zurich</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Revisiting Frank-Wolfe: Projection-Free Sparse Convex Optimization</title>
		<author>
			<persName><forename type="first">M</forename><surname>Jaggi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Learning Low-Dimensional Metrics</title>
		<author>
			<persName><forename type="first">L</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Mason</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Nowak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Regularized Distance Metric Learning: Theory and Algorithm</title>
		<author>
			<persName><forename type="first">R</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Non-linear Metric Learning</title>
		<author>
			<persName><forename type="first">D</forename><surname>Kedem</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Tyree</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Weinberger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Sha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Lanckriet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="2582" to="2590" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Metric Learning: A Survey</title>
		<author>
			<persName><forename type="first">B</forename><surname>Kulis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Foundations and Trends in Machine Learning</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="287" to="364" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">On the Global Linear Convergence of Frank-Wolfe Optimization Variants</title>
		<author>
			<persName><forename type="first">S</forename><surname>Lacoste-Julien</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Jaggi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">R</forename><surname>Leach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">J</forename><surname>Gillet</surname></persName>
		</author>
		<title level="m">An Introduction to Chemoinformatics</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Lee</surname></persName>
		</author>
		<title level="m">U-Statistics: Theory and Practice</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Marcel Dekker</publisher>
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Robust Structural Metric Learning</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">K</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Mcfee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Lanckriet</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013">2013</date>
			<publisher>ICML</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Similarity Learning for High-Dimensional Sparse Data</title>
		<author>
			<persName><forename type="first">K</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bellet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Sha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AISTATS</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="653" to="662" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Low-Rank Similarity Metric Learning in High Dimensions</title>
		<author>
			<persName><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Mu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">F</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">On the method of bounded differences</title>
		<author>
			<persName><forename type="first">C</forename><surname>Mcdiarmid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Surveys in combinatorics</title>
		<imprint>
			<biblScope unit="volume">141</biblScope>
			<biblScope unit="page" from="148" to="188" />
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">An Efficient Sparse Metric Learning in High-Dimensional Space via l1-Penalized Log-Determinant Regularization</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">J</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">J</forename><surname>Zha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">S</forename><surname>Chua</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">J</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">Towards Making High Dimensional Distance Metric Learning Practical</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zhu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1509.04355</idno>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">An Integrated Framework for High Dimensional Distance Metric Learning and Its Application to Fine-Grained Visual Categorization</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1402.0453</idno>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<title level="m" type="main">Learning Sparse Metrics via Linear Programming</title>
		<author>
			<persName><forename type="first">R</forename><surname>Rosales</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Fung</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006">2006</date>
			<publisher>KDD</publisher>
			<biblScope unit="page" from="367" to="373" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Learning a Distance Metric from Relative Comparisons</title>
		<author>
			<persName><forename type="first">M</forename><surname>Schultz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Joachims</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Probability inequalities for the sum in sampling without replacement</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Serfling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Annals of Statistics</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="39" to="48" />
			<date type="published" when="1974">1974</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<title level="m" type="main">Understanding Machine Learning: From Theory to Algorithms</title>
		<author>
			<persName><forename type="first">S</forename><surname>Shalev-Shwartz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ben-David</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014">2014</date>
			<publisher>Cambridge University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Positive Semidefinite Metric Learning Using Boosting-like Algorithms</title>
		<author>
			<persName><forename type="first">C</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Van Den Hengel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="1007" to="1036" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Sparse Compositional Metric Learning</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bellet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Sha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="2078" to="2084" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<monogr>
		<title level="m" type="main">Sparse Compositional Local Metric Learning</title>
		<author>
			<persName><surname>St</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Amand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Huan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
			<publisher>KDD</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Sample complexity of learning mahalanobis distance metrics</title>
		<author>
			<persName><forename type="first">N</forename><surname>Verma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Branson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Parametric Local Metric Learning for Nearest Neighbor Classification</title>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Woznica</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kalousis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="1610" to="1618" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Distance Metric Learning for Large Margin Nearest Neighbor Classification</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">Q</forename><surname>Weinberger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">K</forename><surname>Saul</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="207" to="244" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">High-dimensional Similarity Learning via Dual-sparse Random Projection</title>
		<author>
			<persName><forename type="first">D</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">A N</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Cong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Sparse Metric Learning via Smooth Optimization</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Campbell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="2214" to="2222" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Distance Metric Learning with Eigenvalue Optimization</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="1" to="26" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<monogr>
		<title level="m" type="main">Efficient Stochastic Optimization for Low-Rank Distance Metric Learning</title>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
			<publisher>AAAI</publisher>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
