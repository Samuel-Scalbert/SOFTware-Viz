<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Provenance Supporting Hyperparameter Analysis in Deep Neural Networks</title>
				<funder ref="#_Zkwd233">
					<orgName type="full">Coordenação de Aperfeiçoamento de Pessoal de Nível Superior -Brasil (CAPES) -Finance</orgName>
				</funder>
				<funder>
					<orgName type="full">CNPq</orgName>
				</funder>
				<funder>
					<orgName type="full">Inria (HPDaSc associated team</orgName>
				</funder>
				<funder>
					<orgName type="full">FAPERJ</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Débora</forename><surname>Pina</surname></persName>
							<email>dbpina@cos.ufrj.br</email>
							<affiliation key="aff0">
								<orgName type="institution">Federal University of Rio de Janeiro</orgName>
								<address>
									<settlement>Rio de Janeiro</settlement>
									<country key="BR">Brazil</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Liliane</forename><surname>Kunstmann</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Federal University of Rio de Janeiro</orgName>
								<address>
									<settlement>Rio de Janeiro</settlement>
									<country key="BR">Brazil</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Daniel</forename><surname>De Oliveira</surname></persName>
							<email>danielcmo@ic.uff.br</email>
							<affiliation key="aff1">
								<orgName type="institution">Fluminense Federal University</orgName>
								<address>
									<settlement>Niterói, Rio de Janeiro</settlement>
									<country key="BR">Brazil</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Patrick</forename><surname>Valduriez</surname></persName>
							<email>patrick.valduriez@inria.fr</email>
							<affiliation key="aff2">
								<orgName type="institution" key="instit1">Inria</orgName>
								<orgName type="institution" key="instit2">University of Montpellier</orgName>
								<orgName type="institution" key="instit3">CNRS</orgName>
								<orgName type="institution" key="instit4">LIRMM</orgName>
								<address>
									<settlement>Montpellier</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Marta</forename><surname>Mattoso</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Federal University of Rio de Janeiro</orgName>
								<address>
									<settlement>Rio de Janeiro</settlement>
									<country key="BR">Brazil</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Provenance Supporting Hyperparameter Analysis in Deep Neural Networks</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">E3C1D905BE6BCCFD7BEB04EEF7C5339C</idno>
					<idno type="DOI">10.1007/978-3-030-80960-7_2</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-04-12T14:46+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Provenance</term>
					<term>Deep Learning</term>
					<term>Workflow Steering</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The duration of the life cycle in deep neural networks (DNN) depends on the data configuration decisions that lead to success in obtaining models. Analyzing hyperparameters along the evolution of the network's execution allows for adapting the data. Provenance data derivation traces help the parameter fine-tuning by providing a global data picture with clear dependencies. Provenance can also contribute to the interpretation of models resulting from the DNN life cycle. However, there are challenges in collecting hyperparameters and in modeling the relationships between the data involved in the DNN life cycle to build a provenance database. Current approaches adopt different notions of provenance in their representation and require the execution of the DNN under a specific software framework, which limits interoperability and flexibility when choosing the DNN execution environment. This work presents a provenance data-based approach to address these challenges, proposing a collection mechanism with flexibility in the choice and representation of data to be analyzed. Experiments of the approach, using a convolutional neural network focused on image recognition, provide evidence of the flexibility, the efficiency of data collection, the analysis and the validation of network data.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Provenance data <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b16">17]</ref> constitute a natural solution to assist users in the registration of algorithms, the data derivation path, metadata and parameters relevant to the data transformation steps <ref type="bibr" target="#b17">[18]</ref>. Provenance data have already been successfully used in many scenarios and domains over the last decade (e.g., bioinformatics <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b2">3]</ref>, health <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b4">5]</ref>, visualization <ref type="bibr" target="#b7">[8]</ref>, etc.). Recently, its usage in the Machine Learning (ML) life cycle has gained importance. Among the ML methods, Deep Learning (DL) and Deep Neural Network (DNN) models have gained much attention. Similar to large-scale scientific workflows, ML models are also a result of an iterative process <ref type="bibr" target="#b43">[44]</ref>. ML workflows commonly involve several data transformations, users, algorithms, datasets, parameters, and add the challenge of feedback loops <ref type="bibr" target="#b36">[37]</ref>. According to Silva et al. <ref type="bibr" target="#b36">[37]</ref> there is a lack of capabilities for enabling ML workflow steering and dynamic workflow execution. Associating provenance data with the results of an ML workflow can support user steering to improve fine-tuning of parameters (or hyperparameters), at runtime, which is desired by several users <ref type="bibr" target="#b45">[46,</ref><ref type="bibr" target="#b44">45,</ref><ref type="bibr" target="#b17">18]</ref>.</p><p>The ML life cycle can be seen as a data centric workflow, as it produces an ML model based on input raw data through a data transformation flow. Fig. <ref type="figure" target="#fig_0">1</ref> presents the data transformation flow in the ML life cycle using DNNs (steps 1 to 7 ). The process starts with the data preparation (step 1 ), where outliers can be analyzed, missing values can be imputed and feature engineering may be performed. Once the dataset is prepared, it is split into three subsets (step 2 ): training set, test set, and validation set. The first two sets are used to generate an ML model (step 3 ), e.g., multi-class classification, regression, etc. These models can be tuned (step 4 ), i.e., to set the values of the hyperparameters that produce the most accurate model. ML models are sensitive to hyperparameters <ref type="bibr" target="#b30">[31]</ref>, adjusting them in DNNs may be costly. Finally, the generated model is evaluated using the validation set (step 5 ). There are several evaluation loops where the user may fine-tune parameters. To fine-tune, the user needs to have access to cause and effect data, like what filter was applied to the current model when the dropout value was below a specific threshold. By analyzing the evaluation (step 6 ), the user may decide to accept the generated model or to select a new configuration (step 7 ) and retrain the model. In this paper, we focus on the training phase where fine-tuning happens based on provenance data analysis at runtime (dotted red rectangle in Fig. <ref type="figure" target="#fig_0">1</ref>).</p><p>The advantages of capturing provenance data are well-known <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b17">18]</ref>, such as data quality, data interpretation, and reproducibility of the results. According to Cheney et al. <ref type="bibr" target="#b3">[4]</ref> it is important to consider the use and needs of provenance at an early stage, before adopting a provenance capture approach. Specifically, in DL-based workflows <ref type="bibr" target="#b14">[15]</ref>, provenance data have a lot to contribute to data analysis at runtime for user steering. Provenance data along with metadata, when available during execution (i.e., at runtime), have great potential to support the analysis made by humans regarding hyperparameter configurations or even training data. The evaluation of the several hyperparameters requires that the user is aware of the relationship between many types of metadata, e.g., the chosen hyperparameter values, performance data, environment configuration, etc. This data analysis during the training process can support the user in fine-tuning decisions, complementing auto-tuning solutions <ref type="bibr" target="#b42">[43]</ref>.</p><p>Adding provenance data to ML workflows is challenging. Despite the provenance support of several workflow systems, using these systems to invoke popular ML libraries or platforms can result in several execution conflicts, particularly in high-performance computing environments <ref type="bibr" target="#b36">[37]</ref>. Basically, there are two approaches to make ML workflows provenance aware. The first is provenance provided for a specific ML platform <ref type="bibr" target="#b45">[46,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b29">30]</ref> and the second is the provenance systems that are independent of the domain <ref type="bibr" target="#b31">[32]</ref>. In the first approach, each ML platform provides provenance using its proprietary representation, which is difficult to interpret and compare with execution between different platforms. The provenance systems approach is often tightly coupled to a script programming language, limiting the use of well-known ML platforms or it is too generic requiring a lot of data modeling and instrumenting the workflows.</p><p>In this paper, we present DNNProv and Keras-Prov, two provenance service management approaches that are designed for supporting hyperparameter analysis in DNNs. DNNProv and Keras-Prov integrate both traditional retrospective provenance data (r-prov) with domain-specific DL data. Both solutions provide an API that allows for users to develop their ML-based workflows using different DL frameworks (e.g., Tensorflow, Theano) while being able to share and analyze captured provenance data using W3C PROV. The remainder of this paper is structured as follows. Section 2 discusses related work, Section 3 details the proposed approach. Section 4 presents the experimental evaluation and discussion of results. Finally, Section 5 concludes the paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>With the recent interest in DL methods, several works propose provenance management approaches for data analysis during DNN training <ref type="bibr" target="#b10">[11]</ref>. There are several challenges in making ML workflows provenance aware like taking into account the execution framework that may involve CPUs, GPUs, TPUs, and distributed environments such as clusters and clouds as discussed in <ref type="bibr" target="#b35">[36,</ref><ref type="bibr" target="#b41">42,</ref><ref type="bibr" target="#b13">14]</ref>. In this section, we discuss related work for provenance data management, considering the intention of using provenance for runtime data analysis. We group these works in sections, with approaches that are either focused on the ML domain or that provide domain-agnostic provenance systems. Our provenance services also provide data capture modeled for DL characteristics and analyses, but unlike the approaches that are focused on the DL domain, adopt best practices of provenance systems that follow W3C PROV recommendations. Having preset classes that already represent typical entities and activities from the DL domain improves provenance data preparation for runtime analyses. The result is flexibility in defining new domain data to the DL workflow and being able to execute with different ML platforms with distributed environments having CPUs and GPUs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Machine-and Deep Learning-specific Approaches</head><p>The approaches in this category manage provenance for several purposes in ML platforms <ref type="bibr" target="#b45">[46,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b40">41,</ref><ref type="bibr" target="#b11">12]</ref>. They are all based on a proprietary representation of provenance data, i.e., that does not follow recommendations like W3C PROV. These proprietary representations of provenance data can make interoperability and analysis difficult. If one user needs to compare the results of multiple training processes performed in different frameworks, additional implementations will be required. Next, we discuss the approaches that are focused on the use of provenance to interpret and tune hyperparameters and that are closer to our solution. ModelDB <ref type="bibr" target="#b40">[41]</ref> is a system that aims at addressing model management. Its goal is to automatically track ML models in their native environment, storing trained models and their results to allow for visual exploration (or using SQL). Currently, ModelDB is customized for models generated using scikit-learn and SparkML, and uses visualization only as a way to perform post-mortem analysis of the ML pipeline, i.e., it does not support runtime provenance analysis. Another solution focused on ML experiments is Runway <ref type="bibr" target="#b39">[40]</ref>. Runway manages ML and DL artifacts, such as models, data, or experiments, as well as their provenance. In this sense, Runway allows for tracking the model and data, easing reproducibility. However, in addition to being a proprietary solution, which means that the solution does not follow W3C PROV standard to represent provenance data, Runway is restricted to the Python 3 programming language.</p><p>ModelKB (Model Knowledge Base) <ref type="bibr" target="#b11">[12]</ref> aims at automating the life cycle management process for DL models with minimal user intervention. The contributions of ModelKB are to automatically extract and store model metadata and artifacts, in addition to viewing, consulting, comparing experiments, and reproducing models. ModelKB itself is not a modeling tool, but a complementary system that can automatically manage experiments in their native frameworks, such as TensorFlow <ref type="bibr" target="#b0">[1]</ref>. However, ModelKB does not make the captured data available for analysis at runtime. Schelter et al. <ref type="bibr" target="#b34">[35]</ref> provide an automated tool to extract metadata from the model with an interactive view to query and compare experiments. A declarative language is proposed for users to specify their queries. Thus, this solution focuses on tracking metadata and the provenance of ML experiment data. However, this approach does not use the W3C PROV standard, being an obstacle to foster interoperability.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Domain-agnostic Approaches</head><p>There are several approaches for capturing provenance data <ref type="bibr" target="#b31">[32]</ref> that can be applied (with specializations) to the ML domain. Approaches for automatic capturing provide very fine granularity, generating a significant execution overhead in the process. Systems like noWorkflow <ref type="bibr" target="#b26">[27]</ref>, capture and store provenance data from Python scripts in an automatic way. noWorkflow allows provenance data capture without requiring any modifications in the original Python script. However, it is coupled to the Python language and does not execute in distributed and parallel environments, which limits the use of parallelism of popular ML libraries. Similar to noWorkflow, SPADE <ref type="bibr" target="#b9">[10]</ref> automatically collects provenance from a workflow script including distributed and parallel environments, but this script has to be compiled using an LLVM compiler. In the automatic capture, the user does not spend time defining what provenance data to capture. However, when it comes to analyzing this provenance, significant time and effort are required to understand what and how data was modeled. In addition, due to the fine granularity, the user has to filter and aggregate data before starting the analysis. Having to do this during the training cycle may not be an option.</p><p>Different from the approaches based on automatic provenance capturing, the approaches based on the participation of the user allow to pre-select relevant data for analysis, having less impact on the execution and analysis time. When the user identifies attributes and parameters in W3C PROV entities, activities with their relationships, these chosen names become familiar for runtime analysis. One of these tools is DfAnalyzer <ref type="bibr" target="#b38">[39]</ref>, which is a tool that allows users to set the relevant data to be captured for runtime analysis in high-performance execution environments. One advantage of DfAnalyzer is that it captures provenance throughout the training of a DNN, and does not interfere in the performance of the training. Although DfAnalyzer is W3C PROV compliant and has been used in different domains, it is not designed for supporting provenance capturing during the ML life cycle. Therefore, repetitive work on designing and instrumenting has to be done. Sumatra <ref type="bibr" target="#b5">[6]</ref> captures provenance from the script execution based on a series of annotations in the script. However, Sumatra only supports post-mortem analysis, i.e., only after the ML model is generated. YesWorkflow <ref type="bibr" target="#b21">[22]</ref> is another example of a tool capable of analyzing provenance data. YesWorkflow does not depend on a programming language, adopting a strategy of adding annotations to the scripts to identify provenance data. However, its queries are based on URIs and hyperparameter runtime analyses are not URI-based. Similar to YesWorkflow, in <ref type="bibr" target="#b12">[13]</ref> there is no runtime provenance capture. Instead, they take advantage of applications that provide log files to extract provenance from them. This could be adopted by systems like TensorFlow and Keras, which provide provenance logs. However, the queries are limited to the logged data and it is a post-mortem analysis approach.</p><p>UML2PROV <ref type="bibr" target="#b33">[34]</ref> aims at making UML (Unified Modeling Language) based applications provenance aware automatically. It is an approach that provides a mapping strategy from UML class, State Machine, and Sequence diagrams to define an automatic code generation technique that deploys artifacts for provenance generation in an application. UML2PROV assumes the existence of these diagrams or requires that they be designed or generated through reverse engineering, which limits its use in most ML environments.</p><p>Therefore, capturing provenance for runtime analysis in DL domains using domain-agnostic approaches may be complicated due to several reasons: (i) programming language and compiler dependencies, (ii) lack of support for provenance capturing in HPC and distributed environments, and (iii) lack of support for runtime provenance analysis. The next section describes how DNNProv and Keras-Prov address these limitations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">DNNProv and Keras-Prov</head><p>Due to the continuous increase in the use of ML and DL methods for developing workflows in different domains, the use of provenance data to support analysis has been gaining importance. The analytical potential of provenance data contributes to the analysis of hyperparameter configurations (and their impact on the accuracy of the generated model) and, consequently, supports the fine-tuning <ref type="bibr" target="#b34">[35,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b11">12]</ref>. As the training of DNNs can last for several hours or even days (depending on the computational environment), and a large amount of data is consumed and produced, the user needs to be able to evaluate the training to make adjustments to hyperparameters. Therefore, hyperparameter analysis tools should work during the training of the DNN and quickly provide the required data and entity attributes for analysis without competing for computational resources with the training process.</p><p>To capture, store and analyze provenance data from DNNs in an efficient way, we propose two provenance service management approaches, one independent from the DNN framework (named DNNProv) and the other coupled to a DNN framework (named Keras-Prov). DNNProv and Keras-Prov extend DfAnalyzer <ref type="bibr" target="#b38">[39,</ref><ref type="bibr" target="#b37">38]</ref>, which allows monitoring, debugging, and analyzing provenance during the execution of scientific workflows. One advantage of DfAnalyzer is that it explores in-situ or asynchronous provenance data management, without interfering with ML and DL workflow performance even in HPC environments. Since DfAnalyzer is domain-agnostic, it is not designed for ML and DL domains and targets mainly binary scientific data, this section presents the extensions to DfAnalyzer for ML and DL domains.</p><p>DNNProv and Keras-Prov data representation follows the data model based on the recommendations of the PROV-DM of the W3C PROV <ref type="bibr" target="#b25">[26]</ref> which is an initiative for the representation of different types of provenance data without being specific to a domain. W3C PROV is based on Agent, Activity and Entity concepts. An agent is is something that bears some form of responsibility for an activity, an entity, or for another agent's activity. An activity is something that occurs over a period of time upon or with entities and an entity is a thing with some fixed aspects. The diagram in Fig. <ref type="figure" target="#fig_1">2</ref>, generated by Prov Python<ref type="foot" target="#foot_0">4</ref> and Graphviz<ref type="foot" target="#foot_1">5</ref> , represents some activities of the neural network training process with DNNProv and Keras-Prov, following the notation from <ref type="bibr" target="#b24">[25]</ref>. The orange pentagon represents the Agent concept, yellow ovals represent Entity and blue rectangles represent Activity. The diagram shows what was used directly from PROV-Df (with the tag dfanalyzer) and what was extended on our approach (with the tag dnnprov).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Provenance Model</head><p>The association of provenance data with domain data can assist DNN users to perform rich analyses at runtime and allows the monitoring of the training process. Thereby, in this paper, we present a solution capable of tracking activities that occur in the DL life cycle, providing efficient provenance data capturing and analysis. The proposed approach considers the steps of the DL life cycle as a dataflow. To represent specific data from the DL training process, a specialization of the PROV-Df <ref type="bibr" target="#b38">[39]</ref> model, named DNNProv-Df, is proposed in this subsection. Based on this new model, the user is able to (i) track epochs, learning rate, accuracy, loss function, execution time, etc., (ii) discover which pre-processing methods were used before training the model, (iii) monitor the training process and perform fine-tuning, (iv) discover which files were generated in different execution steps, and (v) interpret the generated results.</p><p>Fig. <ref type="figure">3</ref> presents the DNNProv-Df model represented as a UML class diagram. The classes inside the dotted red area are classes related to the steps of the DL life cycle considered in this paper, with attributes that represent the data related to training metrics and hyperparameters. In the DL life cycle, several different hyperparameters have to be set, e.g., learning rate, batch size, number of epochs, momentum and dropout. Choosing the best hyperparameter values is far from trivial and many combinations are commonly explored. This process is compute-intensive, usually performed in HPC environments, and, several models are generated. Only one of these models is chosen as the best one and this choice must be registered for a posteriori analysis. In addition, as the training process takes a long time, it is necessary to steer it, e.g., by inspecting how the evaluation metrics are evolving during the training so that one can change parameters and start training again if needed.</p><p>The classes related to the dataflow specification are inherited from the PROV-Df model, which are dataflow, dataTransformation, dataset, dataDependency, program and attribute. These classes represent prospective provenance (p-prov). The class dataflow is responsible for representing the different dataflows whose content has been stored in the provenance database. This class contains a name for each dataflow. The class dataTransformation represents the multiple activities associated with a given dataflow. An activity is associated with a program or a script that is As described in <ref type="bibr" target="#b22">[23]</ref>, the hyperparameters are adjusted after or during each iteration. To make decisions regarding the fine-tuning of these hyperparameter values, the user needs to evaluate several data associated with the behavior of the DNN with the hyperparameter configuration used in that iteration, e.g., the training time for each epoch, and the loss associated with each epoch. Thus DNNProv-Df contains the following classes to represent domain-specific data regarding the DNN training process: i trainingModel, o trainingModel, i adaptation, o adaptation and o testingModel.</p><p>The class i trainingModel contains the hyperparameters that have to be set in the DNN before the training process (the prefix i refers to the input parameters of a task and the prefix o in the classes refers to the output parameter values). Some of these hyperparameters are learning rate, number of epochs, optimizer, momentum, and decay. Meanwhile, the class o trainingModel contains performance metrics for the generated model by epoch. This class contains attributes such as elapsed time and the date and time of the end of the epoch's execution. The elapsed time attribute defined in this class allows users to check whether the execution of an epoch is taking longer than expected. Adaptations are made during the training of a DNN. For example, an adaptation can generate a new learning rate at the end of an epoch, using a function that significantly decreases the value of the learning rate every n times by a m factor. Thus, the activity Adaptation receives as input data the set produced by the previous activity (activity Training) and a dataset with information such as the factor m, the value of n and the initial learning rate. This dataset is represented by the class i adaptation. The dataset produced by this activity, represented by the class o adaptation, contains the new learning rate, epoch and the date and time when the adaptation occurred, in addition to identification for the adaptation. Finally, the class o testingModel is related to the activity Testing and provides data about the evaluation of the model. Thus, similarly to the o trainingModel class, o testingModel contains performance metrics, such as accuracy and loss function values. It is worth mentioning that this model can be extended as new hyperparameters and metrics are needed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Architecture of DNNProv and Keras-Prov</head><p>We present two provenance service management solutions for hyperparameters analysis. The architectures of DNNProv and Keras-Prov are presented in Fig. <ref type="figure" target="#fig_2">4</ref>. The main difference between DNNProv and Keras-Prov is where the Provenance Extractor component is deployed. The architecture of both services is composed of three layers, according to Fig. <ref type="figure" target="#fig_2">4</ref>, which are: (i) Training Layer, (ii) Data Layer, and (iii) Analysis Layer. The Training Layer is where the training library executes and interacts with the Provenance Extractor, which accesses the hyperparameter values at runtime and gets their values.</p><p>For DNNProv, the Provenance Extractor is implemented and deployed outside the DNN library. This way, the user can choose any DNN library or framework, and then instrument the code (adding calls to the provenance extractor component) to define which data to capture. Using DNNProv we assume that the programs in the DL life cycle are gray boxes, i.e., part of their source code can be adapted, while the other part can invoke a private source code (black box). In DNNProv, the user defines which domain data and hyperparameters values will be captured and where they should be captured. With this instrumentation, the Provenance Extractor can access the data during training.</p><p>In the case of Keras-Prov, the Provenance Extractor is already implemented within the Keras library, so the user does not need to instrument the code. The user chooses, among the predefined provenance choices, domain data and hyperparameters to be captured. The Provenance Extractor automatically extracts the values of the hyperparameters used in each training. In both Keras-Prov and DNN-Prov, once captured, the provenance data is managed asynchronously with the DL execution. After, the Provenance Extractor interacts with the Data Layer to get the JSON file paths describing the DNN. These file paths, with hyperparameters values, metrics and, etc., are sent to the provenance database. Then, the Provenance Exporter queries the provenance database and sends query results to the Provenance Viewer, which generates a visual representation of the provenance graph as an alternative to the user runtime analysis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Using DNNProv and Keras-Prov</head><p>If the user chooses to use DNNProv, one important step is the code instrumentation. In this step, the user defines which data to capture. The first step is to define the dataflow structure in the source code of the DNN workflow (p-prov). Let us assume that a user needs to capture the data defined in Fig. <ref type="figure">3</ref>, thus one has to include in the source code the fragment shown in Fig. <ref type="figure" target="#fig_3">5</ref>. In this fragment, the user specifies an identifier for the dataflow (dataflow tag = "alexnet") and sets the automatic definition of activities to True. By setting the automatic definition of p-prov, the DNNProv queries the provenance database and identifies the registered activities. If the user chooses to set the automatic definition of p-prov to False, one has to define which activities are part of this dataflow manually. Once the dataflow and its transformations are defined, the user needs to set in the source code where a task starts (and finishes) and where DNNProv can extract (at runtime) the values of the hyperparameters. Note that the dataflow and data transformations specifications are p-prov, while the definition of tasks is r-prov. When the user is defining a task in the source code, one can also define the data dependencies among tasks, i.e., the user specifies in the source code which tasks are responsible for the production and consumption of data in a given dataflow. This step is also shown in Fig. <ref type="figure" target="#fig_3">5</ref> (dependency=t1 -this means that task t2 only starts after task t1 produces data). Multiple dependencies are modeled with binary relationships and queried with join predicates. Once set, this provenance schema can be reused for further DNN analyses. This instrumentation of the source code to capture the provenance data can be a barrier to the adoption of provenance tools by many scientists that are not computer science experts, given the effort that may be required from the user. With this in mind, we proposed Keras-Prov, which is the second provenance service management approach proposed in this paper. Keras-Prov is an extension of the DNN library Keras<ref type="foot" target="#foot_2">6</ref> and its goal is to reduce the effort to adapt the code to capture provenance data during the DNN training process by reducing the need for instrumentation. In the implementation of Keras-Prov, modifications were performed to the source code of Keras<ref type="foot" target="#foot_3">7</ref> to embed the Provenance Extractor component, since Keras does not capture provenance data natively. A class Provenance was created containing methods to deal with the creation of the activities that follow the DL life cycle, following the representation presented in Fig. <ref type="figure">3</ref>. In addition to this data, Keras-Prov captures and stores information about the layers of the DNN, that is, the name that identifies the layer (e.g., activation 1, dropout 1), the type of layer (e.g., activation, dropout) and the value of this layer (e.g., for activation the value is relu, the value for dropout is 0.4). Although Keras-Prov captures several hyperparameter values automatically, it is worth noticing that the user can define new data to be captured. For more information about defining new data to be captured using Keras-Prov please visit https://github.com/dbpina/keras-prov.</p><p>In the Model class of Keras, a provenance method was created to capture provenance data. This method receives a tag to identify the dataflow, if there is an adaptation of the hyperparameters during training (e.g., an update of the learning rate), that is, the use of methods such as LearningRateScheduler offered by Keras, and the list of hyperparameters to be captured. The data received by the provenance method are defined by the user in the source code of the DL workflow following the example presented in Fig. <ref type="figure" target="#fig_4">6</ref>. Different from DNNProv, when using Keras-Prov the user needs only to set which hyperparameters to capture, and no additional instrumentation is required. After setting True to the hyperparameters of interest, the user adds a call to the method provenance. Considering that ML workflows follow the life cycle of Fig. <ref type="figure" target="#fig_0">1</ref>, the inclusion of DNNProv in popular ML systems like Keras, requires the identification, in the source code, of the points at which such activities (network configuration, training, and testing) are performed and how the neural network data, hyperparameters, and metrics (from the training and testing steps) are being manipulated. This step allows to define PROV relationships between them and establishes data extraction into the database for automatic provenance design and capture in those systems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Evaluation</head><p>In this section, we evaluate DNNProv and Keras-Prov. We discuss the results obtained using both approaches for the analysis of hyperparameter configurations during the training of DNNs using provenance data. In the experiments presented in this section, we trained AlexNet <ref type="bibr" target="#b18">[19]</ref> in both DNNProv and Keras-Prov in the cluster Lobo Carneiro (SGI cluster with 504 CPUs Intel Xeon E5-2670v3 (Haswell) -total of 6.048 processors) at COPPE/UFRJ using the Oxford Flower <ref type="bibr" target="#b27">[28]</ref> dataset, which consists of 17 species of flowers with 80 images for each class. The flower categories in this dataset are deliberately chosen to have some ambiguity in each aspect. For example, some classes cannot be distinguished only in colors, such as dandelions and buttercups, others cannot be distinguished only in shapes, such as daffodils and wild windflowers. The images of the flowers were retrieved from different websites and some images from the authors' own photographs <ref type="bibr" target="#b27">[28]</ref>.</p><p>The Alexnet dataflow is composed of the following activities: (i) Training, (ii) Adaptation, and (iii) Testing. Training consumes (used ) the following hyperparameters: the name of the optimizer, the learning rate, number of epochs, and number of layers in the network, and produces (wasGeneratedBy) a set of metrics that helps in the evaluation of results obtained during training, e.g., accuracy, the value of the loss function, the elapsed time and the date and time of the end of the execution of each epoch. Adaptation consumes (used ) the dataset produced by the previous activity (Training), a dataset with information for the adaptation that has taken place and the output contains the values for the new learning rate, the value of the epoch and the date and time when the adaptation occurred, in addition to identification for the adaptation. Testing provides data on the evaluation of the model according to the training dataset and outputs the accuracy and loss function values.</p><p>Several training runs were performed for AlexNet, with variations in hyperparameters values, e.g., learning rate (0.0005, 0.001, 0.002), optimizer (Adam, SGD) and dropout (0.4, 0.7). After a few training executions, the user decided to apply a filter to convert the images (input dataset) to a gray-scale. Because of that, the user needed to add a new activity called Filters, also wanting this activity to be registered at the provenance database. Due to DNNProv's flexibility, a modification was made to the p-prov and this activity was included, which means that in the next training executions, the data defined by the user for this activity started to be captured. Likewise, other extensions can be done to the relational schema showing the flexibility of the approaches.</p><p>Table <ref type="table" target="#tab_0">1</ref> defines provenance queries based on the most frequent queries from <ref type="bibr" target="#b34">[35,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b40">41,</ref><ref type="bibr" target="#b11">12]</ref>. We categorize the set of possible provenance queries as illustrated in Table <ref type="table" target="#tab_1">2</ref>. Queries are classified according to the provenance data processing needed to answer them. For instance, queries in class C1 get entity attributes from a single provenance graph, while queries in class C2 access multiple provenance graphs. Queries in class C3 require relating entity attributes and data derivation path on one graph, while C4 queries multiple provenance graphs. ML frameworks like Tensorflow or Keras mention their provenance support through logs. Despite the possibility of extracting provenance from logs <ref type="bibr" target="#b12">[13]</ref>, it is far from trivial. It requires repetitive log post-processing for every trial, with no flexibility on defining what to capture. Running aggregation queries through epoch iterations from logs, like Q6 and Q8, is also time-consuming and demands a significant effort from the user. Using the queries presented in Table <ref type="table" target="#tab_0">1</ref>, during the training of the DNN, the user is able to monitor metrics by epoch and steer the training at runtime. If, for instance, the loss value is not meeting the criteria defined by the user, one may decide to stop training or modify the learning rate. In this case, these adaptations are also saved (time and date when it happened) since they are important for a posteriori analysis, even at the end of the training process. The user may want to discover if the training with adaptation at runtime produced better results than the training that used the same value for the learning rate without modifications at runtime. It is worth noticing that DNNProv and Keras-Prov can also be connected to data visualization tools, as a setup option, such as Kibana<ref type="foot" target="#foot_4">8</ref> , to create dashboards and other resources to support the user's analysis.</p><p>To evaluate the potential of DNNProv and Keras-Prov, queries Q3, Q6, and Q8 were submitted to the provenance database that was populated with the different training data of AlexNet (from multiple training runs). The results con-sider the number of epochs, if a gray-scale filter was applied to the input dataset and the use of LearningRateScheduler (LRS) for adaptations in the learning rate during training. These results are presented in Tables 3, 4 and 5.</p><p>From the result of Q3 (Table <ref type="table" target="#tab_2">3</ref>), it is possible to investigate, for example, if any epoch is taking longer than usual. In addition, if the loss value attribute is selected along with the identification of the epoch, the specialist can verify whether the increase in the number of epochs no longer contributes to better accuracy after a certain epoch. The result of Q6 (Table <ref type="table" target="#tab_3">4</ref>) shows the impact of learning rate adaptations in model convergence. Though decreasing the learning rate is a known technique, the registered values help the user trace the cause of changes when analyzing different models. These data are also important if the user is evaluating the impact of different learning rate adaptation techniques or different parameters for decreasing learning rate functions, such as Step Decay. From the result of Q8 (Table <ref type="table" target="#tab_4">5</ref>), we observed that the application of the filter that converts the images to a gray-scale presented a worse accuracy in the test set, 0.37, than the training without this filter, which presented an accuracy of 0.59. It is worth mentioning that for the results presented in this paper, AlexNet was trained with a maximum of 100 epochs. AlexNet was also trained a few times with a larger number of epochs, such as 500 and 1000, which took about three and six hours, respectively. Due to this training time, we chose to train with fewer epochs to show provenance helping in evaluating different variations of hyperparameters. Furthermore, provenance queries like Q6 show that the highest accuracy reached by AlexNet with 500 epochs was around 65%, which is consistent with the top accuracy of 68.68% presented for AlexNet in flower categorization <ref type="bibr" target="#b15">[16]</ref>.</p><p>Moreover, we observed the overhead introduced by the proposed approach. The purpose of this measurement was to assess the impact of capturing provenance on training time. We observed that the time overhead corresponds to an increase of 2% in the worst case over the total workflow time. This overhead can be considered negligible, especially in longer executions, considering that the user will have the benefit of queries and visualizations to the captured provenance data. In addition, the size of the provenance database was 5MB and with such a size it is already possible to answer relevant questions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusions</head><p>The approach presented in this paper aims at supporting the analysis of hyperparameter configurations and adaptations in the training of DNNs by capturing relevant provenance data. We present a provenance-based user steering approach that allows for capturing and storing data to query during and after the training. This approach is implemented in two modes, independent and dependent of the DNN library or framework. By adopting the W3C PROV recommendation, both modes aim at reducing the diversity of data representation and the effort in modeling and querying DL training data related to PROV. The first, DNNProv, is not specific to programming languages or libraries, and does not require the use of a particular ML execution environment. However, DNNProv requires the user to instrument the script code of the DNN workflow, which may require some effort. To provide a solution that does not require instrumentation, Keras-Prov adds DNNProv components into Keras to capture the provenance data automatically. In addition, the approach is flexible since it allows for the inclusion of new types of data to be captured, like the DL domain application data. Experiments show the adequacy of the use of provenance in the analysis throughout the training of DNNs, including extensions for capturing data related to pre-processing. As future work, we plan to extend the approach to the domain of Physics Informed Neural Networks (PINN) <ref type="bibr" target="#b32">[33]</ref>. PINNs define the neural network loss function based on partial differential equations that inform physics. Analyzing loss function data in PINNs increases the complexity of provenance data management.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Data transformation flow in the ML life cycle using DNNs</figDesc><graphic coords="3,36.00,72.00,508.86,137.86" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. W3C PROV graph fragment of DNNProv and Keras-Prov</figDesc><graphic coords="6,50.40,94.08,508.88,244.87" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Architecture of DNNProv and Keras-Prov</figDesc><graphic coords="8,99.75,72.00,407.07,170.32" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. A fragment of the source code instrumented for DNNProv</figDesc><graphic coords="8,125.20,407.50,356.20,294.29" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. Setting the hyperparameters of interest in Keras-Prov</figDesc><graphic coords="9,36.00,321.73,508.88,105.50" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>Example of provenance queries. the loss value of epoch 10 of a specific training t' of a specific model m' ? C1 Q2 What are the layers of model m' ? C1 Q3 Retrieve the time consumed and loss by each epoch in the training t' of model m'. C1 Q4 What is the initial value of the learning rate when the training for model m' was more accurate? C2 Q5 Retrieve the combinations of hyperparameters where was obtained the 3 best accuracy values in previous training for model m' ?</figDesc><table><row><cell># Queries</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 .</head><label>2</label><figDesc>Classification of queries.</figDesc><table><row><cell cols="5">Class Entity Attributes Derivation Path Single Graph Multiple Graphs</cell></row><row><cell>C1</cell><cell>Yes</cell><cell>No</cell><cell>Yes</cell><cell>No</cell></row><row><cell>C2</cell><cell>Yes</cell><cell>No</cell><cell>No</cell><cell>Yes</cell></row><row><cell>C3</cell><cell>Yes</cell><cell>Yes</cell><cell>Yes</cell><cell>No</cell></row><row><cell>C4</cell><cell>Yes</cell><cell>Yes</cell><cell>No</cell><cell>Yes</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 .</head><label>3</label><figDesc>Results for the Query Q3</figDesc><table><row><cell cols="3">Epoch Time (seconds) Loss Value</cell></row><row><cell>1</cell><cell>22.075</cell><cell>3.484</cell></row><row><cell>2</cell><cell>20.560</cell><cell>2.870</cell></row><row><cell>3</cell><cell>19.996</cell><cell>2.542</cell></row><row><cell>4</cell><cell>20.478</cell><cell>2.188</cell></row><row><cell>5</cell><cell>20.378</cell><cell>2.015</cell></row><row><cell>6</cell><cell>20.006</cell><cell>1.784</cell></row><row><cell>7</cell><cell>20.486</cell><cell>1.600</cell></row><row><cell>8</cell><cell>20.238</cell><cell>1.466</cell></row><row><cell>9</cell><cell>20.395</cell><cell>1.246</cell></row><row><cell>10</cell><cell>20.318</cell><cell>0.977</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 .</head><label>4</label><figDesc>Results for the Query Q6</figDesc><table><row><cell cols="3">Epoch Learning rate Technique</cell></row><row><cell>10</cell><cell>0.001</cell><cell>LRS</cell></row><row><cell>30</cell><cell>0.00025</cell><cell>LRS</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 5 .</head><label>5</label><figDesc>Results for the Query Q8</figDesc><table><row><cell cols="3">Filter Accuracy Epochs</cell></row><row><cell>None</cell><cell>0.59</cell><cell>100</cell></row><row><cell>Gray-scale</cell><cell>0.37</cell><cell>100</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_0"><p>https://prov.readthedocs.io/en/latest/prov.html</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_1"><p>http://www.graphviz.org/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_2"><p>https://keras.io/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_3"><p>https://github.com/keras-team/keras</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8" xml:id="foot_4"><p>https://www.elastic.co/kibana</p></note>
		</body>
		<back>

			<div type="funding">
<div><p>This work is funded by <rs type="funder">CNPq</rs>, <rs type="funder">FAPERJ</rs>, and <rs type="funder">Inria (HPDaSc associated team</rs>). <rs type="person">D. Pina</rs> and <rs type="person">L. Kunstmann</rs> are supported by the <rs type="funder">Coordenação de Aperfeiçoamento de Pessoal de Nível Superior -Brasil (CAPES) -Finance</rs> <rs type="grantNumber">Code 001</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_Zkwd233">
					<idno type="grant-number">Code 001</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Tensorflow: Large-scale machine learning on heterogeneous distributed systems</title>
		<author>
			<persName><forename type="first">M</forename><surname>Abadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Barham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Brevdo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Citro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Devin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ghemawat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Harp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Irving</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Isard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Jozefowicz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kudlur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Levenberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Mané</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Monga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Moore</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Murray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Olah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Schuster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Steiner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Talwar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Tucker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Vasudevan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Viégas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Warden</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Wattenberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Wicke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zheng</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1603.04467</idno>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Data platform for machine learning</title>
		<author>
			<persName><forename type="first">P</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Arya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bindal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bhatia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gagneja</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Godlewski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Low</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Muss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Paliwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Raman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 International Conference on Management of Data</title>
		<meeting>the 2019 International Conference on Management of Data</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1803" to="1816" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Managing data provenance for bioinformatics workflows using aprovbio</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">F</forename><surname>Almeida</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">M C</forename><surname>Da Silva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Castro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">P F</forename><surname>De Araújo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">E T</forename><surname>Walter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lifschitz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Holanda</surname></persName>
		</author>
		<idno type="DOI">10.1504/IJCBDD.2019.099761</idno>
		<ptr target="https://doi.org/10.1504/IJCBDD.2019.099761" />
	</analytic>
	<monogr>
		<title level="j">Int. J. Comput. Biol. Drug Des</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="153" to="170" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Cheney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Chapman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Davidson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Forbes</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2102.08228</idno>
		<title level="m">Data provenance, curation and quality in metrology</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Challenges of deploying computable biomedical knowledge in real-world applications</title>
		<author>
			<persName><forename type="first">D</forename><surname>Corrigan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Curcin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ethier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Flynn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Sottara</surname></persName>
		</author>
		<ptr target="http://knowledge.amia.org/69862-amia-1.4570936/t002-1.4575206/t002-1.4575207/3201770-1.4575319/3203261-1.4575316" />
	</analytic>
	<monogr>
		<title level="m">AMIA 2019</title>
		<meeting><address><addrLine>Washington, DC, USA</addrLine></address></meeting>
		<imprint>
			<publisher>AMIA</publisher>
			<date type="published" when="2019">November 16-20, 2019. 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Automated capture of experiment context for easier reproducibility in computational research</title>
		<author>
			<persName><forename type="first">A</forename><surname>Davison</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computing in Science &amp; Engineering</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="48" to="56" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Non-repudiable provenance for clinical decision support systems</title>
		<author>
			<persName><forename type="first">E</forename><surname>Fairweather</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Wittner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Chapman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Holub</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Curcin</surname></persName>
		</author>
		<idno>CoRR abs/2006.11233</idno>
		<ptr target="https://arxiv.org/abs/2006.11233" />
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Exploring reproducibility in visualization</title>
		<author>
			<persName><forename type="first">J</forename><surname>Fekete</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Freire</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Rhyne</surname></persName>
		</author>
		<idno type="DOI">10.1109/MCG.2020.3006412</idno>
		<ptr target="https://doi.org/10.1109/MCG.2020.3006412" />
	</analytic>
	<monogr>
		<title level="j">IEEE Computer Graphics and Applications</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="108" to="119" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Provenance for computational tasks: A survey</title>
		<author>
			<persName><forename type="first">J</forename><surname>Freire</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Koop</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Santos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">T</forename><surname>Silva</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computing in Science &amp; Engineering</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="11" to="21" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Spade: Support for provenance auditing in distributed environments</title>
		<author>
			<persName><forename type="first">A</forename><surname>Gehani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Tariq</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM/IFIP/USENIX International Conference on Distributed Systems Platforms and Open Distributed Processing</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="101" to="120" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Automated management of deep learning experiments</title>
		<author>
			<persName><forename type="first">G</forename><surname>Gharibi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Walunj</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Alanazi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Rella</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 3rd International Workshop on Data Management for End-to-End Machine Learning</title>
		<meeting>the 3rd International Workshop on Data Management for End-to-End Machine Learning</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page">8</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Modelkb: towards automated management of the modeling lifecycle in deep learning</title>
		<author>
			<persName><forename type="first">G</forename><surname>Gharibi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Walunj</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Rella</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 7th International Workshop on Realizing Artificial Intelligence Synergies in Software Engineering</title>
		<meeting>the 7th International Workshop on Realizing Artificial Intelligence Synergies in Software Engineering</meeting>
		<imprint>
			<publisher>IEEE Press</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="28" to="34" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Provenance from log files: a bigdata problem</title>
		<author>
			<persName><forename type="first">D</forename><surname>Ghoshal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Plale</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Joint EDBT/ICDT 2013 Workshops</title>
		<meeting>the Joint EDBT/ICDT 2013 Workshops</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="290" to="297" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Artificial intelligence for modeling complex systems: Taming the complexity of expert models to improve decision making</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Gil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Garijo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Khider</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A</forename><surname>Knoblock</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Ratnakar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Osorio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Vargas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Pujara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Shbita</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Vu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">Y</forename><surname>Chiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Feldman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Khandelwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Steinbach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Tayal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Pierce</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Pearson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Hardesty-Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Deelman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ferreira Da Silva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Mayani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">R</forename><surname>Kemanian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Leonard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Peckham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Stoica</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Cobourn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Duffy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Shu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Interactive Intelligent Systems</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<author>
			<persName><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<title level="m">Deep learning</title>
		<imprint>
			<publisher>MIT press Cambridge</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Flower categorization using deep convolutional neural networks</title>
		<author>
			<persName><forename type="first">A</forename><surname>Gurnani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Mavani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Gajjar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Khandhediya</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1708.03763</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A survey on provenance: What for? what form? what from?</title>
		<author>
			<persName><forename type="first">M</forename><surname>Herschel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Diestelkämper</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">B</forename><surname>Lahmar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The VLDB Journal</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="881" to="906" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Provenance-based explanations for automated decisions: final iaa project report</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">D</forename><surname>Huynh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Stalla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Moreau</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Imagenet classification with deep convolutional neural networks</title>
		<author>
			<persName><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="1097" to="1105" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Debugging machine learning pipelines</title>
		<author>
			<persName><forename type="first">R</forename><surname>Lourenço</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Freire</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Shasha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 3rd International Workshop on Data Management for End-to-End Machine Learning</title>
		<meeting>the 3rd International Workshop on Data Management for End-to-End Machine Learning</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1" to="10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Dynamic steering of hpc scientific workflows: A survey</title>
		<author>
			<persName><forename type="first">M</forename><surname>Mattoso</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Dias</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">A</forename><surname>Ocaña</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Ogasawara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Costa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Horta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Silva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>De Oliveira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Future Generation Computer Systems</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="page" from="100" to="113" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Retrospective provenance without a runtime provenance recorder</title>
		<author>
			<persName><forename type="first">T</forename><surname>Mcphillips</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bowers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Belhajjame</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Ludäscher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">7th {USENIX} Workshop on the Theory and Practice of Provenance (TaPP 15)</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<author>
			<persName><forename type="first">H</forename><surname>Miao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">S</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Deshpande</surname></persName>
		</author>
		<title level="m">Modelhub: Lifecycle management for deep learning</title>
		<imprint>
			<publisher>Univ. of Maryland</publisher>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Towards unified data and lifecycle management for deep learning</title>
		<author>
			<persName><forename type="first">H</forename><surname>Miao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">S</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Deshpande</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE 33rd International Conference on Data Engineering (ICDE)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2017">2017. 2017</date>
			<biblScope unit="page" from="571" to="582" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">The w3c prov family of specifications for modelling provenance metadata</title>
		<author>
			<persName><forename type="first">P</forename><surname>Missier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Belhajjame</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Cheney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 16th International Conference on Extending Database Technology</title>
		<meeting>the 16th International Conference on Extending Database Technology</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="773" to="776" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Provenance: an introduction to prov</title>
		<author>
			<persName><forename type="first">L</forename><surname>Moreau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Groth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Synthesis Lectures on the Semantic Web: Theory and Technology</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1" to="129" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">noworkflow: capturing and analyzing provenance of scripts</title>
		<author>
			<persName><forename type="first">L</forename><surname>Murta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Braganholo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Chirigati</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Koop</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Freire</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Provenance and Annotation Workshop</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="71" to="83" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">A visual vocabulary for flower classification</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">E</forename><surname>Nilsback</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR&apos;06)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2006">2006. 2006</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1447" to="1454" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Data analytics in bioinformatics: Data science in practice for genomics analysis workflows</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">A C S</forename><surname>Ocaña</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Silva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>De Oliveira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mattoso</surname></persName>
		</author>
		<idno type="DOI">10.1109/eScience.2015.50</idno>
		<ptr target="https://doi.org/10.1109/eScience.2015.50" />
	</analytic>
	<monogr>
		<title level="m">11th IEEE International Conference on e-Science</title>
		<meeting><address><addrLine>Science; Munich, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2015-08-31">2015. August 31 -September 4, 2015. 2015</date>
			<biblScope unit="page" from="322" to="331" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Implicit provenance for machine learning artifacts</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Ormenisan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ismail</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Haridi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Dowling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of MLSys</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">B</forename><surname>Orr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">R</forename><surname>Müller</surname></persName>
		</author>
		<title level="m">Neural networks: tricks of the trade</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">A survey on collecting, managing, and analyzing provenance from scripts</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">F</forename><surname>Pimentel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Freire</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Murta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Braganholo</surname></persName>
		</author>
		<idno type="DOI">10.1145/3311955</idno>
		<ptr target="https://doi.org/10.1145/3311955" />
	</analytic>
	<monogr>
		<title level="j">ACM Comput. Surv</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1" to="47" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><surname>Raissi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Perdikaris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Karniadakis</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1711.10561</idno>
		<title level="m">Physics informed deep learning (part i): Data-driven solutions of nonlinear partial differential equations</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Automating provenance capture in software engineering with uml2prov</title>
		<author>
			<persName><forename type="first">C</forename><surname>Sáenz-Adán</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Moreau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Pérez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Miles</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">J</forename><surname>García-Izquierdo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Provenance and Annotation Workshop</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="58" to="70" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Automatically tracking metadata and provenance of machine learning experiments</title>
		<author>
			<persName><forename type="first">S</forename><surname>Schelter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Böse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kirschnick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Seufert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning Systems workshop at NIPS</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">The best of both worlds: Challenges in linking provenance and explainability in distributed machine learning</title>
		<author>
			<persName><forename type="first">S</forename><surname>Scherzinger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Seifert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wiese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE 39th International Conference on Distributed Computing Systems (ICDCS)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019">2019. 2019</date>
			<biblScope unit="page" from="1620" to="1629" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Workflows community summit: Bringing the scientific workflows research community together</title>
		<author>
			<persName><forename type="first">R</forename><surname>Ferreira Da Silva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Casanova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Chard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Laney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Ahn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Jha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Goble</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Ramakrishnan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Peterson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Enders</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Thain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">.</forename><surname>Altintas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Babuji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Badia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Bonazzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Coleman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Crusoe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Deelman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Di Natale</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Di Tommaso</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Fahringer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Filgueira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Fursin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ganose</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Gruning</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Katz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Kuchar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kupresanin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Ludascher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Maheshwari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mattoso</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Mehta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Munson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ozik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Peterka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Pottier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Randles</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Soiland-Reyes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Tovar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Turilli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Uram</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Vahi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Wilde</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Wolf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wozniak</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021-03">Mar 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Dfanalyzer: Runtime dataflow analysis tool for computational science and engineering applications</title>
		<author>
			<persName><forename type="first">V</forename><surname>Silva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Campos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Guedes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Camata</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>De Oliveira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">L</forename><surname>Coutinho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Valduriez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mattoso</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SoftwareX</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page">100592</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Dfanalyzer: runtime dataflow analysis of scientific applications using provenance</title>
		<author>
			<persName><forename type="first">V</forename><surname>Silva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>De Oliveira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Valduriez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mattoso</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the VLDB Endowment</title>
		<meeting>the VLDB Endowment</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="2082" to="2085" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Runway: machine learning model experiment management tool</title>
		<author>
			<persName><forename type="first">J</forename><surname>Tsay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Mummert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Bobroff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Braz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Westerink</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hirzel</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Model db: a system for machine learning model management</title>
		<author>
			<persName><forename type="first">M</forename><surname>Vartak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Subramanyam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">E</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Viswanathan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Husnoo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Madden</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zaharia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Workshop on Human-In-the-Loop Data Analytics</title>
		<meeting>the Workshop on Human-In-the-Loop Data Analytics</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page">14</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">From human-human collaboration to human-ai collaboration: Designing ai systems that can work together with people</title>
		<author>
			<persName><forename type="first">D</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Churchill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Maes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Shneiderman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Human-ai collaboration in data science: Exploring data scientists&apos; perceptions of automated ai</title>
		<author>
			<persName><forename type="first">D</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Weisz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Muller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Ram</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Geyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Dugan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Tausczik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Samulowitz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gray</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM on Human-Computer Interaction 3(CSCW)</title>
		<meeting>the ACM on Human-Computer Interaction 3(CSCW)</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1" to="24" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Reproducible and flexible simulation experiments with ml-rules and SESSL</title>
		<author>
			<persName><forename type="first">T</forename><surname>Warnke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Helms</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Uhrmacher</surname></persName>
		</author>
		<idno type="DOI">10.1093/bioinformatics/btx741</idno>
		<ptr target="https://doi.org/10.1093/bioinformatics/btx741" />
	</analytic>
	<monogr>
		<title level="j">Bioinform</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1424" to="1427" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Accelerating human-in-the-loop machine learning: challenges and opportunities</title>
		<author>
			<persName><forename type="first">D</forename><surname>Xin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Macke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Parameswaran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Second Workshop on Data Management for End-To-End Machine Learning</title>
		<meeting>the Second Workshop on Data Management for End-To-End Machine Learning</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="1" to="4" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Diagnosing machine learning pipelines with fine-grained lineage</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">R</forename><surname>Sparks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Franklin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th International Symposium on High-Performance Parallel and Distributed Computing</title>
		<meeting>the 26th International Symposium on High-Performance Parallel and Distributed Computing</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="143" to="153" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
