<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Towards Scalable Hybrid Stores: Constraint-Based Rewriting to the Rescue</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Rana</forename><surname>Alotaibi</surname></persName>
							<email>ralotaib@eng.ucsd.edu</email>
						</author>
						<author>
							<persName><forename type="first">Damian</forename><surname>Bursztyn</surname></persName>
							<email>dbursztyn@gmail.com</email>
						</author>
						<author>
							<persName><forename type="first">Alin</forename><surname>Deutsch</surname></persName>
							<email>deutsch@cs.ucsd.edu</email>
						</author>
						<author>
							<persName><forename type="first">Ioana</forename><surname>Manolescu</surname></persName>
							<email>ioana.manolescu@inria.fr</email>
						</author>
						<author>
							<persName><forename type="first">Stamatis</forename><surname>Zampetakis</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">UC San Diego</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">Thales Digital Factory</orgName>
								<address>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="institution">UC San Diego</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="laboratory" key="lab1">Inria LIX (</orgName>
								<orgName type="laboratory" key="lab2">UMR 7161</orgName>
								<orgName type="institution">CNRS</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff4">
								<orgName type="institution">Ecole polytechnique</orgName>
								<address>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff5">
								<orgName type="institution">TIBCO Orchestra Networks</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Towards Scalable Hybrid Stores: Constraint-Based Rewriting to the Rescue</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">2055C9F41A4549A193362DB76F6CE99C</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-04-12T14:49+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Big data applications routinely involve diverse datasets: relations flat or nested, complex-structure graphs, documents, poorly structured logs, or even text data. To handle the data, application designers usually rely on several data stores used side-by-side, each capable of handling one or a few data models, and each very efficient for some, but not all, kinds of processing on the data. A current limitation is that applications are written taking into account which part of the data is stored in which store and how. This fails to take advantage of (i) possible redundancy, when the same data may be accessible (with different performance) from distinct data stores; (ii) partial query results (in the style of materialized views) which may be available in the stores.</p><p>We present ESTOCADA, a novel approach connecting applications to the potentially heterogeneous systems where their input data resides. ESTOCADA can be used in a polystore setting to transparently enable each query to benefit from the best combination of stored data and available processing capabilities. ESTOCADA leverages recent advances in the area of view-based query rewriting under constraints, which we use to describe the various data models and stored data. Our experiments illustrate the significant performance gains achieved by ESTOCADA.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A RELATIONAL ENCODING OF MOTIVATING</head><p>QBT XM QUERY Q 1 Q 1 &lt; p a t i e n t I D , drug , a d m i s s i o n L o c , a d m i s s i o n T i m e &gt;: -</p><p>Chil d J (M, p a t i e n t I D , " p a t i e n t I D " , " o " ) , Chil d J (M, A , " a d m i s s i o n s " , " o " ) , Chil d J ( A , a d m i s s i o n I D , " a d m i s s i o n I D " , " o " ) , Chil d J ( A , r e p o r t , " r e p o r t s " , " o " ) , V al ue J ( r e p o r t , " l i k e -c o r o n a r y a r t e r y " ) , Chil d J ( A , a d m i s s i o n L o c , " a d m i s s i o n L o c " , " o " ) , Chil d J ( A , a d m i s s i o n T i m e , " a d m i s s i o n T i m e " , " o " ) , Chil d J ( A , LE , " l a b e v e n t s " , " o " ) , Chil d J ( LE , f l a g , " f l a g " , " o " ) ,</p><p>V al ue J ( f l a g , " a b n o r m a l " ) , Chil d J ( LE , l a b I t e m I D , " i d "</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Big Data applications increasingly involve diverse data sources, such as: flat or nested relations, structured or unstructured documents, data graphs, relational databases, etc. Such datasets are routinely hosted in heterogeneous stores. One reason is that the fast pace of application development prevents consolidating all the sources into a single data format and loading them into a single store. Instead, the data model often dictates the choice of the store, e.g., relational data gets loaded into a relational or "Big Table"-style system, JSON documents in a JSON store, etc. Heterogeneous stores also "accumulate" in an application along the time, e.g., at some point one decision is made to host dataset D 1 in Spark and D 2 in MongoDB, while later on another application needs to use D 1 and D 2 together. Systems capable of exploiting diverse Big Data in this fashion are usually termed polystores <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b35">36]</ref>. * Work done while the author was a PhD student working at Inria, France.</p><p>Query evaluation in a polystore recalls to some extent mediator systems <ref type="bibr" target="#b27">[28]</ref>; in both cases, sub-queries are delegated to the underlying stores when possible, while the remaining operations are applied in the upper integration layer. Current polystores process a query assuming that each of its input datasets is available in exactly one store (often chosen for its support of a given data model).</p><p>We identify two limitations of such architectures. First, they do not exploit possible data redundancy: the same data could be stored in several stores, some of which may support a query operation much more efficiently than others. Second, they are unable to take advantage of the presence of partially computed query results, which may be available in one or several stores (in the style of materialized views), when the data model of the queried dataset differs from the data model of the store hosting the view.</p><p>To overcome these limitations, we propose a novel approach for allowing an application to transparently exploit data stored in a set of heterogeneous stores, as a set of (potentially overlapping) data fragments; further, if fragments store results of partial computations applied on the data, we show how to speed up queries using them as materialized views, which reduces query processing effort and seeks to take maximum advantage of the efficient query processing features of each store. Importantly, our approach does not require any change to the application code. The example below illustrates these performance-enhancing opportunities.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1">Motivating example</head><p>Consider the Medical Information Mart for Intensive Care III (MIMIC-III) <ref type="bibr" target="#b32">[33]</ref> dataset, comprising health data for more than 40.000 Intensive Care Unit (ICU) patients from 2001 to 2012. The total size of 46.6 GB, and it consists of : (i) all charted data for all patients and their hospital admission information, ICU stays, laboratory measurements, caregivers' notes, and prescriptions; (ii) the role of caregivers (e.g., MD stands for "medical doctor"), (iii) lab measurements (e.g., ABG stands for "arterial blood gas") and (iv) diagnosis related groups (DRG) codes descriptions.</p><p>Our motivation query Q 1 is: "for the patients transferred into the ICU due to "coronary artery" issues, with abnormal blood test results, find the date/time of admission, their previous location (e.g., emergency room, clinic referral), and the drugs of type "additive" prescribed to them". Evaluating this query through the Aster-ixDB <ref type="bibr" target="#b1">[2]</ref> (Version 9.4) JSON store took more than 25 minutes; this is because the system does not support full-text search by an index if the text occurs within a JSON array. In SparkSQL (v2.3.2), the query took more than an hour, due to its lack of indexes for selective data access. In the MongoDB JSON store (v4.0.2), it took more than 17 minutes due to its limited join capability. Finally, in PostgreSQL with JSON support (v9.6), denoted Postgres in the sequel, Q 1 took 12.6 minutes. Now, consider we had at our disposal three materialized views which pre-compute partial results for Q 1 . SOLR is a well-known highly efficient full-text server, also capable of handling JSON documents. Consider a SOLR server stores a view V 1 storing the IDs of patients and their hospital admission data, as well as the caregivers' reports, include notes on the patients' stay (e.g., detailed diagnosis, etc). Full-text search on V 1 for "coronary artery" allows to efficiently retrieve the IDs of the respective patients. Further, consider that a Postgres server stores a view V 2 with the patients meta-data information and their hospital admission information such as admission time and patients' location prior to admission. Finally, assume available a view V 3 which stores all drugs that are prescribed for each patient that has "abnormal blood" test results, as a JSON document stored in Postgres. Now, we are able to evaluate Q 1 by a full-text search on V 1 followed by a BindJoin <ref type="bibr" target="#b47">[48]</ref> with the result of filtering V 3 , and projecting prescribed drugs as well as patients' admission time and prior location from V 2 . Using a simple Java-based execution engine (implementing select, project, join, etc.) to access the views and join them, this takes about 5.70 mins, or a speedup of 5× w.r.t. plain JSON query evaluation in SparkSQL and AsterixDB. This is also a speedup of 2× and speedup of 3× w.r.t. plain JSON query evaluation in MongoDB and Postgres, respectively. Lessons learned. We can draw the following conclusions from the above example. (1.) Unsurprisingly, materialized views drastically improve query performance since they pre-compute partial query results. (2.) More interestingly: materialized views can strongly improve performance even when stored across several data stores, although such a hybrid scenario incurs a certain performance penalty due to the marshaling of data from one data model/store to another. In fact, exploiting the different strengths of each system (e.g., SOLR's text search, Postgres' efficient join algorithms, etc.) is the second reason (together with materialized view usage) for our performance gains. (3.) Different system combinations work best for different queries, thus it must be easy to add/remove a view in one system, without disrupting other queries that may be currently well-served. As known from classical data integration research <ref type="bibr" target="#b27">[28]</ref>, such flexibility is attained through the "local-as-view" (LAV) approach, where the content of each data source is described as a view. Thus, adding or removing a data source from the system is easily implemented by adding or removing the respective view definition. (4.) Application data sets may come in a variety of formats, e.g., MIMIC is in JSON, Apache log data is often represented in CSV, etc. However, while the storage model may change as data migrates, applications should not be disrupted. A simple way of achieving this is to guarantee them access to the data in its native format, regardless of where it is stored.</p><p>Observe that the combination of 2., 3. and 4. above goes well beyond the state of the art. Most LAV systems assume both the application data and the views are organized according to the same  <ref type="bibr" target="#b38">[39]</ref>, or XML <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b42">43,</ref><ref type="bibr" target="#b45">46]</ref>. Different from these, some LAV systems <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b40">41]</ref> allow different data models for the stored views, but consider only the case when the application data model is XML. As a consequence, the query answering approach adopted in these systems is tailored toward the XML data model and query language.</p><p>In contrast, we aim at a unified approach, supporting any data model both at the application and at the view level.The core technical question to be answered in order to attain such performance benefits without disrupting applications is view-based query rewriting across an arbitrary set of data models. In this paper, we introduce a novel approach for cross-model view-based rewriting and we report on its implementation and experimental evaluation in a polystore context. Our approach is currently capable of handling the systems listed in Table <ref type="table" target="#tab_0">1</ref>, together with their data models and query languages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2">Outline</head><p>The remainder of this paper is organized as follows. Section 2 formalizes the rewriting problem we solve. Section 3 outlines our approach; at its core is a view-based query rewriting algorithm based on an internal model, invisible to users and applications, but which crucially supports rewriting under integrity constraints. Section 4 describes the language we use for (potentially cross-model) views and queries. Section 5 shows how we reduce the multi-data model rewriting problem to one within this internal pivot model, then transform rewritings obtained there into data integration plans. Section 6 describes a set of crucial optimizations and extensions we contributed to the rewriting algorithm at the core of our approach, in order to make it scale to our polystore setting; we formalize the guarantees on this algorithm in Section 7. We present our experimental evaluation in Section 8, discuss related work in Section 9 then conclude in Section 10.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">PROBLEM STATEMENT</head><p>We assume a set of data model-query language pairs P = {(M 1 , L 1 ), (M 2 , L 2 ), . . .} such that for each 1 ≤ i, an L i query evaluated against an M i instance returns an answer which is also an M i instance. The same model may be associated to several query languages; for instance, AsterixDB, MongoDB and Postgres have different query languages for JSON. As we shall see, we consider expressive languages for realistic settings, supporting conjunctive querying, nesting, aggregation, and object creation. Without loss of generality, we consider that a language is paired with one data model only. We consider an integration language IL, capable of expressing computations to be made within each store and across all of them, as follows:</p><p>• For every store S and query q S ∈ L ′ S , IL allows specifying that q S should be evaluated over S; • Further, IL allows expressing powerful processing over the results of one or several such source queries. Such integration language has been proposed in several works <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b35">36]</ref>; we use it to express computations over the views. An IL expression bears obvious similarities with an execution plan in a wrapper-mediator system; its evaluation is split between computations pushed to the stores, and subsequent operations applied by the mediator on top of their results. The main distinction is that IL remains declarative, abstracting the details of each in-store computation, which is simply specified by a query in the store's language.</p><p>We assume available a cost model which, given an IL expression e, returns an estimation of the cost of evaluating e (including the cost of its source sub-queries). The cost may reflect e.g., disk I/O, memory needs, CPU time, transfer time between distributed sites etc. We outline the concrete model we use in Appendix K.</p><p>We term rewriting of a query q an integration query expressed in IL, which is equivalent to q. We consider the following rewriting problem: Definition 1 (Cross-model rewriting problem). Given a query q ∈ IL over several datasets D i , 1 ≤ i ≤ n, and a set of views V materialized over these datasets, find the equivalent rewriting r of q using the views, which minimizes the cost estimation c(r ).</p><p>Most modern query languages include such primitives as arithmetic operations, aggregation, and calls to arbitrary UDFs; these suffice to preclude decidability of checking whether two queries are equivalent. We therefore aim at finding rewritings under blackbox (uninterpreted) function semantics (UFS): we seek rewritings that make the same function calls, with the same arguments as the original query.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">OVERVIEW AND ARCHITECTURE</head><p>We outline here our approach for solving the above problem.</p><p>Our integration language: QBT XM . We devised QBT XM , a concrete integration language which supports queries over several data stores, each with its own data model and query language. QBT XM follows a block-based design, with blocks organized into a tree in the spirit of the classical Query Block Trees (QBT) introduced in System R <ref type="bibr" target="#b48">[49]</ref>, slightly adapted to accommodate subsequent SQL developments, in particular, the ability to nest sub-queries within the select clause <ref type="bibr">[31]</ref>. The main difference in our setting is that each block may be expressed in a different query language and carry over data of a different data model (e.g., SQL for relational data, key-based search API for key-value data, different JSON query languages etc.). We call the resulting language QBT XM , for cross-model QBT (detailed in Section 4.2). QBT XM views. Each materialized view V is defined by an QBT XM query; it may draw data from one or several data sources, of the same or different data models. Each view returns (holds) data following one data model, and is stored in a data store supporting that model.</p><p>Encoding into a single pivot model. We reduce the cross-model rewriting problem to a single-model setting, namely relational constraint-based query reformulation, as follows (see also Figure <ref type="figure" target="#fig_0">1</ref>; yellow background identifies the areas where we bring contributions in this work.). First, we encode relationally the structure of original data sets, the view specifications and the application query.</p><p>Note that the relations used in encoding are virtual, i.e., no data is migrated into them; they are also hidden, i.e., invisible to both the application designers and to users. They only serve to support query rewriting via relational techniques.</p><p>The virtual relations are accompanied by integrity constraints that reflect the features of the underlying data models (for each model M, a set enc(M) of constraints). For instance, we describe the organization of a JSON document data model using a small set of relations such as Node(nID, name), Child(pID, cID), Descendant(aID, dID), etc. together with the constraints specifying that every node has just one parent and one tag, that every child is also a descendant, etc. Such modeling had first been introduced in local-as-view XML integration works <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b40">41]</ref>. The constraints are tuple-generating dependencies (tgds) or equality-generating dependencies (egds) <ref type="bibr" target="#b4">[5]</ref>, extended with such well-researched constraints as denial constraints <ref type="bibr" target="#b24">[25]</ref> and disjunctive constraints <ref type="bibr" target="#b23">[24]</ref>. We detail the pivot model in Section 5.1.</p><p>Reduction from cross-model to single-model rewriting. Our reduction translates the declaration of each view V to additional constraints enc(V ) that reflect the correspondence between V 's input data and its output. Constraints have been used to encode single-model views <ref type="bibr" target="#b16">[17]</ref> and correspondences between source and target schemas in data exchange <ref type="bibr" target="#b19">[20]</ref>. The novelty here is the rich collection of supported models, and the cross-model character of the views.</p><p>An incoming query Q over the original datasets DS 1 , . . . , DS l , whose data models respectively are M 1 , . . . , M l , is encoded as a relational query enc(Q) over the dataset's relational encoding. enc(Q) is centered around conjunctive queries, with extensions such as aggregates, UDFs, nested sub-queries, disjunction and negation.</p><p>The reformulation problem is thus reduced to a purely relational setting: given a relational query enc(Q), a set of relational integrity constraints encoding the views, enc(V 1 ) ∪ . . . ∪ enc(V n ), and the set of relational constraints obtained by encoding the data models M 1 , . . . , M l , find the queries RW i r expressed over the relational views, for some integer k and 1 ≤ i ≤ k, such that each RW i r is equivalent to enc(Q) under these constraints.</p><p>The challenge in coming up with the reduction consists in designing a faithful encoding, i.e., one in which rewritings found by (i) encoding relationally, (ii) solving the resulting relational reformulation problem, and (iii) decoding each reformulation RW i r into a QBT XM query R = dec(RW i r ) over the views in the polystore, correspond to rewritings found by solving the original problem. That is, R is a rewriting of Q given the views {V 1 , . . . , V n } if R = dec(RW i r ), where RW i r is a relational reformulation of enc(Q) under the constraints obtained from encoding V 1 , . . . , V n , M 1 , . . . , M l . The reduction is detailed in Sections 5.2 and 5.3.</p><p>Relational rewriting using constraints. To solve the singlemodel rewriting problem, we need to reformulate relational queries under constraints. The algorithm of choice is known as Chase &amp; Backchase (C&amp;B, in short), introduced in <ref type="bibr" target="#b14">[15]</ref> and improved in <ref type="bibr" target="#b29">[30]</ref> to yield the Provenance-Aware C&amp;B algorithm (PACB, in short). PACB was designed to work with relatively few views and constraints. In contrast, in the polystore setting, each of the many datasources is described by a view, and each view is encoded by many constraints. For instance, the JSON views in our experiments (Section 8) are encoded via ~45 tgds involving 10-way joins in the premise. To cope with this complexity, we incorporated into PACB novel scale-up techniques (discussed in Section 6.1). PACB was designed for conjunctive queries under set semantics. Towards supporting a richer class of queries, we extended it to bag semantics (Section 6.2) and QBTs (Section 6.3).</p><p>Decoding the relational rewritings. On each relational reformulation RW i r issued by our modified PACB rewriting, a decoding step dec(RW i r ) is performed to: (i) Group the reformulation atoms by the view they pertain to; for instance, we infer that the three atoms Document(dID, "file.json"), Root(dID, rID), Child(rID, cID), Node(cID, book) refer to a single JSON document by following the connections among nodes and knowledge of the JSON data model.</p><p>(ii) Reformulate each such atom group into a query which can be completely evaluated over a single view.</p><p>(iii) If several views reside in the same store, identify the largest subquery that can be delegated to that store, along the lines of query evaluation in wrapper-mediator systems <ref type="bibr" target="#b25">[26]</ref>.</p><p>Evaluation of non-delegated operations. A decoded rew-riting may be unable to push (delegate) some query operations to the store hosting a view, if the store does not support them; for instance, most key-value and document stores do not support joins. Similarly, if a query on structured data requests the construction of new nested results (e.g., JSON trees) and if the data is in a store that does not support such result construction natively, it will have to be executed outside of that store. To evaluate such "last-step" operations, we rely on a lightweight execution engine <ref type="bibr" target="#b9">[10]</ref>, which uses a nested relational model and supports bind joins <ref type="bibr" target="#b47">[48]</ref> (with sideways information passing) to evaluate nested subqueries. Our engine can be easily replaced with another similar execution engine; we exemplify this with BigDAWG <ref type="bibr" target="#b17">[18]</ref> in Section 8.1.2.</p><p>Choice of the most efficient rewriting. Decoding may lead to several rewritings R 1 , . . . , R k ; for each R i , several evaluation plans may lead to different performance. The problem of choosing the best rewriting and best evaluation plan in this setting recalls query optimization in distributed mediator systems <ref type="bibr" target="#b43">[44]</ref>. For each rewriting R i , we denote by c(R i ) the lowest cost of an evaluation plan that we can find for R i ; we choose the rewriting R best that minimizes this cost. While devising cost models for polystore settings is beyond the scope of this paper, we architected ESTOCADA to take the cost model as configuration parameter.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">THE QBT XM LANGUAGE</head><p>We present here the language we use for views and queries. First, we recall the classical Query Block Trees (QBTs), then we extend them to cross-model views and queries.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Query Block Trees (QBT)</head><p>Since many of the languages ESTOCADA supports allow for nested queries and functions (user-defined or built-in such as aggregates), our pivot language Query Block Trees (QBTs) also supports these features. These are essentially the classical System R QBTs <ref type="bibr" target="#b48">[49]</ref>, slightly adapted to accommodate subsequent SQL extensions, such as nesting in the select clause (introduced in SQL-1999 <ref type="bibr">[31]</ref>). We first illustrate QBTs on a SQL example.</p><p>Example 1. Consider the following SQL query which computes, for each student who is not enrolled in any course for the Spring'16 quarter, the number of Spring'16 courses she is waitlisted for (a count of 0 is expected if the student is not waitlisted). While this query could be written using joins, outer joins and group by operations, we show a natural alternative featuring nesting (which illustrates how we systematically normalize away such operations): □</p><p>The variables occurring in a block B can be either defined by B (in which case we call them bound in B), or by one of its ancestors (in which case they are called free in B). We assume w.l.o.g. that the bound variables of B have fresh names, i.e., they share no names with variables bound in B's ancestors.</p><p>Example 2. In Example 1, variable s is bound in B 0 , but it occurs free in both B 00 and B 01 . □</p><p>QBTs model select-from-where expressions as blocks, organized into a tree whose parent-child relationship reflects block nesting. Nested blocks always appear as arguments to functions, be they built-in (e.g., COUNT for B 00 and NOT EXISTS for B 01 in Example 1) or user-defined. While not shown in Example 1, the case of blocks nested within the FROM clause corresponds to the identity function.</p><p>As we will show, we use QBTs to translate relationally application queries written in other models, but also (potentially crossmodel) views and rewritings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Integration Language: QBT XM</head><p>To specify cross-model queries and views, we adopted a block-based design, similar to QBTs, but in which each block is expressed in its own language, signaled by an annotation on the block. We call the resulting language QBT XM , which stands for cross-model QBT.</p><p>QBT XM queries comprise a FOR and a RETURN clause. The FOR clause introduces several variables and specifies their legal bindings. The RETURN clause specifies what data should be constructed for each binding of the variables. Variables can range over different data models, which is expressed by possibly several successive blocks, each pertaining to its own model. In SQL style, this defines a Cartesian product of the variable bindings computed by each block from the FOR clause; this Cartesian product can be filtered through WHERE clause. We impose the restriction that variables shared by blocks spanning different data models must be of text or numeric type, so as to avoid dealing with conversions of complex values across models. While there is no conceptual obstacle to handle such conversions automatically, the topic is beyond the scope of this paper. We describe QBT XM informally, by examples; the grammar of QBT XM is delegated to Appendix I.</p><p>Example 3. We illustrate the QBT XM definition of views V 1 and V 2 from Section 1, using AsterixDB's SQL++ syntax (easier to read than the JSON syntax of Postgres):</p><formula xml:id="formula_0">View V 1 : FOR AJ :{ SELECT M . patientID AS patientID , A . admissionID AS admissionID , A . report AS report FROM MIMIC M , M . admissions A } RETURN SJ :{ " patientID " : patientID , " admissionID " : admissionID , " report " : report } View V 2 : FOR AJ :{ SELECT M . patientID AS patientID ,</formula><p>A . admissionID AS admissionID , A . admissionLoc AS admissionLoc A . admissionTime AS admissionTime FROM MIMIC M , M . admissions A } RETURN PR :{ patientID , admissionID , admissionLoc , admissionTime } □ FOR clauses bind variables, while RETURN clauses specify how to construct new data based on the variable bindings. Blocks are delimited by braces annotated by the language whose syntax they conform to. The annotations AJ, PR and SJ stand for the SQL++ language of AsterixDB and the languages of Postgres and Solr, respectively. Also, below, PJ and RK stand respectively for Postgres' JSON query language, and for a simple declarative key-value query language we designed for Redis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">REDUCTION FROM CROSS-MODEL TO SINGLE-MODEL SETTING</head><p>A key requirement in our setting is the ability to reason about queries and views involving multiple data models. This is challenging for several reasons. First, not every data model/query language setting supported in ESTOCADA comes with a known view-based query rewriting (VBQR, in short) algorithm: consider key-value pairs as data model and declarative languages over them, or JSON data and its query languages in circulation, etc. Second, even if we had these algorithms for each model/language pair, neither would readily extend to a solution of the cross-model VBQR setting in which views may be defined over data from various models, materializing their result in yet again distinct models, and in which query rewritings access data from potentially different models than the original query. Third, for the feasibility of development and maintenance as the set of supported model/language pairs evolves, any cross-model VBQR solution needs to be modularly extensible to additional models/languages, in the sense that no modification to the existing code is required and it suffices to just add code dealing with the new model/language pair. Moreover, the developer of this additional code should not need to understand any of the other model/language pairs already supported in ESTOCADA.</p><p>To address these challenges, we reduce the cross-model VBQR problem to a single-model VBQR problem. That is, we propose a unique pivot data model (Section 5.1), on which QBT (Section 4.1) serves as a pivot query language. Together, they allow us to capture data models, queries and views so that cross-model rewritings can be found by searching for rewritings in the single-model pivot setting instead. Section 5.1 presents the pivot model; then, Section 5.2 presents query encoding in the pivot language, Section 5.3 shows how to encode views as constraints, finally Section 5.4 describes the decoding of rewriting into integration plans.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">The Pivot Model</head><p>Our pivot model is relational, and it makes prominent use of expressive integrity constraints. This is sufficiently expressive to capture the key aspects of the data models in circulation today, including: freely nested collections and objects, object identity (e.g., for XML element nodes and JSON objects), limited binding patterns (as required by key-value stores and full-text indexes such as Lucene/Solr), relationships (in the E/R and ODL sense), functional dependencies and much more. The integrity constraints we use are tuple-generating dependencies (tgds) or equality-generating dependencies (egds) <ref type="bibr" target="#b4">[5]</ref>, extended to denial constraints <ref type="bibr" target="#b24">[25]</ref> and disjunctive constraints <ref type="bibr" target="#b23">[24]</ref>.</p><p>JSON. We represent JSON documents as relational instances conforming to the schema VREJ (Virtual Relational Encoding of JSON) in Table <ref type="table">2</ref>. We emphasize that these relational instances are virtual, i.e., the JSON data is not stored as such. Regardless of the JSON data's physical storage, we only use VREJ to encode JSON queries relationally, in order to reason about them. VREJ constraints express the fact that JSON databases are organized into named collections of JSON values, which in turn can be objects (consisting of a set of key-value pairs), arrays of values, and scalar values (numeric or text). We model objects, arrays and values in Collection J (name, id) Child J (parentId, childId, key, type) Eq J (x, y) V alue J (x, y) Table <ref type="table">2</ref>: Snippet of VREJ an object-oriented fashion, i.e. they have identities. This is because some JSON stores, e.g., MongoDB and AsterixDB, support query languages that refer to identity and/or distinguish between equality by value versus equality by identity. Our modeling supports both the identity-aware and the identity-agnostic view of JSON, via appropriate translation of queries and views into pivot language expressions over the VREJ schema. Relation Collection J attaches to each persistent name the id of an array. Value J attaches a scalar value to a given id. Child J states that the value identified by childId is immediately nested within the value identified by parentId. The type attribute records the type of the parent (array "a" or object "o") and determines the kind of nesting and the interpretation of the key attribute: if the parent is an array, key holds the position at which the child occurs; if the parent is an object, then key holds the name of the key whose associated value is the child.</p><p>Our modeling of parent-child (immediate nesting) relationship between JSON values provides the type of value only in conjunction with a navigation step where this value is a parent, and the step leads to a child value of undetermined type. This modeling reflects the information one can glean statically (at query rewriting time, as opposed to query runtime) from JSON query languages in circulation today. Recall that JSON data is semi-structured, i.e., it may lack a schema. Queries can, therefore, express navigation leading to values whose type cannot be determined statically if these values are not further navigated into. The type of a value can be inferred only from the type of navigation step into it.</p><p>Example 4. If a query navigation starts from a named JSON collection "coll" and proceeds to the fifth element e therein, we can infer that "coll" is of array type, but we do not know the type of e. Only if the query specifies an ensuing lookup of the value v associated to key "k" in e can we infer e's type (object). However, absent further navigation steps, we cannot tell the type of the child value v. □ Finally, relation Eq J is intended to model value-based equality for JSON (id-based equality is captured directly as equality of the id attributes).</p><p>We capture the intended meaning of the VREJ relations via constraints that are inherent in the data model (i.e. they would hold if we actually stored JSON data as a VREJ instance). We illustrate a few of these below; following convention, free variables are to be read as universally quantified.</p><p>The fact that a persistent name uniquely refers to a value is expressed by the egd (1) below. Egd <ref type="bibr" target="#b1">(2)</ref> states that an object cannot have two distinct key-value pairs sharing the same key, or that an array cannot have two distinct elements at the same position. Tgds (3) and ( <ref type="formula">4</ref>) state that value-based equality is symmetric, respectively transitive, and tgd <ref type="bibr" target="#b4">(5)</ref> states that value-equal parents must have value-equal children for each parent-child navigation step. Egd <ref type="bibr" target="#b5">(6)</ref> states that no two distinct scalar values may correspond to a given id.</p><formula xml:id="formula_1">Collection J (n, x) ∧ Collection J (n, y) → x = y (1) Child J (p, c 1 , k, t) ∧ Child J (p, c 2 , k, t) → c 1 = c 2</formula><p>(2) Eq J (x, y) → Eq J (y, x)</p><p>(3) Eq J (x, y) ∧ Eq J (y, z) → Eq J (x, z) (4)</p><formula xml:id="formula_2">Eq J (p, p ′ ) ∧ Child J (p, c, k, t) → ∃c ′ Eq J (c, c ′ ) ∧ Child J (p ′ , c ′ , k, t) (5) V alue J (i, v 1 ) ∧ V alue J (i, v 2 ) → v 1 = v 2 (6)</formula><p>Key-Value Store Model. Our interpretation of the key-value pairs model is compatible with many current systems, in particular Redis, supported by ESTOCADA. Calling a map a set of key-value pairs, the store accommodates a set of persistently named maps (called outer maps). Within each outer map, the value associated to a key may be either itself a map (called an inner map), or a scalar value. In case of an inner map, the value associated to a key is a scalar value.</p><p>Given the analogy between key-value and JSON maps, we model the former similarly to the latter, as instances of the relational schema VREK, consisting of the relations: Map KV (name, mapId), Child KV (parentId, childId, key, type) and Eq KV (x, y). Here, Map KV models the association between a persistent name and (the id of) an outer map. Child KV reflects the immediate nesting relationship between a map (the parent) and a value associated to one of its keys (the child). The type attribute tells us whether the parent map is an outer or an inner map (these are treated asymmetrically in some systems). The Eq KV relation models value-based equality, analogously to EQ J for JSON.</p><p>The intended semantics of these relations is enforced by similar constraints to the JSON model, e.g., in a map, there is only one value for a key (Child KV (p, c 1 , k, t), Child KV (p, c 2 , k, t) → c 1 = c 2 ), persistent map names are unique (Map KV (n, x), Map KV (n, y) → x = y) etc.</p><p>XML. Query reformulation for XML has already been reduced in prior work to a purely relational setting using constraints. We refer the reader to <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b16">17]</ref>.</p><p>Relational. It is well known that the relational data model endowed with key, uniqueness and foreign key constraints is captured by our pivot model: key/uniqueness constraints are expressible by egds, and foreign key constraints by tgds.</p><p>Binding Patterns. We have seen above a natural way to model sets of key-value pairs using a relation. To simplify the discussion, we abstract from the parentId and type attributes of relation Child KV above, focusing on the binary relationship between keys and values: KV (key, value). Note that typical key-values store APIs require that values can be looked up only given their key, but not conversely. If we do not capture this limitation, the rewriting algorithm may produce rewritings that correspond to no executable plan. For instance, consider a rewriting of the form: R(v) : -KV (k, v). R corresponds to no legal plan given the access limitation of KV, because R requires the direct extraction of all values stored in the store, without looking them up by key.</p><p>This setting involving relations with limited lookup access is well-known in the literature, and is modeled via the concept of relations adorned with binding patterns <ref type="bibr" target="#b47">[48]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Towards Scalable Hybrid Stores , ,</head><p>In a relational setting, query rewriting when access to the views is limited by binding patterns has been studied for conjunctive queries and views <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b41">42]</ref>, yet complete rewriting under both integrity constraints and binding patterns was not considered until <ref type="bibr" target="#b12">[13]</ref>. <ref type="bibr" target="#b12">[13]</ref> shows how to encode binding patterns using tgd constraints, which fit into our pivot model. The idea is to introduce a unary relation, say A(x) to state that x is accessible, and for each binding pattern a tgd stating that when all required input attributes of a relation are accessible, then the output attributes are accessible as well. This allows the chase with such tgds to determine which attributes of a rewriting are accessible.</p><p>Nulls, Equality and Aggregation. Different stores exhibits wide variability in the treatment of nulls <ref type="bibr" target="#b44">[45]</ref>, thus equality and aggregation semantics may differ across stores. To account for this, by default we use distinct null constants, distinct aggregate functions and distinct equality relationships for the relational encoding of distinct stores. For instance, the sum aggregate of language L 1 is not automatically equated to the sum of L 2 , since the two may treat nulls differently. When the null treatment coincides totally (e.g., for distinct but SQL-compliant RDBMS stores), we use a single common encoding. When it coincides only partially, we encode as much as possible with constraints. For instance the tgd eq 1 (null 1 , x) → eq 2 (null 2 , x) states that if a value x is equal to null in System 1's interpretation of null and equality, this holds also in System 2's interpretation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>MIMIC ( M ) ,</head><p>Child J (M , patientID , " patientID " ," o " ) , Child J (M ,A , " admissions " ," o " ) , Child J (A , admissionID , " admissionID " ," o " ) , Child J (A , admissionLoc , " admissionLoc " ," o " ) , Child J (A , admissionTime , " admissionTime " ," o " ), Child J (A , report , " reports " ," o " ) -&gt; V 2 ( patientID , admissionID , admissionLoc , admissionTime ) The purpose of the pivot language is to reduce the VBQR problem to a single-model setting. The pivot model enables us to represent relationally queries expressed in the various languages supported in our system (recall Table <ref type="table" target="#tab_0">1</ref>), and which can be combined into a single QBT XM query. As shown in Figure <ref type="figure" target="#fig_0">1</ref>, an incoming query Q is encoded as a relational conjunctive enc(Q) over the relational encoding of the datasets it refers to (with extensions such as aggregates, user-defined functions, nested queries, disjunction and negation).</p><p>Figure <ref type="figure" target="#fig_3">3</ref> shows the QBT XM query Q 1 of the motivating scenario, and its relational encoding enc(Q 1 ) appears in Appendix A.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Encoding QBT XM Views as Constraints</head><p>We translate each view definition V into additional relational integrity constraints enc(V ) showing how the view inputs are related to its output. Figure <ref type="figure" target="#fig_2">2</ref> illustrates the relational encoding of QBT XM view V 2 from Section 4 (for space reasons, similar constraints resulting from V 1 and V 2 appear in Appendix B. Due to space limitation, we omit the constraints for V 3 from this version of the paper).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">From Rewritings to Integration Plans</head><p>We translate each query rewriting into a logical plan specifying (i) the (native) query to be evaluated within each store, and (ii) the  Based on the heuristic that the store where a view resides is more efficient than the mediator, and thus it should be preferred for all the operations it can apply, decoding tries to delegated to the stores as much as possible. To that end, it first partitions each rewriting RW r into view-level subqueries, which are sets of atoms referring to the virtual relations of a same view. If a group of view-level subqueries pertains to the same store and if the store supports joins, we translate the group to a single query to be pushed to the store.</p><formula xml:id="formula_3">RW Q 1 &lt; patientID , drug , admissionLoc , admissionTime &gt;: - V 1 (d 1 ) , Child J V 1 (d 1 , patientID , " patientID " ," o " ) , Child J V 1 (d 1 , admissionID , " admissionID " ," o " ) , Child J V 1 (d 1 , report , " report " ," o " ) ,</formula><p>V alue J ( report , " like -coronary artery " ) ,</p><p>V 2 ( patientID , admissionID , admissionLoc , admissionTime ) ,</p><formula xml:id="formula_4">V 3 (d 2 ) ,</formula><p>Child J V 3 (d 2 , patientID , " patientID " ," o " ) , Child J V 3 (d 2 ,A , " admission " ," o " ) , Child J V 3 (A , admissionID , " admissionID " ," o " ) , Child J V 3 (A , drugs , " drugs " ," o " ) , Child J V 3 ( drugs , drug , " drug " ," o " ) , Child J V 3 ( drugs , drugtype , " drugtype " ," o " ) , V alue J ( drugtype , " additive " )</p><formula xml:id="formula_5">Figure 4: Rewriting RW Q 1 of QBT XM query Q 1</formula><p>Example 5 (Delegation-Aware Decoding). Consider the rewriting RW Q 1 of QBT XM query Q 1 shown in Figure <ref type="figure">4</ref>. First, we delimit the view-wide subqueries (delimited by empty lines in the figure), calling them RW Q 1  1 , RW Q 2 1 and RW Q 3 1 in order from the top. The subquery heads contain variables from the head of RW Q 1 , as well as join variables shared with other subqueries. For example, the head of RW Q 2 1 contains the variables admissionLoc and admissionT ime (in the head of RW Q 1 ), and also patientID, admissionID, needed to join with RW Q 1  1 , and RW Q 3 1 . These relational subqueries are then decoded to the native syntax of their respective stores, each constituting a block of the resulting QBT XM rewriting dec(RW Q 1 ) (shown in Appendix C). □ ESTOCADA's plan generator next translates the decoded QBT XM rewriting to a logical plan that pushes leaf blocks to their native store, applying last-step operators on the results. The integration plan for RW Q 1 is shown in Figure <ref type="figure">5</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">PACB OPTIMIZATION AND EXTENSION</head><p>We detail below just enough of the PACB algorithm's inner working to explain our optimization. Then, Section 6.1 introduces our optimization in the original PACB setting (conjunctive relational queries and set semantics). Section 6.2 extends this to bag semantics, Section 6.3 extends it to QBT XM .</p><p>A key ingredient of the PACB algorithm is to capture views as constraints, in particular tgds, thus reducing the view-based rewriting problem to constraints-only rewriting. For a given view V , the constraint V I O states that for every match of the view body against the input data there is a corresponding tuple in the view output; the constraint V O I states the converse inclusion, i.e., each view tuple is due to a view body match. Then, given a set V of view definitions, PACB defines a set of view constraints</p><formula xml:id="formula_6">C V = {V I O , V O I | V ∈ V}.</formula><p>The constraints-only rewriting problem thus becomes: given the source schema σ with a set of integrity constraints I, a set V of view definitions over σ and the target schema τ which includes V, given a conjunctive query Q expressed over σ , find reformulations ρ expressed over τ that are equivalent to Q under the constraints I ∪ C V .</p><p>For instance, if σ = {R, S }, I = ∅, τ = {V } and view V materializes the join of tables R and S, V (x, y) : -R(x, z), S(z, y), the constraints capturing V are:</p><formula xml:id="formula_7">V I O : R(x, z) ∧ S(z, y) → V (x, y) V O I : V (x, y) → ∃z R(x, z) ∧ S(z, y).</formula><p>For input σ -query Q(x, y) : -R(x, z), S(z, y), PACB finds the τreformulation ρ(x, y) : -V (x, y). Algorithmically, this is achieved by: (i) chasing Q with the set of constraints</p><formula xml:id="formula_8">I ∪ C I O V where C I O V = {V I O | V ∈ V};</formula><p>(ii) restricting the chase result to only the τ -atoms (the result is called the universal plan) U ;</p><p>(iii) chasing U with the constraints in I ∪ C O I V , where</p><formula xml:id="formula_9">C O I V = {V O I | V ∈ V};</formula><p>the result is denoted B and called the backchase; finally:</p><p>(iv) matching Q against B and outputting as rewritings those subsets of U that are responsible for the introduction (during the backchase) of the atoms in the image of Q. 2  In our example, I is empty, C I O V = {V I O }, and the result of the chase in phase (i) is Q 1 (x, y) : -R(x, z), S(z, y), V (x, y). The universal plan obtained in phase (ii) by restricting Q 1 to τ is U (x, y) : -V (x, y). The result of backchasing U with C O I V in phase (iii) is B(x, y) : -V (x, y), R(x, z), S(z, y) and in phase (iv) we find a match from Q's body into the R and S atoms of B, introduced during the backchase due to U 's atom V (x, y). This allows us to conclude that ρ(x, y) : -V (x, y) is an equivalent rewriting of Q.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">PACB opt : Optimized PACB</head><p>The idea for our optimization was sparked by the following observation. The backchase phase (step (iii)) involves the V O I constraints for all V ∈ V. The backchase attempts to match the left-hand side of each V O I for each V repeatedly, leading to wasted computation for those views that have no match. In a polystore setting, the large number of data sources and stores lead to a high number of views, most of which are often irrelevant for a given query Q.</p><p>This observation leads to the following modified algorithm. Define the set of views mentioned in the universal plan U as relevant to Q under I, denoted relev I (Q). Define the optimized PACB algorithm PACB opt identical with PACB except phase (iii) where PACB opt replaces</p><formula xml:id="formula_10">C O I V with C O I r el ev I (Q ) .</formula><p>That is, PACB opt performs the backchase only with the OI -constraints of the views determined in phase (i) to be relevant to Q, ignoring all others. This modification is likely to save significant computation when the polystore includes many views. In our example assume that, besides V , V contained 1000 other views {V i } 1≤i ≤1000 , each irrelevant to Q. Then the universal plan obtained by PACB would be the same as U above, and yet {V i O I } 1≤i ≤1000 would still be considered by the backchase phase, which would attempt at every step to apply each of these 1000 constraints. In contrast, PACB opt would save this work.</p><p>In general, ignoring even a single constraint c during backchase may lead to missed rewritings <ref type="bibr" target="#b46">[47]</ref>. This may happen even when c mentions elements of schema σ that are disjoint from those mentioned in U , if the backchase with I exposes semantic connections between these elements. In our setting, we prove that this is not the case: Theorem 6.1. Algorithm PACB opt finds the exact same rewritings as the original PACB. This is because we only ignore some view-capturing constraints, which can be shown (by analysing the backchase evolution) never to apply, regardless of the constraints in I. Combined with the main result from <ref type="bibr" target="#b29">[30]</ref>, Theorem 6.1 yields the completeness of PACB opt in the following sense: Corollary 6.2. Whenever the chase of input conjunctive query Q with the constraints in I terminates 3 , we have: 2 Recall that a chase step s with constraint c matches c's premise against existing atoms e and adds new atoms n corresponding to c's conclusion. To support fast detection of responsible atoms in Phase (iv ), s records that the e atoms are responsible for the introduction of the n atoms <ref type="bibr" target="#b29">[30]</ref>. Our optimization does not affect Phase (iv ). 3 Termination of the chase with tgds is undecidable <ref type="bibr" target="#b13">[14]</ref>, but many sufficient conditions for termination are known, starting with weak acyclicity <ref type="bibr" target="#b18">[19]</ref>. Our constraints are chosen so as to ensure termination. In Section 8.2, we evaluate the performance gains of PACB opt over the original PACB, measuring up to 40x speedup when operating in the polystore regime.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Extending PACB opt to Bag Semantics</head><p>We extended PACB opt to find equivalent rewritings of an input conjunctive query under bag semantics (the original PACB only addresses set semantics). The extension involves a modification to phase (iv). In its original form, the matches from Q into the backchase result B are not necessarily injective, being based on homomorphisms <ref type="bibr" target="#b4">[5]</ref>. These allow multiple atoms from Q to map into the same atom of B. To find bag-equivalent rewritings, we disallow such matches, requiring match homomorphisms to be injective.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">PACB opt qbt : Extending PACB opt to QBTs</head><p>The original PACB algorithm (and our extensions thereof) have so far been defined for conjunctive queries only. However, recall that QBTs (Section 4.1) are nested.</p><p>We extend the PACB opt algorithm to nested QBTs as follows. Each block B is rewritten in the context of its ancestor blocks A 1 , . . . , A n , to take into account the fact that the free variables of B are instantiated with the results of the query corresponding to the conjunction of its ancestor blocks. We therefore replace B with the rewriting of the query </p><formula xml:id="formula_11">A 1 ∧ A 2 ∧ . . . ∧ A n ∧ B.</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">GUARANTEES ON THE REDUCTION</head><p>We provide the following formal guarantees for our solution to the cross-model rewriting problem based on the reduction to singlemodel rewriting. Recall from Section 3 that enc(M) are the relational constraints used to encode M ∈ M in virtual relations, enc(Q) encodes a QBT XM query Q as a QBT query over the virtual relations, and dec(R) decodes a QBT query over the virtual relations into a QBT XM query. Also recall from Section 6 that given a set V of QBT XM views, C V are the relational constraints used to capture V. We have: Theorem 7.1 (Soundness of the reduction). Let Q be a QBT XM query over a polystore over the set of data models M. Let I be a set of integrity constraints satisfied by the data in the polystore and enc(I) be their relational encoding.</p><p>For every rewriting R obtained via our reduction, i.e. 4 A rewriting of Q is join-minimal if none of its joins can be removed while preserving equivalence to Q .</p><formula xml:id="formula_12">R = dec( PACB opt qbt ⟨enc(I) ∪ M ∈M enc(M) ∪ C V , c⟩(enc(Q)) ),</formula><p>R is a c-optimal V-based rewriting equivalent to Q under I, assuming black-box function semantics (Section 2).</p><p>In the above, enc(I) ∪ M ∈M enc(M) ∪ C V is the set of constraints used by the PACB opt qbt algorithm; Theorem 7.1 states the correction of our approach, outlined in Figure <ref type="figure" target="#fig_0">1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">EXPERIMENTAL EVALUATION</head><p>Below, we describe experiments demonstrating the efficiency and effectiveness of our cross-model rewriting technique.</p><p>Hardware Platform. We used commodity cluster machines with an Intel(R) Xeon(R) CPU E5-2640 v4 @ 2.40GHz, 40Cores, 123GB RAM, disk read speed 616 MB/s, and disk write speed 455 MB/s (interesting since some systems, e.g., AsterixDB, write intermediate results to disk).</p><p>Polystore Configuration. For our main polystore setting (called "ESTOCADA polystore engine" hereafter) we use <ref type="bibr" target="#b9">[10]</ref> as a lightweight execution engine and a set of data stores, selected for their capabilities and popularity: an RDBMS (Postgres v9.6), JSON document stores (Postgres v9.6, MongoDB v4.0.2) and AsterixDB v4.9, SparkSQL v2.3.2 and a text search engine (Solr v6.1). We set a 60GB buffer cache for all systems, we configured the number of utilizable cores to 39, and we assigned 8GB to the working memory (the default for Postgres). We set AsterixDB's compiler frame size (the page size for batch query processing) to 6MB.</p><p>Dataset. We used the real-life 46.6 GB MIMIC-III dataset <ref type="bibr" target="#b32">[33]</ref> described in Section 1.1.</p><p>Generating Query and View Families. We created a polystore benchmark based on MIMIC as follows.</p><p>We defined a set QT of 25 query templates, each checking meaningful conditions against a patient's data. These are parameterized by the patient id and by other selection constants, and they involve navigation into the document structure. Each query/view is obtained by joining a subset of QT and picking values for the selection constants, leading to an exponential space of meaningful queries and views. Among them, we identified those with nonempty results: first, non-empty instantiations of QT queries, then joins of two such queries, then three etc., in an adaptation of the Apriori algorithm <ref type="bibr" target="#b6">[7]</ref>. Example 6. Consider the query templates QT 0 , QT 1 and QT 2 in Appendix H, shown directly in relationally encoded form. QT 0 asks for patients' information including patient's PATIENTID, DOB, GENDER and DOD (if available). QT 1 asks for all "abnormal" lab measurement results for patients. QT 2 asks for bloodwork-related lab measurements. The natural join of QT 0 , QT 1 and QT 2 yields a query Q which seeks information on patients with abnormal blood test results. □ The Queries. We chose 50 queries Q EX P among those described above (we show examples in Appendixes D, E, F and G). 58% of the queries (Q 01 , . . . ,Q 29 ) contain full-text operations; all involve joins, selections, and at least two-level-deep navigation into the JSON document structure.</p><p>The Views. We materialized a set of views V EX P as follows.</p><p>We stored in Postgres 6 relational views V Postдr eSQ L ⊂ V EX P of the MIMIC-JSON dataset, comprising the uniformly structured part of the dataset (including all patient chart data and admission under specific services such as Cardiac Surgery, Neurologic Medical, etc). We also stored in Postgres a set V P ostдr es J SO N ⊂ V EX P of 21 views which are most naturally represented as nested JSON documents. These views store for instance: (i) lab tests conducted for each patient with "abnormal" test results (e.g., blood gas, Cerebrospinal Fluid (CSF)); (ii) data about drugs prescribed to patients sensitive to certain types of antibiotics (e.g., CEFEPIME); (iii) data about drugs and lab test prescribed to each patient who underwent specific types of procedures (e.g.,carotid endarterectomy); (iv) microbiology tests conducted for each patient; (v) lab tests for each patient who was prescribed certain drug types (e.g. additive, base); etc. We placed in Solr a view V Sol r ∈ V EX P , storing for each patient the caregivers' reports (unstructured text). The usage of AsterixDB, SparkSQL and MongoDB is detailed below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.1">Cross-Store Rewritings Evaluation</head><p>We study the effectiveness of ESTOCADA cross-store query rewriting: (i) compared to single-store query evaluation (Section 8.1.1); (ii) improving performance in the pre-existing polystore engines: BigDAWG <ref type="bibr" target="#b17">[18]</ref> and ESTOCADA polystore engine (Section 8.1.2). 8.1.1 Single-Store Evaluation Comparison. Figure <ref type="figure">8</ref> sh-ows the rewriting time for the query set and views described above. Notice that most queries are rewritten within 100ms and the few outliers require at most 190ms, which is negligible compared to the query execution time (in the order of minutes, as seen in Figures <ref type="figure">6</ref> and<ref type="figure">7</ref>). Figure <ref type="figure">9</ref> shows the distribution of rewriting time over the same query set when we scale up the number of relevant views (we did not materialize them) to 128 views (this is for stress-test purposes, as 128 views relevant to the data touched by a single query is unlikely).</p><p>Queries with Text Search Predicates. Figure <ref type="figure">6</ref> reports the total execution plus rewriting time of ESTOCADA using the above views for Q 01 to Q 29 , all of which feature a text search predicate against the text notes in the caregiver's report. For each query, cross-model rewriting and evaluation significantly outperforms direct evaluation in any single store. For MongoDB and Postgres, the execution time is correlated with the number of JSON array unnest operators. For instance, query Q 25 has 5 unnest operators whereas query Q 17 has 2. Postgres outperforms MongoDB because the latter lacks join-reordering optimization, and it does not natively support inner joins. These must be simulated by left outer joins -using the $lookup operator -followed by a selection for non-null values -using the $match operator.</p><p>Queries without Text Search Predicates. Figure <ref type="figure">7</ref> repeats this experiment for queries Q 30 ,. . . ,Q 50 , which do not perform text search. These queries each feature join, selection and navigation into the JSON document structure (at least two levels deep). The relevant views for these queries are V P ostдr eSQ L ∪V P ostдr es J SO N ; again, exploiting them outperforms single-store evaluation. Spark-SQL has the highest query execution time; this is because it only supports navigation into JSON arrays through the EXPLODE function, which is highly inefficient (see Appendix F for examples). AsterixDB is outperformed because its optimizer does not support join reordering. In single-store evaluation, Postgres is more efficient; this is why we chose it to store V P ostдr es J SO N .</p><p>Materializing All Views In a Single Store. We performed experiments showing that cross-model evaluation is more efficient than view-based single-store evaluation: on Postgres, for most of our queries; for the other systems, for all our queries. The details can be found in Appendix L.</p><p>8.1.2 Polystore Evaluation Comparison. We study the benefits that ESTOCADA can bring to an existing polystore system by transparently rewriting queries using materialized views stored across different stores. We used two polystore engines: (i) ESTO-CADA polystore engine instantiated with two Postgres servers (one stores relational data while the other stores JSON) and Solr v6.1 for storing text; (ii) the latest release of the BigDAWG polystore. A key BigDAWG concept is an island, or collection of data stores accessed with a single query language. BigDAWG supports islands for relational, array and text data, based on the Postgres, SciDB <ref type="bibr" target="#b3">[4]</ref> and Apache Accumulo <ref type="bibr" target="#b0">[1]</ref> stores, respectively. BigDAWG queries use explicit CAST operators to migrate an intermediary result from an island to another. To work with BigDAWG, we extended it with two new CAST operators: (i) to migrate Solr query results to Postgres; (ii) to migrate Postgres JSON query results to a Postgres relational instance and vice-versa. The main difference between our ESTO-CADA polystore engine and BigDAWG is that we join subquery results in the mediator using a BindJoin <ref type="bibr" target="#b47">[48]</ref>, whereas BigDAWG migrates such results to an island capable of performing the join (typically, a relational one).</p><p>Data Storage. We store the MIMIC-III dataset (in both systems) as follows: patient metadata in Postgres relational instance; caregivers' reports in Solr; patients' lab events, prescriptions, microbiology events, and procedures information in the Postgres JSON instance.</p><p>Polystore Queries. We rewrote Q 01 ,. . . , Q 29 in BigDAWG syntax, referring to each part of the data from its respective island (as BigDAWG requires); we refer to the resulting query set as Q BiдDAW G . Appendix J illustrates a BigDAWG query. We have the same set of queries in QBT XM syntax; we call these queries Q ESTOCADA P olyst or e .</p><p>The Views. To the view set V EX P introduced above, we have added a new set of views V N EW which can benefit Q BiдDAW G and Q ESTOCADA P olyst or e queries as we detail below.</p><p>The queries vary in terms of full-text search predicates selectivity. 60% of Q BiдDAW G and Q ESTOCADA queries consist of fulltext search predicates, which are not highly selective (e.g., "low blood pressure"). We refer to these queries as Q 60%</p><p>BiдDAW G and Q 60%</p><p>ESTOCADA Polystor e . We observed that the cost of such queries in BigDAWG is dominated by moving and ingesting the results of Solr queries in Postgres (relational instance) to join them with the results of other sub-queries. To alleviate this overhead, we materialized in the Postgres server storing JSON a set of 6 views V N EW , which join the data from Solr (using those full-text predicates in the views definitions) with JSON data from the Postgres JSON server.</p><p>Given the Q 60% BiдDAW G queries, V Postдr es J SO N , V Postдr esSQ L and V N EW , our cross-model views-based rewriting approach finds rewritings using views from Postgres (relational instance) and Postgres (JSON instance). The performance saving is due to the fact that we no longer have to move data from Solr to a relational Postgres instance (see Figure <ref type="figure" target="#fig_0">10</ref> for queries labeled *). Although ESTOCADA polystore engine does not require any data movement, it still benefits from utilizing V Postдr es J SO N , V Postдr esSQ L and V N EW to answer Q 60%</p><p>ESTOCADA Polystor e queries as shown in Figure <ref type="figure" target="#fig_0">10</ref> (queries labeled with *). In contrast, the remaining 40% of Q BiдDAW G and Q ESTOCADA Polystor e queries have highly selective full-text search predicates (we refer to these as queries Q 40% BiдDAW G and Q 40%</p><p>ESTOCADA Polystor e ). The high selectivity of these queries reduces the overhead of moving the data from Solr to Postgres (relational instance) in BigDAWG, and in general the data movement is not a bottleneck for these queries. However, both systems can benefit from the materialized views V EX P to evaluate these queries as shown in Figure <ref type="figure" target="#fig_0">10</ref> (queries labeled with +).</p><p>As mentioned earlier, ESTOCADA polystore engine and Big-DAWG differ in terms of multi-store join evaluation strategies, leading to different performance variations when the queries and/or views change. On the queries Q 60% BiдDAW G and Q 60% ESTOCADA Polystor e , where the full-text search predicates are not very selective, Big-DAWG execution time is dominated by moving partial results to the join server. In contrast, ESTOCADA polystore engine performs better since it computes the join in memory in the mediator, thus it does not need to pay the intermediary result storage cost. For the other 40% of queries (with very selective full-text search predicates), BigDAWG data movement cost is negligible, thus its evaluation time is dominated by evaluating the join between sub-queries results in the Postgres relational island, where join algorithms and orders may be better chosen than in the ESTOCADA polystore engine (the two platform support different sets of join algorithms). However, the differences are negligible. The main conclusion of this experiment, however, is that our cross model views-based rewriting approach improves performance in both polystore engines.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.2">PACB VS PACB opt</head><p>This experiment demonstrates the performance gains of PACB opt over PACB in a polystore setting. We consider the queries Q EX P and the 28 views V EX P that can be utilized to answer Q EX P , introduced above. We add to V EX P some irrelevant views V ir r el ⊆ (V -V EX P ).</p><p>We scale the size of V ir r el from 1000 to 4000. Figure <ref type="figure" target="#fig_0">11</ref> presents the average rewriting time of Q EX P in the presence of V EX P ∪V ir r el ; the y axis is in log scale.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.3">Summary of Experimental Findings</head><p>We have shown that our cross-model views-based rewriting approach is portable across polystore engines. Moreover, it is worthwhile, as it improves their performance in natural scenarios for both cross-model and even single-model user queries; the latter are outperformed by rewritings using a distributed cross-store (and cross-model) set of materialized views (even when accounting for the time it takes to find the rewriting). We have also shown that the time spent searching for rewritings is a small fraction of the query execution time and hence a worthwhile investment. As we confirm experimentally, the performance of the rewriting search is due to our optimized PACB opt algorithm, shown to outperform standard PACB by up to 40×.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9">RELATED WORK</head><p>Heterogeneous data integration is an old topic <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b40">41]</ref> addressed mostly in a single-model (typically relational) setting, where cross-model query rewriting and execution did not occur. The federated Garlic system <ref type="bibr" target="#b25">[26]</ref> considered true multi-model settings, but the non-relational stores did not support their own declarative query language (they included for instance text documents, spreadsheets, etc.), being instead wrapped to provide an SQL API. Consequently works on federated databases did not need crossmodel rewriting.</p><p>The remark "one-size does not fit all" <ref type="bibr" target="#b50">[51]</ref> has been recently revisited <ref type="bibr" target="#b31">[32,</ref><ref type="bibr" target="#b39">40]</ref> for heterogeneous stores. <ref type="bibr" target="#b36">[37]</ref> uses a relational database as a "cache" for partial results of a MapReduce computation, while <ref type="bibr" target="#b37">[38]</ref> considers view-based rewriting in a MapReduce setting. Unlike our work, these algorithms need the data, views and query to be in the same data model.</p><p>Polystores <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b17">18]</ref> allow querying heterogeneous stores by grouping similar-model platform into "islands" and explicitly sending queries to one store or another; data sets can also be migrated by the users. Our LAV approach is novel and, as we have shown, enables to improve the performance of such stores also. The integration of "NoSQL" stores has been considered e.g., in [? ] again in a GAV approach, without the benefits of LAV view-based rewriting.</p><p>Adaptive stores for a single data model have been studied e.g., in <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b34">35]</ref>; views have been also used in <ref type="bibr">[50?</ref> ] to improve the performance of a large-scale distributed relational store. The novelty of ESTOCADA here is to support multiple data models, by relying on powerful query reformulation techniques under constraints.</p><p>Data exchange tools such as Clio <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b26">27]</ref> allow migrating data between two different schemas of the same (typically relational and sometimes XML) model (and thus not focused on cross-model rewriting). View-based rewriting and view selection are grounded in the seminal works <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b38">39]</ref>; the latter focuses on maximally contained rewritings, while we target exact query rewriting, which leads to very different algorithms. Further setting our work apart is the scale and usage of integrity constraints. Our pivot model recalls the ones described in <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b40">41]</ref> but ESTOCADA generalizes these works by allowing multiple data models both at the application and storage level.</p><p>CloudMdsQL <ref type="bibr" target="#b35">[36]</ref> is an integration language resembling QBT XM , and our cross-model view-based rewriting approach could be easily adapted to use CloudMdsQL as its integration language, just like we adapted it to use BigDAWG's. The polystore engine supporting CloudMdsQL does not feature our cross-model view-based query rewriting functionality.</p><p>Works on publishing relational data as XML <ref type="bibr" target="#b20">[21]</ref> followed the GAV paradigm, thus did not raise the (cross-model) view-based rewriting problem we address here.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="10">CONCLUSIONS</head><p>We have shown that multi-store architectures have the potential to significantly speed up query evaluation by materializing views in the systems most suited to expected workload operations, even when these views are distributed across stores and data models. ES-TOCADA supports this functionality by a local-as-view approach whose immediate benefit is flexibility since it requires no work when the underlying data storage changes. To make this approach feasible, we had to couple modeling contributions (in designing a reduction from multi-model view-based rewriting to relational rewriting under constraints), with algorithmic contributions (in optimizing and extending the state-of-the-art algorithm for relational view-based rewriting under constraints) and with systems contributions (integrating our rewriting algorithm within <ref type="bibr" target="#b9">[10]</ref> and BigDAWG).</p><p>In our experiments, we achieved performance gains by simply placing the materialized views according to a few common-sense guidelines (e.g., place large unstructured text collections in a store with good full-text indexing support, and place inherently nested data in JSON document stores). As a natural future work step, we are targeting the cost-based recommendation of optimal cross-model view placement. A J P at t e r n -&gt; A J F or P at t er n A J W her e P at t er n ? A J F or P at t e r n -&gt; v ar i abl e IN col l ec t ion N ame | v ar i abl e IN A J P at hEx pr A J W he r e P at t e r n -&gt; WHERE A J Cond i t ion A J Cond i t ion -&gt; A J t e r m | A J t er m=A J t er m | ' ( ' A J Cond i t ion ' ) '</p><p>| A J Cond i t ion AND A J Cond i t ion A J t e r m -&gt; A J P at hEx pr | v ar i abl e | cons t ant | A J F unC al l / / * PJ Pattern * / / P J P at t e r n -&gt; P J F r omP at t er n P J W her e P at t er n ? P J F r omP at t e r n -&gt; r el at ion N ame AS v ar i abl e | J S O N _AR RAY _E LE M E N T S (P J P at hEx pr ) AS v ar i abl e P J W he r e P at t e r n -&gt; WHERE P J Cond i t ion P J Cond i t ion -&gt; P J t e r m | P J t e r m=P J t er m | ' ( ' P J Cond i t ion ' ) ' | P J Cond i t ion AND P J Cond i t ion P J t e r m -&gt; P J P at hEx pr | v ar i abl e | cons t ant | P J F unC al l  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>K COST-BASED OPTIMIZATION</head><p>Optimization in the ESTOCADA polystore engine used in our experiment combines heuristics and costs, as follows.</p><p>First, for each view V i used in a rewriting RW , such that V i resides in the datastore DS i , RW decoding (Section 5.4) consolidates the maximum number of atoms that can be pushed (evaluated) into DS i , depending on the query capabilities of the latter; we call such an operator SourceAccess, and systematically choose to evaluate it in DS i .</p><p>The cost of SourceAccess is estimated using a linear cost model with a fixed start-up component and one that grows linearly with the estimated size of the returned data (see below); this model also uses system (physical) parameters which we computed by running by hand a few "system profiling" queries, notably the observed disk read and write rate (for cold reads) and time to manipulate data in memory for subsequent, hot reads. We had derived these physical parameters for prior work on the same team cluster, thus we just reused those numbers. In general, calibration <ref type="bibr" target="#b22">[23]</ref> can be used, i.e., a module of the polystore systems runs some controlled experiments on each hardware on which it is newly deployed, and from these experiments derives the values characterizing the system performance. Calibration is present in many modern systems, e.g., RHEEM <ref type="foot" target="#foot_1">5</ref> .</p><p>The cardinality of a SourceAccess is estimated using: (i) statistics on the views (e.g., number of tuples, or JSON trees, their average size, etc.); these are gathered at view materialization time, together with the minimum, maximum, and number of distinct values for finegranularity attributes; (ii) default constant factors for inequalities or keyword search. Statistic estimates are rarely exact and ours could be perfected; however, they have already helped us make some good choices.</p><p>Optimization develops left-deep join plans in a bottom-up fashion based on the SourceAccess operators. To place each join, we consider: (i) each data source hosting one input, if it supports joins; (ii) always, as a fall-back, the mediator. On a full join tree, we push the remaining selection (σ ) and projections (π ) as far as possible (taking into account source capabilities), then add possible (linearcost) Construct operators which structure the results in the desired data model. The cost of σ and π are linear in the size of the input with system-dependent constants; the constant for full-text search is higher than for equality selections.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Outline of our approach We consider a polystore setting comprising a set of stores S = {S 1 , S 2 , . . .} such that each store S ∈ S is characterized by a pair (M S , L S ) ∈ P, indicating that S can store instances of the model M S and evaluate queries expressed in L S . We consider a set of data sets D = {D 1 , D 2 , . . .}, such that each data set D ∈ D is an instance of a data model M D . A data set D is stored as a set of (potentially overlapping) materialized views {V 1 D , V 2 D . . .}, such that for every 1 ≤ j, V j D is stored within the storage system S j D ∈ S. Thus, V j D is an instance of a data model supported by S j D 1 .We consider an integration language IL, capable of expressing computations to be made within each store and across all of them, as follows:• For every store S and query q S ∈ L ′ S , IL allows specifying that q S should be evaluated over S; • Further, IL allows expressing powerful processing over the results of one or several such source queries. Such integration language has been proposed in several works<ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b35">36]</ref>; we use it to express computations over the views. An IL expression bears obvious similarities with an execution plan in a wrapper-mediator system; its evaluation is split between computations pushed to the stores, and subsequent operations applied by the mediator on top of their results. The main distinction is that IL remains declarative, abstracting the details of each in-store computation, which is simply specified by a query in the store's language.We assume available a cost model which, given an IL expression e, returns an estimation of the cost of evaluating e (including the cost of its source sub-queries). The cost may reflect e.g., disk I/O, memory needs, CPU time, transfer time between distributed sites etc. We outline the concrete model we use in Appendix K.We term rewriting of a query q an integration query expressed in IL, which is equivalent to q. We consider the following rewriting problem:</figDesc><graphic coords="4,53.80,83.69,240.23,87.94" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>SELECT s . ssn , COUNT ( SELECT w . cno FROM Waitlist w WHERE w . ssn = s . ssn AND w . qtr = ' Spring 2016 ' ) AS cnt FROM Student s WHERE NOT EXISTS ( SELECT c . no FROM Course c , Enrollment e WHERE c . no = e . cno AND s . ssn = e . ssn AND e . qtr = ' Spring 2016 ')This query consists of three blocks. The outermost SELECT-FROM-WHERE expression corresponds to the root block, call it B 0 . The two nested SELECT-FROM-WHERE expressions are modeled as children blocks of the root block, call them B 00 and B 01 for the block nested in the SELECT clause, respectively the block nested in the WHERE clause.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Relational encoding of QBT XM View V 2 5.2 Encoding QBT XM Queries into the Pivot Language</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Motivating scenario QBT XM Query Q 1 remaining logical operations, to be executed within the integration engine. The translation first decodes RW r into QBT XM syntax.Based on the heuristic that the store where a view resides is more efficient than the mediator, and thus it should be preferred for all the operations it can apply, decoding tries to delegated to the stores as much as possible. To that end, it first partitions each rewriting RW r into view-level subqueries, which are sets of atoms referring to the virtual relations of a same view. If a group of view-level subqueries pertains to the same store and if the store supports joins, we translate the group to a single query to be pushed to the store.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Π 1 , 2 , 3 , 4 , 7 Π 1 , 2 , 5 , 6 ▷◁Figure 5 :</head><label>1234712565</label><figDesc>Figure 5: Integration plan of the motivating scenario</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>(a) algorithm PACB opt without a cost model enumerates all joinminimal4 V-based rewritings of Q under I, and (b) algorithm PACB opt equipped with a cost model c finds the c-optimal join-minimal rewritings of Q.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 6 :Figure 7 :</head><label>67</label><figDesc>Figure 6: ESTOCADA (relational and JSON views in Postgres, JSON view in Solr) vs. single-store evaluation</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 8 :Figure 9 :</head><label>89</label><figDesc>Figure 8: Rewriting time (28 relevant views)</figDesc><graphic coords="11,360.44,324.73,153.03,113.38" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head></head><label></label><figDesc>* Q03+ Q04* Q05+ Q06* Q07* Q08* Q09+ Q10* Q11* Q12+ Q13* Q14+ Q15+ Q16* Q17+ Q18* Q19+ Q20* Q21* Q22* Q23* Q24+ Q25* Q26* Q27+ Q28+ Q29* Execution time in minutes (Includes rewriting time) ESTOCADA Polystore Engine (Direct Evaluation) ESTOCADA Polystore Engine (Query Rewriting) BigDAWG (Direct Evaluation) BigDAWG (Query Rewriting)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 10 :Figure 11 :</head><label>1011</label><figDesc>Figure 10: Queries and Rewritings Evaluation In Polystore Engines</figDesc><graphic coords="13,109.89,230.09,142.11,59.74" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>V</head><label></label><figDesc>2 } , P J : { SELECT v 3 -&gt; ' p a t i e n t I D ' AS P I D 2 , A-&gt; ' a d m i s s i o n I D ' AS AI D 2 , D-&gt; ' drug ' AS drug FROM V 3 v 3 , j s o n b _ a r r a y _ e l e m e n t s ( v 3 -&gt; ' a d m i s s i o n ' ) A , j s o n b _ a r r a y _ e l e m e n t s ( A-&gt; ' d r u g s ' ) D WHERE D-&gt;&gt; ' d r u g t y p e ' = ' a d d i t i v e ' } WHERE p a t i e n t I D =P I D 1 AND a d m i s s i o n I D =AI D 1 AND P I D 1 = P I D 2 AND AI D 1 =AI D 2 RETURN AJ : { " p a t i e n t I D " : p a t i e n t I D , " a d m i s s i o n L o c " : a d m i s s i o n L o c , " a d m i s s i o n T i m e " : a d m i s s i o n T i m e , " drug " : drug } D SAMPLE JSON QUERY IN POSTGRES SYNTAX Q 01 : SELECT D . PATIENT-&gt;&gt; ' PATIENTID ' , LI -&gt;&gt; ' LABEL ' FROM MIMIC AS D , LABITEMS AS LI , j s o n b _ a r r a y _ e l e m e n t s ( D . PATIENT-&gt; ' ADMISSIONS ' ) AS A , j s o n b _ a r r a y _ e l e m e n t s ( A-&gt; ' LABEVENTS ' ) AS LE , j s o n b _ a r r a y _ e l e m e n t s ( A-&gt; ' NOTEEVENTS ' ) AS NE WHERE L I . LABITEM-&gt; ' ITEMID ' =LE-&gt; ' ITEMID ' AND L I . LABITEM@&gt; ' { " FLUID " : " B l o o d " } ' AND L I . LABITEM@&gt; ' { " CATEGORY " : " B l o o d Gas " } ' AND LE-&gt;&gt; ' FLAG ' = ' a b n o r m a l ' AND t o _ t s v e c t o r ( ' e n g l i s h ' , NE . t e x t : : t e x t ) @@ p l a i n t o _ t s q u e r y ( ' e n g l i s h ' , ' r e s p i r a t o r y f a i l u r e ' ) E SAMPLE ASTERIXDB QUERY (SQL++) Q 01 : USE M I M I C i i i ; SELECT D . PATIENTID , L I . LABEL FROM MIMIC AS D , LABITEMS LI , D . ADMISSIONS AS A , LABEVENTS AS LE , A . NOTEEVENTS AS N WHERE L I . ITEMID=LE . ITEMID AND LE . FLAG = " a b n o r m a l " AND L I . CATEGORY= " B l o o d Gas " AND L I . FLUID = " B l o o d " AND c o n t a i n s ( N . t e x t , " r e s p i r a t o r y f a i l u r e " ) F SAMPLE SPARKSQL QUERY Q 01 : SELECT D . PATIENTID , L I . LABEL FROM LABITEMS AS LI , MIMIC AS M LATERAL VIEW e x p l o d e ( ADMISSIONS ) AS A LATERAL VIEW e x p l o d e ( A . LABEVENTS ) AS LE LATERAL VIEW e x p l o d e ( A . NOTEEVENTS ) AS N WHERE L I . ITEMID=LE . ITEMID AND LE . FLAG = " a b n o r m a l " AND L I . CATEGORY= " B l o o d Gas " AND L I . FLUID = " B l o o d " AND N . t e x t LIKE ' % r e s p i r a t o r y f a i l u r e % '</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>/</head><label></label><figDesc>/ * RK Pattern * / / RK P at t e r n -&gt; v ar i abl e IN RK LookU p Ex pr / / * AJ Path Expression * / / A J P at hEx pr -&gt; v ar i abl e ' . ' k ey ( ' . ' k ey ) * / / * PJ Path Expression * / / P J P at hEx pr -&gt; v ar i abl e ' -&gt; ' k ey ( ' -&gt; ' k ey ) * / / * RK Look Up Expression * / /RK LookU p Ex pr -&gt; mainM ap N ame ' [ ' k ey ' ] ' | v ar i abl e [ ' k ey ' ] ' / / * AJ Constructor * / / A J Ob jCons t r uc t or -&gt; ' { ' ( k ey ' : ' A J v alue ( ' , ' k ey ' : ' A J v alue ) * ' } ' A J v al ue -&gt; v ar i abl e | cons t ant | A J P at hEx pr | A J P at t er n | A J Ob jCons t r uc t or / / * PJ Constructor * / / P J Ob jCons t r uc t or -&gt; J S O N _BU I LD_O B J ECT ( k ey , P J v alue ( ' , ' k ey , P J v alue ) * ) P J v al ue -&gt; v ar i abl e | cons t ant | P J P at hEx pr | P J P at t er n | P J Ob jCons t r uc t or / / * RK Constructor * / RK M apCons t r uc t or -&gt; k ey -&gt; ' { ' k ey ' : ' v ar i abl e ( ' , ' k ey ' : ' v ar i abl e ) * ' } 'annot at ion -&gt; AJ | PR | PJ | SJ | RK k ey -&gt; STRING col l ec t ion N ame -&gt; STRING mainM ap N ame -&gt; STRING r el at ion N ame -&gt; STRING f un N ame -&gt; STRING cons t ant -&gt; STRING | INTEGER J SAMPLE BIGDAWG QUERYQuery01 : b d r e l ( SELECT P . PATIENTID , TAB2 . LABEL FROM b d c a s t ( b d t e x t ( q= t e x t : r e s p i r a t o r y + f a i l u r e &amp; f l =PATIENTID , ADMISSIONID ) , TAB1 , ' ( PATIENTID INTEGER , ADMISSIONID INTEGER ) ' , r e l a t i o n a l ) , b d c a s t ( b d j q ( SELECT P . PATIENTID AS PATIENTID , ( A-&gt;&gt; ' ADMISSIONID ' ) : : i n t AS ADMISSIONID , LE-&gt;&gt; ' LABEL ' AS LABEL FROM PATIENTEVENTS AS P , LABITEMS LI , j s o n b _ a r r a y _ e l e m e n t s ( P . PATIENTEVENT-&gt; ' ADMISSIONS ' ) AS A , j s o n b _ a r r a y _ e l e m e n t s ( A-&gt; ' LABEVENTS ' ) AS LE WHERE L I . LABITEM-&gt; ' ITEMID ' =LE-&gt; ' ITEMID ' AND L I . LABITEM@&gt; ' { " FLUID " : " B l o o d " } ' AND L I . LABITEM@&gt; ' { " CATEGORY " : " B l o o d Gas " } ' ) , TAB2 , ' ( PATIENTID INTEGER , ADMISSIONID INTEGER , LABEL VARCHAR ) ' , r e l a t i o n a l ) , PATIENTS P WHERE P . PATIENTID= t a b 1 . PATIENTID AND P . PATIENTID= t a b 2 . PATIENTID ) Q04 Q05 Q06 Q07 Q08 Q09 Q10 Q11 Q12 Q13 Q14 Q15 Q16 Q17 Q18 Q19 Q20 Q021 Q22 Q23 Q24 Q25 Q26 Q27 Q28 Q29 Execution time in minutes (includes ABC rewriting time) MongoDB Postgres (JSON instance) ESTOCADA Polystore Engine</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Figure 12 :</head><label>12</label><figDesc>Figure 12: ESTOCADA cross-store query evaluation (relational, resp. JSON views in Postgres, JSON view in Solr) vs. single-store query evaluation with views (in MongoDB and Postgres).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Data Stores Supported by ESTOCADA data model. Thus, their view-based query rewriting algorithms are designed specifically within the bounds of that model, e.g., relational</figDesc><table><row><cell>Data model</cell><cell>Query language/API</cell><cell>Systems</cell></row><row><cell>Relational</cell><cell>SQL</cell><cell>Major vendors</cell></row><row><cell>JSON</cell><cell>SparkSQL</cell><cell>Spark [9]</cell></row><row><cell>JSON</cell><cell>AQL/SQL++</cell><cell>AsterixDB [2]</cell></row><row><cell>JSON</cell><cell>SQLw/JSON</cell><cell>Postgres</cell></row><row><cell>Key-value</cell><cell>Redis API</cell><cell>Redis</cell></row><row><cell>Full-text and JSON</cell><cell>Solr API</cell><cell>Solr</cell></row><row><cell>XML</cell><cell>XQuery, XPath</cell><cell>Saxon [3]</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>We call the resulting algorithm</figDesc><table><row><cell>PACB opt qbt</cell><cell cols="3">, using the notation PACB opt qbt</cell><cell>⟨C, c⟩ to emphasise the fact</cell></row><row><cell cols="4">that it is parameterized by the constraints C and the cost model c.</cell></row><row><cell cols="4">Recalling the uninterpreted (black-box) function semantics from</cell></row><row><cell cols="3">Section 2, Corollary 6.2 implies:</cell></row><row><cell cols="4">Corollary 6.3. Under uninterpreted-function semantics, Corol-</cell></row><row><cell cols="4">lary 6.2 still holds when we replace conjunctive queries with QBT</cell></row><row><cell cols="2">queries and PACB opt with PACB</cell><cell>opt</cell><cell>.</cell></row><row><cell></cell><cell></cell><cell>qbt</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>For uniformity, we describe any collection of stored data as a view, e.g., a table stored in an RDBMS is an (identity) view over itself.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_1"><p>https://github.com/rheem-ecosystem/rheem/tree/master/rheemcore/src/main/java/org/qcri/rheem/core/profiling This model allows to find the cheapest plan for RW ; for a given rewritten query Q, the cheapest rewriting is selected.</p></note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>G SAMPLE MONGODB QUERY</head><p>Q 02 : { " a g g r e g a t e " : " mimic " , " p i p e l i n e " : [ { " $match " : { " $ t e x t " : { " $ s e a r c h " : " \ " r e s p i r a t o r y f a i l u r e \ " " } } } , { " $unwind " : " $ADMISSIONS " } , { " $unwind " : " $ADMISSIONS . LABEVENTS " } , { " $ l o o k u p " : { " from " : " d _ l a b i t e m s " , " l e t " : { " i t e m " : " $ADMISSIONS . LABEVENTS . ITEMID " } , " p i p e l i n e " : [ { " $match " : { " $ e x p r " : { " $and " : [ { " $eq " : [ " $ITEMID " , " $$ i t e m " ] } , { " $eq " : [ " $FLUID " , " B l o o d " ] } ] } } } , { " $ p r o j e c t " : { " ITEMID " : 0 , " \ _ i d " : 0 } } ] , " a s " : " t " } } , { " $match " : { " t " : { " $ne " : [ ] } } } , { " $unwind " : " $ADMISSIONS . ICUSTAYS " } , { " $unwind " : " $ADMISSIONS . ICUSTAYS . PRESCRIPTIONS " } , { " $match " : { " $ e x p r " : { " $and " : [ { " $eq " : [ " $ADMISSIONS . ICUSTAYS . PRESCRIPTIONS . DRUG_TYPE " , " ADDITIVE " ] } , { " $eq " : [ " $ADMISSIONS . ICUSTAYS . PRESCRIPTIONS . DRUG " , " P o t a s s i u m C h l o r i d e " ] } , { " $eq " : [ " $ADMISSIONS . LABEVENTS . FLAG " , " a b n o r m a l " ] } ] } } } , { " $ p r o j e c t " : { " t . LABEL " : 1 , " t . CATEGORY " : 1 } } ] }</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>L MATERIALIZING ALL VIEWS IN A SINGLE STORE EXPERIMENT</head><p>We now compare cross-model evaluation against view-based singlestore evaluation. To that purpose, we stored all V EX P views in each of MongoDB, AsterixDB, SparkSQL and Postgres. As shown in Figure <ref type="figure">12</ref>, multi-store evaluation outperforms single-store evaluation with views in MongoDB. We note that: (i) each MongoDB query joins three materialized views; the required use of the $unwind (a.k.a. unnest) operator inside $lookup operators makes the latter slower. For each document/tuple from an outer collection in the $lookup operator, $unwind unnests the entire inner collection to perform the join, which is inefficient; (ii) MongoDB requires to place the full-text search predicate at the beginning of a query pipeline, which can hurt performance if the predicate is not highly selective. In AsterixDB and SparkSQL, all queries timed out due to the lack of full-text indexing on collection fields. To try to help them, we flattened the nested documents and created the full textsearch index. In this setting, AsterixDB failed with an internal error (ArrayIndexOutOfBoundsException is thrown), while SparkSQL still timed out since it has no full-text index support. For 40% of the queries, single-store view-based evaluation in Postgres outperforms cross-model evaluation, which is the most efficient for 60% of the queries. Note that Postgres benefits from the view-based rewriting algorithm of ESTOCADA here. On top of view-based performance improvements, Postgres exploits more choices of join order and algorithms.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<ptr target="https://accumulo.apache.org/" />
		<title level="m">Apache Accumulo</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<ptr target="https://asterixdb.apache.org/" />
		<title level="m">AsterixDB</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<ptr target="http://saxon.sourceforge.net/" />
		<title level="m">Saxon</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<ptr target="https://www.paradigm4.com/" />
		<title level="m">Scidb</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Foundations of Databases</title>
		<author>
			<persName><forename type="first">Serge</forename><surname>Abiteboul</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Hull</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Victor</forename><surname>Vianu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995">1995</date>
			<publisher>Addison-Wesley</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">RHEEM: Enabling Cross-Platform Data Processing -May The Big Data Be With You! PVLDB</title>
		<author>
			<persName><forename type="first">Divy</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sanjay</forename><surname>Chawla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bertty</forename><surname>Contreras-Rojas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ahmed</forename><forename type="middle">K</forename><surname>Elmagarmid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yasser</forename><surname>Idris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zoi</forename><surname>Kaoudi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Kruse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ji</forename><surname>Lucas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Essam</forename><surname>Mansour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mourad</forename><surname>Ouzzani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paolo</forename><surname>Papotti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jorge-Arnulfo</forename><surname>Quiané-Ruiz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nan</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Saravanan</forename><surname>Thirumuruganathan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anis</forename><surname>Troudi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Fast Algorithms for Mining Association Rules in Large Databases</title>
		<author>
			<persName><forename type="first">Rakesh</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ramakrishnan</forename><surname>Srikant</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PVLDB</title>
		<imprint>
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">H2O: a hands-free adaptive store</title>
		<author>
			<persName><forename type="first">I</forename><surname>Alagiannis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Idreos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ailamaki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGMOD</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Spark SQL: Relational data processing in Spark</title>
		<author>
			<persName><forename type="first">Michael</forename><surname>Armbrust</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Reynold</forename><forename type="middle">S</forename><surname>Xin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cheng</forename><surname>Lian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yin</forename><surname>Huai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Davies</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joseph</forename><forename type="middle">K</forename><surname>Bradley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiangrui</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tomer</forename><surname>Kaftan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ali</forename><surname>Franklin</surname></persName>
		</author>
		<author>
			<persName><surname>Ghodsi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGMOD. ACM</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Mixed-instance querying: a lightweight integration architecture for data journalism</title>
		<author>
			<persName><forename type="first">Raphaël</forename><surname>Bonaque</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tien</forename><surname>Duc Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bogdan</forename><surname>Cautis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">François</forename><surname>Goasdoué</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Javier</forename><surname>Letelier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ioana</forename><surname>Manolescu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oscar</forename><surname>Mendoza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Swen</forename><surname>Ribeiro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xavier</forename><surname>Tannier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michaël</forename><surname>Thomazo</surname></persName>
		</author>
		<ptr target="https://hal.inria.fr/hal-01321201" />
	</analytic>
	<monogr>
		<title level="m">VLDB</title>
		<meeting><address><addrLine>New Delhi, India</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">ViewJoin: Efficient view-based evaluation of tree pattern queries</title>
		<author>
			<persName><forename type="first">Ding</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chee-Yong</forename><surname>Chan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICDE</title>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">CoPhy: A Scalable, Portable, and Interactive Index Advisor for Large Workloads</title>
		<author>
			<persName><forename type="first">Debabrata</forename><surname>Dash</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Neoklis</forename><surname>Polyzotis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anastasia</forename><surname>Ailamaki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PVLDB</title>
		<imprint>
			<date type="published" when="2011">2011. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Rewriting Queries Using Views with Access Patterns Under Integrity Constraints</title>
		<author>
			<persName><forename type="first">Alin</forename><surname>Deutsch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bertram</forename><surname>Ludäscher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alan</forename><surname>Nash</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICDT</title>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">The chase revisited</title>
		<author>
			<persName><forename type="first">Alin</forename><surname>Deutsch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alan</forename><surname>Nash</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeffrey</forename><forename type="middle">B</forename><surname>Remmel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">PODS</title>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Query reformulation with constraints</title>
		<author>
			<persName><forename type="first">Alin</forename><surname>Deutsch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lucian</forename><surname>Popa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Val</forename><surname>Tannen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIGMOD</title>
		<imprint>
			<date type="published" when="2006">2006. 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">MARS: A System for Publishing XML from Mixed and Redundant Storage</title>
		<author>
			<persName><forename type="first">Alin</forename><surname>Deutsch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Val</forename><surname>Tannen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">VLDB</title>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Reformulation of XML Queries and Constraints</title>
		<author>
			<persName><forename type="first">Alin</forename><surname>Deutsch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Val</forename><surname>Tannen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICDT</title>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">The BigDAWG Polystore System</title>
		<author>
			<persName><forename type="first">J</forename><surname>Duggan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Elmore</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Stonebraker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Balazinska</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Howe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kepner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Madden</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Maier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Mattson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">B</forename><surname>Zdonik</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015">2015. 2015</date>
			<publisher>SIGMOD</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Data Exchange: Semantics and Query Answering</title>
		<author>
			<persName><forename type="first">R</forename><surname>Fagin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Kolaitis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Popa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICDT</title>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Data exchange: semantics and query answering</title>
		<author>
			<persName><forename type="first">Ronald</forename><surname>Fagin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Phokion</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Renée</forename><forename type="middle">J</forename><surname>Kolaitis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lucian</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName><surname>Popa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Theoretical Computer Science</title>
		<imprint>
			<date type="published" when="2005">2005. 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">SilkRoute: A framework for publishing relational data in XML</title>
		<author>
			<persName><forename type="first">Mary</forename><surname>Fernández</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yana</forename><surname>Kadiyska</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Suciu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Atsuyuki</forename><surname>Morishima</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wang-Chiew</forename><surname>Tan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TODS</title>
		<imprint>
			<date type="published" when="2002">2002. 2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Query Optimization in the Presence of Limited Access Patterns</title>
		<author>
			<persName><forename type="first">Daniela</forename><surname>Florescu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alon</forename><forename type="middle">Y</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ioana</forename><surname>Manolescu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Suciu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGMOD</title>
		<imprint>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Calibrating the Query Optimizer Cost Model of IRO-DB, an Object-Oriented Federated Database System</title>
		<author>
			<persName><forename type="first">Georges</forename><surname>Gardarin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fei</forename><surname>Sha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhao-Hui</forename><surname>Tang</surname></persName>
		</author>
		<idno>378-389</idno>
		<ptr target="http://www.vldb.org/conf/1996/P378.PDF" />
	</analytic>
	<monogr>
		<title level="m">VLDB</title>
		<imprint>
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Tableau Techniques for Querying Information Sources through Global Schemas</title>
		<author>
			<persName><forename type="first">Gösta</forename><surname>Grahne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alberto</forename><forename type="middle">O</forename><surname>Mendelzon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICDT</title>
		<imprint>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<author>
			<persName><forename type="first">Gosta</forename><surname>Grahne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adrian</forename><surname>Onet</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1303.6682</idno>
		<title level="m">Anatomy of the chase</title>
		<imprint>
			<date type="published" when="2013">2013. 2013</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Optimizing queries across diverse data sources</title>
		<author>
			<persName><forename type="first">Laura</forename><surname>Haas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Donald</forename><surname>Kossmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Edward</forename><surname>Wimmers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jun</forename><surname>Yang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1997">1997. 1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Clio grows up: from research prototype to industrial tool</title>
		<author>
			<persName><forename type="first">Laura</forename><forename type="middle">M</forename><surname>Haas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mauricio</forename><forename type="middle">A</forename><surname>Hernández</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Howard</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lucian</forename><surname>Popa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mary</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGMOD</title>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Answering Queries Using Views: A Survey</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Alon</surname></persName>
		</author>
		<author>
			<persName><surname>Halevy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The VLDB Journal</title>
		<imprint>
			<date type="published" when="2001">2001. 2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Database Cracking</title>
		<author>
			<persName><forename type="first">S</forename><surname>Idreos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">L</forename><surname>Kersten</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Manegold</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIDR</title>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Complete yet practical search for minimal query reformulations under constraints</title>
		<author>
			<persName><forename type="first">Ioana</forename><surname>Ileana</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bogdan</forename><surname>Cautis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alin</forename><surname>Deutsch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yannis</forename><surname>Katsis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGMOD</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">SQL</title>
		<ptr target="http://www.iso.org/iso/iso_catalogue/catalogue_tc/catalogue_detail.htm?csnumber=26196" />
		<imprint>
			<date type="published" when="1999-03">1999. March 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">WWHow! Freeing Data Storage from Cages</title>
		<author>
			<persName><forename type="first">A</forename><surname>Jindal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-A</forename><surname>Quiané-Ruiz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Dittrich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIDR</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">MIMIC-III, a freely accessible critical care database</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Aew Johnson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Pollard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lehman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Ghassemi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Moody</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">A</forename><surname>Szolovits</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">G</forename><surname>Celi</surname></persName>
		</author>
		<author>
			<persName><surname>Mark</surname></persName>
		</author>
		<idno type="DOI">10.1038/sdata.2016.35</idno>
		<ptr target="http://www.nature.com/articles/sdata201635" />
	</analytic>
	<monogr>
		<title level="j">Scientific Data</title>
		<imprint>
			<date type="published" when="2016">2016. 2016. 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Just-In-Time Data Virtualization: Lightweight Data Management with ViDa</title>
		<author>
			<persName><forename type="first">M</forename><surname>Karpathiotakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Alagiannis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Heinis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Branco</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ailamaki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIDR</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Materialized view selection for XQuery workloads</title>
		<author>
			<persName><forename type="first">Asterios</forename><surname>Katsifodimos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ioana</forename><surname>Manolescu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vasilis</forename><surname>Vassalos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGMOD</title>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">CloudMdsQL: querying heterogeneous cloud data stores with a common language</title>
		<author>
			<persName><forename type="first">Boyan</forename><surname>Kolev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Patrick</forename><surname>Valduriez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carlyna</forename><surname>Bondiombouy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ricardo</forename><surname>Jiménez-Peris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Raquel</forename><surname>Pau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">José</forename><surname>Pereira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Distributed and parallel databases</title>
		<imprint>
			<date type="published" when="2016">2016. 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">MISO: souping up big data query processing with a multistore system</title>
		<author>
			<persName><forename type="first">J</forename><surname>Lefevre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sankaranarayanan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Hacigümüs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGMOD</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Opportunistic physical design for big data analytics</title>
		<author>
			<persName><forename type="first">Jeff</forename><surname>Lefevre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jagan</forename><surname>Sankaranarayanan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hakan</forename><surname>Hacigümüs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGMOD</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Querying Heterogeneous Information Sources Using Source Descriptions</title>
		<author>
			<persName><forename type="first">A</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rajaraman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ordille</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">VLDB</title>
		<imprint>
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">How to Fit when No One Size Fits</title>
		<author>
			<persName><forename type="first">H</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Babu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIDR</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Answering XML Queries on Heterogeneous Data Sources</title>
		<author>
			<persName><forename type="first">Ioana</forename><surname>Manolescu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniela</forename><surname>Florescu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Donald</forename><surname>Kossmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">VLDB</title>
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Processing First-Order Queries under Limited Access Patterns</title>
		<author>
			<persName><forename type="first">Alan</forename><surname>Nash</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bertram</forename><surname>Ludäscher</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004">2004</date>
			<publisher>PODS</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Rewriting Nested XML Queries Using Nested Views</title>
		<author>
			<persName><forename type="first">N</forename><surname>Onose</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Deutsch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Papakonstantinou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Curtmola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGMOD</title>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">Principles of Distributed Database Systems</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">T</forename><surname>Özsu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Valduriez</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011">2011</date>
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
	<note>Third Edition</note>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">Semistructured Models, Queries and Algebras in the Big Data Era: Tutorial Summary</title>
		<author>
			<persName><forename type="first">Yannis</forename><surname>Papakonstantinou</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016">2016</date>
			<publisher>SIGMOD</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">InterJoin: Exploiting Indexes and Materialized Views in XPath Evaluation</title>
		<author>
			<persName><forename type="first">Derek</forename><surname>Phillips</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ning</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ihab</forename><forename type="middle">F</forename><surname>Ilyas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">Tamer</forename><surname>Özsu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SSDBM</title>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">A chase too far?</title>
		<author>
			<persName><forename type="first">Lucian</forename><surname>Popa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alin</forename><surname>Deutsch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arnaud</forename><surname>Sahuguet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Val</forename><surname>Tannen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM SIGMOD Record</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="273" to="284" />
			<date type="published" when="2000">2000</date>
			<publisher>ACM</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Answering Queries Using Templates with Binding Patterns</title>
		<author>
			<persName><forename type="first">Anand</forename><surname>Rajaraman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yehoshua</forename><surname>Sagiv</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeffrey</forename><forename type="middle">D</forename><surname>Ullman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">PODS</title>
		<imprint>
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Access Path Selection in a Relational Database Management System</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">Griffith</forename><surname>Selinger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Astrahan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">D</forename><surname>Chamberlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Lorie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">G</forename><surname>Price</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGMOD</title>
		<imprint>
			<date type="published" when="1979">1979</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">F1: A Distributed SQL Database That Scales</title>
		<author>
			<persName><forename type="first">J</forename><surname>Shute</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Vingralek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Samwel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PVLDB</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">One Size Fits All&quot;: An Idea Whose Time Has Come and Gone</title>
		<author>
			<persName><forename type="first">M</forename><surname>Stonebraker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Cetintemel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICDE</title>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
