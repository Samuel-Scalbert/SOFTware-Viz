<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">VCNet: A self-explaining model for realistic counterfactual generation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Victor</forename><surname>Guyomard</surname></persName>
							<email>victor.guyomard@orange.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Orange Labs</orgName>
								<address>
									<settlement>Lannion</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution" key="instit1">Univ Rennes</orgName>
								<orgName type="institution" key="instit2">Inria</orgName>
								<orgName type="institution" key="instit3">CNRS</orgName>
								<orgName type="institution" key="instit4">IRISA</orgName>
								<address>
									<settlement>Rennes</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Fran√ßoise</forename><surname>Fessant</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Orange Labs</orgName>
								<address>
									<settlement>Lannion</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Thomas</forename><surname>Guyet</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution" key="instit1">Inria</orgName>
								<orgName type="institution" key="instit2">Centre de Lyon</orgName>
								<address>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Tassadit</forename><surname>Bouadi</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution" key="instit1">Univ Rennes</orgName>
								<orgName type="institution" key="instit2">Inria</orgName>
								<orgName type="institution" key="instit3">CNRS</orgName>
								<orgName type="institution" key="instit4">IRISA</orgName>
								<address>
									<settlement>Rennes</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Alexandre</forename><surname>Termier</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution" key="instit1">Univ Rennes</orgName>
								<orgName type="institution" key="instit2">Inria</orgName>
								<orgName type="institution" key="instit3">CNRS</orgName>
								<orgName type="institution" key="instit4">IRISA</orgName>
								<address>
									<settlement>Rennes</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">VCNet: A self-explaining model for realistic counterfactual generation</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">0E15BA93C3535BB289EAD1E774C90780</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-04-12T14:45+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Counterfactual explanation is a common class of methods to make local explanations of machine learning decisions. For a given instance, these methods aim to find the smallest modification of feature values that changes the predicted decision made by a machine learning model. One of the challenges of counterfactual explanation is the efficient generation of realistic counterfactuals. To address this challenge, we propose VCNet -Variational Counter Net -a model architecture that combines a predictor and a counterfactual generator that are jointly trained, for regression or classification tasks. VCNet is able to both generate predictions, and to generate counterfactual explanations without having to solve another minimisation problem. Our contribution is the generation of counterfactuals that are close to the distribution of the predicted class. This is done by learning a variational autoencoder conditionally to the output of the predictor in a join-training fashion. We present an empirical evaluation on tabular datasets and across several interpretability metrics. The results are competitive with the state-of-the-art method.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Improvements of machine learning techniques for decision systems has led to the rise of applications in various domains such as healthcare, credit or justice. The eventual sensitivity of such domains, as well as the black-box nature of the algorithms, has motivated the need for methods that explain why some prediction was made. For example, if a person's loan is rejected as a result of a model decision, the bank must be able to explain why. In such a context, it might be interesting to provide an explanation of what that person should change to influence the model's decision. As suggested by Wachter et al. <ref type="bibr">[27]</ref>, one way to build this type of explanation is through the use of counterfactual explanations. A counterfactual is defined as the smallest modification of feature values that changes the prediction of a model to a given output. In addition, the explanation also provides important feedback to the user. In the context of a denied credit, a counterfactual is a close individual for whom his credit is accepted and the feature modifications suggested by a counterfactual acts as recourse for the user. For privacy reason or simply because there is no similar individual with an opposite decision, we aim to generate synthetic individuals as counterfactuals.</p><p>In order to provide a meaningful recourse, the counterfactual is expected to be realistic, i.e. close to the existing examples and respecting the observed correlation among features. Furthermore, in order to be representative of its predicted class, it is interesting to obtain a counterfactual close to the existing examples but relative to the counterfactual class. A counterfactual instance is usually found by iteratively perturbing the input characteristics of the original example until the desired prediction is achieved, which is like minimizing a loss function using an optimization algorithm. Many methods proceed in this way, but differ in their definition of the loss function and optimization method <ref type="bibr" target="#b16">[17]</ref>. These approaches appear to be computationally expensive. Indeed, for each instance to explain, a new optimisation problem has to be solved. Most of the counterfactual methods apply to already trained decision models and treat them as black boxes in the post-hoc paradigm. However, dissociating the prediction of the model from its explanation can lead to an explanation of poor quality <ref type="bibr" target="#b21">[22]</ref>.</p><p>Self-explaining models which incorporate an explanation generation module into their architecture, such that they provide explanations for their own predictions, can be an alternative to the previous approaches. In general, the predictor and explanation generator are trained jointly, hence the presence of the explanation generator is influencing the training of the predictor <ref type="bibr" target="#b6">[7]</ref>. In this spirit, Guo et al. <ref type="bibr" target="#b8">[9]</ref> propose CounterNet, a neural network based architecture for the prediction and counterfactual generation along with a novel variant of back propagation to ensure the stabilization of the training process. Compared to a post-hoc approach, they are able to produce counterfactuals with higher validity. A counterfactual is said to be valid if it succeeds in reaching a different prediction. A limitation of the CounterNet approach is that counterfactuals it generates may lack realism w.r.t. the data points of the class where they are positioned. The proposed approach, VCNet, tackles this issue: similarly to CounterNet, it combines a predictor and a counterfactual generator that are jointly trained. The difference lies in the counterfactual generator based on conditional variational autoencoder (cVAE) whose latent space can be controlled and tweaked to generate realistic counterfactuals. Our approach is inspired from John et al. work about learning disentangled latent spaces in the context of text style transfer <ref type="bibr" target="#b9">[10]</ref>.</p><p>Our main contribution is the proposal of a cVAE for counterfactual generation in order to generate realistic counterfactuals. Our second contribution is a self-explainable architecture of a classifier that embeds a cVAE, used as a counterfactual generator. In this architecture, both the model and the cVAE, are jointly trained with an efficient single back-propagation procedure. After recalling the properties of the variational autoencoder models (Section 3) that interest us in the context of this paper, we describe our proposal (Section 4). Then we present extensive experimental studies on synthetic and real data (Section 5). We compare the quality of the counterfactuals produced with those of CounterNet on different datasets through state-of-the-art metrics. The focus is on tabular data but we also show that our architecture is interesting on images.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Our work is concerned with the search for counterfactual explanation that is usually found by iteratively perturbing the input features of the instance of interest until the desired prediction is reached. In practice, the search of counterfactuals is usually posed as an optimization problem. It consists of minimizing an objective function which encodes desirable properties of the counterfactual instance with respect to the perturbations. Wachter et al. <ref type="bibr">[27]</ref> propose the generation of counterfactual instances by minimizing the distance between the instance to be explained and the counterfactual while pushing the new prediction toward the desired class. Other algorithms optimize other aspects with additional terms in the objective function such as actionability <ref type="bibr" target="#b24">[25]</ref>, diversity <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b22">23]</ref>, realism <ref type="bibr" target="#b25">[26]</ref>.</p><p>All aforementioned techniques search for counterfactual example by solving a separate optimization problem for each instance to be explained. This optimization problem is computationally intensive, making it impractical for large numbers of instances. To address this issue, several frameworks based on generative models have been proposed. A generative counterfactual model is trained to predict the counterfactual perturbations or instances directly. Many of these frameworks use the latent space of variational autoencoder models to generate counterfactuals with linear interpolation <ref type="bibr" target="#b1">[2]</ref>, latent feature selection <ref type="bibr" target="#b5">[6]</ref>, perturbation <ref type="bibr" target="#b20">[21]</ref> or incorporation of the target class in the latent space <ref type="bibr" target="#b18">[19]</ref>).</p><p>All these counterfactual generation techniques are post-hoc as they assume that the explaining task is done after the decision task with a fixed black-box model. In this post-hoc paradigm, the counterfactual search process is completely uninformed from the decision process. Post-hoc explanations may be the only option for already-trained models.</p><p>Another approach is to design models that optimize both the decision and an explanation of that decision during the learning process <ref type="bibr" target="#b0">[1]</ref>. In the context of counterfactual explanations, such a strategy has been recently proposed by Guo et al. <ref type="bibr" target="#b8">[9]</ref> with CounterNet, a framework in which prediction and explanation are jointly learned. The optimization of the counterfactual example generation only once together with the predictive model allows a better alignment between predictions and counterfactual explanations. This leads to explanations of better quality and significantly reduces the generation process time. Our architecture is inspired by theirs but we have chosen to use a conditional variational autoencoder as a generative model of counterfactuals allowing us to exploit text style-transfer techniques <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b18">19]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Backgrounds</head><p>In this section, we introduce some notations, problematic and backgrounds necessary for the presentation of the VCNet architecture in the next section.</p><p>Let X ‚äÜ R p represents the p-dimensional feature space and l ‚â• 2 a number of classes. A training dataset, denoted D = {(x i , y i )} n i=1 , is such that x i ‚àà X and y i ‚àà {1, . . . , l} for each i ‚àà {1, . . . , n}. For a new example x, the prediction consists in deciding to which class ≈∑ the example x belongs. For more generality, we consider probabilistic prediction: the prediction is a probability vector, denoted p ‚àà [0, 1] p . Then, the predicted class is the most likely class according to p. The counterfactual generation yields an example x which is close to x and whose prediction ≈∑ is different from ≈∑ in case the counterfactual is valid.</p><p>Our problem is both to learn from D an accurate predictor, denoted f , and a generator of counterfactual, denoted g. Now that we have presented our problem, we introduce the notion of VAE <ref type="bibr" target="#b11">[12]</ref> and cVAE <ref type="bibr" target="#b23">[24]</ref> which our proposal relies on.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Variational Autoencoder (VAE)</head><p>A variational autoencoder is a generative model where a latent parameterized distribution is learned. If samples are drawn in the latent space according to this distribution, the decoded samples are expected to be distributed according to the training data distribution (an approximate distribution of the training data distribution is learned) <ref type="bibr" target="#b11">[12]</ref>. Formally, let z be a latent vector (drawn from the latent distribution) and x be an example, we denote by q œÜ (z | x) the encoder distribution and by p Œ∏ (x | z) the decoder distribution. Training a VAE is finding the parameters Œ∏ and œÜ that minimize the following objective function, i.e. the opposite of the Evidence Lower Bound (ELBO):</p><formula xml:id="formula_0">L VAE (Œ∏, œÜ) = -E q œÜ (z|x) [log(p Œ∏ (x | z))] + D KL q œÜ (z | x) p(z)<label>(1)</label></formula><p>Generally, distributions are chosen to be Gaussian, meaning that q œÜ (z | x) ‚àº N (¬µ œÜ , Œ£ œÜ ) and p Œ∏ (x | z) ‚àº N (x | ¬µ Œ∏ , Œ£ Œ∏ ) and distribution parameters are estimated thanks to back-propagation. The first term of Eq. 1 encourages reconstructing x at the output of the decoder ( x). The second term encourages the regularization of the latent space by pushing q œÜ (z | x) to a Gaussian prior p ‚àº N (0, I).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Conditional Variational Autoencoder (cVAE)</head><p>A conditional variational autoencoder is a VAE where distributions are conditioned on a given variable c <ref type="bibr" target="#b23">[24]</ref>. The architecture is the same as a standard VAE but c is given as input of the encoder and also as input of the decoder. Then the objective function of Eq. 1 can be rewritten as:</p><formula xml:id="formula_1">L cVAE (Œ∏, œÜ) = -E q œÜ (z|x,c) [log(p Œ∏ (x | z, c))] + D KL q œÜ (z | x, c) p(z)<label>(2)</label></formula><p>The encoder distribution becomes q œÜ (z | x, c) and is pushed to the Gaussian prior p ‚àº N (z | 0, I) by the regularization term regardless of the value of c. The decoder reconstructs x from the concatenation of z with c.</p><p>The initial objective of conditional variational autoencoder is to enrich the expressiveness of the model in supervised settings. In this article, we use a property of the cVAE to disentangle the class specification from the content of the data <ref type="bibr" target="#b12">[13]</ref>. <ref type="foot" target="#foot_0">1</ref> Intuitively, the latent variable z does not need to model the example category, then it can focus on modeling the content of the examples, which is shared by all the categories. To illustrate the effective disentanglement of category and content, Kingma et al. show that the decoder p Œ∏ (x | z, c) can be used to generate images of the ten digits with the same shared content (let say the handwriting) by changing the class c and keeping the same random values for z. The same property has been applied to text style transfer <ref type="bibr" target="#b9">[10]</ref>. In this context, the style is the category, and the content is the wording. For tabular data, the notion of "content" and "style" can be illustrated in the context of the loan decision. The "style" characterizes the category of people loan (accepted or rejected ) and the "content" characterizes the other features. More specifically, the later models correlations between variables that are independent from the loan decisions.</p><p>In our proposal, we exploit the modeling properties of a cVAE to generate counterfactuals. Considering that the cVAE disentangles the category and the content, the decoder of a cVAE can be tweaked in a flexible way. For z the encoding of an example x of class c, p Œ∏ (x | z, c ) generates examples of a category c = c. In addition, (z, c ) is likely the element of class c that is the closest to (z, c) in the latent space. As this space is regularized, p Œ∏ (x | z, c ) generates examples that are similar to x, but belonging to a different class. This fits exactly the expectations of counterfactuals and will be assessed in Section 5.1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">A Join Training Model</head><p>VCNet is a self-explainable<ref type="foot" target="#foot_1">2</ref> model through counterfactual generation. Inspired by CounterNet <ref type="bibr" target="#b8">[9]</ref>, the VCNet model is made of a predictor, f (‚Ä¢), and a counterfactual generator, g(‚Ä¢, ‚Ä¢), that are jointly trained. In the inference phase, each part can be used on demand: on the one side, to get the prediction f (x) for some new example x and, on the other side, to generate its counterfactual g(x, c) for another class c. VCNet can be used as a self-explainable model and generates (f (x) , g (x, c)), i.e. the couple of the prediction and its counterfactual.</p><p>The trick of VCNet is to not train a counterfactual generator, but a supervised autoencoder, i.e. a cVAE. The cVAE is trained as an autoencoder and used as a counterfactual generator in inference.</p><p>We start by presenting the architecture of our network, then we detail the training problem by defining the loss which is optimized and finally, we detail how the trained model is used to generate counterfactuals.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">VCNet Architecture</head><p>VCNet is a neural network architecture. Figure <ref type="figure" target="#fig_0">1</ref> illustrates this architecture made of three main blocks:</p><p>1. Shared layers, s Œ≤ , that transform the input into a dense latent representation. We use fully connected layers with ELU activation functions.</p><p>2. A predictor network f Œ± that takes the shared latent representation and returns a probability vector corresponding to the probabilistic prediction. We use fully connected layers with ELU activation functions.</p><p>3. A conditional variational autoencoder that takes as input the shared latent representation and also the probability vector given by the predictor. The cVAE reconstructs examples and integrates additional layers to handle categorical variables (see details below).</p><p>During training, an example x i is passed through the shared layers to generate a dense latent representation h i = s Œ≤ (x i ). This representation is then shared with both the predictor network and the autoencoder. On the one hand, h i is passed through the predictor f Œ± in order to obtain the probability vector pi . Then, the prediction of an example x i is obtained by the function</p><formula xml:id="formula_2">f Œ±,Œ≤ (x i ) = f Œ± ‚Ä¢ s Œ≤ (x i ).</formula><p>On the other hand, h i is passed through the cVAE. It is first concatenated with pi and then is passed through the encoder of the cVAE and samples a latent vector z i . This latent vector concatenated with pi is passed through the decoder, so as to obtain a reconstructed example xi .</p><p>It can be noticed that the cVAE slightly differs from the original cVAE <ref type="bibr" target="#b23">[24]</ref>. Indeed, formally, the encoder of an end-to-end cVAE includes the shared layer, s Œ≤ . In our architecture, the condition is introduced at an intermediary latent representation of the examples. The idea behind this architecture is to enforce the dense latent representation to be as independent of the class as possible.</p><p>In addition, we adopt the same preprocessing as Guo et al. <ref type="bibr" target="#b8">[9]</ref> to handle categorical variables. At the input of the network, each categorical variable is encoded with a one-hot. At the output of the cVAE, we add a softmax activation function for each one-hot categorical variable in order to obtain a one-hot encoding format by taking the argmax. Finally, continuous variables are scaled to have all variables in [0, 1]. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Loss Function and Training Procedure</head><p>The objective of the training is to jointly learn the predictor and the cVAE. Then, the loss to minimize is made of two terms.</p><p>The first term is derived from the loss of a cVAE defined in Eq. 2. In our case, the cVAE is conditioned by the probability vector obtained at the output of the predictor. Then we can rewrite the objective function as:</p><formula xml:id="formula_3">L cV AE (Œ∏, œÜ, Œ≤; x i ) = -Œª 3 E q œÜ (zi|s Œ≤ (xi), pi) [log(p Œ∏ (x i | z i , pi ))] + Œª 1 D KL q œÜ (z i | s Œ≤ (x i ) , pi ) p(z i ) (3)</formula><p>Œª 1 and Œª 3 are weights to control the impact of each term during the training phase.</p><p>The second term enables us to learn the predictor. We use cross-entropy as classification loss between the output of the predictor pi = f Œ± ‚Ä¢ s Œ≤ (x i ) and the true label y i :</p><formula xml:id="formula_4">L pred (Œ±, Œ≤; x i , y i ) = l k=1 -1 [yi=k] log [f Œ± ‚Ä¢ s Œ≤ (x i )] k<label>(4)</label></formula><p>where [f Œ± ‚Ä¢ s Œ≤ (x i )] k denotes the predicted probability that x i belongs to the k-th class.</p><p>Then, the loss function on the training set (D) is a weighted sum of the losses from Eq. 4 and</p><p>Eq. 3 as follows:</p><formula xml:id="formula_5">L (Œ∏, Œ±, Œ≤, œÜ; D) = n i=1 L cV AE (Œ∏, œÜ, Œ≤; x i ) + Œª 2 1 n n i=1 L pred (Œ±, Œ≤; x i , y i )</formula><p>As mentioned at the beginning of this section, it is worth noticing that our problem is not to learn to generate counterfactuals. Then, contrary to CounterNet that has divergent objectives to optimize, the minimization of L is a simple optimization problem solved by back-propagation.</p><p>Note that Œª 1 ,Œª 2 ,Œª 3 are hyperparameters to tune for training.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Counterfactual Generation</head><p>Since our model does not directly produce counterfactuals, some modifications are needed for inference. An example x i is passed through the prediction network to obtain both its predicted probability vector ( pi ) and its dense vector representation (h i ). This dense vector representation (h i ) and the predicted probability vector ( pi ) are given to the encoder of the cVAE to produce a latent vector z i . Then, the decoder of the cVAE plays the role of a counterfactual generator.</p><p>Because we want to generate an example with a different predicted class we need a probability vector p c such that the class with maximum probability is different from the one of the prediction, i.e. arg max ( pi ) = arg max (p c ). In a binary-classification problem setup, we decided to use a one-hot vector where the probability is 0 for the predicted class of x i and 1 for the opposite class. The reason for this choice is that we want to generate counterfactuals for which the confidence in the predicted class is the highest for the predictor. In the case of a multi-class classification problem, we propose to select the class with the second-highest probability in pi and to switch the values with the predicted class. For example, if we obtain a probability vector pi = [0.6, 0.3, 0.1] then p c = [0.3, 0.6, 0.1]. An alternative solution would be to let the user select the class for which he/she is interested in having a counterfactual. This vector p c and the dense latent representation z i are passed through the cVAE decoder in order to infer a new predicted class to obtain a counterfactual<ref type="foot" target="#foot_2">3</ref> x c . As explained in Section 3.2, the intuition is to benefit from the disentanglement of the latent space of a cVAE: z i contains non-class-specific information about x i and p c encodes information for the desired class. As such, the decoder generates a new example x c that is similar to x i and that belongs to a different class.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments and Results</head><p>Our experiments are organized in four steps. Our main objective is to show that VCNet generates counterfactuals that are both valid (counterfactuals actually belong to another class) and realistic (counterfactuals are close to examples of the same class). In the first set of experiments, we present results of a cVAE on a synthetic dataset to confirm the actual disentanglement of the content and the class. These experiments also aim at providing some intuition about the reason why VCNet works. In the second set of experiments, we compare the results of VCNet with CounterNet, the state-of-the-art algorithm for self-explainable counterfactual generation. The reader interested in the results of more counterfactual generation systems may refer to the original article of Guo et al. <ref type="bibr" target="#b8">[9]</ref>. Our experiments use the same datasets and data preprocessing. In the third experiment, we evaluate the impact of join training on the quality of counterfactuals. We propose a post-hoc version of our framework and compare the results obtained with the jointly trained VCNet. Finally, we present some qualitative experiments on the MNIST dataset. We choose to present experiments on MNIST firstly because it has been widely used in the field of counterfactual generation and, secondly, because it illustrates that VCNet may be applied on different types of data (tabular, images, time series, ...).</p><p>The hyperparameters and architectures of the models used in these experiments are detailed in Supplementary material. The code to reproduce the results of this section is also provided in supplementary material.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">cVAE for counterfactual generation</head><p>Our proposal is based on using a cVAE to generate counterfactuals. It relies on the capability of a cVAE to actually disentangle the class and its content such that the decoder can be used to generate counterfactual examples by changing the class conditioning.In this experiment, we generate a synthetic dataset of examples in R 8 with three classes. Each class is distributed according to a multidimensional Gaussian distribution (see Figure <ref type="figure" target="#fig_1">2</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>on the left).</head><p>A cVAE, i.e. a couple of an encoder œï(x, c) and a decoder œà(z, c), is trained on a set of 10k examples. The complete code of these experiments is available in supplementary material for the sake of reproducibility.</p><p>Figure <ref type="figure" target="#fig_1">2</ref> illustrates the capability of a cVAE to generate realistic examples when changing the class that conditions the decoder. The figure on the left illustrates the dataset. Each colored group of point corresponds to a class. The three figures on the right illustrate datasets that have been generated x = œà(œï(x, c), c ) where x is an example from the test that belongs to class c (origin class). Each figure corresponds to one origin class, the colors of the point correspond to the conditioning class (c ). We observe that all figures look similar. This means that taking œà(œï(x, c), c ) generates an example that looks similar to an example of class c whatever the origin class of x. Thus, it demonstrates that cVAE can be used to generate realistic counterfactuals. Moreover, x is a good counterfactual if it is similar to x. The question is whether z = œï(x, c) is a better choice to generate an example œà(z, c ) than any other example œà(z , c ) (which also likely belongs to c ). To assess this behavior, we randomly generate 10 latent representations z = z + Œ¥ for each x, and compute the Euclidean distance between x = œà(z , c ) and x. Figure <ref type="figure" target="#fig_2">3</ref> shows three graphs: one per couple of classes (the class of the example to explain and the class requested as counterfactual). Each graph illustrates the mean Euclidean distance between x and x with respect to Œ¥ . When Œ¥ = 0, it uses the latent representation of x as input of the cVAE decoder. Intuitively, we expect to have œà(œï(x, c), c ) closer to x than œà(œï(x, c) + Œ¥, c ) and thus, that the higher Œ¥ , the higher the mean distance to the original example. The two graphics on the right illustrates the expected behavior. In these cases, the latent representation of the example seems to generate a counterfactual that is the most similar among the examples of the opposite class. Nonetheless, we observe that it is not always the case. We can note that the distance decreases when perturbing the latent representation of examples in class 0 and regenerating counterfactual examples in class 1. This may be explained by the proximity between the two classes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Comparison between VCNet and CounterNet</head><p>This section compares the quality of counterfactuals of VCNet against CounterNet. We conduct evaluations on six binary-classification datasets with various properties: Adult <ref type="bibr" target="#b13">[14]</ref>, HELOC <ref type="bibr" target="#b7">[8]</ref>, OULAD <ref type="bibr" target="#b14">[15]</ref>, Breast Cancer Wisconsin <ref type="bibr" target="#b2">[3]</ref>, Student performance <ref type="bibr" target="#b3">[4]</ref> and Titanic <ref type="bibr" target="#b10">[11]</ref>. Some of these datasets contain only numerical variables but some others, such as Adult, contain both numerical and categorical variables. More details about the datasets can be found in the supplementary material of the article.</p><p>To evaluate the counterfactual quality, we used the following four metrics that are classical in the literature. Prediction gain: The prediction gain is given by the difference between the predicted probability of the counterfactual x and the predicted probability of the example x, according to the counterfactual class <ref type="bibr" target="#b19">[20]</ref>.</p><formula xml:id="formula_6">Gain = [f pred (x )] yi -[f pred (x)] yi</formula><p>where y i denotes the predicted class for the counterfactual. A higher prediction gain means being more confident in the class change of the counterfactual.</p><p>Validity: A counterfactual is valid if it achieves to obtain a different predicted class <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b4">5]</ref>. Then:</p><formula xml:id="formula_7">Validity = 0, if y i = y 0 1, if y i = y 0</formula><p>where y i denotes the predicted class for the counterfactual and y 0 the predicted class for the example to explain.</p><p>Proximity: The proximity is the L 1 distance between an example, x and its counterfactual, x <ref type="bibr" target="#b17">[18,</ref><ref type="bibr">27]</ref>.</p><formula xml:id="formula_8">Proximity = x -x 1 = Œ¥ 1</formula><p>A low value indicates fewer changes of features to apply to the original example to obtain the counterfactual.</p><p>Proximity score: This metric is inspired from Laugel et al. <ref type="bibr" target="#b15">[16]</ref> to quantify the distance of a counterfactual to examples of the same predicted class:</p><formula xml:id="formula_9">P s (x ) = d (x , a 0 ) 1 H ( H -1)/2 xi,xj ‚ààH d (x i , x j )</formula><p>where d (x , a 0 ) is the Euclidean distance of the counterfactual to the closest example that has the same predicted class (a 0 ) and H is the set of existing examples that have the same predicted class as x . The insight behind this metric is that the counterfactual should be close to an existing example of the same predicted class relative to the rest of the data. Note that to be evaluated, this metric requires a set of m examples X ‚àà R m√óp .</p><p>For each dataset, we choose a random sample of size 25% for counterfactual generation. Then, we compute the mean and standard deviation of each metric for every selected random sample.</p><p>Table <ref type="table" target="#tab_0">1</ref> provides results of VCNet and CounterNet <ref type="bibr" target="#b8">[9]</ref>. More information on the reproducibility of CounterNet results is available in Supplementary material. It is worth noting that Table <ref type="table" target="#tab_0">1</ref> contains additional results for post-hoc VCNet that will be discussed in Section 5.3.</p><p>Counterfactual quality: VCNet achieves perfect validity for 4 of the 6 datasets, and a lower validity of respectively 4.5% and 7.5% for the 2 other datasets (Student and Titanic) compared to CounterNet.</p><p>As far as prediction gain and proximity score are concerned, VCNet outperforms CounterNet for all the 6 datasets. The higher the prediction gain, the more confidence one can have in the prediction related to the class change of the counterfactual. At the same time, a low proximity score reflects the achievement of counterfactuals that are close to real examples belonging to the same class as predicted for the counterfactual.</p><p>For the last evaluated metric that is proximity, we observe that VCNet achieves higher values than CounterNet on 5 of the 6 datasets. A larger proximity value means that the counterfactuals are obtained at the cost of larger changes in the input space.</p><p>Predictive accuracy: Both CounterNet and VCNet are self-explainable models, and if the previous results show that VCNet generates better counterfactuals, it can not be at the expense of the prediction accuracy. Thus, Table <ref type="table" target="#tab_0">1</ref> also presents model accuracies. We observe that VCNet achieved similar performances on 3 of the 6 datasets. On the other hand, the accuracies for the other datasets are lower by 0.4% (HELOC) to 2% (Student), which shows that our method still performs very well in terms of prediction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Impact of join-training on counterfactual quality</head><p>We derived our architecture to a post-hoc version (see Figure <ref type="figure" target="#fig_3">4</ref>). Its training procedure is the following: 1) we first train a prediction model. For our comparisons here, it is composed of the concatenation of the shared layers block and the predictor block of VCNet, but in practice it can be any machine learning model that outputs a probability score. Once the model is trained, we obtain a probability vector pi by forwarding an example x i to the model. 2) then we train a cVAE model conditionally to the probability vector ( pi ) output by the predictor learned during Step 1. The cVAE is composed of the same shared layers block than VCNet, but it is not shared with the predictor.  We compare VCNet with its post-hoc version (Post-hoc VCNet) in order to study the impact of join-training on counterfactuals. Table <ref type="table" target="#tab_0">1</ref> provides the results of the post-hoc version compared to those obtained previously with the join-training approach. We observe a drop of validity for every dataset, which justifies that the join-training approach allows a better alignment of the explanation task with the prediction task. We also observe a significant decrease in prediction gain for all datasets, which means less changes between an example to explain and its counterfactual. Besides, proximity is higher for 3 datasets (Adult, OULAD, Breast-cancer) and lower by respectively 9%, 1% and 0.8% on the remaining datasets (HELOC, Student, Titanic). Thus, we can argue that this drop of prediction gain does not benefit to closer counterfactuals w. indicates that the join-training approach is not at the cost of a lower accuracy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Qualitative results on MNIST dataset</head><p>We evaluated VCNet on the MNIST dataset<ref type="foot" target="#foot_3">4</ref> with metrics suggested in Section 5.2. This experiment illustrates that VCNet is adaptable to several types of data including image datasets. As CounterNet was not applied to image data in the original paper, we do not offer a comparison with this model here. This avoids a poor adaptation of CounterNet and an unfair comparison.</p><p>VCNet gives a mean validity of 0.99, a mean prediction gain of 0.98 and an accuracy of 0.98. The counterfactual quality metrics on MNIST show that VCNet is a good model to generate realistic and valid counterfactuals and, at the same time, to make accurate predictions. These results suggest that VCNet has also good capabilities to generate counterfactuals for images, and not only for tabular data. Figure <ref type="figure" target="#fig_4">5</ref> presents some examples to explain (in the first line) and corresponding counterfactuals generated with VCNet (second line). Each example to explain and its counterfactual is complemented by the predicted class, for instance E-7 means an example predicted class 7 and C-3 means a counterfactual predicted class 3. We first notice that each counterfactual "looks like" an example that matches the predicted class. Moreover, we observe that the orientation of the digits is often preserved, for example E-1 is converted in C-7 by keeping the orientation of E-1. C-6 is interesting as it shows that VCNet is able to provide a realistic counterfactual even if the class of the example to explain is not trivial.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>In this article, we propose VCNet, a new architecture for self-explainable classification based on counterfactuals examples. Our architecture generates at the same time the decision and a counterfactual that can be used by the analyst to understand the algorithm decision. The first advantage of VCNet is to generate explanations and decisions in a simple feed forward pass of the examples. Contrary to post-hoc counterfactuals explanation, VCNet does not require expensive optimization to generate counterfactuals.</p><p>The main contribution of this article is the use of a cVAE as a counterfactual generator in our model. The choice of a cVAE yields realistic counterfactuals and it is simple to train jointly with the prediction model.</p><p>We extensively evaluated the quality of the counterfactuals and compared them to CounterNet. We conclude that VCNet generates valid and realistic counterfactuals. The VCNet counterfactuals are realistic in the sense that they are close to existing examples of the same predicted class (VCNet has better proximity scores than CounterNet) and also the result of a higher confidence in the class change (VCNet has better prediction gains than CounterNet).</p><p>Finally, VCNet is simple to train because the training procedure is not based on counterfactuals directly, but on the disentanglement of the class and the content of examples by the cVAE. It allows proposing a simple optimisation procedure which makes our approach easier to put in practice. This is illustrated by its successful application to a dataset of images. In addition, it is also assessed in terms of model accuracy. Our experiments show that our join-training approach keeps its competitive prediction performance against CounterNet. A future work is to compare VCNet performances against state-of-the-art post-hoc counterfactuals methods and also to include actionability constraints. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B Implementation Details B.1 VCNet Details</head><p>We choose a binary cross entropy loss as the reconstruction error for the cVAE part and a cross entropy loss for the predictor part. We apply a grid search to tune hyperparameters that are specific for each datasets, these values are report in Table <ref type="table">3</ref>. We used an Adam optimizer for every dataset. Table <ref type="table">4</ref> describe the model architecture for every dataset. It contains the dimensions for each block of VCNet. For example, with the adult dataset, the shared encoding transforms an example x i of size 29 into a vector h i of size 15. Then the encoder of the cVAE part takes a concatenation of h i and the prediction vector pi to produce a vector of size 16. This vector is transform by the encoder to a lower representation of size 8 and finally a vector of size 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.2 Post-hoc VCNet For Tabular Data</head><p>For the post-hoc version of VCNet, the architecture is the same as detailed in Table <ref type="table">4</ref>. Nonetheless, hyperparameters for training change. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.3 Additional Information on CounterNet Reproducibility</head><p>We used the CounterNet code that was available at this link https://github.com/bkghz-orange-blue/ CounterNet. For fair comparison, we have computed counterfactuals from available trained models and used the same data processing for VCNet.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: VCNet architecture is composed of three blocks: Shared layers that transform the input into a latent representation (blue square), a predictor that outputs the prediction (brown square), and a conditional variational autoencoder that acts as a counterfactual generator during testing (red square).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Comparison of the examples/counterfactuals distributions for synthetic data. All graphics represent the projection of the examples or counterfacturals on the first two dimensions of the examples space (R 8 ). The graphic on the left represents the original dataset. The three other graphics represent counterfactuals generated from the examples of the test set belonging to each class. For this three rightmost graphics, the same examples have been used to generate counterfactuals with the two other classes. The color/shape of the point represents a class information: the class an example belongs to (graphic on the left) and the class requested for counterfactual generation (3 graphics on the right).</figDesc><graphic coords="9,133.94,101.03,361.42,106.94" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Distance between x, an example of class c to explain, and x = œà(z + Œ¥, c ), a counterfactual for class c perturbed in latent space by Œ¥. Each graphic illustrates this distance with respect to Œ¥ depending on the class c and c (on the right: c = 0 and c = 1; in the middle: c = 0 and c = 2; on the left: c = 1 and c = 2). The mean and variance are computed on 10 random Œ¥.</figDesc><graphic coords="10,99.92,101.03,361.42,116.71" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Post-hoc version of VCNet. (1) is the prediction model and (2) is the cVAE model.</figDesc><graphic coords="12,68.03,442.41,425.19,83.47" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Counterfactuals obtained with VCNet for the MNIST dataset. The top line corresponds to the examples to explain, the bottom to the corresponding counterfactuals.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Comparison of quality metrics of counterfactuals and predictive accuracy for three methods : VCNet, CounterNet and Post-hoc VCNet. Bold items give the best metric values among the three methods.</figDesc><table><row><cell cols="2">Datasets Metrics</cell><cell></cell><cell>Methods</cell><cell></cell></row><row><cell></cell><cell></cell><cell>VCNet</cell><cell cols="2">CounterNet Post-hoc VCNet</cell></row><row><cell>Adult</cell><cell>Validity</cell><cell>1.0</cell><cell>0.99</cell><cell>0.84</cell></row><row><cell></cell><cell>Proximity</cell><cell>7.71 ¬± 2.11</cell><cell>7.16¬± 2.13</cell><cell>7.28¬± 2.23</cell></row><row><cell></cell><cell>Prediction gain</cell><cell cols="2">0.76 ¬± 0.15 0.61¬±0.17</cell><cell>0.47¬±0.35</cell></row><row><cell></cell><cell cols="3">Proximity score 0.04 ¬± 0.11 0.31¬± 0.28</cell><cell>0.06¬±0.14</cell></row><row><cell></cell><cell>Accuracy</cell><cell>0.83</cell><cell>0.83</cell><cell>0.83</cell></row><row><cell cols="2">OULAD Validity</cell><cell>1.0</cell><cell>0.99</cell><cell>0.74</cell></row><row><cell></cell><cell>Proximity</cell><cell>11.66¬±2.46</cell><cell>11.96¬±2.40</cell><cell>11.22¬±2.54</cell></row><row><cell></cell><cell>Prediction gain</cell><cell>0.93¬±0.12</cell><cell>0.74¬±0.13</cell><cell>0.66¬±0.44</cell></row><row><cell></cell><cell cols="2">Proximity score 0.38¬±0.18</cell><cell>0.46¬±0.16</cell><cell>0.38¬±0.18</cell></row><row><cell></cell><cell>Accuracy</cell><cell>0.93</cell><cell>0.93</cell><cell>0.93</cell></row><row><cell>HELOC</cell><cell>Validity</cell><cell>1.0</cell><cell>0.99</cell><cell>0.77</cell></row><row><cell></cell><cell>Proximity</cell><cell>5.60¬±2.11</cell><cell>4.41¬±1.80</cell><cell>5.09¬±1.71</cell></row><row><cell></cell><cell>Prediction gain</cell><cell>0.64¬±0.13</cell><cell>0.56¬±0.15</cell><cell>0.24¬±0.25</cell></row><row><cell></cell><cell cols="2">Proximity score 0.23¬±0.21</cell><cell>0.49¬±0.35</cell><cell>0.40¬±0.32</cell></row><row><cell></cell><cell>Accuracy</cell><cell>0.71</cell><cell>0.72</cell><cell>0.71</cell></row><row><cell>Student</cell><cell>Validity</cell><cell>0.96</cell><cell>1.0</cell><cell>0.46</cell></row><row><cell></cell><cell>Proximity</cell><cell>19.90¬±3.21</cell><cell>19.86¬±2.78</cell><cell>19.68 ¬±3.03</cell></row><row><cell></cell><cell>Prediction gain</cell><cell>0.86¬±0.27</cell><cell>0.76¬±0.05</cell><cell>0.41¬±0.46</cell></row><row><cell></cell><cell cols="2">Proximity score 0.70¬±0.08</cell><cell>0.73¬±0.06</cell><cell>0.75¬±0.08</cell></row><row><cell></cell><cell>Accuracy</cell><cell>0.90</cell><cell>0.92</cell><cell>0.90</cell></row><row><cell>Titanic</cell><cell>Validity</cell><cell>0.92</cell><cell>0.99</cell><cell>0.38</cell></row><row><cell></cell><cell>Proximity</cell><cell>15.43¬±3.79</cell><cell>15.15¬±4.05</cell><cell>15.56¬±5.23</cell></row><row><cell></cell><cell>Prediction gain</cell><cell>0.69¬±0.31</cell><cell>0.66¬±0.15</cell><cell>0.26¬±0.36</cell></row><row><cell></cell><cell cols="2">Proximity score 0.71¬±0.21</cell><cell>0.80¬± 0.16</cell><cell>1.21¬±0.26</cell></row><row><cell></cell><cell>Accuracy</cell><cell>0.82</cell><cell>0.83</cell><cell>0.82</cell></row><row><cell>Breast-</cell><cell>Validity</cell><cell>1.0</cell><cell>1.0</cell><cell>0.59</cell></row><row><cell>cancer</cell><cell>Proximity</cell><cell>5.27¬±1.47</cell><cell>1.51¬±1.01</cell><cell>7.71¬±1.67</cell></row><row><cell></cell><cell>Prediction gain</cell><cell cols="2">0.95 ¬± 0.11 0.69¬±0.15</cell><cell>0.60¬±0.45</cell></row><row><cell></cell><cell cols="2">Proximity score 0.28¬±0.03</cell><cell>0.72¬±0.48</cell><cell>0.94¬± 0.07</cell></row><row><cell></cell><cell>Accuracy</cell><cell>0.96</cell><cell>0.96</cell><cell>0.96</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Datasets details Sandra Wachter, Brent Daniel Mittelstadt, and Chris Russell. Counterfactual explanations without opening the black box: Automated decisions and the GDPR. Harvard Journal of Law and Technology, 31(2):841-887, 2018.We used 6 binary-classification datasets for the comparison of VCNet with CounterNet. Table2describe the size of each dataset as well as the number of categorical and continuous variables.A.2 MNIST DatasetMNIST is composed of 60000 examples in train and 10000 examples in test. We used all of the test set for counterfactual generation.</figDesc><table><row><cell>Dataset</cell><cell>Size</cell><cell>Continuous</cell><cell>Categorical</cell></row><row><cell>Adult</cell><cell>32,561</cell><cell>2</cell><cell>6</cell></row><row><cell>Student</cell><cell>649</cell><cell>2</cell><cell>14</cell></row><row><cell>Titanic</cell><cell>891</cell><cell>2</cell><cell>24</cell></row><row><cell>HELOC</cell><cell>10,459</cell><cell>21</cell><cell>2</cell></row><row><cell>OULAD</cell><cell>32,593</cell><cell>23</cell><cell>8</cell></row><row><cell cols="2">Breast Cancer 569</cell><cell>30</cell><cell>0</cell></row><row><cell>[27] A Dataset Details</cell><cell></cell><cell></cell><cell></cell></row><row><cell>A.1 Tabular Data</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>Table 5 and 6 gives training hyperparameters for the cVAE model and prediction model respectively.</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>For Kingma et al<ref type="bibr" target="#b12">[13]</ref>, what we call the "content" in this paper is denoted the "style". It refers to the writing style of digits in MNIST-like datasets.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>By Self-explainable model here we mean that the predictor is constrained by the counterfactual generator during training but the explanation is not directly used to produce model output as in<ref type="bibr" target="#b0">[1]</ref>.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2"><p>Note that the quality of the generated counterfactual depends on the quality of the learned latent space.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3"><p>http://yann.lecun.com/exdb/mnist/</p></note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Towards robust interpretability with self-explaining neural networks</title>
		<author>
			<persName><forename type="first">David</forename><surname>Alvarez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Melis</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Tommi</forename><surname>Jaakkola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Advances in Neural Information Processing Systems (NIPS)</title>
		<meeting>the Conference on Advances in Neural Information Processing Systems (NIPS)</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="7786" to="7795" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Counterfactual explanations via latent space projection and interpolation</title>
		<author>
			<persName><forename type="first">Brian</forename><surname>Barr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Samuel</forename><surname>Matthew R Harrington</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Sharpe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bruss</forename><surname>Bayan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2112.00890</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">preprint</note>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">UCI repository of machine learning databases</title>
		<author>
			<persName><forename type="first">Catherine</forename><surname>Blake</surname></persName>
		</author>
		<ptr target="http://www.ics.uci.edu/mlearn/MLRepository.html" />
		<imprint>
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Using data mining to predict secondary school student performance</title>
		<author>
			<persName><forename type="first">Paulo</forename><surname>Cortez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alice</forename><surname>Maria</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gon√ßalves</forename><surname>Silva</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Annual Future Business Technology Conference</title>
		<meeting>Annual Future Business Technology Conference</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="5" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A framework and benchmarking study for counterfactual generating methods on tabular data</title>
		<author>
			<persName><forename type="first">Raphael Mazzine Barbosa De</forename><surname>Oliveira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Martens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied Sciences</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">16</biblScope>
			<biblScope unit="page">7274</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Cruds: Counterfactual recourse using disentangled subspaces</title>
		<author>
			<persName><forename type="first">Michael</forename><surname>Downs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><forename type="middle">L</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yaniv</forename><surname>Yacoby</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Finale</forename><surname>Doshi-Velez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weiwei</forename><surname>Pan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML Workshop on Human Interpretability in Machine Learning (WHI)</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="1" to="23" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Self-explaining AI as an alternative to interpretable AI</title>
		<author>
			<persName><forename type="first">C</forename><surname>Daniel</surname></persName>
		</author>
		<author>
			<persName><surname>Elton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Artificial General Intelligence (AGI)</title>
		<meeting>the International Conference on Artificial General Intelligence (AGI)</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="95" to="106" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<author>
			<persName><surname>Fico</surname></persName>
		</author>
		<ptr target="https://community.fico.com/s/explainable-machine-learning-challenge" />
		<title level="m">Explainable machine learning challenge</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">CounterNet: End-to-end training of counterfactual aware predictions</title>
		<author>
			<persName><forename type="first">Hangzhi</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thanh</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amulya</forename><surname>Yadav</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML Workshop on Algorithmic Recourse</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Disentangled representation learning for non-parallel text style transfer</title>
		<author>
			<persName><forename type="first">Vineet</forename><surname>John</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lili</forename><surname>Mou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hareesh</forename><surname>Bahuleyan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Olga</forename><surname>Vechtomova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL)</title>
		<meeting>the Annual Meeting of the Association for Computational Linguistics (ACL)</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="424" to="434" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<author>
			<persName><surname>Kaggle</surname></persName>
		</author>
		<ptr target="https://www.kaggle.com/c/titanic/overview" />
		<title level="m">Titanic -machine learning from disaster</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Auto-encoding variational Bayes</title>
		<author>
			<persName><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Max</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Learning Representations (ICLR)</title>
		<meeting>the International Conference on Learning Representations (ICLR)</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Semisupervised learning with deep generative models</title>
		<author>
			<persName><forename type="first">Shakir</forename><surname>Durk P Kingma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Danilo</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Max</forename><surname>Jimenez Rezende</surname></persName>
		</author>
		<author>
			<persName><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of International Conference on neural information processing systems (NIPS)</title>
		<meeting>International Conference on neural information processing systems (NIPS)</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="3581" to="3589" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">UCI machine learning repository: Adult data set</title>
		<author>
			<persName><forename type="first">R</forename><surname>Kohavi</surname></persName>
		</author>
		<author>
			<persName><surname>Becker</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Open university learning analytics dataset</title>
		<author>
			<persName><forename type="first">Jakub</forename><surname>Kuzilek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Martin</forename><surname>Hlosta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zdenek</forename><surname>Zdrahal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Scientific data</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">170171</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">The dangers of post-hoc interpretability: Unjustified counterfactual explanations</title>
		<author>
			<persName><forename type="first">Thibault</forename><surname>Laugel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marie-Jeanne</forename><surname>Lesot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christophe</forename><surname>Marsala</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xavier</forename><surname>Renard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marcin</forename><surname>Detyniecki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Joint Conference on Artificial Intelligence (IJCAI)</title>
		<meeting>the International Joint Conference on Artificial Intelligence (IJCAI)</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="2801" to="2807" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Interpretable Machine Learning</title>
		<author>
			<persName><forename type="first">Christoph</forename><surname>Molnar</surname></persName>
		</author>
		<editor>C. Molnar</editor>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note>2nd edition</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Explaining machine learning classifiers through diverse counterfactual explanations</title>
		<author>
			<persName><forename type="first">K</forename><surname>Ramaravind</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amit</forename><surname>Mothilal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chenhao</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName><surname>Tan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Fairness, Accountability, and Transparency (FAT)</title>
		<meeting>the Conference on Fairness, Accountability, and Transparency (FAT)</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="607" to="617" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Counterfactuals to control latent disentangled text representations for style transfer</title>
		<author>
			<persName><forename type="first">Sharmila</forename><surname>Reddy Nangi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Niyati</forename><surname>Chhaya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sopan</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nikhil</forename><surname>Kaushik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Harshit</forename><surname>Nyati</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL)</title>
		<meeting>the Annual Meeting of the Association for Computational Linguistics (ACL)</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="40" to="48" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">CounteRGAN: Generating realistic counterfactuals with residual generative adversarial nets</title>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Nemirovsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicolas</forename><surname>Thiebaut</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ye</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abhishek</forename><surname>Gupta</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2009.05199</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Learning model-agnostic counterfactual explanations for tabular data</title>
		<author>
			<persName><forename type="first">Martin</forename><surname>Pawelczyk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Klaus</forename><surname>Broelemann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gjergji</forename><surname>Kasneci</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of The Web Conference (WWW&apos;20)</title>
		<meeting>The Web Conference (WWW&apos;20)</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="3126" to="3132" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Stop explaining black box machine learning models for high stakes decisions and use interpretable models instead</title>
		<author>
			<persName><forename type="first">Cynthia</forename><surname>Rudin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="206" to="215" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Efficient search for diverse coherent explanations</title>
		<author>
			<persName><forename type="first">Chris</forename><surname>Russell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Fairness, Accountability, and Transparency (FAT)</title>
		<meeting>the Conference on Fairness, Accountability, and Transparency (FAT)<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Learning structured output representation using deep conditional generative models</title>
		<author>
			<persName><forename type="first">Kihyuk</forename><surname>Sohn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Honglak</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xinchen</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Advances in Neural Information Processing Systems (NIPS)</title>
		<meeting>the Conference on Advances in Neural Information Processing Systems (NIPS)</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="3483" to="3491" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Actionable recourse in linear classification</title>
		<author>
			<persName><forename type="first">Berk</forename><surname>Ustun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Spangher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yang</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Fairness, Accountability, and Transparency (FAT)</title>
		<meeting>the Conference on Fairness, Accountability, and Transparency (FAT)</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="10" to="19" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Interpretable counterfactual explanations guided by prototypes</title>
		<author>
			<persName><forename type="first">Arnaud</forename><surname>Van Looveren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Janis</forename><surname>Klaise</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Machine Learning and Knowledge Discovery in Databases (ECML/PKDD)</title>
		<meeting>the European Conference on Machine Learning and Knowledge Discovery in Databases (ECML/PKDD)</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="650" to="665" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
