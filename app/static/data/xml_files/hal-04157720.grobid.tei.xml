<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="fr">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">KheOps: Cost-effective Repeatability, Reproducibility, and Replicability of Edge-to-Cloud Experiments</title>
				<funder ref="#_FfJQ9aa">
					<orgName type="full">NIFA</orgName>
				</funder>
				<funder ref="#_DNdKT2m">
					<orgName type="full">Agence Nationale de la Recherche</orgName>
					<orgName type="abbreviated">ANR</orgName>
				</funder>
				<funder ref="#_8n96us8">
					<orgName type="full">HPC-BigData Inria Challenge (IPL)</orgName>
				</funder>
				<funder ref="#_gdqEaaN">
					<orgName type="full">National Science Foundation</orgName>
					<orgName type="abbreviated">NSF</orgName>
				</funder>
				<funder>
					<orgName type="full">Inria</orgName>
				</funder>
				<funder ref="#_48A5ZGN">
					<orgName type="full">U.S. Department of Energy, Office of Science</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Daniel</forename><surname>Rosendo</surname></persName>
							<email>daniel.rosendo@inria.fr</email>
						</author>
						<author>
							<persName><forename type="first">Kate</forename><surname>Keahey</surname></persName>
							<email>keahey@mcs.anl.gov</email>
						</author>
						<author>
							<persName><forename type="first">Alexandru</forename><surname>Costan</surname></persName>
							<email>alexandru.costan@inria.fr</email>
						</author>
						<author>
							<persName><forename type="first">Matthieu</forename><surname>Simonin</surname></persName>
							<email>matthieu.simonin@inria.fr</email>
						</author>
						<author>
							<persName><forename type="first">Patrick</forename><surname>Valduriez</surname></persName>
							<email>patrick.valduriez@inria.fr</email>
						</author>
						<author>
							<persName><forename type="first">Gabriel</forename><surname>Antoniu</surname></persName>
							<email>gabriel.antoniu@inria.fr</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Univ Rennes</orgName>
								<orgName type="institution" key="instit2">Inria</orgName>
								<orgName type="institution" key="instit3">CNRS</orgName>
								<orgName type="institution" key="instit4">IRISA Rennes</orgName>
								<address>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">Argonne National Laboratory Chicago</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="institution" key="instit1">Univ Rennes</orgName>
								<orgName type="institution" key="instit2">Inria</orgName>
								<orgName type="institution" key="instit3">CNRS</orgName>
								<orgName type="institution" key="instit4">IRISA Rennes</orgName>
								<address>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="institution" key="instit1">Univ Rennes</orgName>
								<orgName type="institution" key="instit2">Inria</orgName>
								<orgName type="institution" key="instit3">CNRS</orgName>
								<orgName type="institution" key="instit4">IRISA Rennes</orgName>
								<address>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff4">
								<orgName type="institution" key="instit1">Univ Montpellier</orgName>
								<orgName type="institution" key="instit2">Inria</orgName>
								<orgName type="institution" key="instit3">CNRS</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff5">
								<orgName type="institution">LIRMM Montpellier</orgName>
								<address>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff6">
								<orgName type="institution" key="instit1">Univ Rennes</orgName>
								<orgName type="institution" key="instit2">Inria</orgName>
								<orgName type="institution" key="instit3">CNRS</orgName>
								<orgName type="institution" key="instit4">IRISA Rennes</orgName>
								<address>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">KheOps: Cost-effective Repeatability, Reproducibility, and Replicability of Edge-to-Cloud Experiments</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">A78E088C7EAC3C06134FDD42E73D3D78</idno>
					<idno type="DOI">10.1145/3589806.3600032</idno>
					<note type="submission">Submitted on 10 Jul 2023</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-04-12T14:50+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Computing methodologies ‚Üí Distributed computing methodologies</term>
					<term>‚Ä¢ General and reference ‚Üí Experimentation</term>
					<term>Measurement</term>
					<term>Reproducibility, Replicability, Repeatability, Computing Continuum, Workflows, Edge Computing, Cloud Computing</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>de niveau recherche, publi√©s ou non, √©manant des √©tablissements d'enseignement et de recherche fran√ßais ou √©trangers, des laboratoires publics ou priv√©s.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="fr">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Modern scientific workflows require hybrid infrastructures, combining resources and services executed on the IoT/Edge with other resources and services running on Clouds or on HPC systems (the Computing Continuum <ref type="bibr" target="#b37">[39]</ref>) to enable their optimized execution. Due to the complexity of application deployments on such highly distributed and heterogeneous Edge-to-Cloud infrastructures, realizing the Computing Continuum vision in practice remains burdensome.</p><p>One challenge stems from systematically performing experiments on the continuum. In particular, the processes enabling their reproducibility, as well as the replication of the performance tradeoffs are inherently difficult <ref type="bibr" target="#b39">[41]</ref>. Figure <ref type="figure" target="#fig_1">1</ref> illustrates such processes. Let us consider the case of a group of researchers who execute their experiments on French scientific testbeds such as Grid'5000 <ref type="bibr" target="#b33">[35]</ref> (providing Cloud/HPC servers) and FIT IoT LAB <ref type="bibr" target="#b30">[32]</ref> (providing IoT/Edge devices), and want to publish their results in an article. Next, the readers want to replicate the experiments on American testbeds such as the Chameleon Cloud <ref type="bibr" target="#b43">[44]</ref> and CHI@Edge <ref type="bibr" target="#b42">[43]</ref>.</p><p>These processes compel a lot of effort, are time-consuming, and bring many technical challenges for both sides. For instance, also depicted in Figure <ref type="figure" target="#fig_1">1</ref>, they require: <ref type="bibr" target="#b0">(1)</ref> following methodologies to systematically design the experiments and to reconcile many application requirements or constraints in terms of energy consumption, network efficiency, and hardware resource usage; (2) configuring systems and networks, and deploying applications on testbeds for large-scale evaluations; (3) analyzing, repeating experiments, and publishing results; and (4) finally, providing open access to the experiment artifacts in a public and safe repository.</p><p>Given such complexities, researchers end up not following rigorous methodologies for supporting the reproducibility of the experiments, as observed in our previous survey <ref type="bibr" target="#b51">[52]</ref> and summarized in Figure <ref type="figure">2</ref>. As a consequence, it makes it hard for other researchers to replicate the published studies <ref type="bibr" target="#b45">[46]</ref>. Let us sum up the associated requirements in this context <ref type="bibr" target="#b38">[40,</ref><ref type="bibr" target="#b54">55]</ref>. To enable reproducible experiments on the Edge-to-Cloud continuum, the requirements (a-REQ) of the authors of the experiments can be described as follows:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Published Article</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Bob</head><p>a-REQ 1. Execute experiments on heterogeneous computing resources (e.g., IoT/Edge and Cloud/HPC infrastructures). a-REQ 2. Systematically describe and explain the experimental processes and their reasoning. a-REQ 3. Efficiently configure the experimental infrastructure and express topologies in repeatable ways. a-REQ 4. Easily share the experiment artifacts in a public and safe repository.</p><p>At the same time, to enable the replicability of the experiments, the readers of an article describing those experiments have the following requirements (r-REQ): r-REQ 1. Find and access the experiment as simply as finding and reading its paper. r-REQ 2. Perform the experiment, not just read about it. r-REQ 3. Answer not just to the "What" question (What the experiment does?), but also the "Why" (Why did authors set up that way?) and "How" (How did authors connect machines/devices?)</p><p>Figure <ref type="figure">2</ref>: Support to the reproducibility of Edge-to-Cloud experiments provided by the 34 studies in our survey <ref type="bibr" target="#b51">[52]</ref>.</p><p>r-REQ 4. Efficiently configure the experimental infrastructure to reduce the time spent satisfying all the experiment requirements. In this paper, we study the challenges of reproducing and replicating Edge-to-Cloud experiments in cost-effective ways. Costeffective means to allow authors and readers to easily fulfill their experimental requirements as previously described. This calls for practical solutions beyond the state-of-the-art.</p><p>Our main objective is to provide a collaborative environment and methodology that supports reproducible Edge-to-Coud experimentation between different open testbeds such as Grid'5000, FIT IoT LAB, Chameleon, etc., equipped to deal with IoT/Edge and Cloud/HPC resources which are fundamental to reproducibility <ref type="bibr" target="#b41">[42]</ref>. We propose the following main contributions:</p><p>(  Repeatability Same team, same experimental setup: the measurement can be obtained with stated precision by the same team using the same measurement procedure, the same measuring system, under the same operating conditions, in the same location on multiple trials. For computational experiments, this means that a researcher can reliably repeat their own computation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Reproducibility</head><p>Different team, same experimental setup: the measurement can be obtained with stated precision by a different team using the same measurement procedure, the same measuring system, under the same operating conditions, in the same or a different location on multiple trials. For computational experiments, this means that an independent group can obtain the same result using the author's own artifacts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Replicability</head><p>Different team, different experimental setup: the measurement can be obtained with stated precision by a different team, a different measuring system, in a different location on multiple trials. For computational experiments, this means that an independent group can obtain the same result using artifacts which they develop completely independently.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">BACKGROUND</head><p>In this section, we start by defining the terms repeatability, reproducibility, and replicability (Section 2.1). Next, we explore the following research question from the Computing Continuum perspective: What would a good collaborative system look like?</p><p>In our vision, it should: (1) allow users to share research artifacts in a public and safe repository (Section 2.2); (2) provide an environment for setting up and describing experiments step-by-step (Section 2.3); (3) provide experimental methodologies to leverage heterogeneous Edge-to-Cloud computing resources from various scientific testbeds, at large-scale (Section 2.4).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Repeatability, Reproducibility, Replicability</head><p>An important requirement for researchers from various communities is that the scientific claims be verifiable by others (i.e., building upon published results). As illustrated in Figure <ref type="figure">2</ref>, such requirement is hardly satisfied in the context of Computing Continuum experiments. This can be achieved through repeatability, reproducibility, and replicability (3Rs) <ref type="bibr" target="#b32">[34,</ref><ref type="bibr" target="#b55">56]</ref>. There are many non-uniform definitions of the 3Rs in literature. In this work, we follow the terminology proposed by the ACM Digital Library <ref type="bibr" target="#b0">[1]</ref> (Artifact Review and Badging version 1.1), as presented in Table <ref type="table" target="#tab_0">1</ref>.</p><p>Achieving repeatability means that one can reliably repeat the experiments and obtain precise measurements (e.g., Edge to Cloud processing latency, memory consumption, among others) by using the same methodology and artifacts (i.e., same testbed, same physical machines, same libraries/framework, same network configuration). Executing multiple experiments allows us to explore different scenario settings (e.g., varying the number of Edge devices) and explore the impact of various parameters (e.g., the network configuration between Edge devices and the Cloud server) on the performance metrics.</p><p>Reproducibility means that external researchers having access to the original methodology (e.g., configuration of physical machines, network and systems, scenario descriptions) and using their own artifacts (i.e., data sets, scripts, AI frameworks, etc.) can obtain precise measurements of the application processing latency and throughput, for instance.</p><p>Replicability refers to independent researchers (i.e., the readers of an article that was published by a different team) having access to the original methodology and artifacts (e.g., configuration of physical machines, processing steps, network setup, etc.) and performing the experiments in different testbeds. The goal is that independent researchers can obtain precise results and conclusions consistent with the original study.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Trovi sharing portal</head><p>Collaborative systems should be integrated with public and safe repositories providing open access to the research artifacts to enable the reproducibility of experiments. Repositories like Trovi <ref type="bibr" target="#b26">[28]</ref>, Kaggle <ref type="bibr" target="#b19">[21]</ref>, Code Ocean Explorer <ref type="bibr" target="#b8">[9]</ref>, AI Hub <ref type="bibr" target="#b6">[7]</ref>, GitHub <ref type="bibr" target="#b3">[4]</ref>, and Zenodo <ref type="bibr" target="#b4">[5]</ref> allow users to store versioned and citeable (e.g., through a DOI: Digital Object Identifier) artifacts such as code, datasets, or Jupyter notebooks, among others.</p><p>In this work, we leverage on the Trovi sharing portal because it provides a public REST API that facilitates integration with existing systems. Furthermore, Trovi provides a series of features to manage research artifacts such as: integration with GitHub and Zenodo; creating, packaging, and sharing artifacts as Jupyter notebooks with 500MB in total size by default; support for scientific testbeds like Chameleon, which allows users to re-launch the available artifacts on the testbed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Jupyter environment</head><p>Another important aspect for reproducible and replicable experiments is that collaborative systems support executable research packages composed of code, data, environment configurations, and experiment results. The most popular open-source solutions are Jupyter notebooks <ref type="bibr" target="#b44">[45]</ref> and Apache Zeppelin <ref type="bibr" target="#b7">[8]</ref>. In this work, we use Jupyter notebooks for packaging research artifacts due to its wider compatibility with operating systems and programming languages, and the community support.</p><p>The Jupyter project consists of JupyterHub, JupyterLab, and notebooks. JupyterHub aims to serve Cloud-based Jupyter notebooks for multiple users. The goal is to provide users a ready-to-use computational environment with their own workspace on shared resources. JupyterHub servers are customizable, scalable, and portable on a variety of infrastructures. It is composed of a Hub that manages the following sub-services: a proxy that receives requests from clients; spawners to monitor notebook servers; and an authenticator to manage how users access the system.</p><p>JupyterLab refers to a web-based user interface providing mainly: notebook, terminal, text editor, file browser, and rich outputs. It allows users to configure and arrange their experimental workflows, as well as adding extensions to expand and enrich functionalities.  Finally, notebooks allow users to create programming documents combining: (1) formatted text (e.g., prospective data that explains each step of an experiment workflow); (2) executable code with the respective outputs (e.g., retrospective data derived by the execution); and (3) experimental results with visualizations and various sorts of rich media, such as images and videos.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">E2Clab experimental methodology</head><p>Understanding and optimizing workflow performance requires executing and reproducing complex experiments at large scale. Several existing environments aid users to run such experiments. Their limitations are discussed in the next section and summarized in Table <ref type="table" target="#tab_1">2</ref>. Based on these findings and the specific Computing Continuum requirements, in this work we leverage the E2Clab methodology.</p><p>E2Clab <ref type="bibr" target="#b52">[53]</ref> is an open-source framework (available at <ref type="bibr" target="#b5">[6]</ref>) that implements a rigorous methodology (illustrated in Figure <ref type="figure" target="#fig_3">3</ref>) for designing experiments with real-world workloads on the Edge-to-Cloud Continuum. It allows researchers to reproduce the application behavior in a controlled environment in order to understand and optimize performance <ref type="bibr" target="#b50">[51]</ref>. E2Clab sits on top of EnOSlib <ref type="bibr" target="#b34">[36]</ref> to enforce the experiment configurations on testbeds. High-level features provided by E2Clab are: (i) reproducible experiments; (ii) mapping application parts (Edge, Fog and Cloud/HPC) and physical testbeds; (iii) experiment variation and transparent scaling of scenarios; (iv) defining Edge-to-Cloud network constraints; (v) experiment deployment, execution and monitoring (e.g., on Grid'5000, Chameleon, and FIT IoT LAB); and (vi) workflow optimization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">LIMITATIONS OF EXISTING COLLABORATIVE ENVIRONMENTS</head><p>We briefly discuss the limitations of state-of-the-art collaborative environments, with a focus on the specific challenges of the Computing Continuum.</p><p>Google Colab <ref type="bibr" target="#b16">[18]</ref>. Mainly used by the AI community (more than 50K users), it is a ready-to-use Jupyter notebook service. Colab notebooks are stored in the .ipynb open-source Jupyter notebook format <ref type="bibr" target="#b17">[19]</ref>, and come with the most popular AI libraries and frameworks installed (e.g., Scikit-Learn <ref type="bibr" target="#b49">[50]</ref>, TensorFlow <ref type="bibr" target="#b29">[31]</ref>, PyTorch <ref type="bibr" target="#b48">[49]</ref>, etc.) and allow users to run python code through the browser. It is typically used for machine learning, data analysis and education. Colab is popular because it allows users to share Jupyter notebooks without having to download, install, or run anything. Besdides, it provides free access to very expensive computing resources such as GPUs and TPUs. Colab permits multiple users to collaborate on the same notebook. Sharing datasets, ML models, pipelines, and notebooks on AI Hub <ref type="bibr" target="#b6">[7]</ref> is also possible (more than 167 notebooks). Its GitHub integration allows users to quickly open GitHub-hosted Jupyter notebooks in Google Colab.</p><p>Kaggle <ref type="bibr" target="#b19">[21]</ref>. This is a data science and AI platform that offers a customizable Jupyter notebook environment. Kaggle is a subsidiary of Google and, like Colab, it provides free access to GPUs as well as a repository of community-published (more than 10.3 million users) datasets (more than 50K public datasets) and code (e.g., machine learning code) with more than 400K public notebooks. Kaggle is integrated with AI Hub and is popular in the data science and machine learning communities. Kaggle is also well-known for promoting Community Competitions in machine learning at no cost. The main differences <ref type="bibr" target="#b18">[20]</ref> between Colab and Kaggle are: (1) Kaggle allows collaboration with other users on its Web site, while Colab allows collaboration with anyone using the notebook link; (2) Kaggle has a lot of data sets that users can use directly (e.g., notebooks already set up with Kaggle databases <ref type="bibr" target="#b20">[22]</ref>), while in Colab setting up notebooks with Google Drive <ref type="bibr" target="#b10">[11]</ref> or managing files <ref type="bibr" target="#b9">[10]</ref> (e.g., to load data sets, files, and images) requires extra work; and (3) Kaggle creates a history of notebook commits that we can be reviewed.</p><p>Code Ocean <ref type="bibr" target="#b35">[37]</ref>. Designed according to FAIR <ref type="bibr" target="#b56">[57]</ref> (i.e., Findable, Accessible, Interoperable, and Reusable), Code Ocean aims to make scientific work reproducible. It introduces the concept of Compute Capsule, which refers to Docker <ref type="bibr" target="#b13">[14]</ref> containers composed of code, data, environments, and results. Capsules provide ready-to-use tools such as Git, Jupyter, RStudio, among others. Its integration with Git allows users to save changes on capsules and then commit them with just one click. Furthermore, users can easily share the link of a capsule and grant permissions. Code Ocean provides scalable compute and storage resources hosted on Amazon Web Services. Resources used by capsules are scaled out when the demand exceeds the machine capacity. Finally, Code Ocean provides a public Capsule Repository <ref type="bibr" target="#b8">[9]</ref> with more than 1K research capsules. It allows authors of an article to incorporate capsules into the submission process via a Hub publishing API. Despite these systems being widely used by the AI and data science communities, they present some limitations that hinder their adoption for Computing Continuum research. Table <ref type="table" target="#tab_1">2</ref> summarizes these limitations in terms of:</p><p>(1) access to heterogeneous computing resources, from the IoT/Edge to the Cloud/HPC; (2) support for large-scale experimental evaluations; Listing 1: E2Clab: layers and services configuration. Hardware details described in Section 5.1.</p><p>(3) repeatability and reproducibility of experiments on the same hardware setup, and replicability on different infrastructures. In summary, collaborative environments lack support for providing access to heterogeneous resources (e.g., Edge-to-Cloud); performing experiments at large-scale; and achieving the repeatability, reproducibility, and the replicability of experiments in different testbeds. Hence, the need for novel approaches for reproducible evaluations of workflows targeting the characteristics of the Computing Continuum.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">KHEOPS DESIGN</head><p>This section introduces KheOps, a collaborative environment for the cost-effective reproducibility and replicability of Edge-to-Cloud experiments. KheOps is designed to meet the experimental requirements of both authors and readers as presented in Section 1.  Artifacts hosted in Trovi can also provide references to repositories like container registries (e.g., DockerHub <ref type="bibr" target="#b1">[2]</ref>), multipurpose repositories (e.g., Zenodo <ref type="bibr" target="#b4">[5]</ref>), code repositories (e.g., Github <ref type="bibr" target="#b3">[4]</ref>), and among others.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Architecture and implementation</head><p>4.1.2 Notebook environment. Following our previous work <ref type="bibr" target="#b31">[33]</ref> on integrating experiment workflows with Jupyter notebooks, we extend JupyterHub to authenticate users and to download (using the Trovi REST API) the experiment artifacts available at Trovi. We also extend JupyterLab to allow users to easily share their experiments in Trovi. Furthermore, JupyterLab is set up with the E2Clab framework as an experimental methodology.</p><p>The JupyterLab is packaged with code, data, environment configurations, and experiment results. Its notebooks (file extension .ipynb) allow users to run experiments step-by-step by combining text (e.g., explaining the reasoning of the experiments: What parameters? Why these parameters? and How it was set up?) with executable code. Such notebooks are ready to use (e.g., installed with required library/software), executed through a browser, and shared as a Trovi artifact.  (e.g., computing resources, network, and application execution) according to their experimental needs. The first file, named layers_services.yaml and presented in Listing 1, allows users to lease IoT/Edge and Cloud/HPC resources. Through this file, users may also set up their applications and services as presented in Listing 2. Next, the network.yaml file (Listing 3) allows users to define delay, loss, and bandwidth between computing resources. Finally, the workflow.yaml file (Listing 4) guides users to define the experiment workflow through three main steps: prepare (e.g., copy artifacts to remote nodes, install libraries, etc.), launch (e.g., execute the application parts), and finalize (e.g., backup results from remote nodes to the JupyterLab server).</p><p>E2Clab abstracts all the complexities of deploying and executing experiments across various testbeds. To do so, users need to add the credential files of the respective testbeds to their notebooks. Setting up a VPN is also supported as this may be required to enable the communication between different geographically distributed tesbeds (e.g., Chameleon in the USA and Grid'5000 in France).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Experimental workflow</head><p>In summary, the workflow for launching an experiment artifact on large-scale testbeds consists of 5 main steps. First, through a web interface, users can browse the list of experimental artifacts publicly available in Trovi (step 1). Selecting an artifact displays details such as the experiment description, the authors and contact information, and the artifact versions.</p><p>A launch button allows users to execute the artifact (step 2). This button redirects users to the JupyterHub service. After authentication, the request to launch the artifact is sent to the JupyterHub Spawner. Next, the Spawner spawns the JupyterLab server (step 3) and then it downloads experimental artifacts such as notebooks, code, and datasets, among others (step 4). The JupyterLab service is set up with the E2Clab framework as the experimental methodology. Finally, users can execute the code cells from the notebook to lease IoT/Edge and Cloud/HPC computing resources available on the testbeds, deploy and execute the application, and gather the experiment results (step 5).</p><p>Steps 2 to 4 are automatically executed. This is a one-click feature that allows users to have a ready-to-use environment for reproducing and replicating complex Edge-to-Cloud experiments in a cost-effective manner. Note that the whole workflow requires only three clicks: selecting the experiment artifact (step 1); then launching it (steps 2 to 4); and executing it on the testbeds (step 5).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">EVALUATION</head><p>In this section, we show how KheOps can be used to analyze the performance of a real-life Edge-to-Cloud application deployed in the African savanna (illustrated in Figure <ref type="figure" target="#fig_7">5</ref>). This application is composed of distributed Edge devices monitoring animal migration in the Serengeti region. Devices at the Edge collect and compress wildlife images, then the image is sent to the Cloud where the animal classification happens using a pre-trained Neural Network To reproduce the evaluations in this section, refer to [16].</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Edge Cloud</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Experimental setup</head><p>Application performance metrics. The main tracked metric is the processing time, which refers to the time required to: pre-process the image captured (e.g., image compression on the Edge device); transmit the image to the Cloud server; and finally decompress the image and predict the animal through an AI model. In addition, we analyze the amount of data transmitted to the Cloud and the resource consumption (e.g., CPU and memory) on the Edge device.</p><p>To increase the accuracy of the results, we measure the processing duration 100 times for each experiment, each time with a different image and an interval of 30 seconds (i.e., Edge devices transmit images to the Cloud server every 30 seconds). The remaining metrics are captured using Dool (Dstat) <ref type="bibr" target="#b2">[3]</ref> at application runtime. All results are presented as the mean followed by their respective 95% confidence interval.</p><p>KheOps replicability metric. To measure how close/precise readers experiments are from authors experiments, we define the Replicability Accuracy (ùëÖùëíùëù ùëéùëêùëêùë¢ùëüùëéùëêùë¶ ) metric. For assessing variability and error in results <ref type="bibr" target="#b47">[48]</ref>, a recommendation is to repeat the experiments multiple times to achieve narrower inferential error bars (i.e., confidence interval, standard deviation, etc.) <ref type="bibr" target="#b36">[38]</ref>. The Replicability Accuracy metric is calculated as Equation <ref type="formula">1</ref>:</p><formula xml:id="formula_0">ùëÖùëíùëù ùëéùëêùëêùë¢ùëüùëéùëêùë¶ = 1 - ùëöùëñùëõ(ùë• 1ùê¥ , ùë• 2ùê¥ ) ùëöùëéùë• (ùë• 1ùê¥ , ùë• 2ùê¥ ) - ùëöùëñùëõ(ùë• 1ùëÖ , ùë• 2ùëÖ ) ùëöùëéùë• (ùë• 1ùëÖ , ùë• 2ùëÖ ) (1)</formula><p>Ideally, ùëÖùëíùëù ùëéùëêùëêùë¢ùëüùëéùëêùë¶ would be close to 1. ùë• ùëñùê¥ and ùë• ùëñùëÖ refer to the application performance metric value obtained from authors and readers experiments, respectively. For instance, in Figure <ref type="figure" target="#fig_9">6a</ref>, ùë• 1ùê¥ refers to the Cloud-centric bar and ùë• 2ùê¥ to the Edge+Cloud bar.</p><p>Workload. Devices at the Edge transmit images (from the Snapshot Serengeti dataset <ref type="bibr" target="#b28">[30]</ref> composed of millions of wildlife images collected annually) to the Cloud server that predicts animals using a trained MobileNetV3 Convolutional Neural Network model. We evaluate this workload considering two network configurations, 25Kbit and 15Kbit bandwidth with a round-trip delay of 150ms.</p><p>Software. On the Edge devices, we use the zlib <ref type="bibr" target="#b22">[24]</ref> Python library to compress images. MQTT <ref type="bibr" target="#b21">[23]</ref> protocol is used to transmit images to the Cloud server. On the Cloud server, we use an MQTT broker to receive images, then zlib to decompress images, and finally PyTorch to predict animals.</p><p>Hardware. The authors perform experiments on the following testbeds in France: Grid'5000 and FIT IoT LAB. On Grid'5000 (Cloud server), they use the dahu <ref type="bibr" target="#b12">[13]</ref> machine equipped with an Intel Xeon Gold 6130 CPU 2.10GHz, 16 cores/CPU, 192GB of RAM, and Ethernet network. On FIT IoT LAB (Edge device), they use a Raspberry Pi 3 Model B <ref type="bibr" target="#b23">[25]</ref> with four ARM Cortex-A53 processing cores running at 1.2GHz, 1GB LPDDR2 memory, and 2.4GHz 802.11ac wireless LAN.</p><p>The readers replicate authors experiments on the following testbeds in USA: Chameleon Cloud and CHI@Edge. On Chameleon CHI@TACC (Cloud server), they use the Skylake <ref type="bibr" target="#b11">[12]</ref> machine equipped with an Intel Xeon Gold 6126 CPU 2.60GHz, 12 cores/CPU, 192GB of RAM, and Ethernet network. On CHI@Edge (Edge device), they use a Raspberry Pi 4 <ref type="bibr" target="#b24">[26]</ref>, with four BCM2711 Cortex-A72 processing cores running at 1.5GHz, 8GB LPDDR4 memory, and 2.4GHz and 5GHz 802.11ac wireless LAN.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">How KheOps helps experiment authors</head><p>Let us consider the requirements of the experiment authors (a-REQ) as introduced in Section 1.</p><p>a-REQ 1. Execute experiments on heterogeneous computing resources. KheOps provides access to IoT/Edge devices and Cloud/HPC resources at large-scale, using the E2Clab methodology. Supported testbeds include (but are not limited to, as explained in Section 6.3): Grid'5000, FIT IoT LAB. a-REQ 2. Systematically describe and explain the experimental processes and their reasoning. Through Jupyter notebooks and the E2Clab configuration files, the authors describe and explain the experiment design choices such as the layers (e.g., Edge and Cloud), the services (e.g., the Edge client and the Cloud server), the network constraints, and the application workflow execution. This is done in Jupyter notebooks by combining text (explaining the configurations) followed by executable code (E2Clab files).   We discuss the experimental results from the authors perspective, using the three application performance metrics mentioned earlier.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>5.2.1</head><p>Impact of the network on the processing time. Authors define two sets of experiments. In the first one (Figure <ref type="figure" target="#fig_9">6a</ref>), they fix the network bandwidth at 15Kbit and vary the processing approach between Cloud-centric and Hybrid (Edge+Cloud). In the second one (Figure <ref type="figure" target="#fig_9">6b</ref>), they fix the bandwidth at 25Kbit for both processing approaches.</p><p>From the results, the authors observe that the Hybrid (Edge+Cloud) approach outperforms the Cloud-centric one for both network configurations. In the 15Kbit bandwidth setup, the processing time for the Cloud-centric is about 27 seconds on average, against 24 seconds for the hybrid processing. In the 25Kbit bandwidth configuration, this difference is lower, 13 seconds and 11 seconds for the Cloudcentric and Hybrid, respectively. The higher the bandwidth, the lower will be the difference between the two processing approaches. This is because image transmission is the most time-consuming task among the other tasks (i.e., compressing/decompressing images and model inference).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>5.2.2</head><p>Amount of data sent to the Cloud. According to the results presented in Figure <ref type="figure" target="#fig_10">7a</ref>, authors observe that the Hybrid (Edge+Cloud) approach transmits less data (81kB/s on average) to the Cloud compared to the Cloud-centric approach (96kB/s on average). This is because, in Hybrid processing, Edge devices compress images before transmitting them to the Cloud. <ref type="figure" target="#fig_12">8a</ref> and<ref type="figure" target="#fig_12">8b</ref> show that there is no significant difference in the CPU and memory usage in the Edge device when changing between the Cloud-centric and Hybrid processing approaches. CPU usage is around 4.2% and 4.4% for Hybrid and Cloud-centric processing, respectively. Memory usage is around 0.38GB for both.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.3">Resource consumption on the Edge device. Results in Figures</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">How KheOps helps readers</head><p>After the authors publish their results, other researchers from a different lab download the article from a scientific database and decide to replicate the study on their own premises (e.g., on a different testbed). Following the same logic, we present how KheOps helps the readers to replicate the experiments cost-effectively, that is, according to the readers requirements (r-REQ) in Section 1.</p><p>r-REQ 1. Find and access the experiment as simply as finding and reading the paper. Through the KheOps web interface (step 1 in Figure <ref type="figure" target="#fig_4">4</ref>) the readers obtain access to all the public experiments shared by the community and available in Trovi. Then, they select the experiment shared by the authors of the article to get more details. r-REQ 2. Perform the experiment, not just read about it. Next, in the experiment details web page, readers can launch a JupyterLab server with artifacts in just a single click (steps 2, 3, and 4 in Figure <ref type="figure" target="#fig_4">4</ref>). Finally, following the experiment instructions described in the Jupyter notebook, the readers deploy and execute the experiments on their testbeds, such as (but not limited to): the Chameleon Cloud and CHI@Edge (step 5 in Figure <ref type="figure" target="#fig_4">4</ref>).   r-REQ 3. Experiment reasoning: "What", "Why", and "How". Before running the experiments, the readers can go through the Jupyter notebook to understand What the experiment does (e.g., capture and compress images on Edge devices and then decompress the images and predict the animals on the Cloud server). The readers can also discover Why the authors set up the experiment with a 25kbit and 15kbit network bandwidth. Finally, KheOps allows to understand How the authors interconnect the Edge devices with the Cloud server (e.g., assigning a public IP to the Cloud server, or opening firewall rules; using the MQTT protocol; among others). r-REQ 4. Efficiently configure the experimental infrastructure. To achieve this, the readers just have to adapt the layers_services configuration file (presented in Listing 1) to the Chameleon Cloud and CHI@Edge testbeds. Configuring the network bandwidth to 25kbit and then changing it to 15kbit is as simple as changing the rate parameter in the network file (Listing 3). Finally, copying data to the Edge device, interconnecting it with the Cloud server, launching the application, and finally collecting the results is as simple as defining the workflow configuration file (Listing 4). The network and workflow configuration files are testbed agnostic, meaning that users do not need to update these files when changing the deployment from Grid'5000 + FIT IoT LAB to Chameleon + CHI@Edge.</p><p>Next, we report on the replicated experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>5.3.1</head><p>Impact of the network on the processing time. From the results in Figures <ref type="figure" target="#fig_9">6c</ref> and<ref type="figure" target="#fig_9">6d</ref>, readers conclude that the Hybrid (Edge+Cloud) processing approach outperforms the Cloud-centric one for both network configurations. This conclusion is consistent with the results observed in the published article. Following the analysis, readers observe that in the 15Kbit bandwidth network configuration, the processing time for the Cloudcentric is about 8 seconds on average, against 6.5 seconds for the hybrid processing. In the 25Kbit bandwidth setup, this difference is lower, 5.5 seconds and 4 seconds for the Cloud-centric and Hybrid, respectively. Similarly to the authors results, readers also observe that the higher the bandwidth, the lower will be the difference between the two processing approaches.</p><p>Furthermore, as presented in Table <ref type="table" target="#tab_4">3</ref>, we highlight that readers obtained a replicability accuracy of 88.2% and 94.3% for 15Kbit and 25Kbit network configurations, respectively. 5.3.2 Amount of data sent to the Cloud. According to the results presented in Figure <ref type="figure" target="#fig_10">7b</ref>, readers observe that the Hybrid approach transmits less data than the Cloud-centric. The former transmits around 89.2kB/s and the latter 108.8kB/s. Compressing images on the Edge helps to reduce the amount of data sent to the Cloud server. This conclusion is also consistent with the published article and presents a replicability accuracy of 97.3%. <ref type="figure" target="#fig_12">8c</ref> and<ref type="figure" target="#fig_12">8d</ref> show that there is no significant difference in the CPU and memory usage between the Cloud-centric and the Hybrid processing approaches. CPU usage is around 5.1% and 5% for Hybrid and Cloud-centric processing, respectively. Memory usage is around 1.1GB for both. We highlight that these conclusions are consistent with the published article and present a replicability accuracy of 97.8% and 99.6% for CPU and memory usage, respectively. Despite readers observing a lower processing time compared to the authors, they could verify that their experiment conclusions are consistent with the original study, and their results present a high replicability accuracy (see Table <ref type="table" target="#tab_4">3</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.3">Resource consumption on the Edge device. Results in Figures</head><p>This time difference is expected since readers used a more powerful Edge device (Raspberry Pi4 against Raspberry Pi3) for processing the most time-consuming task (e.g., image compression and then transmission). The Raspberry Pi4 has more RAM memory (8GB vs. 1GB in Raspberry Pi3), a better CPU (1.5GHz vs. 1.2GHz), network (5GHz vs. 2.4GHz).</p><p>Furthermore, regarding the remaining metrics such as the amount of data sent to the Cloud and the CPU and memory usage on the Edge device, readers observe small differences when replicating the original study in different testbeds. This is due to the different deployment approaches used by each testbed, for instance, in FIT IoT LAB the Raspberry Pi 3 board runs an embedded Linux that is built with Yocto <ref type="bibr" target="#b27">[29]</ref>, while CHI@Edge is based on Docker <ref type="bibr" target="#b13">[14]</ref> containers. Despite that, the conclusions observed by authors and readers are the same and present high accuracies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">DISCUSSION</head><p>KheOps core elements (i.e., Trovi, JupyterLab, E2Clab) exhibit several features that make it a promising environment for advancing Computing Continuum research through reproducible and replicable experiments. We briefly discuss them here.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Usability and reusability</head><p>KheOps targets usability by allowing users to easily find experiment artifacts shared in Trovi and then to launch experiments in a JupyterLab server in just a few clicks. KheOps abstracts all the low-level details of defining and configuring the experimental environment. It provides a high-level abstraction for mapping application parts with the Edge and Cloud infrastructures. Besides, the configuration files used to define the whole experimental environment are designed to be easy to use and understand.</p><p>KheOps also targets reusability of the experiment artifacts. For instance, readers of an article can reuse the authors artifacts to replicate the study or build upon the existing artifacts to generate new results. In addition, through E2Clab User-Defined Services, users can define their own services (e.g., the Edge client and the Cloud server) with the desired deployment logic (e.g., mapping the services to the physical machines/devices; installing required software and packages; etc.). Such services can be shared in this repository <ref type="bibr" target="#b14">[15]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Analyzing other real-life applications</head><p>The KheOps approach is generic in terms of deployment and analysis of other applications. We highlight that, despite our evaluations focusing on the African savanna use-case, KheOps can be easily used in other contexts. Supporting new applications can be achieved by describing and implementing their logic in the User-Defined Services configuration file.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Integration with other scientific testbeds</head><p>The KheOps approach is generic with respect to the deployment testbeds. KheOps allows users to analyze application workflows on various large-scale scientific testbeds, beyond the four testbeds used in this work. The definition of the experimental environment through E2Clab configuration files (e.g., layer_services.yaml, network.yaml, and workflow.yaml) is tesbed agnostic, meaning that a deployment on the Grid'5000 testbed can be easily replicated in Chameleon (if the required computing resources are available).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4">Reproducibility and artifact availability</head><p>The experimental evaluations presented in this work follow a rigorous methodology <ref type="bibr" target="#b52">[53]</ref> to support reproducible Edge-to-Cloud experiments on large-scale scientific testbeds. All the experiment artifacts are publicly available [16] at the Trovi sharing portal and the results are also publicly available <ref type="bibr" target="#b15">[17]</ref> in our GitLab repository.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.5">KheOps limitations</head><p>Next, we discuss future research under the KheOps approach to help with experiment reproducibility.</p><p>Provenance data capture. It may assist in the processes of reproducing complex Edge-to-Cloud workflows <ref type="bibr" target="#b46">[47]</ref>. Typically, users have to execute and repeat various experiments. The output of this process generates hundreds of data related to the experimental setup (e.g., hardware, software, code, data set, etc.) and application workflow execution. Analyzing such data is only possible with the help of provenance data capture <ref type="bibr" target="#b53">[54]</ref>.</p><p>Abstract hardware description. The hardware configuration is a significant barrier to reproducibility <ref type="bibr" target="#b25">[27]</ref>, especially in complex Edge-to-Cloud deployments comprising heterogeneous computing resources. The description of resources should be in terms of hardware requirements to execute the experiments (e.g., CPU, GPU, memory, disk, and network). The goal is to abstract the hardware resource description among various testbeds, preventing independent researchers from knowing about the infrastructure of the original experimental environment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">RELATED WORK</head><p>We have not found in the literature related work proposing collaborative environments with a focus on the Edge-to-Cloud Continuum. Closer solutions to KheOps, but without focusing on the Computing Continuum, are Google Colab <ref type="bibr" target="#b16">[18]</ref>, Kaggle <ref type="bibr" target="#b19">[21]</ref>, and Code Ocean <ref type="bibr" target="#b35">[37]</ref> as presented in Section 3.</p><p>KheOps differs from Google Colab, Kaggle, and Code Ocean mainly regarding the features presented in Table <ref type="table" target="#tab_1">2</ref> (limitations) such as the access to heterogeneous Edge-to-Cloud resources; access to large-scale infrastructures; and supporting the experiment repeatability and reproducibility on the same hardware setup and replicability in different infrastructures. In addition, KheOps relies on open scientific testbeds (e.g., Grid5000, FIT IoT LAB, Chameleon, and CHI@Edge) that are highly reconfigurable and controllable and designed to support reproducible experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">CONCLUSION</head><p>KheOps is, to the best of our knowledge, the first collaborative environment supporting the cost-effective reproducibility of applications on the Edge-to-Cloud Continuum. It provides simplified abstractions for systematically defining and explaining the experimental environment through Jupyter notebooks (e.g., infrastructures, services, network, and workflow execution); provides access to heterogeneous computing resources from the IoT/Edge to the Cloud/HPC; and allows researchers to easily find and share the experiment artifacts in the Trovi portal.</p><p>The experimental validation shows that KheOps helps authors to make their experiments repeatable and reproducible on the Grid5000 and FIT IoT LAB testbeds. Furthermore, KheOps helps readers to cost-effectively replicate authors experiments in different infrastructures such as Chameleon Cloud + CHI@Edge testbeds, and obtain the same conclusions with accuracies &gt;88% for all performance metrics.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Alice ( 1 Figure 1 :</head><label>11</label><figDesc>Figure 1: Processes for reproducing and replicating experiments regarding the authors and readers point of view.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>1 )</head><label>1</label><figDesc>A study of the characteristics of the main state-of-theart collaborative environments (e.g., Google Colab, Kaggle, and Code Ocean) for enabling reproducible experiments. Their main limitations in the context of Computing Continuum research are discussed in Section 3. (2) A novel collaborative environment to enable reproducible Edge-to-Cloud experiments (Section 4). This approach, named KheOps, allows researchers to reproduce and replicate Edge-to-Cloud workflows cost-effectively. KheOps core elements are: (1) a portal for sharing experiment artifacts; (2) a notebook environment for packaging code, data, environment, and results; and (3) a multi-platform experimental methodology for deploying experiments on heterogeneous resources from the IoT/Edge (FIT IoT LAB and CHI@Edge) to the Cloud/HPC Continuum (Grid5000 and Chameleon). We highlight that KheOps may be integrated with other large-scale scientific testbeds. (3) An experimental validation of the proposed approach with a real-world use case deployed on real-life IoT/Edge devices and Cloud/HPC systems. The evaluations show that KheOps helps: (1) authors to perform reproducible experiments on the Grid5000 + FIT IoT LAB testbeds, and (2) readers to cost-effectively replicate authors experiments on the Chameleon Cloud + CHI@Edge testbeds, and obtain the same conclusions with high accuracies, &gt;88% for all performance metrics (Section 5).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: E2Clab experiment methodology [53].</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4</head><label>4</label><figDesc>Figure 4 presents the architecture of KheOps, which consists of three main components: (i) Trovi sharing portal; (ii) Jupyter environment (JupyterHub service and JupyterLab server); and (iii) E2Clab framework (multi-platform experiment methodology). Next, present the integration details of KheOps three components, and we briefly describe their main roles. 4.1.1 Experiment repository. KheOps uses Trovi to share research artifacts such as packaged experiments. These artifacts may be</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>4. 1 . 3 Figure 4 :</head><label>134</label><figDesc>Figure 4: KheOps architecture and experimental workflow.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>1 networks : 2 -src : cloud , dst : edge 3 delay : " 150 ms " , rate : " 25 kbit " , loss : " 0.02 " Listing 3: E2Clab: network configuration.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Edge-to-Cloud application: monitoring animals migration in the African savanna.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head></head><label></label><figDesc>Chameleon + CHI@Edge.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Cloud-centric vs Edge+Cloud processing: (a, b) executed by authors on Grid'5000 and FIT IoT LAB testbeds; and (c, d) replicated by readers on Chameleon Cloud and CHI@Edge testbeds.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: Amount of data sent to the Cloud regarding the Cloud-centric and Edge+Cloud processing approaches.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head></head><label></label><figDesc>Chameleon + CHI@Edge.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Figure 8 :</head><label>8</label><figDesc>Figure 8: Resource consumption on the Edge device: CPU and Memory usage.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>ACM Digital Library Terminology Version 1.1<ref type="bibr" target="#b0">[1]</ref> </figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Limitations of Existing Collaborative Environments.</figDesc><table><row><cell></cell><cell>Limitation</cell><cell>Google Colab</cell><cell>Code Ocean</cell><cell>Kaggle</cell></row><row><cell></cell><cell>Resource</cell><cell>CPU, disk, and memory limits; GPU types</cell><cell>experiments run on AWS virtual ma-</cell><cell>limits CPU, GPU, and TPU access; does</cell></row><row><cell></cell><cell>heterogeneity</cell><cell>available; no access to IoT/Edge devices;</cell><cell>chines; no access to IoT/Edge devices;</cell><cell>not support IoT/Edge devices;</cell></row><row><cell></cell><cell>Large-scale</cell><cell>limits sessions to 12 hours; paid access to</cell><cell>limits access to 10 compute hours; paid</cell><cell>limits execution time to 12 hours; paid</cell></row><row><cell></cell><cell>experiments</cell><cell>multiple computing resources.</cell><cell>access to multiple computing resources.</cell><cell>access to Google Cloud Services.</cell></row><row><cell></cell><cell></cell><cell>hard to repeat and reproduce experi-</cell><cell>lacks support for the reproducibility of</cell><cell>lacks support for the repeatability and re-</cell></row><row><cell></cell><cell></cell><cell>ments on the same hardware: resource</cell><cell>distributed experiments. Computing and</cell><cell>producibility of distributed experiments.</cell></row><row><cell></cell><cell>Repeatability,</cell><cell>availability varies over time and usage</cell><cell>storage resources are available in AWS</cell><cell>Computing resources vary over time and</cell></row><row><cell></cell><cell>Reproducibility,</cell><cell>limits fluctuate. Replicability in different</cell><cell>virtual machines in the clients virtual pri-</cell><cell>hence between accesses. Replicability in</cell></row><row><cell></cell><cell>Replicability</cell><cell>infrastructures (e.g., beyond Google ma-</cell><cell>vate cloud. Hard to replicate experiments</cell><cell>different infrastructures is not easy to set</cell></row><row><cell></cell><cell></cell><cell>chines) is not straightforward.</cell><cell>in different infrastructures.</cell><cell>up.</cell></row><row><cell cols="2">1 environment :</cell><cell></cell><cell></cell></row><row><cell>2</cell><cell cols="2">g5k : cluster : dahu</cell><cell></cell></row><row><cell>3</cell><cell cols="2">iotlab : cluster : grenoble</cell><cell></cell></row><row><cell cols="2">4 layers :</cell><cell></cell><cell></cell></row><row><cell cols="2">5 -name : cloud</cell><cell></cell><cell></cell></row><row><cell>6</cell><cell>services :</cell><cell></cell><cell></cell></row><row><cell>7</cell><cell>-name : Server</cell><cell></cell><cell></cell></row><row><cell>8</cell><cell cols="2">environment : g5k , quantity : 1</cell><cell></cell></row><row><cell cols="2">9 -name : edge</cell><cell></cell><cell></cell></row><row><cell>10</cell><cell>services :</cell><cell></cell><cell></cell></row><row><cell>11</cell><cell>-name : Client</cell><cell></cell><cell></cell></row><row><cell>12</cell><cell cols="3">environment : iotlab , archi : rpi3 , quantity : 5</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 :</head><label>3</label><figDesc>Accuracy of replicated experiments.</figDesc><table><row><cell>Metric</cell><cell>Replicability accuracy</cell><cell>Experiment result</cell></row><row><cell cols="2">Processing time 15Kbit 0.943</cell><cell>Figure 6a and 6c</cell></row><row><cell cols="2">Processing time 25Kbit 0.882</cell><cell>Figure 6b and 6d</cell></row><row><cell>Data sent to the cloud</cell><cell>0.973</cell><cell>Figure 7a and 7b</cell></row><row><cell>CPU usage</cell><cell>0.978</cell><cell>Figure 8a and 8c</cell></row><row><cell>Memory usage</cell><cell>0.996</cell><cell>Figure 8b and 8d</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>ACKNOWLEDGMENTS</head><p>This work was funded by <rs type="funder">Inria</rs> through the <rs type="funder">HPC-BigData Inria Challenge (IPL)</rs> and through the <rs type="programName">UNIFY Associate Team</rs> joint in the framework of the <rs type="institution">JLESC international lab</rs> and the <rs type="projectName">HPDaSc associate</rs> team with Brazil. It was co-funded by the <rs type="funder">French ANR OverFlow</rs> project (<rs type="grantNumber">ANR-15-CE25-0003</rs>). Experiments presented in this paper were carried out using the Chameleon Cloud, CHI@Edge, Grid'5000, and <rs type="institution">FIT IoT LAB</rs> testbeds, supported by a scientific interest group hosted by several Universities. We also would like to thank <rs type="institution">Argonne National Laboratory</rs> for supporting this work. This material is based upon work supported by the <rs type="funder">U.S. Department of Energy, Office of Science</rs>, under contract number <rs type="grantNumber">DE-AC02-06CH11357</rs> as well as by the <rs type="funder">NSF</rs> award <rs type="grantNumber">2130889</rs> and <rs type="funder">NIFA</rs> award <rs type="grantNumber">2021-67021-33775</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funded-project" xml:id="_8n96us8">
					<orgName type="project" subtype="full">HPDaSc associate</orgName>
					<orgName type="program" subtype="full">UNIFY Associate Team</orgName>
				</org>
				<org type="funding" xml:id="_DNdKT2m">
					<idno type="grant-number">ANR-15-CE25-0003</idno>
				</org>
				<org type="funding" xml:id="_48A5ZGN">
					<idno type="grant-number">DE-AC02-06CH11357</idno>
				</org>
				<org type="funding" xml:id="_gdqEaaN">
					<idno type="grant-number">2130889</idno>
				</org>
				<org type="funding" xml:id="_FfJQ9aa">
					<idno type="grant-number">2021-67021-33775</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<ptr target="https://www.acm.org/publications/policies/artifact-review-and-badging-current" />
		<title level="m">Artifact Review and Badging Version 1</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">What is Docker Hub? Retrieved Jun 1</title>
		<ptr target="https://www.docker.com/products/docker-hub/" />
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Dool (Dstat) monitoring</title>
		<ptr target="https://github.com/scottchiefbaker/dool" />
		<imprint>
			<date type="published" when="2018-01-14">2018. Jan 14, 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<ptr target="https://github.com/" />
		<title level="m">GitHub</title>
		<imprint>
			<date type="published" when="2018-01-14">2018. Jan 14, 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Zenodo</title>
		<ptr target="https://zenodo.org/" />
		<imprint>
			<date type="published" when="2018-01-14">2018. Jan 14, 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">E2Clab source code</title>
		<ptr target="https://gitlab.inria.fr/E2Clab/e2clab" />
		<imprint>
			<date type="published" when="2019-01-14">2019. Jan 14, 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<ptr target="https://aihub.cloud.google.com/" />
		<title level="m">AI Hub</title>
		<imprint>
			<date type="published" when="2023-01-14">2023. Jan 14, 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Apache Zeppelin</title>
		<ptr target="https://zeppelin.apache.org/" />
		<imprint>
			<date type="published" when="2023-01-15">2023. Jan 15, 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<ptr target="https://codeocean.com/explore" />
		<title level="m">Code Ocean Explore: Open Science Library</title>
		<imprint>
			<date type="published" when="2023-01-19">2023. Jan 19, 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Colab: Cloud Storage from the command line</title>
		<ptr target="https://cloud.google.com/storage/docs/gsutil" />
		<imprint>
			<date type="published" when="2023-01-18">2023. Jan 18, 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Colab: Google Spreadsheets</title>
		<ptr target="https://github.com/burnash/gspread#more-examples" />
		<imprint>
			<date type="published" when="2023-01-18">2023. Jan 18, 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Compute skylake cluster at CHI@TACC</title>
		<ptr target="https://www.chameleoncloud.org/hardware/node/sites/tacc/clusters/chameleon/nodes/0b0bceb9-14bf-423e-890f-3ef187511d71/" />
		<imprint>
			<date type="published" when="2023-02-16">2023. Feb 16, 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Dahu cluster</title>
		<ptr target="https://www.grid5000.fr/w/Grenoble:Hardware#dahu" />
		<imprint>
			<date type="published" when="2023-02-16">2023. Feb 16, 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<ptr target="https://www.docker.com/" />
		<title level="m">Docker</title>
		<imprint>
			<date type="published" when="2023-01-18">2023. Jan 18, 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<ptr target="https://www.chameleoncloud.org/experiment/share/347adbf3-7c14-4834-b802-b45fdd0d9564" />
		<title level="m">E2Clab User Defined Services</title>
		<imprint>
			<date type="published" when="2023-02-08">2023. Feb 8, 2023. 2023. Feb 8, 2023</date>
		</imprint>
	</monogr>
	<note>Experiment artifacts</note>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Experiment results</title>
		<ptr target="https://gitlab.inria.fr/E2Clab/Paper-Artifacts" />
		<imprint>
			<date type="published" when="2023-01-14">2023. Jan 14, 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Google Colab</title>
		<ptr target="https://colab.research.google.com/" />
		<imprint>
			<date type="published" when="2023-01-17">2023. Jan 17, 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Google Colab: Frequently Asked Questions</title>
		<ptr target="https://research.google.com/colaboratory/faq.html" />
		<imprint>
			<date type="published" when="2023-01-18">2023. Jan 18, 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Google Colab vs Kaggle</title>
		<ptr target="https://datasciencenotebook.org/compare/colab/kaggle" />
		<imprint>
			<date type="published" when="2023-01-20">2023. Jan 20, 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Kaggle community</title>
		<ptr target="https://www.kaggle.com/" />
		<imprint>
			<date type="published" when="2023-01-19">2023. Jan 19, 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Kaggle datasets</title>
		<ptr target="https://www.kaggle.com/datasets" />
		<imprint>
			<date type="published" when="2023-01-20">2023. Jan 20, 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">MQTT: The Standard for IoT Messaging</title>
		<ptr target="https://mqtt.org/" />
		<imprint>
			<date type="published" when="2023-02-16">2023. Feb 16, 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Python zlib</title>
		<ptr target="https://docs.python.org/3/library/zlib.html" />
		<imprint>
			<date type="published" when="2023-02-16">2023. Feb 16, 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<ptr target="https://www.iot-lab.info/docs/boards/raspberry-pi-3/" />
		<title level="m">Raspberry Pi 3 Model B</title>
		<imprint>
			<date type="published" when="2023-02-16">2023. Feb 16, 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<ptr target="https://chameleoncloud.org/experiment/chiedge/hardware-info/" />
		<title level="m">Raspberry Pi 4</title>
		<imprint>
			<date type="published" when="2023-02-16">2023. Feb 16, 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">SC: The largest Reproducibility Laboratory</title>
		<ptr target="https://www.chameleoncloud.org/blog/2023/02/20/sc-the-largest-reproducibility-laboratory/" />
		<imprint>
			<date type="published" when="2023-02-08">2023. Feb 8, 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Trovi: Practical Open Reproducibility</title>
		<ptr target="https://chameleoncloud.gitbook.io/trovi/" />
		<imprint>
			<date type="published" when="2023-01-20">2023. Jan 20, 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<ptr target="https://www.yoctoproject.org/" />
		<title level="m">Yocto Project</title>
		<imprint>
			<date type="published" when="2023-01-14">2023. Jan 14, 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Zooniverse dataset</title>
		<ptr target="https://www.zooniverse.org/organizations/meredithspalmer/snapshot-safari" />
		<imprint>
			<date type="published" when="2023-02-16">2023. Feb 16, 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Tensorflow: A system for large-scale machine learning</title>
		<author>
			<persName><forename type="first">Mart√≠n</forename><surname>Abadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paul</forename><surname>Barham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianmin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhifeng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andy</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeffrey</forename><surname>Dean</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthieu</forename><surname>Devin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sanjay</forename><surname>Ghemawat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Geoffrey</forename><surname>Irving</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Isard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">12th {USENIX} symposium on operating systems design and implementation</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="265" to="283" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">FIT IoT-LAB: A large scale open experimental IoT testbed</title>
		<author>
			<persName><forename type="first">Cedric</forename><surname>Adjih</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Emmanuel</forename><surname>Baccelli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><surname>Fleury</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gaetan</forename><surname>Harter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nathalie</forename><surname>Mitton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Noel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roger</forename><surname>Pissard-Gibollet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Frederic</forename><surname>Saint-Marcel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guillaume</forename><surname>Schreiner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julien</forename><surname>Vandaele</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2015 IEEE 2nd World Forum on Internet of Things (WF-IoT)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="459" to="464" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">A case for integrating experimental containers with notebooks</title>
		<author>
			<persName><forename type="first">Jason</forename><surname>Anderson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kate</forename><surname>Keahey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Cloud Computing Technology and Science (CloudCom)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019">2019. 2019</date>
			<biblScope unit="page" from="151" to="158" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Reproducible Research for Computing in Science Engineering</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">A</forename><surname>Barba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">K</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computing in Science Engineering</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="85" to="87" />
			<date type="published" when="2017">2017. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Grid&apos;5000: A Large Scale And Highly Reconfigurable Experimental Grid Testbed</title>
		<author>
			<persName><forename type="first">Rapha√´l</forename><surname>Bolze</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Franck</forename><surname>Cappello</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eddy</forename><surname>Caron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michel</forename><surname>Dayde</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fr√©d√©ric</forename><surname>Desprez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Emmanuel</forename><surname>Jeannot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yvon</forename><surname>J√©gou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephane</forename><surname>Lanteri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julien</forename><surname>Leduc</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nouredine</forename><surname>Melab</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guillaume</forename><surname>Mornet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Raymond</forename><surname>Namyst</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pascale</forename><surname>Primet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Qu√©tier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Olivier</forename><surname>Richard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">El-Ghazali</forename><surname>Talbi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ir√©a</forename><surname>Touche</surname></persName>
		</author>
		<idno type="DOI">10.1177/1094342006070078</idno>
		<ptr target="https://doi.org/10.1177/1094342006070078" />
	</analytic>
	<monogr>
		<title level="j">International Journal of High Performance Computing Applications</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="481" to="494" />
			<date type="published" when="2006">2006. 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Enoslib: A library for experiment-driven research in distributed computing</title>
		<author>
			<persName><forename type="first">Ronan-Alexandre</forename><surname>Cherrueau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marie</forename><surname>Delavergne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexandre</forename><surname>Van Kempen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adrien</forename><surname>Lebre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dimitri</forename><surname>Pertin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Javier</forename><forename type="middle">Rojas</forename><surname>Balderrama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anthony</forename><surname>Simonet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthieu</forename><surname>Simonin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Parallel and Distributed Systems</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1464" to="1477" />
			<date type="published" when="2021">2021. 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Computational reproducibility via containers in psychology</title>
		<author>
			<persName><forename type="first">Xu</forename><surname>Clyburne-Sherin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Seth</forename><forename type="middle">Ariel</forename><surname>Fei</surname></persName>
		</author>
		<author>
			<persName><surname>Green</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Meta-psychology</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Error bars in experimental biology</title>
		<author>
			<persName><forename type="first">Geoff</forename><surname>Cumming</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fiona</forename><surname>Fidler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">L</forename><surname>Vaux</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of cell biology</title>
		<imprint>
			<biblScope unit="volume">177</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="7" to="11" />
			<date type="published" when="2007">2007. 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<ptr target="https://www.etp4hpc.eu/sra.html" />
		<title level="m">ETP4HPC Strategic Research Agenda</title>
		<imprint>
			<date type="published" when="2020-04-29">April 29, 2020</date>
		</imprint>
	</monogr>
	<note>ETP4HPC</note>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">On reproducible AI: Towards reproducible research, open science, and digital scholarship in AI publications</title>
		<author>
			<persName><forename type="first">Erik</forename><surname>Odd</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yolanda</forename><surname>Gundersen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">W</forename><surname>Gil</surname></persName>
		</author>
		<author>
			<persName><surname>Aha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AI magazine</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="56" to="68" />
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Massive Analysis Quality Control (MAQC) Society Board of Directors Shraddha Thakkar 35 Kusko Rebecca 36</title>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Haibe-Kains</surname></persName>
		</author>
		<author>
			<persName><forename type="first">George</forename><forename type="middle">Alexandru</forename><surname>Adam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ahmed</forename><surname>Hosny</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Farnoosh</forename><surname>Khodakarami</surname></persName>
		</author>
		<imprint>
			<publisher>Sansone Susanna-Assunta 37 Tong Weida</publisher>
			<biblScope unit="page">35</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Transparency and reproducibility in artificial intelligence</title>
		<author>
			<persName><forename type="first">Wolfinger</forename><surname>Russ</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Mason</forename><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wendell</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Dopazo</forename><surname>Joaquin 41 Furlanello Cesare 42</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Levi</forename><surname>Waldron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bo</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Mcintosh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anna</forename><surname>Goldenberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anshul</forename><surname>Kundaje</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">586</biblScope>
			<biblScope unit="page" from="14" to="E16" />
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">The Silver Lining</title>
		<author>
			<persName><forename type="first">Kate</forename><surname>Keahey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Internet Computing</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="55" to="59" />
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Chameleon@Edge Community Workshop Report</title>
		<author>
			<persName><forename type="first">Kate</forename><surname>Keahey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><surname>Anderson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Sherman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhuo</forename><surname>Zhen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><surname>Powers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Isabel</forename><surname>Brunkan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Cooper</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Lessons learned from the chameleon testbed</title>
		<author>
			<persName><forename type="first">Kate</forename><surname>Keahey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><surname>Anderson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhuo</forename><surname>Zhen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pierre</forename><surname>Riteau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paul</forename><surname>Ruth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Stanzione</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mert</forename><surname>Cevik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Colleran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Haryadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cody</forename><surname>Gunawi</surname></persName>
		</author>
		<author>
			<persName><surname>Hammock</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">USENIX Annual Technical Conference (USENIX ATC 20)</title>
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
			<biblScope unit="page" from="219" to="233" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">Jupyter Notebooks-a publishing format for reproducible computational workflows</title>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Kluyver</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Ragan-Kelley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fernando</forename><surname>P√©rez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brian</forename><forename type="middle">E</forename><surname>Granger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthias</forename><surname>Bussonnier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Frederic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kyle</forename><surname>Kelley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jessica</forename><forename type="middle">B</forename><surname>Hamrick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><surname>Grout</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sylvain</forename><surname>Corlay</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016">2016. 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Learning from reproducing computational results: introducing three principles and the Reproduction Package</title>
		<author>
			<persName><surname>Matthew S Krafczyk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adhithya</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Bhaskar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Victoria</forename><surname>Marinov</surname></persName>
		</author>
		<author>
			<persName><surname>Stodden</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Philosophical Transactions of the Royal Society A</title>
		<imprint>
			<biblScope unit="volume">379</biblScope>
			<biblScope unit="page">20200069</biblScope>
			<date type="published" when="2021">2021. 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">Encyclopedia of database systems</title>
		<author>
			<persName><forename type="first">Ling</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Tamer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">√ñzsu</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
			<publisher>Springer</publisher>
			<biblScope unit="volume">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m">Reproducibility and replicability in science</title>
		<imprint>
			<publisher>National Academies Press</publisher>
			<date type="published" when="2019">2019</date>
		</imprint>
		<respStmt>
			<orgName>Engineering National Academies of Sciences, Medicine, et al</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Pytorch: An imperative style, high-performance deep learning library</title>
		<author>
			<persName><forename type="first">Adam</forename><surname>Paszke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sam</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Francisco</forename><surname>Massa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Lerer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Bradbury</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gregory</forename><surname>Chanan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Trevor</forename><surname>Killeen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zeming</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Natalia</forename><surname>Gimelshein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luca</forename><surname>Antiga</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in neural information processing systems</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="8026" to="8037" />
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Scikit-learn: Machine learning in Python</title>
		<author>
			<persName><forename type="first">Fabian</forename><surname>Pedregosa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ga√´l</forename><surname>Varoquaux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexandre</forename><surname>Gramfort</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vincent</forename><surname>Michel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bertrand</forename><surname>Thirion</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Olivier</forename><surname>Grisel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mathieu</forename><surname>Blondel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Prettenhofer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ron</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vincent</forename><surname>Dubourg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">the Journal of machine Learning research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2825" to="2830" />
			<date type="published" when="2011">2011. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Reproducible Performance Optimization of Complex Applications on the Edge-to-Cloud Continuum</title>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Rosendo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexandru</forename><surname>Costan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gabriel</forename><surname>Antoniu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthieu</forename><surname>Simonin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jean-Christophe</forename><surname>Lombardo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexis</forename><surname>Joly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Patrick</forename><surname>Valduriez</surname></persName>
		</author>
		<idno type="DOI">10.1109/Cluster48925.2021.00043</idno>
		<ptr target="https://doi.org/10.1109/Cluster48925.2021.00043" />
	</analytic>
	<monogr>
		<title level="m">Cluster 2021 -IEEE International Conference on Cluster Computing</title>
		<meeting><address><addrLine>Portland, OR, United States</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="23" to="34" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Distributed intelligence on the Edge-to-Cloud Continuum: A systematic literature review</title>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Rosendo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexandru</forename><surname>Costan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Patrick</forename><surname>Valduriez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gabriel</forename><surname>Antoniu</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.jpdc.2022.04.004</idno>
		<ptr target="https://doi.org/10.1016/j.jpdc.2022.04.004" />
	</analytic>
	<monogr>
		<title level="j">Journal of Parallel and Distributed Computing</title>
		<imprint>
			<biblScope unit="volume">166</biblScope>
			<biblScope unit="page" from="71" to="94" />
			<date type="published" when="2022-08">2022. Aug. 2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">E2Clab: Exploring the Computing Continuum through Repeatable, Replicable and Reproducible Edge-to-Cloud Experiments</title>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Rosendo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pedro</forename><surname>Silva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthieu</forename><surname>Simonin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexandru</forename><surname>Costan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gabriel</forename><surname>Antoniu</surname></persName>
		</author>
		<idno type="DOI">10.1109/CLUSTER49012.2020.00028</idno>
		<ptr target="https://doi.org/10.1109/CLUSTER49012.2020.00028" />
	</analytic>
	<monogr>
		<title level="m">Cluster 2020 -IEEE International Conference on Cluster Computing</title>
		<meeting><address><addrLine>Kobe, Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="1" to="11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Keeping Track of User Steering Actions in Dynamic Workflows</title>
		<author>
			<persName><forename type="first">Renan</forename><surname>Souza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V√≠tor</forename><surname>Silva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jose</forename><forename type="middle">J</forename><surname>Camata</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">G A</forename><surname>Alvaro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Patrick</forename><surname>Coutinho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marta</forename><surname>Valduriez</surname></persName>
		</author>
		<author>
			<persName><surname>Mattoso</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.future.2019.05.011</idno>
		<ptr target="https://doi.org/10.1016/j.future.2019.05.011" />
	</analytic>
	<monogr>
		<title level="j">Future Generation Computer Systems</title>
		<imprint>
			<biblScope unit="volume">99</biblScope>
			<biblScope unit="page" from="624" to="643" />
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Enhancing reproducibility for computational methods</title>
		<author>
			<persName><forename type="first">Victoria</forename><surname>Stodden</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marcia</forename><surname>Mcnutt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">H</forename><surname>Bailey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ewa</forename><surname>Deelman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yolanda</forename><surname>Gil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brooks</forename><surname>Hanson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><forename type="middle">A</forename><surname>Heroux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><forename type="middle">Pa</forename><surname>Ioannidis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michela</forename><surname>Taufer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">354</biblScope>
			<biblScope unit="page" from="1240" to="1241" />
			<date type="published" when="2016">2016. 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Best Practices for Computational Science: Software Infrastructure and Environments for Reproducible and Extensible Research</title>
		<author>
			<persName><forename type="first">Victoria</forename><surname>Stodden</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sheila</forename><surname>Miguez</surname></persName>
		</author>
		<idno type="DOI">10.5334/jors.ay</idno>
		<ptr target="https://openresearchsoftware.metajnl.com/articles/10.5334/jors.ay" />
	</analytic>
	<monogr>
		<title level="j">Journal of Open Research Software</title>
		<imprint>
			<date type="published" when="2014-07">2014. Jul 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">The FAIR Guiding Principles for scientific data management and stewardship</title>
		<author>
			<persName><forename type="first">Michel</forename><surname>Mark D Wilkinson</surname></persName>
		</author>
		<author>
			<persName><surname>Dumontier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jan</forename><surname>Ijsbrand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gabrielle</forename><surname>Aalbersberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Myles</forename><surname>Appleton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arie</forename><surname>Axton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Niklas</forename><surname>Baak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jan-Willem</forename><surname>Blomberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luiz</forename><surname>Boiten</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Silva</forename><surname>Bonino Da</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Philip</forename><forename type="middle">E</forename><surname>Santos</surname></persName>
		</author>
		<author>
			<persName><surname>Bourne</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Scientific data</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="9" />
			<date type="published" when="2016">2016. 2016</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
