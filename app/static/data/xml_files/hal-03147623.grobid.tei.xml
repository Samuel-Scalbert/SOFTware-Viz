<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">The Tractability of SHAP-Score-Based Explanations over Deterministic and Decomposable Boolean Circuits</title>
				<funder ref="#_7yKQuk7">
					<orgName type="full">Fondecyt</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2020-12-10">10 Dec 2020</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Marcelo</forename><surname>Arenas</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Universidad Católica de Chile</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Institute for Mathematical and Computational Engineering</orgName>
								<orgName type="institution">Universidad Católica de Chile 3 IMFD Chile</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Pablo</forename><surname>Barceló</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Institute for Mathematical and Computational Engineering</orgName>
								<orgName type="institution">Universidad Católica de Chile 3 IMFD Chile</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Leopoldo</forename><surname>Bertossi</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">Universidad Adolfo Ibáñez</orgName>
								<address>
									<settlement>FIC</settlement>
									<country key="CL">Chile</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Mikaël</forename><surname>Monet</surname></persName>
							<affiliation key="aff3">
								<orgName type="laboratory">UMR 9189</orgName>
								<orgName type="institution">Inria Lille -Nord Europe</orgName>
								<address>
									<settlement>CRIStAL</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">The Tractability of SHAP-Score-Based Explanations over Deterministic and Decomposable Boolean Circuits</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2020-12-10">10 Dec 2020</date>
						</imprint>
					</monogr>
					<idno type="MD5">AC445C7B3E8803DA8EDC41B7F9D48D19</idno>
					<idno type="arXiv">arXiv:2007.14045v2[cs.AI]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-04-12T14:49+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Scores based on Shapley values are widely used for providing explanations to classification results over machine learning models. A prime example of this is the influential SHAPscore, a version of the Shapley value that can help explain the result of a learned model on a specific entity by assigning a score to every feature. While in general computing Shapley values is a computationally intractable problem, it has recently been claimed that the SHAP-score can be computed in polynomial time over the class of decision trees. In this paper, we provide a proof of a stronger result over Boolean models: the SHAP-score can be computed in polynomial time over deterministic and decomposable Boolean circuits. Such circuits, also known as tractable Boolean circuits, generalize a wide range of Boolean circuits and binary decision diagrams classes, including binary decision trees, Ordered Binary Decision Diagrams (OBDDs) and Free Binary Decision Diagrams (FBDDs). We also establish the computational limits of the notion of SHAP-score by observing that, under a mild condition, computing it over a class of Boolean models is always polynomially as hard as the model counting problem for that class. This implies that both determinism and decomposability are essential properties for the circuits that we consider, as removing one or the other renders the problem of computing the SHAP-score intractable (namely, #P-hard).</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Explainable artificial intelligence has become an active area of research. Central to it is the observation that artificial intelligence (AI) and machine learning (ML) models cannot always be blindly applied without being able to interpret and explain their results. For example, when someone applies for a loan and sees their application rejected by an algorithmic decision-making system, the system should be able to provide an explanation for that decision. Explanations can be global -focusing on the general input/output relation of the model -, or local -focusing on how features affect the decision of the model for a specific input. Recent literature has strengthened the importance of the latter by showing their ability to provide explanations that are often overlooked by global explanations <ref type="bibr" target="#b15">(Molnar 2020)</ref>.</p><p>One natural way of providing local explanations for classification models consists in assigning numerical scores to the feature values of an entity that has gone through the classification process. Intuitively, the higher the score of a feature value, the more relevant it should be considered. It is in this context that the SHAP-score has been introduced <ref type="bibr" target="#b13">(Lundberg and Lee 2017;</ref><ref type="bibr" target="#b12">Lundberg et al. 2020)</ref>. This recent notion has rapidly gained attention and is becoming influential. There are two properties of the SHAP-score that support its rapid adoption. First, its definition is quite general and can be applied to any kind of classification model. Second, the definition of the SHAP-score is grounded on the well-known Shapley value <ref type="bibr" target="#b19">(Shapley 1953;</ref><ref type="bibr" target="#b18">Roth 1988</ref>), that has already been used successfully in several domains of computer science; see, e.g., <ref type="bibr" target="#b10">(Hunter and Konieczny 2010;</ref><ref type="bibr" target="#b11">Livshits et al. 2020;</ref><ref type="bibr" target="#b14">Michalak et al. 2013;</ref><ref type="bibr" target="#b3">Cesari et al. 2018)</ref>. Thus, SHAP-scores have a clear, intuitive, combinatorial meaning, and inherit all the desirable properties of the Shapley value.</p><p>For a given classifier M , entity e and feature x, the SHAP-score SHAP(M, e, x) intuitively represents the importance of the feature value e(x) to the classification result M (e). In its general formulation, SHAP(M, e, x) is a weighted average of differences of expected values of the outcomes (c.f. Section 2 for its formal definition). Unfortunately, computing quantities that are based on the notion of Shapley value is in general intractable. Indeed, in many scenarios the computation turns out to be #Phard <ref type="bibr" target="#b9">(Faigle and Kern 1992;</ref><ref type="bibr" target="#b8">Deng and Papadimitriou 1994;</ref><ref type="bibr" target="#b11">Livshits et al. 2020;</ref><ref type="bibr" target="#b2">Bertossi et al. 2020)</ref>, which makes the notion difficult to use -if not impossible -for practical purposes <ref type="bibr" target="#b1">(Arora and Barak 2009)</ref>. Therefore, a natural question is: For what kinds of classification models the computation of the SHAP-score can be done efficiently? This is the subject of this paper.</p><p>In this work, we focus on classifiers working with binary feature values (i.e., propositional features that can take the values 0 or 1), and that return 1 (accept) or 0 (reject) for each entity. We will call these Boolean classifiers. The second assumption that we make is that the underlying probability distribution on the population of entities is what we call a product distribution, where each binary feature x has a probability p(x) of being equal to 1, independently of the other features. We note here that the restriction to binary inputs can be relevant in many practical scenarios where the features are of a propositional nature.</p><p>More specifically, we investigate Boolean classifiers defined as deterministic and decomposable Boolean circuits, a widely studied model in knowledge compilation <ref type="bibr" target="#b5">(Darwiche 2001;</ref><ref type="bibr" target="#b7">Darwiche and Marquis 2002)</ref>. Such circuits encompass a wide range of Boolean models and binary decision diagrams classes that are considered in knowledge compilation, and in AI more generally. For instance, they generalize binary decision trees, ordered binary decision diagrams (OBDDs), free binary decision diagrams (FB-DDs), and deterministic and decomposable negation normal norms (d-DNNFs) <ref type="bibr" target="#b5">(Darwiche 2001;</ref><ref type="bibr" target="#b0">Amarilli et al. 2020;</ref><ref type="bibr" target="#b6">Darwiche and Hirth 2020)</ref>. These circuits are also known under the name of tractable Boolean circuits, that is used in recent literature <ref type="bibr" target="#b23">(Shih, Darwiche, and Choi 2019;</ref><ref type="bibr" target="#b20">Shi et al. 2020;</ref><ref type="bibr">Shih, Choi, and Darwiche 2018b,a;</ref><ref type="bibr">Shih et al. 2019;</ref><ref type="bibr" target="#b16">Peharz et al. 2020</ref>). We provide an example of a deterministic and decomposable Boolean circuit next (and give the formal definition in Section 2).</p><p>Example 1.1. We want to classify papers submitted to a conference as rejected (Boolean value 0) or accepted (Boolean value 1). Papers are described by features fg, dtr, nf and na, which stand for "follows guidelines", "deep theoretical result", "new framework" and "nice applications", respectively. The Boolean classifier for the papers is given by the Boolean circuit in Figure <ref type="figure">1</ref>. The input of this circuit are the features fg, dtr, nf and na, each of which can take value either 0 or 1, depending on whether the feature is present (1) or absent (0). The nodes with labels ¬, ∨ or ∧ are logic gates, and the associated Boolean value of each one of them depends on the logical connective represented by its label and the Boolean values of its inputs. The output value of the circuit is given by the top node in the figure . 
The Boolean circuit in Figure <ref type="figure">1</ref> is said to be decomposable, because for each ∧-gate, the sets of features of its inputs are pairwise disjoint. For instance, in the case of the top node in Figure <ref type="figure">1</ref>, the left-hand side input has {fg} as its set of features, while its right-hand side input has {dtr, nf, na} as its set of features, which are disjoint. Also, this circuit is said to be deterministic, which means that for every ∨-gate, two (or more) of its inputs cannot be given value 1 by the same Boolean assignment for the features. For instance, in the case of the only ∨-gate in Figure <ref type="figure">1</ref>, if a Boolean assignment for the features gives value 1 to its left-hand side input, then feature dtr has to be given value 1 and, thus, such an assignment gives value 0 to the right-hand side input of the ∨gate. In the same way, it can be shown that if a Boolean assignment for the features gives value 1 to the right-hand side input of this ∨-gate, then it gives value 0 to its left-hand side input.</p><p>Readers who are not familiar with knowledge compilation can simply think about deterministic and decomposable circuits as a tool for establishing in a uniform manner the tractability of computing SHAP-scores on several Boolean classifier classes. Our main contributions are the following:</p><p>1. We provide a polynomial time algorithm that computes the SHAP-score for deterministic and decomposable Boolean circuits, in the special case of uniform prob- ability distributions (that is, when each p(x) is 1 2 ). In particular, this provides a precise proof of the claim made in <ref type="bibr" target="#b12">(Lundberg et al. 2020</ref>) that the SHAP-score for Boolean classifiers given as decision trees can be computed in polynomial time. Moreover, we also obtain as a corollary that the SHAP-score for Boolean classifiers given as OB-DDs, FBDDs and d-DNNFs can be computed in polynomial time.</p><p>2. We observe that computing the SHAP-score on Boolean circuits in a class is always polynomially as hard as the model counting problem for that class (under a mild condition). By using this observation, we obtain that each one of the determinism assumption and the decomposability assumption is necessary for tractability.</p><p>3. Last, we show that the results above (and most interestingly, the polynomial-time algorithm) can be extended to the SHAP-score defined on product distributions for the entity population.</p><p>Our contributions should be compared to the results obtained in the contemporaneous paper <ref type="bibr" target="#b25">(Van den Broeck et al. 2020)</ref>. There, the authors establish the following theorem: for every class C of classifiers and under product distributions, the problem of computing the SHAP-score for C is polynomial-time equivalent to the problem of computing the expected value for the models in C. Since computing expectations is in polynomial time for tractable Boolean circuits, this in particular implies that computing the SHAP-score is in polynomial time for the circuits that we consider; in other words, their results capture ours. However, there is a fundamental difference in the approach taken to show tractability: their reduction uses multiple oracle calls to the problem of computing expectations, whereas we provide a more direct algorithm to compute the SHAP-score on these circuits.</p><p>Our algorithm for computing the SHAP-score could be used in practical scenarios. Indeed, recently, some classes of classifiers have been compiled into tractable Boolean circuits. This is the case, for instance, of Bayesian Classifiers <ref type="bibr">(Shih, Choi, and Darwiche 2018a)</ref>, Binary Neural Networks <ref type="bibr" target="#b20">(Shi et al. 2020)</ref>, and Random Forests <ref type="bibr" target="#b4">(Choi et al. 2020)</ref>. The idea is to start with a Boolean classifier M given in a formalism that is hard to interpret -for instance a Binary neural network -and to compute a tractable Boolean circuit M ′ that is equivalent to M (this computation can be expensive). One can then use M ′ and the nice properties of tractable Boolean circuits to interpret the decisions of the model. Hence, this makes it possible to apply the results in this paper on the SHAP-score to those classes of classifiers.</p><p>Paper structure. We give preliminaries in Section 2. In Section 3, we prove that the SHAP-score can be computed in polynomial time for deterministic and decomposable Boolean circuits for uniform probability distributions. In Section 4 we establish the limits of the tractable computation of the SHAP-score. Next we show in Section 5 that our results extend to the setting where we consider product distributions. We conclude and discuss future work in Section 6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Preliminaries</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Entities, distributions and classifiers</head><p>Let X be a finite set of features, also called variables. An entity over X is a function e : X → {0, 1}. We denote by ent(X) the set of all entities over X. On this set, we consider the uniform probability distribution, i.e., for an event E ⊆ ent(X), we have that P (E) := |E| 2 |X| . We will come back to this assumption in Section 5, where we will consider the more general product distributions (we start with the uniform distribution to ease the presentation).</p><p>A Boolean classifier M over X is a function M : ent(X) → {0, 1} that maps every entity over X to 0 or 1. We say that M accepts an entity e when M (e) = 1, and that it rejects it if M (e) = 0. Since we consider ent(X) to be a probability space, M can be regarded as a random variable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">The SHAP-score over Boolean classifiers</head><p>Let M : ent(X) → {0, 1} be a Boolean classifier over the set X of features. Given an entity e over X and a subset S ⊆ X of features, the set cw(e, S) := {e ′ ∈ ent(X) | e ′ (x) = e(x) for each x ∈ S} contains those entities that coincide with e over each feature in S. In other words, cw(e, S) is the set of entities that are consistent with e on S. Then, given an entity e ∈ ent(X) and S ⊆ X, we define the expected value of M over X \ S with respect to e as φ(M, e, S) := E M (e ′ ) | e ′ ∈ cw(e, S) .</p><p>Since we consider the uniform distribution over ent(X), we have that φ(M, e, S) = e ′ ∈cw(e,S)</p><formula xml:id="formula_0">1 2 |X\S| M (e ′ ).</formula><p>Intuitively, φ(M, e, S) is the probability that M (e ′ ) = 1, conditioned on the inputs e ′ ∈ ent(X) to coincide with e over each feature in S. This function is then used in the general formula of the Shapley value <ref type="bibr" target="#b19">(Shapley 1953;</ref><ref type="bibr" target="#b18">Roth 1988</ref>) to obtain the SHAP-score for feature values in e. Definition 2.1. Given a Boolean classifier M over a set of features X, an entity e over X, and a feature x ∈ X, the SHAP score of feature x on e with respect to M is defined as</p><formula xml:id="formula_1">SHAP(M, e, x) := S⊆X\{x} |S|! (|X| -|S| -1)! |X|! φ(M, e, S ∪ {x}) -φ(M, e, S) . (1)</formula><p>Thus, SHAP(M, e, x) is a weighted average of the contribution of feature x on e to the classification result, i.e., of the differences between having it and not, under all possible permutations of the other feature values. Observe that, from this definition, a high positive value of SHAP(M, e, x) intuitively means that setting x to e(x) strongly leans the classifier towards acceptance, while a high negative value of SHAP(M, e, x) means that setting x to e(x) strongly leans the classifier towards rejection. Several restrictions of Boolean circuits with good computational properties have been studied. Let C be a Boolean circuit over a set of variables X and g a gate of C. The Boolean circuit C g over X is defined by considering the subgraph of C induced by the set of gates g ′ in C for which there exists a path from g ′ to g in C. Notice that g is the output gate of C g . The set var(g) is defined as the set of variables x ∈ X such that there exists a variable gate with label x in C g . Then, an ∨-gate g of C is said to be deterministic if for every pair g 1 , g 2 of distinct input gates of g, the Boolean circuits C g1 and C g2 are disjoint in the sense that there is no entity e that is accepted by both C g1 and C g2 (that is, there is no entity e ∈ ent(X) such that C g1 (e) = C g2 (e) = 1). The circuit C is called deterministic if every ∨-gate of C is deterministic. An ∧-gate g of C is said to be decomposable if for every pair g 1 , g 2 of distinct input gates of g, we have that var(g 1 ) ∩ var(g 2 ) = ∅. Then, C is called decomposable if every ∧-gate of C is decomposable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Deterministic and decomposable Boolean circuits</head><formula xml:id="formula_2">A</formula><p>Example 2.2. In Example 1.1, we explained at an intuitive level why the Boolean circuit in Figure <ref type="figure">1</ref> is deterministic and decomposable. By using the terminology defined in the previous paragraph, it can be formally checked that this Boolean circuit indeed satisfies these conditions.</p><p>As mentioned before, deterministic and decomposable Boolean circuits generalize many decision diagrams and Boolean circuits classes. We refer to <ref type="bibr" target="#b5">(Darwiche 2001;</ref><ref type="bibr" target="#b0">Amarilli et al. 2020)</ref> for detailed studies of knowledge compilation classes and of their precise relationships. For the reader's convenience, we explain in the supplementary material how FBDDs and binary decision trees can be encoded in linear time as deterministic and decomposable Boolean circuits.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Tractable Computation of the SHAP-Score</head><p>In this section, we prove our first tractability result, namely, that computing the SHAP-score for Boolean classifiers given as deterministic and decomposable Boolean circuits can be done in polynomial time, for uniform probability distributions. Formally: Theorem 3.1. The following problem can be solved in polynomial time. Given as input a deterministic and decomposable Boolean circuit C over a set of features X, an entity e : X → {0, 1}, and a feature x ∈ X, compute the value SHAP(C, e, x).</p><p>In particular, since binary decision trees, OBDDs, FBDDs and d-DNNFs are all restricted kinds of deterministic and decomposable circuits, we obtain as a consequence of Theorem 3.1 that this problem is also in polynomial time for these classes. For instance, for binary decision trees we obtain: Corollary 3.2. The following problem can be solved in polynomial time. Given as input a binary decision tree T over a set of features X, an entity e : X → {0, 1}, and a feature x ∈ X, compute the value SHAP(T, e, x).</p><p>The authors of <ref type="bibr" target="#b12">(Lundberg et al. 2020)</ref> give a proof of this result, but, unfortunately, with few details to fully understand it. Moreover, it is important to notice that Theorem 3.1 is a nontrivial extension of the result for decision trees, as it is known that deterministic and decomposable circuits can be exponentially more succinct than binary decision trees (in fact, than FBDDs) at representing Boolean classifiers <ref type="bibr" target="#b5">(Darwiche 2001;</ref><ref type="bibr" target="#b0">Amarilli et al. 2020)</ref>.</p><p>In order to prove Theorem 3.1, we need to introduce some notation. Let M be a Boolean classifier over a set of features X. We write SAT(M ) ⊆ ent(X) for the set of entities that are accepted by M , and #SAT(M ) for the cardinality of this set. Let e, e ′ ∈ ent(X) be a pair of entities over X. We define sim(e, e ′ ) := {x ∈ X | e(x) = e ′ (x)} to be the set of features on which e and e ′ coincide. Given a Boolean classifier M over X, an entity e ∈ ent(X) and a natural number k ≤ |X|, we define the set SAT(M, e, k) := SAT(M ) ∩ {e ′ ∈ ent(X) | |sim(e, e ′ )| = k}, in other words, the set of entities e ′ that are accepted by M and which coincide with e in exactly k features. Naturally, we write #SAT(M, e, k) for the size of SAT(M, e, k).</p><p>Example 3.3. Let M be the Boolean classifier represented by the circuit in Example 1.1. Then SAT(M ) is the set containing all papers that are accepted according to M , so that #SAT(M ) = 5. Now, consider the entity e such that e(fg) = 1, e(dtr) = 1, e(nf) = 0 and e(na) = 1. Then one can check that #SAT(M, e, 0) = 0, #SAT(M, e, 1) = 0, #SAT(M, e, 2) = 2, #SAT(M, e, 3) = 2 and #SAT(M, e, 4) = 1.</p><p>Our proof of Theorem 3.1 is technical and is divided into two modular parts. The first part, which is developed in Section 3.1, consists in showing that the problem of computing SHAP(•, •, •) can be reduced in polynomial time to that of computing #SAT(•, •, •). This part of the proof is a sequence of formula manipulations, and it only uses the fact that deterministic and decomposable circuits can be efficiently conditioned on a variable value (to be defined in Section 3.1). In the second part of the proof, which is developed in Section 3.2, we show that computing #SAT(•, •, •) can be done in polynomial time for deterministic and decomposable Boolean circuits. It is in this part that the properties of deterministic and decomposable circuits are really used.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Reducing</head><formula xml:id="formula_3">SHAP(•, •, •) to #SAT(•, •, •)</formula><p>In this section, we show that for deterministic and decomposable Boolean circuits, the computation of the SHAPscore can be reduced in polynomial time to the computation of #SAT(•, •, •). To achieve this, we will need two more definitions. Let M be a Boolean classifier over a set of features X and x ∈ X, and let Boolean classifiers M +x : ent(X \ {x}) → {0, 1} and M -x : ent(X \ {x}) → {0, 1} be defined as follows. For e ∈ ent(X \ {x}), we write e +x and e -x the entities over X such that e +x (x) = 1, e -x (x) = 0 and e +x (y) = e -x (y) = e(y) for every y ∈ X \ {x}. Then define M +x (e) := M (e +x ) and M -x (e) := M (e -x ). In the literature, M +x (resp., M -x ) is called the conditioning by x (resp., by ¬x) of M . Conditioning can be done in linear time for a Boolean circuit C by replacing every gate with label x by a constant gate with label 1 (resp., 0). We write C +x (resp., C -x ) for the Boolean circuit obtained via this transformation. One can easily check that, if C is deterministic and decomposable, then C +x and C -x are deterministic and decomposable as well.</p><p>We now introduce the second definition needed for the proof. For a Boolean classifier M over a set of variables X, an entity e ∈ ent(X) and an integer k ≤ |X|, we define</p><formula xml:id="formula_4">H(M, e, k) := S⊆X |S|=k e ′ ∈cw(e,S)</formula><p>M (e ′ ).</p><p>( Then by the definition of the SHAP-score in (1), we have:</p><formula xml:id="formula_6">SHAP(C, e, x) = n-1 k=0 k!(n -k -1)! n! Diff k (C, e, x).</formula><p>Observe that all arithmetical terms (such as k! or n!) can be computed in polynomial time: this is simply because n is given in unary, as it is bounded by the size of the circuit. Therefore, it is enough to show how to compute in polynomial time the quantities Diff k (C, e, x) for each k ∈ {0, . . . , n -1}, as n = |X| is bounded by the size of the input (C, e, x). By definition of φ(•, •, •), we have that Diff k (C, e, x) = αβ, where:</p><formula xml:id="formula_7">α = S⊆X\{x} |S|=k 1 2 n-(k+1) e ′ ∈cw(e,S∪{x}) C(e ′ ) β = S⊆X\{x} |S|=k 1 2 n-k e ′ ∈cw(e,S)</formula><p>C(e ′ ).</p><p>Next we show how the computation of α and β can be reduced in polynomial-time to the computation of H(•, •, •). For an entity e ∈ ent(X) and S ⊆ X, let e |S be the entity over S that is obtained by restricting e to the domain S (that is, formally e |S ∈ ent(S) and e |S (y) := e(y) for every y ∈ S). Then, starting with β, we have that:</p><formula xml:id="formula_8">β = S⊆X\{x} |S|=k 1 2 n-k e ′ ∈cw(e,S) C(e ′ ) = S⊆X\{x} |S|=k 1 2 n-k e ′ ∈cw(e,S) e ′ (x)=1 C(e ′ ) + S⊆X\{x} |S|=k 1 2 n-k e ′ ∈cw(e,S) e ′ (x)=0 C(e ′ ) = 1 2 n-k S⊆X\{x} |S|=k e ′′ ∈cw(e |X\{x} ,S) C +x (e ′′ ) + 1 2 n-k S⊆X\{x} |S|=k e ′′ ∈cw(e |X\{x} ,S) C -x (e ′′ ) = 1 2 n-k H(C +x , e |X\{x} , k) + H(C -x , e |X\{x} , k) .</formula><p>The last equality is obtained by using the definition of H(•, •, •). A similar analysis allows us to conclude that:</p><formula xml:id="formula_9">α =      1 2 n-(k+1) H(C +x , e |X\{x} , k), if C(e) = 1 1 2 n-(k+1) H(C -x , e |X\{x} , k), if C(e) = 0</formula><p>.</p><p>Hence, if we can compute in polynomial time H(•, •, •) for deterministic and decomposable Boolean circuits, then we can compute α and β in polynomial time (because C +x and C -x can be computed in linear time from C, and they are deterministic and decomposable as well). Thus, we can compute Diff k (C, e, x) in polynomial time for each k ∈ {0, . . . , n -1} and, hence, SHAP(C, e, x) as well. In conclusion, SHAP(C, e, x) can be computed in polynomial time if there is a polynomial-time algorithm to compute H(•, •, •) for deterministic and decomposable Boolean circuits.</p><p>Reducing from H(•, •, •) to #SAT(•, •, •). We now show that computing H(•, •, •) can be reduced in polynomial time to computing #SAT(•, •, •). Given as input a deterministic and decomposable circuit C over a set of variables X, an entity e ∈ ent(X), and an integer k ≤ |X|, recall the definition of H(C, e, x) in (2). Then consider an entity e ′′ ∈ ent(X) and reason about how many times e ′′ will occur as a summand in the expression (2). First of all, it is clear that if |sim(e, e ′′ )| &lt; k, then e ′′ will not appear in the sum; this is because if e ′ ∈ cw(e, S) for some S ⊆ X such that |S| = k, then S ⊆ sim(e, e with the last equality being obtained by using the definition of #SAT(•, •, •). This concludes the reduction of this section and, hence, the first part of the proof.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Computing #SAT(•, •, •) in polynomial time</head><p>We now take care of the second part of the proof of Theorem 3.1, i.e., proving that computing #SAT(•, •, •) for deterministic and decomposable Boolean circuits can be done in polynomial time. To do this, given a deterministic and decomposable Boolean circuit C, we first perform two preprocessing steps on C, which will simplify the proof.</p><p>• Rewriting to fan-in at most 2. First, we modify the circuit C so that the fan-in of every ∨and ∧-gate is at most 2. This can simply be done in linear time by rewriting every ∧-gate (resp., and ∨-gate) of fan-in m &gt; 2 with a chain of m -1 ∧-gates (resp., ∨-gates) of fan-in 2. It is clear that the resulting Boolean circuit is deterministic and decomposable. Hence, from now on we assume that the fan-in of every ∨and ∧-gate of C is at most 2. • Smoothing the circuit. A deterministic and decomposable circuit C is smooth <ref type="bibr" target="#b5">(Darwiche 2001;</ref><ref type="bibr">Shih et al. 2019)</ref> if for every ∨-gate g and input gates g 1 , g 2 of g, we have that var(g 1 ) = var(g 2 ), and we call such an ∨gate smooth. A standard construction allows to transform in polynomial time a deterministic and decomposable Boolean circuit C into an equivalent smooth deterministic and decomposable Boolean circuit, and where each gate has fan-in at most 2. Thus, from now on we also assume that C is smooth. We illustrate how the construction works in Example 3.4 . Full details can be found in the supplementary material (namely, in Section E.2, paragraph Smoothing the circuit).</p><p>We have all the ingredients to prove that #SAT(•, •, •) can be computed in polynomial time. Let C be a deterministic and decomposable Boolean circuit over a set of variables X, e ∈ ent(X), ℓ a natural number such that ℓ ≤ |X| and n = |X|. For a gate g of C, let R g be the Boolean circuit over var(g) that is defined by considering the subgraph of C induced by the set of gates g ′ in C for which there exists a path from g ′ to g in C. Notice that R g is a deterministic and decomposable Boolean circuit with output gate g. Moreover, for a gate g and natural number k ≤ |var(g)|, define α k g := #SAT(R g , e |var(g) , k), which we recall is the number of entities e ′ ∈ ent(var(g)) such that e ′ satisfies R g and |sim(e |var(g) , e ′ )| = k. We will show how to compute all the values α k g for every gate g of C and k ∈ {0, . . . , |var(g)|} in polynomial time. This will conclude the proof since, for the output gate g out of C, we have that α ℓ gout = #SAT(C, e, ℓ). Next we explain how to compute these values in a bottom-up manner.</p><p>Variable gate. g is a variable gate with label y ∈ X, so that var(g) = {y}. Then α 0 g = 1e(y) and α 1 g = e(y). Constant gate. g is a constant gate with label a ∈ {0, 1}.</p><p>Then var(g) = ∅ and α 0 g = a.<ref type="foot" target="#foot_1">2</ref> ¬-gate. g is a ¬-gate with input gate g ′ . Then var(g) = var(g ′ ), and the values α k g ′ for k ∈ {0, . . . , |var(g)|} have already been computed. Fix k ∈ {0, . . . , |var(g)|}.</p><p>Since |var(g)| k is equal to the number of entities e ′ ∈ ent(var(g)) such that |sim(e |var(g) , e ′ )| = k, we have that</p><formula xml:id="formula_10">α k g = |var(g)| k -α k g ′ .</formula><p>Therefore, given that |var(g)| k can be computed in polynomial time since k ≤ |var(g)| ≤ n = |X|, we have an efficient way to compute α k g . ∨-gate. g is an ∨-gate. By assumption, g is deterministic, smooth and has fan-in at most 2. If g has only one input g ′ , then clearly var(g) = var(g ′ ) and α k g = α k g ′ for every k ∈ {0, . . . , |var(g)|}. Thus, assume that g has exactly two input gates g 1 and g 2 , and recall that var(g 1 ) = var(g 2 ) = var(g), because g is smooth. Also, recall that α k g1 and α k g2 , for each k ∈ {0, . . . , |var(g)|}, have already been computed. Fix k ∈ {0, . . . , |var(g)|}. Given that g is deterministic and smooth, we have that SAT(R g ) = SAT(R g1 ) ∪ SAT(R g2 ), where SAT(R g1 ) ∩ SAT(R g2 ) = ∅. By intersecting these three sets with the set {e ′ ∈ var(g) | |sim(e |var(g) , e ′ )| = k}, we obtain that SAT(R g , e |var(g) , k) = SAT(R g1 , e |var(g) , k) ∪ SAT(R g2 , e |var(g) , k), where SAT(R g1 , e |var(g) , k) ∩ SAT(R g2 , e |var(g) , k) = ∅. Hence:</p><formula xml:id="formula_11">#SAT(R g , e |var(g) , k) = #SAT(R g1 , e |var(g) , k) + #SAT(R g2 , e |var(g) , k),</formula><p>or, in other words, we have that α k g = α k g1 + α k g2 . Hence, we have an efficient way to compute α k g . ∧-gate. g is an ∧-gate. By assumption, recall that g is decomposable and has fan-in at most 2. If g has only one input g ′ , then clearly var(g) = var(g ′ ) and</p><formula xml:id="formula_12">α k g = α k g ′</formula><p>for every k ∈ {0, . . . , |var(g)|}. Thus, assume that g has exactly two input gates g 1 and g 2 . Recall then that the values α i g1 and α j g2 , for each i ∈ {0, . . . , |var(g 1 )|} and j ∈ {0, . . . , |var(g 2 )|}, have already been computed. Fix k ∈ {0, . . . , |var(g)|}. Given that g is a decomposable ∧-gate, in this case it is possible to prove that: </p><formula xml:id="formula_13">α k g = i∈{0,...,</formula><formula xml:id="formula_14">α i g1 • α j g2 .<label>(3)</label></formula><p>The complete proof of this property can be found in Appendix B. Therefore, as in the previous cases, we conclude that there is an efficient way to compute α k g . This concludes the proof that #SAT(•, •, •) can be computed in polynomial time for deterministic and decomposable Boolean circuits and, hence, the proof of Theorem 3.1.</p><p>Example 3.4. We illustrate how the algorithm for computing the SHAP-score operates on the Boolean circuit C given in Example 1.1. Recall that C is defined over X = {fg, dtr, nf, na}, and assume we want to compute SHAP(C, e, nf) for the entity e with e(x) = 1 for each x ∈ X. By the polynomial time reductions shown in Section 3.1, to compute SHAP(C, e, nf) it suffices to compute H(C -nf , e |X\{nf} , ℓ) and H(C +nf , e |X\{nf} , ℓ) for each ℓ ∈ {0, . . . , 3}, which in turn reduces to the computation of #SAT(C -nf , e |X\{nf} , ℓ) and #SAT(C +nf , e |X\{nf} , ℓ) for each ℓ ∈ {0, . . . , 3}. In what follows, we show how to compute the values #SAT(C +nf , e |X\{nf} , ℓ).</p><p>For the sake of presentation, let D := C +nf and e ⋆ = e |X\{nf} , so that we need to compute #SAT(D, e ⋆ , ℓ) for each ℓ ∈ {0, . . . , 3}. Notice that the values to be computed are #SAT(D, e ⋆ , 0) = 0, #SAT(D, e ⋆ , 1) = 0, #SAT(D, e ⋆ , 2) = 2 and #SAT(D, e ⋆ , 3) = 1. To compute #SAT(D, e ⋆ , ℓ), we first need to replace feature nf by constant 1 in C to generate D = C +nf , and then we need to transform D into a Boolean circuit that is smooth and where each gate has fan-in at most 2. The result of this process is shown in Figure <ref type="figure" target="#fig_3">2</ref>, where the green node is added when replacing feature nf by constant 1, the gray node is added to satisfy the restriction that each gate has fan-in at most 2, and the blue nodes are added to have a smooth Boolean circuit.</p><formula xml:id="formula_15">dtr α 0 = 0 α 1 = 1 ∧ α 0 = 0 α 1 = 1 α 2 = 1 ∨ α 0 = 1 α 1 = 1 na α 0 = 0 α 1 = 1 ¬ α 0 = 1 α 1 = 0 na α 0 = 0 α 1 = 1 fg α 0 = 0 α 1 = 1 ∧ α 0 = 0 α 1 = 1 na α 0 = 0 α 1 = 1 1 α 0 = 1 ∧ ¬ α 0 = 1 α 1 = 0 α 0 = 0 α 1 = 1 α 2 = 0 ∨ α 0 = 0 α 1 = 2 α 2 = 1 ∧ α 0 = 0 α 1 = 0 α 2 = 2 α 3 = 1</formula><p>The algorithm to compute #SAT(D, e ⋆ , ℓ) runs in a bottom-up fashion on the Boolean circuit, computing for each gate g the values α k g for k ∈ {0, . . . , |var(g)|}. We show these values next to each node in Figure <ref type="figure" target="#fig_3">2</ref>, but omitting gate subscripts. For instance, for a variable gate g with label na, we have that var(g) = {na}, α 0 g = 0 and α 1 g = 1, given that e ⋆ |var(g) (na) = e ⋆ (na) = 1. Notice that for the output gate g out of the Boolean circuit, which is its top gate, we have that #SAT(D, e ⋆ , ℓ) = α ℓ gout for each ℓ ∈ {0, . . . , 3}, which were the values to be computed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Limits on the Tractable Computation of the SHAP-Score</head><p>We have shown that the SHAP-score can be computed in polynomial time for deterministic and decomposable circuits. A natural question, then, is whether both determinism and decomposability are necessary for this positive result to hold. In this section we show this to be case, at least under standard complexity assumptions. Recall that #P consists of the class of functions that can be defined by counting the number of accepting paths of a non-deterministic Turing machine that works in polynomial time. The notion of hardness for the class #P is defined in terms of polynomial time Turing reductions. Under widely-held complexity assumptions, #P-hard problems cannot be solved in polynomial time <ref type="bibr" target="#b1">(Arora and Barak 2009)</ref>. We can then prove the following: Theorem 4.1. The following problems are #P-hard. 1. Given as input a decomposable Boolean circuit C over a set of features X, an entity e : X → {0, 1}, and a feature x ∈ X, compute the value SHAP(C, e, x). 2. Given as input a deterministic Boolean circuit C over a set of features X, an entity e : X → {0, 1}, and a feature x ∈ X, compute the value SHAP(C, e, x).</p><p>To prove Theorem 4.1, we start by showing that there is a polynomial-time reduction from the problem of computing the number of entities that satisfy M , for M an arbitrary Boolean classifier, to the problem of computing the SHAP-score over M . This holds under the mild condition that M (e) can be computed in polynomial time for an input entity e, which is satisfied for all the Boolean circuits and binary decision diagrams classes considered in this paper. The proof of this result follows from well-known properties of Shapley values. (A closely related result can be found as Theorem 5.1 in <ref type="bibr" target="#b2">(Bertossi et al. 2020)</ref>). Lemma 4.2. Let M be a Boolean classifier over a set of features X. Then for every e ∈ ent(X) we have:</p><formula xml:id="formula_16">#SAT(M ) = 2 |X| M (e) - x∈X SHAP(M, e, x) .</formula><p>We prove Lemma 4.2 in the supplementary material. Item (1) in Theorem 4.1 follows then by the following two facts: (a) Counting the number of entities that satisfy a DNF formula is a #P-hard problem <ref type="bibr" target="#b17">(Provan and Ball 1983)</ref>, and (b) DNF formulae are particular kinds of decomposable Boolean circuits. Analogously, item (2) in Theorem 4.1 can be obtained from the following two facts: (a) Counting the number of entities that satisfy a 3-CNF formula is a #P-hard problem, and (b) from every 3-CNF formula ψ, we can build in polynomial time an equivalent deterministic Boolean circuit C ψ . Details can be found in the supplementary material.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Tractability for the Product Distribution</head><p>In Section 2, we introduce the uniform distribution, and used it so far as a basis for the SHAP-score. Another probability space that is often considered on ent(X) is the product distribution, defined as follows. Let p : X → [0, 1] be a function that associates to every feature x ∈ X a value p(x) ∈ [0, 1]; intuitively, the probability that x takes value 1. Then, the product distribution generated by p is the probability distribution Π p over ent(X) such that, for every e ∈ ent(X),</p><formula xml:id="formula_17">Π p (e) := x∈X e(x)=1 p(x) • x∈X e(x)=0 (1 -p(x)) .</formula><p>That is, the product distribution that is determined by prespecified marginal distributions, and that makes the features take values independently from each other. Observe the effect of the probability distribution on the SHAPscore: intuitively, the higher the probability of an entity, the more impact this entity will have on the computation. This can be used, for instance, to avoid bias in the explanations <ref type="bibr" target="#b13">(Lundberg and Lee 2017;</ref><ref type="bibr" target="#b2">Bertossi et al. 2020)</ref>.</p><p>Notice that the uniform space is a special case of product space, with Π p invoking p(x) := 1 /2 for every x ∈ X. Thus, our hardness results from Theorem 4.1 also hold in the case where the probabilities p(x) are given as input. What is more interesting is the fact that our tractability result from Theorem 3.1 extends to product distributions. Formally: Theorem 5.1. The following problem can be solved in polynomial time. Given as input a deterministic and decomposable circuit C over a set of features X, rational probability values p(x) for every feature x ∈ X, an entity e : X → {0, 1}, and a feature x ∈ X, compute the value SHAP(C, e, x) under the probability distribution Π p .</p><p>The proof of Theorem 5.1 is more involved than that of Theorem 3.1, and is provided in the supplementary material. In particular, the main difficulty is that φ(M, e, S) is no longer equal to e ′ ∈cw(e,S) 1 2 |X\S| M (e ′ ) (as it was the case for the uniform space), because the entities do not all have the same probability. This prevents us from being able to reduce to the computation of #SAT(•, •, •). Instead, we use a different definition of H(•, •, •), and prove that it can directly be computed in a bottom-up fashion on the circuits. We show in Algorithm 1 our algorithm to compute the SHAP score for deterministic and decomposable Boolean circuits under product distributions, which can be extracted from the proof in the supplementary material. Notice that by using the techniques presented in Section 3, the first step of the algorithm transforms the input circuit C into an equivalent smooth circuit D where each ∨-gate and ∧-gate has fan-in 2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Extensions and Future Work</head><p>We leave open many interesting directions for future work. For instance, we intend to extend our algorithm for efficiently computing the SHAP-score to work with non-Boolean classifiers, and to consider more general probability distributions that could better capture possible correlations and dependencies between features. We also aim to provide an experimental comparison of our algorithm, but specialized for decision trees, with the one provided in <ref type="bibr">(Lundberg et al. 2020, Alg. 2)</ref>. Last, we intend to test our algorithm on real-world scenarios.</p><p>Algorithm 1: SHAP-scores for deterministic and decomposable Boolean circuits Input : Deterministic and decomposable Boolean circuit C over features X with ouput gate g out , rational probability values p(x) for all x ∈ X, entity e ∈ ent(X), and feature x ∈ X. Output: The value SHAP(C, e, x) under the probability distribution Π p .</p><p>1 Transform C into an equivalent smooth circuit D where each ∨-gate and ∧-gate has fan-in 2;</p><p>2 Compute the set var(g) for every gate g in D;</p><p>3 Compute values γ ℓ g and δ ℓ g for every gate g in D and ℓ ∈ {0, . . </p><formula xml:id="formula_18">k! (|X| -k -1)! |X|! • (e(x) -p(x))(γ k gout -δ k gout ) ;</formula><p>Given that g is a decomposable ∧-gate, we have that:</p><formula xml:id="formula_19">SAT(R g ) = SAT(R g1 ) ⊗ SAT(R g2 ).</formula><p>Moreover, we have that SAT(R g , e |var(g) , k) = SAT(R g ) ∩ {e ′ ∈ var(g) | |sim(e |var(g) , e ′ )| = k} and Combining the previous results, we obtain that</p><formula xml:id="formula_20">SAT(R g1 ) ⊗ SAT(R g2 ) ∩ {e ′ ∈ var(g) | |sim(e |var(g) , e ′ )| = k} = {e 1 ∪ e 2 | e 1 ∈ SAT(R g1 ) and e 2 ∈ SAT(R g2 )} ∩ {e ′ ∈ var(g) | |sim(e |var(g) , e ′ )| = k} = {e 1 ∪ e 2 | e 1 ∈ SAT(R g1 ), e 2 ∈ SAT(R g2 ),</formula><formula xml:id="formula_21">SAT(R g , e |var(g) , k) = i∈{0,...,|var(g1)|} j∈{0,...,|var(g2)|} i+j=k SAT(R g1 , e |var(g1) , i) ⊗ SAT(R g2 , e |var(g2) , j).</formula><p>Thus, given that for every pair i 1 , i 2 ∈ {0, . . . , |var(g 1 )|} such that i 1 = i 2 , it holds that</p><formula xml:id="formula_22">SAT(R g1 , e |var(g1) , i 1 ) ∩ SAT(R g1 , e |var(g1) , i 2 ) = ∅</formula><p>(and similarly for R g2 ), we conclude by the definitions of α k g , α i g1 , α j g2 that α k g = i∈{0,...,|var(g1)|} j∈{0,...,|var(g2)|} i+j=k</p><formula xml:id="formula_23">α i g1 • α j g2 ,</formula><p>which was to be shown.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C Proof of Lemma 4.2</head><p>The validity of the equation from Lemma 4.2 will be consequence of the following property of the SHAP-score: for every Boolean classifier M over X, entity e ∈ ent(X) and feature x ∈ X, it holds that x∈X SHAP(M, e, x) = φ(M, e, X)φ(M, e, ∅).</p><p>This property is often called the efficiency property of the Shapley value. Although this is folklore, we prove Equation (4) here for the reader's convenience. For a permutation π : X → {1, . . . , n} and x ∈ X, let S x π denote the set of features that appear before x in π. Formally, S x π := {y ∈ X | π(y) &lt; π(x)}. Then, letting Π(X) be the set of all permutations π : X → {1, . . . , n}, observe that the definition of SHAP-score from Definition 2.1 can be rewritten as</p><formula xml:id="formula_25">SHAP(M, e, x) = 1 n! π∈Π(X) φ(M, e, S x π ∪ {x}) -φ(M, e, S x π ) .</formula><p>Hence, we have that</p><formula xml:id="formula_26">x∈X SHAP(M, e, x) = 1 n! x∈X π∈Π(X) φ(M, e, S x π ∪ {x}) -φ(M, e, S x π ) = 1 n! π∈Π(X) x∈X φ(M, e, S x π ∪ {x}) -φ(M, e, S x π ) = 1 n! π∈Π(X) φ(M, e, X) -φ(M, e, ∅) ,</formula><p>where the last equality is obtained by noticing that the inner sum is a telescoping sum. This establishes Equation ( <ref type="formula" target="#formula_24">4</ref>). Now, we simply use the definition of φ(•, •, •) in this equation to obtain</p><formula xml:id="formula_27">x∈X SHAP(M, e, x) = M (e) - 1 2 n e ′ ∈ent(X) M (e ′ ) = M (e) - #SAT(M ) 2 n ,</formula><p>thus proving Lemma 4.2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D Proof of Theorem 4.1</head><p>We have already explained in the body of this article why Item (1) of Theorem 4.1 holds. We now justify that (2) holds, by proving that from every 3-CNF formula ψ, we can build in polynomial time an equivalent deterministic Boolean circuit C ψ . Given a clause γ = (ℓ 1 ∨ ℓ 2 ∨ ℓ 3 ) consisting of three literals, define d(γ) as the propositional formula</p><formula xml:id="formula_28">(ℓ 1 ∧ ℓ 2 ∧ ℓ 3 ) ∨ (ℓ 1 ∧ ℓ 2 ∧ ℓ 3 ) ∨ (ℓ 1 ∧ ℓ 2 ∧ ℓ 3 ) ∨ (ℓ 1 ∧ ℓ 2 ∧ ℓ 3 ) ∨ (ℓ 1 ∧ ℓ 2 ∧ ℓ 3 ) ∨ (ℓ 1 ∧ ℓ 2 ∧ ℓ 3 ) ∨ (ℓ 1 ∧ ℓ 2 ∧ ℓ 3 ),</formula><p>where x = ¬x and ¬x = x, for each propositional variable x. Clearly, γ and d(γ) are equivalent formulae. Moreover, given a propositional formula</p><formula xml:id="formula_29">ψ = γ 1 ∧ • • • ∧ γ k in 3-CNF,</formula><p>where each γ i is a clause with three literals, define d(ψ) as the propositional formula</p><formula xml:id="formula_30">d(γ 1 ) ∧ • • • ∧ d(γ k ).</formula><p>Clearly, ψ and d(ψ) are equivalent formulae, from which we have that #SAT(ψ) = #SAT(d(ψ)). Moreover, d(ψ) can be directly transformed into a deterministic Boolean Circuit C d(ψ) . Hence, from the fact that C d(ψ) can be constructed in polynomial time from an input propositional formula ψ in 3-CNF, and the fact that #SAT(•) is #P-hard for 3-CNFs, we have that Theorem 4.1 (2) holds from Lemma 4.2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E Proof of Theorem 5.1</head><p>In this section, we prove that computing the SHAP-score for Boolean classifiers given as deterministic and decomposable Boolean circuits can be done in polynomial time for product distributions; see Theorem 5.1 for the formal statement. As mentioned in Section 5, the proof will be slightly more involved than that of Theorem 3.1; this is because not all entities have the same probability, and this prevents us from reducing to #SAT(•, •, •). Instead, we will use a different definition of H(•, •, •) and show that it can directly be computed bottom-up on the circuits. But before that, we introduce new notation that will be more convenient for this proof. For a Boolean classifier M over features X, probability distribution<ref type="foot" target="#foot_2">3</ref> D : ent(X) → [0, 1], entity e ∈ ent(X) and set S ⊆ X, we define φ D (M, e, S) := E e ′ ∼D M (e ′ ) | e ′ ∈ cw(e, S) .</p><p>Notice that we now use the notation E e ′ ∼D [f (e ′ )] for expected value of a random variable f , instead of the simpler E[f (e ′ )] that we used in the body of the paper. This is because we will sometimes need to make explicit what is the probability distribution to consider. Then given a Boolean classifier M over a set of features X, a probability distribution D over ent(X), an entity e over X, and a feature x ∈ X, the Shapley value of feature x in e with respect to M under D is defined as</p><formula xml:id="formula_31">SHAP D (M, e, x) := S⊆X\{x} |S|! (|X| -|S| -1)! |X|! φ D (M, e, S ∪ {x}) -φ D (M, e, S) .<label>(5)</label></formula><p>Note that by taking D to be the uniform probability distribution on ent(X), we obtain the definition that we considered in Section 2. In this section we will consider the product distributions Π p as defined in Section 5. With these notation in place, we can now start the proof.</p><p>For a Boolean classifier M over a set of variables X, a probability distribution D over ent(X), an entity e ∈ ent(X) and a natural number k ≤ |X|, define</p><formula xml:id="formula_32">H D (M, e, k) := S⊆X |S|=k E e ′ ∼D [M (e ′ ) | e ′ ∈ cw(e, S)].</formula><p>Our proof of Theorem 5.1 is divided into two modular parts. The first part, which is developed in Section E.1, consists in showing that the problem of computing SHAP Π• (•, •, •) can be reduced in polynomial time to that of computing H Π• (•, •, •). This part of the proof is again a sequence of formula manipulations, and it only uses the fact that deterministic and decomposable circuits can be efficiently conditioned on a variable value. In the second part of the proof, which is developed in Section E.2, we show that computing H Π• (•, •, •) can be done in polynomial time for deterministic and decomposable Boolean circuits. It is in this part that the magic of deterministic and decomposable circuits really operates.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E.1 Reducing in polynomial</head><formula xml:id="formula_33">-time from SHAP Π• (•, •, •) to H Π• (•, •, •)</formula><p>In this section, we show that for deterministic and decomposable Boolean circuits and under product distributions, the computation of the SHAP-score can be reduced in polynomial time to the computation of H Π• (•, •, •). We wish to compute SHAP Πp (C, e, x), for a given deterministic and decomposable circuit C over a set of variables X, probability mapping p : X → [0, 1], entity e ∈ ent(X) and feature x ∈ X. Define </p><formula xml:id="formula_34">+ (1 -p(x)) • S⊆X\{x} |S|=k E e ′′ ∼Πp |X\{x} [C -x (e ′′ ) | e ′′ ∈ cw(e |X\{x} , S)] = p(x) • H Πp |X\{x} (C +x , e |X\{x} , k) + (1 -p(x)) • H Πp |X\{x} (C -x , e |X\{x} , k),</formula><p>where the last equality is obtained simply by using the definition of We first perform two preprocessing steps on C, which will simplify the proof. These are the same preprocessing steps that we did in Section 3, but we added more details for the reader's convenience.</p><p>Rewriting to fan-in at most 2. First, we modify the circuit C so that the fan-in of every ∨and ∧-gate is at most 2. This can simply be done in linear time by rewriting every ∧-gate (resp., and ∨-gate) of fan-in m &gt; 2 with a chain of m -1 ∧-gates (resp., ∨-gates) of fan-in 2. It is clear that the resulting Boolean circuit is deterministic and decomposable. Hence, from now on we assume that the fan-in of every ∨and ∧-gate of C is at most 2.</p><p>Smoothing the circuit. Recall that a deterministic and decomposable circuit C is smooth if for every ∨-gate g and input gates g 1 , g 2 of g, we have that var(g 1 ) = var(g 2 ), and we call such an ∨-gate smooth. We modify as follows the circuit C so that it becomes smooth. Recall that by the previous paragraph, we assume that the fan-in of every ∨-gate is at most 2. For an ∨-gate g of C having two input gates g 1 , g 2 violating the smoothness condition, define S 1 := var(g 1 ) \ var(g 2 ) and S 2 := var(g 2 ) \ var(g 1 ), and let d S1 , d S2 be Boolean circuits defined as follows. We will show how to compute all the values α l g for every gate g of C and l ∈ {0, . . . , |var(g)|} in polynomial time. This will conclude the proof since, for the output gate g out of C, we have that α k gout = H Πp (C, e, k). Next we explain how to compute these values by bottom-up induction on C.</p><p>Variable gate. g is a variable gate with label y ∈ X, so that var(g) = {y}. Then for e ′ ∈ ent({y}) we have R g (e ′ ) = e ′ (y), therefore ¬-gate. g is a ¬-gate with input gate g ′ . Notice that var(g) = var(g ′ ). Then, since for e ′ ∈ ent(var(g)) we have that R g (e ′ ) = 1 -R g ′ (e ′ ), we have for every l ∈ {0, . . . , |var(g)|}. By induction, the values α l g ′ for l ∈ {0, . . . , |var(g)|} have already been computed. Thus, we can compute all the values α l g for l ∈ {0, . . . , |var(g)|} in polynomial time. ∨-gate. g is an ∨-gate. By assumption, recall that g is deterministic, smooth and has fan-in at most 2. If g has only one input g ′ , then clearly var(g) = var(g ′ ) and α l g = α l g ′ for every l ∈ {0, . . . , |var(g)|}. Thus, assume that g has exactly two input gates g 1 and g 2 , and recall that var(g 1 ) = var(g 2 ) = var(g), because g is smooth. Given that g is deterministic, observe that for every e ′ ∈ ent(var(g)) we have R g (e ′ ) = R g1 (e ′ ) + R g1 (e ′ ). But then for l ∈ {0, . . . , |var(g)|} we have = α l g1 + α l g2 , where the second equality is by linearity of the expectation, and the last equality is valid because g is smooth. By induction, the values α l g1 and α l g2 , for each l ∈ {0, . . . , |var(g)|}, have already been computed. Therefore, we can compute all the values α l g for l ∈ {0, . . . , |var(g)|} in polynomial time. ∧-gate. g is an ∧-gate. By assumption, recall that g is decomposable and has fan-in at most 2. If g has only one input g ′ , then clearly var(g) = var(g ′ ) and α l g = α l g ′ for every l ∈ {0, . . . , |var(g)|}. Thus, assume that g has exactly two input gates g 1 and g 2 . For e ′ ∈ ent(var(g)) we have that R g (e ′ ) = R g1 (e ′ |var(g1) )•R g2 (e ′ |var(g2) ). Moreover, since var(g) = var(g 1 )∪var(g 2 ) and var(g 1 ) ∩ var(g 2 ) = ∅ (because g is decomposable), observe that every S ⊆ var(g) can be uniquely decomposed into S 1 ⊆ var(g 1 ), S 2 ⊆ var(g 2 ) such that S = S 1 ∪ S 2 . Henceforth, for l ∈ {0, . . . , |var(g)|} we have By induction, the values α l1 g1 and α l2 g2 , for each l 1 ∈ {0, . . . , |var(g 1 )|} and l 2 ∈ {0, . . . , |var(g 2 )|}, have already been computed. Therefore, we can compute all the values α l g for l ∈ {0, . . . , |var(g)|} in polynomial time. This concludes the proof of Lemma E.1 and, hence, the proof of Theorem 5.1.</p><formula xml:id="formula_35">α 0 g = S⊆{y} |S|=0 E e ′ ∼Πp |{y} [e ′<label>(</label></formula></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>Figure 1: A deterministic and decomposable Boolean Circuit as a classifier.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>)</head><label></label><figDesc>We first explain how computing SHAP(•, •, •) can be reduced in polynomial time to the problem of computing H(•, •, •), and then how computing H(•, •, •) can be reduced in polynomial time to computing #SAT(•, •, •).Reducing from SHAP(•, •, •) to H(•, •, •). We need to compute SHAP(C, e, x), for a given deterministic and decomposable circuit C over a set of variables X, entity e ∈ ent(X), and feature x ∈ X. Let n = |X|, and define Diff k (C, e, x) := S⊆X\{x} |S|=k (φ(C, e, S ∪{x})φ(C, e, S)).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>′ ) and, thus, k ≤ |sim(e, e ′ )|. Now, how many times does an entity e ′′ ∈ ent(X) such that |sim(e, e ′′ )| ≥ k occur as a summand in the expression? The answer is simple: once per S ⊆ sim(e, e ′′ ) of size k. Since there are |sim(e,e ′′ )| k such sets S, we obtain that H(C, e, k) is equal to e ′′ ∈ent(X) |sim(e,e ′′ )|≥k |sim(e, e ′′ )| k • C(e ′′ ) = e ′′ ∈SAT(C) |sim(e,e ′′ )|≥k |sim(e, e ′′ )| k = n ℓ=k e ′′ ∈SAT(C) |sim(e,e ′′ )|=ℓ |sim(e, e ′′ )| k (C, e, ℓ),</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Execution of our algorithm to compute #SAT(•, •, •) over the Boolean circuit C +nf from Example 3.4.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>and |sim(e |var(g) , e 1 ∪ e 2 )| = k} = {e 1 ∪ e 2 | e 1 ∈ SAT(R g1 ), e 2 ∈ SAT(R g2 ), and there exist i ∈ {0, . . . , |var(g 1 )|}, j ∈ {0, . . . , |var(g 2 )|} such that |sim(e |var(g1) , e 1 )| = i, |sim(e |var(g2) , e 2 )| = j, and i + j = k} = i∈{0,...,|var(g1)|} j∈{0,...,|var(g2)|} i+j=k {e 1 | e 1 ∈ SAT(R g1 ) and |sim(e |var(g1) , e 1 )| = i} ⊗ {e 2 | e 2 ∈ SAT(R g2 ) and |sim(e |var(g2) , e 2 )| = j} = i∈{0,...,|var(g1)|} j∈{0,...,|var(g2)|} i+j=k SAT(R g1 , e |var(g1) , i) ⊗ SAT(R g2 , e |var(g2) , j).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>Diff k (C, e, x) := S⊆X\{x} |S|=k (φ Πp (C, e, S ∪ {x})φ Πp (C, e, S)),and let n = |X|. We then haveSHAP Πp (C, e, x) = S⊆X\{x} |S|!(n -|S| -1)! n! (φ Πp (C, e, S ∪ {x})φ Πp (C, e, S)) nk -1)! n! Diff k (C, e, x).Therefore, it is enough to show how to compute in polynomial time the quantitiesDiff k (C, e, x) for each k ∈ {0, . . . , n -1}. By definition of φ Π• (•, •, •) we have that Diff k (C, e, x) = S⊆X\{x} |S|=k E e ′ ∼Πp [C(e ′ ) | e ′ ∈ cw(e, S ∪ {x})] ( †) -S⊆X\{x} |S|=k E e ′ ∼Πp [C(e ′ ) | e ′ ∈ cw(e, S)] .In this expression, let α and β be the left-and right-hand side terms in the subtraction. For a set of features X, mapping p : X → [0, 1] and S ⊆ X, we write p |S : S → [0, 1] for the mapping that is the restriction of p to S, and Π p |S : ent(S) → [0, 1] for the corresponding product distribution on ent(S). Looking closer at β, we have that β = S⊆X\{x} |S|=k E e ′ ∼Πp [C(e ′ ) | e ′ ∈ cw(e, S)] = p(x) • S⊆X\{x} |S|=k E e ′ ∼Πp [C(e ′ ) | e ′ ∈ cw(e, S) and e ′ (x) = 1] + (1p(x)) • S⊆X\{x} |S|=k E e ′ ∼Πp [C(e ′ ) | e ′ ∈ cw(e, S) and e ′ (x) = 0] = p(x) • S⊆X\{x} |S|=k E e ′′ ∼Πp |X\{x} [C +x (e ′′ ) | e ′′ ∈ cw(e |X\{x} , S)]</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>E</head><label></label><figDesc>y) | e ′ ∈ cw(e |{y} , S)]= E e ′ ∼Πp |{y} [e ′ (y) | e ′ ∈ cw(e |{y} , ∅)] = E e ′ ∼Πp |{y} [e ′ (y)] = 1 • p(y) + 0 • (1p(y)) = p(y) e ′ ∼Πp |{y} [e ′ (y) | e ′ ∈ cw(e |{y} , S)] = E e ′ ∼Πp |{y} [e ′ (y) | e ′ ∈ cw(e |{y} , {y})] = e(y).Constant gate. g is a constant gate with label a ∈ {0, 1}, and var(g) = ∅. We recall the mathematical convention that there is a unique function with the empty domain and, hence, a unique entity over ∅. But thenα 0 g = S⊆∅ |S|=0 E e ′ ∼Πp|∅ [a | e ′ ∈ cw(e |∅ , S)] = E e ′ ∼Πp |∅ [a | e ′ ∈ cw(e |∅ , ∅)] = a.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc>|S|=lE e ′ ∼Πp |var(g) [1 -R g ′ (e ′ ) | e ′ ∈ cw(e |var(g) , S)].By linearity of expectations we deduce thatα l g = S⊆var(g) |S|=l E e ′ ∼Πp |var(g) [1 | e ′ ∈ cw(e |var(g) , S)] -S⊆var(g) |S|=l E e ′ ∼Πp |var(g) [R g ′ (e ′) | e ′ ∈ cw(e |var(g)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head></head><label></label><figDesc>|S|=lE e ′ ∼Πp |var(g) [R g1 (e ′ ) + R g2 (e ′ ) | e ′ ∈ cw(e |var(g) , S)] = S⊆var(g) |S|=l E e ′ ∼Πp |var(g) [R g1 (e ′ ) | e ′ ∈cw(e |var(g) , S)] + S⊆var(g) |S|=l E e ′ ∼Πp |var(g) [R g2 (e ′ ) | e ′ ∈ cw(e |var(g) , S)]</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>EE</head><label></label><figDesc>E e ′ ∼Πp |var(g) [R g1 (e ′ |var(g1) ) • R g2 (e ′ |var(g2) ) | e ′ ∈ cw(e |var(g) , S 1 ∪ S 2 )].But, by definition of the product distribution Π p |var(g) , we have that R g1 (e ′ |var(g1) ) and R g2 (e ′ |var(g2) ) are independent random variables, hence we deduceE e ′ ∼Πp |var(g) [R g1 (e ′ |var(g1) ) | e ′ ∈ cw(e |var(g) , S 1 ∪ S 2 )] × E e ′ ∼Πp |var(g) [R g2 (e ′ |var(g2) ) | e ′ ∈ cw(e |var(g) , S 1 ∪ S 2 )] . e ′′ ∼Πp |var(g 1 ) [R g1 (e ′′ ) | e ′′ ∈cw(e |var(g1) , S 1 )] × E e ′′ ∼Πp |var(g 2 ) [R g2 (e ′′ ) | e ′′ ∈ cw(e |var(g2) , S 2 )] , where the last equality is simply by definition of the product distributions, and because R g1 (e ′ |var(g1) ) is independent of the value e ′ |var(g2) , and similarly for R g2 (e ′ |var(g2) ). But then α l g = S1⊆var(g1) |S1|≤l E e ′′ ∼Πp |var(g 1 ) [R g1 (e ′′ ) | e ′′ ∈ cw(e |var(g1) , S 1 )] × S2⊆var(g2) |S2|=|var(g)|-|S1| 16 E e ′′ ∼Πp |var(g 2 ) [R g2 (e ′′ ) | e ′′ ∈ cw(e |var(g2) , S 2 )] = S1⊆var(g1) |S1|≤l E e ′′ ∼Πp |var(g 1 ) [R g1 (e ′′ ) | e ′′ ∈ cw(e |var(g1) , S 1 )] × α |var(g)|-|var(e ′′ ∼Πp |var(g 1 ) [R g1 (e ′′ ) | e ′′ ∈ cw(e |var(g1) , S 1 )]</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>. , |var(g) \ {x}|} by bottom-up induction on D as follows:</figDesc><table><row><cell>4</cell><cell cols="3">if g is a constant gate with label a ∈ {0, 1} then</cell></row><row><cell>5</cell><cell>γ 0 g , δ 0 g ← a;</cell><cell></cell></row><row><cell>6</cell><cell cols="3">else if g is a variable gate with var(g) = {x}</cell></row><row><cell></cell><cell>then</cell><cell></cell></row><row><cell>7</cell><cell>γ 0 g ← 1;</cell><cell></cell></row><row><cell>8</cell><cell>δ 0 g ← 0;</cell><cell></cell></row><row><cell>10</cell><cell>γ 0 g , δ 0 g ← p(y);</cell><cell></cell></row><row><cell>11</cell><cell>γ 1 g , δ 1 g ← e(y);</cell><cell></cell></row><row><cell>14</cell><cell>γ ℓ g ← |var(g)\{x}| ℓ</cell><cell>-γ ℓ g ′ ;</cell></row><row><cell>15</cell><cell>δ ℓ g ← |var(g)\{x}| ℓ</cell><cell>-δ ℓ g ′ ;</cell></row><row><cell>19</cell><cell>γ ℓ g ← γ ℓ g1 + γ ℓ g2 ;</cell><cell></cell></row><row><cell>20</cell><cell>δ ℓ g ← δ ℓ g1 + δ ℓ g2 ;</cell><cell></cell></row><row><cell>21</cell><cell>end</cell><cell></cell></row><row><cell>22</cell><cell cols="3">else if g is an ∧-gate with input gates g 1 , g 2 then</cell></row><row><cell>23</cell><cell cols="3">for ℓ ∈ {0, . . . , |var(g) \ {x}|} do</cell></row><row><cell>24</cell><cell cols="2">γ ℓ g ← ℓ1∈{0,...,|var(g1)\{x}|}</cell><cell>γ ℓ1 g1 • γ ℓ2 g2 ;</cell></row><row><cell></cell><cell cols="2">ℓ2∈{0,...,|var(g2)\{x}|}</cell></row><row><cell></cell><cell cols="2">ℓ1+ℓ2=ℓ</cell></row><row><cell>25</cell><cell cols="2">δ ℓ g ← ℓ1∈{0,...,|var(g1)\{x}|}</cell><cell>δ ℓ1 g1 • δ ℓ2 g2 ;</cell></row><row><cell></cell><cell cols="2">ℓ2∈{0,...,|var(g2)\{x}|}</cell></row><row><cell></cell><cell cols="2">ℓ1+ℓ2=ℓ</cell></row><row><cell>26</cell><cell>end</cell><cell></cell></row><row><cell cols="2">27 end</cell><cell></cell></row><row><cell cols="2">28 return</cell><cell></cell></row><row><cell></cell><cell>|X|-1</cell><cell></cell></row><row><cell></cell><cell>k=0</cell><cell></cell></row></table><note><p>9 else if g is a variable gate with var(g) = {y} and y = x then 12 else if g is a ¬-gate with input gate g ′ then 13 for ℓ ∈ {0, . . . , |var(g) \ {x}|} do 16 end 17 else if g is an ∨-gate with input gates g 1 , g 2 then 18 for ℓ ∈ {0, . . . , |var(g) \ {x}|} do</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>H • (•, •, •). Hence, if we could compute in polynomial time H Π• (•, •, •) for deterministic and decomposable Boolean circuits, then we could compute β in polynomial time as C +x and C -x can be computed in linear time from C, and they are deterministic and decomposable Boolean circuits as well. We now inspect the term α, which we recall is α = S⊆X\{x} |S|=k E e ′ ∼Πp [C(e ′ ) | e ′ ∈ cw(e, S ∪ {x})]. ′′ ∼Πp |X\{x} [C +x (e ′′ ) | e ′′ ∈ cw(e |X\{x} , S)]</figDesc><table><row><cell cols="3">But then observe that, for S ⊆ X \ {x} and e ′ ∈ cw(e, S ∪ {x}), it holds that</cell></row><row><cell cols="2">C(e ′ ) =</cell><cell>C +x (e ′ |X\{x} ) if e(x) = 1 C -x (e ′ |X\{x} ) if e(x) = 0</cell><cell>.</cell></row><row><cell>Therefore, if e(x) = 1, we have that</cell><cell></cell><cell></cell></row><row><cell>α =</cell><cell>E e</cell><cell></cell></row><row><cell>S⊆X\{x}</cell><cell></cell><cell></cell></row><row><cell>|S|=k</cell><cell></cell><cell></cell></row></table><note><p><p><p><p><p><p><p>= H Πp |X\{x} (C +x , e |X\{x} , k)</p>whereas if e(x) = 0, we have that</p>α = H Πp |X\{x} (C -x , e |X\{x} , k).</p>Hence, again, if we were able to compute in polynomial time H Π• (•, •, •) for deterministic and decomposable Boolean circuits, then we could compute α in polynomial time (as deterministic and decomposable Boolean circuits C +x and C -x can be computed in linear time from C). But then we deduce from ( †) that Diff k (C, e, x) could be computed in polynomial time for each k ∈ {0, . . . , n -1}, from which we have that SHAP Πp (C, e, x) could be computed in polynomial time, therefore concluding the existence of the reduction claimed in this section.</p>E.2 Computing H Π• (•, •, •) in polynomial time</p>We now take care of the second part of the proof of Theorem 5.1, i.e., proving that computing H Π• (•, •, •) for deterministic and decomposable Boolean circuits can be done in polynomial time. Formally:</p>Lemma E.1. The following problem can be solved in polynomial time. Given as input a deterministic and decomposable Boolean circuit C over a set of variables X, rational probability values p(x) for each x ∈ X, an entity e ∈ ent(X) and a natural number k ≤ |X|, compute the quantity H Πp (C, e, k).</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc>If S 1 = ∅, then d S1 consist of the single constant gate 1. Otherwise, d S1 encodes the propositional formula ∧ x∈S1 (x∨¬x), but it is constructed in such a way that every ∧and ∨-gate has fan-in at most 2. Boolean circuit d S2 is constructed exactly as d S1 but considering the set of variables S 2 instead of S 1 . Observe that var(d S1 ) = S 1 , var(d S2 ) = S 2 and d S1 , d S2 always evaluate to 1. Then, we transform g into a smooth ∨-gate by replacing gate g 1 by a decomposable ∧-gate (g 1 ∧ d S2 ), and gate g 2 by a decomposable ∧-gate (g 2 ∧ d S1 ). This does not change the Boolean classifier computed. Moreover, since var(g1 ∧ d S2 ) = var(g 2 ∧ d S1 ) = var(g 1 ) ∪ var(gProof of Lemma E.1. Let C be a deterministic and decomposable Boolean circuit C over a set of variables X, p : X → [0, 1] be a rational probability mapping, e ∈ ent(X) and k a natural number such that k ≤ |X|, and let n = |X|. For a gate g of C, let R g be the Boolean circuit over var(g) that is defined by considering the subgraph of C induced by the set of gates g ′ in C for which there exists a path from g ′ to g in C.4 Notice that R g is a deterministic and decomposable Boolean circuit with output gate g. Moreover, for a gate g and natural number l ≤ |var(g)|, define α l g := H Πp |var(g) (R g , e |var(g) , l), which we recall is equal, by definition, to H Πp |var(g) (R g , e |var(g) , l) = e ′ ∼Πp |var(g) [R g (e ′ ) | e ′ ∈ cw(e |var(g) , S)].</figDesc><table><row><cell>S⊆var(g)</cell></row><row><cell>|S|=l</cell></row></table><note><p><p>2 ), we have that g is now smooth. Finally, the resulting Boolean circuit is deterministic and decomposable. Hence, by repeating the previous procedure for each non-smooth ∨-gate, we conclude that C can be transformed into an equivalent smooth Boolean circuit in polynomial time, which is deterministic and decomposable, and where each gate has fan-in at most 2. Thus, from now on we also assume that C is smooth.</p>E</p></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>Recall that the fan-in of a gate is the number of its input gates. In our definition of Boolean circuits, we allow unbounded fan-in ∧and ∨-gates.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>We recall the mathematical convention that there is a unique function with the empty domain and, hence, a unique entity over ∅.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2"><p>Note that D : ent(X) → [0, 1] is actually a probability mass function, but we will abuse notation to simplify the presentation.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3"><p>The only difference between Rg and Cg (defined in Section 2) is that we formally regard Rg as a Boolean classifier over var(g), while we formally regarded Cg as a Boolean classifier over X.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgments</head><p><rs type="person">Pablo Barceló</rs> was funded by <rs type="funder">Fondecyt</rs> grant <rs type="grantNumber">1200967</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_7yKQuk7">
					<idno type="grant-number">1200967</idno>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Supplementary Material: Technical Appendix A Encoding Binary Decision Trees and FBDDs into Deterministic and Decomposable Boolean Circuits</head><p>In this appendix, we explain why binary decision trees and free binary decision diagrams (FBDDs) are special kinds of deterministic and decomposable Boolean circuits. First we need to define these formalisms.</p><p>Binary Decision Diagrams. A binary decision diagram (BDD) over a set of variables X is a rooted directed acyclic graph D such that: (i) each internal node is labeled with a variable from X, and has exactly two outgoing edges: one labeled 0, the other one labeled 1; and (ii) each leaf is labeled either 0 or 1. Such a BDD represents a Boolean classifier in the following way. Let e be an entity over X, and let π e = u 1 , . . . , u m be the unique path in D satisfying the following conditions: (a) u 1 is the root of D; (b) u m is a leaf of D; and (c) for every i ∈ {1, . . . , m -1}, if the label of u i is x ∈ X, then the label of the edge (u i , u i+1 ) is equal to e(x). Then the value of e in D, denoted by D(e), is defined as the label of the leaf u m . Moreover, a binary decision diagram D is free (FBDD) if for every path from the root to a leaf, no two nodes on that path have the same label, and a binary decision tree is an FBDD whose underlying graph is a tree.</p><p>As we show next, FBDDs can be encoded in linear time as deterministic and decomposable Boolean circuits.</p><p>Encoding FBDDs into deterministic and decomposable Boolean circuits (Folklore). Given an FBDD D over a set of variables X, we explain how D can be encoded as a deterministic and decomposable Boolean circuit C over X. Notice that the technique used in this example also apply to binary decision trees, as they are a particular case of FBDDs. The construction of C is done by traversing the structure of D in a bottom-up manner. In particular, for every node u of D, we construct a deterministic and decomposable circuit α(u) that is equivalent to the FBDD represented by the subgraph of D rooted at u. More precisely, for a leaf u of D that is labeled with ℓ ∈ {0, 1}, we define α(u) to be the Boolean circuit consisting of only one constant gate with label ℓ. For an internal node u of D labeled with variable x ∈ X, let u 0 and u 1 be the nodes that we reach from u by following the 0and 1-labeled edge, respectively. Then α(u) is the Boolean circuit depicted in the following figure:</p><p>x It is clear that the circuit that we obtain is equivalent to the input FBDD. We now argue that this circuit is deterministic and decomposable. For the ∨-gate shown in the figure, if an entity e is accepted by the Boolean circuit in its left-hand size, then e(x) = 0, while if an entity e is accepted by the Boolean circuit in its right-hand size, then e(x) = 1. Hence, we have that this ∨-gate is deterministic, from which we conclude that α(u) is deterministic, as α(u 0 ) and α(u 1 ) are also deterministic by construction. Moreover, the ∧-gates shown in the figure are decomposable as variable x is mentioned neither in α(u 0 ) nor in α(u 1 ): this is because D is a free BDD. Thus, we conclude that α(u) is decomposable, as α(u 0 ) and α(u 1 ) are decomposable by construction. Finally, if u root is the root of D, then by construction we have that α(u root ) is a deterministic and decomposable Boolean circuit equivalent to D. Note that this encoding can trivially be done in linear time. Thus, we often say, by abuse of terminology, that "FBDDs (or binary decision trees) are restricted kinds of deterministic and decomposable circuits".</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B Proof of Theorem 3.1</head><p>To complete the proof of Theorem 3.1, we need to prove equation (3). Recall that in this case, we have that g is an ∧-gate, which is decomposable and has fan-in at most 2. Moreover, we assume that g has exactly two input gates g 1 and g 2 , and we fix k ∈ {0, . . . , |var(g)|}.</p><p>To prove equation (3), we need the following notation. For two disjoint sets of variables X 1 , X 2 and entities e 1 ∈ ent(X 1 ), e 2 ∈ ent(X 2 ), we denote by e 1 ∪ e 2 the entity over X 1 ∪ X 2 that coincides with e 1 over X 1 and with e 2 over X 2 (that is, e 1 ∪ e 2 ∈ ent(X 1 ∪ X 2 ), (e 1 ∪ e 2 )(x 1 ) = e 1 (x 1 ) for every x 1 ∈ X 1 , and (e 1 ∪ e 2 )(x 2 ) = e 2 (x 2 ) for every x 2 ∈ X 2 ). Moreover, for two sets S 1 ⊆ ent(X 1 ), S 2 ⊆ ent(X 2 ), we denote by S 1 ⊗ S 2 the set of entities over X 1 ∪ X 2 defined as S 1 ⊗ S 2 := {e 1 ∪ e 2 | e 1 ∈ S 1 and e 2 ∈ S 2 }.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Connecting knowledge compilation classes and width parameters</title>
		<author>
			<persName><forename type="first">A</forename><surname>Amarilli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Capelli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Monet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Senellart</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Theory Comput. Syst</title>
		<imprint>
			<biblScope unit="volume">64</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="861" to="914" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Computational Complexity -A Modern Approach</title>
		<author>
			<persName><forename type="first">S</forename><surname>Arora</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Barak</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
			<publisher>Cambridge University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Causality-based explanation of classification outcomes</title>
		<author>
			<persName><forename type="first">L</forename><surname>Bertossi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Schleich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Suciu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Vagena</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fourth Workshop on Data Management for End-To-End Machine Learning, DEEM@SIGMOD</title>
		<meeting>the Fourth Workshop on Data Management for End-To-End Machine Learning, DEEM@SIGMOD</meeting>
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">An application of the Shapley value to the analysis of co-expression networks</title>
		<author>
			<persName><forename type="first">G</forename><surname>Cesari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Algaba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Moretti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Nepomuceno</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied network science</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">35</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">On Symbolically Encoding the Behavior of Random Forests</title>
		<author>
			<persName><forename type="first">A</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Shih</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Goyanka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Darwiche</surname></persName>
		</author>
		<idno>CoRR abs/2007.01493</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">On the tractable counting of theory models and its application to truth maintenance and belief revision</title>
		<author>
			<persName><forename type="first">A</forename><surname>Darwiche</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Applied Non-Classical Logics</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">1-2</biblScope>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><surname>Darwiche</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Hirth</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2002.09284</idno>
		<title level="m">On the reasons behind decisions</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A Knowledge Compilation Map</title>
		<author>
			<persName><forename type="first">A</forename><surname>Darwiche</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Marquis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Artif. Intell. Res</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="229" to="264" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">On the complexity of cooperative solution concepts</title>
		<author>
			<persName><forename type="first">X</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">H</forename><surname>Papadimitriou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mathematics of operations research</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="257" to="266" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">The Shapley value for cooperative games under precedence constraints</title>
		<author>
			<persName><forename type="first">U</forename><surname>Faigle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Kern</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Game Theory</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="249" to="266" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">On the measure of conflicts: Shapley inconsistency values</title>
		<author>
			<persName><forename type="first">A</forename><surname>Hunter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Konieczny</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">174</biblScope>
			<biblScope unit="issue">14</biblScope>
			<biblScope unit="page" from="1007" to="1026" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">The Shapley value of tuples in query answering</title>
		<author>
			<persName><forename type="first">E</forename><surname>Livshits</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">E</forename><surname>Bertossi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Kimelfeld</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sebag</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">23rd International Conference on Database Theory, ICDT 2020</title>
		<meeting><address><addrLine>Copenhagen, Denmark</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020-03-30">2020. March 30-April 2, 2020</date>
			<biblScope unit="volume">155</biblScope>
			<biblScope unit="page" from="1" to="20" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">From local explanations to global understanding with explainable AI for trees</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Lundberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Erion</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Degrave</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Prutkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Nair</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Katz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Himmelfarb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Bansal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S.-I</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature machine intelligence</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="2522" to="5839" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A unified approach to interpreting model predictions</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Lundberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S.-I</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="4765" to="4774" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Efficient computation of the Shapley value for game-theoretic network centrality</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">P</forename><surname>Michalak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">V</forename><surname>Aadithya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">L</forename><surname>Szczepanski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Ravindran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">R</forename><surname>Jennings</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Artificial Intelligence Research</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="page" from="607" to="650" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<author>
			<persName><forename type="first">C</forename><surname>Molnar</surname></persName>
		</author>
		<ptr target="https://christophm.github.io/interpretable-ml-book" />
		<title level="m">Interpretable machine learning: A guide for making black box models explainable</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Einsum networks: Fast and scalable learning of tractable probabilistic circuits</title>
		<author>
			<persName><forename type="first">R</forename><surname>Peharz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Vergari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Stelzner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Molina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Trapp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Van Den Broeck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Kersting</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Ghahramani</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2004.06231</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">The complexity of counting cuts and of computing the probability that a graph is connected</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Provan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">O</forename><surname>Ball</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Journal on Computing</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="777" to="788" />
			<date type="published" when="1983">1983</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">E</forename><surname>Roth</surname></persName>
		</author>
		<title level="m">The Shapley value: essays in honor of Lloyd S. Shapley</title>
		<imprint>
			<publisher>Cambridge University Press</publisher>
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">A value for n-person games</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">S</forename><surname>Shapley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Contributions to the Theory of Games</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">28</biblScope>
			<biblScope unit="page" from="307" to="317" />
			<date type="published" when="1953">1953</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">On tractable representations of binary neural networks</title>
		<author>
			<persName><forename type="first">W</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Shih</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Darwiche</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Choi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2004.02082</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">A symbolic approach to explaining Bayesian network classifiers</title>
		<author>
			<persName><forename type="first">A</forename><surname>Shih</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Darwiche</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings IJCAI</title>
		<meeting>IJCAI</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="5103" to="5111" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Formal verification of Bayesian network classifiers</title>
		<author>
			<persName><forename type="first">A</forename><surname>Shih</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Darwiche</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Probabilistic Graphical Models</title>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="427" to="438" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Verifying binarized neural networks by Angluin-style learning</title>
		<author>
			<persName><forename type="first">A</forename><surname>Shih</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Darwiche</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Choi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Theory and Applications of Satisfiability Testing</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="354" to="370" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Smoothing structured decomposable circuits</title>
		<author>
			<persName><forename type="first">A</forename><surname>Shih</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Van Den Broeck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Beame</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Amarilli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="11416" to="11426" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">On the Tractability of SHAP Explanations</title>
		<author>
			<persName><forename type="first">G</forename><surname>Van Den Broeck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Lykov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Schleich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Suciu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2009.08634</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
