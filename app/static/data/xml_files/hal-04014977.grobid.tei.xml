<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Unsupervised Fine-grained Hate Speech Target Community Detection and Characterisation on Social Media</title>
				<funder ref="#_yKmYsa6 #_Ykgd6V2">
					<orgName type="full">Agence Nationale de la Recherche</orgName>
					<orgName type="abbreviated">ANR</orgName>
				</funder>
				<funder>
					<orgName type="full">French government</orgName>
				</funder>
				<funder ref="#_kFyBE9S">
					<orgName type="full">3IA Côte d</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Anaïs</forename><surname>Ollagnier</surname></persName>
							<email>ollagnier@i3s.unice.fr</email>
							<affiliation key="aff0">
								<orgName type="laboratory">I3S</orgName>
								<orgName type="institution" key="instit1">Université Côte d&apos;Azur</orgName>
								<orgName type="institution" key="instit2">Inria</orgName>
								<orgName type="institution" key="instit3">CNRS</orgName>
								<orgName type="institution" key="instit4">Polytech&apos;Nice-Sophia</orgName>
								<address>
									<addrLine>930 route des Colles</addrLine>
									<postCode>06903</postCode>
									<settlement>Sophia Antipolis</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="laboratory">I3S</orgName>
								<orgName type="institution" key="instit1">Université Côte d&apos;Azur</orgName>
								<orgName type="institution" key="instit2">Inria</orgName>
								<orgName type="institution" key="instit3">CNRS</orgName>
								<orgName type="institution" key="instit4">Polytech&apos;Nice-Sophia</orgName>
								<address>
									<addrLine>930 route des Colles</addrLine>
									<postCode>06903</postCode>
									<settlement>Sophia Antipolis</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Elena</forename><surname>Cabrio</surname></persName>
							<email>elena.cabrio@inria.fr</email>
							<affiliation key="aff0">
								<orgName type="laboratory">I3S</orgName>
								<orgName type="institution" key="instit1">Université Côte d&apos;Azur</orgName>
								<orgName type="institution" key="instit2">Inria</orgName>
								<orgName type="institution" key="instit3">CNRS</orgName>
								<orgName type="institution" key="instit4">Polytech&apos;Nice-Sophia</orgName>
								<address>
									<addrLine>930 route des Colles</addrLine>
									<postCode>06903</postCode>
									<settlement>Sophia Antipolis</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Serena</forename><surname>Villata</surname></persName>
							<email>serena.villata@inria.fr</email>
							<affiliation key="aff0">
								<orgName type="laboratory">I3S</orgName>
								<orgName type="institution" key="instit1">Université Côte d&apos;Azur</orgName>
								<orgName type="institution" key="instit2">Inria</orgName>
								<orgName type="institution" key="instit3">CNRS</orgName>
								<orgName type="institution" key="instit4">Polytech&apos;Nice-Sophia</orgName>
								<address>
									<addrLine>930 route des Colles</addrLine>
									<postCode>06903</postCode>
									<settlement>Sophia Antipolis</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Unsupervised Fine-grained Hate Speech Target Community Detection and Characterisation on Social Media</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">63F03A38A272B282FF6DDADCBE65E376</idno>
					<idno type="DOI">10.1007/s13278-023-01061-4</idno>
					<note type="submission">Submitted on 5 Mar 2023</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-04-12T14:52+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Unsupervised Fine-grained Hate Speech Target Community Detection Fine-grained hate speech target detection</term>
					<term>Community detection</term>
					<term>Multi-view clustering</term>
					<term>Sentence embedding</term>
					<term>Social media</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>published or not. The documents may come from teaching and research institutions in France or abroad, or from public or private research centers. L'archive ouverte pluridisciplinaire</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>By empowering the freedom of expression and individual voices, social media platforms such as Twitter and Facebook, and community forums have witnessed an exponential growth, becoming an integral part of our daily lives. Whilst these online spaces have facilitated the communication and exchange of ideas and points of view, they have also opened the door to the proliferation of content that can be degrading, abusive, or otherwise harmful to people. An important and elusive form of such language is hateful speech, i.e., content that mocks or discriminates against a person or group based on specific characteristics such as colour, ethnicity, gender, sexual orientation, nationality, religion, or other characteristics <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2]</ref>. Over the last decade, the preoccupation for the use of electronic means of communication as a tool to convey hate, racist and xenophobic contents tremendously increased <ref type="bibr" target="#b2">[3]</ref>, and a large number of computational methods involving Natural Language Processing (NLP) and Machine Learning (ML) have been proposed for automated online hate speech detection, e.g., <ref type="bibr" target="#b3">[4]</ref><ref type="bibr" target="#b4">[5]</ref><ref type="bibr" target="#b5">[6]</ref>. Most of the prior works have mainly considered the task as a binary classification problem seeking to distinguish hate and non-hate speech. However, recent works have highlighted the importance to consider the different hate speech facets (e.g., nature of the target, hate directness, hostility type) in order to better understand how hate is conveyed online <ref type="bibr" target="#b6">[7]</ref><ref type="bibr" target="#b7">[8]</ref><ref type="bibr" target="#b8">[9]</ref>. On this purpose, a high number of resources and benchmark corpora aiming at evaluating the ability of automated methods to capture fine-grained hate speech phenomena (i.e., multi-level annotation accounting for different hate speech facets) were developed. The following examples extracted from the multilingual hate speech dataset (MLMA) <ref type="bibr" target="#b9">[10]</ref> illustrate a multi-level annotation scheme. Here, we only detail the (group of) victim(s) targeted and the protected characteristics discriminated (e.g., references to racial or sexist stereotypes).</p><p>1. '@user @user go back shithole country grab pussy' -targets: immigrants, protected characteristic: ethnic origin 2. '@user @user another disgusting lying feminazi.' -targets: women, protected characteristic: gender 3. '@url steve guy fucking retard.' -targets: special needs, protected characteristic: disability</p><p>Besides the efforts made to develop methods enabling to distinguish finegrained hate speech phenomena from each other, often only a specific facet is dealt with <ref type="bibr" target="#b10">[11]</ref>. However, hate speech is a complex and multi-faceted notion relying on interconnected phenomena at stake. Despite existing works addressing the task from an intersectional perspective <ref type="bibr" target="#b11">[12]</ref>, the issue of understanding the multiple complex facets of hate speech phenomena is still an open challenge.</p><p>In addition, an important challenge when dealing with social media is to provide robust solutions enabling to cope with the fast and often unpredictable evolution of social media data. This evolution involves both the language level (i.e., neologisms and slang words) or content (i.e., expression of opinions in reaction to societal issues). However, most of existing approaches rely on supervised algorithms which suffer from well-known limitations including the lack of annotated data and the need to regularly update them in order to account for such continuous evolution of this kind of content. Such findings raise questioning about the ability of a such strategy to efficiently address alone the task of hate speech detection.</p><p>To undertake these issues, the research objectives of this paper are the following: <ref type="bibr" target="#b0">(1)</ref> to encode harmful content to unveil key features aiming at contrasting different kinds of abusive behaviours; <ref type="bibr" target="#b1">(2)</ref> to address the task of fine-grained hate speech target community detection adopting an unsupervised technique; and (3) to assess the ability of the proposed pipeline to establish partitioning reflecting complex hate speech phenomena.</p><p>To achieve these goals, we investigate the use of multiple data views (i.e., data structures) holding different properties to obtain meaningful hate speech representations. To do that, we exploit two well-known multilingual pre-trained language models: mBERT (multilingual BERT) <ref type="bibr" target="#b12">[13]</ref> and mUSE (multilingual Universal Sentence Encoder) <ref type="bibr" target="#b13">[14]</ref>, from which syntactic, semantic and relationship information is derived. Then, the task of hate speech detection is transposed into a clustering problem allowing to benefit from unsupervised approaches, which do not need annotated corpora to be trained. Leveraging the last advances in clustering, we investigate the use of Multi-view Clustering (MvC), especially the Multi-view Spectral Clustering (MvSC) algorithm, in order to exploit complementary and consensual information across the multiple data views of a different nature (i.e., feature and graph spaces). To investigate the ability of the proposed pipeline to address challenges in the field (i.e., detecting fine-grained hate speech phenomena), we conduct experiments on a curated version of the French and the English of the MLMA dataset which only includes hostile tweets. We assessed the performances focusing on the target and group labels (hereinafter referred respectively to as target-type / victim-groups). Partitioning is evaluated regarding whether aggregated hate content correspond to existing hate speech target communities in the MLMA dataset, i.e., clusters containing content with the same target-type / victimgroup labels. Conducted experiments show that the simultaneous clustering of multiple data views improves the clustering performance when compared to state-of-the-art clustering methods (k-means, k-medoids and spectral clustering) based on a single feature set on both languages. Furthermore, we also provide a study of the most frequent n-grams extracted from the generated clusters. The goal is to observe the ability of the proposed pipeline to generate semantic spaces reflecting hate speech manifestations used to offend a specific victim-group given a protected characteristic. In other words, we seek to identify whether the generated clusters may unveil an underlying structure of the data similar to those provided by the MLMA multi-aspect hate speech analysis or -on the contrary -it is enabled to uncover different properties. From this study, we analyse the properties resulting from the automatic identification of fine-grained hate speech target communities with the purpose of providing key informational insights aiming at improving the design of machine learning tools dedicated to capture online hateful content.</p><p>In summary, the contributions of our paper are summarised as follows:</p><p>• Leveraging syntactic/semantic and relationship information to enrich hate content representations; • Exploring the use of clustering techniques as a mean to address the task of fine-grained hate speech detection; • Assessing the ability of the proposed pipeline to address the task through an in-depth content analysis of the generated hate speech target communities.</p><p>The paper is organised as follows: Section 2 discusses the related literature on hate speech detection, on community detection in social media and on the multi-view data clustering. Section 3 describes the multilingual hate speech dataset used in this study. Section 4 presents the proposed clustering method and discusses the methodological choices. The experimental procedure is described in Section 5. Section 6 details the experimental setting and report on the obtained results. Finally, Section 7 presents the study about the characterisation of the different types of hate speech used to target communities. Conclusions end the paper, drawing directions for future work. NOTE: This paper contains examples of language which may be offensive to some readers. They do not represent the views of the authors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>The following sections provide a panorama of existing works aiming at automatically identifying abusive behaviours. In particular, we focus on a review of datasets and approaches developed to address this task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Hate Speech Datasets.</head><p>From 2016 onward, a high number of resources and benchmark corpora for many different languages were developed. As hate speech is a complex and multi-faceted notion, the scientific community tackles this issue by developing various semantic frameworks aiming at identifying different topical focus such as specific targets (groups targeted), nuances of hate speech (abusive, toxic, dangerous, offensive or aggressive language) or rhetoric devices (slurs, obscenity, offences or sarcasm). Several surveys describe the current state of the field providing a structured overview of existing datasets <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b14">15]</ref>. Most of available datasets come from Twitter and rely on a binary scheme: two mutually-exclusive values to mark the presence or absence of hate speech such as those introduced in <ref type="bibr" target="#b15">[16]</ref>, <ref type="bibr" target="#b16">[17]</ref> and, <ref type="bibr" target="#b17">[18]</ref>. Some datasets relies on multi-level annotation, with finer-grained schemes accounting for different phenomena. Recently, <ref type="bibr" target="#b18">[19]</ref> adopt a three-layer binary annotation for hate speech, aggressiveness and nature of the target (individual or group), while <ref type="bibr" target="#b9">[10]</ref> provides a fine-grained annotation of tweets about both victim-groups and target-types, hate directness (whether the text is direct or indirect), hostility type and annotator's sentiment. With the purpose to facilitate access to information, the platform hatespeechdata.com<ref type="foot" target="#foot_0">1</ref> catalogues datasets annotated for hate speech, online abuse, and offensive language aiming at training natural language processing systems.</p><p>Several corpora have been developed with the purpose of organising open shared tasks at NLP-related conferences including TRAC 2 (Workshop on Trolling, Aggression and Cyberbullying at LREC 2018 &amp; 2020), EVALITA 2020 Tasks 3 (automatic misogyny identification &amp; hate speech detection) and SemEval 2019 Tasks 5 (HatEval <ref type="bibr" target="#b18">[19]</ref>, multilingual detection of hate speech against immigrants and women in Twitter) &amp; 6 (OffensEval <ref type="bibr" target="#b19">[20]</ref>, identifying and categorising offensive language in social media) at NAACL HLT 2019, as well as Hate Speech and Offensive Content Identification in Indo-European Languages (HASOC 2019 &amp; 2020 4 ), among others.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Hate Speech Detection Methods.</head><p>Most of the prior works have mainly considered the task of hate speech detection as a supervised document classification problem. Following the taxonomy introduced in <ref type="bibr" target="#b1">[2]</ref>, existing methods can be divided into two main categories: classical ML methods and deep learning methods. Classical ML methods require as input feature vectors derived from text representation techniques. Text representation consists of converting textual content into machine-readable format using a collection of meaningful features. While this task has been widely investigated by the NLP community, it is still an ongoing challenge as it involves addressing complex semantic phenomena such as figurative language and idiosyncratic style. As a part of hate speech detection models, this task is mainly addressed using two main text mining encoding techniques: surface features and linguistic-based features. Word and character n-grams are currently the prominent shallow lexical features, and also the most successful ones <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b21">22]</ref>. In <ref type="bibr" target="#b22">[23]</ref>, character 4-grams features outperforms other surface feature representations in distinguish between profanity and hate comments. Concerning linguistic-based features, Part of Speech (PoS) tagging and dependency parsing obtain the best performances by providing a deeper understanding of hateful content <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b23">24]</ref>. Features derived from sentiment analysis, usually used as auxiliary features, are also considered as powerful linguistic cues. The use of sentiment polarity or emotion tone prove effective in tasks on aggression identification and threat detection <ref type="bibr" target="#b24">[25]</ref>. Recently, the use of clustering techniques, especially Brown clustering, show promising results in representing positive and negative sentiment data to enrich offensive comment representations <ref type="bibr" target="#b25">[26]</ref>. Once feature vectors are generated given a text representation strategy, they are consumed by supervised algorithms. Several surveys report the use of different algorithms including Support Vector Machines (SVM), Naive Bayes, Logistic Regression, and Random Forest <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b23">24]</ref>. Among these, SVM is still one of the most popular algorithms to address shared tasks on hate speech detection <ref type="bibr" target="#b26">[27]</ref><ref type="bibr" target="#b27">[28]</ref><ref type="bibr" target="#b28">[29]</ref>.</p><p>Deep learning based methods consists of applying neuronal networks to automatically learn multi-layers of abstract features from raw data. Here, inputs can be simply the raw text data, or take various forms of feature encoding, including any of those used in the classic methods. Prior works based on neuronal networks exploit the network structure either to design classification models or to build language models. In the context of hate speech classification, Convolutional Neural Network (CNN), Recurrent Neural Network (RNN) and, Long Short-Term Memory network (LSTM) have shown to perform better than classic ML methods <ref type="bibr" target="#b1">[2]</ref>. Hybrid methods combining neuronal networks have also been proposed and shown promising performances outperforming state-of-theart methods on a large collection of public hate speech datasets <ref type="bibr" target="#b3">[4]</ref>. In parallel, pre-trained word representations significantly advanced the state of the art in various NLP tasks including shared tasks on hate speech detection <ref type="bibr" target="#b29">[30]</ref>. Besides traditional neuronal network models, transformer-based language models like Bidirectional Encoder Representations from Transformers (BERT) <ref type="bibr" target="#b12">[13]</ref> achieve also state-of-the-art performance. In the SemEval 2019 shared task: Offens-Eval <ref type="bibr" target="#b30">[31]</ref>, most of the top-ranked models relies on BERT models. Recent works address the topic bias issue and introduced fine-tuned Transformer neuronal network architectures achieving state-of-the-art performance in the task of abusive language detection in English <ref type="bibr" target="#b31">[32,</ref><ref type="bibr" target="#b32">33]</ref>.</p><p>From the literature review, we highlight that the task of hate speech detection is mainly considered as a supervised classification problem. However, dealing with social media content means to cope with dynamic data. Moreover, recent studies report the proliferation of code words for communities aiming at countering moderation tools <ref type="bibr" target="#b33">[34]</ref>, while <ref type="bibr" target="#b34">[35]</ref> highlight the difficulties in tracking all racial and minority insults due to the constant evolution of social phenomena and language. Applying supervised methods raise concerns also about the long-term robustness of such systems dealing with evolving social media data. Unsupervised approaches are mainly used in the literature to obtain richer text representations including deep learning to generate embeddings <ref type="bibr" target="#b35">[36]</ref> or LDA and Brown Clustering to provide auxiliary features <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b36">37]</ref>. Concerning this point, clustering techniques, especially community detection algorithms, constitutes a key tool for the analysis of complex networks by enabling the study of mesoscopic structures that are often associated with organisational and functional characteristics of the underlying networks. In the context of social media, the analysis of such networks presents valuable resources from which it is possible to gain insights into the social phenomena and processes <ref type="bibr" target="#b37">[38]</ref>. For instance, outcomes from analysing the community structure of networks have led to a wide range of intelligent services and applications in the fields of opinion mining <ref type="bibr" target="#b38">[39]</ref>, marketing activities <ref type="bibr" target="#b39">[40]</ref> and data-driven decision making <ref type="bibr" target="#b40">[41]</ref>, among others. Often addressed to reveal communities from user-to-user interaction (e.g., mentions, follows), it has also been performed considering only the textual content allowing to uncover cohesive groups or clusters based on semantic knowledge <ref type="bibr" target="#b41">[42]</ref>. Using clustering techniques allow to overcome aforementioned limitations by providing a scalable, adaptive and robust solution to deal with social data. As hate speech is a complex and multi-faceted notion, we investigate the use of multi-view clustering to handle data views holding different properties to leverage richer data information. Introduced in <ref type="bibr" target="#b42">[43]</ref>, the core idea behind Multi-view Clustering is to leverage effectively the diversity and the complementary of multi-view data to improve the clustering performance. Typically, each of these data views provides a different perspective of a given set of entities. The term "multi-view clustering" refers to algorithms that can utilise multiple feature spaces to describe distinct points of view of a phenomenon <ref type="bibr" target="#b42">[43,</ref><ref type="bibr" target="#b43">44]</ref>. Recently, several important related surveys about MvC have been published to summarise the theories, methodologies, taxonomies and applications of the existing MvC approaches <ref type="bibr" target="#b44">[45]</ref><ref type="bibr" target="#b45">[46]</ref><ref type="bibr" target="#b46">[47]</ref>. As a part of this work, we rely on the MVSC-CEV (multi-view spectral clustering by common eigenvectors) algorithm introduced in <ref type="bibr" target="#b47">[48]</ref> which allows the use of an arbitrary number of input views, possibly of a different nature (feature or graph space) and with different dimensions. To the best of our knowledge, this is the first approach based on multi-view clustering applied to the problem of hate speech detection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">The MLMA dataset and its extension</head><p>The multilingual hate speech dataset (MLMA) <ref type="bibr" target="#b9">[10]</ref> provides a fine-grained annotation of 5.647 English tweets, 4.014 French tweets, and 3.353 Arabic tweets. Five facets characterising hate speech are labelled, including the directness of the speech (directness), the hostility type (sentiment), the protected characteristic discriminated (target-type), the group of victims (victim-group), and the annotator's sentiment (annotator sentiment).</p><p>In this paper, we focus on the French and the English portions of the dataset and on the facets related to the target-type and victim-group labels. More precisely, the target-type denotes whether the tweet insults or discriminates against people based on their origin, religious affiliation, gender, sexual orientation, special needs or other. In total, 16 common victim-group have been identified denoting whether the tweet is aimed at women, people of African descent, Hispanics, gay people, Asians, Arabs, immigrants in general, refugees; people of different religious affiliations such as Hindu, Christian, Jewish people, and Muslims; or different political ideologies as socialists, and others. The individual covers hate directed towards one individual, which cannot be generalised. Both target-type and victim-group referring to other correspond to utterances which do not fit with MLMA facets' annotation guidelines. In the dataset, 49 hate speech target communities are identified in French and 70 in English (i.e., combining target-type victim-group labels). A serious skewed distribution of the hate speech target communities is observed in each corpus, with 69.3% of hate speech target communities in French below the average imbalance ratio (i.e., the average proportion of the number of instances in the majority community to the number of instances in the minority ones) and 72.8% in English. Most of the studies on the behaviour of machine learning applications have shown a significant loss of performance facing imbalanced datasets <ref type="bibr" target="#b48">[49]</ref>. As one of the purposes of this study is to evaluate the ability of the proposed pipeline to identify automatically finegrained hate speech phenomena relying on the MLMA labels, the corpora are filtered to alleviate the bias towards the majority communities. Only communities getting an imbalance ratio above 20 for the French corpus and 15 for the English one are considered in this study. In addition, as we focus on hostile tweets conveying abusive or threatening speech only tweets labelled as abusive, hateful, offensive, disrespectful or fearful are considered. The resulting datasets (hereinafter referred respectively to as the FR hate speech target community corpus and the EN hate speech target community corpus) comprise 3.701 and 5.209 tweets divided respectively into 16 and 26 hate speech target communities, as reported in Table <ref type="table" target="#tab_0">1</ref>.</p><p>From this Table, we can observe that English tweets tend to target people with special needs and women over the different target-type facets, while French tweets are more offensive towards the victim-group individual. Figure <ref type="figure" target="#fig_0">1</ref> illustrates the global distribution of target-types on both languages. From this figure, we can observe a flagrant difference between the protected characteristics discriminated according to each language. In detail, tweets discriminating or insulting against people based on their origin is the highest accounted targettype. Concerning the other target-type facets, disparities are more important according to the language. Whilst the target-type sexual orientation is among one of the main protected characteristics discriminated in English (7.85% in total considering the whole English tweets), in French it is pruned due to a low number of samples. The same phenomenon is observed on the target-type religion which is pruned in English while it represents 3.4% of the hateful content in the French corpus. In English, disability is the second most frequent target-type followed by other and gender. In French, the second most populate target-type facet is other followed by disability and religion. Table <ref type="table" target="#tab_1">2</ref> presents a sample of hateful tweets with the corresponding annotations extracted from the MLMA dataset.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Community detection Data views extraction</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">A Framework for Fine-grained Hate Speech Target Community Detection</head><p>This section describes the proposed pipeline for the task of fine-grained hate speech target community detection. As visualised in Figure <ref type="figure" target="#fig_2">2</ref>, it consists of three main steps including the network construction, the data views extraction and the target community detection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Network Construction</head><p>Twitter data are noisy and unstructured, and include linguistic errors and idiosyncratic style. Handling such content implies using adapted cleaning processes to fully leverage data content and extract relevant information. Several works have proposed specific preprocessing pipelines showing significant improvements in model performances <ref type="bibr" target="#b49">[50,</ref><ref type="bibr" target="#b50">51]</ref>. As a part of the proposed work, we have implemented the benchmark preprocessing framework presented in <ref type="bibr" target="#b5">[6]</ref> aiming at dealing with heterogeneous hate speech datasets extracted from various social media. In short, the applied cleaning process consists of performing data normalisation including hashtags (i.e., split into single words), emojis (i.e., replaced by their textual description), user mentions and URLs (i.e., replaced by canonical forms: username and url), and next, tokenises and lemmatises the textual content. After data cleaning and normalisation, the step consists of encoding the hate speech target community corpora to obtain node-like structures. As pre-trained language models have become a popular method achieving state-of-the-art results in a wide range of NLP tasks, especially as a part of feature construction methods <ref type="bibr" target="#b51">[52,</ref><ref type="bibr" target="#b52">53]</ref>, we decide to exploit two well-known multilingual pre-trained language models to generate sentence vector-based features. From empirical studies we conducted on the hate speech target community corpora, mBERT (multilingual BERT) and mUSE (multilingual Universal Sentence Encoder) achieved better performances. These two pre-trained language models -evaluated against XLM-RoBERTa and Quora distilbert multilingual on the community detection task using k-means and spectral clustering with a single feature set -are used to generate sentence embeddings for each tweet. Table <ref type="table" target="#tab_2">3</ref> provides a brief overview of both pre-trained models describing the encoder architecture and the training dataset. In detail, mBERT relies on the transformer model BERT <ref type="bibr" target="#b12">[13]</ref> (Bidirectional Encoder Representations from Transformers) and is pre-trained on a large corpus of multilingual data. More precisely, it is pre-trained with two objectives: Masked Language Modelling (MLM, 15% of tokens are masked and BERT is trained to predict them from context) and Next Sentence Prediction (NSP, it is trained to predict if a chosen next sentence was probable or not given the first sentence). Concerning mUSE, it relies on the USE <ref type="bibr" target="#b53">[54]</ref> (Universal Sentence Encoder) architecture and is originally pre-trained on Wikipedia, web news, web question-answer pages and discussion forums and augmented with the Stanford Natural Language Inference (SNLI) corpus translated to 15 languages. From a multi-task dual-encoder model, this transformer constructs sentence embeddings based on cross-lingual representation learning that combines methods for multi-task learning of monolingual sentence representations. Here, the pre-trained mBERT model used is publicly available on HuggingFace <ref type="foot" target="#foot_2">5</ref> . In order to generate sentence embeddings, we perform a mean pooling of the model outputs. Conversely, the mUSE model used in this study, also released by HuggingFace<ref type="foot" target="#foot_3">6</ref> , allows to generate directly sentence embeddings.</p><p>Once the feature sets are built, the next step is the network construction, which consists of reshaping the data into node-like structures. To identify tweet pairs sharing key textual features, we use the cosine similarity measure. Widely used to determine similarities between vectors <ref type="bibr" target="#b54">[55]</ref>, this similarity measure has the advantage to allow comparisons between inputs with different lengths.</p><p>Figure <ref type="figure" target="#fig_3">3</ref> shows samples of sentence similarity scores obtained from the corresponding affinity matrix of each pre-trained language model. As illustrated, the inner representation of the languages learnt by each pre-trained model results in affinity matrices conveying different sources of rich semantic information. From the affinity matrices, a network (graph) is generated in which individual tweets are the nodes, and similar tweets are grouped together. As a result we obtain a weighted and undirected graph G. Edges have positive weights, and the graph topology is described by the affinity matrix W , where the generic element W uv = W vu &gt; 0 if there is a weighted edge between nodes u and v, while W uv = W vu = 0 otherwise. However, keeping the full information about the network may be problematic. A network with a high edge density may be intractable by traditional tools of network analysis. It may especially pose a serious obstacle for graph clustering techniques <ref type="bibr" target="#b55">[56]</ref>. To overcome this issue and considering the weighted character of the edges in the proposed approach, we perform information reduction using a simple weight thresholding method. Weight thresholding removes all edges with weight lower than a threshold value. This means that the resulting graph G has a thresholded weight matrix W , whose generic element Wuv = Wvu = W uv if W uv ≥ θ and Wuv = Wvu = 0 otherwise. The thresholded graph G is therefore a subgraph of G with the same number of nodes. Concerning the connectivity of this subgraph, as there are so many ways to express hatred some users' utterances obtain similarity scores below the defined threshold. However, these tweets constitute relevant informational segments which can allow to better capture how hate is spread online. In addition, the lack of connectivity in a graph can impact its analysis leading to decrease the quality of the partitioning. To bridge isolated nodes towards the main connected components, we connect them to their closest neighbours (i.e., nodes getting the highest similarity scores). From empirical studies we conducted on the hate speech target community corpora, the weight threshold used throughout the paper is set to 0.8 when referring to the thresholded graphs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Data views Construction</head><p>The MvSC algorithm maximises clustering quality considering the diversity and complementary of different data views. In this regard, one of the main contributions of this work is to derive different views holding specific properties to unveil a more robust network partitioning. Here, data views of different nature are considered including feature sets (syntactic/semantic information) and affinity matrices (relationship information) resulting from the network construction step. Data views used in this work are detailed below:</p><p>-Feature sets (syntactic/semantic information) While the feature sets capture relations, similarities and semantic relationships between sentences, the graph spaces contain information about nodes (i.e., tweets) connectedness (i.e., whether pairs of nodes are adjacent or not in a graph and the nature of their connection). The deriving views obtained from different language models -relying on different encoding strategies and exhibiting different properties -is beneficial to accurately describe the textual data we analyse. In the following section, we describe how these views are consumed by the MvSC algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Community Detection</head><p>Relying on a MvSC algorithm, the final module of the proposed pipeline aims at identifying communities. In the proposed approach, target communities refer to the different hate speech targets introduced in Section 3. In order to unveil mesoscopic structures among tweets related to the expected communities, this step relies on the MVSC-CEV <ref type="bibr" target="#b47">[48]</ref>. The main structural difference between prevailing multi-view clustering methods and MVSC-CEV lies in the step where the information from the multiple views is collapsed into a single view to produce the final clustering assignment. Roughly speaking, multi-view clustering methods consider as input data views and obtain an affinity matrix for each view. Then, a projection of each affinity matrix is computed into a space suitable for clustering, to produce a consensus partition. As a part of the MVSC-CEV algorithm, it clusters all views separately. Then, it takes the obtained clustering assignments and loops back to the data projection step in order to improve the projections with the clustering information previously obtained.</p><p>Formally, the algorithm considers as input a set of D data views V = {V 1 , V 2 , . . . , V D } of the data with n samples each. For each data view V D ∈ V , a similarity matrix is computed using the Gaussian similarity function resulting in a set of similarity matrices S = {S 1 , S 2 , . . . , S D }. In turn, for each S D ∈ S its corresponding Laplacian matrix L D is generated, where L D ∈ L and L corresponds to the set of computed Laplacian matrices. The set of Laplacian matrices L is passed to the S-CPC algorithm <ref type="bibr" target="#b56">[57]</ref> along with k desired number of clusters in order to compute their common eigenvectors. As a result, a matrix X is obtained, where the k largest eigenvectors of the Laplacian matrices</p><formula xml:id="formula_0">L D ∈ L are the first eigenvectors x (i) 1 of each submatrix L (i) D .</formula><p>Finally, k-means is applied to the matrix Y producing the partitioning of the input data samples common to the D input views, where Y is the result of the normalisation of the matrix X. Therefore, it is a co-training approach, since it uses the results of one iteration to further improve the results of the final clustering. Figure <ref type="figure">4</ref> presents a visualisation of the best partitioning (cf. Section 6) resulting from the proposed pipeline applied to the FR hate speech target community corpus. In this example, the consensus partition is obtained computing eigenvectors common to the mUSE view and the following affinity matrices: mBERT-PRO, mUSE-PRO and mUSE-NET. As a result, we obtain a graph composed of 3.701 nodes and 16.945 edges. Each colour refers to one of the 16 ground-truth (labels already used in the MLMA dataset) fine-grained hate speech target communities of the French corpus.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experimental setting</head><p>In this section, we firstly describe the reference methods evaluated in this study, and secondly, we introduce the evaluation metrics used to assess the quality of the clustering produced by each method. Finally, we detail the procedure of hypothesis testing used to perform significance tests.</p><p>Fig. <ref type="figure">4</ref>: Hate speech target community network relying on a 2-views configuration (the mBERT view and the mUSE view). The network is obtained from the FR hate speech target community corpus and it is composed of 16 node communities. Each node colouring corresponds to an hate speech target community. Individual nodes represent the tweets and are linked to each other considering their semantic similarity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Reference methods</head><p>To evaluate the advantages of mixing multiple data views, we compare the MvSC clustering algorithm against three well-known clustering techniques: kmeans <ref type="bibr" target="#b57">[58]</ref>, k-medoids <ref type="bibr" target="#b58">[59]</ref> and spectral clustering <ref type="bibr" target="#b59">[60]</ref>. All these state-of-the art clustering techniques are based on the Scikit-learn implementation. As kmeans only allows feature sets as input, here k-medoids is used to evaluate the performances of the proposed single-view configurations relying on similarity matrices. Conversely, the spectral clustering algorithm allows inputs of a different nature (feature or graph space). Both k-means and k-medoids use default parameters. Concerning spectral clustering, the affinity parameter for the feature spaces is set to 'nearest neighbors' (construct the affinity matrix by computing a graph of nearest neighbours) and for the similarity matrices it is set to 'precomputed nearest neighbors' (interpret precomputed distances and construct a binary affinity matrix from the n neighbors nearest neighbours of each instance). As all the clustering methods analysed and compared require to define a number of desired clusters, the number defined for the French and Unsupervised Fine-grained Hate Speech Target Community Detection the English datasets is respectively 16 and 26 clusters, numbers corresponding to their ground-truth hate speech target communities.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Performance assessment</head><p>Following the methodology described in <ref type="bibr" target="#b60">[61]</ref>, the quality of the clustering methods is evaluated using clustering purity, clustering Adjusted Rand Index (ARI) and the Normalised Mutual Information (NMI) metric. Briefly, purity is the ratio of the summation of how many maximum points of each algorithmic cluster c ∈ k match with a considered gold set cluster g ∈ t and the total number of points in data, such as:</p><formula xml:id="formula_1">purity(c k , g t ) = k i=1 max t j=1 (c i ∩ g j ) N<label>(1)</label></formula><p>the higher the purity the better the clustering outcome is. The maximum purity value is 1.0. The Rand Index calculates a similarity between two clusterings (i.e, sets of clusters), by looking at each peer of individuals and counting those that are or are not in the same cluster, depending on whether you are in actual or predicted clustering:</p><formula xml:id="formula_2">RI = (a + b)/( n C 2 ) (<label>2</label></formula><formula xml:id="formula_3">)</formula><p>where a is the number of times a pair of elements belongs to the same cluster across two clustering methods, b is for those that belong to difference clusters across two clustering methods, and n C 2 is the number of unordered pairs in a set of n elements. As such, the RI does not guarantee that random assignment will produce a value close to 0. This is why this raw index is 'adjusted to account for chance', which gives the ARI score:</p><formula xml:id="formula_4">ARI = RI -Expected RI max(RI) -Expected RI<label>(3)</label></formula><p>The ARI, which is symmetrical, measures the similarity and the consensus of two assignments, ignoring permutations and normalising against what would have happened by chance. The NMI, built on the Shannon entropy of information theory, tries to quantify the amount of shared information between two clusterings C and T . Formally:</p><formula xml:id="formula_5">M I(C, T ) = r i=1 k j=1 p ij log p ij p Ci • p Tj<label>(4)</label></formula><p>It measures the dependence between the observed joint probability p ij of C and T , and the expected joint probability p Ci • p Tj under the independence assumption. When C and T are independent then p ij = p Ci • p Tj , and thus M I(C, T ) = 0. In other words, M I(C, T ) can be thought of as the informational 'overlap' between C and T , or how much we learn about C from knowing T (and about T from knowing C). In order to normalise the M I value, the NMI of C and T is defined as follows:</p><formula xml:id="formula_6">N M I(C, T ) = M I(C, T ) H(C) • M I(C, T ) H(T ) = M I(C, T ) H(C) • H(T )<label>(5)</label></formula><p>where H(.) corresponds to the computation of the Shannon entropy. All these indices lie in the range [0, 1], and values tending towards unity indicate a perfect correlation between the partitions. In our experiments we use the Scikit-learn implementation of the ARI and NMI while the purity is implemented following the instructions reported in <ref type="bibr" target="#b60">[61]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Statistical tests</head><p>For all the analysed and compared stochastic clustering methods in this study, a total of 31 independent executions for each dataset were performed. For each clustering method and evaluation metric, we carried out statistical tests from all the executions to determine the significance of the reported performances.</p><p>To define the appropriate procedure of hypothesis testing, we checked the normality assumption using the Shapiro-Wilk test <ref type="bibr" target="#b61">[62]</ref> and the homogeneity of variance through the Levene's test <ref type="bibr" target="#b62">[63]</ref>. As a result, and for both assumptions, we rejected the null hypotheses indicating that the residuals are not normally distributed and that their variability is statistically insignificant. Therefore, we use the Wilcoxon signed ranks test <ref type="bibr" target="#b63">[64]</ref> to compare every pair of approaches on each dataset and across all datasets. Furthermore, we use the Friedman test <ref type="bibr" target="#b64">[65]</ref> to compare multiple clustering methods on each dataset or across all datasets. In the case where the latter test reveals significant differences between the results, a post hoc Nemenyi test <ref type="bibr" target="#b65">[66]</ref> is performed to establish a hierarchy between the approaches. In all tests, we assume the significance level α = 0.05. From these tests, we expect to assess evidences concerning the plausibility of the following hypotheses:</p><p>1. Question: Considering each evaluation metric individually, are the performances observed on each model equal?</p><p>• Null Hypothesis (H0) -Models achieve similar performances.</p><p>• Alternative Hypothesis (HA) -Some models perform better considering the evaluation metrics.</p><p>2. Question: Considering all evaluation metrics, are there models they do globally perform better?</p><p>• Null Hypothesis (H0) -Proposed models achieve similar performances considering all the evaluation metrics. • Alternative Hypothesis (HA) -Some models provide global better performances.</p><p>Both hypotheses are claimed on each dataset and also across all the datasets. Outcomes of these hypotheses allow to observe whether the combination of certain methods and view configurations perform better depending on the language and the tested evaluation metrics, or not.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Results</head><p>This section investigates the ability of the MVSC-CEV algorithm to generate high-quality clustering solutions on both the FR hate speech target community corpus and the EN hate speech target community corpus by varying the combination of the data views introduced in Section 4.2. Experiments were conducted on an Intel i7-4600U CPU @ 2.10 GHz with 32GB of RAM, using single-threaded processes. Table <ref type="table" target="#tab_3">4</ref> summarises the results achieved by the two baseline clustering techniques and the top-3 models relying on MVSC-CEV. In total 69 experiments were conducted, all the results are reported in Appendix A Table <ref type="table" target="#tab_5">A1</ref>.</p><p>English/French corpus performance -Concerning the English corpus, most of the configurations relying on the MVSC-CEV algorithm outperforms the baseline clustering techniques, except the {mBERT/mUSE/mUSE-PRO} configuration w.r.t. the ARI score. Concerning each evaluation metric, the post hoc Nemenyi test, allowing to evaluate the consistency of the ranking of each model throughout all the iterations, ranks the {mUSE/mBERT-PRO/mUSE-PRO/mUSE-NET} and {mBERT-PRO/mUSE-PRO/mBERT-NET} configurations respectively at the first and the second position. Considering all the metrics, the post hoc Nemenyi test establishes that {mUSE/mBERT-PRO/mUSE-PRO/mUSE-NET} outperforms other models followed by {mBERT-PRO/mUSE-PRO/mBERT-NET} and {mBERT-PRO/mUSE-PRO/mBERT-NET/mUSE-NET}. In French, the majority of the data view configurations combined to the MVSC-CEV algorithm achieves good performances as well as the baseline clustering techniques relying on the feature set and the projection affinity matrix derived from mUSE. The post hoc Nemenyi test allows to establish that {mUSE/mBERT-PRO/mUSE-PRO/mBERT-NET} outperforms the other models w.r.t. the purity score, {mBERT-PRO/mUSE-PRO} regarding the ARI score and {SC view mUSE} w.r.t. the NMI score. Considering all the metrics, the post hoc Nemenyi test establishes that {mUSE/mBERT-PRO/mUSE-PRO} outperforms the other models followed by {mBERT-PRO/mUSE-PRO} and {mUSE/mBERT-PRO/mUSE-PRO/mBERT-NET/mUSE-NET}.</p><p>Overall evaluation -Table <ref type="table" target="#tab_4">5</ref> shows the top-5 models obtained from the post hoc Nemenyi test performed on each evaluation metric considering both corpora. The latter test allows to reject the null hypothesis formulated in Question 1 (cf. Section 5.3). Indeed, the resulting hierarchy confirms that some models achieve better performances regarding the tested evaluation metrics. In detail, {mUSE/mBERT-PRO/mUSE-PRO/mUSE-NET} outperforms the other methods on both the purity score and the NMI score. This finding highlights   the ability of this configuration to generate homogeneous clusters (i.e. each cluster gathers tweets belonging for the most part to the same ground-truth community) and to maximise mutual information (i.e. uncertainties of dependencies between clusters and labels is decreased). Concerning the ARI score, {mBERT-PRO/mUSE-PRO} achieves the best performances providing the most similar partitioning in comparison to the ground-truth communities considering the frequency of occurrence of agreements over the total pairs. In short, most of the top-ranked models rely on the MVSC-CEV algorithm except the fourth-ranked model of the ARI score and both the third and the fifth-ranked models of the NMI. Figure <ref type="figure" target="#fig_4">5</ref> allows to visualise the hierarchy among the models according to post hoc Nemenyi test performed on each evaluation metric considering both corpora. From the latter test we can reject the null hypothesis formulated in Question 2 (cf. Section 5.3). Indeed, {mUSE/mBERT-PRO/mUSE-PRO/mUSE-NET} outperforms all the other models reaching the best balance considering all the evaluation metrics on both languages. {mUSE/mBERT-PRO/mUSE-PRO} and {mBERT-PRO/mUSE-PRO} are respectively ranked at the second and the third position. From these findings, we can confirm that using data views of a different nature is beneficial in this context to improve the clustering performance considering all the tested aspects. Additionally, we can also observe that encapsulating the complementary information of different language representations unveil relevant data properties improving partitioning. Moreover, the consistency of the occurrence of affinity matrices in top-ranked models, especially the ones derived from the network projection, allows to establish that these affinity matrices exhibit relevant properties describing accurately data connections. Furthermore, the majority of the configurations relying on data views based on mUSE achieves better performances considering both the baseline clustering methods and the MVSC-CEV algorithm.</p><p>To sum up, the majority of the models relying on the MVSC-CEV algorithm achieves the best results on both languages and tested evaluation metrics. We can observe a consistency of the performances on each metric highlighting the portability of the proposed pipeline across other languages. In addition, the purity and the NMI score achieve the highest results witnessing the ability of this pipeline to also generate homogeneous clusters and to decrease the uncertainty among clusters. Considering results reported in Appendix A, we can notice that affinity matrices (relationship information) derived from the network projection appear to be a rich source of information as they are a part of most of the top-ranked models. In addition, despite the fact that {mUSE/mBERT-PRO/mUSE-PRO/mUSE-NET} provides the best balance considering both languages and metrics, performances vary throughout the configurations. For instance, to get the best ARI {mBERT-PRO/mUSE-PRO} has to be preferred in French and {mUSE/mBERT-PRO/mUSE-PRO/mUSE-NET} in English.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Hate speech target community Characterisation</head><p>In this section, we explore the partitioning resulting from the proposed pipeline.</p><p>Our goal here is not to perform an error analysis as in standard supervised approaches, but more to identify whether the properties emerging from the generated clusters correspond to the facets used in the MLMA multi-aspect hate speech analysis, i.e., our gold-standard corpus.</p><p>For each language, we explore the partitioning resulting from the best balance model identified in Section 6, namely {mUSE/mBERT-PRO/mUSE-PRO/mUSE-NET}. The methodology consists of observing the ground-truth communities' behaviours within the generated clusters in terms of scatteredness and equivocality. To disambiguate, in this study scatteredness refers to the level of dispersion of the communities and equivocality attempts to qualify the ability of each community to federate their own cluster(s). From these two aspects, we investigate the ability of victim-group and target-type to provide salient properties allowing to generate fully-fledged communities corresponding to the MLMA labels. To establish these two aspects, we consider the most frequent ground-truth hate speech target community label within each cluster as the cluster-head. Next, the content of each cluster is analysed using n-gram co-occurrence statistics.</p><p>Figure <ref type="figure" target="#fig_5">6</ref> describes the behaviours of the communities observed in the partitioning obtained from the EN hate speech target community corpus. Considering the equivocality, 7 ground-truth communities federate their own cluster(s). Among them 4 are the heads of one cluster including other other, sexual orientation other, origin refugees and sexual orientation individual while the others are the heads of multiple clusters. origin other reaches the highest number of clusters by being the head of 10 different clusters representing 38.4% of the total number of clusters. The second and the third communities obtaining the highest degree of equivocality are disability special needs and gender women representing respectively 30.7% and 15.3% of clusters' heads. Considering the scatteredness, we can observe that some communities being cluster-heads are also assimilated to other clusters. For instance, other other and origin refugees are above 70% of scatteredness. Entries composing both of these two clusters occur frequently in clusters having origin other and disability special needs as head. From the mixing of these ground-truth communities, new communities emerge characterising how the hate is expressed towards a victim-group or the different ways of linguistically discriminate a target-type or both. For instance, clusters mixing entries from the ground-truth communities origin refugees and origin other gather tweets using terms such as 'go back country' or 'shithole countries'. These segments are frequently associated with the victim-group refugees but their usage is also extended to discriminate and insult more globally people based on their origin. From the generated communities mixing other other and origin other salient patterns emerge combining vocabularies used to offend people based on their origin or political views such as 'radical leftist', 'leftist terrorist' or 'conspiracy terrorist'. In parallel, 19 groundtruth communities are fully assimilated into the generated clusters regarding various degrees of scatteredness. Among them, origin women reaches 100% of scatteredness showing that tweets composing this ground-truth community are also scattered throughout all the clusters. Entries from this ground-truth community occur frequently within clusters being federated by the community gender women. Studying these combinations highlighted salient properties (identified as a part of two different clusters) characterising hate speech expresses towards women such as 'fucking cunt' and 'little cunt' in the first cluster and 'absolute twat' and 'fucking twat' in the second one. other special needs, origin special needs and origin individual are highly dispersed with a degree of scatteredness above 70%. Considering both of these aspects, we can observe that the cluster-head sexual orientation individual is the less equivocal and scattered ground-truth community. Indeed, this community assimilates only entries belonging to its community or from gender women and disability special needs. Combined to gender women the cluster having sexual orientation individual as head highlights properties related to the women group and hate speeches based on the vocabulary used to discriminate or insult people based on their sexual orientation including 'faggot bitch' and 'suck dick'. origin african descent and origin asians are the ground-truth communities obtaining the lowest degrees of scatteredness with respectively 23.0% and 26.9%. Both of them occur only in the clusters having origin other and disability special needs as head. From the generated clusters assimilating the ground-truth community origin asians, different offensive speeches emerge based on slurs such as 'screeches high' and 'ching chang' when combined to origin other and 'proceeds squint' and 'ching chong' when mixed to disability special needs' entries. Figure <ref type="figure" target="#fig_6">7</ref> allows to better visualise the mixing of communities' semantic spaces within the generated clusters. As previously reported, we can observe that both vocabularies related to the target disability and the group specNeeds are used in offensive comments targeting women. Other prominent mixing can be noticed including the community disability special needs whose the vocabulary is based on common slurs and demeaning expressions widely used to discriminate and insult the other communities. Nodes refer to ground-truth communities and edges link towards communities occurring in the given cluster-head.</p><p>Figure <ref type="figure" target="#fig_7">8</ref> describes the behaviours of the communities observed in the partitioning obtained from the FR hate speech target community corpus. Considering the equivocality, 9 ground-truth communities federate their own cluster(s). Among them 5 are the head of one cluster including origin immigrants, origin arabs, origin african descent, religion muslims and religion jews while the others are the head of multiple clusters. other individual reaches the highest number of clusters being the head of 4 different clusters representing 25.0% of the total number of clusters. The second community obtaining the highest degree of equivocality is other other representing respectively 18.7% of cluster-heads. Considering the scatteredness, we can observe that some communities being cluster-heads are also assimilated to other clusters. For instance, origin african descent and origin other are above 70% of scatteredness. Entries composing both of these two clusters occur frequently in clusters having other individual and other other as head. 'les renois' (EN: niggers) and 'attardé mentaux' (EN: retarded) are the most frequent patterns extracted from the cluster mixing origin african descent and other individual while 'cet attardé' (EN: this retarded) and '@user mongol' (EN: @user mogolian) are the most redundant ones in the generated cluster combining other other and other individual. These findings highlight that both ground-truth communities use frequently a vocabulary based on common slurs and demeaning expressions use to target individuals belonging to the other individual community. In parallel, 7 ground-truth communities are fully assimilated into the generated clusters regarding various degrees of scatteredness. Among them, origin individual, origin left wing people and origin indian/hindu reach 100% of scatteredness showing that tweets composing these ground-truth communities are also scattered throughout all the clusters. origin asians and origin special needs are also highly dispersed with a degree of scatteredness above 80%. Considering both of these aspects, we can observe that the cluster-head religion muslims and religion jews are the less equivocal and scattered ground-truth community. Indeed, these communities assimilate only entries belonging to their communities or from origin arabs for religion muslims and from religion muslims for religion jews. From these clusters, we can observe common slurs specific to each religion. For instance, 'danger de l'islam' (EN: danger of Islam) and 'source du terrorisme' (EN: source of terrorism) for the cluster corresponding to the ground-truth community religion muslims and 'sale juif' (EN: kike) and 'antisémitisme et complotiste' (EN: antisemitism and conspiracy) for the cluster corresponding to the ground-truth community religion jews. From the visualisation of the mixing of the communities' semantic spaces presented in Figure <ref type="figure" target="#fig_8">9</ref>, we can observe that both vocabularies related to the communities origin immigrants and other left wing people are used to convey hate against people based on their origin. Other prominent mixing can be noticed including the community other individual targeting individuals using vocabularies and slurs related to the target disability and the group special needs. Whilst data are highly imbalanced, explaining the assimilation of some ground-truth communities in favor of the multiplication of others, applying the proposed pipeline has unveiled new insights improving the understanding on how hate is conveyed. From this study, we can confirm the relevance of the MLMA facets to unveil sub-semantic spaces reflecting the nature of offensive comments expressed towards the defined attributes. However, from the observed behaviours of the ground-truth communities within the generated clusters we notice difficulties to discriminate among victim-groups and target-types. Indeed vocabularies related to victim-groups, target-types or both can hold specific properties allowing to discriminate between each other or conversely they can share common properties leading to increase the bias. Communities resulting from the partitioning rely on two kinds of phenomenons: clusters assimilating ground-truth communities relying on vocabularies mostly composed of common slurs and demeaning expressions or clusters mixing facets based on complementary vocabularies. For instance, the target-type disability and the victim-group specNeeds composed of offensive messages targeting people with special needs constitute a fully-fledged sub-semantic space specific to these attributes. However, this vocabulary is mostly composed of slurs and demeaning expressions used to discriminate or insult victim-groups, target-types or both such as the target-type origin in both languages and more particularly the victim-group arabs in French (e.g.: '@user c'est pas à toi que je parle gros mongol. t'as pris le melon sale arabe', (EN: '@user I am not talking to you retard. you are big-headed raghead')) and the community gender women in English (e.g.: 'smh women really retarded @url'). Concerning the complementarity between sub-semantic spaces, we have observed bridges built between some spaces leading to a precise characterisation of the type of hate speech expressed frequently towards victim-groups, target-types or both. For instance, clusters have emerged in English combining vocabularies from the community sexual orientation special needs and gender women (e.g.: 'keep your mouth shut you retard bitch' ) or other left wing people and religion muslims in French (e.g.: '@user ferme ta gueule islamo gauchiste', (EN: 'shut the fuck up you libtard')). In addition, we have also observed that communities based on victimgroups, target-types or both referring to other (i.e., the facets gathering tweets which do not correspond to the specific target-types / victim-groups defined by MLMA) federate multiple clusters in both languages. This finding allows to establish that from these facets either new ones emerged allowing to capture other target-types / victim-groups or a finer-grained target community taxonomy exists based on subdivisions of the given ground-truth communities.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Conclusion</head><p>In this paper, we have presented a complete pipeline addressing the task of finegrained hate speech target community detection adopting a clustering approach. Leveraging the last advances in clustering, the proposed pipeline is based on the MVSC-CEV algorithm which performs a simultaneous clustering of multiple data views resulting in a consensus partition of the data. We have explored the use of different language modelling resources to derive different types of data views exhibiting different properties (i.e., syntactic/semantic and relationship information). In total 69 experiments were conducted, both on the FR hate speech target community corpus and on the EN hate speech target community corpus, evaluated against state-of-the-art clustering techniques. As a result, we showed that the majority of the models relying on the MVSC-CEV algorithm achieves the best results on both languages and on the tested evaluation metrics. More particularly, the {mUSE/mBERT-PRO/mUSE-PRO/mUSE-NET} model outperforms all the other models reaching the best balance considering all the evaluation metrics on both languages. Besides that, through the use of clustering techniques we enabled the study of mesoscopic structures of the data to unveil insights on how the hate is conveyed against target communities through the textual messages. Our results on the MLMA ground-truth communities showed the ability of the proposed pipeline to generate clusters corresponding to subsemantic spaces reflecting the nature of offensive comments related to the defined facets. Although the generated clusters do not correspond exactly to the MLMA communities, they unveil new information allowing to investigate hate speech properties related to specific victim-groups, target-types or both. To conclude, this study has proven the possibility to transpose the task of fine-grained hate speech detection into a clustering problem by its ability to address current challenges in the field, i.e., capturing complex hate speech phenomena using unsupervised methods which are more appropriate to deal with social data. An API allowing to test the different view configurations on both languages is available online 7 .</p><p>The findings resulting from the conducted study open also multiple research directions: first, developing improved clustering-oriented solutions to address this task and, (2) leveraging communities to derive auxiliary features aiming at supporting downstream tasks (e.g., classification and misogyny detection). More generally, we hope our efforts based on unsupervised learning clustering techniques will pave the road to achieving an unsupervised pipeline estimating optimal cluster number. Expectations from automating this step include to establish whether the MLMA multi-aspect analysis reflects all the facets allowing to describe accurately hate speech phenomena on social media. In future work, we intend to evaluate the proposed pipeline on the task of fine-grained hate speech detection by including non-hostile tweets in order to establish its ability to deal with real-world data.  </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 :</head><label>1</label><figDesc>Fig. 1: Distribution of the target-type facet in both French and English corpora.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>smh women r retarder @url quel mongol ! jsuis sur c un rebeu Target type: disability Victim group: women Target type: origin Victim group: specNeeds Translation: what a retard ! I'm sure it'</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 2 :</head><label>2</label><figDesc>Fig. 2: Multi-view clustering workflow from Twitter data.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 3 :</head><label>3</label><figDesc>Fig.3: Sentence similarity scores using embeddings from mBERT (left) and mUSE (right).</figDesc><graphic coords="14,48.90,-21.53,339.44,339.44" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 5 :</head><label>5</label><figDesc>Fig. 5: Models' average ranking resulting from the post hoc Nemenyi test performed on each evaluation metric considering both corpora.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 6 :</head><label>6</label><figDesc>Fig. 6: Scatteredness and equivocality of the ground-truth communities in the EN hate speech target community corpus.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 7 :</head><label>7</label><figDesc>Fig.7: Visualisation of the mixing of the communities within the generated clusters for the EN hate speech target community corpus. The bigger the nodes, the bigger the communities occur as a cluster-head in the generated partition. Nodes refer to ground-truth communities and edges link towards communities occurring in the given cluster-head.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 8 :</head><label>8</label><figDesc>Fig. 8: Dispersion and equivocality of the communities in the FR hate speech target community corpus.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 9 :</head><label>9</label><figDesc>Fig.9: Visualisation of the mixing of the communities within the generated clusters for the FR hate speech target community corpus. The bigger the nodes, the bigger the communities occur as a cluster-head in the generated partition. Nodes refer to ground-truth communities and edges link towards communities occurring in the given cluster-head.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. A1 :</head><label>A1</label><figDesc>Fig.A1: The different hierarchies obtained from models' average ranking for each evaluation metric using the post hoc Nemenyi test</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Distribution of hate speech target communities in the French and English corpora.</figDesc><table><row><cell></cell><cell cols="2">FR</cell><cell cols="2">EN</cell></row><row><cell>Target</cell><cell>Group</cell><cell>no. of Tweets</cell><cell>Group</cell><cell>no. of Tweets</cell></row><row><cell></cell><cell>other</cell><cell>619</cell><cell>other</cell><cell>814</cell></row><row><cell>origin</cell><cell>indian/hindu</cell><cell>324</cell><cell>specNeeds</cell><cell>378</cell></row><row><cell></cell><cell>africanDesc</cell><cell>298</cell><cell>individual</cell><cell>301</cell></row><row><cell></cell><cell>arabs</cell><cell>289</cell><cell>women</cell><cell>162</cell></row><row><cell></cell><cell>individual</cell><cell>276</cell><cell>refugees</cell><cell>128</cell></row><row><cell></cell><cell>leftWing</cell><cell>103</cell><cell>immigrants</cell><cell>123</cell></row><row><cell></cell><cell>asians</cell><cell>87</cell><cell>leftWing</cell><cell>101</cell></row><row><cell></cell><cell>immigrants</cell><cell>84</cell><cell>hispanics</cell><cell>96</cell></row><row><cell></cell><cell>specNeeds</cell><cell>61</cell><cell>africanDesc</cell><cell>81</cell></row><row><cell></cell><cell>-</cell><cell>-</cell><cell>muslims</cell><cell>75</cell></row><row><cell></cell><cell>-</cell><cell>-</cell><cell>indian/hindu</cell><cell>67</cell></row><row><cell></cell><cell>-</cell><cell>-</cell><cell>asians</cell><cell>61</cell></row><row><cell>other</cell><cell>individual other</cell><cell>556 442</cell><cell>other women</cell><cell>507 145</cell></row><row><cell></cell><cell>leftWing</cell><cell>280</cell><cell>specNeeds</cell><cell>120</cell></row><row><cell></cell><cell>immigrants</cell><cell>20</cell><cell>individual</cell><cell>55</cell></row><row><cell>religion</cell><cell>muslims jews</cell><cell>71 56</cell><cell>--</cell><cell>--</cell></row><row><cell></cell><cell>-</cell><cell>-</cell><cell>other</cell><cell>133</cell></row><row><cell>sexOrient</cell><cell>-</cell><cell>-</cell><cell>gay</cell><cell>111</cell></row><row><cell></cell><cell>-</cell><cell>-</cell><cell>individual</cell><cell>98</cell></row><row><cell></cell><cell>-</cell><cell>-</cell><cell>specNeeds</cell><cell>67</cell></row><row><cell>disability</cell><cell>specNeeds individual</cell><cell>83 80</cell><cell>specNeeds other</cell><cell>944 58</cell></row><row><cell></cell><cell>-</cell><cell>-</cell><cell>women</cell><cell>55</cell></row><row><cell>gender</cell><cell>women -</cell><cell>22 -</cell><cell>women other</cell><cell>474 55</cell></row><row><cell></cell><cell>-</cell><cell>-</cell><cell>specNeeds</cell><cell>50</cell></row><row><cell>Total</cell><cell>-</cell><cell>3.701</cell><cell>-</cell><cell>5.209</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Annotation examples in the MLMA dataset.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 :</head><label>3</label><figDesc>Description of the Pre-trained language models.</figDesc><table><row><cell>Name</cell><cell>Architecture</cell><cell>Training data</cell></row><row><cell>mBERT [13]</cell><cell>12-layer, 768-hidden, 12-heads</cell><cell>Trained on uncased texts in the top 102</cell></row><row><cell></cell><cell></cell><cell>languages with the largest Wikipedias.</cell></row><row><cell>mUSE [14]</cell><cell>6-layer, 512-hidden, 8-heads</cell><cell>Originally trained on mined question-</cell></row><row><cell></cell><cell></cell><cell>answer pairs, SNLI data, translated</cell></row><row><cell></cell><cell></cell><cell>SNLI data and parallel corpora over</cell></row><row><cell></cell><cell></cell><cell>16 languages. Here, we use the V2</cell></row><row><cell></cell><cell></cell><cell>extended to 50+ languages.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 :</head><label>4</label><figDesc>Detailed results w.r.t. purity, ARI and NMI. The mean and standard deviation from 31 independent runs are reported for each language. According to the post hoc Nemenyi test the best values reported for each metric are in bold while the highlighted rows refer to the best models considering all the metrics for each language.</figDesc><table><row><cell>FR</cell></row><row><cell>EN</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 5 :</head><label>5</label><figDesc>Top-5 models w.r.t. the post hoc Nemenyi test performed on each evaluation metric considering both corpora. FigureA1in Appendix A details the whole hierarchies obtained for each metric.</figDesc><table><row><cell>Rank</cell><cell></cell><cell>Evaluation Metrics</cell><cell></cell></row><row><cell></cell><cell>Purity</cell><cell>ARI</cell><cell>NMI</cell></row><row><cell>1</cell><cell cols="2">{mUSE/mBERT-PRO/mUSE-PRO/mUSE-NET} {mBERT-PRO/mUSE-PRO}</cell><cell>{mUSE/mBERT-PRO/mUSE-PRO/mUSE-NET}</cell></row><row><cell>2</cell><cell>{mBERT-PRO/mUSE-PRO}</cell><cell>{mUSE/mBERT-PRO/mUSE-PRO}</cell><cell>{mUSE/mBERT-PRO/mUSE-PRO}</cell></row><row><cell>3</cell><cell>{mUSE/mBERT-PRO/mUSE-PRO}</cell><cell cols="2">{mUSE/mBERT-PRO/mUSE-PRO/mUSE-NET} {SC view mUSE}</cell></row><row><cell>4</cell><cell>{mUSE/mBERT-PRO}</cell><cell>{SC view mUSE-PRO}</cell><cell>{mBERT-PRO/mUSE-PRO}</cell></row><row><cell>5</cell><cell>{mBERT-PRO/mUSE-PRO/mBERT-NET}</cell><cell>{mUSE/mBERT-PRO}</cell><cell>{KM view mUSE}</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table A1 :</head><label>A1</label><figDesc>Detailed results w.r.t. Purity, ARI and NMI. The mean and standard deviation from 31 independent runs are reported for each language. According to the post hoc Nemenyi test the best values reported for each metric are in bold while the highlighted rows refer to the best models considering all the metrics for each language. PRO/mUSE-PRO} {mUSE/mBERT-PRO/mUSE-PRO/mUSE-NET} {SC view mUSE-PRO} {mUSE/mBERT-PRO} {mUSE/mBERT-PRO/mUSE-PRO/mBERT-NET/mUSE-NET} {mBERT-PRO/mUSE-PRO/mBERT-NET} {mBERT-PRO/mUSE-PRO/mBERT-NET/mUSE-NET}</figDesc><table><row><cell cols="26">Unsupervised Fine-grained Hate Speech Target Community Detection</cell></row><row><cell></cell><cell></cell><cell>0.084±0.003 0.208±0.002</cell><cell>NMI 0.046±0.002 0.136±0.005</cell><cell>0.109±0.003 0.227±0.002</cell><cell>0.121±0.003 0.089±0.002 0.095±0.002 0.113±0.009 0.096±0.005 0.026±0.007 0.100±0.005 0.229±0.003 0.090±0.002 0.197±0.013 0.088±0.001 0.032±0.009 0.092±0.001 0.213±0.002 0.226±0.003 0.220±0.002 0.218±0.000 0.216±0.001 0.216±0.003 0.220±0.004</cell><cell>0.050±0.001 0.147±0.003</cell><cell>0.178±0.000 0.088±0.001 0.211±0.002</cell><cell>0.182±0.001 0.099±0.004 0.225±0.001</cell><cell>0.118±0.000 0.085±0.001 0.198±0.003</cell><cell>0.086±0.001 0.237±0.000 0.207±0.003</cell><cell>0.231±0.003 0.087±0.001 0.212±0.001</cell><cell>0.166±0.000 0.090±0.002 0.214±0.004</cell><cell>0.081±0.001 0.196±0.002</cell><cell>0.081±0.001 0.194±0.001</cell><cell>0.082±0.001 0.204±0.003</cell><cell>NMI 0.053±0.001 0.081±0.002 0.217±0.001 0.095±0.005 0.155±0.002 0.099±0.005 0.217±0.000 0.086±0.002 0.119±0.003 0.093±0.001 0.151±0.003 0.088±0.001 0.227±0.002 0.093±0.003 0.218±0.001 0.094±0.001 0.210±0.002 0.078±0.002 0.219±0.002 0.089±0.002 0.227±0.002 0.081±0.001 0.138±0.001 0.093±0.003 0.157±0.002 0.090±0.001 0.207±0.001 0.146±0.003 0.202±0.003 0.221±0.002 0.231±0.001 0.206±0.002 0.217±0.002 0.208±0.002 0.218±0.002 0.225±0.001 0.194±0.001 0.213±0.001 0.197±0.002 0.221±0.002 0.218±0.002</cell><cell>0.215±0.001</cell><cell>0.141±0.003</cell><cell>0.205±0.002</cell><cell>0.222±0.002</cell><cell>0.198±0.001</cell><cell>0.214±0.002</cell><cell>0.218±0.002</cell><cell>0.134±0.004</cell><cell>0.164±0.002</cell><cell>0.199±0.002</cell></row><row><cell>EN FR {mUSE/mBERT-PRO/mUSE-PRO/mUSE-NET} {mBERT-PRO/mUSE-PRO} {mUSE/mBERT-PRO/mUSE-PRO} {mUSE/mBERT-PRO} {mBERT-PRO/mUSE-PRO/mBERT-NET} {mBERT/mUSE/mUSE-PRO} {mUSE/mBERT-PRO/mUSE-PRO/mBERT-NET/mUSE-NET} {mBERT-PRO/mUSE-PRO/mBERT-NET/mUSE-NET} {KM view mUSE} {SC view mUSE-PRO} {mBERT-PRO/mUSE-PRO} {mUSE/mBERT-{KM view mUSE} {mBERT/mUSE/mUSE-PRO} {mUSE/mBERT-PRO/mUSE-PRO/mUSE-NET} {mUSE/mBERT-PRO/mUSE-PRO} {SC view mUSE} {mBERT-PRO/mUSE-PRO} {KM view mUSE} {mUSE/mBERT-PRO} {mUSE/mBERT-PRO/mUSE-PRO/mBERT-NET/mUSE-NET} {mBERT-PRO/mUSE-PRO/mBERT-NET} {mBERT-PRO/mUSE-PRO/mBERT-NET/mUSE-NET} {SC view mUSE-PRO}</cell><cell>Single-view configs. K-Means &amp; Spectral clustering 1 1 1</cell><cell>0.340±0.004 0.246±0.002 0.092±0.005 0.363±0.004 2 {mBERT/mUSE-PRO/mUSE-NET}</cell><cell>Purity ARI NMI Purity ARI 0.271±0.004 2 0.099±0.001 2 0.011±0.000 0.238±0.001 {mBERT/mBERT-NET/mUSE-NET}</cell><cell cols="2">{KM view mBERT} 0.286±0.006 0.053±0.005 0.128±0.008 0.258±0.003 0.039±0.003 0.351±0.004 0.357±0.003 {KM view mBERT-PRO} 0.299±0.007 0.045±0.007 0.139±0.008 0.254±0.010 0.040±0.007 0.359±0.003 {KM view mBERT-NET} 0.191±0.004 0.002±0.004 0.045±0.011 0.177±0.005 0.000±0.000 0.355±0.001 {KM view mUSE} 0.372±0.007 0.096±0.006 0.259±0.004 0.348±0.004 0.093±0.007 0.340±0.003 {KM view mUSE-PRO} 0.336±0.012 0.088±0.010 0.218±0.011 0.324±0.014 0.091±0.011 0.343±0.005 {KM view mUSE-NET} 0.187±0.003 0.001±0.002 0.033±0.009 0.183±0.007 0.000±0.001 0.351±0.005 CD 0.364±0.003 3 4 5 6 0.268±0.003 0.263±0.003 0.267±0.003 0.250±0.002 0.249±0.003 0.247±0.004 0.273±0.003 0.268±0.003 3 4 5 6 CD 0.101±0.004 0.099±0.004 0.101±0.005 0.088±0.003 0.088±0.006 0.088±0.004 0.108±0.005 0.103±0.004 CD 0.384±0.003 0.378±0.004 0.380±0.004 0.362±0.004 0.360±0.004 0.362±0.004 0.391±0.004 0.380±0.005 3 4 5 6 {mUSE/mBERT-PRO/mUSE-PRO} {mUSE/mBERT-PRO/mBERT-NET} {mUSE/mBERT-PRO/mUSE-NET} {mUSE/mUSE-PRO/mBERT-NET} {mUSE/mUSE-PRO/mUSE-NET} {mUSE/mBERT-NET/mUSE-NET} {mBERT-PRO/mUSE-PRO/mBERT-NET} {mBERT-PRO/mUSE-PRO/mUSE-NET}</cell><cell>0.285±0.004 0.243±0.003 0.087±0.003 0.361±0.003 {mBERT-PRO/mBERT-NET/mUSE-NET}</cell><cell cols="2">{SC view mBERT} 0.352±0.003 0.106±0.009 0.234±0.004 0.306±0.000 0.071±0.000 0.344±0.005 7 {SC view mBERT-PRO} 0.347±0.000 0.094±0.000 0.238±0.000 0.300±0.001 0.065±0.001 0.361±0.001 0.192±0.003 0.262±0.002 7 0.073±0.003 0.096±0.004 0.331±0.005 0.372±0.002 7 {mUSE-PRO/mBERT-NET/mUSE-NET} {mBERT/mUSE/mBERT-PRO/mUSE-PRO}</cell><cell>{SC view mBERT-NET} 0.251±0.000 0.013±0.000 0.151±0.000 0.237±0.000 0.011±0.000 0.341±0.003 0.255±0.003 0.094±0.004 0.369±0.004 8 {mBERT/mUSE/mBERT-PRO/mBERT-NET}</cell><cell cols="7">{SC view mUSE} 0.344±0.000 0.090±0.001 0.242±0.000 0.339±0.000 0.101±0.000 0.343±0.005 8 0.253±0.002 (a) purity {SC view mUSE-PRO} 0.345±0.000 0.101±0.000 0.234±0.000 0.342±0.002 0.103±0.001 {SC view mUSE-NET} 0.232±0.000 0.004±0.000 0.131±0.000 0.291±0.000 0.031±0.000 Multi-view configs. MVSC 0.345±0.004 0.348±0.004 0.328±0.002 0.335±0.002 0.337±0.003 9 10 0.246±0.002 0.252±0.001 0.244±0.002 0.248±0.002 0.257±0.003 8 9 10 0.097±0.005 0.090±0.003 0.091±0.004 0.094±0.005 0.089±0.003 0.097±0.004 (b) ARI 0.362±0.004 0.360±0.002 0.366±0.003 0.363±0.003 0.363±0.004 0.368±0.006 9 10 11 0.288±0.004 Purity ARI NMI Purity ARI 0.330±0.004 {mBERT/mUSE} 0.348±0.004 0.080±0.003 0.238±0.002 0.347±0.002 0.094±0.001 0.348±0.003 {mBERT/mBERT-PRO} 0.320±0.004 0.065±0.003 0.181±0.003 0.302±0.003 0.069±0.001 0.367±0.001 {mBERT/mUSE-PRO} 0.357±0.003 0.084±0.002 0.245±0.003 0.353±0.001 0.093±0.002 0.333±0.005 {mBERT/mBERT-NET} 0.226±0.002 0.012±0.000 0.087±0.001 0.260±0.003 0.037±0.001 0.349±0.004 {mBERT/mUSE-NET} 0.233±0.003 0.009±0.003 0.077±0.001 0.290±0.004 0.056±0.002 0.343±0.003 {mUSE/mBERT-PRO} 0.382±0.003 0.098±0.003 0.263±0.003 0.360±0.002 0.107±0.004 0.355±0.002 {mUSE/mUSE-PRO} 0.361±0.003 0.087±0.003 0.243±0.003 0.358±0.001 0.103±0.005 0.355±0.003 {mUSE/mBERT-NET} 0.361±0.004 0.090±0.003 0.250±0.003 0.341±0.001 0.086±0.002 0.329±0.002 {mUSE/mUSE-NET} 0.359±0.003 0.088±0.005 0.246±0.003 0.344±0.003 0.092±0.003 0.343±0.002 {mBERT-PRO/mUSE-PRO} 0.385±0.002 0.101±0.003 0.267±0.002 0.362±0.002 0.110±0.001 0.332±0.003 {mBERT-PRO/mBERT-NET} 0.335±0.006 0.078±0.004 0.199±0.004 0.281±0.002 0.048±0.001 0.350±0.003 {mBERT-PRO/mUSE-NET} 0.345±0.006 0.080±0.006 0.206±0.005 0.300±0.002 0.058±0.002 11 12 13 14 15 16 17 {mUSE-PRO/mBERT-NET} 0.362±0.003 0.092±0.004 0.253±0.003 0.339±0.002 0.084±0.001 0.348±0.004 0.176±0.003 0.248±0.002 0.265±0.003 0.276±0.001 0.266±0.004 0.251±0.004 0.270±0.004 0.260±0.002 0.262±0.002 0.257±0.002 0.249±0.002 0.254±0.002 0.271±0.002 11 12 13 14 15 16 17 0.261±0.005 0.069±0.005 0.094±0.004 0.099±0.005 0.108±0.005 0.100±0.005 0.089±0.005 0.106±0.006 0.094±0.004 0.098±0.005 0.097±0.004 0.090±0.003 0.097±0.004 0.105±0.005 0.098±0.004 0.324±0.004 0.366±0.003 0.379±0.002 0.390±0.002 0.379±0.005 0.362±0.005 0.383±0.004 0.374±0.003 0.374±0.003 0.369±0.005 0.364±0.003 0.366±0.003 0.380±0.003 12 13 14 15 16 17 0.371±0.005 {mBERT/mUSE/mBERT-PRO/mUSE-NET} {mBERT/mUSE/mUSE-PRO/mBERT-NET} {mBERT/mUSE/mUSE-PRO/mUSE-NET} {mBERT/mUSE/mBERT-NET/mUSE-NET} {mBERT/mBERT-PRO/mUSE-PRO/mBERT-NET} {mBERT/mBERT-PRO/mUSE-PRO/mUSE-NET} {mBERT/mBERT-PRO/mBERT-NET/mUSE-NET} {mBERT/mUSE-PRO/mBERT-NET/mUSE-NET} {mUSE/mBERT-PRO/mUSE-PRO/mBERT-NET} {mUSE/mBERT-PRO/mUSE-PRO/mUSE-NET} {mUSE/mBERT-PRO/mBERT-NET/mUSE-NET} {mUSE/mUSE-PRO/mBERT-NET/mUSE-NET} {mBERT-PRO/mUSE-PRO/mBERT-NET/mUSE-NET} {mBERT/mUSE/mBERT-PRO/mUSE-PRO/mBERT-NET} {mBERT/mUSE/mBERT-PRO/mUSE-PRO/mUSE-NET} {mBERT/mUSE/mBERT-PRO/mBERT-NET/mUSE-NET} {mBERT/mUSE/mUSE-PRO/mBERT-NET/mUSE-NET} {mBERT/mBERT-PRO/mUSE-PRO/mBERT-NET/mUSE-NET} {mUSE/mBERT-PRO/mUSE-PRO/mBERT-NET/mUSE-NET} {mBERT/mUSE/mBERT-PRO/mUSE-PRO/mBERT-NET/mUSE-NET} (c) NMI</cell><cell>{mUSE-PRO/mUSE-NET} 0.358±0.003 0.087±0.005 0.245±0.003 0.342±0.004 0.082±0.002 18</cell><cell>{mBERT-NET/mUSE-NET} 0.251±0.003 0.016±0.001 0.137±0.002 0.259±0.002 0.016±0.001 18 18</cell><cell>{mBERT/mUSE/mBERT-PRO} 0.371±0.002 0.092±0.002 0.256±0.002 0.345±0.002 0.094±0.003 19</cell><cell>{mBERT/mUSE/mUSE-PRO} 0.360±0.002 0.085±0.004 0.247±0.002 0.362±0.001 0.104±0.004 19 19</cell><cell>{mBERT/mUSE/mBERT-NET} 0.360±0.003 0.089±0.005 0.243±0.002 0.337±0.002 0.083±0.001 20</cell><cell cols="4">{mBERT/mUSE/mUSE-NET} 0.360±0.004 0.094±0.004 0.246±0.002 0.339±0.002 0.086±0.002 20 20 {mBERT/mUSE/mUSE-PRO} {mBERT/mBERT-PRO/mUSE-NET} 0.373±0.003 0.094±0.002 0.260±0.001 0.360±0.002 0.098±0.005 {mBERT/mUSE-PRO/mBERT-NET} 0.327±0.004 0.065±0.004 0.179±0.003 0.274±0.006 0.047±0.002 {mBERT/mBERT-PRO/mUSE-NET} 0.314±0.003 0.069±0.004 0.173±0.003 0.305±0.001 0.063±0.001 {mBERT/mUSE-PRO/mBERT-NET} 0.083±0.001 {SC view mBERT} {SC view mUSE} {KM view mUSE-NET} {KM view mBERT-NET} {SC view mBERT-NET} {SC view mUSE-NET} {KM view mBERT} {KM view mBERT-PRO} {SC view mBERT-PRO} {KM view mUSE-PRO} 0.338±0.005 0.247±0.002 {SC view mBERT} {SC view mUSE} {KM view mUSE-PRO} {SC view mBERT-PRO} {KM view mBERT} {KM view mBERT-PRO} {KM view mUSE-NET} {KM view mBERT-NET} {SC view mUSE-NET} {SC view mBERT-NET} 0.091±0.004 {SC view mBERT-PRO} {KM view mUSE-PRO} {SC view mBERT} {SC view mBERT-NET} {KM view mUSE-NET} {KM view mBERT-NET} {KM view mBERT-PRO} {KM view mBERT} {SC view mUSE-NET} 0.367±0.002</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>https://hatespeechdata.com/ Date of access:</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_1"><p>2nd November 2021. 2 https://sites.google.com/view/trac2/home Date of access: 2nd November 2021. 3 http://www.evalita.it/ Date of access: 2nd November 2021. 4 https://hasocfire.github.io/hasoc/2020/index.html Date of access: 24th February 2023.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_2"><p>https://huggingface.co/mBERT-base-multilingual-uncased Date of access: 5th October 2021.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_3"><p>https://huggingface.co/sentence-transformers/distiluse-base-multilingual-cased-v2 Date of access: 5th October 2021.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_4"><p>Unsupervised Fine-grained Hate Speech Target Community Detection</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><p>Acknowledgments. This work is supported by the <rs type="funder">French government</rs>, through the <rs type="funder">3IA Côte d</rs>'<rs type="projectName">Azur Investments</rs> in the Future project managed by the <rs type="funder">National Research Agency (ANR)</rs> with the reference number <rs type="grantNumber">ANR-19-P3IA-0002</rs> and the <rs type="projectName">EFELIA Côte d'Azur</rs> project <rs type="grantNumber">ANR-22-CMAS-0004</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funded-project" xml:id="_kFyBE9S">
					<orgName type="project" subtype="full">Azur Investments</orgName>
				</org>
				<org type="funded-project" xml:id="_yKmYsa6">
					<idno type="grant-number">ANR-19-P3IA-0002</idno>
					<orgName type="project" subtype="full">EFELIA Côte d&apos;Azur</orgName>
				</org>
				<org type="funding" xml:id="_Ykgd6V2">
					<idno type="grant-number">ANR-22-CMAS-0004</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Hate speech</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">T</forename><surname>Nockleby</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Encyclopedia of the American Constitution 2nd ed</title>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="1277" to="1279" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Hate speech detection: A solved problem? the challenging case of long tail on twitter</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Luo</surname></persName>
		</author>
		<idno type="DOI">10.3233/SW-180338</idno>
		<ptr target="https://doi.org/10.3233/SW-180338" />
	</analytic>
	<monogr>
		<title level="j">Semantic Web</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="925" to="945" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Cyberhate: A review and content analysis of intervention strategies</title>
		<author>
			<persName><forename type="first">C</forename><surname>Blaya</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.avb.2018.05.006</idno>
		<ptr target="https://doi.org/10.1016/j.avb.2018.05.006.Bullyingandcyberbullying" />
	</analytic>
	<monogr>
		<title level="m">Protective factors and effective interventions</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="page" from="163" to="172" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Detecting hate speech on twitter using a convolution-gru based deep neural network</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Robinson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Tepper</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-319-93417-4_48</idno>
		<ptr target="https://doi.org/10.1007/978-3-319-93417-448" />
	</analytic>
	<monogr>
		<title level="m">The Semantic Web -15th International Conference, ESWC 2018</title>
		<title level="s">Proceedings. Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Gangemi</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Navigli</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Vidal</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><surname>Hitzler</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Troncy</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Hollink</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Tordai</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Alam</surname></persName>
		</editor>
		<meeting><address><addrLine>Heraklion, Crete, Greece</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">10843</biblScope>
			<biblScope unit="page" from="745" to="760" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">NULI at semeval-2019 task 6: Transfer learning for offensive language detection using bidirectional transformers</title>
		<author>
			<persName><forename type="first">P</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zou</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/s19-2011</idno>
		<ptr target="https://doi.org/10.18653/v1/s19-2011" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th International Workshop on Semantic Evaluation, SemEval@NAACL-HLT 2019</title>
		<editor>
			<persName><forename type="first">J</forename><surname>May</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">E</forename><surname>Shutova</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Herbelot</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">X</forename><surname>Zhu</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Apidianaki</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Mohammad</surname></persName>
		</editor>
		<meeting>the 13th International Workshop on Semantic Evaluation, SemEval@NAACL-HLT 2019<address><addrLine>Minneapolis, MN, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="87" to="91" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A multilingual evaluation for online hate speech detection</title>
		<author>
			<persName><forename type="first">M</forename><surname>Corazza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Menini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Cabrio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Tonelli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Villata</surname></persName>
		</author>
		<idno type="DOI">10.1145/3377323</idno>
		<ptr target="https://doi.org/10.1145/3377323" />
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Internet Techn</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="10" to="11022" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A survey on automatic detection of hate speech in text</title>
		<author>
			<persName><forename type="first">P</forename><surname>Fortuna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Nunes</surname></persName>
		</author>
		<idno type="DOI">10.1145/3232676</idno>
		<ptr target="https://doi.org/10.1145/3232676" />
	</analytic>
	<monogr>
		<title level="j">ACM Comput. Surv</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="85" to="18530" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Vulnerable community identification using hate speech detection on social media</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Mossie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.ipm.2019.102087</idno>
		<ptr target="https://doi.org/10.1016/j.ipm.2019.102087" />
	</analytic>
	<monogr>
		<title level="j">Inf. Process. Manag</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">102087</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Emotionally informed hate speech detection: A multi-target perspective</title>
		<author>
			<persName><forename type="first">P</forename><surname>Chiril</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">W</forename><surname>Pamungkas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Benamara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Moriceau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Patti</surname></persName>
		</author>
		<idno type="DOI">10.1007/s12559-021-09862-5</idno>
		<ptr target="https://doi.org/10.1007/s12559-021-09862-5" />
	</analytic>
	<monogr>
		<title level="j">Cogn. Comput</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="322" to="352" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Multilingual and multi-aspect hate speech analysis</title>
		<author>
			<persName><forename type="first">N</forename><surname>Ousidhoum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Yeung</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D19-1474</idno>
		<ptr target="https://doi.org/10.18653/v1/D19-1474" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing, EMNLP-IJCNLP 2019</title>
		<editor>
			<persName><forename type="first">K</forename><surname>Inui</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Jiang</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">V</forename><surname>Ng</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">X</forename><surname>Wan</surname></persName>
		</editor>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing, EMNLP-IJCNLP 2019<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="4674" to="4683" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Resources and benchmark corpora for hate speech detection: a systematic review</title>
		<author>
			<persName><forename type="first">F</forename><surname>Poletto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Basile</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sanguinetti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Bosco</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Patti</surname></persName>
		</author>
		<idno type="DOI">10.1007/s10579-020-09502-8</idno>
		<ptr target="https://doi.org/10.1007/s10579-020-09502-8" />
	</analytic>
	<monogr>
		<title level="j">Lang. Resour. Evaluation</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="477" to="523" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A hierarchicallylabeled portuguese hate speech dataset</title>
		<author>
			<persName><forename type="first">P</forename><surname>Fortuna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Da Silva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wanner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Nunes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Third Workshop on Abusive Language Online</title>
		<meeting>the Third Workshop on Abusive Language Online</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="94" to="104" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">BERT: pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M.-W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
		<ptr target="https://aclweb.org/anthology/papers/N/N19/N19-1423/" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2019</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2019<address><addrLine>Minneapolis, MN, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019">June 2-7, 2019. 2019</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="4171" to="4186" />
		</imprint>
	</monogr>
	<note>Long and Short Papers</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Multilingual universal sentence encoder for semantic retrieval</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Cer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ahmad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Law</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Constant</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">H</forename><surname>Ábrego</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Tar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Sung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Strope</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Kurzweil</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.acl-demos.12</idno>
		<ptr target="https://doi.org/10.18653/v1/2020.acl-demos.12" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics: System Demonstrations, ACL 2020</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Celikyilmaz</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename><surname>Wen</surname></persName>
		</editor>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics: System Demonstrations, ACL 2020<address><addrLine>Online</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="87" to="94" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Directions in abusive language training data, a systematic review: Garbage in, garbage out</title>
		<author>
			<persName><forename type="first">B</forename><surname>Vidgen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Derczynski</surname></persName>
		</author>
		<idno type="DOI">10.1371/journal.pone.0243300</idno>
		<ptr target="https://doi.org/10.1371/journal.pone.0243300" />
	</analytic>
	<monogr>
		<title level="j">PLOS ONE</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1" to="32" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A dataset of hindi-english code-mixed social media text for hate speech detection</title>
		<author>
			<persName><forename type="first">A</forename><surname>Bohra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Vijay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Akhtar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Shrivastava</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/w18-1105</idno>
		<ptr target="https://doi.org/10.18653/v1/w18-1105" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Second Workshop on Computational Modeling of People&apos;s Opinions, Personality, and Emotions in Social Media, PEOPLES@NAACL-HTL 2018</title>
		<editor>
			<persName><forename type="first">M</forename><surname>Nissim</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">V</forename><surname>Patti</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">B</forename><surname>Plank</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Wagner</surname></persName>
		</editor>
		<meeting>the Second Workshop on Computational Modeling of People&apos;s Opinions, Personality, and Emotions in Social Media, PEOPLES@NAACL-HTL 2018<address><addrLine>New Orleans, Louisiana, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="36" to="41" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Annotating hate speech: Three schemes at comparison</title>
		<author>
			<persName><forename type="first">F</forename><surname>Poletto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Basile</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Bosco</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Patti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Stranisci</surname></persName>
		</author>
		<ptr target="http://ceur-ws.org/Vol-2481/paper56.pdf" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Sixth Italian Conference on Computational Linguistics</title>
		<title level="s">CEUR Workshop Proceedings</title>
		<editor>
			<persName><forename type="first">R</forename><surname>Bernardi</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Navigli</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Semeraro</surname></persName>
		</editor>
		<meeting>the Sixth Italian Conference on Computational Linguistics<address><addrLine>Bari, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">2481</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Hate speech detection using brazilian imageboards</title>
		<author>
			<persName><forename type="first">G</forename><surname>Nascimento</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Carvalho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Da Cunha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">R</forename><surname>Viana</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">P</forename><surname>Guedes</surname></persName>
		</author>
		<idno type="DOI">10.1145/3323503.3360619</idno>
		<ptr target="https://doi.org/10.1145/3323503.3360619" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th Brazillian Symposium on Multimedia and the Web</title>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">A F</forename><surname>Dos Santos</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><forename type="middle">C</forename><surname>Muchaluat-Saade</surname></persName>
		</editor>
		<meeting>the 25th Brazillian Symposium on Multimedia and the Web<address><addrLine>WebMedia; Rio de Janeiro, Brazil</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2019">2019. 2019</date>
			<biblScope unit="page" from="325" to="328" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Semeval-2019 task 5: Multilingual detection of hate speech against immigrants and women in twitter</title>
		<author>
			<persName><forename type="first">V</forename><surname>Basile</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Bosco</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Fersini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Nozza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Patti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">M R</forename><surname>Pardo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sanguinetti</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/s19-2007</idno>
		<ptr target="https://doi.org/10.18653/v1/s19-2007" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th International Workshop on Semantic Evaluation, SemEval@NAACL-HLT 2019</title>
		<editor>
			<persName><forename type="first">J</forename><surname>May</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">E</forename><surname>Shutova</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Herbelot</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">X</forename><surname>Zhu</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Apidianaki</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Mohammad</surname></persName>
		</editor>
		<meeting>the 13th International Workshop on Semantic Evaluation, SemEval@NAACL-HLT 2019<address><addrLine>Minneapolis, MN, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="54" to="63" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Semeval-2019 task 6: Identifying and categorizing offensive language in social media (offenseval)</title>
		<author>
			<persName><forename type="first">M</forename><surname>Zampieri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Malmasi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Nakov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Rosenthal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Farra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Kumar</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/s19-2010</idno>
		<ptr target="https://doi.org/10.18653/v1/s19-2010" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th International Workshop on Semantic Evaluation</title>
		<editor>
			<persName><forename type="first">J</forename><surname>May</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">E</forename><surname>Shutova</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Herbelot</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">X</forename><surname>Zhu</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Apidianaki</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Mohammad</surname></persName>
		</editor>
		<meeting>the 13th International Workshop on Semantic Evaluation<address><addrLine>Minneapolis, MN, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="75" to="86" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Automatic hate speech detection on social media: A brief survey</title>
		<author>
			<persName><forename type="first">A</forename><surname>Alrehili</surname></persName>
		</author>
		<idno type="DOI">10.1109/AICCSA47632.2019.9035228</idno>
		<ptr target="https://doi.org/10.1109/AICCSA47632.2019.9035228" />
	</analytic>
	<monogr>
		<title level="m">16th IEEE/ACS International Conference on Computer Systems and Applications</title>
		<meeting><address><addrLine>Abu Dhabi, UAE</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">A study of text representations in hate speech detection</title>
		<author>
			<persName><forename type="first">C</forename><surname>Themeli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Giannakopoulos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Pittaras</surname></persName>
		</author>
		<idno>CoRR abs/2102.04521</idno>
		<ptr target="https://arxiv.org/abs/2102.04521" />
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Challenges in discriminating profanity from hate speech</title>
		<author>
			<persName><forename type="first">S</forename><surname>Malmasi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zampieri</surname></persName>
		</author>
		<idno type="DOI">10.1080/0952813X.2017.1409284</idno>
		<ptr target="https://doi.org/10.1080/0952813X.2017.1409284" />
	</analytic>
	<monogr>
		<title level="j">J. Exp. Theor. Artif. Intell</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="187" to="202" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Hate speech detection: Challenges and solutions</title>
		<author>
			<persName><forename type="first">S</forename><surname>Macavaney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H.-R</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Russell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Goharian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Frieder</surname></persName>
		</author>
		<idno type="DOI">10.1371/journal.pone.0221152</idno>
		<ptr target="https://doi.org/10.1371/journal.pone.0221152" />
	</analytic>
	<monogr>
		<title level="j">PLOS ONE</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1" to="16" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Hate me, hate me not: Hate speech detection on facebook</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">D</forename><surname>Vigna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Cimino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Dell'orletta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Petrocchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Tesconi</surname></persName>
		</author>
		<ptr target="http://ceur-ws.org/Vol-1816/paper-09.pdf" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First Italian Conference on Cybersecurity (ITASEC17)</title>
		<title level="s">CEUR Workshop Proceedings</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Armando</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Baldoni</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Focardi</surname></persName>
		</editor>
		<meeting>the First Italian Conference on Cybersecurity (ITASEC17)<address><addrLine>Venice, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>CEUR-WS.org</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">1816</biblScope>
			<biblScope unit="page" from="86" to="95" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Offensive language detection using brown clustering</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kübler</surname></persName>
		</author>
		<ptr target="https://aclanthology.org/2020.lrec-1.625/" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of The 12th Language Resources and Evaluation Conference, LREC 2020</title>
		<editor>
			<persName><forename type="first">N</forename><surname>Calzolari</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><surname>Béchet</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><surname>Blache</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K</forename><surname>Choukri</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Cieri</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename><surname>Declerck</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Goggi</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Isahara</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">B</forename><surname>Maegaard</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Mariani</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Mazo</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Moreno</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Odijk</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Piperidis</surname></persName>
		</editor>
		<meeting>The 12th Language Resources and Evaluation Conference, LREC 2020<address><addrLine>Marseille, France</addrLine></address></meeting>
		<imprint>
			<publisher>European Language Resources Association</publisher>
			<date type="published" when="2020">May 11-16, 2020. 2020</date>
			<biblScope unit="page" from="5079" to="5087" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Automated hate speech detection and the problem of offensive language</title>
		<author>
			<persName><forename type="first">T</forename><surname>Davidson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Warmsley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">W</forename><surname>Macy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Weber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eleventh International Conference on Web and Social Media, ICWSM 2017</title>
		<meeting>the Eleventh International Conference on Web and Social Media, ICWSM 2017<address><addrLine>Montréal, Québec, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017">May 15-18, 2017. 2017</date>
			<biblScope unit="page" from="512" to="515" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Profiling hate speech spreaders on twitter: SVM vs. bi-lstm</title>
		<author>
			<persName><forename type="first">I</forename><surname>Vogel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Meghana</surname></persName>
		</author>
		<ptr target="http://ceur-ws.org/Vol-2936/paper-196.pdf" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Working Notes of CLEF 2021 -Conference and Labs of the Evaluation Forum</title>
		<title level="s">CEUR Workshop Proceedings</title>
		<editor>
			<persName><forename type="first">G</forename><surname>Faggioli</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Joly</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Maistro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><surname>Piroi</surname></persName>
		</editor>
		<meeting>the Working Notes of CLEF 2021 -Conference and Labs of the Evaluation Forum<address><addrLine>Bucharest, Romania</addrLine></address></meeting>
		<imprint>
			<publisher>CEUR-WS.org</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">2936</biblScope>
			<biblScope unit="page" from="2193" to="2200" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Hate speech classification using SVM and naive BAYES</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">C</forename><surname>Asogwa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">I</forename><surname>Chukwuneke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">C</forename><surname>Ngene</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">N</forename><surname>Anigbogu</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2204.07057</idno>
		<idno>CoRR abs/2204.07057</idno>
		<ptr target="https://doi.org/10.48550/arXiv.2204.07057" />
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Benchmarking aggression identification in social media</title>
		<author>
			<persName><forename type="first">R</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Ojha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Malmasi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zampieri</surname></persName>
		</author>
		<ptr target="https://aclanthology.org/W18-4401/" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First Workshop on Trolling, Aggression and Cyberbullying, TRAC@COLING 2018</title>
		<editor>
			<persName><forename type="first">R</forename><surname>Kumar</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Ojha</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Zampieri</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Malmasi</surname></persName>
		</editor>
		<meeting>the First Workshop on Trolling, Aggression and Cyberbullying, TRAC@COLING 2018<address><addrLine>Santa Fe, New Mexico, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="1" to="11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Fermi at SemEval-2019 task 6: Identifying and categorizing offensive language in social media using sentence embeddings</title>
		<author>
			<persName><forename type="first">V</forename><surname>Indurthi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Syed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Shrivastava</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Varma</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/S19-2109</idno>
		<ptr target="https://aclanthology.org/S19-2109" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th International Workshop on Semantic Evaluation</title>
		<meeting>the 13th International Workshop on Semantic Evaluation<address><addrLine>Minneapolis, Minnesota, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="611" to="616" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">HurtBERT: Incorporating lexical features with BERT for the detection of abusive language</title>
		<author>
			<persName><forename type="first">A</forename><surname>Koufakou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">W</forename><surname>Pamungkas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Basile</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Patti</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.alw-1.5</idno>
		<ptr target="https://aclanthology.org/2020.alw-1.5" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fourth Workshop on Online Abuse and Harms</title>
		<meeting>the Fourth Workshop on Online Abuse and Harms<address><addrLine>Online</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="34" to="43" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Hatebert: Retraining BERT for abusive language detection in english</title>
		<author>
			<persName><forename type="first">T</forename><surname>Caselli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Basile</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Mitrovic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Granitzer</surname></persName>
		</author>
		<idno>CoRR abs/2010.12472</idno>
		<ptr target="https://arxiv.org/abs/2010.12472" />
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Determining code words in euphemistic hate speech using word embedding networks</title>
		<author>
			<persName><forename type="first">R</forename><surname>Magu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Luo</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/W18-5112</idno>
		<ptr target="https://aclanthology.org/W18-5112" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2nd Workshop on Abusive Language Online (ALW2)</title>
		<meeting>the 2nd Workshop on Abusive Language Online (ALW2)<address><addrLine>Brussels, Belgium</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="93" to="100" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Abusive language detection in online user content</title>
		<author>
			<persName><forename type="first">C</forename><surname>Nobata</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Tetreault</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Mehdad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th International Conference on World Wide Web, WWW 2016</title>
		<meeting>the 25th International Conference on World Wide Web, WWW 2016<address><addrLine>Montreal, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016">April 11 -15, 2016. 2016</date>
			<biblScope unit="page" from="145" to="153" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Comparison of various word embeddings for hate-speech detection</title>
		<author>
			<persName><forename type="first">M</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Goel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Singla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Tehlan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Data Analytics and Management</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Khanna</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><surname>Gupta</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Z</forename><surname>Pólkowski</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Bhattacharyya</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">O</forename><surname>Castillo</surname></persName>
		</editor>
		<meeting><address><addrLine>Singapore</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="251" to="265" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">A survey on hate speech detection using natural language processing</title>
		<author>
			<persName><forename type="first">A</forename><surname>Schmidt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Wiegand</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/W17-1101</idno>
		<ptr target="https://aclanthology.org/W17-1101" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fifth International Workshop on Natural Language Processing for Social Media</title>
		<meeting>the Fifth International Workshop on Natural Language Processing for Social Media<address><addrLine>Valencia, Spain</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1" to="10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">A survey on community detection algorithm and its applications</title>
		<author>
			<persName><forename type="first">P</forename><surname>Meena</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Pawar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Pandey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Turkish Journal of Computer and Mathematics Education (TURCOMAT)</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="4807" to="4815" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Clustering halal food consumers: A twitter sentiment analysis</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Mohamed</surname></persName>
		</author>
		<idno type="DOI">10.1177/1470785318771451</idno>
		<ptr target="https://doi.org/10.1177/1470785318771451" />
	</analytic>
	<monogr>
		<title level="j">International Journal of Market Research</title>
		<imprint>
			<biblScope unit="volume">61</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="320" to="337" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Multifunctional product marketing using social media based on the variable-scale clustering</title>
		<author>
			<persName><forename type="first">A</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Tehnički vjesnik</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="193" to="200" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Using semantic clustering to support situation awareness on twitter: the case of world views</title>
		<author>
			<persName><forename type="first">C</forename><surname>Kingston</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R C</forename><surname>Nurse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Agrafiotis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Milich</surname></persName>
		</author>
		<idno type="DOI">10.1186/s13673-018-0145-6</idno>
		<ptr target="https://doi.org/10.1186/s13673-018-0145-6" />
	</analytic>
	<monogr>
		<title level="j">Hum. centric Comput. Inf. Sci</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">22</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">An evaluation of document clustering and topic modelling in two online social networks: Twitter and reddit</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Curiskis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Drake</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">R</forename><surname>Osborn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Kennedy</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.ipm.2019.04.002</idno>
		<ptr target="https://doi.org/10.1016/j.ipm.2019.04.002" />
	</analytic>
	<monogr>
		<title level="j">Inf. Process. Manag</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">102034</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Multi-view clustering</title>
		<author>
			<persName><forename type="first">S</forename><surname>Bickel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Scheffer</surname></persName>
		</author>
		<idno type="DOI">10.1109/ICDM.2004.10095</idno>
		<ptr target="https://doi.org/10.1109/ICDM.2004.10095" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 4th IEEE International Conference on Data Mining (ICDM 2004)</title>
		<meeting>the 4th IEEE International Conference on Data Mining (ICDM 2004)<address><addrLine>Brighton, UK</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="19" to="26" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">Multi-view Clustering on Relational Data</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">T</forename><surname>De</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>De Carvalho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lechevallier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Despeyroux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">M</forename><surname>De Melo</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-319-02999-3_3</idno>
		<ptr target="https://doi.org/10.1007/978-3-319-02999-33" />
		<editor>Guillet, F., Pinaud, B., Venturini, G., Zighed, D.A.</editor>
		<imprint>
			<date type="published" when="2014">2014</date>
			<publisher>Springer</publisher>
			<biblScope unit="page" from="37" to="51" />
			<pubPlace>Cham</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">A survey on multi-view clustering</title>
		<author>
			<persName><forename type="first">G</forename><surname>Chao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bi</surname></persName>
		</author>
		<idno>CoRR abs/1712.06246</idno>
		<ptr target="https://arxiv.org/abs/1712.06246" />
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Multi-view clustering: A survey</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<idno type="DOI">10.26599/BDMA.2018.9020003</idno>
		<ptr target="https://doi.org/10.26599/BDMA.2018.9020003" />
	</analytic>
	<monogr>
		<title level="j">Big Data Min. Anal</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="83" to="107" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">An overview of recent multiview clustering</title>
		<author>
			<persName><forename type="first">L</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">V</forename><surname>Vasilakos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.neucom.2020.02.104</idno>
		<ptr target="https://doi.org/10.1016/j.neucom.2020.02.104" />
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">402</biblScope>
			<biblScope unit="page" from="148" to="161" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Multiview and multifeature spectral clustering using common eigenvectors</title>
		<author>
			<persName><forename type="first">S</forename><surname>Kanaan-Izquierdo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ziyatdinov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Perera-Lluna</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.patrec.2017.12.011</idno>
		<ptr target="https://doi.org/10.1016/j.patrec.2017.12.011" />
	</analytic>
	<monogr>
		<title level="j">Pattern Recognit. Lett</title>
		<imprint>
			<biblScope unit="volume">102</biblScope>
			<biblScope unit="page" from="30" to="36" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Handling imbalanced data: A survey</title>
		<author>
			<persName><forename type="first">N</forename><surname>Rout</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Mishra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">K</forename><surname>Mallick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Proceedings on Advances in Soft Computing, Intelligent Systems and Applications</title>
		<editor>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Reddy</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K</forename><surname>Viswanath</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K</forename><forename type="middle">M</forename></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><forename type="middle">P</forename></persName>
		</editor>
		<meeting><address><addrLine>Singapore</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="431" to="443" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">A survey on data preprocessing for data stream mining: Current status and future directions</title>
		<author>
			<persName><forename type="first">S</forename><surname>Ramírez-Gallego</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Krawczyk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>García</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Wozniak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Herrera</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.neucom.2017.01.078</idno>
		<ptr target="https://doi.org/10.1016/j.neucom.2017.01.078" />
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">239</biblScope>
			<biblScope unit="page" from="39" to="57" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Effective text data preprocessing technique for sentiment analysis in social media data</title>
		<author>
			<persName><forename type="first">S</forename><surname>Pradha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">N</forename><surname>Halgamuge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">T Q</forename><surname>Vinh</surname></persName>
		</author>
		<idno type="DOI">10.1109/KSE.2019.8919368</idno>
		<ptr target="https://doi.org/10.1109/KSE.2019.8919368" />
	</analytic>
	<monogr>
		<title level="m">11th International Conference on Knowledge and Systems Engineering, KSE 2019</title>
		<meeting><address><addrLine>Da Nang, Vietnam</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019">October 24-26, 2019. 2019</date>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Sequential transfer learning for event detection and key sentence extraction</title>
		<author>
			<persName><forename type="first">A</forename><surname>Ollagnier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">T P</forename><surname>Williams</surname></persName>
		</author>
		<idno type="DOI">10.1109/ICMLA51294.2020.00166</idno>
		<ptr target="https://doi.org/10.1109/ICMLA51294.2020.00166" />
	</analytic>
	<monogr>
		<title level="m">19th IEEE International Conference on Machine Learning and Applications, ICMLA 2020</title>
		<editor>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Wani</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><surname>Luo</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">X</forename><forename type="middle">A</forename><surname>Li</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><surname>Dou</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><surname>Bonchi</surname></persName>
		</editor>
		<meeting><address><addrLine>Miami, FL, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="1023" to="1027" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title level="m" type="main">Pre-trained models for natural language processing: A survey</title>
		<author>
			<persName><forename type="first">X</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Huang</surname></persName>
		</author>
		<idno>CoRR abs/2003.08271</idno>
		<ptr target="https://arxiv.org/abs/2003.08271" />
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
		<title level="m" type="main">Universal sentence encoder</title>
		<author>
			<persName><forename type="first">D</forename><surname>Cer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Hua</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Limtiaco</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">S</forename><surname>John</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Constant</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Guajardo-Cespedes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Tar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Sung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Strope</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Kurzweil</surname></persName>
		</author>
		<idno>CoRR abs/1803.11175</idno>
		<ptr target="https://arxiv.org/abs/1803.11175" />
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">A survey on similarity measures in text mining</title>
		<author>
			<persName><forename type="first">M</forename><surname>Vijaymeena</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Kavitha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine Learning and Applications: An International Journal</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="19" to="28" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Community detection in graphs</title>
		<author>
			<persName><forename type="first">S</forename><surname>Fortunato</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.physrep.2009.11.002</idno>
		<ptr target="https://doi.org/10.1016/j.physrep.2009.11.002" />
	</analytic>
	<monogr>
		<title level="j">Physics Reports</title>
		<imprint>
			<biblScope unit="volume">486</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="75" to="174" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Stepwise estimation of common principal components</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">T</forename><surname>Trendafilov</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.csda.2010.03.010</idno>
		<ptr target="https://doi.org/10.1016/j.csda.2010.03.010" />
	</analytic>
	<monogr>
		<title level="j">Comput. Stat. Data Anal</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="3446" to="3457" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Some methods for classification and analysis of multivariate observations</title>
		<author>
			<persName><forename type="first">J</forename><surname>Macqueen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fifth Berkeley Symposium on Mathematical Statistics and Probability</title>
		<meeting>the Fifth Berkeley Symposium on Mathematical Statistics and Probability<address><addrLine>Oakland, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1967">1967</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="281" to="297" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">A simple and fast algorithm for k-medoids clustering</title>
		<author>
			<persName><forename type="first">H</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Jun</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.eswa.2008.01.039</idno>
		<ptr target="https://doi.org/10.1016/j.eswa.2008.01.039" />
	</analytic>
	<monogr>
		<title level="j">Expert Syst. Appl</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="3336" to="3341" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">On spectral clustering: Analysis and an algorithm</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Weiss</surname></persName>
		</author>
		<ptr target="https://proceedings.neurips.cc/paper/2001/hash/801272ee79cfde7fa5960571fee36b9b-Abstract.html" />
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 14 [Neural Information Processing Systems: Natural and Synthetic, NIPS 2001</title>
		<editor>
			<persName><forename type="first">T</forename><forename type="middle">G</forename><surname>Dietterich</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Becker</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Z</forename><surname>Ghahramani</surname></persName>
		</editor>
		<meeting><address><addrLine>Vancouver, British Columbia, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="849" to="856" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Introduction to information retrieval</title>
		<author>
			<persName><forename type="first">C</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Raghavan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Schütze</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Society for Information Science and Technology</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">496</biblScope>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">An analysis of variance test for normality (complete samples)</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Shapiro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">B</forename><surname>Wilk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biometrika</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="issue">3/4</biblScope>
			<biblScope unit="page" from="591" to="611" />
			<date type="published" when="1965">1965</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<monogr>
		<title level="m" type="main">Robust tests for equality of variances</title>
		<author>
			<persName><forename type="first">H</forename><surname>Levene</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1960">1960</date>
			<publisher>Stanford University Press</publisher>
			<biblScope unit="page" from="278" to="292" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<monogr>
		<author>
			<persName><forename type="first">F</forename><surname>Wilcoxon</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-1-4612-4380-9_16</idno>
		<ptr target="https://doi.org/10.1007/978-1-4612-4380-916" />
		<title level="m">Individual Comparisons by Ranking Methods</title>
		<editor>
			<persName><forename type="first">S</forename><surname>Kotz</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><forename type="middle">L</forename><surname>Johnson</surname></persName>
		</editor>
		<meeting><address><addrLine>New York, NY</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1992">1992</date>
			<biblScope unit="page" from="196" to="202" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">The use of ranks to avoid the assumption of normality implicit in the analysis of variance</title>
		<author>
			<persName><forename type="first">F</forename><surname>Milton</surname></persName>
		</author>
		<idno type="DOI">10.1080/01621459.1937.10503522</idno>
		<ptr target="https://doi.org/10.1080/01621459.1937.10503522" />
	</analytic>
	<monogr>
		<title level="j">Journal of the American Statistical Association</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">200</biblScope>
			<biblScope unit="page" from="675" to="701" />
			<date type="published" when="1937">1937</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<monogr>
		<title level="m" type="main">Distribution-free Multiple Comparisons</title>
		<author>
			<persName><forename type="first">P</forename><surname>Nemenyi</surname></persName>
		</author>
		<ptr target="https://books.google.fr/books?" />
		<imprint>
			<date type="published" when="1963">1963</date>
		</imprint>
		<respStmt>
			<orgName>Princeton University</orgName>
		</respStmt>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
