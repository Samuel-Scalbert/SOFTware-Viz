<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A Never-Ending Project for Humanity Called &quot;the Web&quot;</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<affiliation key="aff0">
								<orgName type="department">I3S</orgName>
								<orgName type="institution" key="instit1">Inria</orgName>
								<orgName type="institution" key="instit2">Université Côte d&apos;Azur</orgName>
								<orgName type="institution" key="instit3">CNRS Sophia Antipolis</orgName>
								<address>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">University of Southampton Southampton</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">A Never-Ending Project for Humanity Called &quot;the Web&quot;</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">AE64B1428C391B3A0AE4B55931F604CD</idno>
					<idno type="DOI">10.1145/3485447.3514195</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-04-12T14:52+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>Information systems → World Wide Web; • Social and professional topics → History of software history, world wide web</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper we summarized the main historical steps in making the Web, its foundational principles and its evolution. First we mention some of the influences and streams of thought that interacted to bring the Web about. Then we recall that its birthplace, the CERN, had a need for a global hypertext system and at the same time was the perfect microcosm to provide a cradle for the Web. We stress how this invention required to strike a balance between the integration of and the departure from the existing and emerging paradigms of the day. We then review the pillars of the Web architecture and the features that made the Web so viral compared to competitors. Finally we survey the multiple mutations the Web underwent no sooner it was born, evolving in multiple directions. We conclude on the fact the Web is now an architecture, an artefact, a science object and a research and development object, and of which we haven't seen the full potential yet.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>In April 2017, the British computer scientist Sir Timothy John Berners-Lee was awarded the Turing award for having invented the World Wide Web, the first Web browser, and the fundamental protocols and algorithms allowing the Web to scale. The same month, the estimate is that the Web has more than 3 billion direct users throughout the world and it is indeed difficult to think of a human activity that has not been impacted by the Web. This paper recalls the main historical steps in making the Web, its foundational principles and its evolution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">SPIDERS ON THE SHOULDERS OF GIANTS</head><p>In this section we highlight the main influences and streams of thought that interacted to bring the Web about and show that Tim Berners-Lee was "standing on the shoulders of giants" when he proposed his project in "Information management: a proposal" <ref type="bibr" target="#b6">[7]</ref> The search for techniques to organize and the means to efficiently access masses of collected information was an omnipresent motivation in the prehistory of the Web. Looking back in time, scholars envisioned worlds of inter-connected information centuries before the Web existed. The ideas of mapping and indexing associations between ideas, facts, and documents long pre-date the existence of computers, and in many ways, they reflect the sophisticated way in which information is indexed by the human brain. When our only means of communicating information was via the written or printed word on paper, inter-connecting pieces of information on different pages was very difficult other than via manually created indexes. With the advent of machines, people were able to imagine a time when the machine could support vast quantities of similar inter-connections.</p><p>The beginning of the twentieth centuries witnessed one of the earliest systematic world knowledge collection and management initiative with Paul Otlet's work on collecting, archiving, indexing and categorizing documentation and his Mundaneum project home of a universal bibliographical system using the universal decimal classification. Otlet foresaw the world-wide networked environment <ref type="bibr" target="#b24">[25]</ref>.</p><p>Among the direct influences for the Web is a seminal paper by Vannevar Bush entitled "As We May Think" <ref type="bibr" target="#b7">[8]</ref>. Bush foresaw the explosive increase in the production of scientific information and predicted the need for a machine to help scientists follow developments in their discipline. He posed, as a scientific challenge in itself, the problem of improving access to knowledge and proposed "a sort of mechanised private file and library". It would use mnemonic index codes to point to and rapidly access any part of imported documents. These attachment points would also allow links to be created between any two elements, thereby externalizing the points and links of association. Bush called his system Memex for "memory extender" recording trails which users build as they move through the information, so that their paths of discovery can be saved and recalled later or passed on to others externalizing "the association of thoughts, in accordance with some intricate web <ref type="bibr">[sic]</ref> of trails carried by the cells of the brain" <ref type="bibr" target="#b7">[8]</ref>.</p><p>Bush's design was based on mechanical technology, but the principles behind the design are, in many ways, even more valid today because of developments in information technology. To bring about such a system, it was necessary to wait for the appearance of computers. In an article at the 1965 ACM conference, Ted Nelson proposed "a file structure for complex, changing and indeterminate information," <ref type="bibr" target="#b21">[22]</ref> where he referenced Bush's article and coined a neologism to refer to this collection of interconnected texts: hypertext, and even hypermedia. The terms are often used interchangeably, although, strictly speaking, hypertext refers to linking text documents, and hypermedia refers more broadly to linking media of any type. In libraries we follow references from one book to another. The idea behind hypertext is that this process can be automated, and that we can harness the power of computers to make the search and query process easier. Nelson argued that it would become possible to store digitally anything that anyone would write, record, photograph, or film, and to produce a system that could connect any piece of information to any other piece of information. Nelson's vision of a universal hypermedia system, Xanadu, is most fully explored in his book Literary Machines <ref type="bibr" target="#b20">[21]</ref>. He defines hypertext as non-sequential writing and views hypertext as a literary medium, but the term encapsulates a wider set of meanings that includes both cross-referencing-linking between documents-and the more general associations between ideas.</p><p>The subsequent years witnessed the development of the first hypertext editors using, in particular, another invention from the same decade: the mouse, with the interfaces and interactions that it allows. We owe these inventions in particular to Douglas Engelbart of the Stanford Research Institute (SRI), who himself received the Turing award in 1997 for his pioneering and inspiring vision of man-machine interactions and the key technologies that allowed their development. In particular, his NLS ("oN-Line System") system combined, in the 1960s, hypertext, a text-editing interface, and the mouse. This system would later be renamed Augment, in reference to the search program of Engelbart who, with an eye toward the pioneering work of the period in artificial intelligence, proposed working on augmented intelligence <ref type="bibr" target="#b11">[12]</ref>.</p><p>The development of hypertext systems stayed in the realm of the research lab for most of the 1970s and 1980s. The systems grew in sophistication as the underlying technologies became more powerful. First-generation systems were implemented on mainframes and were largely text-based. Work on the so-called second-generation systems took advantage of the more advanced user interfaces of 1980s workstation technology. These systems supported graphics and animations, as well as fully formatted text documents. They were also able to provide graphical overviews of the hypertext structure and multi-user support <ref type="bibr" target="#b10">[11]</ref>. With the advent of the PC in the mid-1980s came the emergence of a new generation of hypertext systems that were much easier for individuals to use-notably Hyperties, OWL's Guide, and Apple's HyperCard. HyperCard was made available for free on every Macintosh computer in 1987, and it did more to popularize hypertext in the late 1980s than any other event. The first ACM Hypertext conference was held in the same year. But such systems could only be used to build relatively small applications.</p><p>It is important to understand that, as hypertext systems were emerging, the age of the Internet was also starting. Many research laboratories were already using email as a standard means of communication, and users were anxiously awaiting the ability to share files over the network. Systems such as Gopher and WAIS were being developed to enable files to be downloaded easily, without the need for expert technical knowledge. Although the hypertext concept had then been created, it remained, for years, essentially limited to applications that were locally executed on a computer. The world was hungry to share information over the Internet, and the time was ripe for the emergence of an easy-to-use, Internet-based hypertext system to facilitate these activities. Communication involving packet switching (inter-networking), which was developed between 1972 and 1975 with the work of Louis Pouzin (IRIA and then Inria <ref type="bibr" target="#b22">[23]</ref>, Vinton Cerf (SRI), and Robert Kahn (DARPA, <ref type="bibr" target="#b8">[9]</ref>), culminated in 1978 with the (TCP/IP) standards and the beginnings of the Internet. Network communications applications then multiplied: email (SMTP), mailing lists, file transfers (FTP), remote connections (Telnet), discussion groups, etc. Here as well, we find two Turing award winners from 2004: Vinton Cerf and Robert E. Kahn. The crossing between internet and hypertext research communities led to the development of hypertext systems that handled information on large scale and in distributed environments. Notable examples were the Hyper-G system from the University of Graz <ref type="bibr" target="#b1">[2]</ref>, the Microcosm system from the University of Southampton <ref type="bibr" target="#b14">[15]</ref>, and of course, the Web itself <ref type="bibr" target="#b4">[5]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">WEAVING THE. . . MESH</head><p>Timothy Berners-Lee arrived in 1980 as a consultant for CERN (Centre Européen de Recherche Nucléaire), as a young physics graduate and a self-taught computer scientist. Faced with the quantity of information and documentation that he and his colleagues had to deal with, Tim wrote a program (Enquire) to store information and to support links within it. It worked on a multi-user operating system and thus allowed multiple users to access and contribute to the same data <ref type="bibr" target="#b6">[7]</ref>. In comparison to the CERNDOC documentation system, which was based on a constrained hierarchical structure, Tim found that the arbitrary and bidirectional links within Enquire were more flexible and scalable.</p><p>Tim then returned to the private sector between 1981 and 1983, where he worked on real-time remote procedure calls, and thus in the field of networks and network programming, before returning to CERN in 1984. At that point, he was convinced that there was a need for a global hypertext system at CERN where thousands of people crossed paths from different areas of specialization and worked on different instruments <ref type="bibr" target="#b5">[6]</ref>. In March of 1989, to persuade his management, Tim wrote "Information Management: A Proposal" <ref type="bibr" target="#b6">[7]</ref> where he described a distributed hypertext system that he would call. . . "Mesh".</p><p>In 1989, CERN was the largest Internet hub in Europe and Tim and his colleagues worked on RPC (Remote Procedure Call) allowing a program running on a given machine to invoke procedures from programs running on other machines <ref type="bibr" target="#b17">[18]</ref>. The Unix operating system was very popular and natively integrated functions such as support for Internet protocols and multi-user environments. Tim had the idea of extending the link references to include network addresses, in order to weave a "mesh" between documents made available on different machines. Tim incorporated the principles of hypertext and integrated TCP and DNS into them in an architecture where clicking a link becomes, conceptually, a remote call for procedures, making the Web less a network of documents and more a network of procedures, as what is called now the REST (REpresentational State Transfer) <ref type="bibr" target="#b13">[14]</ref>.</p><p>CERN also already had a programming approach to document writing (e.g., LaTeX, SGML) <ref type="bibr" target="#b17">[18]</ref>, and this had a direct influence on the idea of turning to a simplified markup language that will become HTML. Starting in 1990, the Web documentation was itself in HTML and the Web began self-documenting, opening up the possibility for everyone to add to this documentation, and to learn to "weave through weaving. " This type of reflexivity also made the Web a space designed for humans and machines to co-evolve and collaborate. It supports co-understanding, co-documentation, and the co-conception of all the objects that are part of it, starting with the Web itself.</p><p>Another, relatively poorly known characteristic of the Web at the time of its conception, is that the Web was conceptually open to writing: everything in its architecture allowed not only the consultation (HTTP GET <ref type="bibr" target="#b12">[13]</ref>) but also the modification of the Web (HTTP PUT, POST, DELETE <ref type="bibr" target="#b12">[13]</ref>). The first client prototype imagined by Tim was a WYSIWYG browser and editor called W3 <ref type="bibr" target="#b4">[5]</ref>. But for diverse reasons (security, ease of use, etc.) and because of a lack of editors <ref type="bibr" target="#b4">[5]</ref>, the most popular browsers and servers did not include this possibility of modifying Web pages. It would only be reintroduced, at a certain level, with the invention of Wikis (WikiWikiWeb) in 1994 by Ward Cunningham.</p><p>Tim prototyped his first server and browser on a state-of-theart NeXT Cube workstation. It had a powerful object-based and graphical programming environment that integrated the large-scale networking of computers (TCP/IP and Internet), high level programming languages, progress on human-machine interactions, and notably graphical and multi-window interfaces. With this NeXT and its environment Tim was on the shoulders of the giants we mentioned to start his development. At the end of 1990, the first server and the first browser were tested through an Internet connection. The browser was called World Wide Web, which would become the name of the hypertext that it would give rise to and which would send the name "Mesh" to the dustbin of history.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">BREAKING THE THREAD</head><p>But the Web proposal was not just integrating and hybridizing existing ideas, it was a remarkable exercise in striking a balance between the integration of and the departure from the existing and emerging paradigms of the day. In particular, Tim was convinced that generality and portability were more important than other extensions and he had the idea to "build small, but viral. "</p><p>The core functionality was to allow random associations between arbitrary objects as well as an incremental and trivial contribution for objects and for links by different contributors, justifying a decentralized approach <ref type="bibr" target="#b3">[4]</ref>. The Web always was about moving beyond the silos imposed by the existing applications and searching for independence with respect to the field, task, hardware, operating system <ref type="bibr" target="#b5">[6]</ref> and file paths and systems <ref type="bibr" target="#b3">[4]</ref>. Tim's proposal liberated hypertext from a central server and the data and links were decentralized on the Internet. As a price to pay, the links became unidirectional and were no longer necessarily maintained. The 404 error was born.</p><p>The Web allowed precisely what traditional hypertexts were trying to prevent. However, these breaks were the necessary conditions for the scaling and virality of the Web. Yet this loss of functionality led to new adaptations. For example, the absence of a central index and of bidirectional links would lead to the creation of directories (e.g., Yahoo! in 1994) and search engines (e.g., Altavista, Google) to locate pages and links. The search engines grew to fill the gaps of the Web, the two systems are completely synergistic -one can't exist without the other. Search engines can function because of the way in which the Web encodes hypermedia data, and the Web has overcome some of its inherent disadvantages through the development of search engines. Compared to the state of the art at the time, Tim argued that the network was everything while many other hypertext systems ran on standalone workstations. He showed us that "scruffy works. " It didn't have to be perfect, because we aren't perfect, but it had to be good enough. In addition, he argued that the model and architecture had to be decentralized and non-proprietary, that the standards had to be universal, and that it had to be free to use. Ontologically speaking, either everyone would use the World Wide Web, or no one would.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">WEB PILLARS: IDENTIFY, DESCRIBE AND COMMUNICATE</head><p>The Web architecture was thus built on three pillars:</p><p>• The first, and the most important, is that of identification.</p><p>The major prerequisite for weaving a web is to have anchors. The history of identification on the Web goes through UDIs (Universal Document Identifier), URLs (Uniform Resource Locator), URIs (Universal Resource Identifier), and IRIs (Internationalized Resource Identifier). URLs and URIs are formats for addresses and identifiers allowing the localization, or simply the naming and referencing on the Web, of any type of resource, it is thus a resource-oriented vision of the network <ref type="bibr" target="#b3">[4]</ref>. • The second fundamental notion of Web architecture is that of communication and data transfer. For this, the HTTP protocol allows a request to be made, starting with a URL address, for a representation of the resource identified and localized by the URL, and then the data corresponding to the representation is either obtained or error codes are produced indicating an encountered problem.</p><p>• The third fundamental notion is that of the representation of exchanged data. As the Web was initially motivated by the representation and exchange of documents, HTML was the first language proposed to represent, store, and communicate Web pages. After HTML, other language will be proposed to exchange other kinds of data than Web pages. In fact, Tim revisited the Web architecture in 1996 <ref type="bibr" target="#b3">[4]</ref> putting an accent on addressing, protocols, and content negotiation, a native mechanism of HTTP, offering the possibility to serve, for a given URI, different versions of the same resource, and was directly inspired by the format negotiation mechanism of "System 33" <ref type="bibr" target="#b23">[24]</ref> from Steve Putz at Xerox PARC. Even more than each pillar individually, the way in which they are combined in a simple and elegant architecture is the core of the Web invention and greatly contributed to the virality of the Web <ref type="bibr" target="#b5">[6]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">MAKING THE WEB WORLD WIDE</head><p>At the end of 1990, the first server and the first browser were tested through an Internet connection and at the start of the 2000s there were more than 26 million Web servers running in the world. What made the Web so viral compared to competitors? Some of the reasons were technical, starting with Tim's decision to stress the importance of generality, portability, and extensibility, and his position that they were more important than the satisfaction derived from taking advantage of the latest capabilities of computers (such as graphics at the time). If the Web today has made a major, sustainable technical contribution to the computer science community, it is in particular due to its simplicity, elegance, and extensibility <ref type="bibr" target="#b0">[1]</ref>.</p><p>Tim recognized that simplicity was a necessary condition for the generalized adoption of the Web. His simplification of protocols, including his insistence on the absence of states in the HTTP protocol, made the design easy to implement. In addition, the use of human-readable scripts made the system easy to debug, as well as virally reusable by copy-paste-adapt <ref type="bibr" target="#b5">[6]</ref>. We all made our first Web page by copying-pasting-adapting the source of an existing page.</p><p>From the beginning, Tim also stressed that the result had to be sufficiently attractive in use to allow the information contained to surpass a critical threshold, and that this mass of information would in turn encourage ever more use and contributions. In that, he recognized the power of network effects as a positive feedback of Metcalfe's law, which states that the value of a network is proportional to the square of the number of its users/members. As value increases, more agents join the network to get the benefits, including information that they own into the network, and thus further increasing its value.</p><p>To achieve this, Tim proposed to support links between existing and new databases <ref type="bibr" target="#b6">[7]</ref>, and a systematic compatibility with what was already in existence. From its creation, the Web integrated gateway servers to import legacy resources and to allow access to other applications using techniques such as CGI (Common Gateway Interface). In this way, the Web would integrate, inter-operate, and ultimately absorb existing systems, most notably WAIS and Gopher. This approach facilitated the complete migration of communities of users of older systems to the Web. Tim also designed retro-compatibility or descending compatibility with earlier protocols (FTP, Gopher, WAIS, etc.) as an inter-operability constraint, a show of flexibility, and above all as an assurance of its evolutive nature for the future <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b4">5]</ref>. Further, with approaches like the CGIs, the automatic generation of dynamic pages and the possibility of referencing and reading them immediately played a key role in the weaving of a Web that was sufficiently resourced (numerous nodes), connected, and dense (numerous links) <ref type="bibr" target="#b4">[5]</ref>.</p><p>Beyond these technical choices, other choices made for economic, legal or social reasons also made a difference in the acceptance of the Web. First of all, in 1993, the CERN announced that the architecture and the technological foundations of the Web would be made open source, free of rights, and without any fees <ref type="bibr" target="#b9">[10]</ref>. Another decisive initiative was the establishment, in 1994, of the World Wide Web Consortium (W3C). Before the W3C, Web standards had been published in the form of RFCs (Request For Comments). They would thereafter be published as recommendations from the W3C. The consortium played a primordial role in the normalization of the evolution of the Web architecture, allowing it to grow without losing the standard inter-operability that gave it its universality.</p><p>Finally, the Web also benefited from important external positive factors, in particular the democratization of broadband access. It wasn't until the late 1990s that we saw broadband became readily available, thus enabling the growth of the home computing industry. With large numbers of users possessing high-speed access to the Internet in their homes, companies trying to sell things on the Web had a market for their products.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">MUTATIONS OF THE WEB</head><p>No sooner, the Web emerged from its initial chrysalis of a distributed hypertext documentary system that it started evolving in multiple directions revealing and reaching for its full potential as universal hypermedia software architecture for the internet and every connected thing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1">Mobile Access to the Web</head><p>As of 1996, companies were interested in providing Web access to mobile phones. In 1999, the QR code was made open source, which would contribute to its distribution and its being made available in image recognition applications on mobile phones, in particular for gathering URLs displayed around us. In the same period, WAP (Wireless Application Protocol) and WML (Wireless Markup Language) were proposed for adapting Web access and content to the constraints of mobile phones and their connectivity issues. These first attempts, as well as those made with PDAs with wireless network cards, would have to wait until the mid-2000s and the arrival of smartphones to have platforms upon which they could reach their full potential. The problem was first to overcome the limitations of mobile connections (screen, bandwidth, limited interactions, limited computational power, connection costs, etc.). Then, either by resolving these problems or through their disappearance with increases in the power of the terminals and networks, the work moved to the question of the deeper adaption of usage under mobile conditions: geo-localization, adaptation of interactions and interfaces, access to personal data, contextualization, audio and vocal interaction, augmented reality, coupling of several terminals, etc. Today, mobile Web applications are common, and many native mobile applications have in fact largely been developed using the languages and standards of the Web. In addition, lower entry-level prices and the democratization of smartphones mean that in certain areas of the world, mobile phones are now the primary means that people have of accessing the Web and are the most widespread way of having an initial contact with the Web.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2">Metadata and Linked Data on a Semantic Web</head><p>The PICS (Platform for Internet Content Selection) standardization, which was one of the first recommendations of the W3C in 1996, allowed the filtering of inappropriate content, in particular for children. It was also an early example of the type of decentralization that was desired for the Web in general: the filters capturing user preferences were created and stored in the browsers; the descriptors were stored in the consulted sites, but were generated by third-party authorities. The idea of labelling by, and in reference to, a thirdparty reintroduces in the Web the idea of complex and rich links and represented an opening towards the general notion of metadata on the Web. This idea was in line with another evolution towards a Web of documents and structured data. CSS (Cascading Style Sheets) was an important step that marked the beginning of the separation on the Web of content (HTML) from the way in which it is presented (CSS) allowing the formatting of a document to be made independent of and separated from its structure, and also to use the same formatting for multiple documents, or inversely to vary the formatting of a single document. With Web content now separated from its format, the content was able to evolve through the creation and management of its own data and document structures. This was achieved with the standardization of XML in 1998 and, in its wake, of several languages allowing its validation (DTD, XML Schemas), interrogation (XPATH, XQuery), transformation (XSLT), management (XProc), etc.</p><p>The same year, Tim published the roadmap for the Semantic Web <ref type="bibr" target="#b2">[3]</ref> extending on his idea from an article in 1994 pushing the Web towards resources with semantics oriented towards machines to allow for more automated processing <ref type="bibr" target="#b4">[5]</ref>. The 1998 roadmap would open the door to all of the work that was carried out on the Web of Data and the Semantic Web (RDF, RDFS, SPARQL, OWL, etc.). The Semantic Web and Linked Data are reasserting the importance of the links and triples are essentially typed links. The aim is to shift the emphasis of associative linking from documents to data, facilitating a more comprehensive form of automated reasoning. This shift is desirable for at least three reasons. First, it facilitates data reuse, often in new and unexpected contexts. Second, it helps reduce the amount of relatively expensive human information processing. Third, it releases the large quantity of information, not currently accessible, that is stored in other data management systems and applications.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.3">Web Programming and a Web of Applications</head><p>At the birth of the Web a page would already be generated on the fly on request following a click on a simple link, or in response to a form being submitted. On the server, a code would use the CGI method (Common Gateway Interface) to process requests and generate pages in return. With the introduction of frames in around 1996, it became possible to reload only part of a page. The same year, JavaScript appeared and, in Web applications, it became possible to use, even conjointly, programming on the side of the server as well as on the side of the browser. This marked the beginning of a genealogy of programming languages and techniques for the Web, some of them more server-oriented (ASP, PHP, C#, Python, Ruby, Perl, JSP, etc.), others more client-oriented (e.g., Plugins, ActiveX, CSS+HTML), and some that could be used by both (Java Servlet and Applet, JavaScript). Finally, with the XMLHttpRequest component added to JavaScript, it became possible to exchange data between a page and its server, and also, thanks to its DOM (Document Object Model), to modify a displayed page without necessarily reloading it. This technique would be named AJAX (Asynchronous JavaScript And XML) in 2005 and was massively adopted in Web applications to conjugate code being executed on the client with code being executed on the server, allowing fluid interactions with the user. In parallel, the architecture of the Web was being increasingly studied and formalized (e.g. REST architecture <ref type="bibr" target="#b13">[14]</ref>). In the early 2000s, the proposition of evolving towards a Web of services (SOAP, Simple Object Access Protocol, and WSDL, Web Services Description Language, standards) opened up a new direction for work, to use the Web as a programming platform, which is currently being realized through APIs and associated languages such as JSON. Some go so far as to talk of the Web as an operating system that goes beyond the global collection of services that are offered on the Internet, and that is independent of the computers and individual objects that are connected to it. They see the Web as the programming and execution environment par excellence for Internet applications.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.4">Social Medias and Networks on the Web</head><p>When speaking of the high points in the evolution of the Web, we see references now to what is called Web 1.0, Web 2.0, Web 3.0, etc., terms that give the false impression of major software evolutions in the Web when they are changes in practice or even in the understanding of the Web. Web 1.0 corresponds essentially to the initial document-based and distributed hypermedia vision of the Web. Web 2.0, which is also called the Social Web, reflects both the opening up of the Web to writing, including the AJAX approach for interactions, and the enormous social exchanges that it permitted, with Wikis, blogs, forums, social media, etc., . We are all familiar with the impact of that evolution. Web 3.0 generally covers the integration of Semantic Web practices and the Web of Data into Web 2.0, such as with RDFa (RDF in Attributes) in the Facebook OGP (Open Graph Protocol) or the use of Schema.org in numerous sites integrating social functionalities (for example, votes, ratings, etc.). What the Social Web also made visible is that the Web is a massive network of networks, and it has shown us quite dramatically, and in so many different ways, both how networks shape our lives and the amazing potential of a global hypertext system. The Web is a network designed in such way you can easily overlay other networks on top of it and that is what happened with social networks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.5">Web of Things</head><p>One upcoming evolution that is currently under study is to make the Web a universal application platform for connected objects, called the Web of Things. Today, we literally envisage making a web of everything. But we can also remember the initial influence that RPCs had on the conception of distributed hypertext and see this evolution as a form of returning to the source. In addition, in representing the Web as a mesh of potential calls for procedures that we invoke with each link that we follow, we understand better why ambitions such as that of crawling, indexing, or archiving the Web are complicated or even paradoxical.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">THIS IS FOR EVERYTHING</head><p>"This is for everyone" is the message with which Tim presented the Web during the opening ceremony of the 2012 Summer Olympic Games in London. The Web is for and affects everyone and is also becoming part of everything around us, and is being deployed in all corners of the world. The Web, for everyone, everywhere, and for everything. This Web, with its worldwide reach, a name which at the beginning could have been seen as immodest, revealed itself in just a few years to be a self-fulfilling prophecy, where its being designed to be universal allowed it in fact to evolve towards the universal.</p><p>With the Web of Data, Web of Applications, Web of services, Mobile Web, and a Web that is accessible, international, etc., the Web therefore initiated, very early, its transformation towards a generic hypermedia architecture for programming and interaction, and especially the generalization of a Web potentially linking all types of resources, whether computational or not. The Web can reach anything, as everything can be identified with a URI. As the principles of the Web are extensible and generic, they have allowed us to pass from a documentary vision of a global library to a network of protean resources. One of the major strengths of the Web is in its universality, but we will also see that it requires constant vigilance to be preserved.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9">AN ARTIFACT, A SCIENCE OBJECT AND A RESEARCH OBJECT</head><p>Even today, it is striking to see to what point the Web is both wellknown and at the same time poorly understood, as we can see for example with the tenacious and all-too-often seen confusion between the terms Web and Internet. The Internet allows for the inter-connection between computer networks and connected objects in general. It provides a communication infrastructure that supports numerous applications such as: email, telephoning, and videoconferencing. The Web is the distributed hypermedia that has become the primary software architecture for applications on the Internet.</p><p>Beyond this confusion, the term Web is also often used in a way that fails to differentiate between the founding principles of the software architecture and the object that emerged from it, i.e. the web weaved by its billions of users. The architecture and the object that emerged from it have two histories that are linked but that cover different aspects. Each of these two aspects exhibits, in different ways, complexity that calls for both research and development. The architecture of the Web is based on protocols, models, languages and algorithms that need to be specified, designed, characterized, and validated, as well as on, systematically, constraints such as those related to upscaling, efficiency in time and memory, interoperability, and internationalization. To achieve this, the architecture of the Web and its extensions are the subjects of research, in particular in the digital sciences. Within computer science and the digital sciences -and this is true in other fields as well -the Web has expanded both as a new tool for work but also as a new subject bringing with it both solutions and new problems and needs.</p><p>With respect to the object that has emerged from the use of that architecture, the complexity of its usages, the heterogeneity and volume of its content, services, and data, the dynamic nature of some of its traffic, and the life cycles of its resources and communities, are equally sources of complexity that also call for a scientific approach and for theoretical, applied, experimental, and multi-disciplinary research.</p><p>The different examples of the evolutions of and the facets of the Web lead us to a new need: that of developing the means for studying the Web and its changes. The more the Web grows in its architectural complexity and in the resources linked to it, the more it calls for transdisciplinary research and development <ref type="bibr" target="#b15">[16]</ref>. Tim would even go so far as to say that, ultimately, the Web is more of a social creation than a technical creation <ref type="bibr" target="#b5">[6]</ref>.</p><p>Historically, the Web quickly became a subject of research. Again under the impetus of Robert Cailliau and Tim Berners-Lee, in 1994 the WWW conference series now called "The Web Conference" was started at CERN and became the annual meeting place for the research, development, companies, and major actors of the Web. This research community is vivid <ref type="bibr" target="#b18">[19]</ref> and has grown and diversified, for example with resolutely multidisciplinary initiatives such as "Web Science" or more specialized conferences such as ISWC (International Semantic Web Conference).</p><p>As we seek to understand the origins of the Web, appreciate its current state, and anticipate possible futures, there is an increasing need to address the critical questions that will determine how the Web evolves as both a social and a technical network. The study of the Web-its evolution and its impact on society, on business, and on government-is referred to as Web Science. The Web, and the ways in which people interact with it, change faster than we can observe. This rapid evolution calls for new approaches and new methodologies to enable us to define and implement studies in Web Science. Economic, social, political, cultural, and economic agendas all have a role to play in shaping the new networks, and we need to understand the inter-play between those different perspectives to be able to anticipate the nature of the Web worlds of the future. Web Science must, by definition, be very multi-disciplinary, bringing together researchers from many different disciplines to help us shed light on what is actually going on in this very complex sociotechnical system. In order to monitor and analyze such developments, we need to be collecting evidence on a global scale of the changes brought about by the application of Web technology, and we need to be sharing the data we collect to be re-used in increasingly sophisticated analysis. This is a major role for the Web Scientists of the future.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="10">WE HAVEN'T SEEN THE FULL POTENTIAL OF THE WEB YET</head><p>The Web has modified our relationship with time and space by giving us the possibility of interacting with distant people and things, by giving us access to information that is not locally available, by recording traces of our actions, by documenting a variety of activities, and by allowing us to revisit them and re-experience them a posteriori and remotely. We no longer note down the address of the dentist, we can find it on the Web. We no longer program our VCR, we look for a recording on-line. We no longer go to the train station to buy tickets, but rather download an e-ticket. The omnipresence and hypermnesia of the Web are so established now that we can't stand it when it's not there to respond to us, and the "no results found" page of search engines is virtually never seen anymore. At the historical scale of computer science, the Web has not only uniquely proven itself as an architecture that has passed the test of time, it has defined a new era: there is an era before and an era after the Web. An era where the problem was to have information about or access to a service, and an era where the challenge was to find one's self within the overwhelming quantity of information. An era of fragmentation, and then an era of hyper-integration, even over-integration, with the risks that that entails.</p><p>But the defense of the Web remains necessary. It is universally useful and used, but it remains fragile, and its initial ideals could prove to be just a passing phase if we do not constantly keep watch on their preservation. Tim Berners-Lee is still fighting today against all forms of re-centralization. The stakes (neutrality, decentralization, democratization, etc.), the dangers (re-centralization, levels of access, a Web at different speeds, etc.), limitations (infrastructure needs, energy, costs, etc.) make the Web a never-ending project more than a final achievement. The architecture of the Web is and must remain robust, even in a hostile environment, neutral, even if its underlying layers are compromised, and resilient, even if the infrastructure is lacking or limited, etc. To protect it, we will have to design the spiders that weave the Web architecture to be extremophile animals.</p><p>Inversely, the Web can itself be perceived as a danger. In 1996, Tim wrote about how the diversifying force provided by geography could be weakened by the Web <ref type="bibr" target="#b3">[4]</ref>. He also drew attention in a general way to the ethical and societal stakes of the Web: he recalled the impact that the choices made concerning Web architecture had on the forms of society in which we were living; the necessity of revisiting the notion of copyright in a space where copying could take on so many forms; the privacy-related problems introduced by the multiple opportunities to capture data; the impact that Web-based information has on a voting population; the necessity of working hand-in-hand with legislative systems; etc. <ref type="bibr" target="#b3">[4]</ref>. These subjects raised in 1996 foreshadowed needs that would be even more urgent two decades later, and the need to actively search for interdisciplinarity in the study of the Web and of its evolution. It is important to understand the Web holistically, in all its complexity, and to encourage the "Web Science" movement towards transdisciplinarity. The three W's of the World Wide Web call for the three M's of a Massive Multidisciplinary Method <ref type="bibr" target="#b15">[16]</ref>.</p><p>Further, the Web must also absolutely become a subject for education and training in itself. Its use (basic principles of browsing, searching, etc.), best practices (critical reading, cross-referenced validation, active contributions, etc.), prevention (protection of privacy, protection of children, etc.), are all subjects that every generation should be taught in school as an important element for equal opportunity.</p><p>Whereas at the beginning, before the Web arrived, the problem was to imagine a world with the Web in it, we are now in the inverse situation where people have forgotten or can no longer imagine that there was a world without the Web <ref type="bibr" target="#b25">[26]</ref>. Our choices in Web architecture do have an impact on our societies and this only increases with every evolution of the Web. We are witnessing profound changes in society, and we need to be constantly vigilant to ensure that the technology that is such an important driver in these changes is being developed as a force for social good, rather than as one that can be used to harm or control or manipulate.</p><p>"The Web as I envisaged it, we have not seen it yet.</p><p>The future is still so much bigger than the past. " -Tim Berners-Lee, 2009</p><p>Note: This paper is based on two previous publications by the authors "The Ever Evolving Web: The Power of Networks" <ref type="bibr" target="#b19">[20]</ref> reflecting on the Web and its evolution and "For Everything" <ref type="bibr" target="#b16">[17]</ref> providing an historical perspective on the Web and its mutations.</p></div>		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<ptr target="http://amturing.acm.org/award_winners/berners-lee_8087960.cfm" />
		<title level="m">Citation Sir Tim Berners-Lee, Turing Award, For inventing the World Wide Web, the first web browser, and the fundamental protocols and algorithms allowing the Web to scale</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">The Hyper-G Network Information System</title>
		<author>
			<persName><forename type="first">Keith</forename><surname>Andrews</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Frank</forename><surname>Kappe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hermann</forename><surname>Maurer</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-642-80350-5_20</idno>
		<ptr target="https://doi.org/10.1007/978-3-642-80350-5_20" />
		<imprint>
			<date type="published" when="1996">1996</date>
			<publisher>Springer</publisher>
			<biblScope unit="page" from="206" to="220" />
			<pubPlace>Berlin Heidelberg, Berlin, Heidelberg</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<author>
			<persName><surname>Berners-Lee</surname></persName>
		</author>
		<ptr target="https://www.w3.org/DesignIssues/Semantic.html" />
		<title level="m">Semantic web road map</title>
		<imprint>
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">WWW: Past, present, and future</title>
		<author>
			<persName><forename type="first">Tim</forename><surname>Berners-Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="69" to="77" />
			<date type="published" when="1996">1996. 1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">The World-Wide Web</title>
		<author>
			<persName><forename type="first">Tim</forename><surname>Berners-Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><surname>Cailliau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ari</forename><surname>Luotonen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Henrik</forename><forename type="middle">Frystyk</forename><surname>Nielsen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arthur</forename><surname>Secret</surname></persName>
		</author>
		<idno type="DOI">10.1145/179606.179671</idno>
		<ptr target="https://doi.org/10.1145/179606.179671" />
	</analytic>
	<monogr>
		<title level="j">Commun. ACM</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="76" to="82" />
			<date type="published" when="1994-08">1994. Aug. 1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Weaving the Web: The original design and ultimate destiny of the World Wide Web by its inventor</title>
		<author>
			<persName><forename type="first">Tim</forename><surname>Berners</surname></persName>
		</author>
		<author>
			<persName><forename type="first">-</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><surname>Fischetti</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001">2001</date>
			<publisher>DIANE Publishing Company</publisher>
			<pubPlace>Collingdale, PA 19023, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Information management: A proposal</title>
		<author>
			<persName><forename type="first">Timothy</forename><forename type="middle">J</forename><surname>Berners-Lee</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1989">1989</date>
		</imprint>
		<respStmt>
			<orgName>CERN</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">As we may think</title>
		<author>
			<persName><forename type="first">Vannevar</forename><surname>Bush</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The atlantic monthly</title>
		<imprint>
			<biblScope unit="volume">176</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="101" to="108" />
			<date type="published" when="1945">1945. 1945</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A protocol for packet network intercommunication</title>
		<author>
			<persName><forename type="first">Vinton</forename><surname>Cerf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><surname>Kahn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on communications</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="637" to="648" />
			<date type="published" when="1974">1974. 1974</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<ptr target="https://timeline.web.cern.ch/timelines/The-birth-of-the-World-Wide-Web" />
		<title level="m">The birth of the World Wide Web</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
		<respStmt>
			<orgName>CERN ; CERN</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Hypertext: An Introduction and SurvevJ</title>
		<author>
			<persName><forename type="first">Jeff</forename><surname>Conklin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE computer</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="17" to="41" />
			<date type="published" when="1987">1987. 1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A research center for augmenting human intellect</title>
		<author>
			<persName><forename type="first">C</forename><surname>Douglas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><forename type="middle">K</forename><surname>Engelbart</surname></persName>
		</author>
		<author>
			<persName><surname>English</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the December 9-11, 1968, fall joint computer conference, part I</title>
		<meeting>the December 9-11, 1968, fall joint computer conference, part I<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1968">1968</date>
			<biblScope unit="page" from="395" to="410" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<author>
			<persName><forename type="first">Roy</forename><surname>Fielding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jim</forename><surname>Gettys</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeffrey</forename><surname>Mogul</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Henrik</forename><surname>Frystyk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Larry</forename><surname>Masinter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paul</forename><surname>Leach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tim</forename><surname>Berners-Lee</surname></persName>
		</author>
		<idno>RFC7231</idno>
		<title level="m">Hypertext transfer protocol-HTTP/1.1</title>
		<imprint>
			<date type="published" when="1999">1999</date>
		</imprint>
		<respStmt>
			<orgName>IETF</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Principled Design of the Modern Web Architecture</title>
		<author>
			<persName><forename type="first">Roy</forename><forename type="middle">T</forename><surname>Fielding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><forename type="middle">N</forename><surname>Taylor</surname></persName>
		</author>
		<idno type="DOI">10.1145/514183.514185</idno>
		<ptr target="https://doi.org/10.1145/514183.514185" />
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Internet Technol</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="115" to="150" />
			<date type="published" when="2002">2002. 2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">MICRO-COSM: An Open Model for Hypermedia with Dynamic Linking</title>
		<author>
			<persName><forename type="first">Wendy</forename><surname>Andrew M Fountain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ian</forename><surname>Hall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hugh</forename><forename type="middle">C</forename><surname>Heath</surname></persName>
		</author>
		<author>
			<persName><surname>Davis</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1990">1990</date>
			<biblScope unit="page" from="298" to="311" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">The three &apos;W&apos; of the World Wide Web call for the three &apos;M&apos; of a Massively Multidisciplinary Methodology</title>
		<author>
			<persName><forename type="first">Fabien</forename><surname>Gandon</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-319-27030-2</idno>
		<ptr target="https://doi.org/10.1007/978-3-319-27030-2" />
	</analytic>
	<monogr>
		<title level="m">WEBIST 2014 -10th International Conference (Web Information Systems and Technologies</title>
		<editor>
			<persName><forename type="first">Valérie</forename><surname>Monfort</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Karl-Heinz</forename><surname>Krempels</surname></persName>
		</editor>
		<meeting><address><addrLine>Barcelona, Spain</addrLine></address></meeting>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="volume">226</biblScope>
			<biblScope unit="page" from="3" to="15" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">For everything: Tim Berners-Lee, winner of the 2016 Turing award for having invented</title>
		<author>
			<persName><forename type="first">Fabien</forename><surname>Gandon</surname></persName>
		</author>
		<ptr target="https://hal.inria.fr/hal-01843967" />
	</analytic>
	<monogr>
		<title level="j">Bulletin de la Société Informatique de France</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page">21</biblScope>
			<date type="published" when="1024-09">2017. 1024. Sept. 2017</date>
		</imprint>
	</monogr>
	<note>the Web</note>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<author>
			<persName><forename type="first">James</forename><surname>James M Gillies</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Gillies</surname></persName>
		</author>
		<author>
			<persName><surname>Cailliau</surname></persName>
		</author>
		<title level="m">How the Web was born: The story of the World Wide Web</title>
		<meeting><address><addrLine>USA; Madison Avenue New York, NY</addrLine></address></meeting>
		<imprint>
			<publisher>Oxford University Press</publisher>
			<date type="published" when="2000">2000. 10016</date>
			<biblScope unit="volume">198</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Through the Lens of the Web Conference Series: A Look Into the History of &quot;the Web</title>
		<author>
			<persName><forename type="first">Damien</forename><surname>Graux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fabrizio</forename><surname>Orlandi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of The Web Conference 2020</title>
		<meeting>The Web Conference 2020<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Network Theory| The Ever Evolving Web: The Power of Networks</title>
		<author>
			<persName><forename type="first">Wendy</forename><surname>Hall</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Communication</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">14</biblScope>
			<date type="published" when="2011">2011. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<author>
			<persName><forename type="first">Ted</forename><surname>Nelson</surname></persName>
		</author>
		<title level="m">Literary Machines</title>
		<meeting><address><addrLine>Sausalito, California</addrLine></address></meeting>
		<imprint>
			<publisher>Mindful Press</publisher>
			<date type="published" when="1981">1981</date>
		</imprint>
	</monogr>
	<note>3rd ed.</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Complex information processing: a file structure for the complex, the changing and the indeterminate</title>
		<author>
			<persName><forename type="first">H</forename><surname>Theodor</surname></persName>
		</author>
		<author>
			<persName><surname>Nelson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1965 20th national conference</title>
		<meeting>the 1965 20th national conference<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1965">1965</date>
			<biblScope unit="page" from="84" to="100" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Presentation and major design aspects of the CYCLADES computer network</title>
		<author>
			<persName><forename type="first">Louis</forename><surname>Pouzin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the third ACM symposium on Data communications and Data networks: Analysis and design</title>
		<meeting>the third ACM symposium on Data communications and Data networks: Analysis and design<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1973">1973</date>
			<biblScope unit="page" from="80" to="87" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Design and implementation of the system 33 document service</title>
		<author>
			<persName><forename type="first">Steve</forename><surname>Putz</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">P. Otlet&apos;s Mundaneum and the international perspective in the history of documentation and information science</title>
		<author>
			<persName><forename type="first">Isabelle</forename><surname>Rieusset-Lemarié</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Society for information science</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="301" to="309" />
			<date type="published" when="1997">1997. 1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Weaving the Web</title>
		<author>
			<persName><forename type="first">Neil</forename><surname>Savage</surname></persName>
		</author>
		<idno type="DOI">10.1145/3077334</idno>
		<ptr target="https://doi.org/10.1145/3077334" />
	</analytic>
	<monogr>
		<title level="j">Commun. ACM</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="20" to="22" />
			<date type="published" when="2017-05">2017. May 2017</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
