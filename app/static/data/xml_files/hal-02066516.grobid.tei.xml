<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Transparency, Fairness, Data Protection, Neutrality: Data Management Challenges in the Face of New Regulation</title>
				<funder ref="#_J6UvhCR">
					<orgName type="full">National Science Foundation</orgName>
					<orgName type="abbreviated">NSF</orgName>
				</funder>
				<funder ref="#_kJJTC8X">
					<orgName type="full">Agence Nationale de la Recherche</orgName>
					<orgName type="abbreviated">ANR</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2019-03-08">8 Mar 2019</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Serge</forename><surname>Abiteboul</surname></persName>
							<email>serge.abiteboul@inria.fr</email>
						</author>
						<author>
							<persName><forename type="first">Julia</forename><surname>Stoyanovich</surname></persName>
							<email>stoyanovich@nyu.edu.</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Inria</orgName>
								<orgName type="institution" key="instit2">Ecole Normale Supérieure</orgName>
								<address>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">JULIA STOYANOVICH</orgName>
								<orgName type="institution">New York University</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="institution" key="instit1">Inria</orgName>
								<orgName type="institution" key="instit2">Ecole Normale Supérieure</orgName>
								<address>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="institution">New York University</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Transparency, Fairness, Data Protection, Neutrality: Data Management Challenges in the Face of New Regulation</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2019-03-08">8 Mar 2019</date>
						</imprint>
					</monogr>
					<idno type="MD5">F90CC7B465AE3555F1A4CBD88040EC37</idno>
					<idno type="DOI">10.1145/3310231</idno>
					<idno type="arXiv">arXiv:1903.03683v1[cs.DB]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-04-12T14:46+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>CCS Concepts:</term>
					<term>Information systems → Data management systems</term>
					<term>• Social and professional topics → Computing / technology policy</term>
					<term>Technology audits</term>
					<term>• Applied computing → Law</term>
					<term>transparency</term>
					<term>fairness</term>
					<term>data protection</term>
					<term>neutrality</term>
					<term>responsible data science</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The data revolution continues to transform every sector of science, industry and government. Due to the incredible impact of datadriven technology on society, we are becoming increasingly aware of the imperative to use data and algorithms responsibly -in accordance with laws and ethical norms. In this article we discuss three recent regulatory frameworks: the European Union's General Data Protection Regulation (GDPR), the New York City Automated Decisions Systems (ADS) Law, and the Net Neutrality principle, that aim to protect the rights of individuals who are impacted by data collection and analysis. These frameworks are prominent examples of a global trend: Governments are starting to recognize the need to regulate data-driven algorithmic technology.</p><p>Our goal in this paper is to bring these regulatory frameworks to the attention of the data management community, and to underscore the technical challenges they raise and which we, as a community, are well-equipped to address. The main take-away of this article is that legal and ethical norms cannot be incorporated into data-driven systems as an afterthought. Rather, we must think in terms of responsibility by design, viewing it as a systems requirement.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>The data revolution continues to transform every sector of science, industry and government. Due to the incredible impact of data-driven technology on society, we are becoming increasingly aware of the imperative to use data and algorithms responsibly -in accordance with laws and ethical norms. The goal of this article is to underscore the technical challenges raised by recent legal and regulatory frameworks, which the data management community is well-equipped to address.</p><p>We discuss three recent frameworks: the European Union's General Data Protection Regulation (GDPR) [The European Union 2016], the New York City Automated Decisions Systems (ADS) Law <ref type="bibr">[The New York City Council 2017]</ref>, and the Net Neutrality principle. These frameworks are prominent examples of a global trend: Governments are starting to recognize the need to regulate data-driven algorithmic technology. The GDPR and the NYC ADS Law aim to protect the rights of individuals who are impacted by data collection and analysis, while the Net Neutrality principle ensures that services are being treated equitably. Yet, despite the focus on organizations, rights of individuals also figure prominently in the neutrality debate: One of the imperatives is that individuals should be able to enjoy freedom of choice and expression on-line. We will give some legal context on neutrality by discussing the EU Regulation 2015/2120 [The European <ref type="bibr">Parliament AND Council 2015]</ref>, the Indian Net Neutrality Regulatory Framework [Government of <ref type="bibr">India, Ministry 2018]</ref>, and the ongoing regulatory debate on Net Neutrality in the US.</p><p>Our goal in this paper is to bring these regulatory frameworks to the attention of the data management community. The main take-away of this article is that legal norms cannot be incorporated into data-driven systems as an afterthought. Rather, we must think in terms of responsibility by design, viewing it as a systems requirement.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1">The General Data Protection Regulation</head><p>The European Union recently enacted a sweeping regulatory framework known as the General Data Protection Regulation, or the GDPR [The European <ref type="bibr">Union 2016]</ref>. The regulation was adopted in April 2016, and became enforceable about two years later, on May 25, 2018. The GDPR aims to protect the rights and freedoms of natural persons with regard to how their personal data is processed, moved and exchanged (Article 1). The GDPR is broad in scope, and applies to "the processing of personal data wholly or partly by automated means" (Article 2), both in the private sector and in the public sector. Personal data is broadly construed, and refers to any information relating to an identified or identifiable natural person, called the data subject (Article 4). In this article we focus on the following salient points of the regulation:</p><p>• lawful processing of data is predicated on the data subject's informed consent, stating whether their personal data can be used, and for what purpose (Articles 6, 7);</p><p>• the data subject has a right to correct any errors in their data ("right to rectification", Article 16), to withdraw their data from the system ("right to erasure", Article 17), and to move data from one data processor to another ("right to portability", Article 20);</p><p>• the data subject has the right to be informed about the collection and use of their data. 1</p><p>The primary focus of the GDPR is on protecting the rights of data subjects, by giving them insight into, and control over, the collection and processing of their personal data. Providing insight, in response to the "right to be informed", requires technical methods for algorithmic and data transparency, which we will discuss in Section 2. We will also discuss the challenges inherent in giving individuals an ability to erase or move their data in Section 4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2">The New York City Algorithmic Decision Systems Law</head><p>New York City recently passed a law [The New York City Council 2017] requiring that a task force be put in place to survey the current use of "automated decision systems" (ADS), defined as "computerized implementations of algorithms, including those derived from machine learning or other data processing or artificial intelligence techniques, which are used to make or assist in making decisions, " in City agencies. The task force is working to develop a set of recommendations for enacting algorithmic transparency by the agencies, and will propose procedures for:</p><p>• requesting and receiving an explanation of an algorithmic decision affecting an individual (Section 3 (b));</p><p>1 https://gdpr-info.eu/issues/right-to-be-informed/</p><p>• interrogating automated decision systems for bias and discrimination against members of legally protected groups, and addressing instances in which a person is harmed based on membership in such groups (Sections 3 (c) and (d));</p><p>• assessing how automated decision systems function and are used, and archiving the systems together with the data they use (Sections 3 (e) and (f)).</p><p>In contrast to the GDPR, which is very broad in scope, the NYC ADS Law only regulates City agencies in their use of algorithms and data, and does not directly apply to private companies. However, because government agencies often procure systems and components from industry partners, the Law will likely impact industry practices. Further, while New York is the first US city to pass a law of this kind, we expect other US municipalities to follow with similar legal frameworks or recommendations in the near future.</p><p>The primary focus of the NYC ADS Law is on algorithmic transparency, which, in turn, cannot be achieved without data transparency <ref type="bibr" target="#b24">[Stoyanovich and Howe 2018</ref>]. As we discussed in Section 1.1, transparency is also an implicit requirement of the GDPR, stemming from the "right to be informed". We will discuss the role that the data management community can play in enabling data transparency in Section 2.</p><p>The NYC ADS Law further requires fair and equitable treatment of individuals, mandating that ADS safeguard against bias and discrimination, and provide transparency in this regard. We will discuss fairness in Section 3, and will propose some research directions for the data management community that are complementary to the rich and rapidly expanding body of work on fairness in machine learning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.3">The Net Neutrality Principle</head><p>Net Neutrality is the principle that Internet Service Providers (ISPs) should not discriminate or charge differently based on the message source (the content provider), its destination (the user), or its content. The concept was articulated by Tim Wu in 2003 <ref type="bibr" target="#b28">[Wu 2003</ref>].</p><p>According to Net Neutrality, an ISP cannot block or throttle video streams from YouTube (negative discrimination), or enable free access to Facebook out of package (a kind of positive discrimination). A September 2018 report from Northeastern University and the University of Massachusetts, Amherst, found that US telecommunications companies are indeed slowing internet traffic to and from those two sites in particular, along with other popular apps <ref type="bibr" target="#b14">[Kharif 2018;</ref><ref type="bibr" target="#b20">Molavi Kakhki et al. 2015</ref>]. Of course, there are limits to the non-discrimination, such as blocking pornographic material for young Internet users, filtering hate speech in some countries, or guaranteeing quality for emergency services.</p><p>In ProPublica's story on "machine bias" in an algorithm used for sentencing defendants <ref type="bibr" target="#b2">[Angwin et al. 2016</ref>] amplified calls to make algorithms more transparent and accountable <ref type="bibr" target="#b17">[Kroll et al. 2017]</ref>. Transparency and accountability are intrinsically linked with trust, and are of particular importance when algorithmic systems are integrated into government processes, assisting humans in their decision-making tasks, and sometimes even replacing humans. Transparency of government is a core democratic value, which compels us to develop technological solutions that both increase government efficiency and can be made transparent to the public.</p><p>A narrow interpretation of algorithmic transparency requires that the source code of a system be made publicly available. This is a significant step towards transparency (as long as the posted code is readable, well-documented and complete), but it is rarely sufficient. One of the reasons for this, of particular relevance to the data management community, is that meaningful transparency of algorithmic processes cannot be achieved without transparency of data <ref type="bibr" target="#b24">[Stoyanovich and Howe 2018]</ref>.</p><p>What is data transparency, and how can we achieve it? One immediate interpretation of this term in the context of predictive analytics includes "making the training and validation datasets publicly available. " However, while data should be made open whenever possible, much of it is sensitive and cannot be shared directly. That is, data transparency is in tension with the privacy of individuals who are included in the dataset. In light of this, we may adopt the following alternative interpretation of data transparency: In addition to releasing training and validation datasets whenever possible, vendors should make publicly available summaries of relevant statistical properties of the datasets that can aid in interpreting the decisions made using this data, while applying state-of-the-art methods to preserve the privacy of individuals (such as differential privacy <ref type="bibr" target="#b7">[Dwork and Roth 2014]</ref>). When appropriate, privacy-preserving synthetic datasets can be released in lieu of real datasets to expose certain features of the data <ref type="bibr" target="#b21">[Ping et al. 2017</ref>].</p><p>An important aspect of data transparency is interpretability -surfacing the statistical properties of a dataset, the methodology that was used to produce it, and, ultimately, substantiating its "fitness for use" in the context of a specific automated decision system or task. This consideration of a specific use is particularly important because datasets are increasingly used outside the original context for which they were intended. The data management community can begin addressing these challenges by building on the significant body of work on data profiling (see <ref type="bibr" target="#b0">[Abedjan et al. 2017</ref>] for a recent tutorial), with an eye on the new legal requirements.</p><p>Interpretability rests on making explicit the interactions between the program and the data on which it acts. This property is important both when an automated decision system is interrogated for systematic bias and discrimination, and when it is asked to explain an algorithmic decision that affects an individual. For example, suppose that a system scores and ranks individuals for access to a service. If an individual enters her data and receives the result -say, a score of 42 -this number alone provides no information about why she was scored in this way, how she compares to others, and what she can do to potentially improve her outcome. A prominent example of a system of this kind, which is both opaque and extremely impactful, is the FICO credit scoring system in the US <ref type="bibr" target="#b4">[Citron and Pasquale 2014]</ref>.</p><p>The data management research community is well-positioned to contribute to developing new methods for interpretability. These new contributions can naturally build on a rich body of work on data provenance (see <ref type="bibr" target="#b11">[Herschel et al. 2017</ref>] for a recent survey), on recent work on explaining classifiers <ref type="bibr" target="#b22">[Ribeiro et al. 2016</ref>] and auditing black box models using causal framework <ref type="bibr" target="#b5">[Datta et al. 2016</ref>], and on automatically generating "nutritional labels" for data and models <ref type="bibr" target="#b29">[Yang et al. 2018</ref>].</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">FAIRNESS</head><p>We can all agree that algorithmic decision-making should be fair, even if we do not agree on the definition of fairness.</p><p>But isn't this about algorithm design? Why is this a data problem? Indeed, the machine learning and data mining research communities are actively working on methods for enabling fairness of specific algorithms and their outputs, with a particular focus on classification problems (see, for example, <ref type="bibr" target="#b6">[Dwork et al. 2012;</ref><ref type="bibr" target="#b8">Feldman et al. 2015;</ref><ref type="bibr" target="#b9">Friedler et al. 2016;</ref><ref type="bibr" target="#b10">Hajian and Domingo-Ferrer 2013;</ref><ref type="bibr" target="#b13">Kamiran et al. 2013;</ref><ref type="bibr" target="#b16">Kleinberg et al. 2017;</ref><ref type="bibr" target="#b23">Romei and Ruggieri 2014]</ref> and proceedings of the recently established ACM Conference on Fairness, Accountability, and Transparency (ACM FAT*)<ref type="foot" target="#foot_0">2</ref> ). While important, these approaches focus solely on the final step in the data science lifecycle, and are thus limited by the assumption that input datasets are clean and reliable.</p><p>Data-driven algorithmic decision making usually requires multiple pre-processing stages to address messy input and render it ready for analysis <ref type="bibr" target="#b12">[Jagadish et al. 2014</ref>]. This pre-processing, which includes data cleaning, integration, querying and ranking, is often the source of algorithmic bias <ref type="bibr" target="#b15">[Kirkpatrick 2017;</ref><ref type="bibr" target="#b25">Stoyanovich et al. 2017]</ref>, and so reasoning about sources of bias, and mitigating unfairness upstream from the final step of data analysis, is potentially more impactful.</p><p>For example, much research goes into ensuring statistical parity -a requirement that the demographics of those receiving a particular outcome, (e.g., a positive or negative classification), are identical to the demographics of the population as a whole. Suppose that the input to a binary classifier contains 900 men and 100 women, but that it is known that women represent 50% of the over-all population, and so achieving statistical parity amounts to enforcing a 50-50 gender balance among the positively classified individuals. That is, all else being equal, a woman in the input to the classifier is far more likely to receive a positive classification than a man. An alternative is to observe the following:</p><p>If the input to the classifier was produced by a SQL query, and if relaxing the query would make the input more balanced (e.g., 1000 men and 500 women), then a more effective way to mitigate the lack of statistical parity in the output of the classifier is to relax the query upstream.</p><p>It is easy to construct additional examples that show how bias may be introduced during data cleaning, data integration, querying, and ranking -upstream from the final stage of data analysis. Therefore, it is meaningful to detect and mitigate these effects in the data lifecycle stages in which they occur. (See <ref type="bibr" target="#b19">[Mitchell et al. 2018</ref>] for a discussion of the definitions of "bias", and of the corresponding assumptions made when defining fairness measures.)</p><p>Members of the data management community who are interested in this topic may consider a growing body of work on impossibility results, which show that different notions of fairness cannot be enforced simultaneously, and so require explicit trade-offs <ref type="bibr" target="#b3">[Chouldechova 2017;</ref><ref type="bibr" target="#b9">Friedler et al. 2016;</ref><ref type="bibr" target="#b16">Kleinberg et al. 2017</ref>]. These are not negative results per se, nor are they surprising. Fairness is a subjective, context-dependent and highly politicized concept; a global consensus on what is fair is unlikely to emerge, in the context of algorithmic decision making or otherwise. Think, for example, of the decade-long debate about the interplay between "disparate treatment" and "disparate impact", for which recent examples include by Ricci v. De Stefano<ref type="foot" target="#foot_1">3</ref> and the ongoing lawsuit regarding the use of race in Harvard University admissions<ref type="foot" target="#foot_2">4</ref> . That being said, a productive way to move forward in the data science context is to develop methods that can be instrumented with different alternative fairness notions, and that can support principled and transparent trade-offs between these notions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">MOVING AND REMOVING PERSONAL DATA</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">The Right to Be Forgo en</head><p>The right to be forgotten is originally motivated by the desire of individuals to not be perpetually stigmatized by something they did in the past. Under pressure from despicable social phenomena such as revenge porn, it was turned recently into laws in 2006 in Argentina, and since then in the European Union, as part of the GDPR. In particular, Article 17 of the GDPR states that data subjects have the right to request erasure of their personal data, and that they can do so for a large number of reasons.</p><p>The passing of this law primarily resulted in a high number of requests to search engines to dereference web pages.</p><p>This turned out to be controversial for a number of reasons, including also that the dereferencing by Google is very opaque, and that this company in effect acquired, against its own will, a questionable power to adjudicate. Furthermore, as is advocated by Wikimedia among others, the right to be forgotten sometimes conflicts with other rights such as the public's right to information.</p><p>In addition to search engines, the right to be forgotten affects companies that keep personal data. A prominent example is Facebook, where for many years it was impossible to delete data that pertains to a user's account. A user may close an account, then reopen it some time later and find all her data as it was originally. It is now possible to request the deletion of all data pertaining to an account from Facebook, however, the user has no proof that the deletion indeed occurred.</p><p>An important technical issue, of clear relevance to the data management community, is that of deletion of information in systems that are typically meant to accumulate data. This deletion must be both permanent and deep, in the sense that its effects must propagate through data dependencies. To start, it is difficult to guarantee that all copies of every piece of deleted data have actually been deleted. Further, when some data is deleted, the remaining database may become inconsistent, and may, for example, include dangling pointers. Additionally, production systems typically do not include a strong provenance mechanism, and so they have no means of tracking the use of an arbitrary data item (one to be deleted), and reasoning about the dependencies on that data item in derived data products.</p><p>Although much attention of the data management community has over the years been devoted to tracking and reasoning about provenance, primarily in relational contexts and in workflows (see <ref type="bibr" target="#b11">[Herschel et al. 2017</ref>] for a recent survey), there is still important work to be done on making these methods both practically feasible, and sufficiently general to accommodate the current legal requirements. An important direction that is, to the best of our knowledge, still unexplored, concerns ascertaining the effects of a deletion on downstream processes that are not purely relational, but include other kinds of data analysis tasks, like data mining or predictive analytics.</p><p>Requests for deletion may also conflict with other laws such as requirements to keep certain transaction data for some period of time, or with requirements for fault tolerance and recoverability. Should the deleted pieces of data also be erased from caches and backups? Requesting this functionality gives immediate nightmares to systems engineers in charge of a production data management system, with millions of lines of code and terabytes of legacy data. The likely answer is: "this cannot be done; the only solution I see is redeveloping the system from scratch with right-tobe-forgotten-by-design. " Understanding the impact of deletion requests on our ability to offer guarantees on system resilience and performance, and developing appropriate primitives and protocols for practical use, is another call to action for the data management community.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Interoperability and Portability</head><p>Article 20 of the GDPR, "Right to data portability", stipulates a data subject's right to receive her personal data from a vendor, and to transfer her data to another vendor. The main goals of this provision are both to keep the data subject informed about what data a vendor has about her, and to prevent vendor lock-in. This enables a user who is unhappy with a service to leave for a competing service that best serves her needs, without having to reconstruct her entire data history. This also allows a user to select applications of her choice and have them cooperate, to her best advantage, even if they come from different vendors.</p><p>In response to data portability regulation, and to users' concerns, Google, Twitter, Microsoft, and Facebook teamed up in the Data Transfer Project that aims to facilitate content transfer between applications. Of course, it is not an easy task for a company to provide a service that facilitates the departure of its customers. This is why, in spite of commendable behavior of companies that engage in the Data Transfer Project, it is the role of regulators to impose data portability and interoperability requirements.</p><p>Interoperability of database applications is an old topic. But one can imagine an unlimited number of possibilities, such as having a Whatsapp call talk to a Skype one. And it certainly acquires a different flavor when we consider interoperating applications with billions of users and millions of transactions per second.</p><p>For data portability, it should be noted that the devil is in the detail. The export format should be stable and structured to facilitate reuse. Also, which data can be exported is an issue. Obviously, it includes all data that the user volunteered to the service. But should it also include data the vendor gathered from the behavior of the user (e.g., the time the user is waking up in the morning)? Should it include data the service inferred (e.g., what is the home address of the user, her job address)?</p><p>Another issue with portability is the target system. A user may want to port her photos from Service A to Service B. The issue is then for Service B to be able to incorporate as much data as possible from Service A. Now, the user may want to integrate her photos in a personal information system <ref type="bibr" target="#b1">[Abiteboul et al. 2015</ref>]. Such a system must be able to integrate information from a large panel of domains. This brings us to the fields of data integration <ref type="bibr" target="#b18">[Lenzerini 2002]</ref> and knowledge representation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">NEUTRALITY</head><p>As already mentioned, Net Neutrality is now legally required in some countries. Yet, detecting Net Neutrality violations to enforce the law is not an easy task. Indeed, simply measuring the performance of Internet communications is not easy: measurement results may depend on the location of the source, of the target, of the context (other applications competing for the same bandwidth), and on other factors. Indeed, different measures provided for network traffic typically diverge. The evaluation of Net Neutrality relying on such hard-to-obtain measures is a challenging research topic <ref type="bibr" target="#b20">[Molavi Kakhki et al. 2015]</ref>, which is primarily of interest to the networks and Internet measurement communities, and less so to data management.</p><p>But beyond Net Neutrality, new forms of neutrality are emerging such as device neutrality (is my smart-phone blocking certain apps and favoring others?), and platform neutrality (is this particular web service providing neutral recommendation?). For instance, app stores like Google Play and the Apple App Store, tend to refuse to reference certain services, perhaps because they are competing with the company's own services. Research is needed to be able to verify these new facets of neutrality. In particular, it is not easy to check whether a recommendation engine like Google search or Booking is enforcing only transparent editorial policies, and whether, other than that, their results are comprehensive, impartial and based solely on relevance. For example, it has been observed that search engines tend to favor some "friendly" services over competitors<ref type="foot" target="#foot_3">5</ref> .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">TAKE-AWAYS</head><p>In this article, we discussed several recent regulatory frameworks that aim to protect the rights of individuals, to ensure equitable treatment of services, and to bring transparency to data-driven algorithmic processes in industry and in government. Our goal was to bring these regulatory frameworks to the attention of the data management community, and to underscore the technical challenges they raise and which we, as a community, are well-equipped to address.</p><p>An important take-away of this article is that legal norms cannot be incorporated into data-driven systems as an afterthought. Rather, we must think in terms of responsibility by design, viewing it as a systems requirement.</p><p>We also stress that enacting algorithmic and data transparency, fairness, data protection, and neutrality will require a significant cultural shift. In making this shift, we must accept that the objectives of "efficiency", "accuracy" and "utility" cannot be the primary goal, but that they must be balanced with equitable treatment of members of historically disadvantaged groups, and with accountability and transparency to individuals affected by algorithmic decisions and to the general public.</p><p>In this article we focused on explicit regulation of industry stakeholders by government entities (in the case of the GDPR and the Net Neutrality laws), and on government oversight (in the case of the NYC ADS law). Another implicit regulatory mechanism can be achieved by empowering users and user associations, by providing them with data literacy education and with precise information on how different products and services work. Better educated users can choose better solutions, including more effective ways to protect their private data. Such users can also more easily understand explanations provided to them by an algorithmic system. User associations can help individuals make informed choices, and support them via class actions lawsuits in the case of disputes.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>the European Union, Net Neutrality is guaranteed by EU Regulation 2015/2120 [The European Parliament AND Council 2015], although different countries may interpret the regulation differently. For example, some forms of zero-rating, the practice of providing Internet access without financial cost as a means of positive discrimination, are legal in some EU countries but not in others. Since 2018, India has perhaps the world's strongest Net Neutrality rules [Government of India, Ministry of Communication 2018]. In general, more and more countries are adopting Net Neutrality regulations, with a notable exception. In the United States, the Federal Communications Commission (FCC) issued its Open Internet Order in 2015, reclassifying Internet access -previously classified as an information service -as a common carrier telecommunications service, thereby enforcing some form of Net Neutrality. However, in 2017, under the chairmanship of Ajit Pai, the FCC officially repealed Net Neutrality rules.</figDesc></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_0"><p>https://www.fatconference.org/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_1"><p>https://en.wikipedia.org/wiki/Ricci_v._DeStefano</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_2"><p>https://www.nytimes.com/2018/10/13/us/harvard-affirmative-action-asian-students.html</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_3"><p>https://en.m.wikipedia.org/wiki/European_Union_vs._Google</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>ACKNOWLEDGMENTS</head><p>This work was supported in part by <rs type="funder">National Science Foundation (NSF)</rs> Grant No. <rs type="grantNumber">1741047</rs>, and by <rs type="funder">Agence Nationale de la Recherche (ANR)</rs> Grant <rs type="projectName">Headwork</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_J6UvhCR">
					<idno type="grant-number">1741047</idno>
				</org>
				<org type="funded-project" xml:id="_kJJTC8X">
					<orgName type="project" subtype="full">Headwork</orgName>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Data Profiling: A Tutorial</title>
		<author>
			<persName><forename type="first">Lukasz</forename><surname>Ziawasch Abedjan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Felix</forename><surname>Golab</surname></persName>
		</author>
		<author>
			<persName><surname>Naumann</surname></persName>
		</author>
		<idno type="DOI">10.1145/3035918.3054772</idno>
		<ptr target="http://dx.doi.org/10.1145/3035918.3054772" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 ACM International Conference on Management of Data, SIGMOD Conference 2017</title>
		<meeting>the 2017 ACM International Conference on Management of Data, SIGMOD Conference 2017<address><addrLine>Chicago, IL, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017-05-14">2017. May 14-19, 2017</date>
			<biblScope unit="page" from="1747" to="1751" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Managing Your Digital Life</title>
		<author>
			<persName><forename type="first">Serge</forename><surname>Abiteboul</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>André</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Kaplan</surname></persName>
		</author>
		<idno type="DOI">10.1145/2670528</idno>
		<ptr target="http://dx.doi.org/10.1145/2670528" />
	</analytic>
	<monogr>
		<title level="j">Commun. ACM</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="32" to="35" />
			<date type="published" when="2015-04">2015. April 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Machine Bias: Risk Assessments in Criminal Sentencing</title>
		<author>
			<persName><forename type="first">Julia</forename><surname>Angwin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeff</forename><surname>Larson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Surya</forename><surname>Mattu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lauren</forename><surname>Kirchner</surname></persName>
		</author>
		<ptr target="https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing" />
	</analytic>
	<monogr>
		<title level="j">ProPublica</title>
		<imprint>
			<date type="published" when="2016-05-23">2016. May 23 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Fair prediction with disparate impact: A study of bias in recidivism prediction instruments</title>
		<author>
			<persName><forename type="first">Alexandra</forename><surname>Chouldechova</surname></persName>
		</author>
		<idno>CoRR abs/1703.00056</idno>
		<ptr target="http://arxiv.org/abs/1703.00056" />
		<imprint>
			<date type="published" when="2017">2017. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">The Scored Society: Due Process for Automated Predictions</title>
		<author>
			<persName><forename type="first">Danielle</forename><forename type="middle">K</forename><surname>Citron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Frank</forename><forename type="middle">A</forename><surname>Pasquale</surname></persName>
		</author>
		<ptr target="http://papers.ssrn.com/sol3/papers.cfm?abstract_id=2376209" />
	</analytic>
	<monogr>
		<title level="j">Washington Law Review</title>
		<imprint>
			<biblScope unit="volume">89</biblScope>
			<date type="published" when="2014">2014. 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Algorithmic Transparency via Quantitative Input Influence: Theory and Experiments with Learning Systems</title>
		<author>
			<persName><forename type="first">Anupam</forename><surname>Datta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shayak</forename><surname>Sen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yair</forename><surname>Zick</surname></persName>
		</author>
		<idno type="DOI">10.1109/SP.2016.42</idno>
		<ptr target="http://dx.doi.org/10.1109/SP.2016" />
	</analytic>
	<monogr>
		<title level="j">IEEE SP</title>
		<imprint>
			<biblScope unit="page" from="598" to="617" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Fairness through awareness</title>
		<author>
			<persName><forename type="first">Cynthia</forename><surname>Dwork</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Moritz</forename><surname>Hardt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Toniann</forename><surname>Pitassi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Omer</forename><surname>Reingold</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><forename type="middle">S</forename><surname>Zemel</surname></persName>
		</author>
		<idno type="DOI">10.1145/2090236.2090255</idno>
		<ptr target="http://dx.doi.org/10.1145/2090236.2090255" />
	</analytic>
	<monogr>
		<title level="m">Innovations in Theoretical Computer Science 2012</title>
		<meeting><address><addrLine>Cambridge, MA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012-01-08">2012. January 8-10, 2012</date>
			<biblScope unit="page" from="214" to="226" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">The Algorithmic Foundations of Differential Privacy</title>
		<author>
			<persName><forename type="first">Cynthia</forename><surname>Dwork</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aaron</forename><surname>Roth</surname></persName>
		</author>
		<idno type="DOI">10.1561/0400000042</idno>
		<ptr target="http://dx.doi.org/10.1561/0400000042" />
	</analytic>
	<monogr>
		<title level="j">Foundations and Trends in Theoretical Computer Science</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">3-4</biblScope>
			<biblScope unit="page" from="211" to="407" />
			<date type="published" when="2014">2014. 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Certifying and Removing Disparate Impact</title>
		<author>
			<persName><forename type="first">Michael</forename><surname>Feldman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sorelle</forename><forename type="middle">A</forename><surname>Friedler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Moeller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carlos</forename><surname>Scheidegger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Suresh</forename><surname>Venkatasubramanian</surname></persName>
		</author>
		<idno type="DOI">10.1145/2783258.2783311</idno>
		<ptr target="http://dx.doi.org/10.1145/2783258.2783311" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
		<meeting>the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining<address><addrLine>Sydney, NSW, Australia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015-08-10">2015. August 10-13, 2015</date>
			<biblScope unit="page" from="259" to="268" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">On the (im)possibility of fairness</title>
		<author>
			<persName><forename type="first">A</forename><surname>Sorelle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carlos</forename><surname>Friedler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Suresh</forename><surname>Scheidegger</surname></persName>
		</author>
		<author>
			<persName><surname>Venkatasubramanian</surname></persName>
		</author>
		<idno>CoRR abs/1609.07236</idno>
		<ptr target="http://www.dot.gov.in/net-neutrality." />
		<imprint>
			<date type="published" when="2016">2016. 2016. 2018. -07-2018. July 31 2018. 29-November-2018</date>
			<publisher>Ministry of Communications</publisher>
		</imprint>
	</monogr>
	<note>DoT Letter on Net Neutrality Regulatory Framework dated 31</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A Methodology for Direct and Indirect Discrimination Prevention in Data Mining</title>
		<author>
			<persName><forename type="first">Sara</forename><surname>Hajian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Josep</forename><surname>Domingo-Ferrer</surname></persName>
		</author>
		<idno type="DOI">10.1109/TKDE.2012.72</idno>
		<ptr target="http://dx.doi.org/10.1109/TKDE.2012" />
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Knowl. Data Eng</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1445" to="1459" />
			<date type="published" when="2013">2013. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A survey on provenance: What for? What form? What from</title>
		<author>
			<persName><forename type="first">Melanie</forename><surname>Herschel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ralf</forename><surname>Diestelkämper</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Houssem</forename><surname>Ben</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lahmar</forename></persName>
		</author>
		<idno type="DOI">10.1007/s00778-017-0486-1</idno>
		<ptr target="http://dx.doi.org/10.1007/s00778-017-0486-1" />
	</analytic>
	<monogr>
		<title level="j">VLDB J</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="881" to="906" />
			<date type="published" when="2017">2017. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Big data and its technical challenges</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">V</forename><surname>Jagadish</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Johannes</forename><surname>Gehrke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexandros</forename><surname>Labrinidis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yannis</forename><surname>Papakonstantinou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jignesh</forename><forename type="middle">M</forename><surname>Patel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Raghu</forename><surname>Ramakrishnan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cyrus</forename><surname>Shahabi</surname></persName>
		</author>
		<idno type="DOI">10.1145/2611567</idno>
		<ptr target="http://dx.doi.org/10.1145/2611567" />
	</analytic>
	<monogr>
		<title level="j">Commun. ACM</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="86" to="94" />
			<date type="published" when="2014">2014. 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Quantifying explainable discrimination and removing illegal discrimination in automated decision making</title>
		<author>
			<persName><forename type="first">Faisal</forename><surname>Kamiran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Indre</forename><surname>Zliobaite</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Toon</forename><surname>Calders</surname></persName>
		</author>
		<idno type="DOI">10.1007/s10115-012-0584-8</idno>
		<ptr target="http://dx.doi.org/10.1007/s10115-012-0584-8" />
	</analytic>
	<monogr>
		<title level="j">Knowl. Inf. Syst</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="613" to="644" />
			<date type="published" when="2013">2013. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">YouTube, Netflix Videos Found to Be Slowed by Wireless Carriers</title>
		<author>
			<persName><forename type="first">Olga</forename><surname>Kharif</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018-09">September 2018. September 2018</date>
			<publisher>Bloomberg</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">It&apos;s Not the Algorithm, It&apos;s the Data</title>
		<author>
			<persName><forename type="first">Keith</forename><surname>Kirkpatrick</surname></persName>
		</author>
		<idno type="DOI">10.1145/3022181</idno>
		<ptr target="http://dx.doi.org/10.1145/3022181" />
	</analytic>
	<monogr>
		<title level="j">Commun. ACM</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="21" to="23" />
			<date type="published" when="2017-01">2017. Jan. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Inherent Trade-Offs in the Fair Determination of Risk Scores</title>
		<author>
			<persName><forename type="first">Jon</forename><forename type="middle">M</forename><surname>Kleinberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sendhil</forename><surname>Mullainathan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Manish</forename><surname>Raghavan</surname></persName>
		</author>
		<idno type="DOI">10.4230/LIPIcs.ITCS.2017.43</idno>
		<ptr target="http://dx.doi.org/10.4230/LIPIcs.ITCS.2017" />
	</analytic>
	<monogr>
		<title level="m">8th Innovations in Theoretical Computer Science Conference, ITCS 2017</title>
		<meeting><address><addrLine>Berkeley, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017-01-09">2017. January 9-11, 2017</date>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="page" from="1" to="43" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Accountable Algorithms</title>
		<author>
			<persName><forename type="first">Joshua</forename><forename type="middle">A</forename><surname>Kroll</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joanna</forename><surname>Huey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Solon</forename><surname>Barocas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Edward</forename><forename type="middle">W</forename><surname>Felten</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joel</forename><forename type="middle">R</forename><surname>Reidenberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">G</forename><surname>Robinson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Harlan</forename><surname>Yu</surname></persName>
		</author>
		<ptr target="http://papers.ssrn.com/sol3/papers.cfm?abstract_id=2765268" />
	</analytic>
	<monogr>
		<title level="j">University of Pennsylvania Law Review</title>
		<imprint>
			<biblScope unit="volume">165</biblScope>
			<date type="published" when="2017">2017. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Data Integration: A Theoretical Perspective</title>
		<author>
			<persName><forename type="first">Maurizio</forename><surname>Lenzerini</surname></persName>
		</author>
		<idno type="DOI">10.1145/543613.543644</idno>
		<ptr target="http://dx.doi.org/10.1145/543613.543644" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-first ACM SIGMOD-SIGACT-SIGART Symposium on Principles of Database Systems (PODS &apos;02)</title>
		<meeting>the Twenty-first ACM SIGMOD-SIGACT-SIGART Symposium on Principles of Database Systems (PODS &apos;02)<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="233" to="246" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Prediction-Based Decisions and Fairness: A Catalogue of Choices, Assumptions, and Definitions</title>
		<author>
			<persName><forename type="first">Shira</forename><surname>Mitchell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><surname>Potash</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Solon</forename><surname>Barocas</surname></persName>
		</author>
		<idno>CoRR abs/1811.07867</idno>
		<ptr target="https://arxiv.org/abs/1811.07867" />
		<imprint>
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Identifying Traffic Differentiation in Mobile Networks</title>
		<author>
			<persName><forename type="first">Arash</forename><surname>Molavi Kakhki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abbas</forename><surname>Razaghpanah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anke</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hyungjoon</forename><surname>Koo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rajesh</forename><surname>Golani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Choffnes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Phillipa</forename><surname>Gill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alan</forename><surname>Mislove</surname></persName>
		</author>
		<idno type="DOI">10.1145/2815675.2815691</idno>
		<ptr target="http://dx.doi.org/10.1145/2815675.2815691" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Internet Measurement Conference (IMC &apos;15)</title>
		<meeting>the 2015 Internet Measurement Conference (IMC &apos;15)<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="239" to="251" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">DataSynthesizer: Privacy-Preserving Synthetic Datasets</title>
		<author>
			<persName><forename type="first">Haoyue</forename><surname>Ping</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julia</forename><surname>Stoyanovich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bill</forename><surname>Howe</surname></persName>
		</author>
		<idno type="DOI">10.1145/3085504.3091117</idno>
		<ptr target="http://dx.doi.org/10.1145/3085504.3091117" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 29th International Conference on Scientific and Statistical Database Management</title>
		<meeting>the 29th International Conference on Scientific and Statistical Database Management<address><addrLine>Chicago, IL, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017-06-27">2017. June 27-29, 2017</date>
			<biblScope unit="page" from="1" to="42" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Explaining the Predictions of Any Classifier</title>
		<author>
			<persName><forename type="first">Marco</forename><surname>Túlio Ribeiro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sameer</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carlos</forename><surname>Guestrin</surname></persName>
		</author>
		<idno type="DOI">10.1145/2939672.2939778</idno>
		<ptr target="http://dx.doi.org/10.1145/2939672.2939778" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
		<meeting>the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining<address><addrLine>San Francisco, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016-08-13">2016. August 13-17, 2016</date>
			<biblScope unit="page" from="1135" to="1144" />
		</imprint>
	</monogr>
	<note>Why Should I Trust You?</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">A multidisciplinary survey on discrimination analysis</title>
		<author>
			<persName><forename type="first">Andrea</forename><surname>Romei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Salvatore</forename><surname>Ruggieri</surname></persName>
		</author>
		<idno type="DOI">10.1017/S0269888913000039</idno>
		<ptr target="http://dx.doi.org/10.1017/S0269888913000039" />
	</analytic>
	<monogr>
		<title level="j">Knowledge Eng. Review</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="582" to="638" />
			<date type="published" when="2014">2014. 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<author>
			<persName><forename type="first">Julia</forename><surname>Stoyanovich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bill</forename><surname>Howe</surname></persName>
		</author>
		<ptr target="https://ai.shorensteincenter.org/ideas/2018/11/26/follow-the-data-algorithmic-transparency-starts-with-data-transparency" />
		<title level="m">Follow the data! Algorithmic transparency starts with data transparency</title>
		<imprint>
			<date type="published" when="2017">2018. November 27 2018. 19-March-2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Fides: Towards a Platform for Responsible Data Science</title>
		<author>
			<persName><forename type="first">Julia</forename><surname>Stoyanovich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bill</forename><surname>Howe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Serge</forename><surname>Abiteboul</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gerome</forename><surname>Miklau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arnaud</forename><surname>Sahuguet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gerhard</forename><surname>Weikum</surname></persName>
		</author>
		<idno type="DOI">10.1145/3085504.3085530</idno>
		<ptr target="http://dx.doi.org/10.1145/3085504.3085530" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 29th International Conference on Scientific and Statistical Database Management</title>
		<meeting>the 29th International Conference on Scientific and Statistical Database Management<address><addrLine>Chicago, IL, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017-06-27">2017. June 27-29, 2017</date>
			<biblScope unit="page" from="1" to="26" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<ptr target="https://gdpr-info.eu/." />
		<title level="m">General Data Protection Regulation (GDPR)</title>
		<imprint>
			<publisher>The European Union</publisher>
			<date type="published" when="2016-09-28">2016. 2016. 2016. 28-September-2018</date>
			<biblScope unit="volume">679</biblScope>
		</imprint>
	</monogr>
	<note>Regulation (EU</note>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<ptr target="https://laws.council.nyc.gov/legislation/int-1696-2017/." />
		<title level="m">Local Law in relation to automated decision systems used by agencies</title>
		<imprint>
			<publisher>The New York City Council</publisher>
			<date type="published" when="2017-09-28">2017. 2017. 28-September-2018</date>
		</imprint>
	</monogr>
	<note>Int. No. 1696-A: A</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Network Neutrality, Broadband Discrimination</title>
		<author>
			<persName><forename type="first">Tim</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Telecommunications and High Technology Law</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<date type="published" when="2003">2003. 2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">A Nutritional Label for Rankings</title>
		<author>
			<persName><forename type="first">Ke</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julia</forename><surname>Stoyanovich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abolfazl</forename><surname>Asudeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bill</forename><surname>Howe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">V</forename><surname>Jagadish</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gerome</forename><surname>Miklau</surname></persName>
		</author>
		<idno type="DOI">10.1145/3183713.3193568</idno>
		<ptr target="http://dx.doi.org/10.1145/3183713.3193568" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 International Conference on Management of Data, SIGMOD Conference 2018</title>
		<meeting>the 2018 International Conference on Management of Data, SIGMOD Conference 2018<address><addrLine>Houston, TX, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018-06-10">2018. June 10-15, 2018</date>
			<biblScope unit="page" from="1773" to="1776" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
