<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="fr">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main"></title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">E7A7E3F46CE7EFB45E0C85E071AF22C2</idno>
					<note type="submission">Submitted on 17 Jun 2020</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-04-12T14:46+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>est destinée au dépôt et à la diffusion de documents scientifiques de niveau recherche, publiés ou non, émanant des établissements d'enseignement et de recherche français ou étrangers, des laboratoires publics ou privés.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="fr">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Méthodes de Fusion de Cartes de Caractéristiques pour la Détection Multispectrale par Réseaux de Neurones Profonds</head><p>Heng Zhang, Elisa Fromont, Sébastien Lefèvre, Bruno Avignon</p><p>To cite this version: </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Mots clés</head><p>Détection d'objets sur des images multi-spectrales, fusion multi-spectrale, apprentissage profond.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Références</head></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>Méthodes de Fusion de Cartes de Caractéristiques pour la DétectionMultispectrale par Réseaux de Neurones Profonds</figDesc><table><row><cell>Heng ZHANG 1,3</cell><cell>Elisa FROMONT 1,4</cell><cell>Sébastien LEFEVRE 2</cell><cell>Bruno AVIGNON 3</cell></row><row><cell cols="4">1 Univ Rennes, IRISA 2 Univ Bretagne Sud, IRISA 3 ATERMES 4 IUF, Inria</cell></row><row><cell></cell><cell cols="2">heng.zhang@irisa.fr</cell><cell></cell></row><row><cell>Résumé</cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="2">L'utilisation d'images multispectrales (par exemple des</cell><cell></cell><cell></cell></row><row><cell cols="2">paires d'images en bandes spectrales visible et infrarouge)</cell><cell></cell><cell></cell></row><row><cell cols="2">peut s'avérer particulièrement utile lorsque l'on cherche</cell><cell></cell><cell></cell></row><row><cell cols="2">à détecter des objets dans des environnements variés (par</cell><cell></cell><cell></cell></row><row><cell cols="2">exemple des scènes extérieures capturées de jour ou de</cell><cell></cell><cell></cell></row><row><cell cols="2">nuit). Pour utiliser ces différentes bandes spectrales, le</cell><cell></cell><cell></cell></row><row><cell cols="2">principal problème technique est la fusion des informations</cell><cell></cell><cell></cell></row><row><cell cols="2">complémentaires issues des différentes bandes. Si cette fu-</cell><cell></cell><cell></cell></row><row><cell cols="2">sion peut, en théorie, être mise en oeuvre à différents ni-</cell><cell></cell><cell></cell></row><row><cell cols="2">veaux (précoce, intermédiaire, tardive), les méthodes ré-</cell><cell></cell><cell></cell></row><row><cell cols="2">centes d'apprentissage profond ont montré que la fusion</cell><cell></cell><cell></cell></row><row><cell cols="2">à mi-parcours (intermédiaire) dans le réseau était celle</cell><cell></cell><cell></cell></row><row><cell cols="2">donnant le meilleur gain de performances. Cet article pro-</cell><cell></cell><cell></cell></row><row><cell cols="2">pose deux nouvelles approches intitulées PS-Fuse et Cyclic</cell><cell></cell><cell></cell></row><row><cell cols="2">Fuse-and-Refine pour fusionner au mieux les caractéris-</cell><cell></cell><cell></cell></row><row><cell cols="2">tiques multispectrales au sein d'un réseau de neurones pro-</cell><cell></cell><cell></cell></row><row><cell cols="2">fond. Nos expériences montrent que ces deux contributions</cell><cell></cell><cell></cell></row><row><cell cols="2">conduisent à des améliorations significatives de précision</cell><cell></cell><cell></cell></row><row><cell cols="2">par rapport aux méthodes existantes en détection d'objets</cell><cell></cell><cell></cell></row><row><cell cols="2">sur des jeux de données multispectrales.</cell><cell></cell><cell></cell></row></table><note><p>Heng Zhang, Elisa Fromont, Sébastien Lefèvre, Bruno Avignon. Méthodes de Fusion de Cartes de Caractéristiques pour la Détection Multispectrale par Réseaux de Neurones Profonds. RFIAP 2020 -Reconnaissance des Formes, Image, Apprentissage et Perception, Jun 2020, Vannes, France. pp.1-2. hal-02872123</p></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Multispectral pedestrian detection : Benchmark dataset and baselines</title>
		<author>
			<persName><forename type="first">Soonmin</forename><surname>Hwang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jaesik</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Namil</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yukyung</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">In</forename><surname>So Kweon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Illumination-aware faster R-CNN for robust multispectral pedestrian detection</title>
		<author>
			<persName><forename type="first">Chengyang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruofeng</forename><surname>Tong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Min</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">85</biblScope>
			<biblScope unit="page" from="161" to="171" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Fusion of multispectral data through illumination-aware deep neural networks for pedestrian detection</title>
		<author>
			<persName><forename type="first">Dayan</forename><surname>Guan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanpeng</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiangxin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanlong</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yang</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Fusion</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="page" from="148" to="157" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Multispectral pedestrian detection via simultaneous detection and segmentation</title>
		<author>
			<persName><forename type="first">Chengyang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruofeng</forename><surname>Tong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Min</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">British Machine Vision Conference (BMVC)</title>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page">225</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Crossmodality interactive attention network for multispectral pedestrian detection</title>
		<author>
			<persName><forename type="first">Lu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhiyong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shifeng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xu</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hong</forename><surname>Qiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kaizhu</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amir</forename><surname>Hussain</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Fusion</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="page" from="20" to="29" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Weakly aligned crossmodal learning for multispectral pedestrian detection</title>
		<author>
			<persName><forename type="first">Lu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiangyu</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiangyu</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xu</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhen</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhiyong</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Multispectral deep neural networks for pedestrian detection</title>
		<author>
			<persName><forename type="first">Jingjing</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shaoting</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dimitris</forename><forename type="middle">N</forename><surname>Metaxas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the British Machine Vision Conference 2016, BMVC 2016</title>
		<meeting>the British Machine Vision Conference 2016, BMVC 2016<address><addrLine>York, UK</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016">September 19-22, 2016, 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<ptr target="https://www.flir.com/oem/adas/adas-dataset-form/" />
		<title level="m">Free flir thermal dataset for algorithm training</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Multispectral pedestrian detection using deep fusion convolutional neural networks</title>
		<author>
			<persName><forename type="first">Jörg</forename><surname>Wagner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Volker</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Herman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sven</forename><surname>Behnke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">24th European Symposium on Artificial Neural Networks (ESANN)</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Faster R-CNN : towards real-time object detection with region proposal networks</title>
		<author>
			<persName><forename type="first">Kaiming</forename><surname>Shaoqing Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ross</forename><forename type="middle">B</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jian</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NIPS)</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="91" to="99" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Network in network</title>
		<author>
			<persName><forename type="first">Min</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qiang</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shuicheng</forename><surname>Yan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1312.4400</idno>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Crossmodality interactive attention network for multispectral pedestrian detection</title>
		<author>
			<persName><forename type="first">Lu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhiyong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shifeng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xu</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hong</forename><surname>Qiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kaizhu</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amir</forename><surname>Hussain</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Fusion</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="page" from="20" to="29" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">GFD-SSD : gated fusion double SSD for multispectral pedestrian detection</title>
		<author>
			<persName><forename type="first">Yang</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Izzat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shahrzad</forename><surname>Izzat</surname></persName>
		</author>
		<author>
			<persName><surname>Ziaee</surname></persName>
		</author>
		<idno>CoRR, abs/1903.06999</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Illuminating pedestrians via simultaneous detection &amp; segmentation</title>
		<author>
			<persName><forename type="first">Garrick</forename><surname>Brazil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xi</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaoming</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision (CVPR)</title>
		<meeting>the IEEE International Conference on Computer Vision (CVPR)</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Acnet : Strengthening the kernel skeletons for powerful cnn via asymmetric convolution blocks</title>
		<author>
			<persName><forename type="first">Xiaohan</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuchen</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guiguang</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jungong</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">ImageNet : A Large-Scale Hierarchical Image Database</title>
		<author>
			<persName><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L.-J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">FSSD : feature fusion single shot multibox detector</title>
		<author>
			<persName><forename type="first">Zuoxin</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fuqiang</forename><surname>Zhou</surname></persName>
		</author>
		<idno>CoRR, abs/1712.00960</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Ssd : Single shot multibox detector</title>
		<author>
			<persName><forename type="first">Wei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dragomir</forename><surname>Anguelov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dumitru</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Scott</forename><surname>Reed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cheng-Yang</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><forename type="middle">C</forename><surname>Berg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Very deep convolutional networks for large-scale image recognition</title>
		<author>
			<persName><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Delving deep into rectifiers : Surpassing human-level performance on imagenet classification</title>
		<author>
			<persName><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1026" to="1034" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Is faster r-cnn doing well for pedestrian detection ?</title>
		<author>
			<persName><forename type="first">Liliang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liang</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaodan</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1607.07032</idno>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Fully convolutional region proposal networks for multispectral person detection</title>
		<author>
			<persName><forename type="first">Daniel</forename><surname>König</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Adam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christian</forename><surname>Jarvers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Georg</forename><surname>Layher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Heiko</forename><surname>Neumann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Teutsch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Measures of the amount of ecologic association between species</title>
		<author>
			<persName><forename type="first">Lee</forename><forename type="middle">R</forename><surname>Dice</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ecology</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="297" to="302" />
			<date type="published" when="1945">1945</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
