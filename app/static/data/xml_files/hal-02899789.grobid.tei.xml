<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main"></title>
				<funder ref="#_v6dUYpm">
					<orgName type="full">Agence Nationale de la Recherche</orgName>
					<orgName type="abbreviated">ANR</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Maxime</forename><surname>Metz</surname></persName>
							<email>maxime.metz@inrae.fr</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">ITAP</orgName>
								<orgName type="department" key="dep2">INRAE</orgName>
								<orgName type="institution" key="instit1">Univ Montpellier</orgName>
								<orgName type="institution" key="instit2">Institut Agro</orgName>
								<address>
									<settlement>Montpellier</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="laboratory">ChemHouse Research Group</orgName>
								<address>
									<settlement>Montpellier</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Matthieu</forename><surname>Lesnoff</surname></persName>
							<affiliation key="aff1">
								<orgName type="laboratory">ChemHouse Research Group</orgName>
								<address>
									<settlement>Montpellier</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="laboratory">CIRAD</orgName>
								<orgName type="institution">UMR SELMET</orgName>
								<address>
									<settlement>Montpellier</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="department">CIRAD</orgName>
								<orgName type="laboratory">SELMET</orgName>
								<orgName type="institution" key="instit1">Univ Montpellier</orgName>
								<orgName type="institution" key="instit2">INRA</orgName>
								<orgName type="institution" key="instit3">Institut Agro</orgName>
								<address>
									<settlement>Montpellier</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Florent</forename><surname>Abdelghafour</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">ITAP</orgName>
								<orgName type="department" key="dep2">INRAE</orgName>
								<orgName type="institution" key="instit1">Univ Montpellier</orgName>
								<orgName type="institution" key="instit2">Institut Agro</orgName>
								<address>
									<settlement>Montpellier</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="laboratory">ChemHouse Research Group</orgName>
								<address>
									<settlement>Montpellier</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Reza</forename><surname>Akbarinia</surname></persName>
							<affiliation key="aff4">
								<orgName type="department">Inria &amp; LIRMM</orgName>
								<orgName type="institution">Univ Montpellier</orgName>
								<address>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Florent</forename><surname>Masseglia</surname></persName>
							<affiliation key="aff4">
								<orgName type="department">Inria &amp; LIRMM</orgName>
								<orgName type="institution">Univ Montpellier</orgName>
								<address>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jean-Michel</forename><surname>Roger</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">ITAP</orgName>
								<orgName type="department" key="dep2">INRAE</orgName>
								<orgName type="institution" key="instit1">Univ Montpellier</orgName>
								<orgName type="institution" key="instit2">Institut Agro</orgName>
								<address>
									<settlement>Montpellier</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="laboratory">ChemHouse Research Group</orgName>
								<address>
									<settlement>Montpellier</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff5">
								<address>
									<addrLine>361 Rue Jean Fran√ßois Breton</addrLine>
									<postCode>34196</postCode>
									<settlement>Montpellier</settlement>
								</address>
							</affiliation>
						</author>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">2D233975E52B1115C2E2261703D572E0</idno>
					<idno type="DOI">10.1016/j.chemolab.2020.104076</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-04-12T14:49+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>KNN-PLSDA</term>
					<term>PLSDA</term>
					<term>parSketch</term>
					<term>Big-data</term>
					<term>local-PLS</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>A well known issue regarding PLS lies in the difficulty to apprehend nonlinearities. As a solution, an extension of the method, "KNN-PLS", was developed. However, this solution is based on a neighbourhood selection algorithm whose execution time is highly dependent on the size of the database, leading to prohibitive response times. This article proposes, as an alternative, a new method designed to process large data volumes: "parSketch-PLS". This method combines a "big-data domain" neighbour selection method, called "parSketch", and the PLS method. Essentially, this paper presents a feasibility study, regarding the adaptation of big-data principles for spectral datasets, in non-linear contexts. The parSketch method has not been studied in the context of chemometrics and considering the specific properties of spectral data. This method is based on the approximation of sample neighbourhoods, based on spectral distances. It is then necessary to investigate the relevance of these neighbourhoods for PLS models and predictions. This article compares PLS and KNN-PLS methods with the parSketch-PLS method. In this context, PLS allows to process large volumes of data quickly but performs poorly in prediction while the KNN-PLS method returns accurate predictions, yet with much higher computational time. This paper shows that the proposed pairing offers a good operational trade-off between prediction performances and computational cost. In addition a comprehensive study of the input parameters of parSketch-PLS is conducted. The objective is to understand the influence of these parameters on the prediction performances. This article proposes a framework to interpret the neighbourhoods returned by comparing their relative sizes with the evolution of performances and the input parameters of parSketch.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Chemometrics exploits a wide range of tools for the analysis and interpretation of spectroscopic data. One of the objectives of these tools is to associate spectral information with physicochemical properties in order to predict these properties. Among them, a reference method is PLSR (Partial Least Squares Regression) <ref type="bibr" target="#b0">[1]</ref>. It is a relevant method in various fields such as bioinformatics and social sciences. PLSR enables to realise very efficient predictive models when there is a linear relationship between the spectra and the physicochemical property(ies) of interest. PLSR is composed of a dimension reduction step (PLS) followed by a regression on the scores produced. Similarly, it is possible to carry out a discrimination calculating a discrimination model on the PLS scores. This article focuses on the two methods, under the term PLS. Due to the diversity of applications in the field, it is common to be confronted with data resulting from the aggregation of measurements carried out on samples of different natures. This aggregation often introduces non-linearities in the data (curvatures, clustering). These nonlinearities can significantly alter the quality of the predictions <ref type="bibr" target="#b1">[2]</ref>- <ref type="bibr" target="#b3">[4]</ref>. A solution to this problem is the use of "local" methods <ref type="bibr" target="#b1">[2]</ref>, <ref type="bibr" target="#b4">[5]</ref>- <ref type="bibr" target="#b9">[10]</ref>. One of the most common local methods is "KNN-PLS" (K Nearest Neighbours -PLS) <ref type="bibr" target="#b1">[2]</ref>, <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b10">[11]</ref>- <ref type="bibr" target="#b18">[19]</ref>. The KNN-PLS method consists in determining a neighbourhood of the sample to be predicted, using a similarity criterion, and then calculating a PLS model on the neighbourhood of this sample. This method solves regression problems by computing a PLSR model on each neighbourhood. This method can also be applied to classification problems by computing a PLSDA (PLS Discriminant Analysis) model <ref type="bibr" target="#b19">[20]</ref> on the neighbourhood. Similarity criteria is one of the most studied issues regarding implementations of KNN-PLS models <ref type="bibr" target="#b20">[21]</ref>, <ref type="bibr" target="#b21">[22]</ref>. However, paradoxically, only a few studies have been conducted on neighbours selection and on the associated algorithms. Current KNN-PLS methods are all implementations of the "brute-force" algorithm, which consists in calculating all dissimilarities between the sample to be predicted and all the samples in the database, then ordering these samples according to the dissimilarities. The "brute-force" algorithm has the advantage of being a straightforward and accurate calculus. However, it is fastidious or even unfeasible to process large databases using this method.</p><p>Recent developments in spectroscopic instrumentation (especially hyperspectral imaging) make it possible to acquire large volumes of data. It becomes then unreasonable to apply methods as computationally intensive as the "brute-force" algorithm on these data. An alternative is the use of "big-data" methods. Numerous methods have been developed in this field in order to accelerate the search for neighbours. All these methods share the central notion of indexation <ref type="bibr" target="#b22">[23]</ref>- <ref type="bibr" target="#b26">[27]</ref>. An index is a data structure that enables the search for samples in a time that is sub-linear (often logarithmic) to the size of the database. Therefore, indexing a database consists in adding its data to the index structure to be able to find them quickly.</p><p>However, the conventional indexing structures are not suitable for spectral data, as they contain large numbers of highly inter-correlated variables. Recently, indexing methods have been developed to deal with time series <ref type="bibr" target="#b27">[28]</ref>- <ref type="bibr" target="#b34">[35]</ref> which present similar issues with spectral data. However, only a few time series indexing methods are suitable for large volumes of data.</p><p>Two methods have recently been developed to be processed with extensively parallel architectures in order to process quickly large databases: DPiSAX (Distributed Partitioned indexed Symbolic Aggregate approXimation) <ref type="bibr" target="#b35">[36]</ref> and parSketch <ref type="bibr" target="#b36">[37]</ref>, <ref type="bibr" target="#b37">[38]</ref>.</p><p>In chemometrics, these algorithms have not been tested yet and would solve some major methodological issues, such as finding a fast and reliable neighbour search in the KNN-PLS framework. In this work, it is proposed to study parSketch in the context of chemometrics in order to evaluate the potential of this method to realise applications in chemometrics. The parSketch method combines dimension reduction, achieved by projection on random vectors <ref type="bibr" target="#b36">[37]</ref> , with the creation of lists of samples based on grids. ParSketch's efficiency has been illustrated in terms of calculation cost compared to the "brute-force" method <ref type="bibr" target="#b36">[37]</ref>, <ref type="bibr" target="#b37">[38]</ref>.</p><p>In this paper, it is proposed to conduct a feasibility study of the parSketch method on spectral data. For that, parSketch has been evaluated to replace the "brute-force" algorithm in the KNN-PLS method, i.e. to use the parSketch method and then compute a PLS model on the resulting neighbourhood ("parSketch-PLS"). However, parSketch approximates a neighbourhood. It is therefore necessary to test the influence of this approximation on the quality of PLS results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Theory</head><p>2.1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Notations</head><p>Capital bold characters will be used to designate matrices, e.g. X ; small bold characters for column vectors, e.g. xj will denote the j th column of X; row vectors will be denoted by the transpose notation, e.g. x T i will denote the i th row of X; non bold italic characters will be used for scalars, e.g. matrix elements xij or indices i.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2.2.</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method description</head><p>The creation of an index with parSketch is done in two steps: dimension reduction and grid creation <ref type="bibr" target="#b36">[37]</ref>, <ref type="bibr" target="#b37">[38]</ref>. Let X(np) be the matrix of n spectra per p wavelengths. Let P(pv) be a matrix of v vectors of dimension p, containing the values -1 or 1 according to a random selection.</p><p>The dimension reduction is achieved by calculating the matrix T(nv), obtained by equation (1),</p><p>shown in Figure <ref type="figure">1</ref>. Each line t T i of T corresponds to the sketch of x T i.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>T = XP (1) Figure 1 : Sketch creation</head><p>Adjacent pairs of T columns are grouped together to form two-dimensional spaces (in default setting). Such formed, the spaces are segmented to form g grids (g=v/2 where v is the number of random vectors generated). The projections of sketches in the grids is a fundamental step of the algorithm. The essential operation being how the determination of intervals are implemented (solely for computational efficiency). In this paper, the results are produced with an internal algorithm from R, relying on interval search. The position of all samples in the grid cells is recorded, as illustrated by Figure <ref type="figure">2</ref>. In this figure, T, the matrix of sketches, contains 6 samples described with four variables. T is then mapped into two dimensional grids divided into 3 segments for both of the variables. Each of the 6 samples are then assigned to a cell within the grids according to their values. For example sample "t(1)" is assigned to cell <ref type="bibr">[10-20][10-20]</ref> in grid 1 and to cell [0-10][10-20] in grid 2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 2 : Grid creation</head><p>The search for the neighbours of any unknown sample xnew uses the indexes created in the following way:</p><p>xnew is converted into a sketch using the loadings P: tnew=x T new P. For each grid u, let cu be the cell where tnew is located. The samples present in the cu cell for at least m % of the grids are selected as neighbours of xnew.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 3 : Neighbour search</head><p>This process is illustrated by Figure <ref type="figure">3</ref>, where a new sample is searched for best candidate neighbours in T. The sample is first converted as a sketch, t(new), and placed in the grids using the same process. Consequently, the neighbours of t(new) are chosen within the samples that occur in the same cells as t(new) with a minimum threshold of m. In Figure <ref type="figure">3</ref>, t(1) and t(new) co-occur one, while t(1) and t(new) co-occur twice. With a minimum threshold corresponding to 2 co-occurrences, t( <ref type="formula">6</ref>) would be considered candidate to be a nearest neighbour to t(new).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2.3.</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method properties</head><p>The parSketch method has interesting properties for processing massive data.</p><p>Firstly, the parSketch method has three adjustable parameters to define a trade-off between the computation costs and the accuracy of resulting neighbourhood. The first one, is the number of random vectors v used to generate P. This parameter improves the approximation quality of the neighbourhood. The greater the number of random vectors generated (v), the better the approximation. The second one, is the number of segments s in the grids. This parameter allows to obtain neighbours closer to the sample to be predicted and reduces the number of returned neighbours. The larger the number of segments, the smaller the neighbourhood returned by parSketch. The third parameter, is a threshold regarding the minimum number of grids m in percentage. The higher this threshold, the closer the neighbours returned by parSketch are to the sample to be predicted but fewer in number.</p><p>Secondly, the dimension reduction is very efficient. In contrast to the usual dimension reduction methods used in chemometrics (e.g. principal component analysis or partial least squares) the dimension reduction performed within parSketch is essentially a single matrix product. This reduction is performed through the matrix P which is very easy to generate (from random selection). And more importantly, the Johnson-Lindenstrauss lemma <ref type="bibr" target="#b38">[39]</ref>, guarantees to preserve an approximation of the Euclidean distances between the samples.</p><p>Thirdly, the application of grids to T is facilitated. Indeed, there are no predominant variables in the sketch matrix T because this matrix is obtained using P, constructed from random vectors. It is therefore possible to create grids without having to take precautions regarding the space of the T variables. If factorial methods such as the PCA were used for this dimension reduction, the grids should take into account the variance expressed by each component.</p><p>Fourthly, parSketch uses a large number of low dimensional grids (2 dimensions in this case). This makes possible to discard some constraints inherent to the curse of dimensionality <ref type="bibr" target="#b39">[40]</ref>. Indeed, if large grids were exploited, it would generate hollow subspaces i.e. the returned neighbourhoods would be too small or even non-existent.</p><p>Fifthly, the parSketch method considerably reduces calculation times, thanks to dimension reduction and indexing. In addition, all parSketch steps can be parallelised. This allows parSketch to process large amounts of data. For example, in <ref type="bibr" target="#b36">[37]</ref>, parSketch made it possible to process databases of 3x10 8 samples in a short time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Material and methods</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Data and software</head><p>In this article, a dataset for classification has been defined by sampling hyperspectral images.</p><p>The images correspond to wheat plants. The initial database contained 360,000 reflectance spectra. The samples measured belong to four classes, corresponding to four different genotypes. The spectra were acquired using a hyperspectral camera at p=256 wavelengths ranging from 410 to 1000 nm. One hyperspectral image was acquired for each class containing 90,000 spectra.</p><p>Hyperspectral imaging has the advantage of quickly generating a large number of spectra.</p><p>However, the resulting spectra can be correlated spatially. In order to limit the risks of overfitting, a test set has been carefully constructed. In this case, for each image and thus each class, 100 test samples were selected using the Kennard-Stone method <ref type="bibr" target="#b40">[41]</ref> applied to the coordinates of the pixels in the image. Because samples are selected from images, spectra resulting from adjacent pixels are very likely to be highly correlated. Consequently, a reasonable manner to construct minimally biased validation sets, is to select only one sample in every 7*7 neighbourhoods. The resulting database includs a test set of 400 samples and a calibration set of 354,426 samples. The purpose is to simulate big-data like issues. i.e. when there is a substantial and generic database that is used to predict a few specific samples.</p><p>Using a more conventional sampling ratio would lead to include too many resembling samples between the prediction and the model samples. In this feasibility study, only one test set has been built to study the behavior of the methods. For a real application, multiple randomly sampled sets would be required as well as a fine study for the settings tuning, thanks to processes like cross-validation. Moreover, the data of the learning set and the test are part of the same image and therefore it is not possible to validate this step for a real application.</p><p>Calculations were performed with the R software (version 3.6.1 <ref type="bibr" target="#b41">[42]</ref>), and the Rnirs toolbox for PLS. The R package rnirs is available at https://github.com/mlesnoff/rnirs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Prediction models</head><p>The objective of this article was to compare the properties and classification performance of three types of methods: PLSDA, KNN-PLSDA, parSketch-PLSDA. It was first intended to illustrate the contribution of the KNN-PLS method in relation to PLSDA. Then, it was used to compare KNN and the parSketch algorithm in terms of returned neighbourhoods and in terms of cost to performance potentials.</p><p>The first model was derived from a PLSDA, the model consisted in transforming a univariate variable y (containing q classes) into an n*q matrix Ydummy of q 0/1 dummy variables then to apply a PLS2 model on (X ,Ydummy) <ref type="bibr" target="#b19">[20]</ref> and then to carry out a linear discriminant analysis (LDA) between the PLS2 scores and Y.</p><p>In the second model, derived from a KNN-PLSDA <ref type="bibr" target="#b42">[43]</ref>, the search for neighbours (thanks to brute-force algorithm) is conducted on the first 10 scores of a PLS model <ref type="bibr" target="#b43">[44]</ref>. In this experiment, the influence of two parameters is tested: the size of the neighbourhoods and the number of latent variables. Neighbourhoods of 400, 1000, 3000, 5000 and 10000 samples are considered.</p><p>For the first two models (PLSDA and KNN-PLSDA), the criterion for assessing the quality of the calculated models was the percentage error of prediction on the test set. A third model was estimated by replacing the brute-force algorithm by parSketch in the KNN-PLSDA method.</p><p>The three parameters of parSketch : number of random vectors (v), number of segments (s), minimum % of grids (m), are set with values ranging as: v ‚àà {10, 20, 30, 50, 80, 100}, s ‚àà {5, 7, 9, 11, 13, 15}, m ‚àà {30, 50, 70, 90}.</p><p>In the following this model will be referred to as "parSketch-PLSDA". For the third model, 3 evaluation criteria of the parSketch parameters have been selected. First, the number of predictable samples, i.e. the number of test samples having more than 30 neighbours. Then, the distribution of the number of neighbours is observed. Finally, the prediction error of parSketch-PLSDA is observed through 5 notable combinations of [v,s,m] parameters. Spectra from each group present similar general shapes. There is no significant peak in any wavelength that can clearly discriminate spectra from the different genotypes. Moreover, there is no specific spectral domain in which the four genotypes seem to diverge.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Results and discussion</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Data visualisation</head><p>Figure <ref type="figure">5</ref> presents a projection of the whole spectra on the two first components of a PCA. All genotypes follow a single trajectory with significant overlaps. Similar examinations conducted with up to 20 components lead to the same results. This shows that genotypic differences cannot be explained by the PCA model.  These results are much better compared to the PLSDA model (see figure <ref type="figure">6</ref>) with a minimal prediction error divided by 2.5. This confirms the non-linearity within the data.  <ref type="table" target="#tab_0">1</ref> summarises the minimum misclassification errors and the associated latent variables depending on the size of the considered neighbourhood (from figure <ref type="figure">7</ref>). It illustrates that as the number of neighbours increases, errors decrease but with a growing optimal number of latent variables. Table <ref type="table" target="#tab_0">1</ref> shows that the minimum prediction error is 7% for an optimal number of neighbours of 3000 and a number of latent variables of 16. It can then be concluded that the KNN-PLSDA method for this study is more efficient than the PLSDA. Furthermore, it is observed that to achieve minimal prediction errors, it is necessary to create KNN-PLS models with a large number of PLS latent variables, which means that genotype discrimination is difficult to achieve.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">PLSDA</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">parSketch-PLSDA</head><p>In this section, two points will be discussed : the neighbourhood of samples and the prediction error of the parSketch-PLSDA method. For each sample in the test set, parSketch returns a neighbourhood whose size depends on the parameters of the algorithm. An sample in the test set is said to be predictable, if the neighbourhood returned by parSketch contains at least 30 samples.</p><p>Figure <ref type="figure" target="#fig_3">8</ref> shows that the number of predictable samples decreases as the value of m increases.</p><p>The parameter m is used to select the samples most often present in the same cell as the sample to be predicted (see section 2). The parSketch method constructs grids on sketches that are derived from matrix P random vectors. It is therefore very unlikely to obtain a large number of neighbours if the threshold m is too high (Cf section 2.2).</p><p>Figure <ref type="figure" target="#fig_3">8</ref> shows that the number of predictable samples decreases as the values of s (number of segments) and v (number of random vectors) increase. s defines the number of cells in each grid (see section 2). When the number of cells in each grid increases, the cells are smaller and therefore contain fewer samples.</p><p>The number of random vectors (v) is used to preserve the Euclidean distances in an approximate way. This parameter is not directly related to the size of the neighbourhood but v is linked to the threshold m and thus will have an indirect impact on the number of predictable samples.</p><p>To conclude, s and m have a strong impact on the number of predictable samples while v has a weak (indirect) impact on the number of predictable samples. Figure <ref type="figure" target="#fig_4">9</ref> shows that when the value of parameters m and s is too high, the number of returned neighbours is low or even zero. Moreover, a highly stochastic behaviour of the neighbourhood distributions can be observed when the value of the threshold m is high (e.g. m = 90%). In addition, when m has values that are too high, the impacts of other factors are not observable.</p><p>It is therefore not possible to make conclusions about the influence of the parSketch parameters when the value of the parameters m and s are too high. For future observations, the distributions of the neighbourhoods obtained with parameters m = 90 or s = 15 are not studied.</p><p>In Figure <ref type="figure" target="#fig_4">9</ref>, it is possible to observe the impact of the three parSketch parameters on the neighbourhood distributions of the samples to be predicted.</p><p>Firstly, when v varies, the median number of neighbours and the interquartile range of neighbourhoods are constant. Indeed, the number of random vectors has no impact on the quantity of returned neighbours (see section 2).</p><p>Secondly, as s increases, the median number of neighbours per sample to be predicted decreases. Indeed, s defines the number of cells in each grid, the more s will have a high value the more cells there will be and thus the fewer samples in each cell. When s increases, the interquartile range of neighbourhoods decreases. Indeed, the stronger the segmentation, the less influence there will be on the structure of the position of the samples to be predicted in the database.</p><p>Thirdly, when m increases, the median number of neighbours and the interquartile neighbourhood gap per sample decreases. m is a threshold, the higher the value of m the more similar the samples returned by parSketch will be. Therefore, if the value of m is high, fewer neighbours will be returned by parSketch.</p><p>To conclude, with the help of figures 8 and 9 it is possible to eliminate certain combinations of parameters. Indeed, figure <ref type="figure" target="#fig_3">8</ref> makes it easy to select combinations that allow us to predict a certain number of samples. Then, figure <ref type="figure" target="#fig_4">9</ref> allows the selection of combinations of parameters according to the characteristics of the neighbourhoods (e.g. a high number of neighbours and a low variability of the neighbourhoods). Five combinations were chosen to calculate a PLSDA model (see Table <ref type="table" target="#tab_2">2</ref>). These combinations of parameters were chosen because the resulting neighbourhoods were small and all samples were predictable. However, in these combinations, the median In Figure <ref type="figure" target="#fig_5">10</ref>, the error curves of the parSketch-PLSDA are all very close and provide an optimal error of approximately 10%. Figure <ref type="figure" target="#fig_5">10</ref> shows parSketch-PLSDA provides better prediction than PLSDA. The best combination of parameters approaches the best result of the KNN-PLSDA. To conclude, on the example discussed in the article, the neighbourhood returned by parSketch may provide an alternative. ParSketch provides a neighbourhood that allows us to improve the prediction qualities but this neighbourhood can be very large and therefore not all the neighbours returned by pasketch are useful.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion / perspective</head><p>This article shows that the combination of a big-data indexing algorithm (parSketch) with PLSDA (parsketch-PLSDA) approaches the best results of KNN-PLSDA on the treated example (wheat leaf genotype discrimination by hyperspectral imaging). The parSketch method is not able to obtain as good classification results as the KNN-PLSDA method, but allows better results than a PLSDA. It can be concluded that parSketch-PLS is very efficient in terms of computation time to select neighborhoods in massive datasets and allows to handle non-linear relations between X and Y. ParSketch is less efficient than the brute-force method to obtain relevant neighbours for PLS model calculation, but allows to realise a fast estimation of the neighbourhood on massive databases. The KNN-PLS and parSketch-PLS methods are used in real time, i.e. for each prediction to be performed a PLS model is calculated on the selected neighborhood and the prediction is directly performed. The prediction of the 400 test samples took several hours with KNN-PLS while the prediction using parSketch-PLS took only a few minutes. This article also shows that it is possible to use parSketch to study the database. Indeed, the parameters s and m (number of segments and minimum % of grids) are dependent on the database structure, for example if the database is very compact, the neighbourhoods returned by parSketch will be very large. In order to confirm the feasibility study a real application will be realised in a second step with the parSketch-PLS method. A major problem with parSketch is that it may return too large neighbourhoods. If the neighbourhoods returned by parSketch are too large, it is possible to fail to handle nonlinearity. Indeed, if too many neighbours are returned it is possible that these samples do not all belong to the same linear model. Moreover, the computation time of a PLS model is related to the number of samples. A solution to obtain smaller neighbourhoods and better predictions is to combine parSketch with a method for selecting samples. For example, parSketch could be combined with the brute-force method to reduce the number of distances to be computed for each sample to predict. This means that within a neighbourhood returned by parSketch it would be possible to apply the brute force method. It would therefore be interesting to study parSketch as a filter and then to combine parSketch with another approach of selection or weighting of samples.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>6.</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>8.</head><note type="other">Figure Captions</note></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 4 :Figure 5 :Figure 4</head><label>454</label><figDesc>Figure 4 : Spectra plot of the 4 genotypes</figDesc><graphic coords="13,72.00,522.97,318.00,195.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 6 :Figure 6</head><label>66</label><figDesc>Figure 6 : Error in classification of the test set according to the number of latent</figDesc><graphic coords="15,77.00,72.00,315.75,210.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 7 :Figure 7</head><label>77</label><figDesc>Figure 7 : Classification error of the test set of a KNN-PLSDA, depending on the number</figDesc><graphic coords="16,77.00,125.40,315.00,192.75" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 8 :</head><label>8</label><figDesc>Figure 8 : Heatmap of the number of predictable samples found by parSketch, as a</figDesc><graphic coords="18,75.06,171.89,375.75,229.50" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 9 :</head><label>9</label><figDesc>Figure 9 : Distribution of the number of neighbours per test sample as a function of the</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 10 :</head><label>10</label><figDesc>Figure 10 : Method classification error : parSketch-PLSDA (all 5 combinations); PLSDA</figDesc><graphic coords="22,72.00,171.89,324.75,201.75" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 1 Figure 4 :Figure 5 :Figure 6 :Figure 7 :Figure 8 :</head><label>145678</label><figDesc>Figure 1 : Sketch creation</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 9 :</head><label>9</label><figDesc>Figure 9 : Distribution of the number of neighbours per test sample as a function of the</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 10 :</head><label>10</label><figDesc>Figure 10 : Method classification error : parSketch-PLSDA (all 5 combinations); PLSDA</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="8,72.00,72.00,360.00,289.50" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="9,72.00,97.30,451.50,287.25" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="14,77.00,72.00,293.10,195.40" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="19,72.00,460.87,401.25,269.25" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Optimal classification error according to the number of neighbours</figDesc><table><row><cell>Number of neighbours</cell><cell>Optimal number of LVs</cell><cell>Misclassification error (%)</cell></row><row><cell>100</cell><cell>7</cell><cell>10</cell></row><row><cell>400</cell><cell>13</cell><cell>8</cell></row><row><cell>1000</cell><cell>14</cell><cell>8</cell></row><row><cell>3000</cell><cell>16</cell><cell>7</cell></row><row><cell>5000</cell><cell>14</cell><cell>8</cell></row><row><cell>10000</cell><cell>22</cell><cell>8</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table</head><label></label><figDesc></figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>Combinations of the selected parSketch parameters</figDesc><table><row><cell>Combinaison</cell><cell>m</cell><cell>v</cell><cell>s</cell></row><row><cell>1</cell><cell>50</cell><cell>10</cell><cell>9</cell></row><row><cell>2</cell><cell>50</cell><cell>10</cell><cell>11</cell></row><row><cell>3</cell><cell>50</cell><cell>20</cell><cell>11</cell></row><row><cell>4</cell><cell>50</cell><cell>20</cell><cell>11</cell></row><row><cell>5</cell><cell>50</cell><cell>100</cell><cell>13</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p>This work was supported by the <rs type="funder">French National Research Agency</rs> under the <rs type="programName">Investments for the Future Program</rs>, referred as <rs type="grantNumber">ANR-16-CONV-0004</rs>.</p><p>The authors want to thank <rs type="person">Oleksandra Levchenko</rs> for the productive discussions and relevant insights regarding the parSketch approach and its application to various domains, including chemometrics.</p></div>
<div><head>7.</head></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_v6dUYpm">
					<idno type="grant-number">ANR-16-CONV-0004</idno>
					<orgName type="program" subtype="full">Investments for the Future Program</orgName>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">PLS-regression: a basic tool of chemometrics</title>
		<author>
			<persName><forename type="first">S</forename><surname>Wold</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sj√∂str√∂m</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Eriksson</surname></persName>
		</author>
		<idno type="DOI">10.1016/S0169-7439(01)00155-1</idno>
	</analytic>
	<monogr>
		<title level="j">Chemom. Intell. Lab. Syst</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="109" to="130" />
			<date type="published" when="2001-10">oct. 2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Multivariate Calibration and Chemometrics for near Infrared Spectroscopy: Which Method?</title>
		<author>
			<persName><forename type="first">P</forename><surname>Dardenne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Sinnaeve</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Baeten</surname></persName>
		</author>
		<idno type="DOI">10.1255/jnirs.283</idno>
	</analytic>
	<monogr>
		<title level="j">J. Infrared Spectrosc</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="229" to="237" />
			<date type="published" when="2000-10">oct. 2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">LOCAL Regression Algorithm Improves near Infrared Spectroscopy Predictions When the Target Constituent Evolves in Breeding Populations</title>
		<author>
			<persName><forename type="first">F</forename><surname>Davrieux</surname></persName>
		</author>
		<idno type="DOI">10.1255/jnirs.1213</idno>
	</analytic>
	<monogr>
		<title level="j">J. Infrared Spectrosc</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">National calibration of soil organic carbon concentration using diffuse infrared reflectance spectroscopy</title>
		<author>
			<persName><forename type="first">M</forename><surname>Clairotte</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.geoderma.2016.04.021</idno>
	</analytic>
	<monogr>
		<title level="j">Geoderma</title>
		<imprint>
			<biblScope unit="volume">276</biblScope>
			<biblScope unit="page" from="41" to="52" />
			<date type="published" when="2016">ao√ªt 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Non-linear regression methods in NIRS quantitative analysis</title>
		<author>
			<persName><forename type="first">D</forename><surname>P√©rez-Mar√≠n</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Garrido-Varo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Guerrero</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.talanta.2006.10.036</idno>
	</analytic>
	<monogr>
		<title level="j">Talanta</title>
		<imprint>
			<biblScope unit="volume">72</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="28" to="42" />
			<date type="published" when="2007">avr. 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Local classification: Locally weighted-partial least squares-discriminant analysis (LW-PLS-DA)</title>
		<author>
			<persName><forename type="first">M</forename><surname>Bevilacqua</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Marini</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.aca.2014.05.057</idno>
	</analytic>
	<monogr>
		<title level="j">Anal. Chim. Acta</title>
		<imprint>
			<biblScope unit="volume">838</biblScope>
			<biblScope unit="page" from="20" to="30" />
			<date type="published" when="2014">ao√ªt 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">The application of fourier-transformed near-infrared spectra to quantitative analysis by comparison of similarity indices (CARNAC)</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M C</forename><surname>Davies</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">V</forename><surname>Britcher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">G</forename><surname>Franklin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Ring</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Grant</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">F</forename><surname>Mcclure</surname></persName>
		</author>
		<idno type="DOI">10.1007/BF01205839</idno>
	</analytic>
	<monogr>
		<title level="j">Mikrochim. Acta</title>
		<imprint>
			<biblScope unit="volume">94</biblScope>
			<biblScope unit="issue">1-6</biblScope>
			<biblScope unit="page" from="61" to="64" />
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Covariance-based locally weighted partial least squares for high-performance adaptive modeling</title>
		<author>
			<persName><forename type="first">K</forename><surname>Hazama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kano</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.chemolab.2015.05.007</idno>
	</analytic>
	<monogr>
		<title level="j">Chemom. Intell. Lab. Syst</title>
		<imprint>
			<biblScope unit="volume">146</biblScope>
			<biblScope unit="page" from="55" to="62" />
			<date type="published" when="2015">ao√ªt 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Evaluation of Spectral Pretreatments, Partial Least Squares, Least Squares Support Vector Machines and Locally Weighted Regression for Quantitative Spectroscopic Analysis of Soils</title>
		<author>
			<persName><forename type="first">B</forename><surname>Igne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">B</forename><surname>Reeves</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Mccarty</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">D</forename><surname>Hively</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Lund</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">R</forename><surname>Hurburgh</surname></persName>
		</author>
		<idno type="DOI">10.1255/jnirs.883</idno>
	</analytic>
	<monogr>
		<title level="j">J. Infrared Spectrosc</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="167" to="176" />
			<date type="published" when="2010">juin 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Locally weighted regression and scatter correction for near-infrared reflectance data</title>
		<author>
			<persName><surname>Tormod</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tomas</forename><surname>Naes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bruce</forename><surname>Isaksson</surname></persName>
		</author>
		<author>
			<persName><surname>Kowalski</surname></persName>
		</author>
		<idno type="DOI">10.1021/ac00206a003</idno>
	</analytic>
	<monogr>
		<title level="j">Anal. Chem</title>
		<imprint>
			<biblScope unit="volume">62</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="664" to="673" />
			<date type="published" when="1990">avr. 1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Fecal Near-Infrared Reflectance Spectroscopy Prediction of the Feed Value of Temperate Forages for Ruminants and Some Parameters of the Chemical Composition of Feces: Efficiency of Four Calibration Strategies</title>
		<author>
			<persName><forename type="first">D</forename><surname>Andueza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Picard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Dozias</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Aufr√®re</surname></persName>
		</author>
		<idno type="DOI">10.1177/0003702817712740</idno>
	</analytic>
	<monogr>
		<title level="j">Appl. Spectrosc</title>
		<imprint>
			<date type="published" when="2017">juin 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Use of LOCAL algorithm with near infrared spectroscopy in forage resources for grazing systems in Colombia</title>
		<author>
			<persName><forename type="first">C</forename><surname>Ariza-Nieto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Mayorga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Mojica</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Parra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Afanador-Tellez</surname></persName>
		</author>
		<idno type="DOI">10.1177/0967033517746900</idno>
	</analytic>
	<monogr>
		<title level="j">J. Infrared Spectrosc</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="44" to="52" />
			<date type="published" when="2018">f√©vr. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">LOCAL Prediction with near Infrared Multi-Product Databases</title>
		<author>
			<persName><forename type="first">P</forename><surname>Berzaghi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Shenk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">O</forename><surname>Westerhaus</surname></persName>
		</author>
		<idno type="DOI">10.1255/jnirs.258</idno>
	</analytic>
	<monogr>
		<title level="j">J. Infrared Spectrosc</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="9" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">The Development of near Infrared Wheat Quality Models by Locally Weighted Regressions</title>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">I F E</forename><surname>Barton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Shenk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">O</forename><surname>Westerhaus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">B</forename><surname>Funk</surname></persName>
		</author>
		<idno type="DOI">10.1255/jnirs.280</idno>
	</analytic>
	<monogr>
		<title level="j">J. Infrared Spectrosc</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Soil parameter quantification by NIRS as a Chemometric challenge at &apos;Chimiom√©trie 2006</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Fern√°ndez Pierna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Dardenne</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.chemolab.2007.06.007</idno>
	</analytic>
	<monogr>
		<title level="j">Chemom. Intell. Lab. Syst</title>
		<imprint>
			<biblScope unit="volume">91</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="94" to="98" />
			<date type="published" when="2008">mars 2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Reducing NIR prediction errors with nonlinear methods and large populations of intact compound feedstuffs</title>
		<author>
			<persName><forename type="first">E</forename><surname>Fern√°ndez-Ahumada</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Meas. Sci. Technol</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page">85601</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Evaluation of Local Approaches to Obtain Accurate Near-Infrared (NIR) Equations for Prediction of Ingredient Composition of Compound Feeds</title>
		<author>
			<persName><forename type="first">E</forename><surname>Fern√°ndez-Ahumada</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Fearn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>G√≥mez-Cabrera</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Guerrero-Ginel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">C</forename><surname>P√©rez-Mar√≠n</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Garrido-Varo</surname></persName>
		</author>
		<idno type="DOI">10.1366/12-06937</idno>
	</analytic>
	<monogr>
		<title level="j">Appl. Spectrosc</title>
		<imprint>
			<biblScope unit="volume">67</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="924" to="929" />
			<date type="published" when="2013">ao√ªt 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Investigation of a LOCAL Calibration Procedure for near Infrared Instruments</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Shenk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">O</forename><surname>Westerhaus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Berzaghi</surname></persName>
		</author>
		<idno type="DOI">10.1255/jnirs.115</idno>
	</analytic>
	<monogr>
		<title level="j">J. Infrared Spectrosc</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="223" to="232" />
			<date type="published" when="1997-10">oct. 1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Global or Local? A Choice for NIR Calibrations in Analyses of Forage Quality</title>
		<author>
			<persName><forename type="first">G</forename><surname>Sinnaeve</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Dardenne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Agneessens</surname></persName>
		</author>
		<idno type="DOI">10.1255/jnirs.43</idno>
	</analytic>
	<monogr>
		<title level="j">J. Infrared Spectrosc</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="163" to="175" />
			<date type="published" when="1994">juin 1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Partial least squares for discrimination</title>
		<author>
			<persName><forename type="first">M</forename><surname>Barker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Rayens</surname></persName>
		</author>
		<idno type="DOI">10.1002/cem.785</idno>
	</analytic>
	<monogr>
		<title level="j">J. Chemom</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="166" to="173" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Locally-Biased Regression</title>
		<author>
			<persName><forename type="first">T</forename><surname>Fearn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M C</forename><surname>Davies</surname></persName>
		</author>
		<idno type="DOI">10.1255/jnirs.397</idno>
	</analytic>
	<monogr>
		<title level="j">J. Infrared Spectrosc</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="467" to="478" />
			<date type="published" when="2003">d√©c. 2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Optimization criteria in sample selection step of local regression for quantitative analysis of large soil NIRS database</title>
		<author>
			<persName><forename type="first">F</forename><surname>Gog√©</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Joffre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Jolivet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Ross</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Ranjard</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.chemolab.2011.11.003</idno>
	</analytic>
	<monogr>
		<title level="j">Chemom. Intell. Lab. Syst</title>
		<imprint>
			<biblScope unit="volume">110</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="168" to="176" />
			<date type="published" when="2012">janv. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Binary B-trees for Virtual Memory</title>
		<author>
			<persName><forename type="first">R</forename><surname>Bayer</surname></persName>
		</author>
		<idno type="DOI">10.1145/1734714.1734731</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1971 ACM SIGFIDET (Now SIGMOD) Workshop on Data Description, Access and Control</title>
		<meeting>the 1971 ACM SIGFIDET (Now SIGMOD) Workshop on Data Description, Access and Control<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1971">1971</date>
			<biblScope unit="page" from="219" to="235" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Multidimensional binary search trees used for associative searching</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Bentley</surname></persName>
		</author>
		<idno type="DOI">10.1145/361002.361007</idno>
	</analytic>
	<monogr>
		<title level="j">Commun. ACM</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="509" to="517" />
			<date type="published" when="1975">sept. 1975</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Quad trees a data structure for retrieval on composite keys</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Finkel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Bentley</surname></persName>
		</author>
		<idno type="DOI">10.1007/BF00288933</idno>
	</analytic>
	<monogr>
		<title level="j">Acta Inform</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="9" />
			<date type="published" when="1974">mars 1974</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">R-trees: A Dynamic Index Structure for Spatial Searching</title>
		<author>
			<persName><forename type="first">A</forename><surname>Guttman</surname></persName>
		</author>
		<idno type="DOI">10.1145/602259.602266</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1984 ACM SIGMOD International Conference on Management of Data</title>
		<meeting>the 1984 ACM SIGMOD International Conference on Management of Data<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1984">1984</date>
			<biblScope unit="page" from="47" to="57" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Nearest Neighbor Queries</title>
		<author>
			<persName><forename type="first">N</forename><surname>Roussopoulos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kelley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Vincent</surname></persName>
		</author>
		<idno type="DOI">10.1145/223784.223794</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1995 ACM SIGMOD International Conference on Management of Data</title>
		<meeting>the 1995 ACM SIGMOD International Conference on Management of Data<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page" from="71" to="79" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">The TS-Tree: Efficient Time Series Search and Retrieval</title>
		<author>
			<persName><forename type="first">I</forename><surname>Assent</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Krieger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Afschari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Seidl</surname></persName>
		</author>
		<imprint>
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Indexing spatio-temporal trajectories with Chebyshev polynomials</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ng</surname></persName>
		</author>
		<idno type="DOI">10.1145/1007568.1007636</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2004 ACM SIGMOD international conference on Management of data -SIGMOD &apos;04</title>
		<meeting>the 2004 ACM SIGMOD international conference on Management of data -SIGMOD &apos;04<address><addrLine>Paris, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page">599</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Beyond one billion time series: indexing and mining very large time series collections with iSAX2+</title>
		<author>
			<persName><forename type="first">A</forename><surname>Camerra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Shieh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Palpanas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Rakthanmanon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Keogh</surname></persName>
		</author>
		<idno type="DOI">10.1007/s10115-012-0606-6</idno>
	</analytic>
	<monogr>
		<title level="j">Knowl. Inf. Syst</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="123" to="151" />
			<date type="published" when="2014">avr. 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">iSAX 2.0: Indexing and Mining One Billion Time Series</title>
		<author>
			<persName><forename type="first">A</forename><surname>Camerra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Palpanas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Shieh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Keogh</surname></persName>
		</author>
		<idno type="DOI">10.1109/ICDM.2010.124</idno>
	</analytic>
	<monogr>
		<title level="m">2010 IEEE International Conference on Data Mining</title>
		<meeting><address><addrLine>Sydney, Australia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="58" to="67" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Fast Subsequence Matching in Time-Series Databases</title>
		<author>
			<persName><forename type="first">C</forename><surname>Faloutsos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ranganathan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Manolopoulos</surname></persName>
		</author>
		<imprint>
			<biblScope unit="page">11</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Data Mining a Trillion Time Series Subsequences Under Dynamic Time Warping</title>
		<author>
			<persName><forename type="first">T</forename><surname>Rakthanmanon</surname></persName>
		</author>
		<imprint>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">iSAX: disk-aware mining and indexing of massive time series datasets</title>
		<author>
			<persName><forename type="first">J</forename><surname>Shieh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Keogh</surname></persName>
		</author>
		<idno type="DOI">10.1007/s10618-009-0125-6</idno>
	</analytic>
	<monogr>
		<title level="j">Data Min. Knowl. Discov</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="24" to="57" />
			<date type="published" when="2009">ao√ªt 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">A data-adaptive and dynamic segmentation index for whole matching on time series</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Pei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Huang</surname></persName>
		</author>
		<idno type="DOI">10.14778/2536206.2536208</idno>
	</analytic>
	<monogr>
		<title level="m">Proc. VLDB Endow</title>
		<meeting>VLDB Endow</meeting>
		<imprint>
			<date type="published" when="2013">ao√ªt 2013</date>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="793" to="804" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">DPiSAX: Massively Distributed Partitioned iSAX</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">E</forename><surname>Yagoubi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Akbarinia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Masseglia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Palpanas</surname></persName>
		</author>
		<idno type="DOI">10.1109/ICDM.2017.151</idno>
	</analytic>
	<monogr>
		<title level="m">2017 IEEE International Conference on Data Mining (ICDM)</title>
		<meeting><address><addrLine>New Orleans, LA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1135" to="1140" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Spark-parSketch: A Massively Distributed Indexing of Time Series Datasets</title>
		<author>
			<persName><forename type="first">O</forename><surname>Levchenko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D.-E</forename><surname>Yagoubi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Akbarinia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Masseglia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Kolev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Shasha</surname></persName>
		</author>
		<idno type="DOI">10.1145/3269206.3269226</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th ACM International Conference on Information and Knowledge Management -CIKM &apos;18</title>
		<meeting>the 27th ACM International Conference on Information and Knowledge Management -CIKM &apos;18<address><addrLine>Torino, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="1951" to="1954" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">RadiusSketch: Massively Distributed Indexing of Time Series</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">E</forename><surname>Yagoubi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Akbarinia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Masseglia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Shasha</surname></persName>
		</author>
		<idno type="DOI">10.1109/DSAA.2017.49</idno>
	</analytic>
	<monogr>
		<title level="m">2017 IEEE International Conference on Data Science and Advanced Analytics (DSAA)</title>
		<meeting><address><addrLine>Tokyo, Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="262" to="271" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Extensions of lipschitz maps into Banach spaces</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">B</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lindenstrauss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Schechtman</surname></persName>
		</author>
		<idno type="DOI">10.1007/BF02764938</idno>
	</analytic>
	<monogr>
		<title level="j">Isr. J. Math</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="129" to="138" />
			<date type="published" when="1986">juin 1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">M</forename><surname>Bishop</surname></persName>
		</author>
		<title level="m">Pattern recognition and machine learning</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Computer Aided Design of Experiments</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">W</forename><surname>Kennard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">A</forename><surname>Stone</surname></persName>
		</author>
		<idno type="DOI">10.1080/00401706.1969.10490666</idno>
	</analytic>
	<monogr>
		<title level="j">Technometrics</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="137" to="148" />
			<date type="published" when="1969">f√©vr. 1969</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">R: A language and environment for statistical computing</title>
		<author>
			<persName><forename type="first">Team</forename><surname>Core</surname></persName>
		</author>
		<ptr target="https://www.R-project.org/" />
	</analytic>
	<monogr>
		<title level="m">R Foundation for Statistical Computing</title>
		<meeting><address><addrLine>Vienna, Austria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Comparison of locally weighted PLS strategies for regression and discrimination on agronomic NIR data</title>
		<author>
			<persName><forename type="first">M</forename><surname>Lesnoff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Metz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-M</forename><surname>Roger</surname></persName>
		</author>
		<idno type="DOI">10.1002/cem.3209</idno>
	</analytic>
	<monogr>
		<title level="j">J. Chemom</title>
		<imprint>
			<biblScope unit="page">3209</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Local partial least squares based on global PLS scores</title>
		<author>
			<persName><forename type="first">G</forename><surname>Shen</surname></persName>
		</author>
		<idno type="DOI">10.1002/cem.3117</idno>
	</analytic>
	<monogr>
		<title level="j">J. Chemom</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page">3117</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
