<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Federated Multi-Task Learning under a Mixture of Distributions</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Othmane</forename><surname>Marfoq</surname></persName>
							<email>othmane.marfoq@inria.fr</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Inria</orgName>
								<orgName type="institution" key="instit2">Université Côte d&apos;Azur</orgName>
								<address>
									<country key="FR">France</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution">Accenture Labs</orgName>
								<address>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Giovanni</forename><surname>Neglia</surname></persName>
							<email>giovanni.neglia@inria.fr</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Inria</orgName>
								<orgName type="institution" key="instit2">Université Côte d&apos;Azur</orgName>
								<address>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Aurélien</forename><surname>Bellet</surname></persName>
							<email>aurelien.bellet@inria.fr</email>
							<affiliation key="aff1">
								<orgName type="institution" key="instit1">Inria</orgName>
								<orgName type="institution" key="instit2">Université de Lille</orgName>
								<address>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Laetitia</forename><surname>Kameni</surname></persName>
							<email>laetitia.kameni@accenture.com</email>
							<affiliation key="aff2">
								<orgName type="institution">Accenture Labs</orgName>
								<address>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Richard</forename><surname>Vidal</surname></persName>
							<email>richard.vidal@accenture.com</email>
							<affiliation key="aff2">
								<orgName type="institution">Accenture Labs</orgName>
								<address>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Federated Multi-Task Learning under a Mixture of Distributions</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">C967AD90778FA6AFF38DD4B23567270D</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-04-12T14:49+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The increasing size of data generated by smartphones and IoT devices motivated the development of Federated Learning (FL), a framework for on-device collaborative training of machine learning models. First efforts in FL focused on learning a single global model with good average performance across clients, but the global model may be arbitrarily bad for a given client, due to the inherent heterogeneity of local data distributions. Federated multi-task learning (MTL) approaches can learn personalized models by formulating an opportune penalized optimization problem. The penalization term can capture complex relations among personalized models, but eschews clear statistical assumptions about local data distributions. In this work, we propose to study federated MTL under the flexible assumption that each local data distribution is a mixture of unknown underlying distributions. This assumption encompasses most of the existing personalized FL approaches and leads to federated EM-like algorithms for both client-server and fully decentralized settings. Moreover, it provides a principled way to serve personalized models to clients not seen at training time. The algorithms' convergence is analyzed through a novel federated surrogate optimization framework, which can be of general interest. Experimental results on FL benchmarks show that our approach provides models with higher accuracy and fairness than state-of-the-art methods.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Federated Learning (FL) <ref type="bibr" target="#b27">[28]</ref> allows a set of clients to collaboratively train models without sharing their local data. Standard FL approaches train a unique model for all clients <ref type="bibr" target="#b46">[47,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b47">48]</ref>. However, as discussed in <ref type="bibr" target="#b55">[56]</ref>, the existence of such a global model suited for all clients is at odds with the statistical heterogeneity observed across different clients <ref type="bibr" target="#b36">[37,</ref><ref type="bibr" target="#b27">28]</ref>. Indeed, clients can have non-iid data and varying preferences. Consider for example a language modeling task: given the sequence of tokens "I love eating," the next word can be arbitrarily different from one client to another. Thus, having personalized models for each client is a necessity in many FL applications.</p><p>Previous work on personalized FL. A naive approach for FL personalization consists in learning first a global model and then fine-tuning its parameters at each client via a few iterations of stochastic gradient descent <ref type="bibr" target="#b57">[58]</ref>. In this case, the global model plays the role of a meta-model to be used as initialization for few-shot adaptation at each client. In particular, the connection between FL and Model Agnostic Meta Learning (MAML) <ref type="bibr" target="#b26">[27]</ref> has been studied in <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b0">1]</ref> in order to build a more suitable meta-model for local personalization. Unfortunately, these methods can fail to build a model with low generalization error (as exemplified by LEAF synthetic dataset <ref type="bibr" target="#b6">[7,</ref><ref type="bibr">App. 1]</ref>). An alternative 35th Conference on Neural Information Processing Systems (NeurIPS 2021). arXiv:2108.10252v3 [cs.LG] 18 Feb 2022 approach is to jointly train a global model and one local model per client and then let each client build a personalized model by interpolating them <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b43">44]</ref>. However, if local distributions are far from the average distribution, a relevant global model does not exist and this approach boils down to every client learning only on its own local data. This issue is formally captured by the generalization bound in <ref type="bibr">[14,</ref>  <ref type="bibr">Theorem 1]</ref>.</p><p>Clustered FL <ref type="bibr" target="#b55">[56,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b43">44]</ref> addresses the potential lack of a global model by assuming that clients can be partitioned into several clusters. Clients belonging to the same cluster share the same optimal model, but those models can be arbitrarily different across clusters (see <ref type="bibr">[56,</ref>  <ref type="bibr">Assumption 2]</ref> for a rigorous formulation). During training, clients learn the cluster to which they belong as well as the cluster model. The Clustered FL assumption is also quite limiting, as no knowledge transfer is possible across clusters. In the extreme case where each client has its own optimal local model (recall the example on language modeling), the number of clusters coincides with the number of clients and no federated learning is possible.</p><p>Multi-Task Learning (MTL) has recently emerged as an alternative approach to learn personalized models in the federated setting and allows for more nuanced relations among clients' models <ref type="bibr" target="#b58">[59,</ref><ref type="bibr" target="#b62">63,</ref><ref type="bibr" target="#b66">67,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b15">16]</ref>. The authors of <ref type="bibr" target="#b58">[59,</ref><ref type="bibr" target="#b62">63]</ref> were the first to frame FL personalization as a MTL problem. In particular, they defined federated MTL as a penalized optimization problem, where the penalization term models relationships among tasks (clients). The work <ref type="bibr" target="#b58">[59]</ref> proposed the MOCHA algorithm for the client-server scenario, while <ref type="bibr" target="#b62">[63,</ref><ref type="bibr" target="#b66">67]</ref> presented decentralized algorithms for the same problem. Unfortunately, these algorithms can only learn simple models (linear models or linear combination of pre-trained models), because of the complex penalization term. Other MTL-based approaches <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b35">36]</ref> are able to train more general models at the cost of considering simpler penalization terms (e.g., the distance to the average model), thereby losing the capability to capture complex relations among tasks. Moreover, a general limitation of this line of work is that the penalization term is justified qualitatively and not on the basis of clear statistical assumptions on local data distributions.</p><p>More recently, <ref type="bibr" target="#b56">[57]</ref> proposed pFedHN. pFedHN feeds local clients' representations to a global (across clients) hypernetwork, which can output personalized heterogeneous models. Unfortunately, the hypernetwork has a large memory footprint already for small clients' models (e.g., the hypernetwork in the experiments in <ref type="bibr" target="#b56">[57]</ref> has 100 more parameters than the output model). Hence, it is not clear if pFedHN can scale to more complex models. Moreover, pFedHN requires each client to communicate multiple times for the server to learn meaningful representations. Therefore, its performance is likely to deteriorate when clients participate only once (or few times) to training, as it is the case for large-scale cross-device FL training. Furthermore, even once the hypernetwork parameters have been learned, training personalized models for new clients still requires multiple client-server communication rounds. More similar to our approach, FedFOMO <ref type="bibr" target="#b67">[68]</ref> lets each client interpolate other clients' local models with opportune weights learned during training. However, this method lacks both theoretical justifications for such linear combinations and convergence guarantees. Moreover, FedFOMO requires the presence of a powerful server able to 1) store all individual local models and 2) learn for each client-through repeated interactions-which other clients' local models may be useful. Therefore, FedFOMO is not suited for cross-device FL where the number of clients may be very large (e.g., 10 5 -10 7 participating clients <ref type="bibr">[28,</ref>  <ref type="bibr">Table 2]</ref>) and a given client may only participate in a single training round.</p><p>Overall, although current personalization approaches can lead to superior empirical performance in comparison to a shared global model or individually trained local models, it is still not well understood whether and under which conditions clients are guaranteed to benefit from collaboration.</p><p>Our contributions. In this work, we first show that federated learning is impossible without assumptions on local data distributions. Motivated by this negative result, we formulate a general and flexible assumption: the data distribution of each client is a mixture of M underlying distributions. The proposed formulation has the advantage that each client can benefit from knowledge distilled from all other clients' datasets (even if any two clients can be arbitrarily different from each other). We also show that this assumption encompasses most of the personalized FL approaches previously proposed in the literature.</p><p>In our framework, a personalized model is a linear combination of M shared component models. All clients jointly learn the M components, while each client learns its personalized mixture weights. We show that federated EM-like algorithms can be used for training. In particular, we propose FedEM and D-FedEM for the client-server and the fully decentralized settings, respectively, and we prove convergence guarantees. Our approach also provides a principled and efficient way to infer personalized models for clients unseen at training time. Our algorithms can easily be adapted to solve more general problems in a novel framework, which can be seen as a federated extension of the centralized surrogate optimization approach in <ref type="bibr" target="#b42">[43]</ref>. To the best of our knowledge, our paper is the first work to propose federated surrogate optimization algorithms with convergence guarantees.</p><p>Through extensive experiments on FL benchmark datasets, we show that our approach generally yields models that 1) are on average more accurate, 2) are fairer across clients, and 3) generalize better to unseen clients than state-of-the-art personalized and non-personalized FL approaches.</p><p>Paper outline. The rest of the paper is organized as follows. In Section 2 we provide our impossibility result, introduce our main assumptions, and show that several popular personalization approaches can be obtained as special cases of our framework. Section 3 describes our algorithms, states their convergence results, and presents our general federated surrogate optimization framework. Finally, we provide experimental results in Section 4 before concluding in Section 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Problem Formulation</head><p>We consider a (countable) set T of classification (or regression) tasks which represent the set of possible clients. We will use the terms task and client interchangeably. Data at client t ∈ T is generated according to a local distribution D t over X × Y. Local data distributions {D t } t∈T are in general different, thus it is natural to fit a separate model (hypothesis) h t ∈ H to each data distribution D t . The goal is then to solve (in parallel) the following optimization problems</p><formula xml:id="formula_0">∀t ∈ T , minimize ht∈H L Dt (h t ),<label>(1)</label></formula><p>where h t : X → ∆ |Y| (∆ D denoting the unitary simplex of dimension D), l : ∆ |Y| × Y → R + is a loss function, <ref type="foot" target="#foot_0">1</ref> and L Dt (h t ) = E (x,y)∼Dt [l(h t (x), y)] is the true risk of a model h t under data distribution D t . For (x, y) ∈ X × Y, we will denote the joint distribution density associated to D t by p t (x, y), and the marginal densities by p t (x) and p t (y).</p><p>A set of T clients [T ] {1, 2, . . . T } ⊆ T participate to the initial training phase; other clients may join the system in a later stage. We denote by S t = {s</p><formula xml:id="formula_1">(i) t = (x (i) t , y<label>(i)</label></formula><p>t )} nt i=1 the dataset at client t ∈ [T ] drawn i.i.d. from D t , and by n = T t=1 n t the total dataset size. The idea of federated learning is to enable each client to benefit from data samples available at other clients in order to get a better estimation of L Dt , and therefore get a model with a better generalization ability to unseen examples.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">An Impossibility Result</head><p>We start by showing that some assumptions on the local distributions p t (x, y), t ∈ T are needed for federated learning to be possible, i.e., for each client to be able to take advantage of the data at other clients. This holds even if all clients participate to the initial training phase (i.e., T = [T ]).</p><p>We consider the classic PAC learning framework where we fix a class of models H and seek a learning algorithm which is guaranteed, for all possible data distributions over X × Y, to return with high probability a model with expected error -close to the best possible error in the class H. The worst-case sample complexity then refers to the minimum amount of labeled data required by any algorithm to reach a given -approximation.</p><p>Our impossibility result for FL is based on a reduction to an impossibility result for Semi-Supervised Learning (SSL), which is the problem of learning from a training set with only a small amount of labeled data. The authors of <ref type="bibr" target="#b3">[4]</ref> conjectured that, when the quantity of unlabeled data goes to infinity, the worst-case sample complexity of SSL improves over supervised learning at most by a constant factor that only depends on the hypothesis class <ref type="bibr" target="#b3">[4,</ref><ref type="bibr">Conjecture 4]</ref>. This conjecture was later proved for the realizable case and hypothesis classes of finite VC dimension <ref type="bibr" target="#b12">[13,</ref><ref type="bibr">Theorem 1]</ref>, even when the marginal distribution over the domain set X is known [21, Theorem 2]. <ref type="foot" target="#foot_1">2</ref>In the context of FL, if the marginal distributions p t (x) are identical, but the conditional distributions p t (y|x) can be arbitrarily different, then each client t can learn using: 1) its own local labeled dataset, and 2) the other clients' datasets, but only as unlabeled ones (because their labels have no relevance for t). The FL problem, with T clients, then reduces to T parallel SSL problems, or more precisely, it is at least as difficult as T parallel SSL problems (because client t has no direct access to the other local datasets but can only learn through the communication exchanges allowed by the FL algorithm). The SSL impossibility result implies that, without any additional assumption on the local distributions p t (x, y) , t ∈ [T ], any FL algorithm can reduce the sample complexity of client-t's problem in <ref type="bibr" target="#b0">(1)</ref> only by a constant in comparison to local learning, independently of how many other clients participate to training and how large their datasets' sizes are.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Learning under a Mixture Model</head><p>Motivated by the above impossibility result, in this work we propose to consider that each local data distribution D t is a mixture of M underlying distributions Dm , 1 ≤ m ≤ M , as formalized below. Assumption 1. There exist M underlying (independent</p><formula xml:id="formula_2">) distributions Dm , 1 ≤ m ≤ M , such that for t ∈ T , D t is mixture of the distributions { Dm } M m=1 with weights π * t = [π * t1 , . . . , π * tM ] ∈ ∆ M , i.e. z t ∼ M(π * t ), ((x t , y t ) |z t = m) ∼ Dm , ∀t ∈ T ,<label>(2)</label></formula><p>where M(π) is a multinomial (categorical) distribution with parameters π.</p><p>Similarly to what was done above, we use p m (x, y), p m (x), and p m (y) to denote the probability distribution densities associated to Dm . We further assume that marginals over X are identical. Assumption 2. For all m ∈ [M ], we have p m (x) = p(x).</p><p>Assumption 2 is not strictly required for our analysis to hold, but, in the most general case, solving Problem (1) requires to learn generative models. Instead, under Assumption 2 we can restrict our attention to discriminative models (e.g., neural networks). <ref type="foot" target="#foot_2">3</ref> More specifically, we consider a parameterized set of models H with the following properties. </p><p>where c ∈ R is a normalization constant. The function l(•, •) is then the log-loss associated to p m (y|x).</p><p>We refer to the hypotheses in H as component models or simply components. We denote by Θ * ∈ R M ×d the matrix whose m-th row is θ * m , and by Π * ∈ ∆ T ×M the matrix whose t-th row is π * t ∈ ∆ M . Similarly, we will use Θ and Π to denote arbitrary parameters. Remark 1. Assumptions 2-3 are mainly technical and are not required for our approach to work in practice. Experiments in Section 4 show that our algorithms perform well on standard FL benchmark datasets, for which these assumptions do not hold in general.</p><p>Note that, under the above assumptions, p t (x, y) depends on Θ * and π * t . Moreover, we can prove (see App. A) that the optimal local model h * t ∈ H for client t is a weighted average of models in H. Proposition 2.1. Let l(•, •) be the mean squared error loss, the logistic loss or the cross-entropy loss, and Θ and Π be a solution of the following optimization problem: minimize</p><formula xml:id="formula_4">Θ,Π E t∼D T E (x,y)∼Dt [-log p t (x, y|Θ, π t )] ,<label>(4)</label></formula><p>where D T is any distribution with support T . Under Assumptions 1, 2, and 3, the predictors</p><formula xml:id="formula_5">h * t = M m=1 πtm h θm (x) , ∀t ∈ T<label>(5)</label></formula><p>minimize E (x,y)∼Dt [l(h t (x), y)] and thus solve Problem (1).</p><p>Proposition 2.1 suggests the following approach to solve Problem <ref type="bibr" target="#b0">(1)</ref>. First, we estimate the parameters Θ and πt , 1 ≤ t ≤ T , by minimizing the empirical version of Problem (4) on the training data, i.e., minimizing:</p><formula xml:id="formula_6">f (Θ, Π) - log p(S 1:T |Θ, Π) n - 1 n T t=1 nt i=1 log p(s (i) t |Θ, π t ),<label>(6)</label></formula><p>which is the (negative) likelihood of the probabilistic model (2). <ref type="foot" target="#foot_3">4</ref> Second, we use <ref type="bibr" target="#b4">(5)</ref> to get the client predictor for the T clients present at training time. Finally, to deal with a client t new / ∈ [T ] not seen during training, we keep the mixture component models fixed and simply choose the weights π tnew that maximize the likelihood of the client data and get the client predictor via (5).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Generalizing Existing Frameworks</head><p>Before presenting our federated learning algorithms in Section 3, we show that the generative model in Assumption 1 extends some popular multi-task/personalized FL formulations in the literature.</p><p>Clustered Federated Learning <ref type="bibr" target="#b55">[56,</ref><ref type="bibr" target="#b19">20]</ref> assumes that each client belongs to one among C clusters and proposes that all clients in the same cluster learn the same model. Our framework recovers this scenario considering M = C and π * tc = 1 if task (client) t is in cluster c and π * tc = 0 otherwise. Personalization via model interpolation <ref type="bibr" target="#b43">[44,</ref><ref type="bibr" target="#b13">14]</ref> relies on learning a global model h glob and T local models h loc,t , and then using at each client the linear interpolation h t = α t h loc,t + (1 -α t )h glob . Each client model can thus be seen as a linear combination of M = T + 1 models h m = h loc,m for m ∈ [T ] and h 0 = h glob with specific weights π * tt = α t , π * t0 = 1 -α t , and π * tt = 0 for t ∈ [T ] \ {t}. Federated MTL via task relationships. The authors of <ref type="bibr" target="#b58">[59]</ref> proposed to learn personalized models by solving the following optimization problem inspired from classic MTL formulations:</p><formula xml:id="formula_7">min W,Ω T t=1 nt i=1 l(h wt (x (i) t ), y (i) t ) + λ tr (W ΩW ) ,<label>(7)</label></formula><p>where h wt are linear predictors parameterized by the rows of matrix W and the matrix Ω captures task relationships (similarity). This formulation is motivated by the alternating structure optimization method (ASO) <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b69">70]</ref>. In App. B, we show that, when predictors h θ * m are linear and have bounded norm, our framework leads to the same ASO formulation that motivated Problem <ref type="bibr" target="#b6">(7)</ref>. Problem <ref type="bibr" target="#b6">(7)</ref> can also be justified by probabilistic priors <ref type="bibr" target="#b68">[69]</ref> or graphical models <ref type="bibr" target="#b34">[35]</ref> (see <ref type="bibr" target="#b58">[59,</ref><ref type="bibr">App. B.1]</ref>). Similar considerations hold for our framework (see again App. B). Reference <ref type="bibr" target="#b66">[67]</ref> extends the approach in <ref type="bibr" target="#b58">[59]</ref> by letting each client learn a personalized model as a weighted combination of M known hypotheses. Our approach is more general and flexible as clients learn both the weights and the hypotheses. Finally, other personalized FL algorithms, like pFedMe <ref type="bibr" target="#b15">[16]</ref>, FedU <ref type="bibr" target="#b16">[17]</ref>, and those studied in <ref type="bibr" target="#b23">[24]</ref> and in <ref type="bibr" target="#b22">[23]</ref>, can be framed as special cases of formulation <ref type="bibr" target="#b6">(7)</ref>. Their assumptions can thus also be seen as a particular case of our framework.</p><p>3 Federated Expectation-Maximization</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Centralized Expectation-Maximization</head><p>Our goal is to estimate the optimal components' parameters Θ * = (θ * m ) 1≤m≤M and mixture weights Π * = (π * t ) 1≤t≤T by minimizing the negative log-likelihood f (Θ, Π) in <ref type="bibr" target="#b5">(6)</ref>. A natural approach to solve such non-convex problems is the Expectation-Maximization algorithm (EM), which alternates between two steps. Expectation steps update the distribution (denoted by q t ) over the latent variables z (i) t for every data point s</p><formula xml:id="formula_8">(i) t = (x (i) t , y (i) t )</formula><p>given the current estimates of the parameters {Θ, Π}. Maximization steps update the parameters {Θ, Π} by maximizing the expected log-likelihood, where the expectation is computed according to the current latent variables' distributions.</p><p>The following proposition provides the EM updates for our problem (proof in App. C). Proposition 3.1. Under Assumptions 1 and 2, at the k-th iteration the EM algorithm updates parameter estimates through the following steps:</p><formula xml:id="formula_9">E-step: q k+1 t (z (i) t = m) ∝ π k tm • exp -l(h θ k m (x (i) t ), y (i) t ) , t ∈ [T ], m ∈ [M ], i ∈ [n t ]<label>(8)</label></formula><p>M-step:</p><formula xml:id="formula_10">π k+1 tm = nt i=1 q k+1 t (z (i) t = m) n t , t ∈ [T ], m ∈ [M ] (9) θ k+1 m ∈ arg min θ∈R d T t=1 nt i=1 q k+1 t (z (i) t = m)l h θ (x (i) t ), y (i) t , m ∈ [M ]<label>(10)</label></formula><p>The EM updates in Proposition 3.1 have a natural interpretation. In the E-step, given current component models Θ k and mixture weights Π k , (8) updates the a-posteriori probability q k+1 t (z</p><formula xml:id="formula_11">(i) t = m) that point s (i)</formula><p>t of client t was drawn from the m-th distribution based on the current mixture weight π k tm and on how well the corresponding component θ k m classifies s (i)</p><p>t . The M-step consists of two updates under fixed probabilities q k+1 t . First, <ref type="bibr" target="#b8">(9)</ref> updates the mixture weights π k+1 t to reflect the prominence of each distribution Dm in S t as given by q k+1 t . Finally, <ref type="bibr" target="#b9">(10)</ref> updates the components' parameters Θ k+1 by solving M independent, weighted empirical risk minimization problems with weights given by q k+1 t . These weights aim to construct an unbiased estimate of the true risk over each underlying distribution Dm using only points sampled from the client mixtures, similarly to importance sampling strategies used to learn from data with sample selection bias <ref type="bibr" target="#b60">[61,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b63">64]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Client-Server Algorithm</head><p>Federated learning aims to train machine learning models directly on the clients, without exchanging raw data, and thus we should run EM while assuming that only client t has access to dataset S t . The E-step <ref type="bibr" target="#b7">(8)</ref> and the Π update ( <ref type="formula">9</ref>) in the M-step operate separately on each local dataset S t and can thus be performed locally at each client t. On the contrary, the Θ update (10) requires interaction with other clients, since the computation spans all data samples S 1:T .</p><p>In this section, we consider a client-server setting, in which each client t can communicate only with a centralized server (the orchestrator) and wants to learn components' parameters Θ * = (θ * m ) 1≤m≤M and its own mixture weights π * t . We propose the algorithm FedEM for Federated Expectation-Maximization (Alg. 1). FedEM proceeds through communication rounds similarly to most FL algorithms including FedAvg <ref type="bibr" target="#b46">[47]</ref>, FedProx <ref type="bibr" target="#b37">[38]</ref>, SCAFFOLD <ref type="bibr" target="#b28">[29]</ref>, and pFedMe <ref type="bibr" target="#b15">[16]</ref>. At each round, 1) the central server broadcasts the (shared) component models to the clients, 2) each client locally updates components and its personalized mixture weights, and 3) sends the updated components back to the server, 4) the server aggregates the updates. The local update performed at client t consists in performing the steps in ( <ref type="formula" target="#formula_9">8</ref>) and ( <ref type="formula">9</ref>) and updating the local estimates of θ m through a solver which approximates the exact minimization in (10) using only the local dataset S t (see <ref type="bibr">line 7)</ref>. FedEM can operate with different local solvers-even different across clients-as far as they satisfy some local improvement guarantees (see the discussion in App. H). In what follows, we restrict our focus on the practically important case where the local solver performs multiple stochastic gradient descent updates (local SGD <ref type="bibr" target="#b59">[60]</ref>). Under the following standard assumptions (see e.g., <ref type="bibr" target="#b65">[66]</ref>), FedEM converges to a stationary point of f . Below, we use the more compact notation l(θ; s </p><formula xml:id="formula_12">(i) t ) l(h θ (x (i) t ), y (i) t )</formula><formula xml:id="formula_13">1 K K k=1 E ∇ Θ f Θ k , Π k 2 F ≤ O 1 √ K , 1 K K k=1 ∆ Π f (Θ k , Π k ) ≤ O 1 K 3/4 , (<label>11</label></formula><formula xml:id="formula_14">)</formula><p>where the expectation is over the random batches samples, and</p><formula xml:id="formula_15">∆ Π f (Θ k , Π k ) f Θ k , Π k - f Θ k , Π k+1 ≥ 0.</formula><p>Theorem 3.2 (proof in App. G.1) expresses the convergence of both sets of parameters (Θ and Π) to a stationary point of f . Indeed, the gradient of f with respect to Θ becomes arbitrarily small (left inequality in <ref type="bibr" target="#b10">(11)</ref>) and the update in Eq. ( <ref type="formula">9</ref>) leads to arbitrarily small improvements of f (right inequality in <ref type="bibr" target="#b10">(11)</ref>).</p><p>We conclude this section observing that FedEM allows an unseen client, i.e., a client t new / ∈ [T ] arriving after the distributed training procedure, to learn its personalized model. The client simply retrieves the learned components' parameters Θ K and computes its personalized weights π tnew (starting for example from a uniform initialization) through one E-step <ref type="bibr" target="#b7">(8)</ref> and the first update in the M-step (9).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Fully Decentralized Algorithm</head><p>In some cases, clients may want to communicate directly in a peer-to-peer fashion instead of relying on the central server mediation [see 28, Section 2.1]. In fact, fully decentralized schemes may provide stronger privacy guarantees <ref type="bibr" target="#b11">[12]</ref> and speed-up training as they better use communication resources <ref type="bibr" target="#b40">[41,</ref><ref type="bibr" target="#b45">46]</ref> and reduce the effect of stragglers <ref type="bibr" target="#b49">[50]</ref>. For these reasons, they have attracted significant interest recently in the machine learning community <ref type="bibr" target="#b40">[41,</ref><ref type="bibr" target="#b62">63,</ref><ref type="bibr" target="#b41">42,</ref><ref type="bibr" target="#b61">62,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b50">51,</ref><ref type="bibr" target="#b45">46,</ref><ref type="bibr" target="#b30">31]</ref>. We refer to <ref type="bibr" target="#b48">[49]</ref> for a comprehensive survey of fully decentralized optimization (also known as consensus-based optimization), and to <ref type="bibr" target="#b30">[31]</ref> for a unified theoretical analysis of decentralized SGD.</p><p>We propose D-FedEM (Alg. 4 in App. D.2), a fully decentralized version of our federated expectation maximization algorithm. As in FedEM, the M-step for Θ update is replaced by an approximate maximization step consisting of local updates. The global aggregation step in FedEM (Alg. 1, line 10) is replaced by a partial aggregation step, where each client computes a weighted average of its current components and those of a subset of clients (its neighborhood), which may vary over time. The convergence of decentralized optimization schemes requires certain assumptions to guarantee that each client can influence the estimates of other clients over time. In our paper, we consider the general assumption in <ref type="bibr" target="#b30">[31,</ref><ref type="bibr">Assumption 4]</ref> (restated as Assumption 8 in App. E for completeness). For instance, this assumption is satisfied if the graph of clients' communications is strongly connected every τ rounds. D-FedEM converges to a stationary point of f (formal statement in App. E and proof in App. G.2). Theorem 3.3 (Informal). In the same setting of Theorem 3.2 and under the additional Assumption 8, D-FedEM's individual estimates (Θ k t ) 1≤t≤T converge to a common value Θk . Moreover, Θk and Π k converge to a stationary point of f .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Federated Surrogate Optimization</head><p>FedEM and D-FedEM can be seen as particular instances of a more general framework-of potential interest for other applications-that we call federated surrogate optimization.</p><p>The standard majorization-minimization principle <ref type="bibr" target="#b33">[34]</ref> iteratively minimizes, at each iteration k, a surrogate function g k majorizing the objective function f . The work <ref type="bibr" target="#b42">[43]</ref> studied this approach when each g k is a first-order surrogate of f (the formal definition from <ref type="bibr" target="#b42">[43]</ref> is given in App. F.1).</p><p>Our novel federated surrogate optimization framework considers that the objective function f is a weighted sum f = T t=1 ω t f t of T functions and iteratively minimizes f in a distributed fashion using partial first-order surrogates g k t for each function f t . "Partial" refers to the fact that g k t is not required to be a first order surrogate wrt the whole set of parameters, as defined formally below. Definition 1 (Partial first-order surrogate). A function g(u, v) : R du × V → R is a partial-first-order surrogate of f (u, v) wrt u near (u 0 , v 0 ) ∈ R du × V when the following conditions are satisfied:</p><formula xml:id="formula_16">1. g(u, v) ≥ f (u, v) for all u ∈ R du and v ∈ V; 2. r(u, v) g(u, v) -f (u, v</formula><p>) is differentiable and L-smooth with respect to u. Moreover, we have r(u 0 , v 0 ) = 0 and</p><formula xml:id="formula_17">∇ u r(u 0 , v 0 ) = 0. 3. g(u, v 0 ) -g(u, v) = d V (v 0 , v) for all u ∈ R du and v ∈ arg min v ∈V g(u, v ), where d V is non-negative and d V (v, v ) = 0 ⇐⇒ v = v .</formula><p>Under the assumption that each client t can compute a partial first-order surrogate of f t , we propose algorithms for federated surrogate optimization in both the client-server setting (Alg. 3) and the fully decentralized one (Alg. 5) and prove their convergence under mild conditions (App. G.1 and G.2).</p><p>FedEM and D-FedEM can be seen as particular instances of these algorithms and Theorem. 3.2 and Theorem. 3.3 follow from the more general convergence results for federated surrogate optimization. We can also use our framework to analyze the convergence of other FL algorithms such as pFedMe <ref type="bibr" target="#b15">[16]</ref>, as we illustrate in App. F.3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>Datasets and models. We evaluated our method on five federated benchmark datasets spanning a wide range of machine learning tasks: image classification (CIFAR10 and CIFAR100 <ref type="bibr" target="#b32">[33]</ref>), handwritten character recognition (EMNIST <ref type="bibr" target="#b7">[8]</ref> and FEMNIST <ref type="bibr" target="#b6">[7]</ref>), <ref type="foot" target="#foot_4">5</ref> and language modeling (Shakespeare <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b46">47]</ref>). Shakespeare dataset (resp. FEMNIST) was naturally partitioned by assigning all lines from the same characters (resp. all images from the same writer) to the same client. We created federated versions of CIFAR10 and EMNIST by distributing samples with the same label across the clients according to a symmetric Dirichlet distribution with parameter 0.4, as in <ref type="bibr" target="#b64">[65]</ref>. For CI-FAR100, we exploited the availability of "coarse" and "fine" labels, using a two-stage Pachinko allocation method <ref type="bibr" target="#b38">[39]</ref> to assign 600 sample to each of the 100 clients, as in <ref type="bibr" target="#b53">[54]</ref>. We also evaluated our method on a synthetic dataset verifying Assumptions 1-3. For all tasks, we randomly split each local dataset into training (60%), validation (20%) and test (20%) sets. Table <ref type="table" target="#tab_1">1</ref> summarizes datasets, models, and number of clients (more details can be found in App. I.1). Code is available at https://github.com/omarfoq/FedEM.</p><p>Other FL approaches. We compared our algorithms with global models trained with FedAvg <ref type="bibr" target="#b46">[47]</ref> and FedProx <ref type="bibr" target="#b37">[38]</ref> as well as different personalization approaches: a personalized model trained only on the local dataset, FedAvg with local tuning (FedAvg+) <ref type="bibr" target="#b26">[27]</ref>, Clustered FL <ref type="bibr" target="#b55">[56]</ref> and pFedMe <ref type="bibr" target="#b15">[16]</ref>.</p><p>For each method and each task, the learning rate and the other hyperparameters were tuned via grid search (details in App. I. Average performance of personalized models. The performance of each personalized model (which is the same for all clients in the case of FedAvg and FedProx) is evaluated on the local test dataset (unseen at training). Table <ref type="table" target="#tab_2">2</ref> shows the average weighted accuracy with weights proportional to local dataset sizes. We observe that FedEM obtains the best performance across all datasets.</p><p>Fairness across clients. FedEM's improvement in terms of average accuracy could be the result of learning particularly good models for some clients at the expense of bad models for other clients.</p><p>Table <ref type="table" target="#tab_2">2</ref> shows the bottom decile of the accuracy of local models, i.e., the (T /10)-th worst accuracy (the minimum accuracy is particularly noisy, notably because some local test datasets are very small).</p><p>Even clients with the worst personalized models are still better off when FedEM is used for training.</p><p>Clients sampling. In cross-device federated learning, only a subset of clients may be available at each round. We ran CIFAR10 experiments with different levels of participation: at each round a given fraction of all clients were sampled uniformly without replacement. We restrict the comparison to FedEM and FedAvg+, as 1) FedAvg+ performed better than FedProx and FedAvg in the previous CIFAR10 experiments, 2) it is not clear how to extend pFedMe and Clustered FL to handle client sampling. Results in Fig. <ref type="figure">1</ref> (left) show that FedEM is more robust to low clients' participation levels. We provide additional results on client sampling, including a comparison with APFL <ref type="bibr" target="#b13">[14]</ref>, in App. J.6.</p><p>Generalization to unseen clients. As discussed in Section 3.2, FedEM allows new clients arriving after the distributed training to easily learn their personalized models. With the exception of FedAvg+, it is not clear how the other personalized FL algorithms should be extended to tackle the same goal (see discussion in App. J.3). In order to evaluate the quality of new clients' personalized models, we performed an experiment where only 80% of the clients ("old" clients) participate to the training. The remaining 20% join the system in a second phase and use their local training datasets to learn their personalized weights. Table <ref type="table" target="#tab_3">3</ref> shows that FedEM allows new clients to learn a personalized model at least as good as FedAvg's global one and always better than FedAvg+'s one. Unexpectedly, new clients achieve sometimes a significantly higher test accuracy than old clients (e.g., 47.5% against 44.1% on CIFAR100). Our investigation in App. J.3 suggests that, by selecting their mixture weights on local datasets that were not used to train the components, new clients can compensate for potential overfitting in the initial training phase. We also investigate in App. J.3 the effect of the local dataset size on the accuracy achieved by unseen clients, showing that personalization is effective even when unseen clients have small datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Effect of M .</head><p>A limitation of FedEM is that each client needs to update and transmit M components at each round, requiring roughly M times more computation and M times larger messages. Nevertheless, the number of components to consider in practice is quite limited. We used M = 3 in our previous experiments, and Fig. <ref type="figure">1</ref> (right) shows that larger values do not yield much improvement and M = 2 already provides a significant level of personalization. In all experiments above, the number of communication rounds allowed all approaches to converge. As a consequence, even if other methods Figure <ref type="figure">1</ref>: Effect of client sampling rate (left) and FedEM number of mixture components M (right) on the test accuracy for CIFAR10 <ref type="bibr" target="#b32">[33]</ref>.</p><p>trained over M = 3 times more rounds-in order to have as much computation and communication as FedEM-the conclusions would not change. As a final experiment, we considered a time-constrained setting, where FedEM is limited to run one third (= 1/M ) of the rounds (Table <ref type="table" target="#tab_10">7</ref> in App. J.5). Even if FedEM does not reach its maximum accuracy, it still outperforms the other methods on 3 datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>In this paper, we proposed a novel federated MTL approach based on the flexible assumption that local data distributions are mixtures of underlying distributions. Our EM-like algorithms allow clients to jointly learn shared component models and personalized mixture weights in client-server and fully decentralized settings. We proved convergence guarantees for our algorithms through a general federated surrogate optimization framework which can be used to analyze other FL formulations.</p><p>Extensive empirical evaluation shows that our approach learns models with higher accuracy and fairness than state-of-the-art FL algorithms, even for clients not present at training time.</p><p>In future work, we aim to reduce the local computation and communication of our algorithms. Aside from standard compression schemes <ref type="bibr" target="#b21">[22]</ref>, a promising direction is to limit the number of component models that a client updates/transmits at each step. This could be done in an adaptive manner based on the client's current mixture weights. A simultaneously published work <ref type="bibr" target="#b14">[15]</ref> proposes a federated EM algorithm (also called FedEM), which does not address personalization but reduces communication requirements by compressing appropriately defined complete data sufficient statistics.</p><p>A second interesting research direction is to study personalized FL approaches under privacy constraints (quite unexplored until now with the notable exception of <ref type="bibr" target="#b2">[3]</ref>). Some features of our algorithms may be beneficial for privacy (e.g., the fact that personalized weights are kept locally and that all users contribute to all shared models). We hope to design differentially private versions of our algorithms and characterize their privacy-utility trade-offs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Acknowledgements</head><p>This work has been supported by the French government, through the 3IA Côte d'Azur Investments in the Future project managed by the National Research Agency (ANR) with the reference number ANR-19-P3IA-0002, and through grants ANR-16-CE23-0016 (Project PAMELA) and ANR-20-CE23-0015 (Project PRIDE). The authors are grateful to the OPAL infrastructure from Université Côte d'Azur for providing computational resources and technical support. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Proof of Proposition 2.1</head><p>For h ∈ H and (x, y) ∈ X × Y, let p h (y|x) denote the conditional probability distribution of y given x under model h, i.e.,</p><formula xml:id="formula_18">p h (y|x) e c h (x) × exp -l (h (x) , y) ,<label>(12)</label></formula><p>where</p><formula xml:id="formula_19">c h (x) -log y∈Y exp -l (h (x) , y) d y .<label>(13)</label></formula><p>We also remind that the entropy of a probability distribution q over Y is given by</p><formula xml:id="formula_20">H (q) - y∈Y q (y) • log q (y) d y,<label>(14)</label></formula><p>and that the Kullback-Leibler divergence between two probability distributions q 1 and q 2 over Y is given by</p><formula xml:id="formula_21">KL (q 1 ||q 2 ) y∈Y q 1 (y) • log q 1 (y) q 2 (y) d y. (<label>15</label></formula><formula xml:id="formula_22">)</formula><p>Proposition 2.1. Let l(•, •) be the mean squared error loss, the logistic loss or the cross-entropy loss, and Θ and Π be a solution of the following optimization problem:</p><formula xml:id="formula_23">minimize Θ,Π E t∼D T E (x,y)∼Dt [-log p t (x, y|Θ, π t )] ,<label>(4)</label></formula><p>where D T is any distribution with support T . Under Assumptions 1, 2, and 3, the predictors</p><formula xml:id="formula_24">h * t = M m=1 πtm h θm , ∀t ∈ T<label>(5)</label></formula><p>minimize E (x,y)∼Dt [l(h t (x), y)] and thus solve Problem (1).</p><p>Proof. We prove the result for each of the three possible cases of the loss function. We verify that c h does not depend on h in each of the three cases, then we use Lemma A.3 to conclude.</p><p>Mean Squared Error Loss This is the case of a regression problem where Y = R d for some d &gt; 0. For x, y ∈ X × Y and h ∈ H, we have</p><formula xml:id="formula_25">p h (y|x) = 1 (2π) d • exp - h (x) -y 2 2 ,<label>(16)</label></formula><p>and</p><formula xml:id="formula_26">c h (x) = -log (2π) d (<label>17</label></formula><formula xml:id="formula_27">)</formula><p>Logistic Loss This is the case of a binary classification problem where Y = {0, 1}. For x, y ∈ X × Y and h ∈ H, we have</p><formula xml:id="formula_28">p h (y|x) = (h (x)) y • (1 -h (x)) 1-y ,<label>(18)</label></formula><p>and</p><formula xml:id="formula_29">c h (x) = 0<label>(19)</label></formula><p>Cross-entropy loss This is the case of a classification problem where Y = [L] for some L &gt; 1.</p><p>For x, y ∈ X × Y and h ∈ H, we have</p><formula xml:id="formula_30">p h (y|x) = L l=1 (h (x)) 1 {y=l} ,<label>(20)</label></formula><p>and</p><formula xml:id="formula_31">c h (x) = 0 (21) Conclusion For t ∈ T , consider a predictor h * t minimizing E (x,y)∼Dt [l(h t (x), y)]. Using Lemma A.3, for (x, y) ∈ X × Y, we have p h * t (y|x) = M m=1 πtm • p m y|x, θm .<label>(22)</label></formula><p>We multiply both sides of this equality by y and we integrate over y ∈ Y. Note that in all three cases we have ∀x ∈ X ,</p><formula xml:id="formula_32">y∈Y y • p h (•|x) d y = h(x).<label>(23)</label></formula><p>It follows that</p><formula xml:id="formula_33">h * t = M m=1 πtm h θm , ∀t ∈ T . (<label>24</label></formula><formula xml:id="formula_34">)</formula><p>Supporting Lemmas Lemma A.1. Suppose that Assumptions 1 and 3 hold, and consider Θ and Π to be a solution of Problem (4). Then</p><formula xml:id="formula_35">p t (x, y| Θ, πt ) = p t (x, y|Θ * , π * t ), ∀t ∈ T .<label>(25)</label></formula><p>Proof. For t ∈ T ,</p><formula xml:id="formula_36">E (x,y)∼Dt -log p t (x, y| Θ, πt )<label>(26)</label></formula><p>= -</p><formula xml:id="formula_37">(x,y)∈X ×Y p t (x, y|Θ * , π * t ) • log p t (x, y| Θ, πt ) d x d y<label>(27)</label></formula><p>= -</p><formula xml:id="formula_38">(x,y)∈X ×Y p t (x, y|Θ * , π * t ) • log p t (x, y| Θ, πt ) p t (x, y|Θ * , π * t ) d x d y - (x,y)∈X ×Y p t (x, y|Θ * , π * t ) • log p t (x, y|Θ * , π * t ) d x d y (28) = KL p t (•|Θ * , π * t ) p t • | Θ, πt + H [p t (•|Θ * , π * t )] ,<label>(29)</label></formula><p>Since the KL divergence is non-negative, we have</p><formula xml:id="formula_39">E (x,y)∼Dt -log p t (x, y| Θ, πt ) ≥ H [p t (•|Θ * , π * t )] = E (x,y)∼Dt [-log p t (x, y|Θ * , π * t )] .<label>(30)</label></formula><p>Taking the expectation over t ∼ D T , we write</p><formula xml:id="formula_40">E t∼D T E (x,y)∼Dt -log p t (x, y| Θ, πt ) ≥ E t∼D T E (x,y)∼Dt [-log p t (x, y|Θ * , π * t )] .<label>(31)</label></formula><p>Since Θ and Π is a solution of Problem (4), we also have</p><formula xml:id="formula_41">E t∼D T E (x,y)∼Dt -log p t (x, y| Θ, πt ) ≤ E t∼D T E (x,y)∼Dt [-log p t (x, y|Θ * , π * t )] .<label>(32)</label></formula><p>Combining ( <ref type="formula" target="#formula_40">31</ref>), <ref type="bibr" target="#b31">(32)</ref>, and (29), we have</p><formula xml:id="formula_42">E t∼D T KL p t (•|Θ * , π * t ) p t • | Θ, πt = 0. (<label>33</label></formula><formula xml:id="formula_43">)</formula><p>Since KL divergence is non-negative, and the support of D T is the countable set T , it follows that</p><formula xml:id="formula_44">∀t ∈ T , KL p t (•|Θ * , π * t ) p t • | Θ, πt = 0.<label>(34)</label></formula><p>Thus,</p><formula xml:id="formula_45">p t (x, y| Θ, πt ) = p t (x, y|Θ * , π * t ), ∀t ∈ T . (<label>35</label></formula><formula xml:id="formula_46">)</formula><p>Lemma A.2. Consider M probability distributions on Y, that we denote q m , m ∈ [M ], and α = (α 1 , . . . , α m ) ∈ ∆ M . For any probability distribution q over Y, we have</p><formula xml:id="formula_47">M m=1 α m • KL q m M m =1 α m • q m ≤ M m=1 α m • KL (q m q) ,<label>(36)</label></formula><p>with equality if and only if,</p><formula xml:id="formula_48">q = M m=1 α m • q m .<label>(37)</label></formula><p>Proof.</p><formula xml:id="formula_49">M m=1 α m • KL (q m q) - M m=1 α m • KL q m M m =1 α m • q m = M m=1 α m • KL (q m q) -KL q m M m =1 α m • q m (38) = - M m=1 α m y∈Y q m (y) • log q (y) M m =1 α m • q m (y) (39) = - y∈Y M m=1 α m • q m (y) • log q (y) M m =1 α m • q m (y) d y (40) = KL M m=1 α m • q m q ≥ 0.<label>(41)</label></formula><p>The equality holds, if and only if,</p><formula xml:id="formula_50">q = M m=1 α m • q m . (<label>42</label></formula><formula xml:id="formula_51">)</formula><p>Lemma A.3. Consider Θ and Π to be a solution of Problem (4). Under Assumptions 1, 2, and 3, if c h does not depend on h ∈ H, then the predictors h * t , t ∈ T , minimizing</p><formula xml:id="formula_52">E (x,y)∼Dt [l(h t (x), y)], verify for (x, y) ∈ X × Y p h * t (y|x) = M m=1 πtm • p m y|x, θm .<label>(43)</label></formula><p>Proof. For t ∈ T and h t ∈ H, under Assumptions 1, 2, and 3, we have</p><formula xml:id="formula_53">E (x,y)∼Dt [l(h t (x), y)] = x,y∈X ×Y l(h t (x), y) • p t (x, y|Θ * , π * t ) d x d y.<label>(44)</label></formula><p>Using Lemma A.1, it follows that</p><formula xml:id="formula_54">E (x,y)∼Dt [l(h t (x), y)] = x,y∈X ×Y l(h t (x), y) • p t x, y| Θ, πt d x d y.<label>(45)</label></formula><p>Thus, using Assumptions 1 and 2 we have, </p><formula xml:id="formula_55">E (x,y)∼Dt [l(h t (x), y)] (46) = x,y∈X ×Y l(h t (x), y) • p t x, y| Θ, πt d x d y (47) = x,y∈X ×Y l(h t (x), y) • M m=1 πtm • p m y|x, θm p (x) d x d y<label>(48)</label></formula><formula xml:id="formula_56">= x∈X c ht (x) + M m=1 πtm • H p m •|x, θm p (x) d x + x∈X M m=1 πtm • KL p m • |x, θm p ht (•|x) p (x) d x.<label>(52)</label></formula><p>Let h • t be a predictor satisfying the following equality:</p><formula xml:id="formula_57">p h • t (y|x) = M m=1 πtm • p m y|x, θm .</formula><p>Using Lemma A.2, we have</p><formula xml:id="formula_58">M m=1 πtm • KL p m • |x, θm p ht (•|x) ≥ M m=1 πtm • KL p m • |x, θm p h • t (•|x)<label>(53)</label></formula><p>with equality if and only if</p><formula xml:id="formula_59">p ht (•|x) = p h • t (•|x) .<label>(54)</label></formula><p>Since c h does not depend on h, replacing (53) in ( <ref type="formula" target="#formula_56">52</ref>), it follows that</p><formula xml:id="formula_60">E (x,y)∼Dt [l(h t (x), y)] ≥ E (x,y)∼Dt [l(h • t (x), y)] .<label>(55)</label></formula><p>This inequality holds for any predictor h t and in particular for h * t ∈ arg min E (x,y)∼Dt [l(h t (x), y)], for which it also holds the opposite inequality, then:</p><formula xml:id="formula_61">E (x,y)∼Dt [l(h * t (x), y)] = E (x,y)∼Dt [l(h • t (x), y)] ,<label>(56)</label></formula><p>and the equality implies that</p><formula xml:id="formula_62">p h * t (•|x) = p h • t (•|x) = M m=1 πtm • p m •|x, θm .<label>(57)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B Relation with Other Multi-Task Learning Frameworks</head><p>In this appendix, we give more details about the relation of our formulation with existing frameworks for (federated) MTL sketched in Section 2.3. We suppose that Assumptions 1-3 hold and that each client learns a predictor of the form <ref type="bibr" target="#b4">(5)</ref>. Note that this is more general than <ref type="bibr" target="#b66">[67]</ref>, where each client learns a personal hypothesis as a weighted combination of a set of M base known hypothesis, since the base hypothesis and not only the weights are learned in our case.</p><p>Alternating Structure Optimization <ref type="bibr" target="#b69">[70]</ref>. Alternating structure optimization (ASO) is a popular MTL approach that learns a shared low-dimensional predictive structure on hypothesis spaces from multiple related tasks, i.e., all tasks are assumed to share a common feature space P ∈ R d ×d , where d ≤ min(T, d) is the dimensionality of the shared feature space and P has orthonormal columns (P P = I d ), i.e., P is semi-orthogonal matrix. ASO leads to the following formulation: minimize</p><formula xml:id="formula_63">W,P :P P =I d T t=1 nt i=1 l h wt x (i) t</formula><p>, y</p><formula xml:id="formula_64">(i) t + α (tr (W W ) -tr (W P P W )) + β tr (W W ) ,<label>(58)</label></formula><p>where α ≥ 0 is the regularization parameter for task relatedness and β ≥ 0 is an additional L2 regularization parameter.</p><p>When the hypothesis (h θ ) θ are assumed to be linear, Eq. ( <ref type="formula" target="#formula_5">5</ref>) can be written as W = ΠΘ. Writing the LQ decomposition<ref type="foot" target="#foot_5">6</ref> of matrix Θ, i.e., Θ = LQ, where L ∈ R M ×M is a lower triangular matrix and Q ∈ R M ×d is a semi-orthogonal matrix (QQ = I M ), ( <ref type="formula" target="#formula_5">5</ref>) becomes</p><formula xml:id="formula_65">W = ΠLQ ∈ R T ×d , thus, W = W Q Q, leading to the constraint W -W Q Q 2 F = tr (W W ) -tr (W Q QW ) = 0. If we assume θ m 2 2 to be bounded by a constant B &gt; 0 for all m ∈ [M ], we get the constraint tr (W W ) ≤ T B. It means that minimizing T t=1 nt i=1 l h wt x (i) t , y (i) t</formula><p>under our Assumption 1 can be formulated as the following constrained optimization problem minimize</p><formula xml:id="formula_66">W,Q:QQ =I M T t=1 nt i=1 l h wt x (i) t , y (i) t , subject to tr {W W } -tr {W Q QW } = 0, tr (W W ) ≤ T B.<label>(59)</label></formula><p>Thus, there exists Lagrange multipliers α ∈ R and β &gt; 0, for which Problem ( <ref type="formula" target="#formula_66">59</ref>) is equivalent to the following regularized optimization problem minimize</p><formula xml:id="formula_67">W,Q:QQ =I M T t=1 nt i=1 l h wt x (i) t , y (i) t + α (tr {W W } -tr {W Q QW }) + β tr {W W } ,<label>(60)</label></formula><p>which is exactly Problem <ref type="bibr" target="#b57">(58)</ref>.</p><p>Federated MTL via task relationships. The ASO formulation above motivated the authors of <ref type="bibr" target="#b58">[59]</ref> to learn personalized models by solving the following problem</p><formula xml:id="formula_68">min W,Ω T t=1 nt i=1 l h wt x (i) t , y (i) t + λ tr (W ΩW ) ,<label>(61)</label></formula><p>Two alternative MTL formulations are presented in <ref type="bibr" target="#b58">[59]</ref> to justify Problem (61): MTL with probabilistic priors <ref type="bibr" target="#b68">[69]</ref> and MTL with graphical models <ref type="bibr" target="#b34">[35]</ref>. Both of them can be covered using our Assumption 1 as follows:</p><p>• Considering T = M and Π = I M in Assumption 1 and introducing a prior on Θ of the form</p><formula xml:id="formula_69">Θ ∼ N 0, σ 2 I d MN (I d ⊗ Ω)<label>(62)</label></formula><p>lead to a formulation similar to MTL with probabilistic priors <ref type="bibr" target="#b68">[69]</ref>.</p><p>• Two tasks t and t are independent if π t , π t = 0, thus using Ω t,t = π t , π t leads to the same graphical model as in <ref type="bibr" target="#b34">[35]</ref>.</p><p>Several personalized FL formulations, e.g., pFedMe <ref type="bibr" target="#b15">[16]</ref>, FedU <ref type="bibr" target="#b16">[17]</ref> and the formulation studied in <ref type="bibr" target="#b23">[24]</ref> and in <ref type="bibr" target="#b22">[23]</ref>, are special cases of formulation <ref type="bibr" target="#b61">(62)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C Centralized Expectation Maximization</head><p>Proposition 3.1. Under Assumptions 1 and 2, at the k-th iteration the EM algorithm updates parameter estimates through the following steps:</p><formula xml:id="formula_70">E-step: q k+1 t (z (i) t = m) ∝ π k tm • exp -l(h θ k m (x (i) t ), y (i) t ) , t ∈ [T ], m ∈ [M ], i ∈ [n t ]<label>(8)</label></formula><p>M-step:</p><formula xml:id="formula_71">π k+1 tm = nt i=1 q k+1 t (z (i) t = m) n t , t ∈ [T ], m ∈ [M ] (9) θ k+1 m ∈ arg min θ∈R d T t=1 nt i=1 q k+1 t (z (i) t = m)l h θ (x (i) t ), y (i) t , m ∈ [M ] (10)</formula><p>Proof. The objective is to learn parameters { Θ, Π} from the data S 1:T by maximizing the likelihood p (S 1:T |Θ, Π). We introduce functions q t (z), t ∈ [T ] such that q t ≥ 0 and M z=1 q t (z) = 1 in the expression of the likelihood. For Θ ∈ R M ×d and Π ∈ ∆ T ×M , we have</p><formula xml:id="formula_72">log p(S 1:T |Θ, Π) = T t=1 nt i=1 log p t s (i) t |Θ, π t (63) = T t=1 nt i=1 log   M m=1   p t s (i) t , z (i) t = m|Θ, π t q t z (i) t = m   q t z (i) t = m  <label>(64)</label></formula><formula xml:id="formula_73">≥ T t=1 nt i=1 M m=1 q t z (i) t = m log p t s (i) t , z (i) t = m|Θ, π t q t z (i) t = m<label>(65)</label></formula><formula xml:id="formula_74">= T t=1 nt i=1 M m=1 q t z (i) t = m log p t s (i) t , z<label>(i)</label></formula><formula xml:id="formula_75">t = m|Θ, π t - T t=1 nt i=1 M m=1 q t z (i) t = m log q t z (i) t = m (66) L(Θ, Π, Q 1:T ),<label>(67)</label></formula><p>where we used Jensen's inequality because log is concave. L(Θ, Π, Q 1:T ) is an evidence lower bound.</p><p>The centralized EM-algorithm corresponds to iteratively maximizing this bound with respect to Q 1:T (E-step) and with respect to {Θ, Π} (M-step).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E-step.</head><p>The difference between the log-likelihood and the evidence lower bound L(Θ, Π, Q 1:T ) can be expressed in terms of a sum of KL divergences:</p><formula xml:id="formula_76">logp(S 1:T |Θ, Π) -L(Θ, Π, Q 1:T ) = = T t=1 nt i=1    log p t s (i) t |Θ, π t - M m=1 q t z (i) t = m log p t s (i) t , z (i) t = m|Θ, π t q t z (i) t = m    (68) = T t=1 nt t=1 M m=1 q t z (i) t = m   log p t s (i) t |Θ, π t -log p t s (i) t , z (i) t = m|Θ, π t q t z (i) t = m   (69) = T t=1 nt t=1 M m=1 q t z (i) t = m log p t s (i) t |Θ, π t • q t z (i) t = m p t s (i) t , z (i) t = m|Θ, π t (70) = T t=1 nt t=1 M m=1 q t z (i) t = m log q t z (i) t = m p t z (i) t = m|s (i) t , Θ, π t (71) = T t=1 nt i=1 KL q t z (i) t ||p t z (i) t |s (i) t , Θ, π t ≥ 0.<label>(72)</label></formula><p>For fixed parameters {Θ, Π}, the maximum of L(Θ, Π, Q 1:T ) is reached when</p><formula xml:id="formula_77">T t=1 nt i=1 KL q t z (i) t ||p t z (i) t |s (i) t , Θ, π t = 0.</formula><p>Thus for t ∈ [T ] and i ∈ [n t ], we have:</p><formula xml:id="formula_78">q t (z (i) t = m) = p t (z (i) t = m|s (i) t , Θ, π t ) (73) = p t (s (i) t |z (i) t = m, Θ, π t ) × p t (z (i) t = m|Θ, π t ) p t s (i) t |Θ, π t (74) = p m (s (i) t |θ m ) × π tm M m =1 p m (s (i) t ) × π tm (75) = p m y (i) t |x (i) t , θ m × p m x (i) t × π tm M m =1 p m y (i) t |x (i) t , θ m × p m x (i) t × π tm (76) = p m y (i) t |x (i) t , θ m × p x (i) t × π tm M m =1 p m y (i) t |x (i) t , , θ m × p x (i) t × π tm ,<label>(77)</label></formula><p>where (77) relies on Assumption 2. It follows that q t (z</p><formula xml:id="formula_79">(i) t = m) = p t (z (i) t = m|s (i) t , Θ, π t ) = p m y (i) t |x (i) t , θ m × π tm M m =1 p m y (i) t |x (i) t , θ m × π tm .<label>(78)</label></formula><p>M-step. We maximize now L(Θ, Π, Q 1:T ) with respect to {Θ, Π}. By dropping the terms not depending on {Θ, Π} in the expression of L(Θ, Π, Q 1:T ) we write:</p><formula xml:id="formula_80">L(Θ, Π, Q 1:T ) = T t=1 nt i=1 M m=1 q t z (i) t = m log p t s (i) t , z (i) t = m|Θ, π t + c (79) = T t=1 nt i=1 M m=1 q t z (i) t = m log p t s (i) t |z (i) t = m, Θ, π t + log p t z (i) t = m|Θ, π t + c (80) = T t=1 nt i=1 M m=1 q t z (i) t = m log p θm s (i) t + log π tm + c (81) = T t=1 nt i=1 M m=1 q t z (i) t = m log p θm y (i) t |x (i) t + log p m x (i) t + log π tm + c (82) = T t=1 nt i=1 M m=1 q t z (i) t = m log p θm y (i) t |x (i) t + log π tm + c ,<label>(83) (84)</label></formula><p>where c and c are constant not depending on {Θ, Π}.</p><p>Thus, for t ∈ [T ] and m ∈ [M ], by solving a simple optimization problem we update π tm as follows:</p><formula xml:id="formula_81">π tm = nt i=1 q t (z (i) t = m) n t . (<label>85</label></formula><formula xml:id="formula_82">)</formula><p>On the other hand, for m ∈ [M ], we update θ m by solving: </p><formula xml:id="formula_83">θ m ∈ arg min θ∈R d T t=1 nt i=1 q t (z (i) t = m) × l h θ (x (i) t ), y (i) t . (<label>86</label></formula><formula xml:id="formula_84">q k t z (i) t = m ← π k tm •exp -l(h θ k m (x (i) t ),y (i) t ) M m =1 π k tm •exp -l(h θ k m (x<label>(i) t ),y (i) t )</label></formula><p>;</p><formula xml:id="formula_85">// M-step 10 π k tm ← n t i=1 q k t (z (i) t =m) nt ; θ k m,t ← LocalSolver(J, m, θ k-1 m , q k t , S t ) ; client t sends θ k m,t , 1 ≤ m ≤ M to the server; for component m = 1, . . . , M do θ k m ← T t=1 nt n • θ k m,t ;</formula><p>Function LocalSolver(J, m, θ, q, S):</p><p>for j = 0, . . . , J -1 do Sample indexes I uniformly from 1, . . . , |S|;</p><formula xml:id="formula_86">θ ← θ -η k-1,j i∈I q(z (i) = m) • ∇ θ l h θ x (i) , y (i) ; return θ; Algorithm 3: Federated Surrogate Optimization Input : u 0 ∈ R du ; V 0 = v 0 t 1≤t≤T ∈ V T ; number of iterations K; number of local steps J Output : u K ; v K t</formula><p>for iterations k = 1, . . . , K do server broadcasts u k-1 to the T clients; for tasks t = 1, . . . , T in parallel over T clients do Compute partial first-order surrogate function</p><formula xml:id="formula_87">g k t of f t near u k-1 , v k-1 t ; v k t ← arg min v∈V g k t u k-1 , v ; u k t ← LocalSolver(J, u k-1 t , v k-1 t , g k t , S t );</formula><p>client t sends u k t to the server;</p><formula xml:id="formula_88">u k ← T t=1 ω t • u k t ;</formula><p>Function LocalSolver(J, u, v, g, S): </p><formula xml:id="formula_89">for j = 0, . . . , J -1 do sample ξ k-1,j from S; u ← u -η k-1,j • ∇ u g(u, v; ξ k-</formula><formula xml:id="formula_90">q k t z (i) t = m ← π k tm •exp -l(h θ k m (x (i) t ),y (i) t ) M m =1 π k tm •exp -l(h θ k m (x<label>(i) t ),y (i) t )</label></formula><p>;</p><formula xml:id="formula_91">// M-step 10 π k tm ← n t i=1 q k t (z (i) t =m) nt ; 11 θ k-1 2 m,t ← LocalSolver(J, m, θ k-1 m,t , q k t , S t , t); Send θ k-1 2 m,t , 1 ≤ m ≤ M to neighbors; Receive θ k-1 2 m,s , 1 ≤ m ≤ M from neighbors; for component m = 1, . . . , M do θ k m,t ← T s=1 w k-1 s,t • θ k-1 2 m,s ;</formula><p>Function LocalSolver(J, m, θ, q, S, t):</p><p>for j = 0, . . . , J -1 do Sample indexes I uniformly from 1, . . . , |S|;</p><formula xml:id="formula_92">θ ← θ -nt n • η k-1,j i∈I q(z (i) = m) • ∇ θ l h θ x (i) , y (i) ;</formula><p>return θ;</p><p>Algorithm 5: Fully-Decentralized Federated Surrogate Optimization</p><formula xml:id="formula_93">Input : u 0 ∈ R du ; V 0 = v 0 t 1≤t≤T ∈ V T ; number of iterations K; number of local step J; mixing matrix distributions W k for k ∈ [K] Output : u K t for t ∈ [T ]; v K t for t ∈ [T ] for iterations k = 1, . . . , K do</formula><p>// Select the communication topology and the aggregation weights</p><formula xml:id="formula_94">Sample W k-1 ∼ W k-1 ;</formula><p>for tasks t = 1, . . . , T in parallel over T clients do compute partial first-order surrogate function</p><formula xml:id="formula_95">g k t of f t near u k-1 t , v k-1 t ; v k t ← arg min v∈V g k t u k-1 t , v ; u k-1 2 t ← LocalSolver(J, u k-1 t , v k-1 t , g k t , t); Send u k-1 2 t to neighbors; Receive u k-1 2 s</formula><p>from neighbors;</p><formula xml:id="formula_96">u k t ← T s=1 w k-1 ts × u k-1 2 s ;</formula><p>Function LocalSolver(J, u, v, g, S, t):</p><formula xml:id="formula_97">for j = 0, . . . , J -1 do sample ξ k-1,j from S ; u ← u -ω t • η k-1,j ∇ u g(u, v, ξ k-1,j );</formula><p>return u;</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E Details on the Fully Decentralized Setting</head><p>As mentioned in Section 3.3, the convergence of decentralized optimization schemes requires certain assumptions on the sequence of mixing matrices (W k ) k&gt;0 , to guarantee that each client can influence the estimates of other clients over time. In our paper, we consider the following general assumption. Assumption 8 ([31, <ref type="bibr">Assumption 4]</ref>). Symmetric doubly stochastic mixing matrices are drawn at each round k from (potentially different) distributions W k ∼ W k and there exists two constants p ∈ (0, 1], and integer τ ≥ 1 such that for all Ξ ∈ R M ×d×T and all integers l ∈ {0, . . . , K/τ }:</p><formula xml:id="formula_98">E ΞW l,τ -Ξ 2 F ≤ (1 -p) Ξ -Ξ 2 F ,<label>(87)</label></formula><p>where W l,τ W (l+1)τ -1 . . . W lτ , Ξ Ξ 11 T , and the expectation is taken over the random distributions W k ∼ W k . Assumption 8 expresses the fact that the sequence of mixing matrices, on average and every τ communication rounds, brings the values in the columns of Ξ closer to their row-wise average (thereby mixing the clients' updates over time). For instance, the assumption is satisfied if the communication graph is strongly connected every τ rounds, i.e., the graph ([T ], E), where the edge (i, j) belongs to the graph if w h i,j &gt; 0 for some h ∈ {k + 1, . . . , k + τ } is connected. We provide below the rigorous statement of Theorem 3.3, which was informally presented in Section 3.3. It shows that D-FedEM converges to a consensus stationary point of f (proof in App. G.2). Theorem 3.3. Under Assumptions 1-8, when clients use SGD as local solver with learning rate η = a0 √ K , D-FedEM's iterates satisfy the following inequalities after a large enough number of communication rounds K:</p><formula xml:id="formula_99">1 K K k=1 E ∇ Θ f Θk , Π k 2 F ≤ O 1 √ K , 1 K K k=1 T t=1 n t n KL π k t , π k-1 t ≤ O 1 K ,<label>(88)</label></formula><p>where Θk = Θ k 1 , . . . Θ k T • 11 T . Moreover, individual estimates Θ k t 1≤t≤T converge to consensus, i.e., to Θk :</p><formula xml:id="formula_100">min k∈[K] E T t=1 Θ k t -Θk 2 F ≤ O 1 √ K .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F Federated Surrogate Optimization</head><p>In this appendix, we give more details on the federated surrogate optimization framework introduced in Section 3.4. In particular, we provide the assumptions under which Alg. 3 and Alg. 5 converge.</p><p>We also illustrate how our framework can be used to study existing algorithms.</p><p>F.1 Reminder on Basic (Centralized) Surrogate Optimization</p><p>In this appendix, we recall the (centralized) first-order surrogate optimization framework introduced in <ref type="bibr" target="#b42">[43]</ref>. In this framework, given a continuous function f : R d → R, we are interested in solving</p><formula xml:id="formula_101">min θ∈R d f (θ)</formula><p>using the majoration-minimization scheme presented in Alg. 6.</p><p>Algorithm 6: Basic Surrogate Optimization</p><formula xml:id="formula_102">Input : θ 0 ∈ R d ; number of iterations K; Output : θ K for iterations k = 1, . . . , K do Compute g k , a surrogate function of f near θ k-1 ;</formula><p>Update solution:</p><formula xml:id="formula_103">θ k ∈ arg min θ g k (θ);</formula><p>This procedure relies on surrogate functions, that approximate well the objective function in a neighborhood of a point. Reference <ref type="bibr" target="#b42">[43]</ref> focuses on first-order surrogate functions defined below. Definition F.1 (First-Order Surrogate <ref type="bibr" target="#b42">[43]</ref>). A function g : R d → R is a first order surrogate of f near θ k ∈ R d when the following is satisfied:</p><p>• Majorization: we have g(θ ) ≥ f (θ ) for all θ ∈ arg min θ∈R d g(θ). When the more general condition g ≥ f holds, we say that g is a majorant function.</p><p>• Smoothness: the approximation error r g -f is differentiable, and its gradient is L-Lipschitz. Moreover, we have r(θ k ) = 0 and ∇r(θ k ) = 0.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F.2 Novel Federated Version</head><p>As discussed in Section 3.4, our novel federated surrogate optimization framework minimizes an objective function (u, v 1:T ) → f (u, v 1:T ) that can be written as a weighted sum f (u, v 1:T ) = T t=1 ω t f t (u, v t ) of T functions. We suppose that each client t ∈ [T ] can compute a partial first order surrogate of f t , defined as follows. Definition 1 (Partial first-order surrogate). A function g(u, v) : R du × V → R is a partial first-order surrogate of f (u, v) wrt u near (u 0 , v 0 ) ∈ R du × V when the following conditions are satisfied:</p><formula xml:id="formula_104">1. g(u, v) ≥ f (u, v) for all u ∈ R du and v ∈ V; 2. r(u, v) g(u, v) -f (u, v) is differentiable and L-smooth with respect to u. Moreover, we have r(u 0 , v 0 ) = 0 and ∇ u r(u 0 , v 0 ) = 0. 3. g(u, v 0 ) -g(u, v) = d V (v 0 , v) for all u ∈ R du and v ∈ arg min v ∈V g(u, v ), where d V is non-negative and d V (v, v ) = 0 ⇐⇒ v = v .</formula><p>Under the assumption that each client t can compute a partial first order surrogate of f t , we propose algorithms for federated surrogate optimization in both the client-server setting (Alg. 3) and the fully decentralized one (Alg. 5). Both algorithms are iterative and distributed: at each iteration k &gt; 0, client t ∈ [T ] computes a partial first-order surrogate</p><formula xml:id="formula_105">g k t of f t near u k-1 , v k-1 t (resp. u k-1 t , v k-1 t</formula><p>) for federated surrogate optimization in Alg. 3 (resp. for fully decentralized surrogate optimization in Alg 5).</p><p>The convergence of those two algorithms requires the following standard assumptions. Each of them generalizes one of the Assumptions 4-7 for our EM algorithms. </p><formula xml:id="formula_106">[∇ u g k t (u, v; ξ)] = ∇ u g k t (u, v) and E ξ ∇ u g k t (u, v; ξ)-∇ u g k t (u, v) 2 ≤ σ 2 .</formula><p>Assumption 7 . (Bounded dissimilarity) There exist β and G such that</p><formula xml:id="formula_107">T t=1 ω t • ∇ u g k t (u, v) 2 ≤ G 2 + β 2 T t=1 ω t • ∇ u g k t (u, v) 2 .</formula><p>Under these assumptions a parallel result to Theorem. 3.2 holds for the client-server setting. Theorem 3.2 . Under Assumptions 4 -7 , when clients use SGD as local solver with learning rate η = a0 √ K , after a large enough number of communication rounds K, the iterates of federated surrogate optimization (Alg. 3) satisfy:</p><formula xml:id="formula_108">1 K K k=1 E ∇ u f u k , v k 1:T 2 F ≤ O 1 √ K , 1 K K k=1 ∆ v f (u k , v k 1:T ) ≤ O 1 K 3/4 , (<label>89</label></formula><formula xml:id="formula_109">)</formula><p>where the expectation is over the random batches samples, and</p><formula xml:id="formula_110">∆ v f (u k , v k 1:T ) f u k , v k 1:T - f u k , v k+1 1:T ≥ 0.</formula><p>In the fully decentralized setting, if in addition to Assumptions 4 -7 , we suppose that Assumption 8 holds, a parallel result to Theorem. 3.3 holds. Theorem 3.3 . Under Assumptions 4 -7 and Assumption 8, when clients use SGD as local solver with learning rate η = a0 √ K , after a large enough number of communication rounds K, the iterates of fully decentralized federated surrogate optimization (Alg. 5) satisfy:</p><formula xml:id="formula_111">1 K K k=1 E ∇ u f ūk , v k 1:T 2 ≤ O 1 √ K , 1 K K k=1 T t=1 ω t • d V v k t , v k+1 t ≤ O 1 K ,<label>(90</label></formula><p>) where ūk = 1 T T t=1 u k t . Moreover, local estimates u k t 1≤t≤T converge to consensus, i.e., to ūk :</p><formula xml:id="formula_112">1 K K k=1 T t=1 u k t -ūk 2 ≤ O 1 √ K .</formula><p>The proofs of Theorem 3.2 and Theorem 3.3 are in Section G.1 and Section G.2, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F.3 Illustration: Analyzing pFedMe with Federated Surrogate Optimization</head><p>In this section, we show that pFedMe <ref type="bibr" target="#b15">[16]</ref> can be studied through our federated surrogate optimization framework. With reference to the general formulation of pFedMe in [16, Eq. ( <ref type="formula" target="#formula_2">2</ref>) and (3)], consider</p><formula xml:id="formula_113">g k t (w) = f t θ k-1 + λ 2 • θ k-1 -ω 2 ,<label>(91)</label></formula><p>where</p><formula xml:id="formula_114">θ k-1 = prox f t λ ω k-1 arg min θ f t (θ) + λ 2 • θ -ω k-1 2</formula><p>. We can verify that g k t is a first-order surrogate of f t near θ k-1 :</p><formula xml:id="formula_115">1. It is clear that g k t θ k-1 = f t θ k-1 . 2. Since θ k-1 = prox f t λ ω k-1</formula><p>, using the envelope theorem (assuming that f t is proper, convex and lower semi-continuous), it follows that ∇f t ω k-1 = λ θ k-1 -ω k-1 = ∇g k k ω k-1 . Therefore, pFedMe can be seen as a particular case of the federated surrogate optimization algorithm (Alg. 3), to which our convergence results apply.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>G Convergence Proofs</head><p>We study the client-server setting and the fully decentralized setting in Section G.1 and Section G.2, respectively. In both cases, we first prove the more general result for the federated surrogate optimization introduced in App. F, and then derive the specific result for FedEM and D-FedEM.</p><p>G.1 Client-Server Setting G.1.1 Additional Notations Remark 2. For convenience and without loss of generality, we suppose in this section that ω ∈ ∆ T , i.e., ∀t ∈ [T ], ω t ≥ 0 and</p><formula xml:id="formula_116">T t =1 ω t = 1.</formula><p>At iteration k &gt; 0, we use u k-1,j t to denote the j-th iterate of the local solver at client t ∈ [T ], thus</p><formula xml:id="formula_117">u k-1,0 t = u k-1 ,<label>(92)</label></formula><p>and</p><formula xml:id="formula_118">u k = T t=1 ω t • u k-1,J t . (<label>93</label></formula><formula xml:id="formula_119">)</formula><p>At iteration k &gt; 0, the local solver's updates at client t ∈ [T ] can be written as (for 0 ≤ j ≤ J -1):</p><formula xml:id="formula_120">u k-1,j+1 t = u k-1,j t -η k-1,j ∇ u g k t u k-1,j t , v k-1 t ; ξ k-1,j t ,<label>(94)</label></formula><p>where ξ k-1,j t is the batch drawn at the j-th local update of u k-1 t .</p><p>We introduce η k-1 = J-1 j=0 η k-1,j , and we define the normalized update of the local solver at client t ∈ [T ] as,</p><formula xml:id="formula_121">δk-1 t - u k-1,J t -u k-1,0 t η k-1 = J-1 j=0 η k-1,j • ∇ u g k t u k-1,j t , v k-1 t ; ξ k-1,j t J-1 j=0 η k-1,j ,<label>(95)</label></formula><p>and also define</p><formula xml:id="formula_122">δ k-1 t J-1 j=0 η k-1,j • ∇ u g k t u k-1,j t , v k-1 t η k-1 . (<label>96</label></formula><formula xml:id="formula_123">)</formula><p>With this notation,</p><formula xml:id="formula_124">u k -u k-1 = -η k-1 • T t=1 ω t • δk-1 t .<label>(97)</label></formula><p>Finally, we define g k , k &gt; 0 as</p><formula xml:id="formula_125">g k (u, v 1:T ) T t=1 ω t • g k t (u, v t ) .<label>(98)</label></formula><p>Note that g k is a convex combination of functions g k t , t ∈ [T ].</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>G.1.2 Proof of Theorem 3.2</head><p>Lemma G.1. Suppose that Assumptions 5 -7 hold. Then, for k &gt; 0, and (η k,j ) 0≤j≤J-1 such that</p><formula xml:id="formula_126">η k J-1 j=0 η k,j ≤ min 1 2 √ 2L , 1</formula><p>4Lβ , the updates of federated surrogate optimization (Alg 3) verify</p><formula xml:id="formula_127">E f (u k , v k 1:T ) -f (u k-1 , v k-1 1:T ) η k-1 ≤ - 1 4 E ∇ u f u k-1 , v k-1 1:T 2 - 1 η k-1 T t=1 ω t • d V v k-1 t , v k t + 2η k-1 L   J-1 j=0 η 2 k-1,j η k-1 L + 1   σ 2 + 4η 2 k-1 L 2 G 2 . (<label>99</label></formula><formula xml:id="formula_128">)</formula><p>Proof. This proof uses standard techniques from distributed stochastic optimization. It is inspired by <ref type="bibr" target="#b65">[66,</ref><ref type="bibr">Theorem 1]</ref>.</p><p>For k &gt; 0, g k is L-smooth wrt u, because it is a convex combination of L-smooth functions g k t , t ∈ [T ]. Thus, we write</p><formula xml:id="formula_129">g k u k , v k-1 1:T -g k u k-1 , v k-1 1:T ≤ u k -u k-1 , ∇ u g k (u k-1 , v k-1 1:T ) + L 2 u k -u k-1 2 ,</formula><p>(100) where &lt; u, u &gt; denotes the scalar product of vectors u and u . Using Eq. ( <ref type="formula" target="#formula_124">97</ref>), and taking the expectation over random batches ξ k-1,j t 0≤j≤J-1 1≤t≤T</p><p>, we have</p><formula xml:id="formula_130">E g k u k , v k-1 1:T -g k u k-1 , v k-1 1:T ≤ -η k-1 E T t=1 ω t • δk-1 t , ∇ u g k (u k-1 , v k-1 1:T ) T1 + Lη 2 k-1 2 • E T t=1 ω t • δk-1 t 2 T2 .<label>(101)</label></formula><p>We bound each of those terms separately. For T 1 we have</p><formula xml:id="formula_131">T 1 = E T t=1 ω t • δk-1 t , ∇ u g k u k-1 , v k-1 1:T (102) = E T t=1 ω t • δk-1 t -δ k-1 t , ∇ u g k u k-1 , v k-1 1:T + E T t=1 ω t • δ k-1 t , ∇ u g k u k-1 , v k-1 1:T . (<label>103</label></formula><formula xml:id="formula_132">)</formula><p>Because stochastic gradients are unbiased (Assumption 6 ), we have</p><formula xml:id="formula_133">E δk-1 t -δ k-1 t = 0,<label>(104) thus,</label></formula><formula xml:id="formula_134">T 1 = E T t=1 ω t • δ k-1 t , ∇ u g k u k-1 , v k-1 1:T (105) = 1 2   ∇ u g k u k-1 , v k-1 1:T 2 + E T t=1 ω t • δ k-1 t 2   - 1 2 E ∇ u g k u k-1 , v k-1 1:T - T t=1 ω t • δ k-1 t 2 . (<label>106</label></formula><formula xml:id="formula_135">)</formula><p>For T 2 we have for k &gt; 0,</p><formula xml:id="formula_136">T 2 = E T t=1 ω t • δk-1 t 2 (107) = E T t=1 ω t • δk-1 t -δ k-1 t + T t=1 ω t • δ k-1 t 2 (108) ≤ 2 E T t=1 ω t • δk-1 t -δ k-1 t 2 + 2 E T t=1 ω t • δ k-1 t 2 (109) = 2 T t=1 ω 2 t • E δk-1 t -δ k-1 t 2 + 2 1≤s =t≤T ω t ω s E δk-1 t -δ k-1 t , δk-1 s -δ k-1 s + 2 E T t=1 ω t δ k-1 t 2 . (<label>110</label></formula><formula xml:id="formula_137">)</formula><p>Since clients sample batches independently, and stochastic gradients are unbiased (Assumption 6 ), we have</p><formula xml:id="formula_138">E δk-1 t -δ k-1 t , δk-1 s -δ k-1 s = 0,<label>(111) thus,</label></formula><formula xml:id="formula_139">T 2 ≤ 2 T t=1 ω 2 t • E δk-1 t -δ k-1 t 2 + 2 E T t=1 ω t δ k-1 t 2 (112) = 2 T t=1 ω 2 t E J-1 j=0 η k-1,j η k-1 ∇ u g k t u k-1,j t , v k-1 t -∇ u g k t u k-1,j t , v k-1 t ; ξ k-1,j t 2 + 2 E T t=1 ω t δ k-1 t 2 .<label>(113)</label></formula><p>Using Jensen inequality, we have</p><formula xml:id="formula_140">J-1 j=0 η k-1,j η k-1 ∇ u g k t u k-1,j t , v k-1 t -∇ u g k t u k-1,j t , v k-1 t ; ξ k-1,j t 2 ≤ J-1 j=0 η k-1,j η k-1 ∇ u g k t u k-1,j t , v k-1 t -∇ u g k t u k-1,j t , v k-1 t ; ξ k-1,j t 2 ,<label>(114)</label></formula><p>and since the variance of stochastic gradients is bounded by σ 2 (Assumption 6 ), it follows that</p><formula xml:id="formula_141">E J-1 j=0 η k-1,j η k-1 ∇ u g k t u k-1,j t , v k-1 t -∇ u g k t u k-1,j t , v k-1 t ; ξ k-1,j t 2 ≤ J-1 j=0 η k-1,j η k-1 σ 2 = σ 2 . (<label>115</label></formula><formula xml:id="formula_142">)</formula><p>Replacing back in the expression of T 2 , we have</p><formula xml:id="formula_143">T 2 ≤ 2 T t=1 ω 2 t σ 2 + 2 E T t=1 ω t • δ k-1 t 2 . (<label>116</label></formula><formula xml:id="formula_144">)</formula><p>Finally, since 0 ≤ ω t ≤ 1, t ∈ [T ] and T t=1 ω t = 1, we have</p><formula xml:id="formula_145">T 2 ≤ 2σ 2 + 2 E T t=1 ω t • δ k-1 t 2 . (<label>117</label></formula><formula xml:id="formula_146">)</formula><p>Having bounded T 1 and T 2 , we can replace Eq. ( <ref type="formula" target="#formula_134">106</ref>) and Eq. (117) in Eq. ( <ref type="formula" target="#formula_130">101</ref>), and we get</p><formula xml:id="formula_147">E g k (u k , v k-1 1:T ) -g k (u k-1 , v k-1 1:T ) ≤ - η k-1 2 ∇ u g k u k-1 , v k-1 1:T 2 + η 2 k-1 Lσ 2 34 - η k-1 2 (1 -2Lη k-1 ) • E T t=1 ω t • δ k-1 t 2 + η k-1 2 E ∇ u g k u k-1 , v k-1 1:T - T t=1 ω t • δ k-1 t 2 . (<label>118</label></formula><formula xml:id="formula_148">) As η k-1 ≤ 1 2 √ 2L ≤ 1 2L , we have E g k (u k , v k-1 1:T ) -g k (u k-1 , v k-1 1:T ) ≤ - η k-1 2 ∇ u g k u k-1 , v k-1 1:T 2 + η 2 k-1 Lσ 2 + η k-1 2 E ∇ u g k u k-1 , v k-1 1:T - T t=1 ω t δ k-1 t 2 . (<label>119</label></formula><formula xml:id="formula_149">) Replacing ∇ u g k u k-1 , v k-1 1:T = T t=1 ω t • ∇ u g k t u k-1 , v k-1 t</formula><p>, and using Jensen inequality to bound the last term in the RHS of Eq. ( <ref type="formula" target="#formula_148">119</ref>), we have</p><formula xml:id="formula_150">E g k (u k , v k-1 1:T ) -g k (u k-1 , v k-1 1:T ) ≤ - η k-1 2 ∇ u g k u k-1 , v k-1 1:T 2 + η 2 k-1 Lσ 2 + η k-1 2 T t=1 ω t • E ∇ u g k t u k-1 , v k-1 t -δ k-1 t 2 T3 . (<label>120</label></formula><formula xml:id="formula_151">)</formula><p>We now bound the term T 3 :</p><formula xml:id="formula_152">T 3 = E ∇ u g k t u k-1 , v k-1 t -δ k-1 t 2 (121) = E ∇ u g k t u k-1 , v k-1 t - J-1 j=0 η k-1,j η k-1 ∇ u g k t u k-1,j t , v k-1 t 2 (122) = E J-1 j=0 η k-1,j η k-1 ∇ u g k t u k-1 , v k-1 t -∇ u g k t u k-1,j t , v k-1 t 2 (123) ≤ J-1 j=0 η k-1,j η k-1 E ∇ u g k t u k-1 , v k-1 t -∇ u g k t u k-1,j t , v k-1 t 2 (124) ≤ J-1 j=0 η k-1,j η k-1 L 2 E u k-1 -u k-1,j t 2 , (<label>125</label></formula><formula xml:id="formula_153">)</formula><p>where the first inequality follows from Jensen inequality and the second one follow from the L-smoothness of g k t (Assumption 5 ). We bound now the term</p><formula xml:id="formula_154">E u k-1 -u k-1,j t for j ∈ {0, . . . , J -1} and t ∈ [T ], E u k-1 -u k-1,j t 2 = E u k-1,j t -u k-1,0 t 2 (126) = E j-1 l=0 u k-1,l+1 t -u k-1,l t 2 (127) = E j-1 l=0 η k-1,l ∇ u g k t u k-1,j t , v k-1 t ; ξ k-1,l t 2 (128) ≤ 2E j-1 l=0 η k-1,l ∇ u g k t u k-1,l t , v k-1 t ; ξ k-1,l t -∇ u g k t u k-1,l t , v k-1 t 2 + 2E j-1 l=0 η k-1,l ∇ u g k t u k-1,l t , v k-1 t 2 (129) = 2 j-1 l=0 η 2 k-1,l E ∇ u g k t u k-1,l t , v k-1 t ; ξ k-1,l t -∇ u g k t u k-1,l t , v k-1 t 2 + 2E j-1 l=0 η k-1,l ∇ u g k t u k-1,l t , v k-1 t 2 (130) ≤ 2σ 2 j-1 l=0 η 2 k-1,l + 2E j-1 l=0 η k-1,l ∇ u g k t u k-1,l t , v k-1 t 2 , (<label>131</label></formula><formula xml:id="formula_155">)</formula><p>where, in the last two steps, we used the fact that stochastic gradients are unbiased and have bounded variance (Assumption 6 ). We bound now the last term in the RHS of Eq. ( <ref type="formula" target="#formula_154">131</ref>),</p><formula xml:id="formula_156">E j-1 l=0 η k-1,l ∇ u g k t u k-1,l t , v k-1 t 2 = E j-1 l =0 η k-1,l • j-1 l=0 η k-1,l j-1 l =0 η k-1,l ∇ u g k t u k-1,l t , v k-1 t 2 (132) ≤ j-1 l =0 η k-1,l 2 • j-1 l=0 η k-1,l j-1 l =0 η k-1,l E ∇ u g k t u k-1,l t , v k-1 t 2 (133) = j-1 l=0 η k-1,l • j-1 l=0 η k-1,l E ∇ u g k t u k-1,l t , v k-1 t 2 (134) = j-1 l=0 η k-1,l • j-1 l=0 η k-1,l E ∇ u g k t u k-1,0 t , v k-1 t -∇ u g k t u k-1,0 t , v k-1 t + ∇ u g k t u k-1,l t , v k-1 t 2 (135) ≤2 j-1 l=0 η k-1,l • j-1 l=0 η k-1,l • E ∇ u g k t u k-1,0 t , v k-1 t 2 + E ∇ u g k t u k-1,l t , v k-1 t -∇ u g k t u k-1,0 t , v k-1 t 2 (136) =2 j-1 l=0 η k-1,l • j-1 l=0 η k-1,l • E ∇ u g k t u k-1 , v k-1 t 2 + E ∇ u g k t u k-1,l t , v k-1 t -∇ u g k t u k-1 , v k-1 t 2 (137) ≤2 j-1 l=0 η k-1,l j-1 l=0 η k-1,l E ∇ u g k t u k-1 , v k-1 t 2 + L 2 E u k-1,l t -u k-1 2 (138) =2L 2 j-1 l=0 η k-1,l j-1 l=0 η k-1,l • E u k-1,l t -u k-1 2 + 2 j-1 l=0 η k-1,l 2 E ∇ u g k t u k-1 , v k-1 t 2 , (<label>139</label></formula><formula xml:id="formula_157">)</formula><p>where the first inequality is obtained using Jensen inequality, and the last one is a result of the L-smoothness of g t (Assumption 5 ). Replacing Eq. ( <ref type="formula" target="#formula_156">139</ref>) in Eq. ( <ref type="formula" target="#formula_154">131</ref>), we have</p><formula xml:id="formula_158">J-1 j=0 η k-1,j η k-1 • E u k-1 -u k-1,j t 2 ≤ 2σ 2   J-1 j=0 η k-1,j η k-1 • j-1 l=0 η 2 k-1,l   + 4L 2 J-1 j=0 η k-1,j η k-1 j-1 l=0 η k-1,l • j-1 l=0 η k-1,l • E u k-1,l t -u k-1 t 2 + 4   J-1 j=0 η k-1,j η k-1 j-1 l=0 η k-1,l 2   • E ∇ u g k t u k-1 t , v k-1 t 2 . (<label>140</label></formula><formula xml:id="formula_159">) Since j-1 l=0 η k-1,l • E u k-1,l t -u k-1 t 2 ≤ J-1 j=0 η k-1,j • E u k-1,j t -u k-1 t 2</formula><p>, we have</p><formula xml:id="formula_160">J-1 j=0 η k-1,j η k-1 • E u k-1 -u k-1,j t 2 ≤ 2σ 2   J-1 j=0 η k-1,j η k-1 • j-1 l=0 η 2 k-1,l   + 4L 2   J-1 j=0 η k-1,j η k-1 j-1 l=0 η k-1,l   •   J-1 j=0 η k-1,j • E u k-1,j t -u k-1 2   + 4   J-1 j=0 η k-1,j η k-1 j-1 l=0 η k-1,l 2   • E ∇ u g k t u k-1 , v k-1 t 2 . (<label>141</label></formula><formula xml:id="formula_161">)</formula><p>We use Lemma G.11 to simplify the last expression, obtaining</p><formula xml:id="formula_162">J-1 j=0 η k-1,j η k-1 • E u k-1 -u k-1,j t 2 ≤ 2σ 2 •    J-1 j=0 η 2 k-1,j    + 4η 2 k-1 E ∇ u g k t u k-1 , v k-1 t 2 + 4η k-1 L 2 • J-1 j=0 η k-1,j E u k-1,j t -u k-1 2 . (<label>142</label></formula><formula xml:id="formula_163">)</formula><p>Rearranging the terms, we have</p><formula xml:id="formula_164">1 -4η 2 k-1 L 2 • J-1 j=0 η k-1,j η k-1 • E u k-1 -u k-1,j t 2 ≤ 2σ 2 •    J-1 j=0 η 2 k-1,j    + 4η 2 k-1 • E ∇ u g k t u k-1 , v k-1 t 2 . (<label>143</label></formula><formula xml:id="formula_165">)</formula><p>Finally, replacing Eq. ( <ref type="formula" target="#formula_164">143</ref>) into Eq. ( <ref type="formula" target="#formula_152">125</ref>), we have</p><formula xml:id="formula_166">1 -4η 2 k-1 L 2 • T 3 ≤ 2σ 2 L 2 •   J-1 j=0 η 2 k-1,j   + 4η 2 k-1 L 2 • E ∇ u g k t u k-1 , v k-1 t 2 . (144) For η k-1 small enough, in particular if η k-1 ≤ 1 2 √ 2L , then 1 2 ≤ 1 -4η 2 k-1 L 2 , thus T 3 2 ≤ 2σ 2 L 2 •   J-1 j=0 η 2 k-1,j   + 4η 2 k-1 L 2 • E ∇ u g k t u k-1 , v k-1 t 2 . (<label>145</label></formula><formula xml:id="formula_167">)</formula><p>Replacing the bound of T 3 from Eq. (145) into Eq. ( <ref type="formula" target="#formula_150">120</ref>), we have obtained</p><formula xml:id="formula_168">E g k (u k , v k-1 1:T ) -g k (u k-1 , v k-1 1:T ) ≤ - η k-1 2 E ∇ u g k u k-1 , v k-1 1:T 2 + 4η 3 k-1 L 2 T t=1 ω t • E ∇ u g k t u k-1 , v k-1 t 2 + 2η k-1 L   J-1 j=0 η 2 k-1,j L + η k-1   • σ 2 . (<label>146</label></formula><formula xml:id="formula_169">)</formula><p>Using Assumption 7 , we have</p><formula xml:id="formula_170">E g k (u k , v k-1 1:T ) -g k (u k-1 , v k-1 1:T ) ≤ - η k-1 2 E ∇ u g k u k-1 , v k-1 1:T 2 + 4η 3 k-1 L 2 β 2 • E T t=1 ω t • ∇ u g k t u k-1 , v k-1 t 2 + 2η k-1 L   J-1 j=0 η 2 k-1,j L + η k-1   • σ 2 + 4η 3 k-1 L 2 G 2 . (<label>147</label></formula><formula xml:id="formula_171">)</formula><p>Dividing by η k-1 , we get</p><formula xml:id="formula_172">E g k (u k , v k-1 1:T ) -g k (u k-1 , v k-1 1:T ) η k-1 ≤ 8η 2 k-1 L 2 β 2 -1 2 E ∇ u g k u k-1 , v k-1 1:T 2 + 2η k-1 L   J-1 j=0 η 2 k-1,j η k-1 L + 1   • σ 2 + 4η 2 k-1 L 2 G 2 . (<label>148</label></formula><formula xml:id="formula_173">) For η k-1 small enough, if η k-1 ≤ 1 4Lβ , then 8η 2 k-1 L 2 β 2 -1 ≤ 1 2 . Thus, E g k (u k , v k-1 1:T ) -g k (u k-1 , v k-1 1:T ) η k-1 ≤ - 1 4 E ∇ u g k u k-1 , v k-1 1:T 2 + 2η k-1 L   J-1 j=0 η 2 k-1,j η k-1 L + 1   • σ 2 + 4η 2 k-1 L 2 G 2 . (<label>149</label></formula><formula xml:id="formula_174">) Since for t ∈ [T ], g k t is a partial first-order surrogate of f t near u k-1 , v k-1 t</formula><p>, we have (see Def. 1)</p><formula xml:id="formula_175">g k t u k-1 , v k-1 t = f t u k-1 , v k-1 t ,<label>(150)</label></formula><formula xml:id="formula_176">∇ u g k t u k-1 , v k-1 t = ∇ u f t u k-1 , v k-1 t ,<label>(151)</label></formula><formula xml:id="formula_177">g k t u k , v k-1 t = g k t u k , v k t + d V v k-1 t , v k t .<label>(152)</label></formula><p>Multiplying by ω t and summing over t ∈ [T ], we have</p><formula xml:id="formula_178">g k u k-1 , v k-1 1:T = f u k-1 , v k-1 1:T , (<label>153</label></formula><formula xml:id="formula_179">)</formula><formula xml:id="formula_180">∇ u g k u k-1 , v k-1 1:T = ∇ u f u k-1 , v k-1 1:T ,<label>(154)</label></formula><formula xml:id="formula_181">g k u k , v k-1 1:T = g k u k , v k 1:T + T t=1 ω t • d V v k-1 t , v k t .<label>(155)</label></formula><p>Replacing Eq. ( <ref type="formula" target="#formula_178">153</ref>), Eq. ( <ref type="formula" target="#formula_180">154</ref>) and Eq. (155) in Eq. ( <ref type="formula" target="#formula_173">149</ref>), we have</p><formula xml:id="formula_182">E g k (u k , v k 1:T ) -f (u k-1 , v k-1 1:T ) η k-1 ≤ - 1 4 E ∇ u f u k-1 , v k-1 1:T 2 - 1 η k-1 T t=1 ω t • d V v k-1 t , v k t + 2η k-1 L      J-1 j=0 η 2 k-1,j η k-1    L + 1   • σ 2 + 4η 2 k-1 L 2 G 2 . (<label>156</label></formula><formula xml:id="formula_183">)</formula><p>Using again Definition 1, we have</p><formula xml:id="formula_184">g k (u k , v k 1:T ) ≥ f (u k , v k 1:T ),<label>(157)</label></formula><p>thus,</p><formula xml:id="formula_185">E f (u k , v k 1:T ) -f (u k-1 , v k-1 1:T ) η k-1 ≤ - 1 4 E ∇ u f u k-1 , v k-1 1:T 2 - 1 η k-1 T t=1 ω t • d V v k-1 t , v k t + 2η k-1 L   J-1 j=0 η 2 k-1,j η k-1 L + 1   • σ 2 + 4η 2 k-1 L 2 G 2 . (<label>158</label></formula><formula xml:id="formula_186">)</formula><p>Lemma G.2. For k ≥ 0 and t ∈ [T ], the iterates of Alg. 3 verify</p><formula xml:id="formula_187">0 ≤ d V v k+1 t , v k t ≤ f t u k , v k t -f t (u k , v k+1 t ) (159) Proof. Since v k+1 t ∈ arg min v∈V g k t u k-1 , v , and g k t is a partial first-order surrogate of f t near {u k-1 , v k-1 t }, we have g k t u k-1 , v k-1 t -g k t u k-1 , v k t = d V v k-1 t , v k t ,<label>(160)</label></formula><p>thus,</p><formula xml:id="formula_188">f t u k-1 , v k-1 t -f t u k-1 , v k t ≥ d V v k-1 t , v k t ,<label>(161</label></formula><p>) where we used the fact that</p><formula xml:id="formula_189">g k t u k-1 , v k-1 t = f t u k-1 , v k-1 t ,<label>(162)</label></formula><p>and,</p><formula xml:id="formula_190">g k t u k-1 , v k t ≥ f t u k-1 , v k t .<label>(163)</label></formula><p>Theorem 3.2 . Under Assumptions 4 -7 , when clients use SGD as local solver with learning rate η = a0 √ K , after a large enough number of communication rounds K, the iterates of federated surrogate optimization (Alg. 3) satisfy:</p><formula xml:id="formula_191">1 K K k=1 E ∇ u f u k , v k 1:T 2 F ≤ O 1 √ K , 1 K K k=1 E ∆ v f (u k , v k 1:T ) ≤ O 1 K 3/4 ,<label>(89</label></formula><p>) where the expectation is over the random batches samples, and</p><formula xml:id="formula_192">∆ v f (u k , v k 1:T ) f u k , v k 1:T - f u k , v k+1 1:T ≥ 0. Proof. For K large enough, η = a0 √ K ≤ 1 J min 1 2 √ 2L , 1</formula><p>4Lβ , thus the assumptions of Lemma G.1 are satisfied. Lemma G.1 and non-negativity of d V lead to</p><formula xml:id="formula_193">E f (u k , v k 1:T ) -f (u k-1 , v k-1 1:T ) Jη ≤ - 1 4 E ∇ u f u k-1 , v k-1 1:T 2 + 2ηL (ηL + 1) • σ 2 + 4J 2 η 2 L 2 G 2 . (<label>164</label></formula><formula xml:id="formula_194">)</formula><p>Rearranging the terms and summing for k ∈ [K], we have</p><formula xml:id="formula_195">1 K K k=1 E ∇ u f u k-1 , v k-1 1:T 2 ≤ 4E f (u 0 , v 0 1:T ) -f (u K , v K 1:T ) JηK + 8 ηL (ηL + 1) • σ 2 + 2J 2 η 2 L 2 G 2 K (165) ≤ 4E f (u 0 , v 0 1:T ) -f * JηK + 8 ηL (ηL + 1) • σ 2 + 2J 2 η 2 L 2 G 2 K , (<label>166</label></formula><formula xml:id="formula_196">)</formula><p>where we use Assumption 4 to obtain (166). Thus,</p><formula xml:id="formula_197">1 K K k=1 E ∇ u f u k-1 , v k-1 1:T 2 = O 1 √ K . (<label>167</label></formula><formula xml:id="formula_198">)</formula><p>To prove the second part of Eq. ( <ref type="formula" target="#formula_108">89</ref>), we first decompose</p><formula xml:id="formula_199">∆ v f u k , v k 1:T -f u k , v k+1 1:T ≥ 0 as follow, ∆ v = f u k , v k 1:T -f u k+1 , v k+1 1:T T k 1 + f u k+1 , v k+1 1:T -f u k , v k+1 1:T T k 2 . (<label>168</label></formula><formula xml:id="formula_200">)</formula><p>Using again Lemma G.1 and Eq. ( <ref type="formula" target="#formula_197">167</ref>), it follows that</p><formula xml:id="formula_201">1 K K k=1 E T k 1 ≤ O 1 K . (<label>169</label></formula><formula xml:id="formula_202">)</formula><p>For T k 2 , we use the fact that f is 2L-smooth (Lemma G.12) w.r.t. u and Cauchy-Schwartz inequality. Thus, for k &gt; 0, we write</p><formula xml:id="formula_203">T k 2 = f u k+1 , v k+1 1:T -f u k , v k+1 1:T (170) ≤ ∇ u f u k+1 , v k+1 1:T • u k+1 -u k + 2L 2 u k+1 -u k 2 . (<label>171</label></formula><formula xml:id="formula_204">)</formula><p>Summing over k and taking expectation:</p><formula xml:id="formula_205">1 K K k=1 E T k 2 ≤ 1 K K k=1 E ∇ u f u k+1 , v k+1 1:T • u k+1 -u k + 1 K K k=1 2L 2 E u k+1 -u k 2 (172) ≤ 1 K K k=1 E ∇ u f u k+1 , v k+1 1:T 2 K k=1 E u k+1 -u k 2 + 1 K K k=1 2L 2 E u k+1 -u k 2 , (<label>173</label></formula><formula xml:id="formula_206">)</formula><p>where the second inequality follows from Cauchy-Schwarz inequality. From Eq. ( <ref type="formula" target="#formula_164">143</ref>), with η k-1 = Jη, we have for t ∈ [T ]</p><formula xml:id="formula_207">E u k -u k-1,J t 2 ≤ 4σ 2 Jη 2 + 8J 3 η 2 • E ∇ u g k t u k-1 , v k-1 t 2 . (<label>174</label></formula><formula xml:id="formula_208">)</formula><p>Multiplying the previous by ω t and summing for t ∈ [T ], we have</p><formula xml:id="formula_209">T t=1 ω t • E u k-1 -u k-1,J t 2 ≤ 4J 2 σ 2 η 2 + 8J 3 η 2 • T t=1 ω t E ∇ u g k t u k-1 , v k-1 t 2 . (<label>175</label></formula><formula xml:id="formula_210">)</formula><p>Using Assumption 7 , it follows that</p><formula xml:id="formula_211">T t=1 ω t E u k-1 -u k-1,J t 2 ≤ 4J 2 η 2 2JG 2 + σ 2 + 8J 3 η 2 β 2 E T t=1 ω t ∇ u g k t u k-1 , v k-1 t 2 .</formula><p>(176) Finally using Jensen inequality and the fact that</p><formula xml:id="formula_212">g k t is a partial first-order of f t near u k-1 , v k-1 t , we have E u k-1 -u k 2 ≤ 4J 2 η 2 2JG 2 + σ 2 + 8J 3 η 2 β 2 E ∇ u f u k-1 , v k-1 1:T 2 . (<label>177</label></formula><formula xml:id="formula_213">)</formula><p>From Eq. (167) and η ≤ O(1/ √ K), we obtain</p><formula xml:id="formula_214">1 K K k=1 E u k-1 -u k 2 ≤ O (1) ,<label>(178)</label></formula><p>Replacing the last inequality in Eq. ( <ref type="formula" target="#formula_205">173</ref>) and using again Eq. (167), we obtain</p><formula xml:id="formula_215">1 K K k=1 E T k 2 ≤ O 1 K 3/4 .<label>(179)</label></formula><p>Combining Eq. ( <ref type="formula" target="#formula_201">169</ref>) and Eq. ( <ref type="formula" target="#formula_215">179</ref>), it follows that</p><formula xml:id="formula_216">1 K K k=1 E ∆ v f (u k , v k 1:T ) ≤ O 1 K 3/4 .<label>(180)</label></formula><p>G.1.3 Proof of Theorem 3.2</p><p>In this section, f denotes the negative log-likelihood function defined in Eq. ( <ref type="formula" target="#formula_6">6</ref>). Moreover, we introduce the negative log-likelihood at client t as follows</p><formula xml:id="formula_217">f t (Θ, Π) - log p(S t |Θ, Π) n - 1 n t nt i=1 log p(s (i) t |Θ, π t ).<label>(181)</label></formula><p>Theorem 3.2. Under Assumptions 1-7, when clients use SGD as local solver with learning rate η = a0 √ K , after a large enough number of communication rounds K, FedEM's iterates satisfy:</p><formula xml:id="formula_218">1 K K k=1 E ∇ Θ f Θ k , Π k 2 F ≤ O 1 √ K , 1 K K k=1 ∆ Π f (Θ k , Π k ) ≤ O 1 K 3/4 ,<label>(11)</label></formula><p>where the expectation is over the random batches samples, and</p><formula xml:id="formula_219">∆ Π f (Θ k , Π k ) f Θ k , Π k - f Θ k , Π k+1 ≥ 0.</formula><p>Proof. We prove this result as a particular case of Theorem 3.2 . To this purpose, in this section, we consider that V ∆ M , u = Θ ∈ R dM , v t = π t , and ω t = n t /n for t ∈ [T ]. For k &gt; 0, we define g k t as follows:</p><formula xml:id="formula_220">g k t Θ, π t = 1 n t nt i=1 M m=1 q k t z (i) t = m • l h θm (x (i) t ), y<label>(i) t</label></formula><p>-log p m (x</p><formula xml:id="formula_221">(i) t ) -log π t + log q k t z (i) t = m -c ,<label>(182)</label></formula><p>where c is the same constant appearing in Assumption 3, Eq. ( <ref type="formula" target="#formula_3">3</ref>). With this definition, it is easy to check that the federated surrogate optimization algorithm (Alg. 3) reduces to FedEM (Alg. 2). Theorem 3.2 then follows immediately from Theorem 3.2 , once we verify that g k t 1≤t≤T satisfy the assumptions of Theorem 3.2 . Assumption 4 , Assumption 6 , and Assumption 7 follow directly from Assumption 4, Assumption 6, and Assumption 7, respectively. Lemma G.3 shows that for k &gt; 0, g k is smooth w.r.t. Θ and then Assumption 5 is satisfied. Finally, Lemmas G.4-G.6 show that for t ∈</p><formula xml:id="formula_222">[T ] g k t is a partial first-order surrogate of f t w.r.t. Θ near Θ k-1 , π t with d V (•, •) = KL(• •). Lemma G.3. Under Assumption 5, for t ∈ [T ] and k &gt; 0, g k t is L-smooth w.r.t Θ. Proof. g k t is a convex combination of L-smooth function θ → l(θ; s (i) t ), i ∈ [n t ]. Thus it is also L-smooth. Lemma G.4. Suppose that Assumptions 1-3, hold. Then, for t ∈ [T ], Θ ∈ R M ×d and π t ∈ ∆ M r k t (Θ, π t ) g k t (Θ, π t ) -f t (Θ, π t ) = 1 n t nt i=1 KL q k t z (t) i p t z (t) i |s (t) i , Θ, π t ,</formula><p>where KL is Kullback-Leibler divergence.</p><p>Proof. Let k &gt; 0 and t ∈ [T ], and consider Θ ∈ R M ×d and π t ∈ ∆ M , then</p><formula xml:id="formula_223">g k t Θ, π t = 1 n t nt i=1 M m=1 q k t z (i) t = m • l h θm (x (i) t ), y (i) t -log p m (x (i) t ) -log π t + log q k t z (i) t = m -c ,<label>(183)</label></formula><formula xml:id="formula_224">= 1 n t nt i=1 M m=1 q k t z (i) t = m • -log p m y (i) t |x (i) t , θ m -log p m (x (i) t ) -log π t + log q k t z (i) t = m (184) = 1 n t nt i=1 M m=1 q k t z (i) t = m • -log p m y (i) t |x (i) t , θ m • p m (x (i) t ) • p t z (i) t = m + log q k t z (i) t = m (185) = 1 n t nt i=1 M m=1 q k t z (i) t = m • log q k t z (i) t = m -log p t s (i) t , z<label>(i)</label></formula><formula xml:id="formula_225">t = m Θ, π t ) (186) = 1 n t nt t=1 M m=1 q k t z (i) t = m log q k t z (i) t = m p t s<label>(i) t , z (i)</label></formula><formula xml:id="formula_226">t = m|Θ, π t .<label>(187)</label></formula><p>Thus,</p><formula xml:id="formula_227">r k t Θ, π t g k t (Θ, π t ) -f t (Θ, π t )<label>(188)</label></formula><p>= -</p><formula xml:id="formula_228">1 n t nt t=1 M m=1   q k t z (i) t = m • log p t s (i) t , z<label>(i)</label></formula><formula xml:id="formula_229">t = m|Θ, π t q k t z (i) t = m   + 1 n t nt i=1 log p t s (i) t |Θ, π t (189) = 1 n t nt t=1 M m=1 q k t z (i) t = m log p t s (i) t |Θ, π t -log p t s<label>(i) t , z (i)</label></formula><formula xml:id="formula_230">t = m|Θ, π t q k t z (i) t = m (190) = 1 n t nt t=1 M m=1 q k t z (i) t = m log p t s (i) t |Θ, π t • q k t z (i) t = m p t s (i) t , z<label>(i)</label></formula><formula xml:id="formula_231">t = m|Θ, π t (191) = 1 n t nt t=1 M m=1 q k t z (i) t = m • log q k t z (i) t = m p t z (i) t = m|s (i) t , Θ, π t .<label>(192)</label></formula><p>Thus,</p><formula xml:id="formula_232">r k t (Θ, π t ) = 1 n t nt i=1 KL q k t (•) p t (•|s (t) i , Θ, π t ) ≥ 0.<label>(193)</label></formula><p>The following lemma shows that g k t and g k (as defined in Eq. 98) satisfy the first two properties in Definition 1.</p><p>Lemma G.5. Suppose that Assumptions 1-3 and Assumption 5 hold. For all k ≥ 0 and t ∈ [T ], g k t is a majorant of f t and r k t</p><formula xml:id="formula_233">g k t -f t is L-smooth in Θ. Moreover r k t Θ k-1 , π k-1 t = 0 and ∇ Θ r k t Θ k-1 , π k-1 t = 0.</formula><p>The same holds for g k , i.e., g k is a majorant of f ,</p><formula xml:id="formula_234">r k g k -f is L-smooth in Θ, r k Θ k-1 , Π k-1 = 0 and ∇ Θ r k Θ k-1 , Π k-1 = 0 Proof. For t ∈ [T ], consider Θ ∈ R M ×d and π t ∈ ∆ M , we have (Lemma G.4)</formula><formula xml:id="formula_235">r k t (Θ, π t ) g k t (Θ, π t ) -f t (Θ, π t ) = 1 n t nt i=1 KL q k t z (t) i p t z (i) t |s (i) t , Θ, π t . (<label>194</label></formula><formula xml:id="formula_236">)</formula><p>Since KL divergence is non-negative, it follows that g k t is a majorant of f t , i.e.,</p><formula xml:id="formula_237">∀ Θ ∈ R M ×d , π t ∈ ∆ M : g k t (Θ, π) ≥ f t (Θ, π t ) .<label>(195)</label></formula><p>Moreover since, q k t z</p><formula xml:id="formula_238">(i) t = p t z (i) t |s (i) t , Θ k-1 , π k-1 t for k &gt; 0, it follows that r k t Θ k-1 , π k-1 t = 0.<label>(196)</label></formula><p>For i ∈ [n t ] and m ∈ [M ], from Eq. 78, we have</p><formula xml:id="formula_239">p t z (i) t = m|s (i) t , Θ, π t = p m y (i) t |x (i) t , θ m × π tm M m =1 p m y (i) t |x (i) t , θ m × π tm (197) = exp -l h θm (x<label>(i) t ), y (i) t</label></formula><formula xml:id="formula_240">× π tm M m =1 exp -l h θ m (x<label>(i) t ), y (i) t × π tm (198)</label></formula><p>= exp -l h θm (x</p><formula xml:id="formula_241">(i) t ), y (i) t + log π tm M m =1 exp -l h θ m (x (i) t ), y (i) t + log π tm . (<label>199</label></formula><formula xml:id="formula_242">)</formula><p>For ease of notation, we introduce</p><formula xml:id="formula_243">l i (θ) l h θ (x (i) t ), y (i) t , θ ∈ R d , m ∈ [M ], i ∈ [n t ],<label>(200)</label></formula><formula xml:id="formula_244">γ m (Θ) p t z (i) t = m|s (i) t , Θ, π t , m ∈ [M ],<label>(201)</label></formula><p>and,</p><formula xml:id="formula_245">ϕ i (Θ) KL q k t z (t) i p t z (i) t |s (i) t , Θ, π t . (<label>202</label></formula><formula xml:id="formula_246">) For i ∈ [n t ], function l i is differentiable because smooth (Assum 5), thus γ m , m ∈ [M ]</formula><p>is differentiable as the composition of the softmax function and the function {Θ → -l i (Θ) + log π tm }. Its gradient is given by</p><formula xml:id="formula_247">∇ θm γ m (Θ) = -γ m (Θ) • (1 -γ m (Θ)) • ∇l i (θ m ) , ∇ θ m γ m (Θ) = γ m (Θ) • γ m (Θ) • ∇l i (θ m ) , m = m.<label>(203)</label></formula><p>Thus for m ∈ [M ], we have</p><formula xml:id="formula_248">∇ θm ϕ i (Θ) = M m =1 q k t z (t) i = m • ∇ θm γ m (Θ) γ m (Θ) (204) = m =1 m =m q k t z (t) i = m • γ m (Θ) • γ m (Θ) γ m (Θ) • • ∇l i (θ m ) -q k t z (t) i = m • γ m (Θ) • (1 -γ m (Θ)) γ m (Θ) • ∇l i (θ m ) .<label>(205)</label></formula><p>Using the fact that</p><formula xml:id="formula_249">M m =1 q k t z (t) i = m = 1, it follows that ∇ θm ϕ i (Θ) = γ m (Θ) -q k t z (t) i = m • ∇l i (θ m ) .<label>(206)</label></formula><p>Since l i , i ∈ [n t ] is twice continuously differentiable (Assumption 5), and</p><formula xml:id="formula_250">γ m , m ∈ [M ] is differentiable, then φ i , i ∈ [n t ] is twice continuously differentiable. We use H (ϕ i (Θ)) ∈ R dM ×dM (resp. H (l i (θ)) ∈ R d×d )</formula><p>to denote the Hessian of ϕ (resp. l i ) at Θ (resp. θ). The Hessian of ϕ i is a block matrix given by</p><formula xml:id="formula_251">           H (ϕ i (Θ)) m,m = -γ m (Θ) • (1 -γ m (Θ)) • ∇l i (θ m ) • ∇l i (θ m ) + γ m (Θ) -q k t z (t) i = m • H (l i (θ m )) H (ϕ i (Θ)) m,m = γ m (Θ) • γ m (Θ) • ∇l i (θ m ) • ∇l i (θ m ) , m = m.</formula><p>(207) We introduce the block matrix H ∈ R dM ×dM , defined by</p><formula xml:id="formula_252">   Hm,m = -γ m (Θ) • 1 -γ m (Θ) • ∇l i (θ m ) • (∇l i (θ m )) Hm,m = γ m (Θ) • γ m (Θ) • ∇ θ l i (θ m ) • ∇l i (θ m ) , m = m,<label>(208)</label></formula><p>Eq. ( <ref type="formula">207</ref>) can be written as</p><formula xml:id="formula_253">     H (ϕ i (Θ)) m,m -Hm,m = γ m (Θ) -q k t z (t) i = m • H (l i (θ m )) H (ϕ i (Θ)) m,m<label>-Hm,m = 0, m = m.</label></formula><p>(209) We recall that a twice differentiable function is L smooth if and only if the eigenvalues of its Hessian are smaller then L, see e.g., [52, Lemma 1.2.2] or [6, Section 3.2]. Since l i and also -l i are L-smooth (Assumption 5), we have for θ ∈ R d ,</p><formula xml:id="formula_254">-L • I d H (l i (θ)) L • I d .<label>(210)</label></formula><p>Using Lemma G.15, we can conclude that matrix H is semi-definite negative. Since</p><formula xml:id="formula_255">-1 ≤ γ m (Θ) -q k t z (t) i = m ≤ 1,<label>(211)</label></formula><p>it follows that</p><formula xml:id="formula_256">H (ϕ i (Θ)) L • I dM .<label>(212)</label></formula><p>The last equation proves that ϕ i is L-smooth. Thus r k t is L-smooth with respect to Θ as the average of L-smooth function.</p><formula xml:id="formula_257">Moreover, since r k t (Θ k-1 , π k-1 t ) = 0 and ∀Θ, Π; r k t (Θ, π t ) ≥ 0, it follows that Θ k-1 is a minimizer of Θ → r k t Θ, π k-1 t . Thus, ∇ Θ r k t (Θ k-1 , π k-1 t ) = 0.</formula><p>For Θ ∈ R M ×d and Π ∈ ∆ T ×M , we have</p><formula xml:id="formula_258">r k (Θ, Π) g k (Θ, Π) -f (Θ, Π)<label>(213)</label></formula><formula xml:id="formula_259">T t=1 n t n • g k t (Θ, π t ) -f t (Θ, π t ) (214) = T t=1 n t n r k t (Θ, π t ) .<label>(215)</label></formula><p>We see that r k is a weighted average of r k t 1≤t≤T . Thus,</p><formula xml:id="formula_260">r k t is L-smooth in Θ, r k (Θ, Π) ≥ 0, moreover r k t Θ k-1 , Π k-1 = 0 and ∇ Θ r k t Θ k-1 , Π k-1 = 0.</formula><p>The following lemma shows that g k t and g k satisfy the third property in Definition 1. Lemma G.6. Suppose that Assumption 1 holds and consider Θ ∈ R M ×d and Π ∈ ∆ T ×M , for k &gt; 0, the iterates of Alg. 3 verify</p><formula xml:id="formula_261">g k (Θ, Π) = g k Θ, Π k + T t=1 n t n KL π k t , π t .</formula><p>Proof. For t ∈ [T ] and k &gt; 0, consider Θ ∈ R M ×d and π t ∈ ∆ M such that ∀m ∈ [M ]; π tm = 0, we have</p><formula xml:id="formula_262">g k t (Θ, π t ) -g k t Θ, π k t = M m=1 1 n t nt i=1 q k t z (i) t = m =π k tm (Proposition 3.1) × log π k tm -log π tm (216) = M m=1 π k tm log π k tm π tm (217) = KL π k t , π t .<label>(218)</label></formula><p>We multiply by nt n and some for t ∈ [T ]. It follows that</p><formula xml:id="formula_263">g k Θ, Π k + T t=1 n t n KL π k t , π t = g k (Θ, Π) .<label>(219)</label></formula><p>G.2 Fully Decentralized Setting G.2.1 Additional Notations Remark 3. For convenience and without loss of generality, we suppose in this section that</p><formula xml:id="formula_264">ω t = 1, t ∈ [T ].</formula><p>We introduce the following matrix notation:</p><formula xml:id="formula_265">U k u k 1 , . . . , u k T ∈ R du×T (220) Ūk ūk , . . . , ūk ∈ R du×T (221) ∂g k U k , v k 1:T ; ξ k ∇ u g k 1 u k 1 , v k 1 ; ξ k 1 , . . . , ∇ u g k T u k T , v k T ; ξ k T ∈ R du×T<label>(222)</label></formula><p>where ūk = 1</p><formula xml:id="formula_266">T T t=1 u k t and v k 1:T = v k t 1≤t≤T ∈ V T .</formula><p>We denote by u k-1,j t the j-th iterate of the local solver at global iteration k at client t ∈ [T ], and by U k-1,j the matrix whose column t is u k-1,j t , thus,</p><formula xml:id="formula_267">u k-1,0 t = u k-1 t ; U k-1,0 = U k-1 ,<label>(223) and,</label></formula><formula xml:id="formula_268">u k t = T s=1 w k-1 st u k-1,J s ; U k = U k-1,J W k-1 .<label>(224)</label></formula><p>Using this notation, the updates of Alg. 5 can be summarized as</p><formula xml:id="formula_269">U k =   U k-1 - J-1 j=0 η k-1,j ∂g k U k-1,j , v 1:T ; ξ k-1,j   W k-1 .<label>(225)</label></formula><p>Similarly to the client-server setting, we define the normalized update of local solver at client t ∈ [T ]:</p><formula xml:id="formula_270">δk-1 t - u k-1,J t -u k-1,0 t η k-1 = J-1 j=0 η k-1,j ∇ u g k t u k-1,j t , v k t ; ξ k-1,j t J-1 j=0 η k-1,j ,<label>(226)</label></formula><p>and</p><formula xml:id="formula_271">δ k-1 t J-1 j=0 η k-1,j ∇ u g k t u k-1,j t , v k t η k-1 .<label>(227)</label></formula><p>Because clients updates are independent, and stochastic gradient are unbiased, it is clear that</p><formula xml:id="formula_272">E δ k-1 t -δk-1 t = 0,<label>(228)</label></formula><p>and that</p><formula xml:id="formula_273">∀ t, s ∈ [T ] s.t. s = t, E δ k-1 t -δk-1 t , δ k-1 s -δk-1 s = 0.</formula><p>(229) We introduce the matrix notation,</p><formula xml:id="formula_274">Υk-1 δk-1 1 , . . . , δk-1 T ∈ R du×T ; Υ k-1 δ k-1 1 , . . . , δ k-1 T ∈ R du×T . (<label>230</label></formula><formula xml:id="formula_275">)</formula><p>Using this notation, Eq. ( <ref type="formula" target="#formula_269">225</ref>) becomes</p><formula xml:id="formula_276">U k = U k-1 -η k-1 Υk-1 W k-1 .<label>(231)</label></formula><p>G.2.2 Proof of Theorem 3.3</p><p>In fully decentralized optimization, proving the convergence usually consists in deriving a recurrence on a term measuring the optimality of the average iterate (in our case this term is</p><formula xml:id="formula_277">E ∇ u f ūk , v k 1:T</formula><p>2 ) and a term measuring the distance to consensus, i.e., E T t=1 u k t -ūk 2 . In what follows we obtain those two recurrences, and then prove the convergence. Lemma G.7 (Average iterate term recursion). Suppose that Assumptions 5 -7 and Assumption 8 hold. Then, for k &gt; 0, and</p><formula xml:id="formula_278">(η k,j ) 1≤j≤J-1 such that η k J-1 j=0 η k,j ≤ min 1 2 √ 2L , 1</formula><p>8Lβ , the updates of fully decentralized federated surrogate optimization (Alg. 5) verify</p><formula xml:id="formula_279">E f (ū k , v k 1:T ) -f (ū k-1 , v k-1 1:T ) ≤ - 1 T T t=1 E d V v k t , v k-1 t - η k-1 8 E ∇ u f ūk-1 , v k-1 1:T 2 + (12 + T ) η k-1 L 2 4T • T t=1 E u k-1 t -ūk-1 2 + η 2 k-1 L T   4 J-1 j=0 L • η 2 k-1,j η k-1 + 1   σ 2 + 16η 3 k-1 L 2 T G 2 . (<label>232</label></formula><formula xml:id="formula_280">)</formula><p>Proof. We multiply both sides of Eq. ( <ref type="formula" target="#formula_276">231</ref>) by 11 T , thus for k &gt; 0 we have,</p><formula xml:id="formula_281">U k • 11 T = U k-1 -η k-1 Υk-1 W k-1 11 T ,<label>(233)</label></formula><p>since W k-1 is doubly stochastic (Assumption 8), i.e., W k-1 11 T = 11 T , is follows that,</p><formula xml:id="formula_282">Ūk = Ūk-1 -η k-1 Υk-1 • 11 T ,<label>(234)</label></formula><p>thus,</p><formula xml:id="formula_283">ūk = ūk-1 - η k-1 T • T t=1 δk-1 t . (<label>235</label></formula><formula xml:id="formula_284">)</formula><p>Using the fact that g k is L-smooth with respect to u (Assumption 5 ), we write</p><formula xml:id="formula_285">E g k ūk , v k-1 1:T = E g k ūk-1 - η k-1 T T t=1 δk-1 t , v k-1 1:T (236) ≤ g k (ū k-1 , v k-1 1:T ) -E ∇ u g k (ū k-1 , v k-1 1:T ), η k-1 T T t=1 δk-1 t + L 2 E η k-1 T T t=1 δk-1 t 2 (237) = g k (ū k-1 , v k-1 1:T ) -η k-1 E ∇ u g k (ū k-1 , v k-1 1:T ), 1 T T t=1 δk-1 t T1 + η 2 k-1 • L 2T 2 E T t=1 δk-1 t 2 T2 ,<label>(238)</label></formula><p>where the expectation is taken over local random batches. As in the client-server case, we bound the terms T 1 and T 2 . First, we bound T 1 , for k &gt; 0, we have</p><formula xml:id="formula_286">T 1 = E ∇ u g k (ū k-1 , v k-1 1:T ), 1 T T t=1 δk-1 t (239) = E ∇ u g k ūk-1 , v k-1 1:T , 1 T T t=1 δk-1 t -δ k-1 t =0, because E[δ k-1 t -δk-1 t ]=0 + E ∇ u g k ūk-1 , v k-1 1:T , 1 T T t=1 δ k-1 t (240) = E ∇ u g k ūk-1 , v k-1 1:T , 1 T T t=1 δ k-1 t (241) = 1 2 E ∇ u g k ūk-1 , v k-1 1:T 2 + 1 2 E 1 T T t=1 δ k-1 t 2 - 1 2 E ∇ u g k ūk-1 , v k-1 1:T - 1 T T t=1 δ k-1 t 2 . (<label>242</label></formula><formula xml:id="formula_287">)</formula><p>We bound now T 2 . For k &gt; 0, we have,</p><formula xml:id="formula_288">T 2 = E T t=1 δk-1 t 2 (243) = E T t=1 δk-1 t -δ k-1 t + T t=1 δ k-1 t 2 (244) ≤ 2E T t=1 δk-1 t -δ k-1 t 2 + 2 • E T t=1 δ k-1 t 2 (245) = 2 • T t=1 E δk-1 t -δ k-1 t 2 + 2 1≤t =s≤T E δk-1 t -δ k-1 t , δk-1 s -δ k-1</formula><p>s =0; because of Eq. ( <ref type="formula">229</ref>)</p><formula xml:id="formula_289">+ 2E T t=1 δ k-1 t 2 (246) = 2 • T t=1 E δk-1 t -δ k-1 t 2 + 2 • E T t=1 δ k-1 t 2 (247) = 2 • E T t=1 δ k-1 t 2 + 2 • T t=1 1 η 2 k-1 E J-1 j=0 η k-1,j • ∇ u g k t u k-1,j t , v k-1 t -∇ u g k t u k-1,j t , v k-1 t ; ξ k-1,j t 2 . (<label>248</label></formula><formula xml:id="formula_290">)</formula><p>Since batches are sampled independently, and stochastic gradients are unbiased with finite variance (Assumption 6 ), the last term in the RHS of the previous equation can be bounded using σ 2 , leading to</p><formula xml:id="formula_291">T 2 ≤ 2 • T t=1 J-1 j=0 η 2 k-1,j η 2 k-1 σ 2 + 2 • E T t=1 δ k-1 t 2 (249) = 2T • σ 2 • T t=1 • J-1 j=0 η 2 k-1,j η 2 k-1 + 2E T t=1 δ k-1 t 2<label>(250)</label></formula><formula xml:id="formula_292">≤ 2T • σ 2 + 2 • E T t=1 δ k-1 t 2 . (<label>251</label></formula><formula xml:id="formula_293">)</formula><p>Replacing Eq. ( <ref type="formula" target="#formula_286">242</ref>) and Eq. ( <ref type="formula" target="#formula_292">251</ref>) in Eq. ( <ref type="formula" target="#formula_285">238</ref>), we have</p><formula xml:id="formula_294">E g k (ū k , v k-1 1:T ) -g k (ū k-1 , v k-1 1:T ) ≤ - η k-1 2 E ∇ u g k ūk-1 , v k-1 1:T 2 - η k-1 2 (1 -2Lη k-1 ) E 1 T T t=1 δ k-1 t 2 + L T η 2 k-1 σ 2 + η k-1 2 E ∇ u g k ūk-1 , v k-1 1:T - 1 T T t=1 δ k-1 t 2 .<label>(252)</label></formula><p>For η k-1 small enough, in particular for η k-1 ≤ 1 2L , we have</p><formula xml:id="formula_295">E g k (ū k , v k-1 1:T ) -g k (ū k-1 , v k-1 1:T ) ≤ - η k-1 2 E ∇ u g k ūk-1 , v k-1 1:T 2 + L T η 2 k-1 σ 2 + η k-1 2 E 1 T T t=1 ∇ u g k t ūk-1 , v k-1 t -δ k-1 t 2 . (<label>253</label></formula><formula xml:id="formula_296">)</formula><p>We use Jensen inequality to bound the last term in the RHS of the previous equation, leading to</p><formula xml:id="formula_297">E g k (ū k , v k-1 1:T ) -g k (ū k-1 , v k-1 1:T ) ≤ - η k-1 2 E ∇ u g k ūk-1 , v k-1 1:T 2 + L T η 2 k-1 σ 2 + η k-1 2T • T t=1 E ∇ u g k t ūk-1 , v k-1 t -δ k-1 t 2 T3 . (<label>254</label></formula><formula xml:id="formula_298">)</formula><p>We bound now the term T 3 :</p><formula xml:id="formula_299">T 3 = E ∇ u g k t ūk-1 , v k-1 t -δ k-1 t 2 (255) = E ∇ u g k t ūk-1 , v k-1 t - J-1 j=0 η k-1,j • ∇ u g k t u k-1,j t , v k-1 t η k-1 2 (256) = E J-1 j=0 η k-1,j η k-1 • ∇ u g k t ūk-1 , v k-1 t -∇ u g k t u k-1,j t , v k-1 t 2 . (<label>257</label></formula><formula xml:id="formula_300">)</formula><p>Using Jensen inequality, it follows that</p><formula xml:id="formula_301">T 3 ≤ J-1 j=0 η k-1,j η k-1 • E ∇ u g k t ūk-1 , v k-1 t -∇ u g k t u k-1,j t , v k-1 t 2 (258) = J-1 j=0 η k-1,j η k-1 • E ∇ u g k t ūk-1 , v k-1 t -∇ u g k t u k-1 t , v k-1 t + ∇ u g k t u k-1 t , v k-1 t -∇ u g k t u k-1,j t , v k-1 t 2 (259) ≤ 2 • E ∇ u g k t ūk-1 , v k-1 t -∇ u g k t u k-1 t , v k-1 t 2 + 2 • J-1 j=0 η k-1,j η k-1 • E ∇ u g k t u k-1 t , v k-1 t -∇ u g k t u k-1,j t , v k-1 t 2 (260) ≤ 2L 2 • E ūk-1 -u k-1 t 2 + 2L 2 • J-1 j=0 η k-1,j η k-1 • E u k-1,j t -u k-1,0 t 2 ,<label>(261)</label></formula><p>where we used the L-smoothness of g k t (Assumption 5 ) to obtain the last inequality. As in the centralized case (Lemma G.1), we bound terms u k-1,j t -u k-1,0 t 2 , j ∈ {0, . . . , J -1}. Using exactly the same steps as in the proof of Lemma G.1, Eq. ( <ref type="formula" target="#formula_164">143</ref>) holds with u k-1,0 t instead of u k-1 t , i.e.,</p><formula xml:id="formula_302">1 -4η 2 k-1 L 2 • J-1 j=0 η k-1,j η k-1 • E u k-1,0 t -u k-1,j t 2 ≤ 2σ 2 •    J-1 j=0 η 2 k-1,j    + 4η 2 k-1 • E ∇ u g k t u k-1,0 t , v k-1 t 2 . (<label>262</label></formula><formula xml:id="formula_303">)</formula><p>For η k-1 small enough, in particular for η k-1 ≤ 1 2 √ 2L , we have</p><formula xml:id="formula_304">J-1 j=0 η k-1,j η k-1 • E u k-1,0 t -u k-1,j t 2 ≤ 8η 2 k-1 • E ∇ u g k t u k-1,0 t , v k-1 t 2 + 4σ 2 •    J-1 j=0 η 2 k-1,j    (263) ≤ 8η 2 k-1 • E ∇ u g k t u k-1,0 t , v k-1 t -∇ u g k t ūk-1 , v k-1 t + ∇ u g k t ūk-1 , v k-1 t 2 + 4σ 2 •    J-1 j=0 η 2 k-1,j    (264) ≤ 16η 2 k-1 • E ∇ u g k t u k-1,0 t , v k-1 t -∇ u g k t ūk-1 , v k-1 t 2 + 16η 2 k-1 • ∇ u g k t ūk-1 , v k-1 t 2 + 4σ 2 •    J-1 j=0 η 2 k-1,j    (265) ≤ 16η 2 k-1 L 2 • E u k-1 t -ūk-1 2 + 16η 2 k-1 • ∇ u g k t ūk-1 , v k-1 t 2 + 4σ 2 •    J-1 j=0 η 2 k-1,j    ,<label>(266)</label></formula><p>where the last inequality follows from the L-smoothness of g k t . Replacing Eq. (266) in Eq. ( <ref type="formula" target="#formula_301">261</ref>), we have</p><formula xml:id="formula_305">T 3 ≤ 32η 2 k-1 L 4 • E u k-1 t -ūk-1 2 + 8L 2 σ 2 •    J-1 j=0 η 2 k-1,j    + 32η 2 k-1 L 2 • E ∇ u g k t ūk-1 , v k-1 t 2 + 2L 2 • E ūk-1 -u k-1 t 2 . (<label>267</label></formula><formula xml:id="formula_306">)</formula><p>For η k small enough, in particular if</p><formula xml:id="formula_307">η k ≤ 1 2 √</formula><p>2L we have,</p><formula xml:id="formula_308">T 3 ≤ 6L 2 E u k-1 t -ūk-1 2 + 8L 2 σ 2 J-1 j=0 η 2 k-1,j + 32η 2 k-1 L 2 ∇ u g k t ūk-1 , v k-1 t 2 . (<label>268</label></formula><formula xml:id="formula_309">)</formula><p>Replacing Eq. ( <ref type="formula" target="#formula_308">268</ref>) in Eq. ( <ref type="formula" target="#formula_297">254</ref>), we have</p><formula xml:id="formula_310">E g k (ū k , v k-1 1:T ) -g k (ū k-1 , v k-1 1:T ) ≤ 3η k-1 L 2 T • T t=1 E u k-1 t -ūk-1 2 + η 2 k-1 L T   4 J-1 j=0 T L • η 2 k-1,j η k-1 + 1   σ 2 - η k-1 2 E ∇ u g k ūk-1 , v k-1 1:T 2 + 16η 3 k-1 L 2 T T t=1 ∇ u g k t ūk-1 , v k-1 t 2 .<label>(269)</label></formula><p>We use now Assumption 7 to bound the last term in the RHS of the previous equation, leading to</p><formula xml:id="formula_311">E g k (ū k , v k-1 1:T ) -g k (ū k-1 , v k-1 1:T ) ≤ 3η k-1 L 2 T • T t=1 E u k-1 t -ūk-1 2 + η 2 k-1 L T   4 J-1 j=0 T L • η 2 k-1,j η k-1 + 1   σ 2 - η k-1 • 1 -32η 2 k-1 L 2 β 2 2 E ∇ u g k ūk-1 , v k-1 1:T 2 + 16η 3 k-1 L 2 T G 2 . (<label>270</label></formula><formula xml:id="formula_312">)</formula><p>For η k-1 small enough, in particular, if η k-1 ≤ 1 8Lβ , we have</p><formula xml:id="formula_313">E g k (ū k , v k-1 1:T ) -g k (ū k-1 , v k-1 1:T ) ≤ - η k-1 4 E ∇ u g k ūk-1 , v k-1 1:T 2 + 3η k-1 L 2 T • T t=1 E u k-1 t -ūk-1 2 + η 2 k-1 L T   4 J-1 j=0 T L • η 2 k-1,j η k-1 + 1   σ 2 + 16η 3 k-1 L 2 T G 2 . (<label>271</label></formula><formula xml:id="formula_314">)</formula><p>We use Lemma G.14 to get</p><formula xml:id="formula_315">E g k (ū k , v k-1 1:T ) -f (ū k-1 , v k-1 1:T ) ≤ - η k-1 8 E ∇ u f ūk-1 , v k-1 1:T 2 + (12 + T ) η k-1 L 2 4T • T t=1 E u k-1 t -ūk-1 2 + η 2 k-1 L T   4 J-1 j=0 L • η 2 k-1,j η k-1 + 1   σ 2 + 16η 3 k-1 L 2 T G 2 .<label>(272)</label></formula><p>Finally, since g k t is a partial first-order surrogate of f t near u k-1 , v k-1 t , we have</p><formula xml:id="formula_316">E f (ū k , v k 1:T ) -f (ū k-1 , v k-1 1:T ) ≤ - 1 T T t=1 E d V v k t , v k-1 t - η k-1 8 E ∇ u f ūk-1 , v k-1 1:T 2 + (12 + T ) η k-1 L 2 4T • T t=1 E u k-1 t -ūk-1 2 + η 2 k-1 L T   4 J-1 j=0 L • η 2 k-1,j η k-1 + 1   σ 2 + 16η 3 k-1 L 2 T G 2 . (<label>273</label></formula><formula xml:id="formula_317">)</formula><p>Lemma G.8 (Recursion for consensus distance, part 1). Suppose that Assumptions 5 -7 and Assumption 8 hold. For k ≥ τ , consider m = k τ -1 and</p><formula xml:id="formula_318">(η k,j ) 1≤j≤J-1 such that η k J-1 j=0 η k,j ≤ min 1 4L , 1 4Lβ</formula><p>then, the updates of fully decentralized federated surrogate optimization (Alg 5) verify</p><formula xml:id="formula_319">E T t=1 u k t -ūk 2 F ≤ (1 - p 2 )E U mτ -Ūmτ 2 F + 44τ 1 + 2 p L 2 k-1 l=mτ η 2 l E U l -Ūl 2 F + T • σ 2 • k-1 l=mτ    η 2 l + 16τ L 2 1 + 2 p •    J-1 j=0 η 2 l,j       + 16τ 1 + 2 p G 2 k-1 l=mτ η 2 l + 16τ 1 + 2 p β 2 k-1 l=mτ η 2 l E ∇ u f ūl,j , v l 1:T 2 .</formula><p>Proof. For k ≥ τ , and m = k τ -1, we have</p><formula xml:id="formula_320">E T t=1 u k t -ūk 2 F = E U k -Ūk 2 F (274) = E U k -Ūmτ -Ūk -Ūmτ 2 F (275) ≤ E U k -Ūmτ 2 F ,<label>(276)</label></formula><p>where we used the fact that A -</p><formula xml:id="formula_321">Ā 2 F = A • I -11 T F ≤ I -11 T 2 • A 2 F = A<label>2</label></formula><p>F to obtain the last inequality. Using Eq. ( <ref type="formula" target="#formula_276">231</ref>) recursively, we have</p><formula xml:id="formula_322">U k = U mτ k-1 l =mτ W l - k-1 l=mτ η l Υl k-1 l =l W l .<label>(277)</label></formula><p>Thus,</p><formula xml:id="formula_323">E T t=1 u k t -ūk 2 F ≤ E U mτ k-1 l =mτ W l -Ūmτ - k-1 l=mτ η l Υl k-1 l =l W l 2 F (278) = E U mτ k-1 l =mτ W l -Ūmτ - k-1 l=mτ η l Υ l k-1 l =l W l + k-1 l=mτ η l Υ l -Υl k-1 l =l W l 2 F (279) = E U mτ k-1 l =mτ W l -Ūmτ - k-1 l=mτ η l Υ l k-1 l =l W l 2 F + E k-1 l=mτ η l Υ l -Υl k-1 l =l W l 2 F + 2E U mτ k-1 l =mτ W l -Ūmτ - k-1 l=mτ η l Υ l k-1 l =l W l , k-1 l=mτ η l Υ l -Υl k-1 l =l W l F .<label>(280)</label></formula><p>Since stochastic gradients are unbiased, the last term in the RHS of the previous equation is equal to zero. Using the following standard inequality for Euclidean norm with α &gt; 0,</p><formula xml:id="formula_324">a + b 2 ≤ (1 + α) a 2 + 1 + α -1 b 2 ,<label>(281)</label></formula><p>we have</p><formula xml:id="formula_325">E T t=1 u k t -ūk 2 F ≤ (282) (1 + α) E U mτ k-1 l =mτ W l -Ūmτ 2 F + 1 + α -1 E k-1 l=mτ η l Υ l k-1 l =l W l 2 F + k-1 l=mτ η 2 l E Υ l -Υl k-1 l =l W l 2 F .<label>(283)</label></formula><p>Since k ≥ (m + 1)τ and matrices W l l≥0 are doubly stochastic, we have</p><formula xml:id="formula_326">E T t=1 u k t -ūk 2 F ≤ (1 + α) E U mτ    (m+1)τ -1 l =mτ W l    -Ūmτ 2 F + 1 + α -1 E k-1 l=mτ η l Υ l 2 F + k-1 l=mτ η 2 l E Υ l -Υl 2 F (284) ≤ (1 + α) E U mτ    (m+1)τ -1 l =mτ W l    -Ūmτ 2 F + 1 + α -1 • (k -mτ ) k-1 l=mτ η 2 l E Υ l 2 F + k-1 l=mτ η 2 l E Υ l -Υl 2 F ,<label>(285)</label></formula><p>where we use the fact that AB F ≤ A 2 B F and that A = 1 when A is a doubly stochastic matrix to obtain the first inequality, and Cauchy-Schwarz inequality to obtain the second one. Using Assumption 8 to bound the first term of the RHS of the previous equation and the fact that that k ≤ (m + 2)τ , it follows that</p><formula xml:id="formula_327">E T t=1 u k t -ūk 2 F ≤ (1 + α)(1 -p)E U mτ -Ūmτ 2 F + 2τ 1 + α -1 k-1 l=mτ η 2 l E Υ l 2 F + k-1 l=mτ η 2 l E Υ l -Υl 2 F .<label>(286)</label></formula><p>We use the fact that stochastic gradients have bounded variance (Assumption 6 ) to bound</p><formula xml:id="formula_328">E Υ l -Υl 2 F as follows, E Υ l -Υl 2 F = T t=1 E δ l t -δl t 2 (287) = T t=1 E J-1 j=0 η l,j η l • ∇ u g l+1 t u l,j t , v k-1 t -∇ u g l+1 t u l,j t , v l t ; ξ l,j t 2<label>(288)</label></formula><formula xml:id="formula_329">≤ T t=1 J-1 j=0 η l,j η l • E ∇ u g l+1 t u l,j t , v k-1 t -∇ u g l+1 t u l,j t , v l t ; ξ l,j t 2<label>(289)</label></formula><formula xml:id="formula_330">≤ T t=1 J-1 j=0 η l,j η l σ 2 (290) = T • σ 2 ,<label>(291)</label></formula><p>where we used Jensen inequality to obtain the first inequality and Assumption 6 to obtain the second inequality. Replacing back in Eq. ( <ref type="formula" target="#formula_327">286</ref>), we have</p><formula xml:id="formula_331">E T t=1 u k t -ūk 2 F ≤ (1 + α)(1 -p)E U mτ -Ūmτ 2 F + 2τ 1 + α -1 k-1 l=mτ η 2 l E Υ l 2 F + T • σ 2 • k-1 l=mτ η 2 l .<label>(292)</label></formula><p>The last step of the proof consists in bounding E Υ l 2 F for l ∈ {mτ, . . . , k -1},</p><formula xml:id="formula_332">E Υ l 2 F = T t=1 E δ l t 2 (293) = T t=1 E J-1 j=0 η l,j η l • ∇ u g l+1 t u l,j t , v l t 2<label>(294)</label></formula><formula xml:id="formula_333">≤ T t=1 J-1 j=0 η l,j η l • E ∇ u g l+1 t u l,j t , v l t 2<label>(295)</label></formula><formula xml:id="formula_334">≤ T t=1 J-1 j=0 η l,j η l • E ∇ u g l+1 t u l,j t , v l t -∇ u f t u l t , v l t + ∇ u f t u l t , v l t 2 (296) ≤ 2 T t=1 J-1 j=0 η l,j η l • E ∇ u g l+1 t u l,j t , v l t -∇ u f t u l t , v l t 2 + 2 T t=1 E ∇ u f t u l t , v l t 2 . (297)<label>53</label></formula><p>Since g l+1 t is a first order surrogate of f near u l t , v l t , we have</p><formula xml:id="formula_335">E Υ l 2 F ≤ 2 T t=1 J-1 j=0 η l,j η l • E ∇ u g l+1 t u l,j t , v l t -∇ u g l+1 t u l,0 t , v l t 2 + 2 T t=1 E ∇ u f t u l t , v l t -∇ u f t ūl , v l t + ∇ u f t ūl , v l t 2 (298) ≤ 2 T t=1 J-1 j=0 η l,j η l • E ∇ u g l+1 t u l,j t , v l t -∇ u g l+1 t u l,0 t , v l t 2 + 4 T t=1 E ∇ u f t u l t , v l t -∇ u f t ūl , v l t 2 + 4 T t=1 E ∇ u f t ūl , v l t 2 . (<label>299</label></formula><formula xml:id="formula_336">)</formula><p>Since f is 2L-smooth w.r.t u (Lemma G.12) and g is L-smooth w.r.t u (Assumption 5 ), we have</p><formula xml:id="formula_337">E Υ l 2 F ≤ 2 T t=1 J-1 j=0 η l,j η l • L 2 E u l,j t -u l,0 t 2 + 16L 2 • T t=1 E u l t -ūl 2 + 4 T t=1 E ∇ u f t ūl , v l t 2 .<label>(300)</label></formula><p>We use Eq. ( <ref type="formula" target="#formula_304">266</ref>) to bound the first term in the RHS of the previous equation, leading to</p><formula xml:id="formula_338">E Υ l 2 F ≤ 32η 2 l L 2 T t=1 E ∇ u g l+1 t ūl,j , v l t 2 + 16L 2 1 + 2η 2 l L 2 • T t=1 E u l t -ūl 2 + 4 T t=1 E ∇ u f t ūl , v l t 2 + 8T L 2 σ 2 •    J-1 j=0 η 2 l,j    .<label>(301)</label></formula><p>Using Lemma G.14, we have</p><formula xml:id="formula_339">E Υ l 2 F ≤ 4 1 + 16η 2 l L 2 • T t=1 E ∇ u f t ūl,j , v l t 2 + 16L 2 1 + 6η 2 l L 2 • T t=1 E u l t -ūl 2 + 8L 2 σ 2 T •    J-1 j=0 η 2 l,j    .<label>(302)</label></formula><p>For η l small enough, in particular, for η l ≤ 1 4L , we have</p><formula xml:id="formula_340">E Υ l 2 F ≤ 8 T t=1 E ∇ u f t ūl,j , v l t 2 + 22L 2 E U l -Ūl 2 F + 8L 2 σ 2 T    J-1 j=0 η 2 l,j    .<label>(303)</label></formula><p>Replacing Eq. (303) in Eq. ( <ref type="formula" target="#formula_331">292</ref>), we have</p><formula xml:id="formula_341">E T t=1 u k t -ūk 2 F ≤ (1 + α)(1 -p)E U mτ -Ūmτ 2 F + 44τ 1 + α -1 L 2 k-1 l=mτ η 2 l E U l -Ūl 2 F + 16τ 1 + α -1 k-1 l=mτ η 2 l T t=1 E ∇ u f t ūl,j , v l t 2 + T • σ 2 • k-1 l=mτ    η 2 l + 16τ L 2 1 + α -1 •    J-1 j=0 η 2 l,j       .<label>(304)</label></formula><p>Using Lemma G.13 and considering α = p 2 , we have</p><formula xml:id="formula_342">E T t=1 u k t -ūk 2 F ≤ (1 - p 2 )E U mτ -Ūmτ 2 F + 44τ 1 + 2 p L 2 k-1 l=mτ η 2 l E U l -Ūl 2 F + T • σ 2 • k-1 l=mτ    η 2 l + 16τ L 2 1 + 2 p •    J-1 j=0 η 2 l,j       + 16τ 1 + 2 p G 2 k-1 l=mτ η 2 l + 16τ 1 + 2 p β 2 k-1 l=mτ η 2 l E ∇ u f ūl,j , v l 1:T 2 . (<label>305</label></formula><formula xml:id="formula_343">)</formula><p>Lemma G.9 (Recursion for consensus distance, part 2). Suppose that Assumptions 5 -7 and Assumption 8 hold. Consider m = k τ , then, for</p><formula xml:id="formula_344">(η k,j ) 1≤j≤J-1 such that η k J-1 j=0 η k,j ≤ min 1 4L , 1 4Lβ</formula><p>, the updates of fully decentralized federated surrogate optimization (Alg 5) verify</p><formula xml:id="formula_345">E T t=1 u k t -ūk 2 F ≤ (1 + p 2 )E U mτ -Ūmτ 2 F + 44τ 1 + 2 p L 2 k-1 l=mτ η 2 l E U l -Ūl 2 F + T • σ 2 • k-1 l=mτ    η 2 l + 16τ L 2 1 + 2 p •    J-1 j=0 η 2 l,j       + 16τ 1 + 2 p G 2 k-1 l=mτ η 2 l + 16τ 1 + 2 p β 2 k-1 l=mτ η 2 l E ∇ u f ūl,j , v l 1:T 2 . (<label>306</label></formula><formula xml:id="formula_346">)</formula><p>Proof. We use exactly the same proof as in Lemma G.8, with the only difference that Eq. (284)-Eq. ( <ref type="formula" target="#formula_327">286</ref>) is replaced by</p><formula xml:id="formula_347">E T t=1 u k t -ūk 2 F ≤ (1 + α)E U mτ -Ūmτ 2 F + 2τ 1 + α -1 k-1 l=mτ η 2 l E Υ l 2 F + k-1 l=mτ η 2 l E Υ l -Υl 2 F ,<label>(307)</label></formula><p>resulting from the fact that</p><formula xml:id="formula_348">(m+1)τ -1 l =mτ</formula><p>W l is a doubly stochastic matrix.</p><p>Lemma G.10. Under Assum. 5 -7 and Assum 8. For η k,j = η J with</p><formula xml:id="formula_349">η ≤ min 1 4L , p 92τ L , 1 4βL , 1 32 √ 2 • p τ β ,</formula><p>the iterates of Alg. 5 verifies</p><formula xml:id="formula_350">(12 + T )L 2 4T K k=0 E U k -Ūk 2 F ≤ 1 16 K k=0 E ∇ u f ūk , v k 1:T 2 +16A• 12 + T T • τ L 2 p (K +1)η 2 ,</formula><p>(308) for some constant A &gt; 0 and K &gt; 0.</p><p>Proof. Note that for k &gt; 0, η k = J-1 j=0 η kj = η, and that</p><formula xml:id="formula_351">k-1 l=mτ η 2 l = k-1 l=mτ η 2 ≤ 2τ • η 2</formula><p>Using Lemma G.8 and Lemma G.9, and the fact that p ≤ 1, we have for m</p><formula xml:id="formula_352">= k τ -1 E U k -Ūk 2 F ≤ (1 - p 2 )E U mτ -Ūmτ 2 F + 132τ p L 2 η 2 k-1 l=mτ E U l -Ūl 2 F +η 2 2τ T σ 2 1 + 16τ L 2 J 1 + 2 p + 16τ 1 + 2 p G 2 A + 16τ p β 2 η 2 k-1 l=mτ E ∇ u f ūl , v l 1:T 2 . (<label>309</label></formula><formula xml:id="formula_353">)</formula><p>and for m = k τ ,</p><formula xml:id="formula_354">E U k -Ūk 2 F ≤ (1 + p 2 )E U mτ -Ūmτ 2 F + 132τ p L 2 η 2 k-1 l=mτ E U l -Ūl 2 F +η 2 2τ T σ 2 1 + 16τ L 2 J 1 + 2 p + 16τ 1 + 2 p G 2 A + 16τ p β 2 D η 2 k-1 l=mτ E ∇ u f ūl , v l 1:T 2 .<label>(310)</label></formula><p>Using the fact that η ≤ p 92τ L , it follows that for m = k τ -1</p><formula xml:id="formula_355">E U k -Ūk 2 F ≤ (1 - p 2 )E U mτ -Ūmτ 2 F + p 64τ k-1 l=mτ E U l -Ūl 2 +η 2 A + Dη 2 k-1 l=mτ E ∇ u f ūl , v l 1:T 2 ,<label>(311)</label></formula><p>and for m = k τ ,</p><formula xml:id="formula_356">E U k -Ūk 2 F ≤ (1 + p 2 )E U mτ -Ūmτ 2 F + p 64τ k-1 l=mτ E U l -Ūl 2 F +η 2 A + Dη 2 k-1 l=mτ E ∇ u f ūl , v l 1:T 2 . (<label>312</label></formula><formula xml:id="formula_357">)</formula><p>The rest of the proof follows using [31, <ref type="bibr">Lemma 14]</ref> </p><formula xml:id="formula_358">with B = (12+T )L 2 4T , b = 1 8 , constant (thus 8τ p -slow 7 ) steps-size η ≤ 1 32 √ 2 p τ β = 1 16 p/8</formula><p>Dτ and constant weights ω k = 1.</p><p>Theorem 3.3 . Under Assumptions 4 -7 and Assumption 8, when clients use SGD as local solver with learning rate η = a0 √ K , after a large enough number of communication rounds K, the iterates of fully decentralized federated surrogate optimization (Alg. 5) satisfy:</p><formula xml:id="formula_359">1 K K k=1 E ∇ u f ūk , v k 1:T 2 ≤ O 1 √ K ,<label>(313)</label></formula><p>and,</p><formula xml:id="formula_360">1 K K k=1 T t=1 ω t • E d V v k t , v k+1 t ≤ O 1 K ,<label>(314)</label></formula><p>where ūk = 1 T T t=1 u k t . Moreover, local estimates u k t 1≤t≤T converge to consensus, i.e., to ūk :</p><formula xml:id="formula_361">1 K K k=1 T t=1 E u k t -ūk 2 ≤ O 1 √ K .<label>(315)</label></formula><p>Proof. We prove first the convergence to a stationary point in u, i.e. Eq. (313), using <ref type="bibr" target="#b30">[31,</ref><ref type="bibr">Lemma 17]</ref>, then we prove Eq. (314) and Eq. (315).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Note that for</head><formula xml:id="formula_362">K large enough, η ≤ min 1 4L , p 92τ L , 1 4βL , 1 32 √ 2 • p τ β .</formula><p>Proof of Eq. 313. Rearranging the terms in the result of Lemma G.7 and dividing it by η we have</p><formula xml:id="formula_363">1 η • E f (ū k , v k 1:T ) -f (ū k-1 , v k-1 1:T ) ≤ - 1 8 E ∇ u f ūk-1 , v k-1 1:T 2 + (12 + T ) L 2 4T • E U k-1 -Ūk-1 2 + ηL T 4L J + 1 σ 2 + 16η 2 L 2 T G 2 . (<label>316</label></formula><formula xml:id="formula_364">)</formula><p>Summing over k ∈ [K + 1], we have</p><formula xml:id="formula_365">1 η • E f (ū K+1 , v K+1 1:T ) -f (ū 0 , v 0 1:T ) ≤ - 1 8 K k=0 E ∇ u f ūk , v k 1:T 2 + (12 + T ) L 2 4T • K k=0 E U k -Ūk 2 + (K + 1)ηL T 4L J + 1 σ 2 + 16(K + 1) • η 2 L 2 T G 2 .<label>(317)</label></formula><p>Using Lemma G.10, we have</p><formula xml:id="formula_366">1 η • E f (ū K+1 , v K+1 1:T ) -f (ū 0 , v 0 1:T ) ≤ - 1 16 K k=0 E ∇ u f ūk , v k 1:T 2 + 16A • 12 + T T • τ L 2 p (K + 1)η 2 + (K + 1)ηL T 4L J + 1 σ 2 + 16(K + 1)η 2 L 2 T G 2 . (<label>318</label></formula><formula xml:id="formula_367">)</formula><p>Using Assumption 4 , it follows that</p><formula xml:id="formula_368">1 16 K k=0 E ∇ u f ūk , v k 1:T 2 ≤ f (ū 0 , v 0 1:T ) -f * η + 16A • 12 + T T • τ L 2 p (K + 1)η 2 + (K + 1)ηL T 4L J + 1 σ 2 + 16(K + 1)η 2 L 2 T G 2 .</formula><p>(319)</p><p>We divide by K + 1 and we have</p><formula xml:id="formula_369">1 16(K + 1) K k=0 E ∇ u f ūk , v k 1:T 2 ≤ f (ū 0 , v 0 1:T ) -f * η(K + 1) + 16A • 12 + T T • τ L 2 p η 2 + ηL T 4L J + 1 σ 2 + 16η 2 L 2 T G 2 . (<label>320</label></formula><formula xml:id="formula_370">)</formula><p>The final result follows from <ref type="bibr" target="#b30">[31,</ref><ref type="bibr">Lemma 17]</ref>.</p><p>Proof of Eq. 315. We multiply Eq. (308) (Lemma G.10) by 1 K+1 , and we have</p><formula xml:id="formula_371">1 K + 1 K k=0 E U k -Ūk 2 F ≤ 1 16(K + 1) K k=0 E ∇ u f ūk , v k 1:T 2 F + 64Aτ p(K + 1)</formula><p>Kη 2 , (321) since η ≤ O 1 √ K , using Eq. ( <ref type="formula" target="#formula_359">313</ref>), it follows that</p><formula xml:id="formula_372">1 K K k=1 E U k -Ūk 2 F ≤ O 1 √ K .<label>(322)</label></formula><p>Thus,</p><formula xml:id="formula_373">1 K K k=1 T t=1 E u k t -ūk 2 F ≤ O 1 √ K . (<label>323</label></formula><formula xml:id="formula_374">)</formula><p>Proof of Eq. 314. Using the result of Lemma G.7 we have</p><formula xml:id="formula_375">1 T T t=1 E d V v k t , v k-1 t ≤ E f (ū k-1 , v k-1 1:T ) -f (ū k , v k 1:T ) + (12 + T ) η k-1 L 2 4T • T t=1 E u k-1 t -ūk-1 2 + η 2 k-1 L T   4 J-1 j=0 L • η 2 k-1,j η k-1 + 1   σ 2 + 16η 3 k-1 L 2 T G 2 . (<label>324</label></formula><formula xml:id="formula_376">)</formula><p>The final result follows from the fact that η = O 1 √ K and Eq. (315).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>G.2.3 Proof of Theorem 3.3</head><p>We state the formal version of Theorem 3.3, for which only an informal version was given in the main text. Theorem 3.3. Under Assumptions 1-8, when clients use SGD as local solver with learning rate η = a0 √ K , D-FedEM's iterates satisfy the following inequalities after a large enough number of communication rounds K:</p><formula xml:id="formula_377">1 K K k=1 E ∇ Θ f Θk , Π k 2 F ≤ O 1 √ K , 1 K K k=1 T t=1 n t n KL π k t , π k-1 t ≤ O 1 K ,<label>(325)</label></formula><p>where Θk = Θ k 1 , . . . Θ k T • 11 T . Moreover, individual estimates Θ k t 1≤t≤T converge to consensus, i.e., to Θk :</p><formula xml:id="formula_378">min k∈[K] E T t=1 Θ k t -Θk 2 F ≤ O 1 √ K .</formula><p>Proof. We prove this result as a particular case of Theorem 3.3 . To this purpose, we consider that V ∆ M , u = Θ ∈ R dM , v t = π t , and ω t = n t /n for t ∈ [T ]. For k &gt; 0, we define g k t as follow,</p><formula xml:id="formula_379">g k t Θ, π t = 1 n t nt i=1 M m=1 q k t z (i) t = m • l h θm (x (i) t ), y<label>(i) t</label></formula><p>-log p m (x</p><formula xml:id="formula_380">(i) t ) -log π t + log q k t z (i) t = m -c , (<label>326</label></formula><formula xml:id="formula_381">)</formula><p>where c is the same constant appearing in Assumption 3, Eq. ( <ref type="formula" target="#formula_3">3</ref>). With this definition, it is easy to check that the federated surrogate optimization algorithm (Alg. 5) reduces to D-FedEM (Alg. 4).</p><p>Proof. Consider arbitrary u, v ∈ R du × V, and for t ∈ [T ], consider g {u,v} to be a partial first-order surrogate of f t near {u, v}. We write Assumption 7 for g </p><formula xml:id="formula_382">ω t • ∇ u f t (u, v) 2 ≤ G 2 + β 2 T t=1 ω t • ∇ u f t (u, v) 2 . (<label>333</label></formula><formula xml:id="formula_383">)</formula><p>Remark 4. Note that the assumption of Lemma G.13 is implicitly verified in Alg. 3 and Alg. 5, where we assume that every client t ∈ T canfunction compute a partial first-order surrogate of its local objective f t near any iterate (u, v) ∈ R du × V. Lemma G.14. For k &gt; 0, the iterates of Alg. 5, verify the following inequalities:</p><formula xml:id="formula_384">g k ūk-1 , v k-1 1:T ≤ f ūk-1 , v k-1 1:T + L 2 T t=1 ω t ūk-1 -u k-1 t 2 , ∇ u f ūk-1 , v k-1 1:T 2 ≤ 2 ∇ u g k ūk-1 , v k-1 1:T 2 + 2L 2 T t=1 ω t ūk-1 + u k-1 t 2 ,</formula><p>and,</p><formula xml:id="formula_385">∇ u g k ūk-1 , v k-1 1:T 2 ≤ 2 ∇ u f ūk-1 , v k-1 1:T 2 + 2L 2 T t=1 ω t ūk-1 -u k-1 t 2 ,</formula><p>Proof. For k &gt; 0 and t ∈ [T ], we have</p><formula xml:id="formula_386">g k t ūk-1 , v k-1 t = g k t ūk-1 , v k-1 t + f t ūk-1 , v k-1 t -f t ūk-1 , v k-1 t (334) = f t ūk-1 , v k-1 t + r k t ūk-1 , v k-1 t (335) = f t ūk-1 , v k-1 t + r k t ūk-1 , v k-1 t -r k t u k-1 t , v k-1 t + r k t u k-1 t , v k-1 t .<label>(336)</label></formula><p>Since</p><formula xml:id="formula_387">g k t u k t , v k-1 t = f t u k t , v k-1 t</formula><p>(Definition 1), it follows that</p><formula xml:id="formula_388">g k t ūk-1 , v k-1 t = f t ūk-1 , v k-1 t + r k t ūk-1 , v k-1 t -r k t u k-1 t , v k-1 t .<label>(337)</label></formula><p>Because r k t is L-smooth in u (Definition 1), we have</p><formula xml:id="formula_389">r k t ūk-1 , v k-1 t -r k t u k-1 t , v k-1 t ≤ ∇ u r k t u k-1 t , v k-1 t , ūk-1 -u k-1 t + L 2 ūk-1 -u k-1 t 2 . (<label>338</label></formula><formula xml:id="formula_390">)</formula><p>Since g k t is a partial first order surrogate of We have ∇ u r k t u k-1 t , v k-1 t = 0, thus</p><formula xml:id="formula_391">g k t ūk-1 , v k-1 t ≤ f t ūk-1 , v k-1 t + L 2 ūk-1 -u k-1 t 2 . (<label>339</label></formula><formula xml:id="formula_392">)</formula><p>Multiplying by ω t and summing for t ∈ [T ], we have</p><formula xml:id="formula_393">g k ūk-1 , v k-1 1:T ≤ f ūk-1 , v k-1 1:T + L 2 T t=1 ω t ūk-1 -u k-1 t 2 ,<label>(340)</label></formula><p>and the first inequality is proved.</p><formula xml:id="formula_394">+ M m=1     M m =1 m =m (α m • α m • x m • u m • u m • x m )     (353) = M m=1     -α m • (1 -α m ) • x m , u m 2 + α m • x m , u m M m =1 m =m α m • x m , u m     . (<label>354</label></formula><formula xml:id="formula_395">) Since α ∈ ∆ M , ∀m ∈ [M ], M m =1 m =m α m = (1 -α m ) ,<label>(355) thus,</label></formula><p>x</p><formula xml:id="formula_396">• H • x = M m=1 α m • x m , u m • M m =1 m =m α m x m , u m -x m , u m (356) = M m=1 α m • x m , u m • M m =1 α m x m , u m -x m , u m (357) = M m=1 α m • x m , u m 2 - M m=1 α m • x m , u m 2 . (<label>358</label></formula><formula xml:id="formula_397">)</formula><p>Using Jensen inequality, we have x • H • x ≤ 0.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I Details on Experimental Setup I.1 Datasets and Models</head><p>In this section we provide detailed description of the datasets and models used in our experiments. We used a synthetic dataset, verifying Assumptions 1-3, and five "real" datasets (CIFAR-10/CIFAR-100 <ref type="bibr" target="#b32">[33]</ref>, sub part of EMNIST <ref type="bibr" target="#b7">[8]</ref>, sub part of FEMNIST <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b46">47]</ref> and Shakespeare <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b46">47]</ref>) from which, two (FEMNIST and Shakespeare) has natural client partitioning. Below, we give a detailed description of the datasets and the models / tasks considered for each of them.</p><p>I.1.1 CIFAR-10 / CIFAR-100 CIFAR-10 and CIFAR-100 are labeled subsets of the 80 million tiny images dataset. They both share the same 60, 000 input images. CIFAR-100 has a finer labeling, with 100 unique labels, in comparison to CIFAR-10, having 10 unique label. We used Dirichlet allocation <ref type="bibr" target="#b64">[65]</ref>, with parameter α = 0.4 to partition CIFAR-10 among 80 clients. We used Pachinko allocation <ref type="bibr" target="#b53">[54]</ref> with parameters α = 0.4 and β = 10 to partition CIFAR-100 on 100 clients. For both of them we train MobileNet-v2 <ref type="bibr" target="#b54">[55]</ref> architecture with an additional linear layer. We used TorchVision <ref type="bibr" target="#b44">[45]</ref> implementation of MobileNet-v2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I.1.2 EMNIST</head><p>EMNIST (Extended MNIST) is a 62-class image classification dataset, extending the classic MNIST dataset. In our experiments, we consider 10% of the EMNIST dataset, that we partition using Dirichlet allocation of parameter α = 0.4 over 100 clients. We train the same convolutional network as in <ref type="bibr" target="#b53">[54]</ref>. The network has two convolutional layers (with 3 × 3 kernels), max pooling, and dropout, followed by a 128 unit dense layer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I.1.3 FEMNIST</head><p>FEMNIST (Federated Extended MNIST) is a 62-class image classification dataset built by partitioning the data of Extended MNIST based on the writer of the digits/characters. In our experiments, we used a subset with 15% of the total number of writers in FEMNIST. We train the same convolutional network as in <ref type="bibr" target="#b53">[54]</ref>. The network has two convolutional layers (with 3 × 3 kernels), max pooling, and dropout, followed by a 128 unit dense layer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I.1.4 Shakespeare</head><p>This dataset is built from The Complete Works of William Shakespeare and is partitioned by the speaking roles <ref type="bibr" target="#b46">[47]</ref>. In our experiments, we discarded roles with less than two sentences. We consider character-level based language modeling on this dataset. The model takes as input a sequence of 200 English characters and predicts the next character. The model embeds the 80 characters into a learnable 8-dimensional embedding space, and uses two stacked-LSTM layers with 256 hidden units, followed by a densely-connected layer. We also normalized each character by its frequency of appearance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I.1.5 Synthetic dataset</head><p>Our synthetic dataset has been generated according to Assumptions 1-3 as follows:    </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>J.6 Additional Results under Client Sampling</head><p>In our experiments, except for Figure <ref type="figure">1</ref>, we considered that all clients participate at each round. We run extra experiments with client sampling, by allowing only 20% of the clients to participate at each round. We also incorporate APFL <ref type="bibr" target="#b13">[14]</ref> into the comparison. Table <ref type="table" target="#tab_11">8</ref> summarizes our findings, giving the average and standard deviation of the test accuracy across 3 independent runs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>J.7 Convergence Plots</head><p>Figures 3 to 8 show the evolution of average train loss, train accuracy, test loss, and test accuracy over time for each experiment shown in Table <ref type="table" target="#tab_2">2</ref>.    </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Assumption 3 .</head><label>3</label><figDesc>H = {h θ } θ∈R d is a set of hypotheses parameterized by θ ∈ R d , whose convex hull is in H. For each distribution Dm with m ∈ [M ], there exists a hypothesis h θ * m , such that l h θ * m (x) , y = -log p m (y|x) + c,</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>t (x), y) • p m y|x, θm d y p (x) d x (49) = x∈X M m=1 πtm c ht (x) -y∈Y p m y|x, θm log p ht (y|x) d y p (x) d x (50) = x∈X c ht (x) -M m=1 πtm y∈Y p m y|x, θm log p ht (y|x) d y p (x) d x (51)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Train loss, train accuracy, test loss, and test accuracy for CIFAR10 [33]. .</figDesc><graphic coords="75,315.90,302.15,178.20,145.31" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Train loss, train accuracy, test loss, and test accuracy for CIFAR100 [33].</figDesc><graphic coords="76,117.90,225.28,178.20,145.31" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Train loss, train accuracy, test loss, and test accuracy for EMNIST [8].</figDesc><graphic coords="76,117.90,553.26,178.20,145.31" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Train loss, train accuracy, test loss, and test accuracy for FEMNIST [7, 47].</figDesc><graphic coords="77,117.90,223.45,178.20,145.31" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: Train loss, train accuracy, test loss, and test accuracy for Shakespeare [7, 47].</figDesc><graphic coords="77,117.90,552.65,178.20,145.31" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>.</head><label></label><figDesc>Assumption 4. The negative log-likelihood f is bounded below by f * ∈ R. ) 2 ≤ σ 2 . Assumption 7. (Bounded dissimilarity) There exist β and G such that for any set of weights α ∈ ∆ M :</figDesc><table><row><cell cols="12">Algorithm 1: FedEM (see also the more detailed Alg. 2 in App. D.1)</cell><cell></cell><cell></cell></row><row><cell cols="15">Input : Data S 1:T ; number of mixture distributions M ; number of communication rounds K Output : θ K m , m ∈ [M ]</cell></row><row><cell cols="7">for iterations k = 1, . . . , K do</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="10">server broadcasts θ k-1 m , 1 ≤ m ≤ M , to the T clients;</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="10">for tasks t = 1, . . . , T in parallel over T clients do</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="8">for component m = 1, . . . , M do</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="10">update q k t (z t = m) as in (8), ∀i ∈ {1, . . . , n t }; (i)</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="7">update π k tm as in (9);</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="10">θ k m,t ← LocalSolver(m, θ k-1 m , q k t , S t );</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="10">client t sends θ k m,t , 1 ≤ m ≤ M , to the server;</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="8">for component m = 1, . . . , M do</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="2">θ k m ←</cell><cell cols="2">T t=1</cell><cell cols="3">nt n × θ k m,t ;</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="15">Assumption 7 limits the level of dissimilarity of the different tasks, similarly to what is done in [66].</cell></row><row><cell cols="15">Theorem 3.2. Under Assumptions 1-7, when clients use SGD as local solver with learning rate η = a0 √ K , after a large enough number of communication rounds K, FedEM's iterates satisfy:</cell></row><row><cell cols="15">Assumption 5. (Smoothness) For all t ∈ [T ] and i ∈ [n t ], the function θ → l(θ; s (i) t ) is L-smooth</cell></row><row><cell cols="8">and twice continuously differentiable.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="15">Assumption 6. (Unbiased gradients and bounded variance) Each client t ∈ [T ] can sample a random</cell></row><row><cell cols="15">batch ξ from S t and compute an unbiased estimator g t (θ, ξ) of the local gradient with bounded</cell></row><row><cell cols="7">variance, i.e., E ξ [g t (θ, ξ)] = 1 nt</cell><cell cols="6">nt i=1 ∇ θ l(θ; s (i) t ) and E ξ g t (θ, ξ) -1 nt</cell><cell cols="2">nt i=1 ∇ θ l(θ; s (i)</cell></row><row><cell>T t=1</cell><cell>n t n</cell><cell>1 n t</cell><cell cols="2">nt i=1</cell><cell>M m=1</cell><cell cols="2">α m • l(θ; s (i) t )</cell><cell>2</cell><cell>≤ G 2 + β 2 1 n</cell><cell>t=1 T</cell><cell>i=1 nt</cell><cell>m=1 M</cell><cell>α m • l(θ; s (i) t )</cell><cell>2</cell><cell>.</cell></row></table><note><p>t</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>2). FedAvg+ updated the local model through a single pass on the local dataset. Unless otherwise stated, the number of components considered by FedEM was M = 3, training occurred over 80 communication rounds for Shakespeare and 200 rounds for all other datasets. Datasets and models (details in App. I.1).</figDesc><table><row><cell>Dataset</cell><cell>Task</cell><cell>Clients</cell><cell>Total samples</cell><cell>Model</cell></row><row><cell>FEMNIST [7]</cell><cell>Handwritten character recognition</cell><cell>539</cell><cell>120, 772</cell><cell>2-layer CNN + 2-layer FFN</cell></row><row><cell>EMNIST [8]</cell><cell>Handwritten character recognition</cell><cell>100</cell><cell>81, 425</cell><cell>2-layer CNN + 2-layer FFN</cell></row><row><cell>CIFAR10 [33]</cell><cell>Image classification</cell><cell>80</cell><cell>60, 000</cell><cell>MobileNet-v2 [55]</cell></row><row><cell>CIFAR100 [33]</cell><cell>Image classification</cell><cell>100</cell><cell>60, 000</cell><cell>MobileNet-v2 [55]</cell></row><row><cell>Shakespeare [7, 47]</cell><cell>Next-Character Prediction</cell><cell>778</cell><cell>4, 226, 158</cell><cell>Stacked-LSTM [25]</cell></row><row><cell>Synthetic</cell><cell>Binary Classification</cell><cell>300</cell><cell>1, 570, 507</cell><cell>Linear model</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>Test accuracy: average across clients / bottom decile. At each round, clients train for one epoch. Results for D-FedEM are in App. J.1. A comparison with MOCHA [59], which can only train linear models, is presented in App. J.2.</figDesc><table><row><cell>Dataset</cell><cell>Local</cell><cell cols="4">FedAvg [47] FedProx [38] FedAvg+ [27] Clustered FL [56] pFedMe [16] FedEM (Ours)</cell></row><row><cell>FEMNIST</cell><cell>71.0 / 57.5</cell><cell>78.6 / 63.9</cell><cell>78.9 / 64.0</cell><cell>75.3 / 53.0</cell><cell>73.5 / 55.1 74.9 / 57.6 79.9 / 64.8</cell></row><row><cell>EMNIST</cell><cell>71.9 / 64.3</cell><cell>82.6 / 75.0</cell><cell>83.0 / 75.4</cell><cell>83.1 / 75.8</cell><cell>82.7 / 75.0 83.3 / 76.4 83.5 / 76.6</cell></row><row><cell>CIFAR10</cell><cell>70.2 / 48.7</cell><cell>78.2 / 72.4</cell><cell>78.0 / 70.8</cell><cell>82.3 / 70.6</cell><cell>78.6 / 71.2 81.7 / 73.6 84.3 / 78.1</cell></row><row><cell>CIFAR100</cell><cell>31.5 / 19.9</cell><cell>40.9 / 33.2</cell><cell>41.0 / 33.2</cell><cell>39.0 / 28.3</cell><cell>41.5 / 34.1 41.8 / 32.5 44.1 / 35.0</cell></row><row><cell cols="3">Shakespeare 32.0 / 16.6 46.7 / 42.8</cell><cell>45.7 / 41.9</cell><cell>40.0 / 25.5</cell><cell>46.6 / 42.7 41.2 / 36.8 46.7 / 43.0</cell></row><row><cell>Synthetic</cell><cell>65.7 / 58.4</cell><cell>68.2 / 58.9</cell><cell>68.2 / 59.0</cell><cell>68.9 / 60.2</cell><cell>69.1 / 59.0 69.2 / 61.2 74.7 / 66.7</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 :</head><label>3</label><figDesc>Average test accuracy across clients unseen at training (train accuracy in parenthesis).</figDesc><table /><note><p><p><p><p>Dataset</p>FedAvg</p><ref type="bibr" target="#b46">[47]</ref> </p>FedAvg+ [27] FedEM (Ours) FEMNIST 78.3 (80.9) 74.2 (84.2) 79.1 (81.5) EMNIST 83.4 (82.7) 83.7 (92.9) 84.0 (83.3) CIFAR10 77.3 (77.5) 80.4 (80.5) 85.9 (90.7) CIFAR100 41.1 (42.1) 36.5 (55.3) 47.5 (46.6) Shakespeare 46.7 (47.1) 40.2 (93.0) 46.7 (46.6) Synthetic 68.6 (70.0) 69.1 (72.1) 73.0 (74.1)</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc>Client-Server Algorithm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . D.2 Fully Decentralized Algorithm . . . . . . . . . . . . . . . . . . . . . . . . . .</figDesc><table><row><cell>Table of Contents</cell></row><row><cell>A Proof of Proposition 2.1</cell></row><row><cell>B Relation with Other Multi-Task Learning Frameworks</cell></row><row><cell>C Centralized Expectation Maximization</cell></row><row><cell>D Detailed Algorithms</cell></row><row><cell>D.1</cell></row></table><note><p>E Details on the Fully Decentralized Setting F Federated Surrogate Optimization F.1 Reminder on Basic (Centralized) Surrogate Optimization . . . . . . . . . . . . . F.2 Novel Federated Version . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . F.3 Illustration: Analyzing pFedMe with Federated Surrogate Optimization . . . . . G Convergence Proofs G.1 Client-Server Setting . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . G.2 Fully Decentralized Setting . . . . . . . . . . . . . . . . . . . . . . . . . . . . G.3 Supporting Lemmas . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . H Distributed Surrogate Optimization with Black-Box Solver H.1 Supporting Lemmas . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . H.2 Proof of Theorem H.1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . H.3 Proof of Theorem H.1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . I Details on Experimental Setup I.1 Datasets and Models . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . I.2 Implementation Details . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . J Additional Experimental Results J.1 Fully Decentralized Federated Expectation-Maximization . . . . . . . . . . . . J.2 Comparison with MOCHA . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . J.3 Generalization to Unseen Clients . . . . . . . . . . . . . . . . . . . . . . . . . J.4 FedEM and Clustering . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . J.5 Effect of M in Time-Constrained Setting . . . . . . . . . . . . . . . . . . . . . J.6 Additional Results under Client Sampling . . . . . . . . . . . . . . . . . . . . . J.7 Convergence Plots . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head></head><label></label><figDesc>)Alg. 2 is a detailed version of Alg. 1 (FedEM), with local SGD used as local solver.Alg. 3 gives our general algorithm for federated surrogate optimization, from which Alg. 2 is derived. R d for 1 ≤ m ≤ M ; for tasks t = 1, . . . , T in parallel over T clients do</figDesc><table><row><cell>D Detailed Algorithms</cell></row><row><cell>D.1 Client-Server Algorithm</cell></row><row><cell>Algorithm 2: FedEM: Federated Expectation-Maximization</cell></row><row><cell>Input : Data S 1:T ; number of mixture components M ; number of communication rounds K;</cell></row><row><cell>number of local steps J</cell></row><row><cell>Output :θ K m for 1 ∈ [M ]; π K t for t ∈ [T ]</cell></row><row><cell>// Initialization</cell></row><row><cell>server randomly initialize θ 0 m ∈ Randomly initialize π 0 t ∈ ∆ M ;</cell></row><row><cell>// Main loop</cell></row><row><cell>for iterations k = 1, . . . , K do</cell></row><row><cell>server broadcasts θ k-1</cell></row></table><note><p>m , 1 ≤ m ≤ M to the T clients; for tasks t = 1, . . . , T in parallel over T clients do for component m = 1, . . . , M do // E-step 8 for sample i = 1, . . . , n t do 9</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head></head><label></label><figDesc>Alg. 4 shows D-FedEM, the fully decentralization version of our federated expectation maximization algorithm.Alg. 5 gives our general fully decentralized algorithm for federated surrogate optimization, from which Alg. 4 is derived. Algorithm 4: D-FedEM: Fully Decentralized Federated Expectation-Maximization Input : Data S 1:T ; number of mixture components M ; number of iterations K; number of local steps J; mixing matrix distributions W k for k ∈ [K] Output : θ K m,t for m ∈ [M ] and t ∈ [T ]; π t for t ∈ [T ] // Initialization for tasks t = 1, . . . , T in parallel over T clients do Randomly initialize Θ t = (θ m,t ) 1≤m≤M ∈ R M ×d ; Randomly initialize π 0 t ∈ ∆ M ; // Main loop for iterations k = 1, . . . , K do // Select the communication topology and the aggregation weights</figDesc><table><row><cell>D.2 Fully Decentralized Algorithm</cell></row><row><cell>return Θ;</cell></row></table><note><p><p><p><p><p><p>1,j </p>);</p>Sample W k-1 ∼ W k-1 ;</p>for tasks t = 1, . . . , T in parallel over T clients do for component m = 1, . . . , M do // E-step</p>8</p>for sample i = 1, . . . , n t do 9</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head></head><label></label><figDesc>Assumption 4 . The objective function f is bounded below by f * ∈ R. Assumption 5 . (Smoothness) For all t ∈ [T ] and k &gt; 0, g k t is L-smooth wrt to u. Assumption 6 . (Unbiased gradients and bounded variance) Each client t ∈ [T ] can sample a random batch ξ from S t and compute an unbiased estimator ∇ u g k t (u, v; ξ) of the local gradient with bounded variance, i.e., E ξ</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head></head><label></label><figDesc>{u,v} , is a partial first-order surrogate of f t near {u, v}, it follows that</figDesc><table><row><cell>T</cell><cell>ω t • ∇ u g t {u,v}</cell><cell>(u, v)</cell><cell>2</cell><cell>≤ G 2 + β 2</cell><cell>T</cell><cell>ω t • ∇ u g t {u,v}</cell><cell>(u, v)</cell><cell>2</cell><cell>.</cell><cell>(332)</cell></row><row><cell>t=1</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>t=1</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>{u,v} t Since g</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>T</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>t=1</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head></head><label></label><figDesc>1. Sample weightπ t ∼ Dir (α) , t ∈ [T ] from a symmetric Dirichlet distribution of parameter α ∈ R + 2. Sample θ m ∈ R d ∼ U [-1, 1] d , m ∈ [M ] for uniform distribution over [-1, 1]</figDesc><table /><note><p>d . 3. Sample m t , t ∈ [T ] from a log-normal distribution with mean 4 and sigma 2, then set n t = min (50 + m t , 1000). 4. For t ∈ [T ] and i ∈ [n t ], draw x (i) t ∼ U [-1, 1] d and (i) t ∼ N (0, I d ). 5. For t ∈ [T ] and i ∈ [n t ], draw z (i) t ∼ M (π t ).</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 7 :</head><label>7</label><figDesc>Test and train accuracy comparison across different tasks. For each method, the best test accuracy is reported. For FedEM we run only K M rounds, where K is the total number of rounds for other methods-K = 80 for Shakespeare and K = 200 for all other datasets-and M = 3 is the number of components used in FedEM.</figDesc><table><row><cell>Dataset</cell><cell>Local</cell><cell>FedAvg [47]</cell><cell>FedProx [38]</cell><cell>FedAvg+ [27]</cell><cell>Clustered FL [56]</cell><cell>pFedMe [16]</cell><cell>FedEM (Ours)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 8 :</head><label>8</label><figDesc>Test accuracy under 20% client sampling: average across clients with +/-standard deviation over 3 independent runs. All experiments with 1200 communication rounds. ± 0.14 77.7 ± 0.16 77.8 ± 0.07 78.2 ± 0.27 82.1 ± 0.13 CIFAR100 [33] 40.6 ± 0.17 39.7 ± 0.75 39.9 ± 0.08 40.3 ± 0.71 43.2 ± 0.23 Synthetic 68.2 ± 0.02 69.0 ± 0.03 69.1 ± 0.03 69.1 ± 0.04 74.7 ± 0.01</figDesc><table><row><cell>Dataset</cell><cell>FedAvg [47]</cell><cell>FedAvg+ [27]</cell><cell>pFedMe [16]</cell><cell>APFL [14]</cell><cell>FedEM (Ours)</cell></row><row><cell>CIFAR10 [33]</cell><cell>73.1</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>In the case of (multi-output) regression, we have ht : X → R d for some d ≥ 1 and l : R d × R d → R + .</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>We note that whether the conjecture in<ref type="bibr" target="#b3">[4]</ref> holds in the agnostic case is still an open problem.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2"><p>A possible way to ensure that Assumption 2 holds is to use the batch normalization technique from<ref type="bibr" target="#b39">[40]</ref> to account for feature shift.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3"><p>As the distribution DT over tasks in Proposition 2.1 is arbitrary, any positively weighted sum of clients' empirical losses could be considered.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_4"><p>For training, we sub-sampled 10% and 15% from EMNIST and FEMNIST datasets respectively.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_5"><p>Note that when Θ is a full rank matrix, this decomposition is unique.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_6"><p>The notion of τ -slow decreasing sequence is defined in [31,Defintion 2].</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8" xml:id="foot_7"><p>As shown by<ref type="bibr" target="#b65">[66,</ref> Theorem. 2], the convergence is guaranteed in two scenarios: 1) G 2 = 0, 2) All clients use take the same number of local steps using the same local solver. Note that we allow each client to use an arbitrary approximate local solver.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="9" xml:id="foot_8"><p>https://github.com/gingsmith/fmtl</p></note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Theorem 3.3 then follows immediately from Theorem 3.3 , once we verify that g k t 1≤t≤T satisfy the assumptions of Theorem 3.3 . Assumption 4 , Assumption 6 , and Assumption 7 follow directly from Assumption 4, Assumption 6, and Assumption 7, respectively. Lemma G. <ref type="bibr" target="#b2">3</ref> shows that for k &gt; 0, g k is smooth w.r.t. Θ and then Assumption 5 is satisfied. Finally, Lemmas G.4-G.6 show that for t ∈ [T ] g k t is a partial first-order surrogate of f t near Θ k-1 t , π t with d V (•, •) = KL(• •).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>G.3 Supporting Lemmas</head><p>Lemma G.11. Consider J ≥ 2 and positive real numbers η j , j = 0, . . . , J -1, then:</p><p>Proof. For the first inequality,</p><p>For the second inequality</p><p>For the third inequality,</p><p>Lemma G.12. Suppose that g is a partial first-order surrogate of f , and that g is L-smooth, where L is the constant appearing in Definition 1, then f is 2L-smooth.</p><p>Proof. The difference between f and g is L-smooth, and g is L-smooth, thus f is 2L-smooth as the sum of two L-smooth functions.</p><p>Lemma G. <ref type="bibr" target="#b12">13</ref>. Consider f = T t=1 ω t • f t , for weights ω ∈ ∆ T . Suppose that for all (u, v) ∈ R du × V, and t ∈ [T ], f t admits a partial first-order surrogate g {u,v} t near {u, v}, and that g {u,v} = T t=1 ω t • g {u,v} t verifies Assumption 7 for t ∈ [T ]. Then f also verifies Assumption 7 .</p><p>Writing the gradient of Eq. (337), we have</p><p>Multiplying by ω t and summing for t ∈ [T ], we have</p><p>Thus,</p><p>where (344) follows from a</p><p>The proof of the last inequality is similar, it leverages a + b 2 ≤ 2 a 2 + 2 a 2 to upper bound (343).</p><p>then H is a semi-definite negative matrix.</p><p>Proof.</p><p>We have:</p><p>H Distributed Surrogate Optimization with Black-Box Solver</p><p>In this section, we cover the scenario where the local SGD solver used in our algorithms (Alg. 3 and Alg. 5) is replaced by a (possibly non-iterative) black-box solver that is guaranteed to provide a local inexact solution of ∀m ∈ [M ], minimize</p><p>with the following approximation guarantee. Assumption 9 (Local α-approximate solution). There exists 0 &lt; α &lt; 1 such that for t</p><p>where</p><p>t ), θ k m,t is the output of the local solver at client t and θ k-1 m is its starting point (see Alg. 2).</p><p>We further assume strong convexity.</p><p>Assumption 9 is equivalent to the γ-inexact solution used in <ref type="bibr" target="#b36">[37]</ref> (Lemma. H.2), when local functions (Φ t ) 1≤t≤T are assumed to be convex. We also need to have G 2 = 0 in Assumption 7 as in <ref type="bibr" target="#b37">[38,</ref><ref type="bibr">Definition 3]</ref>, in order to ensure the convergence of Alg. 2 and Alg. 4 to a stationary point of f , as shown by <ref type="bibr" target="#b65">[66,</ref><ref type="bibr">Theorem. 2</ref>]. 8  Theorem H.1. Suppose that Assumptions 1-7, 9 and 10 hold with G 2 = 0 and α &lt; 1 β 2 κ 4 , then the updates of federated surrogate optimization converge to a stationary point of f , i.e.,</p><p>and</p><p>As in App. G, we provide the analysis for the general case of federated surrogate optimization (Alg. 3) before showing that FedEM (Alg. 2) is a particular case.</p><p>We suppose that, at iteration k &gt; 0, the partial first-order surrogate functions g k t , t ∈ [T ] used in Alg. 3 verifies, in addition to Assumptions 4 -7 , the following assumptions that generalize Assumptions 9 and 10, Assumption 9 (Local α-inexact solution). There exists 0 &lt; α &lt; 1 such that for t ∈ [T ] and k &gt; 0,</p><p>where u k t, * ∈ arg min u∈R du g k t u, v k t . Assumption 10 . For t ∈ [T ] and k &gt; 0, g k t is µ-strongly convex in u.</p><p>Under these assumptions a parallel result to Theorem. H.1 holds.</p><p>Theorem H.1 . Suppose that Assumptions 4 -7 , Assumptions 9 and 10 hold with G 2 = 0 and α &lt; 1 β 2 κ 4 , then the updates of federated surrogate optimization converges to a stationary point of f , i.e., lim</p><p>and</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>H.1 Supporting Lemmas</head><p>First, we prove the following result. Lemma H.2. Under Assumptions 5 , 9 and 10 , the iterates of Alg. 2 verify for k &gt; 0 and t</p><p>where κ = L/µ.</p><p>), we have using Assumption 9 ,</p><p>thus,</p><p>Combining Eq. (367) and Eq. (369), we have</p><p>Lemma H.3. Suppose that Assumptions 5 , 7 , 9 and 10 hold with G 2 = 0. Then,</p><p>where α = β 2 κ 4 α, and</p><p>where the last inequality is a result of Lemma H.2. Using Jensen inequality, we have</p><p>Using Assumption 7 and Jensen inequality with the " √ •" function, it follows that</p><p>Since g k is L-smooth in u as a convex combination of L-smooth function, we have</p><p>Using Polyak-Lojasiewicz (PL), we have</p><p>(384) Using the L-smoothness of g k in u, we have</p><p>Thus,</p><p>Thus,</p><p>= 0 and that r k t is non-negative and L-smooth in u. Lemma H.4. Suppose that Assumptions 4 and 5 hold and that</p><p>then</p><p>If we moreover suppose that Assumption 10 holds and that there exists 0 &lt; α &lt; 1 such that for all k &gt; 0,</p><p>where</p><p>It follows that the sequence f u k , v k k≥0 is a non-increasing sequence. Since f is bounded below (Assum. 4 ), it follows that f u k , v k k≥0 is convergent. Denote by f ∞ its limit. The sequence</p><p>Proof of Eq. 390 Using the fact that</p><p>Thus,</p><p>By summing over k then passing to the limit when k → +∞, we have</p><p>Proof of Eq. 391 Because the L-smoothness of u → r k u, v k 1:T , we have</p><p>Thus,</p><p>because r k is a non-negative function (Definition 1). Finally, using Eq. (390), it follows that</p><p>Proof of Eq. 393 We suppose now that there exists 0 &lt; α &lt; 1 such that</p><p>It follows that,</p><p>then,</p><p>and by using the definition of g k we have,</p><p>Since</p><p>From Eq. (406) and Eq. ( <ref type="formula">407</ref>), it follows that,</p><p>Finally, since</p><p>Since g k is µ-strongly convex in u (Assumption 10), we write</p><p>It follows that, </p><p>and,</p><p>Proof.</p><p>(414) Computing the gradient norm, we have,</p><p>Since g k is L-smooth in u, we write</p><p>Thus by replacing Eq. (418) in Eq. ( <ref type="formula">416</ref>), we have</p><p>Using Lemma H.3, there exists 0 &lt; α &lt; 1, such that</p><p>Thus, the conditions of Lemma H.4 hold, and we can use Eq. ( <ref type="formula">391</ref>) and (393), i.e.</p><p>Finally, combining this with Eq. (419), we get the final result </p><p>and,</p><p>Proof. We prove this result as a particular case of Theorem H.1 . To this purpose, we consider that V ∆ M , u = Θ ∈ R dM , v t = π t , and ω t = n t /n for t ∈ [T ]. For k &gt; 0, we define g k t as follow,</p><p>where c is the same constant appearing in Assumption 3, Eq. ( <ref type="formula">3</ref>). With this definition, it is easy to check that the federated surrogate optimization algorithm (Alg. 3) reduces to FedEM (Alg. 2). Theorem H.1 then follows immediately from Theorem H.1 , once we verify that g k t 1≤t≤T satisfy the assumptions of Theorem H.1 . Assumption 4 , Assumption 6 , Assumption 7 , Assumption 9 and Assumption 10 follow directly from Assumption 4, Assumption 6, Assumption 7, Assumption 9 and Assumption 10, respectively. Lemma G.3 shows that for k &gt; 0, g k is smooth w.r.t. Θ and then Assumption 5 is satisfied. Finally, Lemmas G.4-G.6 show that for t ∈ [T ] g k t is a partial first-order surrogate of </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Dataset</head><p>GPU Simulation time Shakespeare <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b46">47]</ref> Quadro RTX 8000 4h42min FEMNIST <ref type="bibr" target="#b6">[7]</ref> Quadro RTX 8000 1h14min EMNIST <ref type="bibr" target="#b7">[8]</ref> GeForce GTX 1080 Ti 46min CIFAR10 <ref type="bibr" target="#b32">[33]</ref> GeForce GTX 1080 Ti 2h37min CIFAR100 <ref type="bibr" target="#b32">[33]</ref> GeForce GTX 1080 Ti 3h9min Synthetic GeForce GTX 1080 Ti 20min</p><p>Table <ref type="table">5</ref>: Learning rates η used for the experiments in Table <ref type="table">2</ref>. Base-10 logarithms are reported.</p><p>Dataset FedAvg <ref type="bibr" target="#b46">[47]</ref> FedProx <ref type="bibr" target="#b37">[38]</ref> FedAvg+ <ref type="bibr" target="#b26">[27]</ref> Clustered FL <ref type="bibr" target="#b55">[56]</ref> pFedMe <ref type="bibr" target="#b15">[16]</ref> FedEM (Ours)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I.2 Implementation Details</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I.2.1 Machines</head><p>We ran the experiments on a CPU/GPU cluster, with different GPUs available (e.g., Nvidia Tesla V100, GeForce GTX 1080 Ti, Titan X, Quadro RTX 6000, and Quadro RTX 8000). Most experiments with CIFAR10/CIFAR-100 and EMNIST were run on GeForce GTX 1080 Ti cards, while most experiments with Shakespeare and FEMNIST were run on the Quadro RTX 8000 cards. For each dataset, we ran around 30 experiments (not counting the development/debugging time). Table <ref type="table">4</ref> gives the average amount of time needed to run one simulation for each dataset. The time needed per simulation was extremely long for Shakespeare dataset, because we used a batch size of 128.</p><p>We remarked that increasing the batch size beyond 128 caused the model to converge to poor local minima, where the model keeps predicting a white space as next character.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I.2.2 Libraries</head><p>We used PyTorch <ref type="bibr" target="#b52">[53]</ref> to build and train our models. We also used Torchvision <ref type="bibr" target="#b44">[45]</ref> implementation of MobileNet-v2 <ref type="bibr" target="#b54">[55]</ref>, and for image datasets preprossessing. We used LEAF <ref type="bibr" target="#b6">[7]</ref> to build FEMNIST dataset and the federated version of Shakespeare dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I.2.3 Hyperparameters</head><p>For each method and each task, the learning rate was set via grid search on the set 10 -0.5 , 10 -1 , 10 -1.5 , 10 -2 , 10 -2.5 , 10 -3 . FedProx and pFedMe's penalization parameter µ was tuned via grid search on 10 1 , 10 0 , 10 -1 , 10 -2 , 10 -3 . For Clustered FL, we used the same values of tolerance as the ones used in its official implementation <ref type="bibr" target="#b55">[56]</ref>. We found tuning tol 1 and tol 2 particularly hard: no empirical rule is provided in <ref type="bibr" target="#b55">[56]</ref>, and the few random setting we tried did not show any improvement in comparison to the default ones. For each dataset and each method, Table <ref type="table">5</ref> reports the learning rate η that achieved the corresponding result in Table <ref type="table">2</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>J Additional Experimental Results</head><p>J.1 Fully Decentralized Federated Expectation-Maximization D-FedEM considers the scenario where clients communicate directly in a peer-to-peer fashion instead of relying on the central server mediation. In order to simulate D-FedEM, we consider a binomial Erdős-Rényi graph <ref type="bibr" target="#b17">[18]</ref> with parameter p = 0.5, and we set the mixing weight using Fast Mixing Markov Chain <ref type="bibr" target="#b4">[5]</ref> rule. We report the result of this experiment in Table <ref type="table">6</ref>, showing the average weighted accuracy with weight proportional to local dataset sizes. We observe that D-FedEM often performs better than other FL approaches and slightly worst than FedEM, except on CIFAR-10 where it has low performances.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>J.2 Comparison with MOCHA</head><p>In the case of synthetic dataset, for which train a linear model, we compare FedEM with MOCHA <ref type="bibr" target="#b58">[59]</ref>. We implemented MOCHA in Python following the official implementation 9 in MATLAB. We tuned the parameter λ of MOCHA on a holdout validation set via grid search in {10 1 , 10 0 , 10 -1 , 10 -2 , 10 -3 }, and we found that the optimal value of λ is 10 0 . For this value, we ran MOCHA on the synthetic dataset with three different seeds, and we found that the average accuracy is 73.4 ± 0.05 in comparison to 74.7 ± 0.01 achieved by FedEM. Note that MOCHA is the second best method after FedEM on this dataset. Unfortunately, MOCHA only works for linear models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>J.3 Generalization to Unseen Clients</head><p>Table <ref type="table">3</ref> shows that FedEM allows new clients to learn a personalized model at least as good as FedAvg's global one and always better than FedAvg+'s one. Unexpectedly, new clients achieve sometimes a significantly higher test accuracy than old clients (e.g., 47.5% against 44.1% on CIFAR100).</p><p>In order to better understand this difference, we looked at the distribution of FedEM personalized weights for the old clients and new ones. The average distribution entropy equals 0.27 and 0.92 for old and new clients, respectively. This difference shows that old clients tend to have more skewed distributions, suggesting that some components may be overfitting the local training dataset leading the old clients to give them a high weight.</p><p>We also considered a setting where unseen clients progressively collect their own dataset. We investigate the effect of the number of samples on the average test accuracy across unseen clients, starting from no local data (and therefore using uniform weights to mix the M components) and progressively adding more labeled examples until the full local labeled training set is assumed to be available. Figure <ref type="figure">2</ref> shows that FedEM achieves a significant level of personalization as soon as clients collect a labeled dataset whose size is about 20% of what the original clients used for training.</p><p>As we mentioned in the main text, it is not clear how the other personalized FL algorithms (e.g., pFedMe and Clustered FL) should be extended to handle unseen clients. For example, the global model learned by pFedMe during training can then be used to perform some "fine-tuning" at the new clients, but how exactly? The original pFedMe paper <ref type="bibr" target="#b15">[16]</ref> does not even mention this issue. For example, the client could use the global model as initial vector for some local SGD steps (similarly to what done in FedAvg+ or the MAML approaches) or it could perform a local pFedMe update (lines 6-9 in [16, Alg. 1]). The problem is even more complex for Clustered FL (and again not discussed in <ref type="bibr" target="#b55">[56]</ref>). The new client should be assigned to one of the clusters identified. One can think to compute the cosine distances of the new client from those who participated in training, but this would require the server to maintain not only the model learned, but also the last-iteration gradients of all clients that participated in the training. Moreover, it is not clear which metric should be considered to assign the new client to a given cluster (perhaps the average cosine similarity from all clients in the cluster?). This is an arbitrary choice as <ref type="bibr" target="#b55">[56]</ref> does not provide a criterion to assign clients to a cluster, but only to decide if a given cluster should be split in two new ones. It appears that many options are possible and they deserve separate investigation. Despite these considerations, we performed an additional experiment extending pFedMe to unseen clients as described in the second option above on CIFAR-100 dataset with a sampling rate of 20%. pFedMe achieves a test accuracy of 40.5% ± 1.66%, in comparison to 38.9% ± 0.97% for FedAvg and 42.7% ± 0.33% for FedEM. FedEM thus performs better on unseen clients, and pFedMe's accuracy shows a much larger variability.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>J.4 FedEM and Clustering</head><p>We performed additional experiments with synthetic datasets to check if FedEM recovers clusters in practice. We modified the synthetic dataset generation so that the mixture weight vector π t of each client t has a single entry equal to 1 that is selected uniformly at random. We consider two scenarios both with T = 300 client, the first with M = 2 component and the second with M = 3 components. In both cases FedEM recovered almost the correct Π * and Θ * : we have cosine_distance Θ * , Θ ≤ 10 -2 and cosine_distance Π * , Π ≤ 10 -8 . A simple clustering algorithm that assigns each client to the component with the largest mixture weight achieves 100% accuracy, i.e., it partitions the clients in sets coinciding with the original clusters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>J.5 Effect of M in Time-Constrained Setting</head><p>Recall that in FedEM, each client needs to update and transmit M components at each round, requiring roughly M times more computation and M times larger messages than the competitors in our study.</p><p>In this experiment, we considered a challenging time-constrained setting, where FedEM is limited to run one third (= 1/M ) of the rounds of the other methods. The results in Table <ref type="table">7</ref> show that even if FedEM does not reach its maximum accuracy, it still outperforms the other methods on 3 datasets.</p><p>We additionally compared FedEM with a model having the same number of parameters in order to check if FedEM's advantage comes from the additional model parameters rather than by its specific formulation. To this purpose, we trained Resnet-18 and Resnet-34 on CIFAR10. The first one has about 3 times more parameters than MobileNet-v2 and then roughly as many parameters as FedEM with M = 3. The second one has about 6 times more parameters than FedEM with M = 3. We </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Debiasing Model Updates for Improving Personalized Federated Training</title>
		<author>
			<persName><forename type="first">Durmus</forename><surname>Alp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Emre</forename><surname>Acar</surname></persName>
		</author>
		<ptr target="https://proceedings.mlr.press/v139/acar21a.html" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 38th International Conference on Machine Learning</title>
		<editor>
			<persName><forename type="first">Marina</forename><surname>Meila</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Tong</forename><surname>Zhang</surname></persName>
		</editor>
		<meeting>the 38th International Conference on Machine Learning</meeting>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2021-07">July 2021</date>
			<biblScope unit="volume">139</biblScope>
			<biblScope unit="page" from="21" to="31" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A Framework for Learning Predictive Structures from Multiple Tasks and Unlabeled Data</title>
		<author>
			<persName><forename type="first">Rie</forename><surname>Kubota</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ando</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Tong</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">61</biblScope>
			<biblScope unit="page" from="1817" to="1853" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Personalized and Private Peer-to-Peer Machine Learning</title>
		<author>
			<persName><forename type="first">Aurélien</forename><surname>Bellet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rachid</forename><surname>Guerraoui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mahsa</forename><surname>Taziki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marc</forename><surname>Tommasi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AISTATS</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Does Unlabeled Data Provably Help? Worst-case Analysis of the Sample Complexity of Semi-Supervised Learning</title>
		<author>
			<persName><forename type="first">Shai</forename><surname>Ben-David</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tyler</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Pál</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008">2008</date>
			<publisher>COLT</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Fastest Mixing Markov Chain on A Graph</title>
		<author>
			<persName><forename type="first">Stephen</forename><surname>Boyd</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Persi</forename><surname>Diaconis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lin</forename><surname>Xiao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM REVIEW</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="page" from="667" to="689" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Convex Optimization: Algorithms and Complexity</title>
		<author>
			<persName><forename type="first">Sébastien</forename><surname>Bubeck</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1405.4980</idno>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note>math.OC</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Leaf: A benchmark for federated settings</title>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Caldas</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1812.01097</idno>
	</analytic>
	<monogr>
		<title level="m">International Workshop on Federated Learning for Data Privacy and Confidentiality (in conjunction with NeurIPS 2019)</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>Presented at the 2nd</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">EMNIST: Extending MNIST to handwritten letters</title>
		<author>
			<persName><forename type="first">Gregory</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Saeed</forename><surname>Afshar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Tapson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andre</forename><surname>Van Schaik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 International Joint Conference on Neural Networks (IJCNN). IEEE</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="2921" to="2926" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Variational Federated Multi-Task Learning</title>
		<author>
			<persName><forename type="first">Luca</forename><surname>Corinzia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joachim</forename><forename type="middle">M</forename><surname>Buhmann</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1906.06268[cs.LG</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Learning Bounds for Importance Weighting</title>
		<author>
			<persName><forename type="first">Corinna</forename><surname>Cortes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yishay</forename><surname>Mansour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mehryar</forename><surname>Mohri</surname></persName>
		</author>
		<ptr target="https://proceedings.neurips.cc/paper/2010/file/59c33016884a62116be975a9bb8257e3-Paper.pdf" />
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>
			<persName><forename type="first">J</forename><surname>Lafferty</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Williams</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Shawe-Taylor</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Zemel</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Culotta</surname></persName>
		</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="volume">23</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Sample Selection Bias Correction Theory</title>
		<author>
			<persName><forename type="first">Corinna</forename><surname>Cortes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mehryar</forename><surname>Mohri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Riley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Afshin</forename><surname>Rostamizadeh</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008">2008</date>
			<publisher>ALT</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Privacy Amplification by Decentralization</title>
		<author>
			<persName><forename type="first">Edwige</forename><surname>Cyffers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aurélien</forename><surname>Bellet</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2012.05326[cs.LG</idno>
	</analytic>
	<monogr>
		<title level="m">Presented at the Privacy Preserving Machine Learning workshop (in conjunction with NeurIPS 2020)</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Unlabeled Data Does Provably Help</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">U</forename><surname>Malte Darnstädt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Balázs</forename><surname>Simon</surname></persName>
		</author>
		<author>
			<persName><surname>Szörényi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">STACS</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Adaptive Personalized Federated Learning</title>
		<author>
			<persName><forename type="first">Yuyang</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohammad</forename><surname>Mahdi Kamani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mehrdad</forename><surname>Mahdavi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2003.13461</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Federated Expectation Maximization with heterogeneity mitigation and variance reduction</title>
		<author>
			<persName><forename type="first">Aymeric</forename><surname>Dieuleveut</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gersende</forename><surname>Fort</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><surname>Moulines</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Geneviève</forename><surname>Robin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Personalized Federated Learning with Moreau Envelopes</title>
		<author>
			<persName><surname>Canh T Dinh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tuan</forename><forename type="middle">Dung</forename><surname>Nguyen H Tran</surname></persName>
		</author>
		<author>
			<persName><surname>Nguyen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">34th Conference on Neural Information Processing Systems</title>
		<meeting><address><addrLine>NeurIPS</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">FedU: A Unified Framework for Federated Multi-Task Learning with Laplacian Regularization</title>
		<author>
			<persName><surname>Canh T Dinh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Tung</surname></persName>
		</author>
		<author>
			<persName><surname>Vu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Minh</forename><forename type="middle">N</forename><surname>Nguyen H Tran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongyu</forename><surname>Dao</surname></persName>
		</author>
		<author>
			<persName><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2102.07148</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">On Random Graphs I</title>
		<author>
			<persName><forename type="first">P</forename><surname>Erdös</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rényi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Publicationes Mathematicae Debrecen</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">290</biblScope>
			<date type="published" when="1959">1959</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Personalized federated learning: A meta-learning approach</title>
		<author>
			<persName><forename type="first">Alireza</forename><surname>Fallah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aryan</forename><surname>Mokhtari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Asuman</forename><surname>Ozdaglar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">34th Conference on Neural Information Processing Systems</title>
		<meeting><address><addrLine>NeurIPS</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">An Efficient Framework for Clustered Federated Learning</title>
		<author>
			<persName><forename type="first">Avishek</forename><surname>Ghosh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jichan</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dong</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kannan</forename><surname>Ramchandran</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
			<publisher>NeurIPS</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">When can unlabeled data improve the learning rate?</title>
		<author>
			<persName><forename type="first">Christina</forename><surname>Göpfert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shai</forename><surname>Ben-David</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Olivier</forename><surname>Bousquet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sylvain</forename><surname>Gelly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Tolstikhin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruth</forename><surname>Urner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Learning Theory</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1500" to="1518" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Federated Learning with Compression: Unified Analysis and Sharp Guarantees</title>
		<author>
			<persName><forename type="first">Farzin</forename><surname>Haddadpour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohammad</forename><surname>Mahdi Kamani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aryan</forename><surname>Mokhtari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mehrdad</forename><surname>Mahdavi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Lower bounds and optimal algorithms for personalized federated learning</title>
		<author>
			<persName><forename type="first">Filip</forename><surname>Hanzely</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Slavomıér</forename><surname>Hanzely</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Samuel</forename><surname>Horváth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Richtárik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">34th Conference on Neural Information Processing Systems</title>
		<meeting><address><addrLine>NeurIPS</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Federated Learning of a Mixture of Global and Local Models</title>
		<author>
			<persName><forename type="first">Filip</forename><surname>Hanzely</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Richtárik</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2002.05516[cs.LG</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Long Short-Term Memory</title>
		<author>
			<persName><forename type="first">Sepp</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jürgen</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural Computation 9</title>
		<imprint>
			<date type="published" when="1997">1997</date>
			<biblScope unit="page" from="1735" to="1780" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Personalized cross-silo federated learning on non-iid data</title>
		<author>
			<persName><forename type="first">Yutao</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="7865" to="7873" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Improving federated learning personalization via model agnostic meta learning</title>
		<author>
			<persName><forename type="first">Yihan</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jakub</forename><surname>Konečný</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Keith</forename><surname>Rush</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sreeram</forename><surname>Kannan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1909.12488</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>Presented at NeurIPS FL workshop 2019</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Advances and Open Problems in Federated Learning</title>
		<author>
			<persName><forename type="first">Peter</forename><surname>Kairouz</surname></persName>
		</author>
		<idno type="DOI">10.1561/2200000083</idno>
		<ptr target="http://dx.doi.org/10.1561/2200000083" />
	</analytic>
	<monogr>
		<title level="j">Foundations and Trends® in Machine Learning</title>
		<idno type="ISSN">1935-8237</idno>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">1-2</biblScope>
			<biblScope unit="page" from="1" to="210" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">SCAFFOLD: Stochastic controlled averaging for federated learning</title>
		<author>
			<persName><forename type="first">Praneeth</forename><surname>Sai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Satyen</forename><surname>Karimireddy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mehryar</forename><surname>Kale</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sashank</forename><surname>Mohri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Reddi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ananda</forename><surname>Stich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Suresh</forename><surname>Theertha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="5132" to="5143" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Adaptive gradient-based meta-learning methods</title>
		<author>
			<persName><forename type="first">Mikhail</forename><surname>Khodak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maria-Florina F</forename><surname>Balcan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ameet</forename><forename type="middle">S</forename><surname>Talwalkar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="5917" to="5928" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">A Unified Theory of Decentralized SGD with Changing Topology and Local Updates</title>
		<author>
			<persName><forename type="first">Anastasia</forename><surname>Koloskova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Loizou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sadra</forename><surname>Boreiri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Jaggi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Stich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Federated learning: Strategies for improving communication efficiency</title>
		<author>
			<persName><forename type="first">Jakub</forename><surname>Konečný</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brendan</forename><surname>Mcmahan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Felix</forename><forename type="middle">X</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Richtárik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ananda</forename><surname>Theertha Suresh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dave</forename><surname>Bacon</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1610.05492</idno>
	</analytic>
	<monogr>
		<title level="m">NIPS 2016 Workshop on Private Multi-Party Machine Learning</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Learning multiple layers of features from tiny images</title>
		<author>
			<persName><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
	<note type="report_type">MSc thesis</note>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Optimization Transfer Using Surrogate Objective Functions</title>
		<author>
			<persName><forename type="first">Kenneth</forename><surname>Lange</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">R</forename><surname>Hunter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilsoon</forename><surname>Yang</surname></persName>
		</author>
		<ptr target="http://www.jstor.org/stable/1390605" />
	</analytic>
	<monogr>
		<title level="j">Journal of Computational and Graphical Statistics</title>
		<idno type="ISSN">10618600</idno>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="20" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Graphical models. English</title>
		<author>
			<persName><forename type="first">L</forename><surname>Steffen</surname></persName>
		</author>
		<author>
			<persName><surname>Lauritzen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">Oxford Statistical Science Series</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<date type="published" when="1996">1996</date>
			<publisher>Clarendon Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Ditto: Fair and robust federated learning through personalization</title>
		<author>
			<persName><forename type="first">Tian</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shengyuan</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ahmad</forename><surname>Beirami</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Virginia</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="6357" to="6368" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Federated learning: Challenges, methods, and future directions</title>
		<author>
			<persName><forename type="first">Tian</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anit</forename><surname>Kumar Sahu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ameet</forename><surname>Talwalkar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Virginia</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Signal Processing Magazine</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="50" to="60" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Federated Optimization in Heterogeneous Networks</title>
		<author>
			<persName><forename type="first">Tian</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anit</forename><surname>Kumar Sahu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Manzil</forename><surname>Zaheer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maziar</forename><surname>Sanjabi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ameet</forename><surname>Talwalkar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Virginia</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Third MLSys Conference</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Pachinko Allocation: DAG-Structured Mixture Models of Topic Correlations</title>
		<author>
			<persName><forename type="first">Wei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
		<idno type="DOI">10.1145/1143844.1143917</idno>
		<ptr target="https://doi.org/10.1145/1143844.1143917" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd International Conference on Machine Learning. ICML &apos;06</title>
		<meeting>the 23rd International Conference on Machine Learning. ICML &apos;06<address><addrLine>Pittsburgh, Pennsylvania, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="577" to="584" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">FedBN: Federated Learning on Non-IID Features via Local Batch Normalization</title>
		<author>
			<persName><forename type="first">Xiaoxiao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiang</forename><surname>Meirui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaofei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Kamp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qi</forename><surname>Dou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Can Decentralized Algorithms Outperform Centralized Algorithms? A Case Study for Decentralized Parallel Stochastic Gradient Descent</title>
		<author>
			<persName><forename type="first">Xiangru</forename><surname>Lian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ce</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Huan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cho-Jui</forename><surname>Hsieh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ji</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 31st International Conference on Neural Information Processing Systems. NIPS&apos;17</title>
		<meeting>the 31st International Conference on Neural Information Processing Systems. NIPS&apos;17<address><addrLine>Long Beach, California, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Curran Associates Inc</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="5336" to="5346" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Asynchronous Decentralized Parallel Stochastic Gradient Descent</title>
		<author>
			<persName><forename type="first">Xiangru</forename><surname>Lian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ce</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ji</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Optimization with first-order surrogate functions</title>
		<author>
			<persName><forename type="first">Julien</forename><surname>Mairal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="783" to="791" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">Three approaches for personalization with applications to federated learning</title>
		<author>
			<persName><forename type="first">Yishay</forename><surname>Mansour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mehryar</forename><surname>Mohri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jae</forename><surname>Ro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ananda</forename><surname>Theertha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Suresh</forename></persName>
		</author>
		<idno type="arXiv">arXiv:2002.10619</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Torchvision the Machine-Vision Package of Torch</title>
		<author>
			<persName><forename type="first">Sébastien</forename><surname>Marcel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yann</forename><surname>Rodriguez</surname></persName>
		</author>
		<idno type="DOI">10.1145/1873951.1874254</idno>
		<ptr target="https://doi.org/10.1145/1873951.1874254" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 18th ACM International Conference on Multimedia. MM &apos;10</title>
		<meeting>the 18th ACM International Conference on Multimedia. MM &apos;10<address><addrLine>Firenze, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="1485" to="1488" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Throughput-Optimal Topology Design for Cross-Silo Federated Learning</title>
		<author>
			<persName><forename type="first">Othmane</forename><surname>Marfoq</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chuan</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Giovanni</forename><surname>Neglia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Vidal</surname></persName>
		</author>
		<ptr target="https://proceedings" />
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>
			<persName><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Ranzato</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Hadsell</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><forename type="middle">F</forename><surname>Balcan</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Lin</surname></persName>
		</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="19478" to="19487" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Communication-efficient learning of deep networks from decentralized data</title>
		<author>
			<persName><forename type="first">Brendan</forename><surname>Mcmahan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eider</forename><surname>Moore</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Ramage</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Seth</forename><surname>Hampson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Blaise</forename><surname>Aguera Y Arcas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Artificial Intelligence and Statistics</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1273" to="1282" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Agnostic Federated Learning</title>
		<author>
			<persName><forename type="first">Mehryar</forename><surname>Mohri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gary</forename><surname>Sivek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ananda</forename><surname>Theertha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Suresh</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="4615" to="4625" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Network Topology and Communication-Computation Tradeoffs in Decentralized Optimization</title>
		<author>
			<persName><forename type="first">A</forename><surname>Nedić</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Olshevsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">G</forename><surname>Rabbat</surname></persName>
		</author>
		<idno type="DOI">10.1109/JPROC.2018.2817461</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE</title>
		<meeting>the IEEE</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">106</biblScope>
			<biblScope unit="page" from="953" to="976" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">The Role of Network Topology for Distributed Machine Learning</title>
		<author>
			<persName><forename type="first">Giovanni</forename><surname>Neglia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gianmarco</forename><surname>Calbi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Don</forename><surname>Towsley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gayane</forename><surname>Vardoyan</surname></persName>
		</author>
		<idno type="DOI">10.1109/INFOCOM.2019.8737602</idno>
	</analytic>
	<monogr>
		<title level="m">IEEE INFOCOM</title>
		<imprint>
			<date type="published" when="2019">2019. 2019</date>
			<biblScope unit="page" from="2350" to="2358" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Decentralized gradient methods: does topology matter?</title>
		<author>
			<persName><forename type="first">Giovanni</forename><surname>Neglia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chuan</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Don</forename><surname>Towsley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gianmarco</forename><surname>Calbi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AISTATS</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<author>
			<persName><forename type="first">Y</forename><surname>Nesterov</surname></persName>
		</author>
		<ptr target="http://gen.lib.rus.ec/book/index.php?md5=488d3c36f629a6e021fc011675df02ef" />
		<title level="m">Introductory Lectures on Convex Optimization: A Basic Course</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
	<note>1st ed. Applied Optimization</note>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">PyTorch: An Imperative Style, High-Performance Deep Learning Library</title>
		<author>
			<persName><forename type="first">Adam</forename><surname>Paszke</surname></persName>
		</author>
		<ptr target="http://papers.neurips.cc/paper/9015-pytorch-an-imperative-style-high-performance-deep-learning-library.pdf" />
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>
			<persName><forename type="first">H</forename><surname>Wallach</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Beygelzimer</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><surname>Alché-Buc</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">E</forename><surname>Fox</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Garnett</surname></persName>
		</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="8024" to="8035" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Adaptive Federated Optimization</title>
		<author>
			<persName><forename type="first">J</forename><surname>Sashank</surname></persName>
		</author>
		<author>
			<persName><surname>Reddi</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=LkFG3lB13U5" />
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Mobilenetv2: Inverted residuals and linear bottlenecks</title>
		<author>
			<persName><forename type="first">Mark</forename><surname>Sandler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Menglong</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrey</forename><surname>Zhmoginov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liang-Chieh</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="4510" to="4520" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Clustered Federated Learning: Model-Agnostic Distributed Multitask Optimization Under Privacy Constraints</title>
		<author>
			<persName><forename type="first">Felix</forename><surname>Sattler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Klaus-Robert</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wojciech</forename><surname>Samek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Transactions on Neural Networks and Learning Systems</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Personalized Federated Learning using Hypernetworks</title>
		<author>
			<persName><forename type="first">Aviv</forename><surname>Shamsian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aviv</forename><surname>Navon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ethan</forename><surname>Fetaya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gal</forename><surname>Chechik</surname></persName>
		</author>
		<ptr target="https://proceedings.mlr.press/v139/shamsian21a.html" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 38th International Conference on Machine Learning</title>
		<editor>
			<persName><forename type="first">Marina</forename><surname>Meila</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Tong</forename><surname>Zhang</surname></persName>
		</editor>
		<meeting>the 38th International Conference on Machine Learning</meeting>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2021-07">July 2021</date>
			<biblScope unit="volume">139</biblScope>
			<biblScope unit="page" from="9489" to="9502" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">An Investigation Into On-device Personalization of End-to-end Automatic Speech Recognition Models</title>
		<author>
			<persName><forename type="first">Khe</forename><surname>Chai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sim</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Petr</forename><surname>Zadrazil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Françoise</forename><surname>Beaufays</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">INTERSPEECH</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Federated Multi-Task Learning</title>
		<author>
			<persName><forename type="first">Virginia</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chao-Kai</forename><surname>Chiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maziar</forename><surname>Sanjabi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ameet</forename><surname>Talwalkar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 31st International Conference on Neural Information Processing Systems. NIPS&apos;17</title>
		<meeting>the 31st International Conference on Neural Information Processing Systems. NIPS&apos;17<address><addrLine>Long Beach, California, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Curran Associates Inc</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="4427" to="4437" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Local SGD Converges Fast and Communicates Little</title>
		<author>
			<persName><forename type="first">U</forename><surname>Sebastian</surname></persName>
		</author>
		<author>
			<persName><surname>Stich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Direct Importance Estimation with Model Selection and Its Application to Covariate Shift Adaptation</title>
		<author>
			<persName><forename type="first">Masashi</forename><surname>Sugiyama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shinichi</forename><surname>Nakajima</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hisashi</forename><surname>Kashima</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paul</forename><surname>Buenau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Motoaki</forename><surname>Kawanabe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">D 2 : Decentralized Training over Decentralized Data</title>
		<author>
			<persName><forename type="first">Hanlin</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiangru</forename><surname>Lian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ce</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ji</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Decentralized Collaborative Learning of Personalized Models over Networks</title>
		<author>
			<persName><forename type="first">Paul</forename><surname>Vanhaesebrouck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aurélien</forename><surname>Bellet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marc</forename><surname>Tommasi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AISTATS</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Weighted Emprirical Risk Minimization: Transfer Learning based on Importance Sampling</title>
		<author>
			<persName><forename type="first">Robin</forename><surname>Vogel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mastane</forename><surname>Achab</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stéphan</forename><surname>Clémençon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Charles</forename><surname>Tillier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ESANN</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Federated Learning with Matched Averaging</title>
		<author>
			<persName><forename type="first">Hongyi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mikhail</forename><surname>Yurochkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuekai</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dimitris</forename><surname>Papailiopoulos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yasaman</forename><surname>Khazaeni</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=BkluqlSFDS" />
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Tackling the objective inconsistency problem in heterogeneous federated optimization</title>
		<author>
			<persName><forename type="first">Jianyu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qinghua</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hao</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gauri</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Vincent Poor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">34th Conference on Neural Information Processing Systems</title>
		<meeting><address><addrLine>NeurIPS</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Fully Decentralized Joint Learning of Personalized Models and Collaboration Graphs</title>
		<author>
			<persName><forename type="first">Valentina</forename><surname>Zantedeschi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aurélien</forename><surname>Bellet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marc</forename><surname>Tommasi</surname></persName>
		</author>
		<ptr target="http://proceedings.mlr.press/v108/zantedeschi20a.html" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of Machine Learning Research</title>
		<editor>
			<persName><forename type="first">Silvia</forename><surname>Chiappa</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Roberto</forename><surname>Calandra</surname></persName>
		</editor>
		<meeting>Machine Learning Research</meeting>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2020-08">Aug. 2020</date>
			<biblScope unit="volume">108</biblScope>
			<biblScope unit="page" from="864" to="874" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Personalized Federated Learning with First Order Model Optimization</title>
		<author>
			<persName><forename type="first">Michael</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Karan</forename><surname>Sapra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sanja</forename><surname>Fidler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Serena</forename><surname>Yeung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jose</forename><forename type="middle">M</forename><surname>Alvarez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">A Convex Formulation for Learning Task Relationships in Multi-task Learning</title>
		<author>
			<persName><forename type="first">Yu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dit</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yeung</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th Conference on Uncertainty in Artificial Intelligence</title>
		<meeting>the 26th Conference on Uncertainty in Artificial Intelligence<address><addrLine>UAI</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010">2010. 2010</date>
			<biblScope unit="page">733</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Clustered Multi-Task Learning Via Alternating Structure Optimization</title>
		<author>
			<persName><forename type="first">Jiayu</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianhui</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jieping</forename><surname>Ye</surname></persName>
		</author>
		<ptr target="https://proceedings.neurips.cc/paper/2011/file/a516a87cfcaef229b342c437fe2b95f7-Paper.pdf" />
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>
			<persName><forename type="first">J</forename><surname>Shawe-Taylor</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Zemel</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><surname>Bartlett</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><surname>Pereira</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K</forename><forename type="middle">Q</forename><surname>Weinberger</surname></persName>
		</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="volume">24</biblScope>
		</imprint>
	</monogr>
	<note>7] 71.0 (99.2) 78.6 (79.5) 78.6 (79.6) 75.3 (86.0) 73.5 (74.3) 74.9 (91.9) 74.0 (80.9) EMNIST [8] 71.9 (99.9) 82.6 (86.5) 82.7 (86.6) 83.1 (93.5) 82.7 (86.6) 83.3 (91.1) 82.7 (89.4) CIFAR10 [33] 70.2 (99.9) 78.2 (96.8) 78.0 (96.7) 82.3 (98.9) 78.6 (96.8) 81.7 (99.8) 82.5 (92.2) CIFAR100 [33] 31.5 (99.9) 41.0 (78.5) 40.9 (78.6) 39.0 (76.7) 41.5 (78.9) 41.8 (99.6) 42.0 (72.9) Shakespeare [7] 32.0 (95.3) 46.7 (48.7) 45.7 (47.3) 40.0 (93.1) 46.6 (48.7) 41.2 (42.1) 43.8 (44.6) Synthetic 65.7 (91.0) 68.2 (68.7) 68.2 (68.7) 68.9 (71.0) 69.1 (85.1) 69.2 (72.8) 73.2 (74.7</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
