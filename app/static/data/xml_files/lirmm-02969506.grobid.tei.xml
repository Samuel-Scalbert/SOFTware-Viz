<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="fr">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Uma abordagem para coleta e análise de dados de configurações em redes neurais profundas</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Débora</forename><surname>Pina</surname></persName>
							<email>dbpina@cos.ufrj.br</email>
							<affiliation key="aff2">
								<orgName type="institution">Universidade Federal do Rio de Janeiro (PESC/COPPE/UFRJ)</orgName>
								<address>
									<country key="BR">Brasil</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Liliane</forename><surname>Kunstmann</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">Universidade Federal do Rio de Janeiro (PESC/COPPE/UFRJ)</orgName>
								<address>
									<country key="BR">Brasil</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Daniel</forename><surname>De Oliveira</surname></persName>
							<email>danielcmo@ic.uff.br</email>
							<affiliation key="aff3">
								<orgName type="institution">Universidade Federal Fluminense (IC/UFF)</orgName>
								<address>
									<country key="BR">Brasil</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Patrick</forename><surname>Valduriez</surname></persName>
							<email>patrick.valduriez@inria.fr</email>
							<affiliation key="aff4">
								<orgName type="laboratory">LIRMM</orgName>
								<orgName type="institution" key="instit1">Inria</orgName>
								<orgName type="institution" key="instit2">University of Montpellier</orgName>
								<orgName type="institution" key="instit3">CNRS ¸a</orgName>
								<address>
									<country>Franc</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Marta</forename><surname>Mattoso</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">Universidade Federal do Rio de Janeiro (PESC/COPPE/UFRJ)</orgName>
								<address>
									<country key="BR">Brasil</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Marta</forename><forename type="middle">Mattoso</forename><surname>Uma Abor-</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">dagem para coleta e análise de dados de configurações em redes neurais profundas. SBBD</orgName>
								<address>
									<postCode>2020</postCode>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">Simpósio Brasileiro de Banco de Dados</orgName>
								<address>
									<postCode>2020</postCode>
									<settlement>Sep, Virtual</settlement>
									<country>Brazil. pp</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff5">
								<orgName type="institution">ciclo de vida. No entanto</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff6">
								<orgName type="department">representac ¸ão de dados a serem</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff7">
								<orgName type="department">Este trabalho foi realizado com apoio da Coordenac ¸ão de Aperfeic ¸oamento de Pessoal de Nível Superior -Brasil (CAPES) -Código de Financiamento 001</orgName>
								<orgName type="institution" key="instit1">CNPq</orgName>
								<orgName type="institution" key="instit2">FAPERJ e INRIA</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Uma abordagem para coleta e análise de dados de configurações em redes neurais profundas</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">4AC6C8971CF2FC3C2486EA59223810F1</idno>
					<idno type="DOI">10.5753/sbbd.2020.13639</idno>
					<note type="submission">Submitted on 16 Oct 2020</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-04-12T14:44+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>est destinée au dépôt et à la diffusion de documents scientifiques de niveau recherche, publiés ou non, émanant des établissements d'enseignement et de recherche français ou étrangers, des laboratoires publics ou privés.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="fr">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduc ¸ão</head><p>Nos últimos anos, a comunidade científica tem presenciado um aumento na popularidade de aplicac ¸ões em técnicas de aprendizado profundo (i.e., Deep Learning ou AP) <ref type="bibr" target="#b5">[Gharibi et al. 2019</ref><ref type="bibr" target="#b6">, Miao et al. 2017]</ref>, incluindo as PINNs, redes neurais profundas guiadas pelas leis da Física na soluc ¸ão de problemas em ciência computacional <ref type="bibr" target="#b9">[Raissi et al. 2017]</ref>.</p><p>AP é o termo usado para denotar o problema de treinar redes neurais profundas e permitir inferências, como a rede neural convolucional (CNN) <ref type="bibr" target="#b1">[Badan and Sekanina 2019]</ref>. O treinamento das CNNs busca pela configurac ¸ão de uma série de hiperparâmetros (p. ex., taxa de aprendizado, batch size, número de épocas, momentum e dropout) que levem à validac ¸ão dos resultados. As CNNs são particularmente sensíveis à definic ¸ão de hiperparâmetros. Essas definic ¸ões dependem da evoluc ¸ão do comportamento dos dados, só conhecido durante ou ao término da execuc ¸ão do treinamento. Adaptac ¸ões a essas decisões são realizadas em um processo de tentativa e erro até se atingir a validac ¸ão dos resultados <ref type="bibr" target="#b14">[Zaharia et al. 2018]</ref>. A etapa de treinamento torna o ciclo de vida da CNN computacionalmente custoso, cansativo e propenso a erros. Apesar de soluc ¸ões de otimizac ¸ão automática de hiperparâmetros, como o Cloud Auto ML<ref type="foot" target="#foot_0">1</ref> , e <ref type="bibr" target="#b1">[Badan and Sekanina 2019]</ref>, a análise de dados junto à configurac ¸ão é necessária. O uso de dados de proveniência <ref type="bibr" target="#b7">[Moreau and Groth 2013]</ref> vem sendo proposto para contribuir para a flexibilidade da representac ¸ão e análise de dados quando especializados para AP <ref type="bibr" target="#b2">[Breck et al. 2019</ref><ref type="bibr" target="#b3">, Caveness et al. 2020]</ref>. Uma vantagem no uso de dados de proveniência é a padronizac ¸ão na representac ¸ão de metadados e a derivac ¸ão dos dados ao longo do treinamento da CNN por meio do PROV-DM do W3C <ref type="bibr" target="#b7">[Moreau and Groth 2013]</ref>.</p><p>A avaliac ¸ão das diversas configurac ¸ões de hiperparâmetros exige que seja feita a relac ¸ão entre vários tipos de dados e metadados, p. ex., métricas como acurácia, dados do ambiente computacional utilizado para o treinamento da CNN <ref type="bibr" target="#b14">[Zaharia et al. 2018</ref>]. Soluc ¸ões de coleta automática de dados para análise tendem a ser pouco flexíveis quanto à escolha do que será coletado e principalmente sobre como esses dados são analisados. Soluc ¸ões com flexibilidade na coleta e análise de dados de proveniência como em <ref type="bibr" target="#b8">[Pina et al. 2019</ref>] exigem uma etapa de modelagem que pode ser uma barreira para a adoc ¸ão de ferramentas de proveniência.</p><p>Este artigo apresenta uma abordagem centrada em dados de proveniência, propondo um mecanismo de coleta automática, porém com flexibilidade na escolha de dados a serem coletados e analisados. A abordagem foi baseada na CNNProv <ref type="bibr" target="#b8">[Pina et al. 2019</ref>] e implementada por meio do Keras-Prov, uma extensão do Keras<ref type="foot" target="#foot_1">2</ref> , que é uma API que executa sobre a plataforma de AP TensorFlow<ref type="foot" target="#foot_2">3</ref> . O objetivo do Keras-Prov é reduzir as ac ¸ões que o usuário deve realizar para a análise de dados, em especial hiperparâmetros, durante o treinamento de CNNs. Ao adotar o padrão W3C PROV-DM, o Keras-Prov provê uma representac ¸ão de dados pública, extensível e adotada em diversos domínios de aplicac ¸ão, o que facilita a interoperabilidade. O Keras-Prov é capaz de rastrear as transformac ¸ões de dados e conjuntos de dados relacionados aos hiperparâmetros e métricas do treinamento da CNN de modo automático. O armazenamento dos dados de proveniência e adaptac ¸ões dos usuários em configurac ¸ões em SGBDs permite que os dados ao longo do treinamento sejam analisados globalmente. Por ser possível estender o esquema da base de dados de proveniência, dados do domínio da aplicac ¸ão podem ser modelados e acrescentados à base de proveniência ao serem coletados ao longo do treinamento. Experimentos realizados com a DenseED, uma aplicac ¸ão real de CNN densa guiada por leis da Física, mostram a adequac ¸ão do Keras-Prov para a análise de hiperparâmetros de CNNs e o baixo impacto no desempenho da API no Keras. Além desta introduc ¸ão, este artigo contém outras quatro sec ¸ões. A Sec ¸ão 2 discute os trabalhos relacionados, a Sec ¸ão 3 apresenta a abordagem Keras-Prov, a Sec ¸ão 4 os experimentos e, finalmente, a Sec ¸ão 5 conclui este artigo.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Trabalhos Relacionados</head><p>Há um crescente uso de dados de proveniência em aprendizado de máquina (AM) <ref type="bibr" target="#b10">[Schelter et al. 2017</ref><ref type="bibr" target="#b13">, Tsay et al. 2018</ref><ref type="bibr" target="#b6">, Miao et al. 2017]</ref>. No entanto, não foram encontradas abordagens que oferec ¸am funcionalidades do Keras-Prov (i.e., utilizac ¸ão de dados de proveniência especificamente na fase de treinamento de CNNs, possibilidade de realizar a análise online, flexibilidade quanto à escolha do que vai ser coletado e a extensão para coleta de outros dados, independência de portal, e com baixa sobrecarga). O ModelHub <ref type="bibr" target="#b6">[Miao et al. 2017]</ref> é um sistema para gerência do ciclo de vida de redes neurais profundas cujo objetivo é armazenar pesos de modelos em diferentes versões, com foco no AP. O ModelHub possui um modelo proprietário para representac ¸ão dos metadados do treinamento da rede neural, o que dificulta a interoperabilidade. A ferramenta Runway <ref type="bibr" target="#b13">[Tsay et al. 2018</ref>] tem como objetivo a gerência de artefatos de AM e AP, como modelos, dados ou experimentos. A soluc ¸ão permite rastrear o modelo e os dados desde o uso no treinamento até a implementac ¸ão, facilitando a reprodutibilidade. No entanto, além de ser uma soluc ¸ão proprietária, é restrita à linguagem de programac ¸ão Python. <ref type="bibr" target="#b10">[Schelter et al. 2017]</ref> propõem uma ferramenta automatizada para extrair os metadados do modelo e apresentá-los com uma visualizac ¸ão interativa para auxiliar na comparac ¸ão de experimentos. Dessa forma, essa soluc ¸ão concentra-se no rastreamento de metadados e na proveniência dos dados de experimentac ¸ão de AM. Porém, a abordagem proposta não utiliza padrões de representac ¸ão, como o W3C PROV, afetando a interoperabilidade. Essas soluc ¸ões preveem o uso de AM para aplicac ¸ões de negócios. Keras-Prov herda os benefícios da DfAnalyzer <ref type="bibr" target="#b11">[Silva et al. 2018</ref>] para acomodar dados científicos junto à proveniência e execuc ¸ão em ambientes de processamento de alto desempenho, facilitando seu uso em PINNs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Abordagem centrada em dados: Keras-Prov</head><p>O objetivo principal do Keras-Prov é reduzir o esforc ¸o de adaptac ¸ão do código para captura de dados de proveniência (uma vez que o Keras não captura tais dados de forma nativa) durante o treinamento da CNN. O Keras foi escolhido por ser uma API de rede neural de código aberto muito utilizada e com documentac ¸ão disponível. A arquitetura do Keras-Prov é apresentada na Figura 1, e é composta de três camadas: (i) Treinamento, (ii) Dados e (iii) Análise. A camada de Treinamento é onde o Keras é executado e interage com bibliotecas de AP como o TensorFlow e o Theano. É importante ressaltar que o Keras teve seu código modificado para capturar os hiperparâmetros mais comuns e enviar seus valores para o Extrator de Proveniência. O Keras-Prov identifica automaticamente as transformac ¸ões de dados no código do usuário, os hiperparâmetros e seus valores utilizados em cada treinamento, assim como as métricas coletadas. O Extrator recebe os dados assincronamente e os grava na camada de Dados. O banco de dados de proveniência segue o esquema da Figura 3, que estende o Prov-Df <ref type="bibr" target="#b12">[Silva et al. 2017]</ref>. A Figura 3 representa em termos dos conceitos Agente (Agent), Atividade (Activity) e Entidade (Entity) do W3C PROV as transformac ¸ões de dados do processo de treinamento das CNNs e os hiperparâmetros. Além dos dados de proveniência, o modelo treinado também é armazenado na camada de dados. O Visualizador de proveniência gera uma representac ¸ão visual do grafo de proveniência, de forma a facilitar a análise por parte do usuário. Tais componentes são extensíveis, de forma que diferentes bibliotecas de treinamento de CNNs podem ser acopladas para capturar e armazenar hiperparâmetros e outros dados de treinamento.</p><p>Para utilizar o Keras-Prov é necessário que o usuário defina no código quais os hiperparâmetros devem ser capturados e armazenados, com base na lista disponibilizada, definindo com o valor True ou False. O trecho de código na Figura 2 define dados de configurac ¸ão da DenseED.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Avaliac ¸ão Experimental</head><p>Utilizamos a DenseED <ref type="bibr" target="#b4">[Freitas et al. 2020</ref>] como estudo de caso do Keras-Prov. A Den-seED é uma PINN que usa uma CNN densa, como um modelo substitutivo para viabilizar a quantificac ¸ão de incertezas <ref type="bibr" target="#b15">[Zhu and Zabaras 2018]</ref>. A DenseED tem como objetivo substituir o cálculo da migrac ¸ão reversa no tempo (MRT) por um modelo treinado. Desta forma o cálculo da MRT que teria que ser realizado para cada distribuic ¸ão de probabilidade pode ser reduzido.</p><p>A instrumentac ¸ão desta CNN utiliza as transformac ¸ões Treinamento, Adaptac ¸ão e Teste. Treinamento consome (used) o nome do otimizador, os hiperparâmetros taxa de aprendizado, número de épocas e número de camadas da rede, e produz (wasGeneratedBy) um conjunto de métricas que auxiliam na avaliac ¸ão dos resultados obtidos durante o treinamento, p. ex., a acurácia, o valor da func ¸ão de perda, o tempo decorrido e a data e hora do fim da execuc ¸ão de cada época. Adaptac ¸ão consome (used) o conjunto produzido pela transformac ¸ão anterior (Treinamento), um conjunto de dados com informac ¸ões para a adaptac ¸ão ocorrida e o conjunto de dados de saída contém a nova taxa de aprendizado, o valor da época e a data e hora em que a adaptac ¸ão ocorreu, além de uma identificac ¸ão para a adaptac ¸ão. Teste provê dados sobre a avaliac ¸ão do modelo de acordo com o conjunto de dados de treinamento e tem como saída os valores de acurácia e da func ¸ão de perda. Porém, nesse caso, foram acrescentadas transformac ¸ões para captura de informac ¸ões acerca das camadas encoder, decoder e dense block.</p><p>O Keras-Prov foi avaliado sob duas perspectivas: (i) sobrecarga introduzida com a captura de proveniência e (ii) capacidade de consulta aos dados de proveniência. Com o código da DenseED adaptado para a utilizac ¸ão do Keras-Prov, foi realizado o treinamento variando-se o número de épocas, taxa de aprendizado, momentum, decay e o otimizador escolhido. As execuc ¸ões foram feitas com 20, 50 e 100 épocas, a taxa de aprendizado foi variada com os valores 0,0005, 0,001 e 0,002, o decay foi variado com os valores 0,0001 e 0,000001 e o momentum foi variado com os valores 0,5 e 0,9. Cada configurac ¸ão de hiperparâmetros foi executada cinco vezes e a média do tempo de execuc ¸ão foi considerada. O tempo de execuc ¸ão foi medido a partir do início da aplicac ¸ão até sua finalizac ¸ão, o Keras-Prov já estava inicializado antes da execuc ¸ão da aplicac ¸ão e o MonetDB já estava com o schema definido (conforme Figura 3). O desvio padrão das cinco medic ¸ões para as diferentes configurac ¸ões de hiperparâmetros ficou entre 0,009 e 0,265. A medic ¸ão da sobrecarga adicionada pelo Keras-Prov corresponde a um aumento de menos de 2,5% (no pior caso) sobre o tempo total de treinamento da CNN.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusão</head><p>Este artigo tem como objetivo apoiar a fase de treinamento e otimizac ¸ão das CNNs ao registrar informac ¸ões relevantes à análise de combinac ¸ões de hiperparâmetros para reconfigurac ¸ões. O Keras-Prov é uma extensão à API Keras, que é utilizada por muitas bibliotecas de AP (p. ex., TensorFlow e Theano). Por meio do Keras-Prov, o usuário não necessita de um grande esforc ¸o de adaptac ¸ão de seu código para capturar dados de proveniência, ao mesmo tempo que possui flexibilidade para incluir novos dados a serem analisados e armazenados. O Keras-Prov foi avaliado com a CNN DenseED, um exemplo de uso de CNN por pesquisadores que não são da área de ciência da computac ¸ão, uma situac ¸ão que tende a aumentar e necessitar ainda mais de auxílio na análise e configurac ¸ão de hiperparâmetros. Experimentos evidenciam a adequac ¸ão do uso de proveniência nas atividades de análise ao longo do treinamento de CNNs, incluindo extensões para redes densas, contribuindo para um padrão de esquema que permite ao usuário consultar de forma integrada os dados de proveniência associados aos dados usados no treinamento. Como trabalhos futuros, pretende-se estender o uso do Keras-Prov no apoio às redes neurais guiadas pelas leis da Física e quantificac ¸ão de incertezas, que assim como em AP, requerem um processo analítico na criac ¸ão de novos modelos.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figura 1 :</head><label>1</label><figDesc>Figura 1: Arquitetura do Keras-Prov</figDesc><graphic coords="5,70.87,85.04,226.76,140.50" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figura</head><label></label><figDesc>Figura 2: C ódigo no Keras-Prov</figDesc><graphic coords="5,70.87,262.10,453.53,143.54" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>O</head><label></label><figDesc>potencial analítico do Keras-Prov resulta do processamento de consultas na base de proveniência. Foram executadas consultas para avaliar configurac ¸ões de hiperparâmetros junto aos dados de métricas sobre o treinamento das CNNs para o usuário poder realizar os ajustes com mais seguranc ¸a e confianc ¸a. Para as consultas da Figura 4 utilizamos a DenseED com o otimizador Adam, 20 épocas e taxa de aprendizado 0,001. A consulta (a) mostra "Qual o valor de perda para a DenseED com K=24 e L=4 no momento atual (época 200)?" e a consulta (b) mostra "Qual o valor da func ¸ão de perda (loss function) de cada época para as quatro primeiras épocas da CNN DenseED?". À medida que o treinamento progride, o usuário continua realizando consultas à base. Por exemplo, ao se chegar em 200 épocas, o usuário decide finalizar a execuc ¸ão, pois esses valores não estão satisfazendo seus critérios. Nesse caso, o usuário altera o número de camadas no bloco denso para 8 e o treinamento segue com os novos dados que são armazenados na base de dados.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figura 4 :</head><label>4</label><figDesc>Figura 4: Consultas sobre o bloco denso = 4 junto às camadas encoder/decoder.</figDesc><graphic coords="6,70.87,417.57,453.54,113.79" type="bitmap" /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>https://cloud.google.com/automl</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>https://keras.io/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2"><p>www.tensorflow.org/</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName><surname>Referências</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Optimizing convolutional neural networks for embedded systems by means of neuroevolution</title>
		<author>
			<persName><forename type="first">F</forename><surname>Badan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Sekanina</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TPNC</title>
		<imprint>
			<biblScope unit="volume">11934</biblScope>
			<biblScope unit="page" from="109" to="121" />
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Data validation for machine learning</title>
		<author>
			<persName><forename type="first">E</forename><surname>Breck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Polyzotis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Roy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">E</forename><surname>Whang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zinkevich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Systems and Machine Learning (SysML)</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Tensorflow data validation: Data analysis and validation in continuous ml pipelines</title>
		<author>
			<persName><forename type="first">E</forename><surname>Caveness</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">S</forename><surname>Gc</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Polyzotis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Roy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zinkevich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 ACM SIGMOD</title>
		<meeting>the 2020 ACM SIGMOD</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="2793" to="2796" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">An encoder-decoder deep surrogate for reverse time migration in seismic imaging under uncertainty</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">S</forename><surname>Freitas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">H</forename><surname>Barbosa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">M</forename><surname>Guerra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">L</forename><surname>Coutinho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">A</forename><surname>Rochinha</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2006.09550</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Modelkb: towards automated management of the modeling lifecycle in deep learning</title>
		<author>
			<persName><forename type="first">G</forename><surname>Gharibi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Walunj</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Rella</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Int. Work. on Realizing Art. Intel. Synergies in Soft. Eng</title>
		<imprint>
			<publisher>IEEE Press</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="28" to="34" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Towards unified data and lifecycle management for deep learning</title>
		<author>
			<persName><forename type="first">H</forename><surname>Miao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">S</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Deshpande</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE 33rd ICDE</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2017">2017. 2017</date>
			<biblScope unit="page" from="571" to="582" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Provenance: an introduction to prov</title>
		<author>
			<persName><forename type="first">L</forename><surname>Moreau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Groth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Synthesis Lectures on the Semantic Web: Theory and Technology</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1" to="129" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Análise de hiperparâmetros em aplicac ¸ões de aprendizado profundo por meio de dados de proveniência</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">B</forename><surname>Pina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Neves</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Paes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>De Oliveira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mattoso</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">XXXIV SBBD</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="223" to="228" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Physics informed deep learning (part i): Data-driven solutions of nonlinear partial differential equations</title>
		<author>
			<persName><forename type="first">M</forename><surname>Raissi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Perdikaris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Karniadakis</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1711.10561</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Automatically tracking metadata and provenance of machine learning experiments</title>
		<author>
			<persName><forename type="first">S</forename><surname>Schelter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-H</forename><surname>Böse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kirschnick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Seufert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ML Systems workshop</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Dfanalyzer: runtime dataflow analysis of scientific applications using provenance</title>
		<author>
			<persName><forename type="first">V</forename><surname>Silva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>De Oliveira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Valduriez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mattoso</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PVLDB</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2082" to="2085" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Raw data queries during data-intensive parallel workflow execution</title>
		<author>
			<persName><forename type="first">V</forename><surname>Silva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Leite</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Camata</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>De Oliveira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">L</forename><surname>Coutinho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Valduriez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mattoso</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">FGCS</title>
		<imprint>
			<biblScope unit="volume">75</biblScope>
			<biblScope unit="page" from="402" to="422" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Runway: machine learning model experiment management tool</title>
		<author>
			<persName><forename type="first">J</forename><surname>Tsay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Mummert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Bobroff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Braz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Westerink</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hirzel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SysML</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Accelerating the machine learning lifecycle with mlflow</title>
		<author>
			<persName><forename type="first">M</forename><surname>Zaharia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Davidson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ghodsi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Konwinski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Murching</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Nykodym</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Ogilvie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Parkhe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zumar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Data Eng. Bull</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="page" from="39" to="45" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Bayesian deep convolutional encoder-decoder networks for surrogate modeling and uncertainty quantification</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Zabaras</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Computational Physics</title>
		<imprint>
			<biblScope unit="volume">366</biblScope>
			<biblScope unit="page" from="415" to="447" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
