<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A Knowledge Rich Task Planning Framework for Human-Robot Collaboration</title>
				<funder>
					<orgName type="full">Région Occitanie and the Artificial and Natural Intelligence Toulouse Institute</orgName>
					<orgName type="abbreviated">ANITI</orgName>
				</funder>
				<funder>
					<orgName type="full">Défi Clé &quot;Robotique Centrée sur l&apos;Humain</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Shashank</forename><surname>Shekhar</surname></persName>
							<email>shashank.shekhar@laas.fr</email>
							<affiliation key="aff0">
								<orgName type="laboratory">LAAS-CNRS</orgName>
								<orgName type="institution" key="instit1">Universite de Toulouse</orgName>
								<orgName type="institution" key="instit2">CNRS</orgName>
								<orgName type="institution" key="instit3">INSA</orgName>
								<address>
									<settlement>Toulouse</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Anthony</forename><surname>Favier</surname></persName>
							<email>anthony.favier@laas.fr</email>
							<affiliation key="aff0">
								<orgName type="laboratory">LAAS-CNRS</orgName>
								<orgName type="institution" key="instit1">Universite de Toulouse</orgName>
								<orgName type="institution" key="instit2">CNRS</orgName>
								<orgName type="institution" key="instit3">INSA</orgName>
								<address>
									<settlement>Toulouse</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="laboratory">Artificial and Natural Intelligence Toulouse Institute (ANITI)</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Rachid</forename><surname>Alami</surname></persName>
							<email>rachid.alami@laas.fr</email>
							<affiliation key="aff0">
								<orgName type="laboratory">LAAS-CNRS</orgName>
								<orgName type="institution" key="instit1">Universite de Toulouse</orgName>
								<orgName type="institution" key="instit2">CNRS</orgName>
								<orgName type="institution" key="instit3">INSA</orgName>
								<address>
									<settlement>Toulouse</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="laboratory">Artificial and Natural Intelligence Toulouse Institute (ANITI)</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Madalina</forename><surname>Croitoru</surname></persName>
							<email>madalina.croitoru@lirmm.fr</email>
							<affiliation key="aff2">
								<orgName type="laboratory">LIRMM</orgName>
								<orgName type="institution">University of Montpellier</orgName>
								<address>
									<settlement>Montpellier</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">A Knowledge Rich Task Planning Framework for Human-Robot Collaboration</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">FC56E8F80F7EAF4C2EDD8D1AAA8838A4</idno>
					<idno type="DOI">10.1007/978-3-031-</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-04-12T14:47+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Collaborative planning</term>
					<term>Knowledge reasoning</term>
					<term>Inference</term>
					<term>Theory of Mind (ToM)</term>
					<term>Human-aware task planning</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper, we position ourselves within the context of collaborative planning. Drawing upon our recent research, we introduce a novel, knowledge rich task planning framework that represents and reasons and effectively addresses agents' first-order false beliefs to solving a task planning problem with a shared goal. Our contributions to this work are as follows: First, to enhance the reasoning abilities of an existing framework, an intuitive observability model for situation assessment is addressed, and for that, an improved knowledge modeling is considered. This effectively captures agents' predictable false beliefs and motivates us to exploit the power of off-the-shelf knowledge reasoners. Second, a new planning approach that incorporates this improved encoding. And, to show the effectiveness of our planner and present our initial findings and proof of concept, we conduct a thorough use case analysis.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Human-robot collaboration/interaction (HRC/I) is a current research focus due to the growing number of robot-assisted applications <ref type="bibr" target="#b12">[13]</ref>. Collaborative robots add clear value to real-world domains like household <ref type="bibr" target="#b16">[17]</ref>, workshops <ref type="bibr" target="#b14">[15]</ref>, or medical facilities <ref type="bibr" target="#b11">[12]</ref>.</p><p>In this work, we address a task planning problem where humans and robots jointly achieve a shared goal. For seamless human-robot collaboration, we believe that it is essential not to restrict human behaviors and, hence, consider humans as uncontrollable agents <ref type="bibr" target="#b6">[7]</ref>. Our focus is on developing a planning framework that generates collaborative behaviors for an autonomous robot while anticipating the possible human behaviors and being congruent to humans' choices. Frameworks that support such requirements, in general, include HAT-P/EHDA <ref type="bibr" target="#b5">[6]</ref>, ADACORL <ref type="bibr" target="#b15">[16]</ref> and CommPlan <ref type="bibr" target="#b16">[17]</ref>, to cite but a few.</p><p>Restricted observability available in the environment often leads agents to form false beliefs about the progress of the task and other agents' beliefs. For instance, an agent may rely on "only believing what they see or can infer" to update or form new beliefs. For the robot to anticipate such situations while planning its behavior to collaborate, it should consider Theory of Mind (ToM) to maintain and manage agents' distinct beliefs.</p><p>Our recently proposed planner extends the HATP/EHDA framework and considers the first-order ToM, that is, managing (false) beliefs about the physical world <ref type="bibr" target="#b9">[10]</ref>. Roughly, its main idea works as follows: First, the existing problem encoding is enhanced. To be specific, we categorize each environmental property as either observable -meaning its real value can be assessed directly from the environment -or indirectly inferable. In the latter case, the changes in the property's status persist in the environment when an action is executed, but cannot be observed directly. However, an agent can assess this knowledge either as an observer or as an actor, or when they are communicated. Second, to consider restricted observability, we introduce the concept of co-presence and co-location. We formulate the environment such that a collection of discrete places where action manipulation can take place, permitting the enhanced encoding to enable precise action executions, or an agent assessing the value of an environmental property when they are physically situated within a specified place.</p><p>The encoding is used in HATP/EHDA as input, modifying the planner to use improved knowledge modeling to handle better the evolution of agents' firstorder (false) beliefs and estimate the actions humans are likely to perform. (Due to space restrictions, we will provide only a high-level description of it.) However, some limitations to the above line of work are: First, the context under which the reasoning works is limited. For example, associating an observable state property directly to a discrete place in the environment is not always intuitive and straightforward and enables sound reasoning. To understand this, consider the following scenario: A robot holding a coffee mug can be assessed from where the robot is currently situated. Moreover, if the robot moves from one place to another, then the condition under which the robot holding the coffee mug can be assessed, also changes implicitly. Or, if a table is moved, then the condition to assess the orientation of blocks on top of it would change implicitly, too. Second, the system's ability to refute a false belief is limited.</p><p>In this regard, our contributions to this paper are the following.</p><p>1. We first extend and generalize the concepts introduced earlier for observing the value of an environmental property. We provide a new encoding that is much cleaner and intuitive and achieves a sound resolution and refutation. 2. Second, the planning algorithm is improved by incorporating the new encoding for better managing the evolution of agents' predictable (false) beliefs.</p><p>To show the efficacy of our planning approach and present our preliminary findings and proof of concept, we conduct a use case analysis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">The Illustrative Example</head><p>Consider an adapted version of the scenario appearing in <ref type="bibr" target="#b9">[10]</ref>. The scenario includes a pot of water on the stove, while the pasta packet is in the adja-cent room. One sub-task is to pour the pasta into the pot, which can only be done after turning on the stove (results in holding StoveOn) and adding salt to the water (results in SaltIn). Suppose, the robot is responsible for turning on the stove (turn-stove-on), while the human is tasked with fetching the pasta (grab-pasta, however, for that, they need to move to the other room where the pasta packet is kept) and pouring it into the pot (pour-pasta). Both the robot and the human have the capability to add salt (add-salt) to the pot. Humans can be uncontrollable but assumed to be rational, so they can choose to either first add salt, or first fetch the pasta. Next, the robot's actions depend on the human's decision, resulting in the generation of different false beliefs. Such variability in beliefs observed can be precisely attributed to the restricted observability and available human choices within the system. Suppose, when the human is temporarily absent to bring pasta, the robot can act in kitchen. When they return, they can "assess" whether the robot turned on the stove, which is observable. However, the presence of salt (SaltIn) is not directly observable to her. To prevent misunderstandings, a proactive robot needs to anticipate false beliefs held by humans. Here, humans may mistakenly believe that salt is not added to the pasta or be uncertain about it.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">The Basic Architecture and Recent Advancements</head><p>We provide a brief overview of the HATP/EHDA (human-aware task planning by emulating human decisions and actions) architecture <ref type="bibr" target="#b5">[6]</ref>, building upon previous research, e.g. <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b4">5]</ref>. We also discuss recent advancements that have been made based on its planning framework. (For a better understanding of the basic terminologies, definitions, and planning models, we refer readers to <ref type="bibr" target="#b10">[11]</ref>.)</p><p>The HATP/EHDA architecture considers: (1.) distinct capabilities and characteristics of humans and robots, (2.) utilization of human task and/or action models by the robot to inform decision-making, considering human capabilities and environmental dynamics, and (3.) flexibility for humans to choose an action from the available choices, which is congruent to the shared goal.</p><p>The HATP/EHDA planning scheme utilizes a two-agent model consisting of a human and a robot, represented as two-agent-HTN (hierarchical task networks) <ref type="bibr" target="#b10">[11]</ref>, adapted as per the requirements. Roughly speaking, each agent has their own initial belief state, action model &amp; methods, and task network. Our focus is on a sequential task to be solved, where both agents have a shared initial task network that needs to be decomposed. Considering perfectly aligned agents' beliefs with the real world to begin with, the classical scheme assumes that the belief state of an agent consists of properties that are either true or false. Assuming the environment is fully observable, the planning scheme uses agents' task/action models and beliefs to decompose their task network into valid primitive components, resulting in an implicitly coordinated plan for the robot within a joint solution policy <ref type="bibr" target="#b5">[6]</ref>. This policy encompasses both the robot's actions and an estimated policy for the human. For more details, see <ref type="bibr" target="#b9">[10]</ref>.</p><p>A new formalism is proposed to enhance the planning scheme's robustness for estimating human initiatives when dealing with restricted observability. It considers the first-order Theory of Mind for managing agents' (false) belief updates, resulting in improved management of their mental state and enhanced collaboration <ref type="bibr" target="#b8">[9]</ref>. As we pointed earlier, this scheme addresses the need for a less abstract problem formulation, and conceptualizes place-based situation-assessment models, and hence capturing collaboration nuances more accurately.</p><p>An offline planning approach is proposed to detect predictable false beliefs of humans and address them through explicit communication actions if mandatory w.r.t. the goal. It promotes more accurate understanding and alignment between the robot and humans, allowing for minimal communication. Another way, as mentioned in <ref type="bibr" target="#b9">[10]</ref>, is to delay critical actions, enabling humans to reach a state s.t. the robot's actions become perceivable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Improved Problem Encoding</head><p>We consider two types of agents. First is GT, which stands for ground truth, an omnipresent (virtual) agent that cannot achieve any task, however, it immediately knows all the effects when an action is applied. The second type refers to real agents, e.g., a robot. Real agents can have false beliefs, which means their beliefs about the world may diverge from the GT 's beliefs. Moreover, no real-world uncertainty is considered w.r.t. agents' beliefs.</p><p>An environmental property is Boolean type, and is augmented by an argument, ?a -agent (e.g., Human/Robot), which is also its first argument. It represents that the agent believes that this property holds true given it is contained in the agent's beliefs. In this work, we restrict ourselves to those properties that are directly observable in the environment, while relying on the existing concepts with some minor updates required, for managing beliefs w.r.t. the facts that are indirectly inferable. To manage appropriate dynamics of the world, we augment the parameter list of relevant state properties which are observable with an argument ?p -Places (at the end of its parameter list). However, for those that are observable but associating them directly to a place is not intuitive to the domain modeler, e.g., StoveOn is a property of a stove and can be assessed from where it is currently situated, we use a different strategy to cater to them.</p><p>With a lifted (primitive) action schema, we specify how it is only modeled to affect the beliefs of the GT agent, in principle, focusing on observable state properties.</p><p>:action turn-stove-on (?a -agent ?st -stove ?k -kitchen)</p><p>:precondition (and (not(= GT ?a))(at ?a ?a ?k)(stoveAt ?a ?st ?k) ...) :effect (and (stoveOn GT ?st) ...)</p><p>Real agents assess available information systematically from the environment, and for that, we include the following in our problem specification:</p><p>Language &amp; Interpretation: Informally, to assess the value of a property, an agent needs to respect certain condition(s). Of course, a condition could be that the agent is co-located, as supported by the existing system. However, inspired by the work in <ref type="bibr" target="#b3">[4]</ref>, we generalize this idea and specify rules for knowledge reasoning to capture more complex contexts. For one observable property (representing the consequent), conditions for assessing its value are "formulated" in the antecedent of a knowledge rule. Formally, a rule is of the form p(a 1 , x, y), q(x) → s(y, b 1 ), which also means that ∀x∀y(p(a 1 , x, y), q(x) → s(y, b 1 )), where x and y are free variables, and p, q and s are names. a 1 and b 1 are constants.</p><p>For example, when an agent is situated at the stove's location, it will acknowledge the current status of StoveOn. A corresponding rule to it is, R1: ∀s∀k∀a(stoveAt(a, s, k), stoveon(GT, s), at(a, a, k) → stoveon(a, s). Note that the GT's beliefs play a key role here. Similarly, we can write other important rules for our example domain: R2: ∀a 1 ∀k(at(GT, a 1 , k) → at(a 1 , a 1 , k)), R3: ∀a 1 ∀a 2 ∀k(at(GT, a 1 , k), at(a 2 , a 2 , k) → at(a 2 , a 1 , k)), and R4: ∀a∀s(¬stoveat(GT, s, kitchen), at(a, a, kitchen) → ¬stoveat(a, s, kitchen)). It treats the stove as a mobile object, which alters the context to also evaluate the status of StoveOn along with determining its current location.</p><p>Page restrictions allow us to offer a concise overview only, reserving detailed semantics for future research. In rules, it is important to note that the implications must not be contraposed. Anything that cannot be evaluated as true is considered false for agents. Our focus on stratified rule sets avoids potential issues related to unsafe negation usage and ambiguity in interpretation <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b13">14]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Incorporating New Encoding for Planning</head><p>We adapt our planning mechanism presented in <ref type="bibr" target="#b9">[10]</ref>, to assess new encoding's effectiveness. It assumes that the robot's beliefs never deviate from GT's beliefs, and hence essentially two distinct belief states are handled by the scheme.</p><p>Two questions arise at this point: First, how does the state transition occur during planning and how are the agents' (false) beliefs updated? Second, how are the relevant false beliefs detected and addressed? We rely on the existing mechanism to address the second question and how beliefs are updated when agents do indirect inference. Our main focus will be to address how the new observability model is incorporated into the planning workflow.</p><p>Once an action is executed, such as the human moving to the kitchen, the process of situation assessment is initiated to evaluate the environment from the perspectives of individual agents. Here, our approach diverges from current methods. Instead of directly matching the co-location of agents with state properties and assessing the latter's values, we invoke an external reasoner to deduce such knowledge. Using the agent's beliefs, the reasoner verifies the formula that captures the context specified (in the rules) to deduce new knowledge or to refute a fact that humans believe but is no longer true in the robot's beliefs. This departure from the existing encoding allows us to remove the hardcoded context within an action. For instance, if the human moves from one room to another, carrying the pasta packet that was initially in the room, the new location for assessing the packet switches to the kitchen. Moreover, we needed to hardcode it within each action that updates the place of an agent in the environment. However, with the new encoding, if the robot sees the human in the kitchen, then given the domain rules, it can assess whether the human is holding the pasta packet, by their presence in the kitchen.</p></div>		</body>
		<back>

			<div type="acknowledgement">
<div><p>Acknowledgments. This work has been partially financed by <rs type="funder">Défi Clé "Robotique Centrée sur l'Humain</rs>" supported by <rs type="funder">Région Occitanie and the Artificial and Natural Intelligence Toulouse Institute (ANITI)</rs>.</p></div>
			</div>
			<listOrg type="funding">
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Toward Human-Aware Robot Task Planning</title>
		<author>
			<persName><forename type="first">R</forename><surname>Alami</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Clodic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Montreuil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">A</forename><surname>Sisbot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Chatila</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI spring symposium 2006: to boldly go where no human-robot team has gone before</title>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Planning and plan-execution for humanrobot cooperative task achievement</title>
		<author>
			<persName><forename type="first">S</forename><surname>Alili</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Warnier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ali</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Alami</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ICAPS</title>
		<meeting>of ICAPS</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Towards a Theory of Declarative Knowledge</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">R</forename><surname>Apt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Blair</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Walker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Foundations of Deductive Databases and Logic Programming</title>
		<editor>
			<persName><forename type="first">J</forename><surname>Minker</surname></persName>
		</editor>
		<imprint>
			<publisher>Morgan Kaufmann</publisher>
			<date type="published" when="1988">1988</date>
			<biblScope unit="page" from="89" to="148" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Graal: A toolkit for query answering with existential rules</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">F</forename><surname>Baget</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Leclère</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">L</forename><surname>Mugnier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Rocher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Sipieter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Rule Technologies: Foundations, Tools, and Applications: 9th International Symposium, RuleML</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A Human-Aware Task Planner Explicitly Reasoning About Human and Robot Decision, Action and Reaction</title>
		<author>
			<persName><forename type="first">G</forename><surname>Buisan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Alami</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of HRI</title>
		<meeting>of HRI</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">HATP/EHDA: A Robot Task Planner Anticipating and Eliciting Human Decisions and Actions</title>
		<author>
			<persName><forename type="first">G</forename><surname>Buisan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Favier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mayima</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Alami</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ICRA</title>
		<meeting>of ICRA</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A Human-Aware Robot Task Planner</title>
		<author>
			<persName><forename type="first">M</forename><surname>Cirillo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Karlsson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Saffiotti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ICAPS</title>
		<meeting>of ICAPS</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">The HATP hierarchical planner: Formalisation and an initial study of its usability and practicality</title>
		<author>
			<persName><forename type="first">L</forename><surname>De Silva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Lallement</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Alami</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of IROS</title>
		<meeting>of IROS</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Robust Planning for Human-Robot Joint Tasks with Explicit Reasoning on Human Mental State</title>
		<author>
			<persName><forename type="first">A</forename><surname>Favier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Shekhar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Alami</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AI-HRI, AAAI Symposium</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Anticipating False Beliefs and Planning Pertinent Reactions in Human-Aware Task Planning with Models of Theory of Mind</title>
		<author>
			<persName><forename type="first">A</forename><surname>Favier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Shekhar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Alami</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">PlanRob 2023, the ICAPS Workshop</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><surname>Ghallab</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Nau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Traverso</surname></persName>
		</author>
		<title level="m">Automated Planning -Theory and Practice</title>
		<imprint>
			<publisher>Elsevier</publisher>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Collaboration with a robotic scrub nurse</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">G</forename><surname>Jacob</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">T</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">A</forename><surname>Akingba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Wachs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="68" to="75" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Autonomy in physical human-robot interaction: A brief survey</title>
		<author>
			<persName><forename type="first">M</forename><surname>Selvaggio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Cognetti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Nikolaidis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ivaldi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Siciliano</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Rob. Autom. Lett</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">In Defense of PDDL Axioms</title>
		<author>
			<persName><forename type="first">S</forename><surname>Thiébaux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hoffmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Nebel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of IJCAI</title>
		<meeting>of IJCAI</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Human-aware robotic assistant for collaborative assembly: Integrating human motion prediction with planning in time</title>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">V</forename><surname>Unhelkar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">A</forename><surname>Lasota</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Tyroller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">D</forename><surname>Buhai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Marceau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Deml</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Shah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Rob. Autom. Lett</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="2394" to="2401" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Semi-Supervised Learning of Decision-Making Models for Human-Robot Collaboration</title>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">V</forename><surname>Unhelkar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Shah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of CoRL</title>
		<meeting>of CoRL</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Decision-Making for Bidirectional Communication in Sequential Human-Robot Collaborative Tasks</title>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">V</forename><surname>Unhelkar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Shah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of HRI</title>
		<meeting>of HRI</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
