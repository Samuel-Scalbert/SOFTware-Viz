<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Evaluating Explanations of Relational Graph Convolutional Network Link Predictions on Knowledge Graphs</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Nicholas</forename><surname>Halliwell</surname></persName>
							<email>nicholas.halliwell@inria.fr</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Inria</orgName>
								<orgName type="institution" key="instit2">Université Côte d&apos;Azur</orgName>
								<orgName type="institution" key="instit3">CNRS</orgName>
								<address>
									<region>I3S</region>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Evaluating Explanations of Relational Graph Convolutional Network Link Predictions on Knowledge Graphs</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">FB93D8543D18FA03DECA6BF72D5FABEB</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-04-12T14:54+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Recently, explanation methods have been proposed to evaluate the predictions of Graph Neural Networks on the task of link prediction. Evaluating explanation quality is difficult without ground truth explanations. This thesis is focused on providing a method, including datasets and scoring metrics, to quantitatively evaluate explanation methods on link prediction on Knowledge Graphs.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction</head><p>Knowledge Graphs represent facts as triples in the form <ref type="bibr">(subject, predicate, object)</ref>, where a subject and object represent a real-world entity, linked by some predicate. Knowledge Graphs often do not explicitly contain every available fact. Link prediction on Knowledge Graphs is used to identify unknown facts from existing ones. Relational Graph Convolutional Networks (RGCN) <ref type="bibr" target="#b6">(Schlichtkrull et al. 2018)</ref> extends Graph Convolutional Networks <ref type="bibr" target="#b5">(Kipf and Welling 2017)</ref> for applications to link prediction on Knowledge Graphs, using the scoring function from DistMult <ref type="bibr" target="#b7">(Yang et al. 2015)</ref> as an output layer, returning a probability of the input triple being a fact.</p><p>Several algorithms have been proposed to explain the predictions of an RGCN used for link prediction, in particular: ExplaiNE <ref type="bibr" target="#b3">(Kang, Lijffijt, and Bie 2019)</ref> quantifies how the predicted probability of a link changes when weakening or removing a link with a neighboring node, while GNNExplainer <ref type="bibr" target="#b8">(Ying et al. 2019)</ref> explains the predictions of any Graph Neural Network, learning a mask over the adjacency matrix to identify the most informative subgraph.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Contributions Defining Ground Truth Explanations</head><p>The weakness of these papers is their evaluation of explanation quality due to the lack of available datasets with ground truth explanations. Evaluating the quality of explanation is essential to determining when to prefer one explanation method over another. Without ground truth explanations, researchers will have difficulties determining if their newly created algorithm is generating high quality explanations. This thesis addresses this issue by defining a method, including datasets and scoring metrics, to quantitatively evaluate these explanation methods. For this thesis, ground truth explanations are defined as a single justification for an entailment. We use an open-source semantic reasoner with rule-tracing capabilities <ref type="bibr" target="#b0">(Corby et al. 2012)</ref> to generate ground truth explanations for each rule we choose to define. For this thesis, we focus on explaining family relationships, as no prior domain knowledge is needed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Benchmarking Non-Ambiguous Explanations</head><p>The first step to quantitatively evaluating explanation methods starts with defining explanations where one and only one possible explanation can exist for some input triple. We define two datasets, Royalty-20k and Royalty-30k <ref type="bibr">(Halliwell, Gandon, and Lecue 2021a)</ref>, where each triple in the training and test set has exactly one set of triples determining why a link exists between the two given entities. Additionally, we propose the use of a scoring metric for non-ambiguous explanations, which involves computing the Jaccard similarity between the predicted and ground truth explanation. Lastly, in the first work of this thesis, we benchmark two state-ofthe-art explanation methods, ExplaiNE and GNNExplainer, using the proposed dataset and scoring metric. In practice, there is often more than one way to explain a prediction. The beginning of this thesis focuses on the simplified case where there is only one way to explain each triple.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Benchmarking Ambiguous Explanations</head><p>When evaluating explanation quality, one must consider that there can be multiple ways to explain why a link could exist between two nodes. In other words, explanations can be nonunique. After defining datasets with only one ground truth explanation, we further expand on this idea of using justifications of an entailment as explanations to address the issue of benchmarking explanation methods with non-unique explanations.</p><p>The second work in this thesis involves designing a method, including a dataset and performance metrics, for evaluating explanations with non-unique explanations. This work focuses on 6 family relationships: hasSpouse, has-Brother, hasSister, hasGrandparent, hasChild, and hasParent. We construct a dataset including all possible explanations for each triples using these 6 family relationships. Furthermore, several scoring metrics are adapted to this task based on the generalized precision and recall <ref type="bibr" target="#b4">(Kekäläinen and Järvelin 2002)</ref>. Indeed the binary precision and recall could be used for this task, however, these metrics fail to account for the fact that some explanations can be more intuitive than others to users. Both metrics would give a score of 1 when a predicted explanation exactly matches a ground truth explanation. However, an explanation method could predict an unintuitive explanation, and receive the highest possible evaluation score, potentially misleading practitioners into thinking the predicted explanation is of high quality. Therefore, scoring metrics used for this task must compare a predicted explanation to all possible explanations, and account for the fact that explanations have different degrees of relevance.</p><p>We conduct a user experiment, where for each predicate, users are shown all possible explanations and asked to assign a score based on how intuitive the explanation is. These user scores are used as relevance scores in the generalized precision and recall adapted for this task. We benchmark Ex-plaiNE and GNNExplainer on this dataset, using these performance metrics. This work was published as <ref type="bibr" target="#b2">(Halliwell, Gandon, and Lecue 2021b)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Remaining Work</head><p>The remainder of this thesis involves two remaining tasks; understanding the role graph embeddings play on the quality of explanation generated by an explanation method, and comparing these state-of-the-art explanation methods against rule based algorithms.</p><p>Understanding the Role of Graph Embeddings on Explanation Generation. Indeed the graph embeddings learned by the RGCN plays some role in the quality of explanation generated by a post-hoc explanation method such as ExplaiNE or GNNExplainer. For all of our previous experiments, the embeddings are kept fixed, i.e., the exact same embeddings are used to benchmark both explanation methods. The extent to which the graph embedding influences the explanation is unknown. One natural question that stems from this idea is if the accuracy of the RGCN is increased or decreased slightly, how does the learned embedding influence the explanations generated by ExplaiNE or GNNExplainer? In other words, is there a relationship between perturbations in a given entity embedding and the performance metrics of the quality of explanation generated? When an explanation method generates an inaccurate explanation, is the explanation method flawed, or is this due to a bad embedding that is not capturing enough information.</p><p>In order to investigate this further, one first step would be to understand what properties of the graph the graph embedding has learned. Indeed this is no trivial task, however, one would want to ensure that a graph embedding captured the relationship between each triple and all its possible sets of explanations. I hope to be able to identify when an explanation method is generating a bad explanation from when the graph embedding model is learning a bad latent representation of the entities. This work may involve adapting the loss function and weight matrices of the RGCN to provide more insights as to what information the embedding is capturing.</p><p>Rule Based Link Prediction. Using an RGCN along with ExplaiNE or GNNExplainer is not the only way to perform explainable link prediction. Rule based methods can also be applied to this task. An interesting experiment would be to compare these rule based approaches to more recent explanation methods such as ExplaiNE and GNNExplainer. As of Fall 2021, rule based methods have not been benchmarked on any datasets constructed during this thesis. All datasets and metrics designed in this thesis are readily available to be used on other link prediction models and explanation methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conclusion</head><p>This thesis allows researchers and practitioners to quantitatively evaluate explanation methods on the task of link prediction on Knowledge Graphs in ways they were previously unable to.</p></div>		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">KGRAM Versatile Inference and Query Engine for the Web of Linked Data</title>
		<author>
			<persName><forename type="first">O</forename><surname>Corby</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gaignard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Faron Zucker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Montagnat</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE/WIC/ACM Int. Conference on Web Intelligence</title>
		<meeting><address><addrLine>Macao, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Linked Data Ground Truth for Quantitative and Qualitative Evaluation of Explanations for Relational Graph Convolutional Network Link Prediction on Knowledge Graphs</title>
		<author>
			<persName><forename type="first">N</forename><surname>Halliwell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Gandon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Lecue</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Web Intelligence and Intelligent Agent Technology</title>
		<meeting><address><addrLine>Melbourne, Australia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">User Scored Evaluation of Non-Unique Explanations for Relational Graph Convolutional Network Link Prediction on Knowledge Graphs</title>
		<author>
			<persName><forename type="first">N</forename><surname>Halliwell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Gandon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Lecue</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Knowledge Capture. Virtual Event</title>
		<meeting><address><addrLine>United States</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2021">2021b</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">ExplaiNE: An Approach for Explaining Network Embedding-based Link Predictions</title>
		<author>
			<persName><forename type="first">B</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lijffijt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">D</forename><surname>Bie</surname></persName>
		</author>
		<idno>CoRR, abs/1904.12694</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Using graded relevance assessments in IR evaluation</title>
		<author>
			<persName><forename type="first">J</forename><surname>Kekäläinen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Järvelin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Assoc. Inf. Sci. Technol</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="issue">13</biblScope>
			<biblScope unit="page" from="1120" to="1129" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Semi-Supervised Classification with Graph Convolutional Networks</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">N</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Int. Conf. on Learning Representations</title>
		<imprint>
			<publisher>ICLR</publisher>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Modeling Relational Data with Graph Convolutional Networks</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Schlichtkrull</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">N</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Bloem</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Van Den Berg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Titov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Semantic Web Conference</title>
		<imprint>
			<publisher>ESWC</publisher>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Embedding Entities and Relations for Learning and Inference in Knowledge Bases</title>
		<author>
			<persName><forename type="first">B</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Yih</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Deng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">3rd International Conference on Learning Representations</title>
		<imprint>
			<publisher>ICLR</publisher>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">GNNExplainer: Generating Explanations for Graph Neural Networks</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Bourgeois</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zitnik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
