<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Data and Machine Learning Model Management with Gypscie</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Patrick</forename><surname>Valduriez</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Data and Machine Learning Model Management with Gypscie</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="laboratory">CARLA 2022 -Workshop on HPC and Data Sciences meet Scientific Computing</orgName>
								<orgName type="institution">SCALAC</orgName>
								<address>
									<addrLine>Sep 2022</addrLine>
									<settlement>Porto Alegre</settlement>
									<country key="BR">Brazil</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Fabio</forename><surname>Porto</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Data and Machine Learning Model Management with Gypscie</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="laboratory">CARLA 2022 -Workshop on HPC and Data Sciences meet Scientific Computing</orgName>
								<orgName type="institution">SCALAC</orgName>
								<address>
									<addrLine>Sep 2022</addrLine>
									<settlement>Porto Alegre</settlement>
									<country key="BR">Brazil</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Data and Machine Learning Model Management with Gypscie</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">EC752A1369948160AE097AA458312692</idno>
					<idno type="DOI">10.1109/ICDE.2017.112</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-04-12T14:50+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract/>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Data and Machine Learning Model Management with Gypscie</head><p>Fabio Porto 1[0000-0002-4597-4832] and Patrick Valduriez 2,<ref type="foot" target="#foot_0">3</ref>[0000-0001-6506-7538]</p><p>1 Laboratório Nacional de Computação Científica, Petropolis, RJ, Brazil 2 Inria, University of Montpellier,CNRS, LIRMM, Montpellier, France fporto@lncc.br, patrick.valduriez@inria.fr</p><p>The synergy of big data and machine learning (ML) has led to the new data science, with many benefits for data-intensive applications in terms of more accurate predictive data analysis and better decision making. For instance, in the context of the HPDaSc (High Performance Data Science) project between Inria and Brazil 3 , we have shown the importance of realtime analytics using ML models to make critical high-consequence decisions, e.g., preventing an oil drill from getting stuck in the ocean subsurface salt layer based on a driller's realtime data, predicting extreme weather events and supporting realtime analytics based on the visualization of simulated data of the cardio vascular system, or the effectiveness of ML to deal with scientific data, e.g., computing Probability Density Functions (PDFs) over simulated seismic data using Spark.</p><p>As predictive analytics using ML models (or models for short) become prevalent in different stages of scientific exploration, a new set of artifacts are produced during the models' life-cycle that need to be managed <ref type="bibr" target="#b1">[2]</ref>. In addition to the models with their evolving versions, ML life-cycle artifacts include the collected training data and pre-processing workflows, data labels and selected features, model training, tuning and monitoring statistics and provenance information. However, to realize the full potential of data science, these artifacts must be built and combined, which can be very complex as there can be many to select from. Furthermore, they should be shared and reused, in particular, in different execution environments such as HPC or Spark clusters.</p><p>In order to support the complete ML life-cycle process and produced artifacts, we have been developing the Gypscie framework, which offers collaborating researchers a common software infrastructure to develop, share, improve and publish ML artifacts. Figure <ref type="figure">1</ref> depicts the framework architecture.</p><p>Gypscie offers a web interface that easy the accomplishment of complex ML model tasks, even by non computer science savvy researchers. It also offers a notebook interface and an API for direct python scripts integration with the framework services. Users can build dataflows graphically to model data preprocessing tasks. Registered dataflows can be scheduled for execution and, during run time, have their activites and involved data recorded for provenance. Models can be trained using registered datasets and have stored the corresponding testing performance metrics. We integrate the Databrics MLFlow component 4 to interface Gypscie with different machine learning execution engines. Three Fig. <ref type="figure">1</ref>. Gypscie Architecture aspects of Gypscie stand out. Multiple-Environments: Tasks in Gypscie can be scheduled in environments that best fit the running process. For data transformation processes, data locality is prioritized and Big Data frameworks like Apache Spark and Dask are usual choices. The Santos Dumont HPC system is a strong candidate for large scale data processing and their usage in large model training. Model composition: Gypscie automatically selects and allocates multiple spatio-temporal deep learning models, using the DJEnsemble approach <ref type="bibr" target="#b2">[3]</ref>. The composition of published models is a particular motivation for sharing models within the framework. SAVIME: A multi-dimensional array in-memory DBMS <ref type="bibr" target="#b0">[1]</ref> that enriches the framework with declarative, SQL-Like, query processing that is used to explore registered datasets and invoke ML models. SAVIME can process the datasets directly from their raw format with no data ingestion cost.</p><p>A first version of Gypscie has been deployed on two different applications. The first one supports oil exploration by managing models that predict the rupture of platforms stabilizers, as well as the corresponding online monitoring data. The second one refers to ML models predicting extreme rainfall events in the city of Rio de Janeiro. The latter runs on a shared-nothing cluster at LNCC and work is in progress to enable scheduling ML training using the Santos Dumont HPC system.</p></div>			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_0"><p>https://team.inria.fr/zenith/hpdasc</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_1"><p>https://github.com/mlflow/mlflow</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Savime: An array dbms for simulation analysis and ml models prediction</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">S</forename><surname>Lustosa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Silva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">R</forename><surname>Da Silva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Valduriez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Porto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Information and Data Management</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2021-02">Feb 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Towards unified data and lifecycle management for deep learning</title>
		<author>
			<persName><forename type="first">H</forename><surname>Miao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">S</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Deshpande</surname></persName>
		</author>
		<idno type="DOI">10.1109/ICDE.2017.112</idno>
		<ptr target="https://doi.org/10.1109/ICDE.2017.112" />
	</analytic>
	<monogr>
		<title level="m">IEEE 33rd International Conference on Data Engineering (ICDE)</title>
		<imprint>
			<date type="published" when="2017">2017. 2017</date>
			<biblScope unit="page" from="571" to="582" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Djensemble: A cost-based selection and allocation of a disjoint ensemble of spatio-temporal models</title>
		<author>
			<persName><forename type="first">R</forename><surname>Pereira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Souto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Chaves</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Zorilla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Tsan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Rusu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Ogasawara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ziviani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Porto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SSDBM 2021</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="226" to="231" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
