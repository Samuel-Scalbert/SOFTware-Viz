<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Facilitating Heterogeneous Dataset Understanding</title>
				<funder ref="#_UAQGPS5 #_WqpB5tw">
					<orgName type="full">unknown</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Nelly</forename><surname>Barret</surname></persName>
							<email>nelly.barret@inria.fr</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Inria</orgName>
								<orgName type="institution" key="instit2">Institut Polytechnique de Paris</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Facilitating Heterogeneous Dataset Understanding</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">F6C6CB08BFFCEA05B806B3C966E3A40B</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-04-12T14:48+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The era of Big Data and data sharing has lead to very large volumes of data becoming available to users across the world. This data is heterogeneous in its modelling, format and quality. Taking full advantage of such data raises many challenges, in particular related to the integration and the understanding of such data. My PhD thesis, started in January 2021, seeks to develop novel methods to help users without advanced IT skills discover a new dataset, by (𝑖) building an abstract understanding of the data, as consisting of records and collections, (𝑖𝑖) interpreting or classifying the data based on users' interests, and leveraging Information Extraction and Natural Language tools.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Since the last decades, the Open Data Initiative has led to an increasing number of publicly-spread datasets. Such datasets are often quite large and heterogeneous (depending on the source provider, the field, the kind of data, etc). Many such datasets are large; further, they are extremely heterogeneous, in particular for what concerns their data model (RDF, JSON, XML, CSV, property graphs, relational databases, etc.), their schema (if a schema exists), etc. The scale and heterogeneity make it challenging for human users to identify, among the many available datasets, those that could be used for a given application they have in mind.</p><p>This thesis is part of the ConnectionLens project <ref type="bibr" target="#b0">[1]</ref>, which aims at integrating heterogeneous data into a graph. Our goal is to create small expressive descriptions of what a dataset is about, using the power of integration of ConnectionLens. In this paper, we present the challenges (Section 2), then the approach (Section 3) and finally some preliminary results (Section 4) before concluding (Section 5).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">CHALLENGES</head><p>Finding the right dataset is complicated, especially because they are often not well-documented and it can be difficult to appreciate how it can be useful. Our approach, which aims at helping users to choose a dataset, should satisfy the following requirements:</p><p>• R1: The approach should be applicable to any kind of data. There are various data formats, such as RDF (as in the Open Data Cloud), but also XML (as in the PubMed database), JSON (most of French open data), relational databases, and so on. This requirement is handled by Section 3.1. • R2: The data descriptions we build for users should be sufficiently expressive, but also compact. Users need to understand what is inside a dataset, but when a full description is complex, we need to bring them only the most important facts about it. We discuss how to fulfil this requirement in Sections 3.2 and 3.3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">APPROACH</head><p>ConnectionLens is a system capable to produce a graph 𝐺 from any dataset of any format, where each node is a piece of data and edges link these nodes to reflect the content of the original source. Moreover, an entity extraction process is applied on text nodes, to extract from them named entities, such as Person, Location, Organization, Date, etc. In my thesis, to be able to produce compact descriptions of any data format, we leverage ConnectionLens to start our summarization method from the graph 𝐺. Our approach is the following:</p><p>(1) Build a structural summary of 𝐺. The structural summary 𝐺 ′ is a graph computed out of 𝐺, potentially much smaller than 𝐺, and which gives us a first idea of groups of nodes that may contain similar information: each such group of 𝐺 nodes is represented by a single node in 𝐺 ′ . (2) Find collections and records. Starting from the summary, we seek to identify the nodes that represent records, that is, objects of a certain "kind" with some internal structure, and collections, that is, containers of potentially many records of the same "kind". (3) Categorize collections. Finally, we aim at classifying collections among a set of categories K, containing (𝑖) the kind(s) of data that the user is looking for, if the user can formulate such a request, e.g., "Books", or "Places to visit", and/or (𝑖𝑖) a set of generic categories we pre-define, such as Person, Organization, Location, Event and Creative work. The categorization adds a limited form of semantics (we keep things simple on purpose since we assume non-technical users), and enable adapting to the users' interest.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Summarization</head><p>We explain now how we compute the summary 𝐺 ′ of 𝐺. For efficiency, we distinguish two cases: rooted, acyclic data source graphs, vs. the general case where graphs may have cycles and/or may not have a root. Rooted acyclic graphs. These graphs are obtained for instance from XML or JSON datasets. On such graphs, we apply the strong DataGuide summarization method <ref type="bibr" target="#b3">[4]</ref> to create 𝐺 ′ from 𝐺. A Dataguide is a concise summary of the structure of a database. This method builds a set of paths, such that each path of the DAG appears exactly once in the summary. Such summarization method works only on acyclic graphs because the recursion should not encounter a cycle.</p><p>General graphs. Such graphs can originate in RDF, property graphs, or relational database datasets (where primary-foreign keys can lead to cyclic connections between the tuples). For such graphs, we need a graph summarization method that (𝑖) reflects all the graph, (𝑖𝑖) groups nodes into equivalence classes and (𝑖𝑖𝑖) can be computed efficiently even from large graphs. RDFQuotient <ref type="bibr" target="#b2">[3]</ref>, originally introduced for RDF but easy to adapt to arbitrary graphs, meets these criteria, thus we rely on it to compute the summary 𝐺 ′ of 𝐺 for non-acyclic graphs. RDFQuotient gives a set of equivalence classes between nodes based on their types and their properties.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Records and Collections</head><p>We seek to understand 𝐺 ′ based on two key concepts:</p><p>• A Record is basically a thing; in data modelling terms, it describes either an entity or a relationship. It has some properties (e.g. a title and a DOI for a paper) and can handle nested collections (e.g. the authors list of a paper). • A Collection is a set of similar records (e.g. a bibliography is a collection of books). They are explicit when a node handles similar records; or implicit when some records refer to the same purpose without being handled by a node. Other nodes in 𝐺 ′ are called Sub-Records and are mainly the properties of the records (i.e. the set of outgoing properties of a record 𝑟 , referred as 𝑟 .P). Furthermore, we compute the signature of each sub-record 𝑠, where the signature is compound of a domain ("to which categories 𝑠 belongs to?") and a range ("to which categories 𝑠 points to?"). For example, the sub-record settledDownIn has for domain {Person, Organization} and for range {Location}.</p><p>To find them, we first determine collections and then, in a topdown fashion, the direct children of collections are identified as records. To compute collections, we rely on a clustering algorithm we devised, based on the support of a set of properties among a set of potential records (how many of these records have this set of properties). Our clustering algorithm identifies both explicit collections, where a 𝐺 ′ node is actually the parent of all the nodes representing the records in the collection, and implicit collections, where such a common parent/collection node does not exist in 𝐺 ′ .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Analysis and Categorization of Collections</head><p>Given a set of hints H and a set of user-defined categories K, we aim at categorizing a collection 𝑐 among K, i.e. give a category 𝑘 ∈ K to 𝑐 using H , as illustrated by Algorithm 1. A hint ℎ is a triple ⟨𝐴, 𝑙, 𝐵⟩ where A is the domain ⊆ K, 𝑙 is the label and 𝐵 is the range ⊆ K. For instance, the hint ⟨Organization, hasCEO, Person⟩ states that a collection having a record holding the property hasCEO, whose signature's range matches Person, should be categorized as an Organization.</p><p>For each record 𝑟 ∈ 𝑐, we initialize K 𝑟 (set of candidate categories in which 𝑟 may belong) and scores (score of 𝑛𝑐 for each hint in H ). Then, if 𝑟 has a label semantically close to one of the category in K, this category is stored as a candidate category in K 𝑟 . For each child 𝑛𝑐 ∈ 𝑟 , we create a pair 𝜋 containing the label and the signature of 𝑛𝑐. Then, we compute the similarity of 𝜋 with each hint ℎ in H , where the similarity is based on the label and the signature of both elements. We choose the hint ℎ leading to the highest similarity score for each 𝜋. Each category indicated by the domain of ℎ gets a vote. Then, we classify 𝑟 in the category that gets the highest number of votes or Other if no category is frequent enough. Finally, we classify 𝑐 in the most represented category in its records. We also determine if a collection describes entities or relationships, by looking at the connections between the collections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">STATUS</head><p>We have fully implemented our approach in a prototype, which leverages the graph creation and storage of ConnectionLens <ref type="bibr" target="#b0">[1]</ref>, and includes the novel algorithms described in Section 3. More details can be found in a short paper <ref type="bibr" target="#b1">[2]</ref>. Figure <ref type="figure" target="#fig_0">1</ref> shows an example of our approach applied on a set of PubMed articles. The set of articles is considered as a collection of Creative Work. Moreover, the authors are identified as a collection of Persons.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">CONCLUSION AND PERSPECTIVES</head><p>My PhD thesis aims to create expressive descriptions of big heterogeneous datasets by using summarization methods and categorization of expressive structures (records and collections). Beyond finalizing the implementation of our platform for all the data models we consider (notably, beyond XML and RDF, also JSON and property graphs), we will experiment to analyse its scalability as well as the expressiveness and precision of the record categorization. Next, we will investigate the adoption of sampling-based approaches, to try to construct such dataset descriptions without traversing the dataset entirely, in order to further improve performance. Thesis context My PhD is funded by DIM RFSI and is a collaboration between Inria and WeDoData, a SME specialized in data visualization and interactive data-driven Web content. My PhD advisers are Ioana Manolescu (Inria) and Karen Bastien (WeDoData).</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Algorithm 1 :</head><label>1</label><figDesc>Classifying a collection 𝑐Input: a collection 𝑐, hints H, categories K Output: a category 𝑘 ∈ K or Other 1 foreach 𝑟 ∈ C do 2 between 𝑘 and the label of 𝑟 is higher than a threshold then 6 K𝑟 ← K𝑟 ∪ {𝑘 } 7 foreach 𝑛𝑐 ∈ 𝑟 .children do 8 𝜋 ← (𝑛𝑐.𝑙𝑎𝑏𝑒𝑙, 𝑛𝑐.𝑠𝑖𝑔𝑛𝑎𝑡𝑢𝑟𝑒) 9 foreach ℎ ∈ H do 10 scores ← scores (ℎ, 𝑠𝑖𝑚 (𝜋, ℎ)) 11 bestHint ← argmax(scores) 12 K𝑟 ← K𝑟 ∪ { bestHint.domain } 13 Classify 𝑟 in the most frequent 𝑘 ∈ K𝑟 , or Other 14 Classify 𝑐 with the most frequent category of its records</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Example of 𝐺 ′ , an abstract graph with collections and categorized records.</figDesc><graphic coords="3,324.59,239.39,226.97,141.11" type="bitmap" /></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><p>Acknowledgments. This work is funded by <rs type="grantNumber">DIM RFSI PHD 2020-01</rs> and <rs type="projectName">AI Chair SourcesSay</rs> project (<rs type="grantNumber">ANR-20-CHIA-0015-01</rs>) grants.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funded-project" xml:id="_UAQGPS5">
					<idno type="grant-number">DIM RFSI PHD 2020-01</idno>
					<orgName type="project" subtype="full">AI Chair SourcesSay</orgName>
				</org>
				<org type="funding" xml:id="_WqpB5tw">
					<idno type="grant-number">ANR-20-CHIA-0015-01</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Graph integration of structured, semistructured and unstructured data for data journalism</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Anadiotis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Balalau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Conceicao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Galhardas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">Y</forename><surname>Haddad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Manolescu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Merabti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>You</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021-07">July 2021</date>
		</imprint>
		<respStmt>
			<orgName>Information Systems</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Toward generic abstractions for data of any model</title>
		<author>
			<persName><forename type="first">N</forename><surname>Barret</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Manolescu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Upadhyay</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note>Short paper, accepted for publication at BDA 2021</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">RDF graph summarization for firstsight structure discovery</title>
		<author>
			<persName><forename type="first">F</forename><surname>Goasdoué</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Guzewicz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Manolescu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The VLDB Journal</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">5</biblScope>
			<date type="published" when="2020-04">Apr. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Dataguides: Enabling query formulation and optimization in semistructured databases</title>
		<author>
			<persName><forename type="first">R</forename><surname>Goldman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Widom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">VLDB</title>
		<imprint>
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
