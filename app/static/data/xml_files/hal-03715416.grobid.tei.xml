<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Privacy-Preserving Synthetic Educational Data Generation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Jill-Jênn</forename><surname>Vie</surname></persName>
							<email>jill-jenn.vie@inria.fr</email>
							<affiliation key="aff0">
								<orgName type="laboratory">SODA</orgName>
								<orgName type="institution">Inria Saclay</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Tomas</forename><surname>Rigaux</surname></persName>
							<email>tomas.rigaux@inria.fr</email>
							<affiliation key="aff0">
								<orgName type="laboratory">SODA</orgName>
								<orgName type="institution">Inria Saclay</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Sein</forename><surname>Minn</surname></persName>
							<email>sein.minn@inria.fr</email>
							<affiliation key="aff1">
								<orgName type="laboratory">CEDAR</orgName>
								<orgName type="institution">Inria Saclay&apos;Orves</orgName>
								<address>
									<addrLine>1 rue Honoré d&apos;Estienne d</addrLine>
									<postCode>91120</postCode>
									<settlement>Palaiseau</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Privacy-Preserving Synthetic Educational Data Generation</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">5171AB39E4CF060B2788FF7E82FB6C2E</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-04-12T14:45+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Generative models</term>
					<term>Privacy</term>
					<term>Item response theory</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Institutions collect massive learning traces but they may not disclose it for privacy issues. Synthetic data generation opens new opportunities for research in education. In this paper we present a generative model for educational data that can preserve the privacy of participants, and an evaluation framework for comparing synthetic data generators. We show how naive pseudonymization can lead to re-identification threats and suggest techniques to guarantee privacy. We evaluate our method on existing massive educational open datasets.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Educational platforms collect massive amounts of data related to human learning. These can be used to personalize education, train AI-assisted learning systems, but using this data may also harm privacy <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b1">2]</ref>. The General Data Protection Regulation (GDPR) protects any information relating to an identified or identifiable natural person. GDPR concerns pseudonymized data, i.e. processing "so that personal data can no longer be attributed to a specific data subject without the use of additional information" (Art. 4 3 ) but does not concern anonymized data, i.e. "personal data rendered anonymous in such a manner that the data subject is not or no longer identifiable" (Recital 26 4 ).</p><p>Privacy risk is hard to quantify, as an open dataset can be archived indefinitely, open datasets can be combined, and technology for re-identification is improving over time. There have been a huge number of privacy issues after the re-identification of pseudonymized data <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b24">25]</ref>. When a movie-streaming service organized a 1-million-dollar data challenge, some researchers managed, using solely the movie ratings from the pseudonymized dataset, to match IMDb profiles with the zip code of participants in the pseudonymized dataset <ref type="bibr" target="#b17">[18]</ref>.</p><p>In this paper, we are interested in generating truly anonymized educational records: data that does not belong to anybody, but still shares some interesting properties than real datasets, in order to power technology-enhanced learning. Our contribution is twofold. We first show how we can generate logs of data using generative models such as Markov chains or neural networks. We also define a way to practically measure re-identification risk and show how naive pseudonymization techniques, such as dropping a set of rows, or renumbering IDs, are not enough to ensure the privacy of participants. One of our methods is easily scalable as it can generate 1 million rows in 3 seconds while preserving utility and respecting privacy.</p><p>This study provides opportunities to open more datasets: instead of just releasing simple statistics, institutions and governments could also provide synthetic datasets so that citizens could provide personalized, innovative solutions for preparing for national examinations. This would benefit research communities such as technology enhanced-learning, educational data mining, and learning analytics, as today it is extremely hard for researchers to have access to student data that is considered too sensitive.</p><p>We first review related work, then introduce the task of privacy-preserving synthetic data generation. We then explain our framework for evaluation, the experiments we made on two real educational datasets, and finally discuss our results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related work</head><p>In order to protect data, mechanisms such as k-anonymity have been considered, i.e. processing the data so that any person is indistinguishable from k -1 other ones in a dataset. However, when we consider high dimensional data, such as mobile geolocation data or educational logging data, then few points are enough to make people unique, therefore k-anonymity is no longer feasible: <ref type="bibr" target="#b5">[6]</ref> showed that 4 timestamp-location points are needed to uniquely identify 95% of individual trajectories in a dataset of 1.5M rows. The uniqueness of a user in a dataset was defined by <ref type="bibr" target="#b24">[25]</ref>, which showed that 15 demographic points are enough to re-identify 99.96% of Americans. k-anonymity also has limitations, as sensitive attributes can be inferred either due to a lack of diversity or using external knowledge <ref type="bibr" target="#b16">[17]</ref>.</p><p>Some educational research communities attach importance to synthetic or simulated data; while others are mainly interested in real data. For example, in psychometrics, the science of measurement, the validity of a student response model is usually both shown on simulated and real data. "Pseudo-students" can also be used to test the quality of an instructional design <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b28">29]</ref>. Generative models, recently famous for deep fakes, are mainly encountered in automatic exercise generation <ref type="bibr" target="#b2">[3]</ref>, simulated response patterns, or student performance prediction, rarely for the generation of a whole dataset. There is a trade-off between generating data that is completely fake, and not very useful; and data that is useful, however easy to re-identify.</p><p>A direct identifier is a specific information that references an individual, such as a name, an e-mail address, or an identification number. A quasi-identifier<ref type="foot" target="#foot_1">5</ref> is any piece of information, be it a geographical position at a certain time, or even an opinion on some topic, that could be used, possibly in combination with other quasi-identifiers, with the purpose of re-identifying an individual. In this paper, we are interested to illustrate what can be done using only three simple columns: user ID, item ID and outcome, whether the user got a correct attempt on the item. Our approach can naturally be generalized to several columns, by estimating the conditional probability distributions between variables in order to generate new data that respects those distributions. There are several toolkits to do so, based on Bayesian networks, e.g. sdv.dev <ref type="bibr" target="#b18">[19]</ref>; however, in most of them, there is no measurement of re-identification risk.</p><p>Item response theory: estimating outcome given user and item parameters Response models can be used for estimating both the difficulty of exercises in a questionnaire and the latent abilities of examinees. The Rasch model <ref type="bibr" target="#b23">[24]</ref>, also called 1-parameter logistic, is the most famous and simplest item response theory model (we will denote it by IRT). It is used in real-world adaptive tests such as GMAT, and can also be used to generate synthetic response data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>P r(R</head><formula xml:id="formula_0">ij = 1) = σ(θ i -d j )</formula><p>where R ij is 1 if user i answers item j correctly, σ : x → 1/(1 + exp(-x)) is the sigmoid function, θ i represents the ability parameter of user i and d j represents the difficulty of item j.</p><p>Privacy-preserving, one row per user Differential privacy <ref type="bibr" target="#b8">[9]</ref> (DP) is a theoretical framework for proving that the output of a generative model will be indistinguishable by a parameter ε &gt; 0 had a user be present or absent in the training data. It is hard to know which value of epsilon is needed <ref type="bibr" target="#b14">[15]</ref>, but it is related to the budget of queries we can make to the generative model. DP usually relies on adding noise to model weights and is useful for performing queries with privacy guarantees such as histograms <ref type="bibr" target="#b0">[1]</ref>, n-grams statistics <ref type="bibr" target="#b3">[4]</ref>. More rarely, DP has been applied to privacy-preserving data generation, usually in settings where there is only one record per user. This is why privacy-preserving Bayesian networks have been proposed such as PrivBayes <ref type="bibr" target="#b30">[31]</ref>, implemented in the Python package DataSynthesizer <ref type="bibr" target="#b22">[23]</ref>. In <ref type="bibr" target="#b7">[8]</ref>, DataSynthesizer is illustrated on real educational data.</p><p>Several rows per user In our setting, we have several records per user, and we are dealing with the interaction of two entities, users and exercises, that we don't want to protect equally. We want to protect user data, but we want to be able to precisely estimate exercise difficulty. If we were just adding noise to IRT parameters, we would be blurring the utility of our item bank. Once we move to high-dimensional scenarios, such as time series, or logging data at irregular time intervals, there are several observations available for each user, and this may arbitrarily increase the risk of re-identification. For example, <ref type="bibr" target="#b15">[16]</ref> is collecting typing data in order to predict programming experience. They show that delay between keystrokes is enough to re-identify people, but by rounding or bucketing those values, they can still achieve good prediction for the task at hand while reducing re-identification. If the blur is not big enough, people can still be re-identified <ref type="bibr" target="#b5">[6]</ref>. 3 Privacy-Preserving Synthetic Data Generation</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Goal</head><p>A synthetic dataset should have several properties:</p><p>Utility The fake dataset should bear a strong similarity to the real dataset (histograms, similar results to queries). Also if we conduct a study, e.g. estimating item difficulties using an IRT model, the learned parameters should be similar for both the real and the generated dataset.</p><p>Privacy It should not be easy to re-identify participants in the real dataset from the synthetic dataset.</p><p>For example, it is easy to generate random noise, and complete dummy datasets with guaranteed privacy, but it won't be useful if we do not preserve correlation between columns.</p><p>For the sake of simplicity, we assume that the data is provided as triplets (i, j t , r t ) = (userID, actionID, outcome) where the outcome r t is 1 if user i makes a successful action j t and 0 otherwise. See Table <ref type="table" target="#tab_0">1</ref> for an example of such dataset.</p><p>We first need a model of sequence prediction, to identify which action comes next. Formally, we need a model of p(j t+1 |j t , . . . , j 1 ). Then, we need a response model p(r t |i, j t ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Sequence generation</head><p>Markov chains This simple probabilistic graphical model has been used for generating text, music, etc. It relies on a probability transition for jumping from one action to another: P su = Pr(j t+1 = u|j t = s) is the probability to jump from action s to action u. The Markov chain is trained on existing corpus of actions. Once the P matrix has been estimated, it can be used to sample a random walk from action to action. A Markov chain is said memoryless because the next action only depends on the current action: p(j t+1 |j t , . . . , j 1 ) = p(j t+1 |j t ).</p><p>Recurrent neural networks Neural networks are famous for natural language processing, and generation. RNNs have been used in knowledge tracing for predicting student performance <ref type="bibr" target="#b21">[22]</ref>. They have many more parameters, so they can remember more than simple Markov chains, but they are way slower to train. Some works have shown that a simple updated IRT model could match the performance of RNN <ref type="bibr" target="#b29">[30]</ref> for knowledge tracing. <ref type="bibr" target="#b9">[10]</ref> has shown that it depends on how much the dataset contains long sequences and if the sequential aspect of the dataset is prominent. A Gated recurrent unit (GRU) is an example of RNN. In our case, the input is sequence (j 1 , . . . , j t ) and the output is sequence ( j 2 , . . . , j t+1 ) and GRU computes:</p><formula xml:id="formula_1">s t = σ (W j t + U h t-1 + b) z t = σ (W ′ j t + U ′ h t-1 + b ′ ) ĥt = tanh (W ′′ + U ′′ (s t * h t-1 ) + b ′′ ) h t = (1 -z t ) * h t-1 + z t * ĥt h 0 = 0 j t+1 = argmax(W ′′′ h t + b ′′′ )</formula><p>where σ is the same sigmoid function as in IRT, * denotes element-wise product, and parts of input and output where shown in red for clarity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Response pattern generation</head><p>Once the sequence of skills has been generated, what is left is to generate outcomes. For this we use the Rasch model:</p><formula xml:id="formula_2">p(r t = 1|i, j t ) = σ(θ i -d jt ).</formula><p>We fit an IRT model on the training dataset to learn the θ i ability of each user i and the difficulty d j of each action j. Then, to generate new users, we just need to fit a normal distribution on the histogram of existing θ values and sample from it to generate responses using the IRT model and the estimated action difficulties d j , see Figure <ref type="figure" target="#fig_0">1</ref>. This is the core of our strategy: as the generated j t and the sampled θ do not correspond to any particular user anymore, the generated dataset should be anonymous.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Evaluation Framework</head><p>To compare strategies for educational data generation, our architecture is described in Figure <ref type="figure" target="#fig_1">2</ref> and explained in this Section. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Training set sampling and generation</head><p>For each original dataset, we first sample a training set that will be used to train the generators. This training set contains the rows that belong to half of all users. Then our models will generate new, synthetic (or fake) tabular datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Utility</head><p>To compare the real and fake sets, we first compute some histograms for the real and generated sequences: a number of occurrences of each action, sequence lengths, and distribution of repeated skills.</p><p>Once the fake dataset has been generated, we want to know whether training an IRT model to estimate the difficulty of actions has similar findings on the real dataset and on the fake dataset. We compute the root mean squared error of action difficulty parameters learned by IRT between the training set and the fake set. The weighted RMSE (denoted wRM SE) is given by the following formula:</p><formula xml:id="formula_3">wRM SE = N i=1 w i (d i -di ) 2</formula><p>The usual RMSE is when all actions are equally weighted, i.e. w i = 1/N for all i. However some actions are less frequent than others, so it is normal that their parameter is not well estimated. Therefore we also introduce a weighted RMSE where w i corresponds to the frequency of action i in the training set, i.e. its number of occurrences divided by the size of the training set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Reidentification score</head><p>As a measure of how easy it is to re-identify people, we borrow the practical task of membership inference encountered in <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b26">27]</ref>. We assume that an adversary has access to the original dataset (e.g. some auxiliary information about the population from the outside world) and the fake generated dataset, and wants to guess which users were in the training set. This is a classification problem where for each user in the original dataset, we want to guess 1 if it was present in the training set used to generate the fake set, and 0 otherwise. We will now give examples of why membership inference is already an issue: if the dataset used for training the fake set corresponds to some query, i.e. "students with special needs" or "students having a certain socioeconomic status", then membership inference is already something that may harm privacy. More generally, if one person can be re-identified just by a few actions, then using other sources of information (e.g. cookies, other databases), these actions can be used to uniquely describe this user, and re-identify them in other databases. This is exactly the example of the Netflix Prize <ref type="bibr" target="#b17">[18]</ref>. Once a classifier is performing membership inference, its performance can be evaluated using the area under the ROC curve (AUC), a number between 0 and 1. Any random guess should have an AUC of 0.5, as half of the original people belong to the training set, as stated in Section 4.1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Datasets</head><p>Datasets are described below and their statistics are reported in Table <ref type="table" target="#tab_1">2</ref>. Median refers to the median across all users of the median number of repeats for each skill. Max refers to the maximum across all users of the maximum number of repeats for a skill.</p><p>Assistments 2009 This dataset contains 279,000 outcomes of 4,163 students attempting math exercises. Each exercise is mapped to one among 112 knowledge components in Mathematics <ref type="bibr" target="#b10">[11]</ref>. This dataset is popular in the Educational Data Mining community, notably for knowledge tracing. Here, we consider that a skill corresponds to an action.</p><p>Duolingo 2018 This massive dataset contains the outcomes of 1,213 Englishspeaking people learning French. It contains 1.2M logs of users attempting to type words in the Duolingo app. The actions are the words expected in the correct answer, and the outcomes are at the word level: 1 for a correctly typed word, 0 for a spelling mistake, see again Table <ref type="table" target="#tab_0">1</ref> on page 4 for an example. This dataset was part of the Duolingo competition at NAACL-HLT 2018 for a knowledge tracing task <ref type="bibr" target="#b25">[26]</ref>.</p><p>We remove actions where the success rate is either 0% or 100%, as those are either too easy or impossible to get right, and their corresponding IRT parameters are ±∞. For example, in the Duolingo dataset, the French word « train » had 0% success rate. We were surprised so we looked at the expected sentences and discovered that it was in fact the « en train de » locution, which is the translation of the -ing form in English, which is hard to get right for English people learning French ("She is eating" ↔ « Elle est en train de manger »). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Generative models</head><p>Baseline Drop As a baseline, we drop a certain amount of rows from the training set (a ratio r ∈ {0., 0.25, 0.5, 0.75, 0.99, 0.999}), then randomize user IDs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Markov chain</head><p>The Markov chain for generating actions was implemented using the lea Python package for discrete probability distributions <ref type="bibr" target="#b6">[7]</ref>. As parameters, we define a length limit of 1000 for Assistments and 10000 for Duolingo. Our Markov chain takes 3 seconds to train and generate the Duolingo dataset.</p><p>RNN Our recurrent neural network is a Gated Recurrent Unit (GRU) implemented in PyTorch. The batch size was 64 for Assistments and 16 for Duolingo. We minimize the cross entropy loss of observed actions using the Adam optimizer <ref type="bibr" target="#b13">[14]</ref>. Training takes approximately two hours for the Duolingo dataset. It is trained on smaller sequences first then longer sequences.</p><p>IRT For generating the outcomes from user parameters and actions, we use a Rasch model denoted by IRT, implemented as LogisticRegression in the scikit-learn package <ref type="bibr" target="#b20">[21]</ref>. We use the default regularization parameter C = 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Re-identification model</head><p>We compute, for each original sequence, the longest common subsequence with each fake sequence in the fake dataset. This is performed in O(ℓℓ ′ ) time for a pair of sequences of lengths ℓ and ℓ ′ , so O(M N ) in total where M is the size of the original dataset and N the size of the fake dataset. Our implementation is written in C++.</p><p>Then we take the maximum of those matching scores divided by the length of the fake sequence, i.e. best-normalized percentage of matching. It gives a matching score for each original user, used for the classification task of membership inference. The quality of re-identification is estimated using AUC.</p><p>We limit the re-identification to users with enough information. More precisely, we define the cumulative entropy of a user as t -p(j t ) log p(j t ), where (j t ) t is its sequence of actions and p(j) the frequency of action j in the original dataset. We then only try to re-identify users with an entropy larger than -p log p for p the proportion of users in the training dataset (p = 0.5 in our experiments), i.e. the entropy of the information "user as part of the training dataset". In Assistments this induces filtering of 15% of users while in Duolingo it does not change anything, as sequences are already pretty long and diverse, so they contain a lot of information already.</p><p>Our experiments can be reproduced using our code which is free and open source software<ref type="foot" target="#foot_2">6</ref> .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Results and Discussion</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">First look at the synthetic datasets</head><p>We first compare the histogram of actions in Figure <ref type="figure" target="#fig_2">3</ref>, where Base represents the training set. We see that the Markov chain, a very simple model, approximates the skill histograms better than RNN. We give examples of generated sequences from our approach on the Duolingo dataset in Table <ref type="table" target="#tab_2">3</ref>. For clarity, we do not display the outcomes, only actions which are French words. Markov chains are simple, but it is a memoryless process that explains why bigrams (consecutive words) are preserved but not whole sentences (e.g. « Il faut du fromage et juin à midi »). RNNs are longer to train but they can preserve longer contexts, such as generating several sentences in the same theme (food for the second sentence, or animals in the third sentence), like in the original dataset. However, it may not preserve bigrams (e.g. « des robe »). Quantitative results are provided in Table <ref type="table" target="#tab_3">4</ref> and Figure <ref type="figure" target="#fig_3">4</ref>. Drop baselines with ratios of 0.5 and 0.75 are the worst of possible worlds: loss in estimation quality of the action difficulty parameters, and easy membership inference. What is quite remarkable is that on the Duolingo dataset, even if we drop 75% of rows, it is still possible to exactly recover 100% of the training set. This is probably because there are more tokens and sequences are longer (the minimal length is 90 and the median length is 742), so people are more easily unique.</p><p>Markov chain and RNN have comparable quality RMSE scores to the Drop baseline for low ratio. But even Drop 0, which corresponds to keeping all lines and rewriting the user IDs, is very easy to re-identify (AUC 0.913), which shows that simple pseudonymization is not enough. Therefore, the best models are Markov chain and RNN, which is particularly visible in Figure <ref type="figure" target="#fig_3">4</ref>. This means we can freely share the fake dataset: it will follow a similar distribution to the real one, but the underlying "users" do not exist; they cannot be re-identified.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Limitations, impact and future work</head><p>A limitation is that so far we consider a model of evolution for the skill j, i.e. the question that is assessed at each time, but not for the user ability θ, i.e. a learning model. Natural extensions would be to consider knowledge tracing models such as PFA <ref type="bibr" target="#b19">[20]</ref> or more sophisticated ones such as DAS3H <ref type="bibr" target="#b4">[5]</ref>, to get dynamic models of learning.</p><p>In future work, we'd like to test our setting on more sophisticated tabular datasets: users would be even more unique. We notably want to work on timestamps, as the delays between attempts may be unique between participants, therefore may harm privacy. In this paper, we were interested in learning item difficulties, but other applications may have a different objective to optimize. We want to highlight the fact that for the sake of researchers in technology-enhanced learning, item parameters should be as open as possible; while for the sake of students, user parameters should be kept as private as possible.</p><p>The example shown in this paper helps raise awareness in what can be done with student data. Our re-identification task of membership inference may seem a bit weak, so here is a more precise example. Let us now assume that for the sake of providing accurate recommendations, a dataset of student logs with a particular condition, say ADHD, is shared. We show that it could be possible, having access to a bigger dataset of students logs, to identify which students have ADHD. Personalized education should be able to provide further help to students with special needs, without letting anyone know which student has what condition.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Conclusion</head><p>In this paper, we show how we can generate educational data records for research while preserving the privacy of real users. We illustrated that naive pseudonymization or dropping rows from a dataset is not enough, as techniques based on text mining can re-identify who was in the training set. Our approach generates fake users, thus anonymized data that can be freely shared. We advocate for more open datasets to nurture educational research and foster technology-enhanced learning; but privacy-preserving, synthetically generated ones.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. From the estimated θ parameters from the training set, it is easy to fit a Gaussian and sample new users from it.</figDesc><graphic coords="7,236.81,115.84,141.73,94.49" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. The architecture of our study</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Histogram of actions for the original and generated datasets by Markov chain and RNN.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 4 .</head><label>4</label><figDesc>Fig.<ref type="bibr" target="#b3">4</ref>. The trade-off between quality (low weighted RMSE) and privacy (low reidentification AUC) for all models considered. The bottom left is better.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>Example of minimal tabular dataset.</figDesc><table><row><cell cols="3">user ID action ID outcome</cell><cell>description</cell></row><row><cell>2487</cell><cell>384</cell><cell>1</cell><cell>user 2487 got token "I" correct</cell></row><row><cell>2487</cell><cell>242</cell><cell>0</cell><cell>user 2487 got token "ate" incorrect</cell></row><row><cell>2487</cell><cell>39</cell><cell>1</cell><cell>user 2487 got token "an" correct</cell></row><row><cell>2487</cell><cell>65</cell><cell>1</cell><cell>user 2487 got token "apple" correct</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 .</head><label>2</label><figDesc>Statistics for the datasets considered in the study.</figDesc><table><row><cell>Dataset</cell><cell>Size Users Actions</cell><cell cols="2">Repeated actions Med Max</cell><cell cols="3">Sequence length Min Med Max</cell></row><row><cell cols="2">Assistments 2009 279k 4163 112</cell><cell>3</cell><cell>144</cell><cell>1</cell><cell>20</cell><cell>1021</cell></row><row><cell cols="2">Duolingo SLAM 2018 1.2M 1213 2416</cell><cell>1</cell><cell>4</cell><cell>90</cell><cell cols="2">742 10008</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 .</head><label>3</label><figDesc>Original vs. generated Duolingo sequences. La femme Je suis rouge L' homme Je suis riche Je mange Il est riche Je suis calme 2. Je suis riche Je suis rouge L' homme Je mange Il est riche Je suis calme ... 3. Je suis rouge Je suis riche L' homme Il est riche Je mange Je suis calme ... 4. ... Les chiens Les chiens Vous êtes grand Je mange des baguettes Markov generated 1. Le costume La bière est rouge Les filles mangent Cet homme est riche 2. Aux mois d' accord Tu es grande Je parle Qui suis riche L' éléphant Ma femme 3. Le tigre Le menu Le sac est un costume Quoi Combien Oui je vais bien 4. Quatorze enfants C' est violet Ma robe Il faut du fromage et juin à midi Vous avez un animal Vous mangez une secrétaire Sinon je sais Le cheval gagne Ça va Oui je sais Je motive mon chien RNN generated 1. Nous mangeons Nous apprenons Je parle Il parle Je parle Je sais Il faut J' aime le fromage Je veux veux un poisson 2. Le bonbon est rouge J' aime boire La carotte J' aime manger Un oeuf La confiture Je bois une boisson rouge 3. Tu es en train de manger Un dauphin Le chat est noir Le éléphant est vert 4. Il faut du pain Elle pose des chats Les chiennes Il pleut des frites Ces enfants mangent des robe 6.2 Quality and re-identification trade-off</figDesc><table><row><cell>1.</cell></row><row><cell>Original</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 .</head><label>4</label><figDesc>Results. RMSE should be low for good utility and Re-identification AUC should be low for good privacy. The best results are shown in bold.</figDesc><table><row><cell>Dataset</cell><cell>Metric</cell><cell>0.</cell><cell>Drop 0.25 0.5 0.75 0.99 0.999</cell><cell>MC RNN</cell></row><row><cell>ASSISTments 2009</cell><cell cols="4">RMSE wRMSE 0.000 0.035 0.064 0.105 0.481 0.692 0.065 0.061 0.000 0.093 0.147 0.283 0.719 0.833 0.245 0.213 Re-ID AUC 0.913 0.776 0.680 0.588 0.497 0.497 0.495 0.508</cell></row><row><cell>Duolingo SLAM 2018</cell><cell cols="4">RMSE wRMSE 0.000 0.067 0.113 0.195 0.624 0.985 0.114 0.143 0.000 0.208 0.308 0.450 0.730 0.793 0.369 0.431 Re-ID AUC 1.000 1.000 1.000 1.000 0.554 0.506 0.511 0.516</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>⋆ Equal contribution. 3 https://gdpr-info.eu/art-4-gdpr/ 4 https://gdpr-info.eu/recitals/no-26/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_1"><p>https://edps.europa.eu/system/files/2021-04/21-04-27_aepd-edps_ anonymisation_en_5.pdf</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_2"><p>https://github.com/Akulen/PrivGen</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Differentially private histogram publishing through lossy compression</title>
		<author>
			<persName><forename type="first">G</forename><surname>Acs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Castelluccia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE 12th International Conference on Data Mining</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2012">2012. 2012</date>
			<biblScope unit="page" from="1" to="10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Ai in education: learner choice and fundamental rights</title>
		<author>
			<persName><forename type="first">B</forename><surname>Berendt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Littlejohn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Blakemore</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Learning, Media and Technology</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="312" to="324" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">An authoring tool for semi-automatic generation of self-assessment exercises</title>
		<author>
			<persName><forename type="first">B</forename><surname>Cablé</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Guin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lefevre</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Artificial Intelligence in Education</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="679" to="682" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Differentially private sequential data publication via variable-length n-grams</title>
		<author>
			<persName><forename type="first">R</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Acs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Castelluccia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2012 ACM conference on Computer and communications security</title>
		<meeting>the 2012 ACM conference on Computer and communications security</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="638" to="649" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">DAS3H: modeling student learning and forgetting for optimally scheduling distributed practice of skills</title>
		<author>
			<persName><forename type="first">B</forename><surname>Choffin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Popineau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bourda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Vie</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1905.06873</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Unique in the crowd: The privacy bounds of human mobility</title>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">A</forename><surname>De Montjoye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A</forename><surname>Hidalgo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Verleysen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">D</forename><surname>Blondel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Scientific reports</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="5" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Probabilistic inference using generators: The statues algorithm</title>
		<author>
			<persName><forename type="first">P</forename><surname>Denis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Science and Information Conference</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="133" to="154" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Using synthetic data generators to promote open science in higher education learning analytics</title>
		<author>
			<persName><forename type="first">M</forename><surname>Dorodchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Al-Hossami</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Benedict</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Demeter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2019 IEEE International Conference on Big Data (Big Data)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="4672" to="4675" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Differential privacy: A survey of results</title>
		<author>
			<persName><forename type="first">C</forename><surname>Dwork</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on theory and applications of models of computation</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="1" to="19" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">When is deep learning the best approach to knowledge tracing</title>
		<author>
			<persName><forename type="first">T</forename><surname>Gervet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Koedinger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schneider</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Mitchell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Educational Data Mining</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="31" to="54" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">The assistments ecosystem: Building a platform that brings scientists and teachers together for minimally invasive research on human learning and teaching</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">T</forename><surname>Heffernan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">L</forename><surname>Heffernan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Artificial Intelligence in Education</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="470" to="497" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">ETHICS in AIED: Who Cares? An EC-TEL workshop</title>
		<author>
			<persName><forename type="first">W</forename><surname>Holmes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Iniesto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sharples</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Scanlon</surname></persName>
		</author>
		<ptr target="http://oro.open.ac.uk/67263/" />
	</analytic>
	<monogr>
		<title level="m">EC-TEL 2019 Fourteenth European Conference on Technology Enhanced Learning</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Jordon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Jarrett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yoon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Barnes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Elbers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Thoral</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ercole</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Belgrave</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Van Der Schaar</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2007.12087</idno>
		<title level="m">Hide-and-seek privacy challenge</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">How much is enough? choosing ε for differential privacy</title>
		<author>
			<persName><forename type="first">J</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Clifton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Information Security</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="325" to="340" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Preventing keystroke based identification in open data sets</title>
		<author>
			<persName><forename type="first">J</forename><surname>Leinonen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Ihantola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Hellas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM Conference on Learning@Scale</title>
		<imprint>
			<date type="published" when="2017">2017. 2017</date>
			<biblScope unit="page" from="101" to="109" />
		</imprint>
	</monogr>
	<note>Proceedings of the Fourth</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">l-diversity: Privacy beyond k-anonymity</title>
		<author>
			<persName><forename type="first">A</forename><surname>Machanavajjhala</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Kifer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gehrke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Venkitasubramaniam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Knowledge Discovery from Data (TKDD)</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">3</biblScope>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Robust de-anonymization of large sparse datasets</title>
		<author>
			<persName><forename type="first">A</forename><surname>Narayanan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Shmatikov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2008 IEEE Symposium on Security and Privacy</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2008">2008. 2008</date>
			<biblScope unit="page" from="111" to="125" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">The synthetic data vault</title>
		<author>
			<persName><forename type="first">N</forename><surname>Patki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Wedge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Veeramachaneni</surname></persName>
		</author>
		<idno type="DOI">10.1109/DSAA.2016.49</idno>
		<ptr target="https://doi.org/10.1109/DSAA.2016.49" />
	</analytic>
	<monogr>
		<title level="m">2016 IEEE International Conference on Data Science and Advanced Analytics (DSAA)</title>
		<imprint>
			<date type="published" when="2016-10">Oct 2016</date>
			<biblScope unit="page" from="399" to="410" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Performance factors analysis-a new alternative to knowledge tracing</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">I</forename><surname>Pavlik</surname><genName>Jr</genName></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Cen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">R</forename><surname>Koedinger</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
	<note type="report_type">Online Submission</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Scikit-learn: Machine learning in python</title>
		<author>
			<persName><forename type="first">F</forename><surname>Pedregosa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Varoquaux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gramfort</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Michel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Thirion</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Grisel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Blondel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Prettenhofer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Dubourg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">the Journal of machine Learning research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2825" to="2830" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Deep knowledge tracing</title>
		<author>
			<persName><forename type="first">C</forename><surname>Piech</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bassen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ganguli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sahami</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">J</forename><surname>Guibas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sohl-Dickstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in neural information processing systems</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Datasynthesizer: Privacy-preserving synthetic datasets</title>
		<author>
			<persName><forename type="first">H</forename><surname>Ping</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Stoyanovich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Howe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 29th International Conference on Scientific and Statistical Database Management</title>
		<meeting>the 29th International Conference on Scientific and Statistical Database Management</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1" to="5" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">On General Laws and the Meaning of Measurement in Psychology</title>
		<author>
			<persName><forename type="first">G</forename><surname>Rasch</surname></persName>
		</author>
		<ptr target="https://projecteuclid.org/euclid.bsmsp/1200512895" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fourth Berkeley Symposium on Mathematical Statistics and Probability</title>
		<meeting>the Fourth Berkeley Symposium on Mathematical Statistics and Probability<address><addrLine>Berkeley, Calif</addrLine></address></meeting>
		<imprint>
			<publisher>University of California Press</publisher>
			<date type="published" when="1961">1961</date>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="321" to="333" />
		</imprint>
	</monogr>
	<note>Contributions to Biology and Problems of Medicine</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Estimating the success of reidentifications in incomplete datasets using generative models</title>
		<author>
			<persName><forename type="first">L</forename><surname>Rocher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Hendrickx</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">A</forename><surname>De Montjoye</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature communications</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="9" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Second language acquisition modeling</title>
		<author>
			<persName><forename type="first">B</forename><surname>Settles</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Brust</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Gustafson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hagiwara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Madnani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the thirteenth workshop on innovative use of NLP for building educational applications</title>
		<meeting>the thirteenth workshop on innovative use of NLP for building educational applications</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="56" to="65" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Membership inference attacks against machine learning models</title>
		<author>
			<persName><forename type="first">R</forename><surname>Shokri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Stronati</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Shmatikov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 IEEE symposium on security and privacy (SP)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="3" to="18" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Two pseudo-students: Applications of machine learning to formative evaluation</title>
		<author>
			<persName><forename type="first">K</forename><surname>Van Lehn</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1990">1990</date>
			<pubPlace>Pittburgh, PA, Dept of Psychology</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Carnegie-Mellon Univ</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Tech. rep.</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Applications of simulated students: An exploration</title>
		<author>
			<persName><forename type="first">K</forename><surname>Vanlehn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ohlsson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Nason</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of artificial intelligence in education</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="135" to="135" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Back to the basics: Bayesian extensions of IRT outperform neural networks for proficiency estimation</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">H</forename><surname>Wilson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Karklin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Ekanadham</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ternational Educational Data Mining Society</title>
		<imprint>
			<publisher>ERIC</publisher>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">PrivBayes: Private data release via Bayesian networks</title>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Cormode</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">M</forename><surname>Procopiuc</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Xiao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Database Systems (TODS)</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1" to="41" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
