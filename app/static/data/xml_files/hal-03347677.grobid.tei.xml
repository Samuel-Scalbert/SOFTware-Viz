<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">HADAD: A Lightweight Approach for Optimizing Hybrid Complex Analytics Queries</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Rana</forename><surname>Alotaibi</surname></persName>
							<email>ralotaib@eng.ucsd.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">UC San Diego</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="institution">UC San Diego</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="institution">UC San Diego</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Bogdan</forename><surname>Cautis</surname></persName>
							<email>bogdan.cautis@u-psud.fr</email>
							<affiliation key="aff1">
								<orgName type="institution">Univ. Paris Saclay</orgName>
								<address>
									<country key="FR">France</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Univ. Paris Saclay</orgName>
								<address>
									<country key="FR">France</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Univ. Paris Saclay</orgName>
								<address>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Alin</forename><surname>Deutsch</surname></persName>
							<email>deutsch@eng.ucsd.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">UC San Diego</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="institution">UC San Diego</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="institution">UC San Diego</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Ioana</forename><surname>Manolescu</surname></persName>
							<email>ioana.manolescu@inria.fr</email>
							<affiliation key="aff2">
								<orgName type="institution" key="instit1">Inria</orgName>
								<orgName type="institution" key="instit2">Institut Polytechnique de Paris</orgName>
								<address>
									<country key="FR">France</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution" key="instit1">Inria</orgName>
								<orgName type="institution" key="instit2">Institut Polytechnique de Paris</orgName>
								<address>
									<country key="FR">France</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution" key="instit1">Inria</orgName>
								<orgName type="institution" key="instit2">Institut Polytechnique de Paris</orgName>
								<address>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">HADAD: A Lightweight Approach for Optimizing Hybrid Complex Analytics Queries</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">0E6BEAF435187E3655CA7283E982F60B</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-04-12T14:49+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Hybrid complex analytics workloads typically include (i) data management tasks (joins, filters, etc. ), easily expressed using relational algebra (RA)-based languages, and (ii) complex analytics tasks (regressions, matrix decompositions, etc.), mostly expressed in linear algebra (LA) expressions. Such workloads are common in a number of areas, including scientific computing, web analytics, business recommendation, natural language processing, speech recognition. Existing solutions for evaluating hybrid complex analytics queriesranging from LA-oriented systems, to relational systems (extended to handle LA operations), to hybrid systems -fail to provide a unified optimization framework for such a hybrid setting. These systems either optimize data management and complex analytics tasks separately, or exploit RA properties only while leaving LA-specific optimization opportunities unexplored. Finally, they are not able to exploit precomputed (materialized) results to avoid computing again (part of) a given mixed (LA and RA) computation.</p><p>We describe HADAD, an extensible lightweight approach for optimizing hybrid complex analytics queries, based on a common abstraction that facilitates unified reasoning: a relational model endowed with integrity constraints, which can be used to express the properties of the two computation formalisms. Our approach enables full exploration of LA properties and rewrites, as well as semantic query optimization. Importantly, our approach does not require modifying the internals of the existing systems. Our experimental evaluation shows significant performance gains on diverse workloads, from LA-centered ones to hybrid ones.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Modern analytical tasks typically include (i) data management tasks (e.g., joins, filters) to perform pre-processing steps including feature selection, transformation, and engineering <ref type="bibr" target="#b16">[18,</ref><ref type="bibr" target="#b20">22,</ref><ref type="bibr" target="#b32">34,</ref><ref type="bibr" target="#b39">41,</ref><ref type="bibr" target="#b41">43]</ref>, tasks that are easily expressed using relational algebra (RA)-based languages, as well as (ii) complex analytics tasks (e.g., regressions, matrices decompositions), which are mostly expressed using linear algebra (LA) operations <ref type="bibr" target="#b31">[33]</ref>. Such workloads are common in several application domains including scientific computing, web analytics, business recommendation, natural language processing <ref type="bibr" target="#b36">[38]</ref>, or speech recognition <ref type="bibr" target="#b27">[29]</ref>. To perform such analytical tasks, data scientists can choose from a variety of systems, tools, and languages. Languages/libraries such as R <ref type="bibr" target="#b2">[3]</ref> and NumPy <ref type="bibr" target="#b1">[2]</ref>, as well as LAoriented systems such as SystemML <ref type="bibr" target="#b17">[19]</ref> and TensorFlow <ref type="bibr" target="#b9">[11]</ref> treat matrices and linear algebra operations as first-class citizens: they offer a rich set of built-in LA operations and algorithms. However, it can be difficult to express data management tasks that include pre-processing and data transformation in these systems. Further, expression rewrites, based on equivalences that hold due to wellknown LA properties, are not exploited in some of these systems, leading to missed optimization opportunities.</p><p>Many works haved sought to efficiently integrate RA and LA processing in a hybrid environment where both algebraic styles can be used together <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b25">27,</ref><ref type="bibr" target="#b30">32,</ref><ref type="bibr" target="#b33">35,</ref><ref type="bibr" target="#b35">37,</ref><ref type="bibr" target="#b37">39,</ref><ref type="bibr" target="#b43">45]</ref>. Some works propose calling LA packages through user defined functions (UDFs), where libraries such as R and NumPy are embedded in the host language <ref type="bibr" target="#b0">[1]</ref>. Others suggest to treat LA objects as first-class citizens in a column-oriented store or RDBMS and using built-in functions to express LA operations <ref type="bibr" target="#b30">[32,</ref><ref type="bibr" target="#b35">37]</ref>. However, the semantics of LA operations remain hidden behind these built-in functions and UDFs, i.e., LA routines, which the optimizers treat as black-boxes. LARA <ref type="bibr" target="#b33">[35]</ref> introduces a declarative domain-specific language for collections and matrices, which enables optimization across the two algebraic abstractions. SPORES <ref type="bibr" target="#b44">[46]</ref> and SPOOF <ref type="bibr" target="#b19">[21]</ref> optimize LA expressions, by converting them into RA, optimizing the latter, and then converting the result back to an (optimized) LA expression. Polystore or hybrid systems provide an environment, where mixed RA and LA programs can be written and executed across different systems <ref type="bibr" target="#b25">[27,</ref><ref type="bibr" target="#b43">45]</ref>.</p><p>We identify unexplored optimization opportunities in existing solutions for evaluating hybrid complex analytics queries. First, they do not fully exploit LA properties and rewrites, whereas it has been shown that such rewrites can drastically enhance LA-based pipelines' performance <ref type="bibr" target="#b42">[44]</ref>. Second, they do not support semantic query optimization <ref type="bibr" target="#b10">[12]</ref>, which includes taking advantage of partial materialized computation results, i.e., materialized views, known to improve the performance of a variety of queries.</p><p>We propose HADAD, an extensible, lightweight, holistic optimizer for analytical queries, based on reasoning on a common abstraction: relational model with integrity constraints. This brings within reach powerful cost-based optimizations across RA and LA, without the need to modify the internals of the existing systems; as we show, it is very easy to add within HADDAD knowledge about a wider range of LA operations than previous work could consider, while also enabling view-based rewriting and semantic query optimization using integrity constraints. The benefits of our optimized rewrites apply both to systems that provide a mixed-programming interface, such as polystores, and to LA-oriented systems designed and built for matrix operations. Last but not least, our holistic, cost-based approach enables to judiciously apply for each query the best available optimization. For instance, given the computation M(N P) for some matrices M, N and P, we may rewrite it into (MN )P if its estimated cost is smaller than that of the original expression, or we may turn it into MV if a materialized view V stores exactly the result of (N P). HADAD capitalizes on a framework Paper Organization. The rest of this paper is organized as follows. Section 2 formalizes the query optimization problem we solve in the context of a hybrid setting. After some preliminaries (Section 3), Section 4 provides an end-to-end overview of our approach. Section 5 presents our novel reduction of a rewriting problem with LA views into one that can be solved by existing techniques from the relational setting. Section 6 describes our extension to the query rewriting engine, integrating two different cost models, to help prune out inefficient rewritings as soon as they are enumerated. We formalize our solution's guarantees in Section 7 and present our experimental evaluation in Section 8. We then discuss related work and conclude in Section 9.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">PROBLEM STATEMENT</head><p>We consider a set of value domains D i , e.g., D 1 denotes integers, D 2 denotes real numbers, D 3 strings, etc. We consider two basic data types: relations (sets of tuples) as in classical database modeling, and matrices (bi-dimensional arrays). Any attribute in a tuple or cell in a matrix is a value from some D i . We assume a matrix can be implicitly converted into a relation (the order among matrix rows is lost), and the opposite conversion (each tuple becomes a matrix line, in some order that is unknown, unless the relation was explicitly sorted before the conversion).</p><p>We consider a set R ops of (unary or binary) relational algebra operators; concretely, R ops comprises the standard relational selection, projection, and join. We also consider a set L ops of linear algebra operators, comprising: unary operators which apply to a matrix and return a matrix (e.g., inversion and transposition), a number (e.g., the trace), or two matrices (e.g., the LU decomposition <ref type="bibr" target="#b34">[36]</ref>); unary operations applied to a matrix and a number and returning a matrix, such as the scalar-matrix multiplication; binary operations applied to two matrices, or a matrix and a number, and returning a matrix or a number, such as matrix sum and product, scalar product, etc. The full set L ops of LA operations we support is detailed in Section 5.1. A hybrid (RA and/or LA) expression is defined as follows:</p><p>• any value from a domain D i , any matrix, and any relation, is an expression; • (RA operators): given some expressions E, E ′ , ro 1 (E) is also an expression, where ro 1 ∈ R ops is a unary relational operator, and E's type matches ro 1 's expected input type. The same holds for ro 2 (E, E ′ ), where ro 2 ∈ R ops is a binary relational operator (i.e., the join); • (LA operators): given some expressions E, E ′ which are either numeric matrices or numbers (which can be seen as degenerate matrices of 1 × 1), and some real number r , the following are also expressions: lo 1 (E) where lo 1 ∈ L ops is a unary operator, and lo 2 (E, E ′ ) where lo 2 ∈ L ops is a binary operator (again, provided that E, E ′ match the expected input types of the operators).</p><p>Clearly, an important set of equivalence rules hold over our hybrid expressions, well-known respectively in the RA and the LA literature. These equivalences lead to alternative evaluation strategies for each expression.</p><p>Further, we assume given a (potentially empty) set of materialized views V, expressions which have been previously computed over some inputs (matrices and/or relations), and whose results are directly available (e.g., as a file on disk). Detecting when a materialized view can be used instead of evaluating (part of) an expression is another important source of alternative evaluation strategies.</p><p>Given an expression E and a cost model that assigns a cost (a real number) to an expression, we consider the problem of identifying the most efficient (lowest-cost) rewrite derived from E by: (i) exploiting RA and LA equivalence rules, and/or (ii) replacing part of an expression with a scan of a materialized view equivalent to that expression.</p><p>Below, we detail our approach, the equivalence rules we capture, and two alternative cost models we devised for this hybrid RA/LA setting. Importantly, our solution (based on a relational encoding with integrity constraints) capitalizes on the framework previously introduced in <ref type="bibr" target="#b12">[14]</ref>, where it was used to rewrite queries using materialized views in a polystore setting, where the data, views, and query cover a variety of data models (relational, JSON, XML, etc. ). Those queries can be expressed in a combination of standard database query languages, including SQL, JSON query languages, XQuery, etc. The ability to rewrite such queries using heterogeneous views directly and fully transfers to HADAD: thus, instead of a relation, we could have the (tuple-structured) results of an XML or JSON query; views materialized by joining an XML document with a JSON one and a relational database could also be reused. The novelty of our work is to extend the benefits of rewriting and viewbased optimization to LA computations, crucial for modern analytics and ML workloads. In what follows (Section 5), we focus on capturing matrix data and LA computations in the relational framework, along with relational data naturally; this enables our novel, holistic optimization of hybrid expressions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">PRELIMINARIES</head><p>We recall conjunctive queries <ref type="bibr" target="#b21">[23]</ref>, integrity constraints <ref type="bibr" target="#b10">[12]</ref>, and query rewriting under constraints <ref type="bibr" target="#b29">[31]</ref>; these concepts are at the core of our approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Conjunctive Query and Constraints</head><p>A conjunctive query (or simply CQ) Q is an expression of the form Q(x):-R 1 (y 1 ), . . . , R n (y n ), where each R i is a predicate (relation) of some finite arity, and x, y 1 , . . . , y n are tuples of variables or constants. Each R i (y i ) is called a relational atom. The expression Q(x) is the head of the query, while the conjunction of relational atoms R 1 (y 1 ), . . . , R n (y n ) is its body. All variables in the head are called distinguished. Also, every variable in x must appear at least once in y 1 , . . . , y n . Different forms of constraints have been studied in the literature <ref type="bibr" target="#b10">[12]</ref>. In this work, we use Tuple Generating Dependencies (TGDs) and Equality Generating Dependencies (EGDs), stated by formulas of the form ∀x 1 , . . .</p><formula xml:id="formula_0">x n ϕ(x 1 , . . . x n ) → ∃z 1 , . . . , z k ψ (y 1 , . . . , y m ), where {z 1 , . . . , z k } = {y 1 , . . . , y m }\{x 1 , . . . , x n }.</formula><p>The constraint's premise ϕ is a possibly empty conjunction of relational atoms over variables x 1 , . . . , x n and possibly constants. The constraint's conclusion ψ is a non-empty conjunction of atoms over variables y 1 , . . . , y m and possibly constants, atoms that are relational ones in the case of TGDs or equality atoms -of the form w = w ′ -in the case of EGDs. For instance, consider a relation Review(paper, reviewer, track) listing reviewers of papers submitted to a conference's tracks, and a relation PC (member, affiliation) listing the affiliation of every program committee member <ref type="bibr" target="#b23">[25]</ref>.The fact that a paper can only be submitted to a single track is captured by the following EGD: ∀p∀r∀t∀r ′ ∀t ′ Review(p, r, t) ∧Review(p, r ′ , t ′ ) → t = t ′ . We can also express that papers can be reviewed only by PC members by the following TGD: ∀p∀r∀t Review(p, r, t) → ∃a PC(r, a).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Provenance-Aware Chase &amp; Back-Chase</head><p>A key ingredient leveraged in our approach is relational query rewriting using views, in the presence of constraints. The stateof-the-art method for this task, called Chase &amp; Backchase, was introduced in <ref type="bibr" target="#b24">[26]</ref> and improved in <ref type="bibr" target="#b29">[31]</ref>, as the Provenance-Aware Chase &amp; Back-Chase (PACB in short). At the core of these methods is the idea to model views as constraints, in this way reducing the view-based rewriting problem to constraints-only rewriting. Specifically, for a given view V defined by a query, the constraint V I O states that for every match of the view body against the input data, there is a corresponding (head) tuple in the view output, while the constraint V O I states the converse inclusion, i.e., each view output tuple is due to a view body match. From a set V of view definitions, PACB therefore derives a set of view constraints</p><formula xml:id="formula_1">C V = {V I O , V O I | V ∈ V}.</formula><p>Given a source schema σ with a set of integrity constraints I, a set V of views defined over σ , and a conjunctive query Q over σ , the rewriting problem thus becomes: find every reformulation query ρ over the schema of view names V that is equivalent to Q under the constraints I ∪ C V .</p><p>For instance, if σ = {R, S }, I = ∅, τ = {V } and we have a view V materializing the join of relations R and S, V (x, y):-R(x, z), S(z, y), the pair of constraints capturing V is the following:</p><formula xml:id="formula_2">V I O : ∀x∀z∀y R(x, z) ∧ S(z, y) → V (x, y) V O I : ∀x∀yV (x, y) → ∃z R(x, z) ∧ S(z, y).</formula><p>Given the query Q(x, y):-R(x, z), S(z, y), PACB finds the reformulation ρ(x, y):-V (x, y). Algorithmically, this is achieved by: (iii) annotating each atom of the universal plan U with a unique ID called a provenance term.</p><formula xml:id="formula_3">E E ′ ≡ enc LA (E) RW e dec LA (RW e ) PACB ++ C V MMC</formula><p>(iv) chasing U with the constraints in</p><formula xml:id="formula_4">I ∪ C O I V , where C O I V = {V O I | V ∈ V},</formula><p>and annotating each relational atom a introduced by these chase steps with a provenance formula<ref type="foot" target="#foot_0">1</ref> π (a), which gives the set of U -subqueries whose chasing led to the creation of a; the result of this phase, called the backchase, is denoted B.</p><p>(v) matching Q against B and outputting as rewritings the subsets of U that are responsible for the introduction (during the backchase) of the atoms in the image h(Q) of Q; these rewritings are read off directly from the provenance formula π (h(Q)).</p><p>In our example, I is empty,</p><formula xml:id="formula_5">C I O V = {V I O }</formula><p>, and the result of the chase in phase (i) is Q 1 (x, y):-R(x, z), S(z, y), V (x, y). The universal plan obtained in (ii) by restricting Q 1 to the schema of view names is U (x, y):-V (x, y) p 0 , where p 0 denotes the provenance term of atom V (x, y). The result of backchasing U with C O I V in phase (iv) is B(x, y):-V (x, y) p 0 , R(x, z) p 0 , S(z, y) p 0 . Note that the provenance formulas of the R and S atoms (a simple term, in this example) are introduced by chasing the view V . Finally, in phase (v) we find one match image given by h from Q's body into the R and S atoms from B's body. The provenance formula π (h(Q)) of the image h is p 0 , which corresponds to an equivalent rewriting ρ(x, y):-V (x, y).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">HADAD OVERVIEW</head><p>We outline here our approach as an extension to <ref type="bibr" target="#b12">[14]</ref> for solving the rewriting problem for LA-based computations. Hybrid Expressions and Views. A hybrid expression (whether asked as a query, or describing a materialized view) can be purely relational (RA), in which case we assume it is specified as a conjunctive query. Other expressions are purely linear-algebra ones (LA); we assume that they are defined in a dedicated LA language such as R <ref type="bibr" target="#b2">[3]</ref>, DML <ref type="bibr" target="#b17">[19]</ref>, etc. , using linear algebra operators from our set L ops (see Section 5.1), commonly used in real-world machine learning workloads. Finally, a hybrid expression can combine RA and LA, e.g., an RA expression (resulting in a relation) is treated as a matrix input by an LA operator, whose output may be converted again to a table and joined further, etc.</p><p>Our approach is based on a reduction to a relational model. Below, we show how to bring our hybrid expressions -and, most specifically, their LA components -under a relational form (the RA part of each expression is already in the target formalism).</p><p>Encoding into a Relational Model. Let E be an LA expression (query) and V be a set of materialized views. We reduce the LAviews based rewriting problem to the relational rewriting problem under integrity constraints, as follows (see Figure <ref type="figure" target="#fig_0">1</ref>). First, we encode relationally E, V, and the set L ops of linear algebra operators. Note that the relations used in the encoding are virtual and hidden, i.e., invisible to both the application designers and users. They only serve to support query rewriting via relational techniques.</p><p>These virtual relations are accompanied by a set of relational integrity constraints enc LA (LA pr op ) that reflect a set LA pr op of LA properties of the supported LA operations L ops . For instance, we model the matrix addition operation using a relation add M (M, N , R) to denote that O is the result of M + N , together with a set of constraints stating that add M is a functional relation that is commutative, associative, etc. These constraints are EGDs or TGDs (recall Section 3). We detail our relational encoding in Section 5. Reduction form LA-based to Relational Rewriting. Our reduction translates the declaration of each view V ∈ V to additional constraints enc LA (V ) that reflect the correspondence between V 's input data and its output. Separately, E is also encoded as a relational query enc LA (E) over the relational encodings of L ops and its basic ingredients (matrices). Now, the reformulation problem is reduced to a purely relational setting, as follows. We are given a relational query enc LA (E) and a set C V = enc LA (V 1 ) ∪ . . . ∪ enc LA (V n ) of relational integrity constraints encoding the views V. We add as further input a set of relational constraints enc LA (LA pr op ), which encodes relationally the LA pr op operators; we called them Matrix-Model Encoding constraints, or MMC in short. We must find the rewritings RW i r expressed over the relational views C V and MMC, for some integer k and 1 ≤ i ≤ k, such that each RW i r is equivalent to enc LA (E) under these constraints (C V MMC). Solving this problem yields a relationally encoded rewriting RW e expressed over the (virtual) relations used in the encoding; a final decoding step is needed to obtain E ′ , the rewriting of the (LA or, more generally, hybrid) E using the views V.</p><p>The challenge in coming up with the reduction consists in designing an encoding, i.e., one in which rewritings found by (i) encoding relationally, (ii) solving the resulting relational rewriting problem, and (iii) decoding a resulting rewriting over the views, is guaranteed to produce an equivalent expression E ′ . The reduction is detailed in Section 5. Relational Rewriting Using Constraints. To solve the relational rewriting problem under constraints, the algorithm of choice is PACB (recall Section 3). Our PACB rewriting engine (PACB ++ hereafter) has been extended to utilize the Pruned pr ov algorithm sketched and discussed in <ref type="bibr" target="#b28">[30,</ref><ref type="bibr" target="#b29">31]</ref>, which prunes inefficient rewritings during the rewritings search phase, based on a simple cost model using two different matrix sparsity estimators. Section 6 details the choice of an efficient rewriting utilizing the PACB ++ engine. Decoding of the Relational Rewriting. For the selected relational reformulation RW e by PACB ++ , a decoding step dec(RW e ) is performed to translate RW e into the native syntax of its respective underlying store/engine (e.g., R, DML, etc.).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">REDUCTION TO THE RELATIONAL MODEL</head><p>Our internal model is relational, and it makes prominent use of expressive integrity constraints (TGDs and EGDs, recall Section 3). This framework suffices to describe the features and properties of most data models used today, notably including relational, XML, JSON, graph, etc <ref type="bibr" target="#b12">[14,</ref><ref type="bibr" target="#b13">15]</ref>.</p><p>Going beyond, in this section, we present a novel way to reason relationally about LA primitives/operations by treating them as uninterpreted functions with black-box semantics, and adding constraints that capture their important properties. First, we give an overview of a wide range of LA operations that we consider in Section 5.1. Then, in Section 5.2, we show how matrices and their operations can be represented (encoded) using a set of virtual relations, part of a schema we call VREM (for Virtual Relational Encoding of Matrices), together with the integrity constraints MMC that capture the LA properties of these operations. Regardless of matrix data's physical storage, we only use VREM to encode LA expressions and views relationally to reason about them. Section 5.3 exemplifies relational rewritings obtained via our reduction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Matrix Algebra</head><p>We consider a wide range of matrix operations <ref type="bibr" target="#b15">[17,</ref><ref type="bibr" target="#b34">36]</ref>, which are common in real-world machine learning algorithms <ref type="bibr" target="#b3">[5]</ref>: elementwise multiplication (i.e., Hadamard-product) (multi E ), matrix-scalar multiplication (multi MS ), matrix multiplication (multi M ), addition (add M ), division (div M ), transposition (tr ), inversion (inv M ), determinant (det), trace (trace), exponential (exp), adjoints (adj), direct sum (sum D ), direct product (product D ), summation (sum M ), rows and columns summation (rowSum M and colSum M , respectively), QR decomposition (QR), Cholesky decomposition (cho), LU decomposition (LU ), and pivoted LU decomposition (LU P).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">VREM Schema and Relational Encoding</head><p>To model LA operations on the VREM relational schema (part of which appears in Table <ref type="table">1</ref>), we also rely on a set of integrity constraints MMC, which are encoded using relations in VREM. We detail the encoding below. 5.2.1 Base Matrices and Dimensionality Modeling. We denote by M k ×z (D) a matrix of k rows and z columns, whose entries (values) come from a domain D, e.g., the domain of real numbers R. For brevity we just use M k×z . We define a virtual relation name(M i 1 , n) ∈ VREM attaching a unique ID M i 1 to any matrix identified by a name denoted n (which may be e.g. of the form "/data/M.csv"). This relation (shown at the top left in Table <ref type="table">1</ref>) is accompanied by an EGD key constraint I name ∈ MMC m , where MMC m ⊂ MMC, and I name states that two matrices with the same name n have the same ID:</p><formula xml:id="formula_6">I name : ∀M i 1 ∀M i 2 name(M i 1 , n) ∧ name(M i 2 , n) → M i 1 = M i<label>2</label></formula><p>Note that the matrix ID in name (and all the other virtual relations used in our encoding) are not IDs of individual matrix objects: rather, each identifies an equivalence class (induced by value equality) of expressions. That is, two expressions are assigned the same ID iff they yield value-based-equal matrices.</p><p>The dimensions of a matrix are captured by a size(M i 1 , k, z) relation, where k and z are the number of rows, resp. columns and M i 1 is an ID. An EGD constraint I size ∈ MMC m holds on the size relation, stating that the ID determines the dimensions:</p><formula xml:id="formula_7">Operation Encoding Operation Encoding Operation Encoding Matrix scan name(M i 1 , n) Inversion inv M (M i 1 , R o ) Cells sum sum M (M i 1 , s) Multiplication multi M (M i 1 , M i 2 , R o ) Scalar Multiplication multi MS (s, M i 1 , R o ) Row sum rowSum M (M i 1 , R o ) Addition add M (M i 1 , M i 2 , R o ) Determinant det(M i 1 , R o ) Col sums colSum M (M i 1 , R o ) Division div M (M i 1 , M i 2 , R o ) Trace trace(M i 1 , s) Direct sum sum D (M i 1 , M i 2 , R o ) Hadamard product multi E (M i 1 , M i 2 , R o ) Exponential exp(M i 1 , R o ) Kronecker product product D (M i 1 , M i 2 , R o ) Transposition tr (M i 1 , R o ) Adjoints adj(M i 1 , R o ) Diagonal diaд M (M i 1 , R o ) Table 1: Snippet of the VREM Schema I size : ∀M i 1 ∀k 1 ∀z 1 ∀k 2 ∀z 2 size(M i 1 , k 1 , z 1 ) ∧ size(M i 1 , k 2 , z 2 ) → k 1 = k 2 ∧ z 1 = z 2</formula><p>The identity I and zero O matrices are captured by the Zero(O) and Identity(I ), relations respectively, which are accompanied by EGD constraints I iden , I zer o ∈ MMC m , stating that zero matrices with the same sizes have the same IDs, and this also applies for identity matrices with the same size:  <ref type="table">1</ref>. We now illustrate the encoding of an LA expression on the VREM schema.</p><formula xml:id="formula_8">I zer o : ∀O i 1 ∀O i 2 ∀k∀z Zero(O i 1 ) ∧ size(O i 1 , k, z) ∧ Zero(O i 2 ) ∧ size(O i 2 , k, z) → O i 1 = O i 2 I iden : ∀I i 1 ∀I i 2 ∀i Identity(I i 1 ) ∧ size(I i 1 , k, k) ∧ Identity(I i 2 ) ∧ size(I i 2 , k, k) → I i 1 = I i 2 5.</formula><p>Example 5.1. Consider the LA expression E: ((MN ) T ), where the two matrices M 100×1 and N 1×10 are stored as "M.csv" and "N .csv", respectively. The encoding function enc(E) takes as argument the LA expression E and returns a conjunctive query whose: (i) body is the relational encoding of E using VREM (see below), and (ii) head has one distinguished variable, denoting the equivalence class of the result. For instance: enc(((MN</p><formula xml:id="formula_9">) T ) = Let enc(MN ) = Let enc(M) = Q 0 (M i 1 ):-name(M i 1 , "M.csv"); enc(N ) = Q 1 (N i 1 ):-name(N i 1 , "N .csv"); R o 1 = freshId() in Q 2 (R o 1 ):-multi M (M i 1 , N i 1 , R o 1 ),Q 0 (M i 1 ), Q 1 (N i 1 ); R o 2 = freshId() in Q(R o 2 ):-tr (R o 1 , R o 2 ), Q 2 (R o<label>1</label></formula><p>); In the above, nesting is dictated by the syntax of E. From the inner (most indented) to the outer, we first encode M and N as small queries using the name relation, then their product (to whom we assign the newly created identifier R o 1 ), using the multi M relation and encoding the relationship between this product and its inputs in the definition of</p><formula xml:id="formula_10">Q 2 (R o 1 ). Next, we create a fresh ID R o 2 used to encode the full E (the transposed of Q 2 ) via relation tr , in the query Q(R o 2 )</formula><p>. For brevity, we omit the matrices' size relations in this example and hereafter. Now, by unfolding Q 0 and Q 1 in Q, we obtain the final encoding of ((MN ) T ) as a conjunctive query Q: <ref type="figure" target="#fig_1">2</ref> shows some of the constraints MMC LA pr op ⊂ MMC, which capture textbook LA properties <ref type="bibr" target="#b15">[17,</ref><ref type="bibr" target="#b34">36]</ref> of our LA operations (Section 5.1). The TGDs (1), ( <ref type="formula" target="#formula_6">2</ref>) and (3) state that matrix addition is commutative, matrix transposition is distributive with respect to addition, and the transposition of the inverse of matrix M i 1 is equivalent to the inverse of the transposition of M i 1 , respectively. We also express that the virtual relations are functional by using EGD key constraints. For example, the following I mul t i M ∈ MMC LA pr op constraint states that multi M is functional, that is the products of pairwise equal matrices are equal.</p><formula xml:id="formula_11">Unfolding Q 2 (R o 1 ) in the body of Q yields: Q(R o 2 ) :-tr (R o 1 , R o 2 ), multi M (M i 1 , N i 1 , R o 1 ), Q 0 (M i 1 ),Q 1 (N i 1 ); ∀M i 1 ∀M i 2 ∀R o add M (M i 1 , M i 2 , R o ) → add M (M i 2 , M i 1 , R o ) (1) ∀M i 1 ∀M i 2 ∀R o 1 ∀R o 2 add M (M i 1 , M i 2 , R o 1 ) ∧ tr (R o 1 , R o 2 ) → ∃R o 3 ∃R o 4 tr (M i 1 , R o 3 ) ∧ tr (M i 2 , R o 4 ) ∧ add M (R o 3 , R o 4 , R o 2 )<label>(2)</label></formula><formula xml:id="formula_12">∀M i 1 ∀R o 1 ∀R o 2 inv M (M i 1 , R o 1 ) ∧ tr (R o 1 , R o 2 ) → ∃R o 3 tr (M i 1 , R o 3 ) ∧ inv M (R o 3 , R o 2 )<label>(3)</label></formula><formula xml:id="formula_13">Q(R o 2 ) :-tr (R o 1 , R o 2 ), multi M (M i 1 , N i 1 , R o 1 ), name(M i 1 , "M.csv"),name(N i 1 , "N .csv"); 5.2.3 Encoding LA Properties as Integrity Constraints. Fig- ure</formula><formula xml:id="formula_14">I mul t i M : ∀M i 1 ∀M i 2 ∀R o 1 ∀R o 2 multi M (M i 1 , M i 2 , R o 1 ) ∧ multi M (M i 1 , M i 2 , R o 2 ) → R o 1 = R o 2</formula><p>Other properties <ref type="bibr" target="#b15">[17,</ref><ref type="bibr" target="#b34">36]</ref> of the LA operations we consider are similarly encoded; due to space constraints, we relegate them to the technical report [4].</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>5.2.4</head><p>Encoding LA Views as Constraints. We translate each view definition V (defined in LA language such as R, DML, etc) into relational constraints enc LA (V ) ∈ C V , where C V is the set of relational constraints used to capture the views V. These constraints show how the view's inputs are related to its output over the VREM schema. Figure <ref type="figure">3</ref> illustrates the encoding as a TGD constraint of the view V : (N ) T +(M T ) -1 stored in a file "V .csv" and computed based on the matrices N and M (e.g., stored as "N .csv" and "M.csv", respectively).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>5.2.5</head><p>Encoding Matrix Decompositions. Matrix decompositions play a crucial role in many LA computations. For instance, for every symmetric positive definite matrix M there exists a unique</p><formula xml:id="formula_15">∀M i 1 ∀N i 1 ∀R o 1 ∀R o 2 ∀R o 3 ∀R o 4 name(M i 1 , "M.csv") ∧ name(N i 1 , "N .csv") ∧ tr (N i 1 , R o 1 ) ∧ tr (M i 1 , R o 2 ) ∧ inv M (R o 2 , R o 3 ) ∧ add M (R o 1 , R o 3 , R o 4 ) → name(R o 4 , "V .csv") Figure 3: Relational Encoding of view V</formula><p>Cholesky Decomposition (CD) of the form M = LL T , where L is a lower triangular matrix. We model CD, as well as other well-known decompositions (LU, QR, and Pivoted LU or PLU) as a set of virtual relations VREM dec , which we add to VREM. For instance, to CD we associate a relation cho(M i 1 , L o ), which denotes that L o is the output of the CD decomposition for a given matrix M whose ID is</p><formula xml:id="formula_16">M i 1 .</formula><p>cho is a functional relation, meaning every symmetric positive definite matrix has a unique CD decomposition. This functional aspect is captured by an EGD, conceptually similar to the constraint I mul t i M (Section 5.2.3). The property M = LL T is captured as a TGD constraint I cho ∈ MMC LA pr op :</p><formula xml:id="formula_17">I cho : ∀M i 1 type(M i 1 , "S") → ∃ L o 1 ∃L o 2 cho(M i 1 , L o 1 )∧ type(L o 1 , "L") ∧ tr (L o 1 , L o 2 ) ∧ multi M (L o 1 , L o 2 , M i 1 )<label>(4)</label></formula><p>The atom type(M i 1 , "S") indicates the type of matrix M i 1 , where the constant "S" denotes a matrix that is symmetric positive definite; similarly, type(L o 1 ,"L") denotes that the matrix L o 1 is a lower triangular matrix. For each base matrix, its type (if available) (e.g., symmetric, upper triangular, etc. ) is specified as TGD constraint. For example, we state that a certain matrix M (and any other matrix value-equal to M) is symmetric positive definite as follows:</p><formula xml:id="formula_18">∀M 1 name(M i 1 , "M.csv") → type(M i 1 , "S")<label>(5)</label></formula><p>Example 5.2. Consider a view V =N + LL T , where L = cho(M) and M is a symmetric positive definite matrix encoded as in <ref type="bibr" target="#b3">(5)</ref>. Let E be the LA expression M + N . The reader realizes easily that V can be used to answer E directly, thanks to the specific property of the CD decomposition (4), and since M + N = N + M, which is encoded in <ref type="bibr" target="#b0">(1)</ref>. However, at the syntactic level, V and E are very dissimilar. Knowledge of ( <ref type="formula" target="#formula_9">1</ref>) and (4) and the ability to reason about them is crucial in order to efficiently answer E based on V .</p><p>The output matrix of CD decomposition is a lower triangular matrix L, which is not symmetric positive definite, meaning that CD decomposition can not be applied again on L. For other decompositions, such as QR(M) = [Q, R] decomposition, where M is a square matrix, Q is an orthogonal matrix <ref type="bibr" target="#b34">[36]</ref> and R is an upper triangular matrix, there exists a QR decomposition for the orthogonal matrix</p><formula xml:id="formula_19">Q such that QR(Q) = [Q, I ],</formula><p>where I is an identity matrix and QR(R) = [I, R]. We say the fixed point of the QR decomposition is QR(I ) = [I, I ]. These properties of the Q decompositions are captured with the following constraints, which are part of MMC LApr op :</p><formula xml:id="formula_20">∀M i 1 ∀n∀k name(M i 1 , n) ∧ size(M i 1 , k, k) → ∃Q o ∃R o QR(M i 1 , Q o , R o ) ∧ type(Q o , "O") ∧ type(R o , "U ") ∧ multi M (Q o , R o , M i 1 )<label>(6)</label></formula><formula xml:id="formula_21">∀Q i 1 type(Q i 1 , "O") → ∃I o QR(Q i 1 , Q i 1 , I o ) ∧ identity(I o ) ∧ multi M (Q i 1 , I o , Q i 1 )<label>(7)</label></formula><formula xml:id="formula_22">∀R i 1 type(R i 1 , "U ") → ∃I o QR(R i 1 , I o , R i 1 ) ∧ identity(I o ) ∧ multi M (I o , R i 1 , R i 1 )<label>(8)</label></formula><formula xml:id="formula_23">∀I i 1 identity(I i 1 ) → QR(I i 1 , I i 1 , I i 1 )<label>(9)</label></formula><p>Known LA properties of the other matrix decompositions (LU and PLU) are similarly encoded.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>5.2.6</head><p>Encoding LA-Oriented System Rewrite Rules. Most LAoriented systems <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b2">3]</ref> execute an incoming expression (LA pipeline) as-is, that is: run operations in a sequence, whose order is dictated by the expression syntax. Such systems do not exploit basic LA properties, e.g., reordering a chain of multiplied matrices in order to reduce the intermediate size. SystemML <ref type="bibr" target="#b17">[19]</ref> is the only system that models some LA properties as static rewrite rules. It also comprises a set of rewrite rules which modify the given expressions to avoid large intermediates for aggregation and statistical operations such as rowSums(M), sum(M), etc. For example, SystemML uses rule:</p><formula xml:id="formula_24">sum(MN ) = sum(colSums(M) T ⊙ rowSums(N )) (i)</formula><p>to rewrite sum(MN ) (summing all cells in the matrix product) where ⊙ is a matrix element-wise multiplication, to avoid actually computing MN and materializing it; similarly, it rewrites sum(M T ) into sum(M), to avoid materializing M T , etc. However, the performance benefits of rewriting depend on the rewriting power (or, in other words, on how much the system understands the semantics of the incoming expression), as the following example shows.</p><p>Example 5.3. Consider the LA expression E=((M T ) k (M + N ) T ), where M and N are square matrixes, and expression E ′ =sum(E), which computes the sum of all cells in E. The expression E ′ can be rewritten to RW 0 : sum(E ′′ ), where E ′′ is:</p><formula xml:id="formula_25">sum(colSums(M + N ) T ⊙ rowSums(M k ))</formula><p>Failure to exploit the properties LA pr op1 : (MN ) T =M T N T and/or LA pr op2 : (M n ) T = (M T ) n prevents from finding rewriting RW 0 . E ′ admits the alternative rewriting RW 1 : sum(t(colSums((M T ) k )) ⊙ t(colSums(M + N )) which can be obtained by directly applying the rewrite rule (i) above and rowSums(M T )=colSums(M) T , without exploiting the properties LA pr op1 and LA pr op2 . However, RW 1 introduces more intermediate results than RW 0 .</p><p>To fully exploit the potential of rewrite rules (for statistical or aggregation operations), they should be accompanied by sufficient knowledge of, and reasoning on, known properties of LA operations.</p><p>To bring such fruitful optimization to other LA-oriented systems lacking support of such rewrite rules, we have incorporated Sys-temML's rewrite rules into our framework, encoding them as a set of integrity constraints over the virtual relations in the schema VREM, denoted MMC St at Aдд (MMC St at Aдд ⊂ MMC).</p><formula xml:id="formula_26">RW 1 : (M -1 ) T + N T RW 2 : (M T ) -1 + N T RW 3 : N T + (M -1 ) T RW 4 : (N T ) -1 + N T RW 5 : (N + M -1 ) T Figure 4: Equivalent rewritings of the pipeline Q p .</formula><p>Thus, these rewrite rules can be exploited together with other LA properties. For instance, the rewrite rule (i) is modeled by the following integrity constraint I sum ∈ MMC St at Aдд :</p><formula xml:id="formula_27">∀M i 1 ∀N i 1 ∀R o multi M (M i 1 , N i 1 , R o ) ∧ sum(R o , s) → ∃R o 1 ∃R o 2 ∃R o 3 ∃R o 4 colSums(M i 1 , R o 1 ) ∧ tr (R o 1 , R o 2 ) ∧ rowSums(N i 1 , R o 3 ) ∧ multi E (R o 2 , R o 3 , R o 4 ) ∧ sum(R o 4 , s)</formula><p>We refer the reader to the extended version of the paper [4] for a full list of SystemML's encoded rewrite rules.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Relational Rewriting Using Constraints</head><p>With the set of views constraints C V and MMC = MMC m ∪ MMC LA pr op ∪ MMC St at Aдд , we rely on PACB ++ to rewrite a given expression under integrity constraints. We exemplify this below, and detail PACB ++ 's inner workings in Section 6.</p><p>The view V shown in Figure <ref type="figure">3</ref> can be used to fully rewrite (return the answer for) the pipeline Q p : (M -1 + N ) T by exploiting the TGDs (1), ( <ref type="formula" target="#formula_6">2</ref>) and (3) listed in Figure <ref type="figure" target="#fig_1">2</ref>, which describe the following three LA properties, denoted LA pr op 1 :</p><formula xml:id="formula_28">M +N = M +N ; ((M +N )) T = (M) T + (N ) T and ((M) -1 ) T = ((M) T ) -1 . The relational rewriting RW 0 of Q p using the view V is RW 0 (R o 4 ):-name(R o 4 , "V .csv").</formula><p>In this example, RW 0 is the only views-based rewriting of Q p . However, five other rewritings exist (shown in Figure <ref type="figure">4</ref>), which reorder its operations just by exploiting the set LA pr op 1 of LA properties.</p><p>Rewritings RW 0 to RW 5 have different evaluation costs. We discuss next how we estimate which among these alternatives (including evaluating Q p directly) is likely the most efficient.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">CHOICE OF AN EFFICIENT REWRITING</head><p>We introduce our cost model (Section 6.1), which can take two different sparsity estimators (Section 6.2). Then, we detail our extension to the PACB rewriting engine based on the Prune pr ov algorithm (Section 6.3) to prune out inefficient rewritings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Cost Model</head><p>We estimate the cost of an expression E, denoted γ (E), as the sum of the intermediate result sizes if one evaluates E "as stated", in the syntactic order dictated by the expression. Real-world matrices may be dense (most or all elements are non-zero) or sparse (a majority of zero elements). The latter admit more economical representations that do not store zero elements, which our intermediate result size measure excludes. To estimate the number of non-zeros (nnz, in short), we incorporated two different sparsity estimators from the literature (discussed in Section 6.2) into our framework. Example 6.1. Consider E 1 = (MN )M and E 2 = M(N M), where we assume the matrices M 50K ×100 and N 100×50K are dense. The total cost of E 1 is γ (E 1 ) = 50K × 50K and γ (E 2 ) = 100 × 100 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">LA-based Sparsity Estimators</head><p>We outline below two existing sparsity estimators <ref type="bibr" target="#b17">[19,</ref><ref type="bibr" target="#b44">46]</ref> that we have incorporated into our framework to estimate nnz.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>6.2.1</head><p>Naïve Metadata Estimator. The naïve metadata estimator <ref type="bibr" target="#b18">[20,</ref><ref type="bibr" target="#b44">46]</ref> derives the sparsity of the output of LA expression solely from the base matrices' sparsity. This incurs no runtime overhead since metadata about the base matrices, including the nnz, columns and rows are available before runtime in a specific metadata file. The most common estimator is the worst-case estimator <ref type="bibr" target="#b18">[20]</ref>, which we use in our framework.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>6.2.2</head><p>Matrix Non-zero Count (MNC) Estimator. The MNC estimator <ref type="bibr" target="#b40">[42]</ref> exploits matrix structural properties such as single non-zero per row, or columns with varying sparsity, for efficient, accurate, and general sparsity estimation; it relies on count-based histograms that exploit these properties. We have also adopted this framework into our approach, and compute histograms about the base matrices offline. However, the MNC framework still needs to derive and construct histograms for intermediate results online (during rewriting cost estimation). We study this overhead in Section 8.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Rewriting Pruning: PACB ++</head><p>We extended the PACB rewriting engine with the Prune pr ov algorithm sketched and discussed in <ref type="bibr" target="#b28">[30,</ref><ref type="bibr" target="#b29">31]</ref>, to eliminate inefficient rewritings during the rewriting search phase. The naïve PACB algorithm generates all minimal (by join count) rewritings before choosing a minimum-cost one. While this sufficies on the scenarios considered in <ref type="bibr" target="#b12">[14,</ref><ref type="bibr" target="#b29">31]</ref>, the settings we obtain from our LA encoding stress-test the naïve algorithm, as commutativity, associativity, etc. blow up the space of alternate rewritings exponentially. Scalability considerations forced us to further optimize naïve PACB to find only minimum-cost rewritings, aggressively pruning the others during the generation phase. We illustrate Prune pr ov and our improvements next. Prune pr ov Minimum-Cost Rewriting. Recall from Section 3 that the minimal rewritings of a query Q are obtained by first finding the set H of all matches (i.e., containment mappings) from Q to the result B of backchasing the universal plan U . Denoting with π (S) the provenance formula of a set of atoms S, PACB computes the DNF form D of h ∈H π (h(Q)). Each conjunct c of D determines a subquery sq(c) of U which is guaranteed to be a rewriting of Q.</p><p>The idea behind cost-based pruning is that, whenever the naive PACB backchase would add a provenance conjunct c to an existing atom a's provenance formula π (a), Prune pr ov does so more conservatively: if the cost γ (sq(c)) is larger than the minimum cost threshold T found so far, then c will never participate in a minimumcost rewriting and need not be added to π (a). Moreover, atom a itself need not be chased into B in the first place if all its provenance conjuncts have above-threshold cost. Example 6.2. Let E = M(N M), where we assume for simplicity that M 50K ×100 and N 100×50K are dense. Exploiting the associativity of matrix-multiplication (MN )M = M(N M) during the chase leads to the following universal plan U annotated with provenance terms:</p><formula xml:id="formula_29">U (R o 2 ) : name(M i 1 , "M.csv") p 0 ∧ size(M i 1 , 50000, 100) p 1 ∧ name(N i 1 , "N .csv") p 2 ∧ size(N i 1 , 100, 50000) p 3 ∧ multi M (M i 1 , N i 1 , R o 1 ) p 4 ∧ multi M (R o 1 , M i 1 , R o 2 ) p 5 ∧ multi M (N i 1 , M i 1 , R o 3 ) p 6 ∧ multi M (M i 1 , R o 3 , R<label>o</label></formula><p>2 ) p 7 Now, consider in the back-chase the associativity constraint C:</p><formula xml:id="formula_30">∀M i 1 ∀N i 1 ∀R o 1 ∀R o 2 multi M (M i 1 , N i 1 , R o 1 ) ∧ multi M (R o 1 , M i 1 , R o 2 ) → ∃R o 4 multi M (N i 1 , M i 1 , R o 4 ) ∧ multi M (M i 1 , R o 4 , R o 2 )</formula><p>There exists a containment mapping h embedding the two atoms in the premise P of C into the U atoms whose provenance annotations are p 4 and p 5 . The provenance conjunct collected from P's image is π (h(P))=p 4 ∧ p 5 .</p><p>Without pruning, the backchase would chase U with the constraint C, yielding U ′ which features additional π (h(P))-annotated atoms multi</p><formula xml:id="formula_31">M (N i 1 , M i 1 , R o 4 ) p 4 ∧p 5 ∧ multi M (M i 1 , R o 4 , R o 2 ) p 4 ∧p 5 E has precisely two matches h 1 , h 2 into U ′ . h 1 (E)</formula><p>involves the newly added atoms as well as those annotated with p 0 , p 1 , p 2 , p 3 . Collecting all their provenance annotations yields the conjunct c 1 = p 0 ∧ p 1 ∧ p 2 ∧ p 3 ∧ p 4 ∧ p 5 . c 1 determines the U -subquery sq(c 1 ) corresponding to the rewriting (MN )M, of cost (50K) 2 .</p><p>h 2 (E)'s image yields the provenance conjunct c 2 = p 0 ∧ p 1 ∧ p 2 ∧ p 3 ∧ p 6 ∧ p 7 , which determines the rewriting M(N M) that happens to be the original expression E of cost 100 2 .</p><p>The naive PACB would find both rewritings, cost them, and drop the former in favor of the latter.</p><p>With pruning, the threshold T is the cost of the original expression 100 2 . The chase step with C is never applied, as it would introduce the provenance conjunct π (h(P)) which determines U-subquery sq(π (h 2 exceeding T . The atoms needed as image of E under h 1 are thus never produced while backchasing U , so the expensive rewriting is never discovered. This leaves only the match image h 2 (E), which corresponds to the efficient rewriting M(N M).</p><formula xml:id="formula_32">(P)) = multi M (M i 1 , N i 1 , R o 1 ) p 4 ∧ multi M (R o 1 , M i 1 , R o 2 ) p 5 of cost (50K)</formula><p>Our improvements on Prune pr ov . Whenever the pruned chase step is applicable and applied for each TGD constraint, the original algorithm searches for all minimal-rewritings RW that can be found "so far", then it costs each rw ∈ RW to find the "so far" minimum-cost one rw e and adjusts the thresholdT to the cost of rw e . However, this strategy can cause redundant costing of rw ∈ RW whenever the pruned chase step is applied again for another constraint. Therefore, in our modified version of Prune pr ov , we keep track of the rewriting costs already estimated, to prevent such redundant work. Additionally, the search for minimal-rewritings "so far" (matches of the query Q into the evolving universal plan instance U ′ , see Section 3) whenever the pruned chase step is applied is modeled as a query evaluation of Q against U ′ (viewed as a symbolic/canonical database <ref type="bibr" target="#b10">[12]</ref>). This involves repeatedly evaluating the same query plan. However, the query is evaluated over evolutions of the same instance. Each pruned chase step adds a few new tuples to the evolving instance, corresponding to atoms introduced by the step, while most of the instance is unchanged. Therefore, instead of evaluating the query plan from scratch, we employ incremental evaluation as in <ref type="bibr" target="#b29">[31]</ref>. The plan is kept in memory along with the populated hash tables, and whenever new tuples are added to the evolving instance, we push them to the plan.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">GUARANTEES ON THE REDUCTION</head><p>We detail the conditions under which we guarantee that our approach is sound (i.e., it generates only equivalent, cost-optimal rewritings), and complete (i.e., it finds all equivalent cost-optimal rewritings).</p><p>We denote with L the language of hybrid expressions described in Section 2. Let V ⊆ L be a set of materialized view definitions.</p><p>Let LA pr op be a set of properties of the LA operations in L ops that admits relational encoding over VREM. We say that LA pr op is terminating if it corresponds to a set of TGDs and EGDs with terminating chase (this holds for our choice of LA pr op ).</p><p>Denote with γ a cost model for expressions from L. We say that γ is monotonic if expressions are never assigned a lower cost than their subexpressions (this is true for both models we used).</p><p>We call E ∈ L (γ , LA pr op , V)-optimal if for every</p><formula xml:id="formula_33">E ′ ∈ L that is (LA pr op ,V)-equivalent to E we have γ (E ′ ) ≥ γ (E).</formula><p>Let Eq γ ⟨LA pr op , V⟩(E) denote the set of all (γ , LA pr op , V)-optimal expressions that are (LA pr op ,V)-equivalent to E.</p><p>We denote with HADAD⟨LA pr op , V, γ ⟩ our parameterized solution based on relational encoding followed by PACB++ rewriting and next by decoding all the relational rewritings generated by the cost-based pruning PACB++ (recall Figure <ref type="figure" target="#fig_0">1</ref>). Given E ∈ L, HADAD⟨LA pr op , V, γ ⟩(E) denotes all expressions returned by HADAD⟨LA pr op , V, γ ⟩ on input E. Theorem 7.1 (Soundness). If the cost model γ is monotonic, then for every E ∈ L and every rw ∈ HADAD⟨LA pr op , V, γ ⟩(E), we have rw ∈ Eq γ ⟨LA pr op , V⟩(E).</p><p>Theorem 7.2 (Completeness). If γ is monotonic and LA pr op is terminating, then for every E ∈ L and every rw ∈ Eq γ ⟨LA pr op , V⟩(E), we have rw ∈ HADAD⟨LA pr op , V, γ ⟩(E).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">EXPERIMENTAL EVALUATION</head><p>We evaluate our approach, first on LA pipelines (Section 8.1), then on real-world hybrid scenarios (Section 8.2). Due to space constraints, we delegate other results to our extended version of the paper [4].</p><p>Experimental Environment. We used a single node with an Intel(R) Xeon(R) CPU E5-2640 v4 @ 2.40GHz, 40 Cores (hyperthreading), 123GB RAM, disk read speed 616 MB/s, and disk write speed 455 MB/s. We run on OpenJDK Java 8 VM . As for LA systems/libraries, we used R 3.6.0, Numpy 1.16.6 (python 2.7), Ten-sorFlow 1.4.1, Spark 2.4.5 (MLlib), and SystemML 1.2.0; hybrid scenarios were evaluated in the SparkSQL <ref type="bibr" target="#b14">[16]</ref> polystore.</p><p>Systems Configuration Tuning. We discuss here the most important installation and configuration details. We use a JVM-based linear algebra library for SystemML as recommended in <ref type="bibr" target="#b42">[44]</ref>, at the optimization level 4. Additionally, we enable multi-threaded matrix operations in a single node. We run Spark using the standalone cluster manager, and using OpenBLAS (built from the sources as detailed in <ref type="bibr" target="#b8">[10]</ref>) to take advantage of its accelerations <ref type="bibr" target="#b42">[44]</ref>. SparkM-Llib's datatypes do not support many basic LA operations, such as scalar-matrix multiplication, matrix element-wise multiplication, etc. To support them, we use the Breeze Scala library <ref type="bibr" target="#b5">[7]</ref>, convert MLlib's datatypes to Breeze types and express the basic LA operations in Spark. The driver memory allocated for Spark and SystemML is 115GB. To maximize TensorFlow performance, we compile it from sources. For all systems/libraries, we set the number of cores to 24; all systems use double precision numbers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>No. Expression</head><p>No.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Expression</head><p>No. Expression  Datasets. We used several real-world, sparse matrices, for which Table <ref type="table" target="#tab_2">3</ref> lists the dimensions and the sparsity (S X ) (i) dielFilterV3real (DFV in short) is an analysis of a microwave filter with different mesh qualities <ref type="bibr" target="#b22">[24]</ref>; (ii) 2D_54019_highK (2D_54019 in short) is a 2D semiconductor device simulation <ref type="bibr" target="#b22">[24]</ref>; (iii) we used several subsets of an Amazon books review dataset <ref type="bibr" target="#b4">[6]</ref> (in JSON), and similarly (iv) subsets of a Netflix movie rating dataset <ref type="bibr" target="#b6">[8]</ref>. The latter two were easily converted into matrices where columns are items and rows are customers <ref type="bibr" target="#b44">[46]</ref>; we extracted smaller subsets of all real datasets to ensure the various computations applied on them fit in memory (e.g., Amazon/(AS) denotes the small version of the Amazon dataset). We also used a set synthetic, dense matrices, described in Table <ref type="table" target="#tab_3">4</ref>.</p><formula xml:id="formula_34">P1.1 (M N ) T P1.2 A T + B T P1.3 C -1 D -1 P1.4 (A + B)v 1 P1.5 ((D) -1 ) -1 P1.6 t</formula><p>LA benchmark. We select a set P of 57 LA expressions (pipelines) used in prior studies and/or frequently occurring in real-world LA computations, as follows:</p><p>Real-world matrix expressions include: a chain of matrix selfproducts used for reachability queries and other graph analytics <ref type="bibr" target="#b40">[42]</ref> (P1.29 in Table <ref type="table">18</ref>); expressions used in Alternating Least Square Factorization (ALS) <ref type="bibr" target="#b44">[46]</ref> (P2.25 in Table <ref type="table">17</ref>); Poisson Nonnegative Matrix Factorization (PNMF) <ref type="bibr" target="#b44">[46]</ref> (P1.13 in Table <ref type="table">18</ref>); Nonnegative Matrix Factorization (NMF) <ref type="bibr" target="#b42">[44]</ref>(P1.25 and P1.26 in Table <ref type="table">18</ref>); complex predicate for image masking <ref type="bibr" target="#b40">[42]</ref> (P1.30 in Table <ref type="table">18</ref>); recommendation computation <ref type="bibr" target="#b40">[42]</ref> (P1.30 in Table <ref type="table">18</ref>); finally, Ordinary Least Squares Regression (OLS) <ref type="bibr" target="#b42">[44]</ref> (P2.21 in Table <ref type="table">17</ref>).</p><p>Synthetic expressions were also generated, based on a set of basic matrix operations (inverse, multiplication, addition, etc.), and   <ref type="table">18</ref>.</p><p>Methodology. We evaluate our approach using the LA pipelines in Table <ref type="table">18</ref> and Table <ref type="table">17</ref>, systems/tools mentioned above, and the matrices in Table <ref type="table" target="#tab_4">5</ref>. For TensorFlow and NumPy, we present the results only for dense matrices, due to limited support for sparse matrices. In Section 8.1, we focus on LA pipeline rewriting, while Section 8.2 describes experiments on real-world, hybrid scenarios.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.1">Experiments on LA-based Pipelines</head><p>In Section 8.1.1, we show the performance benefits of our approach to existing LA systems using a set P ¬Opt ⊂ P of 38 pipelines, whose performance can be improved just by exploiting LA properties (in the absence of views). In Section 8.1.2, we study our optimization overhead for the set P Opt = P \ P ¬Opt of 19 pipelines that are already optimized. Finally, in Section 8.1.3, we show how our approach improves the performance of 30 pipelines from P, denoted P V iews , using pre-materialized views. 8.1.1 Effectiveness of LA Rewriting (No Views). For each system, we run the original pipeline and our rewriting 5 times; we report the average of the last 4 running times. We exclude the data loading time. For fairness, we ensured SparkMLib and SystemML compute the entire pipeline (despite their lazy evaluation mode). Figure <ref type="figure">5</ref> illustrates the original pipeline execution time Q ex ec and the selected rewriting execution time RW ex ec for P1.  For P1.1 (see Figure <ref type="figure">5</ref>(a)), both matrices are dense. The speed-up (1.5× to 4×) comes from rewriting (MN ) T (intermediate result size to (50K) 2 ) into N T M T , much cheaper since both N T and M T are of size 50K ×100. We exclude MLlib from this experiment since it failed to allocate memory for the intermediate matrix (Spark/MLLib limits the maximum size of a dense matrix). As a variation (not plotted in the Figure ), we ran the same pipeline with the ultra-sparse AS matrix (0.0075% non-zeros) used as M. The Q ex ec and RW ex ec time are very comparable using SystemML, because we avoid large dense intermediates. In R, this scenario lead to a runtime exception since the multiplication operator tries to densify the matrix M. To avoid it, we cast M during load time to a dense matrix type. Thus, the speed-up achieved is the same as if M and N were both dense. If, instead, N S (1.3860% non-zeros) plays the role of M, our rewrite achieves ≈ 1.8× speed-up for SystemML.</p><p>For P1.3 (Figure <ref type="figure">5</ref>(b)), the speed-up comes from rewriting C -1 D -1 to (DC) -1 . Interestingly, TensorFlow is the only system that applies this optimization by itself. SystemML timed-out (&gt;1000 secs) for both original pipeline and its rewriting.  This leads to speed-up of up to 9× for MLlib, which does not natively support matrix addition, thus we convert its matrices to Breeze types in order to perform it (as in <ref type="bibr" target="#b42">[44]</ref>).</p><p>P1.15 (Figure <ref type="figure">5(d)</ref>) is a matrix chain multiplication. The naïve left-to-right evaluation plan (MN )M computes an intermediate matrix of size O(n 2 ), where n is 50K. Instead, the rewriting M(N M) only needs an O(m 2 ) intermediate matrix, where m is 100, and is much faster. To avoid MLLib memory failure on P1.15, we use the distributed matrix of type BlockMatrix for both matrices. While M thus converted has the same sparsity, Spark views it as being of a dense type ( multiplication on BlockMatrix is considered to produce dense matrices) <ref type="bibr" target="#b7">[9]</ref>. SystemML does optimize the multiplication order if the user does not enforce it. Further (not shown in the Figure ), we ran P.15 with AS in the role of M. This is 4× faster in SystemML since with an ultra sparse M, multiplication is more efficient. This is not the case for MLlib which views it as dense. For R, we again had to densify M during loading to prevent crashes.</p><p>Figure <ref type="figure" target="#fig_4">6</ref> studies P1.13 and P1.25, two real-world pipelines involved in ML algorithms, using the MNC cost model; note the logscale y axis. Rewriting P1.13: sum(MN ) into sum(t(colSums(M)) * rowSums(N )) yields a speed-up of 50×; while SystemML has this rewrite as a static rule, it did not apply it. Our rewrite allowed Sys-temML and the others to benefit from it. Not shown in the Figure , 
we re-ran this with M ultra sparse (using AS) and SystemML: the rewrite did not bring benefits, since MN is already efficient. In this Figure <ref type="figure">7</ref>: P1.14 and P2.12 evaluation before and after rewrite Figure <ref type="figure">8</ref>: R speed-up on P ¬Opt experiment and subsequently, whenever MLlib is absent, this is due to its lack of support for LA operations (here, sum of all cells in a matrix) on BlockMatrix. For P1.25, the important optimization is selecting the multiplication order in MN N T (Figure <ref type="figure" target="#fig_4">6(b)</ref>). SystemML is efficient here, due to its dedicated operator tsmm for transpose-self matrix multiplication and mmchain for matrix multiply chains.</p><p>Figure <ref type="figure">7</ref> shows up to 42× rewriting speed-up achieved by turning P1.14 and P2.12 into sum(t(colSums(M)) * rowSums(N )). This exploits several properties: (i) (MN ) T = N T M T , (ii) sum(M T ) = sum(M), (iii) sum(row/colSums(M)) = sum(M), and (iv) sum(MN ) = sum(t(colSums(M)) * rowSums(N )). SystemML captures (ii), (iii), and (iv) as static rewrite rules, however, it is unable to exploit these performance-saving opportunities since it is unaware of (i). Other systems lack support for more or all of these properties.</p><p>Figure <ref type="figure">8</ref> shows the distribution of the significant rewriting speedup on P ¬Opt running on R, and using the MNC-based cost model. For clarity, we split the distribution into two figures: on the left, 25 P ¬Opt pipelines with speed-up lower than 10×; on the right, the remaining 13 with greater speed-up. Among the former, 87% achieved at least 1.5× speed-up. The latter are sped up by 10× to 60×. P1.5 is an extreme case here (not plotted): it is sped up by about 1000×, simply by rewriting ((D) -1 ) -1 into D. 8.1.2 Rewriting Performance and Overhead. We now study the running time RW f ind of our rewriting algorithm, and the rewrite overhead defined as RW f ind /(Q ex ec + RW f ind ), where Q ex ec is the time to run the pipeline "as stated". We ran each experiment 100 times and report the average of the last 99 times. The global trends are as follows. (i) For a fixed pipeline and set of data matrices, the overhead is slightly higher using the MNC cost model, since histograms are built during optimization. (ii) For a fixed pipeline and cost model, sparse matrices lead to a higher overhead simply because Q ex ec tends to be smaller. (iii) Some (system, pipeline) pairs lead to a low Q ex ec when the system applies internally the same optimization that HADAD finds "outside" of the system.</p><p>Concretely, for the P ¬Opt pipelines, on the dense and sparse matrices listed in Table <ref type="table" target="#tab_4">5</ref>, using the naïve cost model, 64% of the RW f ind times are under 25ms (50% are under 20ms), and the longest is about 200m. Using the MNC estimator, 55% took less than 20ms, and the longest (outlier) took about 300ms. Among the 39 P ¬Opt pipelines, SystemML finds efficient rewritings for a set of 6, denoted P ¬Opt S M , while TensorFlow optimizes a different set of 11, denoted P ¬Opt T F . On these subsets, where HADAD's optimization is redundant, using dense matrices, the overhead is very low: with the MNC model, 0.48% to 1.12% on P ¬Opt S M (0.64% on average), and 0.0051% to 3.51% on P ¬Opt T F</p><p>(1.38% on average). Using the naïve estimator slightly reduces this overhead, but across P ¬Opt , this model misses 4 efficient rewritings. On sparse matrices, the overhead is at most 4.86% with the naïve estimator and up to 5.11% with the MNC one.</p><p>Among the already-optimal pipelines P Opt , 70% involve expensive operations such as inverse, determinant, matrix exponential, leading to rather long Q ex ec times. Thus, the rewriting overhead is less than 1% of the total time, on all systems, using sparse or dense matrices, and the naïve or the MNC-based cost models. For the other P Opt pipelines with short Q ex ec , mostly matrix multiplications chains already in the optimal order, on dense matrices, the overhead reaches 0.143% (SparkMlLib) to 9.8% (TensorFlow) using the naïve cost model, while the MNC cost model leads to an overhead of 0.45% (SparkMlib) up to 10.26% (TensorFlow). On sparse matrices, using the naïve and MNC cost models, the overhead reaches up to 0.18% (SparkMLlib) to 1.94% (SystemML), and 0.5% (SparkMLlib) to 2.61% (SystemML), respectively. 8.1.3 Effectiveness of view-based LA rewriting. We have defined a set V exp of 12 views that pre-compute the result of some expensive operations (multiplication, inverse, determinant, etc.) which can be used to answer our P V iews pipelines, and materialized them on disk as CSV files. The experiments outlined below used the naïve cost model; all graphs have a log-scale y axis. Discussion. For P2.14 (Figure <ref type="figure" target="#fig_7">9</ref>(a)), using the view V 4 = N M by and the multiplication associativity leads to up to 2.8× speed-up.</p><p>Figure <ref type="figure" target="#fig_7">9</ref>(b) shows the gain due to the view V 1 = D -1 , for the ordinary-least regression (OLS) pipeline P2.21. It has 8 rewritings, 4 of which use V 1 ; they are found thanks to the properties</p><formula xml:id="formula_35">(CD) -1 = D -1 C -1 , (CD)E = C(DE) and (D T ) -1 = (D -1 ) T among others.</formula><p>The cheapest rewriting is V (V T (D T v 1 )), since it introduces small intermediates due to the optimal matrix chain multiplication order. This rewrite leads to 70×, 55× and 150× speed-ups on R, NumPy and MLlib, respectively; TensorFlow is omitted as matmul operator does not support matrix-vector multiplication. It could run this pipeline by converting the matrices to NumPy, whose performance we already report separately. On SystemML, the original pipeline timed out (&gt; 1000 seconds).</p><p>Pipeline P2.25 (Figure <ref type="figure" target="#fig_7">9</ref>(c)) benefits from a view V 5 , which precomputes a dense intermediate vector multiplication result; then, rewriting based on the property (A + B)v = Av + Bv leads to a 65× speed-up in SystemML. For MLlib, as discussed before, to avoid memory failure, we used BlockMatrix types. for all matrices and  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.2">Hybrid (LA and RA) Scenarios</head><p>We now study the benefits of rewriting on hybrid expressions combining relational and linear algebra. Scenario 1 (Hyb 1 ): Amazon reviews. This JSON dataset contains product information, product reviews (text) and reviewer information. We defined two materialized views: V 1 stores review id, product id, and the overall rate for "Kindle-Edition" books as a relational table; V 2 stores the reviewer id, product id, and the review text as a text datasource in Solr. A query constructs a product-review matrix X for "Kindle-Edition" books, where the review text mentions "mystery". This matrix is loaded in SystemML, where we filter rows with rating less than 2. Next, an analysis is run, through the computation:</p><formula xml:id="formula_36">(u 1 v T 2 -X )v 2 ,</formula><p>which appears in the ALS algorithm <ref type="bibr" target="#b44">[46]</ref>. Note that u 1 and v 2 are synthetic dense vectors of size 100K × 1 and 50K × 1, respectively, and X is ultra sparse (0.00028% non-zeros). Rewriting modifies the pre-processing by introducing V 1 and V 2 ; it also pushes the rating filter into the pre-processing part. The analysis is rewritten into u 1 v T 2 v 2 -Xv 2 ; this is the main reason for the 60× speed-up we bring to SystemML (Figure <ref type="figure" target="#fig_0">10</ref>). First, X is ultra sparse which makes the computation of Xv 2 extremely efficient. Second, SystemML evaluates u 1 v T 2 v 2 efficiently in one go without intermediates, taking advantage of tsmm operator (discussed earlier) and mmchain for matrix multiply chains, where the best way to evaluate it computes v T 2 v 2 first, which results in a scalar, instead of computing u 1 v T 2 , which results in a dense matrix of size 100K ×50K. Alone, SystemML is unable to exploit its own efficient operations for lack of awareness the LA property Av + Bv = (A + B)v. Scenario 2 (Hyb 2 ): Netflix reviews. The dataset is in CSV form, and it contains movie id, customer id, overall rate and rating time. A query (in the pre-processing part) constructs a review matrix X , where columns are movies, and rows are customers. In the same fashion as in the previous scenario, X is loaded for analysis in SystemML, where we filter rows with overall rate greater than 3. Next, we run the same analysis computation described in Scenario 1, where the obtained rewriting is also the same. The main difference here is that matrix X is much denser (0.261% non-zeros), and the rewriting does not involve using materialized views. The rewrite achieves ∼20× speed-up as shown in Figure <ref type="figure" target="#fig_0">10</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.3">Experiments Summary</head><p>We have shown that HADAD brings significant performance-saving across LA-oriented and potentially polystore engines/systems without the need to modify their internals. It improves their performance by order of magnitudes on typical LA-based and hybrid pipelines. Moreover, as we confirm experimentally, the time spent searching for rewritings is a small fraction of the query execution time for P ¬Opt pipelines hence a worthwhile investment. In addition, the rewriting overhead of P Opt pipelines is very negligible compared to the original pipeline execution time in the presence of sparse/dense matrices and using naïve and MNC-based cost models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9">RELATED WORK AND CONCLUSION</head><p>LA-oriented Systems, Libraries &amp; Languages. SystemML <ref type="bibr" target="#b17">[19]</ref> offers high-level R-like linear algebra abstractions, using a declarative language called Declarative Machine Learning (DML). The system applies some logical LA pattern-based rewrites and physical execution optimizations, based on cost estimates for the latter. SparkMLlib <ref type="bibr" target="#b37">[39]</ref> provides LA operations and built-in function implementations of popular ML algorithms, such as linear regression, etc. on Spark RDDs. The library supports sparse and dense matrices, but the user has to select this type explicitly. R <ref type="bibr" target="#b2">[3]</ref> and NumPy <ref type="bibr" target="#b1">[2]</ref> are two of the most popular computing environments for statistical data analysis, widely used in academia and industry. They provide a high-level abstraction that can simplify the programming of numerical and statistical computations, by treating matrices as first-class citizens and by providing a rich set of built-in LA operations and ML algorithms. However, LA properties in most of these systems remain unexploited, which makes them miss opportunities to use their own highly efficient operators (recall Hyb 1 in Section 8.2). Our experiments (Section 8) show that LA pipeline evaluation in these systems can be sped up, often by more 10×, by our rewriting using (i) LA properties and (ii) materialized views. Bridging the Gap: Linear and Relational Algebra. There has been a recent increase in research for unifying the execution of relational and linear algebra queries /pipelines <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b25">27,</ref><ref type="bibr" target="#b30">32,</ref><ref type="bibr" target="#b33">35,</ref><ref type="bibr" target="#b35">37,</ref><ref type="bibr" target="#b37">39,</ref><ref type="bibr" target="#b43">45]</ref>.</p><p>A key limitation of these works is that the semantics of linear algebra operations remains hidden behind built-in functions and/or UDFs, preventing performance-enhancing rewrites. Some of these works call LA packages through UDFs, where libraries such as R and NumPy are embedded in the host language <ref type="bibr" target="#b0">[1]</ref>. Other works treat LA objects as first-class citizens and use built-in functions to express LA operations <ref type="bibr" target="#b26">[28,</ref><ref type="bibr" target="#b30">32,</ref><ref type="bibr" target="#b35">37]</ref>. Closer to our work, LARA <ref type="bibr" target="#b33">[35]</ref> relies on a declarative domain-specific language for collections and matrices, which can enable optimization across the two algebraic abstractions. SPORES <ref type="bibr" target="#b44">[46]</ref> and SPOOF <ref type="bibr" target="#b19">[21]</ref> optimize LA expressions, by converting them into RA, optimizing the latter, and then converting the result back to an (optimized) LA expression. SPORES and SPOOF are restricted to a small set of selected LA operations (the ones that can be expressed in relational algebra), while we support significantly more (Section 5.1), and model properties allowing to optimize with them. Further, as they do not reason with constraints, they cannot exploit materialized views in an LA (or hybrid LA/RA) context; as shown in our experiments, such rewritings can bring large performance advantages. Our work can also complementing the optimizations of LARA, SPORES or SPOOF, to extend to these platforms the benefits of views-based rewriting. Conclusion. HADAD is an extensible lightweight approach for optimizing hybrid complex analytics queries, based on the powerful intermediate abstraction of a a relational model with integrity constraints. HADAD extends <ref type="bibr" target="#b12">[14]</ref> with a reduction from LA view-based rewriting to relational rewriting under constraints. It enables a full exploration of rewrites using a large set of LA operations, with no modification to the execution platform. Our experiments show performance gains of up to several orders of magnitude on LA and hybrid workloads. Future work includes reasoning about cell-wise operations, building upon the FAQ <ref type="bibr" target="#b11">[13]</ref> framework.  P2.16 trace((DC) -1 ) + traceD) P2.17                   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C P ¬Opt AND P</head><formula xml:id="formula_37">V iews PIPELINES REWRITES No. Rewrite No. Rewrite No. Rewrite P1.1 N T M T P1.2 (A + B) T P1.3 (DC) -1 P1.4 Av 1 + Bv 1 P1.5 D P1.6 s 1 trace(D) P1.7 A P1.8 (s 1 + s 2 )A P1.9 det(D)</formula><formula xml:id="formula_38">((((C + D) -1 ) T )D P2.18 rowSums(A + B) T P2.25 u 1 v T 2 v 2 -Xv 2 Table 12: P ¬Opt Pipelines (Part 2) Rewrites No. Expression No. Expression No. Expression V 1 (D) -1 V 2 (C T ) -1 V 3 N M V 4 u 1 v T 2 V 5 DC V 6 A + B V 7 C -1 V 8 C T D V 9 (D + C) -1 V 10 det(CD) V 11 det(DC) V 12 (DC) T Table 13: The set of views V exp No. Rewrite No. Rewrite No. Rewrite P1.2 (V 6 ) T P1.3 V 7 V 1 P1.4 (V 6 )v 1 P1.11 colSums(V 6 ) T P1.15 M(V 3 ) P1.17 V 10 * det(C) P1.19 V 2 P1.20 trace(V 7 ) P1.21 (C + V 1 ) T P1.22 trace(V 9 ) P1.24 trace(V 1 V 7 ) + trace(D) P1.29 V 5 CCC P1.30 V 3 ⊙ V 3 R T P2.2 det(V 1 ) P2.4 s 1 (V 6) P2.5 det(V 9 ) P2.6 (V 1 C) T P2.9 trace(V 12 ) + trace(D) P2.11 sum(V 6 ) P2.13 (MV 3 ) T P2.14 MV 3 N P2.16 trace(V 7 V 1 ) + traceD) P2.17 (V T 9 )D P2.18 rowSums(V 6 ) T P2.20 (MV 3 ) T P2.21 V 1 (V T 1 (D T v 1 )) P2.25 V 4 v 1 -Xv 1 P1.23 det((V 7 V 1 ) + D) P2.26 exp(V 9 ) P2.27 V T 9 V 5</formula></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Outline of our reduction (i) chasing Q with the constraints I∪C I O V , where C I O V = {V I O | V ∈ V}; intuitively, this enriches (extends) Q with all the consequences that follow from its atoms and the constraints I ∪ C I OV . (ii) restricting the chase result to only the V-atoms; the result is called the universal plan) U .(iii) annotating each atom of the universal plan U with a unique ID called a provenance term.(iv) chasing U with the constraints inI ∪ C O I V , where C O I V = {V O I | V ∈ V},and annotating each relational atom a introduced by these chase steps with a provenance formula 1 π (a), which gives the set of U -subqueries whose chasing led to the creation of a; the result of this phase, called the backchase, is denoted B.(v) matching Q against B and outputting as rewritings the subsets of U that are responsible for the introduction (during the backchase) of the atoms in the image h(Q) of Q; these rewritings are read off directly from the provenance formula π (h(Q)).In our example, I is empty,C I O V = {V I O }, and the result of the chase in phase (i) is Q 1 (x, y):-R(x, z), S(z, y), V (x, y). The universal plan obtained in (ii) by restricting Q 1 to the schema of view names is U (x, y):-V (x, y) p 0 , where p 0 denotes the provenance term of atom V (x, y). The result of backchasing U with C O I V in phase (iv) is B(x, y):-V (x, y) p 0 , R(x, z) p 0 , S(z, y) p 0 . Note that the provenance formulas of the R and S atoms (a simple term, in this example) are introduced by chasing the view V . Finally, in phase (v) we find one match image given by h from Q's body into the R and S atoms from B's body. The provenance formula π (h(Q)) of the image h is p 0 ,</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: MMC Constraints Capturing Basic LA Properties</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>2 (d) P1. 15 Figure 5 :</head><label>2155</label><figDesc>Figure 5: Evaluation time with and without rewriting the figure. For brevity in the figures, we use SM for SystemML, NP for NumPy, TF for Tensorflow, and SP for MLlib.For P1.1 (see Figure5(a)), both matrices are dense. The speed-up (1.5× to 4×) comes from rewriting (MN ) T (intermediate result size to (50K) 2 ) into N T M T , much cheaper since both N T and M T are of size 50K ×100. We exclude MLlib from this experiment since it failed to allocate memory for the intermediate matrix (Spark/MLLib limits the maximum size of a dense matrix). As a variation (not plotted in the Figure), we ran the same pipeline with the ultra-sparse AS matrix (0.0075% non-zeros) used as M. The Q ex ec and RW ex ec time are very comparable using SystemML, because we avoid large dense intermediates. In R, this scenario lead to a runtime exception since the multiplication operator tries to densify the matrix M. To avoid it, we cast M during load time to a dense matrix type. Thus, the speed-up achieved is the same as if M and N were both dense. If, instead, N S (1.3860% non-zeros) plays the role of M, our rewrite achieves ≈ 1.8× speed-up for SystemML.For P1.3 (Figure5(b)), the speed-up comes from rewriting C -1 D -1 to (DC) -1 . Interestingly, TensorFlow is the only system that applies this optimization by itself. SystemML timed-out (&gt;1000 secs) for both original pipeline and its rewriting.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: P1.13 and P1.25 evaluation before and after rewrite For pipeline P1.4 (Figure 5(c)), we rewrite (A + B)v 1 to Av 1 + Bv 1 . Adding a sparse matrix A to a dense matrix B results into materializing a dense intermediate of size 1M × 100. Instead, Av 1 + Bv 1 has fewer non-zeros in the intermediate results, and Av 1 can be computed efficiently since A is sparse. The MNC sparsity estimator has a noticeable overhead here. We run the same pipeline, where the dense Syn 4 matrix plays both A and B (not shown in the Figure).This leads to speed-up of up to 9× for MLlib, which does not natively support matrix addition, thus we convert its matrices to Breeze types in order to perform it (as in<ref type="bibr" target="#b42">[44]</ref>).P1.15 (Figure5(d)) is a matrix chain multiplication. The naïve left-to-right evaluation plan (MN )M computes an intermediate matrix of size O(n 2 ), where n is 50K. Instead, the rewriting M(N M) only needs an O(m 2 ) intermediate matrix, where m is 100, and is much faster. To avoid MLLib memory failure on P1.15, we use the distributed matrix of type BlockMatrix for both matrices. While M thus converted has the same sparsity, Spark views it as being of a</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>3 , u 1 : 27 Figure 9 : 8 Figure 10 :</head><label>31279810</label><figDesc>Figure 9: P2.14, P2.21, P2.25 and P2.27 performance before and after rewriting using the views V exp</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 9 (</head><label>9</label><figDesc>d) shows that for P2.27 exploiting the views V 2 = (D + C) -1 and V 3 = DC leads to speed-ups of 4× to 41× on different systems. Properties enabling rewriting here are C + D = D + C, (D T ) -1 = (D -1 ) T and (CD)E = C(DE).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head></head><label></label><figDesc>colSums(A + B) T P1.12 colSums(M)N P1.13 sum(colSums(M) T * rowSums(N )) P1.14 sum(colSums(M) T * rowSums(N )) P1.15 M(N M) P1.16 sum(A) P1.17 det(C) * det(D) * det(C) P1.18 sum(A) P1.25 M ⊙ (N T /(M(N N T )))</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>D 2 Figure 11 : 2 Figure 12 : 6 Figure 13 : 8 Figure 14 : 8 Figure 15 : 9 Figure 16 : 10 Figure 17 :</head><label>2112126138148159161017</label><figDesc>Figure 11: P1.2 evaluation time with and without rewriting</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 18 :</head><label>18</label><figDesc>Figure 18: P1.10 evaluation time with and without rewriting</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure 19 :</head><label>19</label><figDesc>Figure 19: P1.11 evaluation time with and without rewriting</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Figure 20 : 12 Figure 21 :</head><label>201221</label><figDesc>Figure 20: P1.11 evaluation time with and without rewriting</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Figure 22 :</head><label>22</label><figDesc>Figure 22: P1.14 evaluation time with and without rewriting</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>Figure 23 : 16 Figure 24 : 16 Figure 25 :</head><label>2316241625</label><figDesc>Figure 23: P1.15 evaluation time with and without rewriting</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head>Figure 26 :</head><label>26</label><figDesc>Figure 26: P1.17 evaluation time with and without rewriting</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_16"><head>Figure 27 : 18 Figure 28 : 25 Figure 29 : 1 Figure 30 : 2 Figure 31 : 3 Figure 32 :Figure 33 :Figure 34 : 8 Figure 35 :Figure 36 : 10 Figure 37 :</head><label>27182825291302313323334835361037</label><figDesc>Figure 27: P1.18 evaluation time with and without rewriting</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_17"><head>Figure 38 :</head><label>38</label><figDesc>Figure 38: P2.11 evaluation time with and without rewriting</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_18"><head>Figure 39 : 13 Figure 40 : 14 Figure 41 :</head><label>3913401441</label><figDesc>Figure 39: P2.11 evaluation time with and without rewriting</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_19"><head>Figure 42 :</head><label>42</label><figDesc>Figure 42: P2.15 evaluation time with and without rewriting</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_20"><head>Figure 43 : 16 Figure 44 : 18 Figure 45 :</head><label>4316441845</label><figDesc>Figure 43: P2.15 evaluation time with and without rewriting</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_21"><head>Figure 46 : 8 Figure 49 : 11 Figure 52 : 16 Figure 56 :</head><label>4684911521656</label><figDesc>Figure 46: P2.18 evaluation time with and without rewriting</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_22"><head>Figure 57 : 3 Figure 60 : 9 Figure 62 : 11 Figure 64 : 14 Figure 66 : 16 Figure 68 : 18 Figure 69 : 3 Figure 70 : 11 Figure 71 :</head><label>5736096211641466166818693701171</label><figDesc>Figure 57: P1.17 evaluation time with and without rewriting</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_23"><head>21 Figure 72 :</head><label>2172</label><figDesc>Figure 72: P1.17,P1.19,P1.20 and P1.21 evaluation time with and without rewriting</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_24"><head>Figure 73 : 5 Figure 74 : 16 Figure 75 : 11 Figure 76 :</head><label>7357416751176</label><figDesc>Figure 73: P1.22,P1.23,P1.24 and P1.29 evaluation time with and without rewriting</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_25"><head>15 Figure 77 :</head><label>1577</label><figDesc>Figure77: Speed-ups of MorpheusR (with HADAD rewrites) over MorpheusR (without HADAD rewrites) for pipelines 2.12 and 2.15 on synthetic data for a PK-FK join.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_26"><head>13 Figure 78 : 16 Figure 79 :</head><label>13781679</label><figDesc>Figure 78: RW f ind overhead as a percentage (%) of the total time (Q ex ec + RW f ond ) for pipelines 1.1,1.10 and 1.13</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>2.2 Encoding Matrix Algebra Expressions. LA operations are encoded into dedicated relations, as shown in Table</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>r ace(s 1 D) LA Benchmark Pipelines (Part 1)</figDesc><table><row><cell></cell><cell>P1.7</cell><cell cols="2">((A) T ) T</cell><cell>P1.8</cell><cell>s 1 A + s 2 A</cell><cell>P1.9</cell><cell>det (D T )</cell></row><row><cell></cell><cell>P1.10</cell><cell cols="2">r ow Sums(A T )</cell><cell>P1.11</cell><cell>r owSums(A T + B T )</cell><cell>P1.12</cell><cell>col Sums(M N )</cell></row><row><cell></cell><cell>P1.13</cell><cell cols="2">sum(M N )</cell><cell cols="2">P1.14 sum(col Sums(N T M T ))</cell><cell>P1.15</cell><cell>(M N )M</cell></row><row><cell></cell><cell>P1.16</cell><cell cols="2">sum(A T )</cell><cell>P1.17</cell><cell>det (C DC)</cell><cell>P1.18</cell><cell>sum(col Sums(A))</cell></row><row><cell></cell><cell>P1.19</cell><cell cols="2">(C T ) -1</cell><cell>P1.20</cell><cell>t r ace(C -1 )</cell><cell>P1.21</cell><cell>(C + D -1 ) T</cell></row><row><cell></cell><cell>P1.22</cell><cell cols="2">t r ace((C + D) -1 )</cell><cell>P1.23</cell><cell>det ((C D) -1 ) + D)</cell><cell>P1.24 t r ace((C D) -1 )) + t r ace(D)</cell></row><row><cell></cell><cell>P1.25</cell><cell cols="2">M ⊙ (N T /(M N N T ))</cell><cell>P1.26</cell><cell>N ⊙ (M T /(M T M N ))</cell><cell>P1.27</cell><cell>t r ace(D(C D) T )</cell></row><row><cell></cell><cell>P1.28</cell><cell cols="2">A ⊙ (A ⊙ B + A)</cell><cell>P1.29</cell><cell>DC CC</cell><cell>P1.30</cell><cell>N M ⊙ N M R T</cell></row><row><cell>Name</cell><cell>Rows n</cell><cell>Cols m</cell><cell>Nnz ||X|| 0</cell><cell>S X</cell><cell></cell></row><row><cell>DFV</cell><cell>1M</cell><cell>100</cell><cell cols="2">8050 0.0080%</cell><cell></cell></row><row><cell>2D_54019</cell><cell>50K</cell><cell>100</cell><cell cols="2">3700 0.0740%</cell><cell></cell></row><row><cell>Amazon/(AS )</cell><cell>50K</cell><cell>100</cell><cell cols="2">378 0.0075%</cell><cell></cell></row><row><cell>Amazon/(AM )</cell><cell>100K</cell><cell>100</cell><cell cols="2">673 0.0067%</cell><cell></cell></row><row><cell>Amazon/(AL 1 )</cell><cell>1M</cell><cell>100</cell><cell cols="2">6539 0.0065%</cell><cell></cell></row><row><cell>Amazon/(AL 2 )</cell><cell>10M</cell><cell>100</cell><cell cols="2">11897 0.0011%</cell><cell></cell></row><row><cell>Amazon/(AL 3 )</cell><cell>100K</cell><cell>50K</cell><cell cols="2">103557 0.0020%</cell><cell></cell></row><row><cell>Netflix/(N S )</cell><cell>50K</cell><cell>100</cell><cell cols="2">69559 1.3911%</cell><cell></cell></row><row><cell>Netflix/(N M )</cell><cell>100K</cell><cell>100</cell><cell cols="2">139344 1.3934%</cell><cell></cell></row><row><cell>Netflix/(N L 1 )</cell><cell>1M</cell><cell>100</cell><cell cols="2">665445 0.6654%</cell><cell></cell></row><row><cell>Netflix/(N L 2 )</cell><cell>10M</cell><cell>100</cell><cell cols="2">665445 0.0665%</cell><cell></cell></row><row><cell>Netflix/(N L 3 )</cell><cell>100K</cell><cell>50K</cell><cell>15357418</cell><cell>0.307%</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 :</head><label>3</label><figDesc>Overview of Used Real Datasets.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 :</head><label>4</label><figDesc>Syntactically Generated Dense Datasets Syn 7 , Syn 8 and Syn 9 , respectively.</figDesc><table><row><cell cols="2">Name Rows n</cell><cell>Cols m</cell><cell>Name</cell><cell>Rows n</cell><cell>Cols m</cell></row><row><cell>Syn 1</cell><cell>50K</cell><cell>100</cell><cell>Syn 6</cell><cell>20K</cell><cell>20K</cell></row><row><cell>Syn 2</cell><cell>100</cell><cell>50K</cell><cell>Syn 7</cell><cell>100</cell><cell>1</cell></row><row><cell>Syn 3</cell><cell>1M</cell><cell>100</cell><cell>Syn 8</cell><cell>50K</cell><cell>1</cell></row><row><cell>Syn 4</cell><cell>5M</cell><cell>100</cell><cell>Syn 9</cell><cell>100K</cell><cell>1</cell></row><row><cell>Syn 5</cell><cell>10K</cell><cell>10K</cell><cell>Syn 10</cell><cell>100</cell><cell>100</cell></row><row><cell cols="2">Matrix Name</cell><cell>.</cell><cell cols="2">Used Data</cell><cell></cell></row><row><cell cols="2">A and B</cell><cell cols="3">AM, AL 1 , AL 2 , NM, NL 1 , NL 2 , dielFilter, Syn 3 or Syn 4</cell><cell></cell></row><row><cell cols="2">C and D</cell><cell></cell><cell cols="2">Syn 5 or Syn 6</cell><cell></cell></row><row><cell>M</cell><cell></cell><cell cols="3">AS, NS, Syn 1 , or 2D_54019</cell><cell></cell></row><row><cell>N</cell><cell></cell><cell></cell><cell>Syn 2</cell><cell></cell><cell></cell></row><row><cell>R</cell><cell></cell><cell></cell><cell>Syn 10</cell><cell></cell><cell></cell></row><row><cell>X</cell><cell></cell><cell></cell><cell cols="2">AL 3 or NL 3</cell><cell></cell></row><row><cell cols="2">v 1 ,v 2 and u 1</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 5 :</head><label>5</label><figDesc>Matrices used for each matrix name in a pipeline</figDesc><table /><note><p><p><p>. a set of combination templates, written as a Rule-Iterated Context-Free Grammar (RI-CFG)</p><ref type="bibr" target="#b38">[40]</ref></p>. Expressions thus generated include P2.16, P2.16, P2.23, P2.24 in Table</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head></head><label></label><figDesc>1, P1.3, P1.4, and P1.15, including the rewriting time RW f ind , using the MNC cost model. For each pipeline, the used datasets are on top of</figDesc><table><row><cell>No.</cell><cell>Expression</cell><cell>No.</cell><cell>Expression</cell><cell>No.</cell><cell>Expression</cell></row><row><cell>P2.1</cell><cell>t r ace(C + D)</cell><cell>P2.2</cell><cell>det (D -1 )</cell><cell>P2.3</cell><cell>t r ace(D T )</cell></row><row><cell>P2.4</cell><cell>s 1 A + s 1 B</cell><cell>P2.5</cell><cell>det ((C + D) -1 )</cell><cell>P2.6</cell><cell>C T (D T ) -1</cell></row><row><cell>P2.7</cell><cell>DD -1 C</cell><cell>P2.8</cell><cell>det (C T D)</cell><cell>P2.9</cell><cell>t r ace(C T D T + D)</cell></row><row><cell>P2.10</cell><cell>r ow Sums(M N )</cell><cell>P2.11</cell><cell>sum(A + B)</cell><cell cols="2">P2.12 sum(r owSums(N T M T ))</cell></row><row><cell>P2.13</cell><cell>((M N )M ) T</cell><cell>P2.14</cell><cell>((M N )M )N</cell><cell>P2.15</cell><cell>sum(r owSums(A))</cell></row><row><cell cols="2">P2.16 t r ace(C -1 D -1 ) + t r ace D)</cell><cell>P2.17</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 11 :</head><label>11</label><figDesc>P ¬Opt Pipelines (Part 1) Rewrites</figDesc><table><row><cell>No.</cell><cell>Rewrite</cell><cell>No.</cell><cell>Rewrite</cell><cell>No.</cell><cell>Rewrite</cell></row><row><cell>P2.1</cell><cell>trace(C) + trace(D)</cell><cell>P2.2</cell><cell>1/det(D)</cell><cell>P2.3</cell><cell>trace(D)</cell></row><row><cell>P2.4</cell><cell>s 1 (A + B)</cell><cell>P2.5</cell><cell>1/det((C + D))</cell><cell>P2.6</cell><cell>(D -1 C) T</cell></row><row><cell>P2.7</cell><cell>C</cell><cell>P2.8</cell><cell>det(C)  *  det(D)</cell><cell>P2.9</cell><cell>trace(DC) + trace(D)</cell></row><row><cell>P2.10</cell><cell>MrowSumsN )</cell><cell cols="4">P2.11 sum(A) + sum(B) P2.12 sum(colSums(M) T  *  rowSums(N )</cell></row><row><cell>P2.13</cell><cell>(M(N M)) T</cell><cell>P2.14</cell><cell>(M(N M))N</cell><cell>P2.15</cell><cell>sum(A)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 14 :</head><label>14</label><figDesc>P V iews Pipelines Rewrites</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>Provenance formulas are constructed from provenance terms using logical conjunction and disjunction.</p></note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>A L ops OPERATIONS PROPERTIES (LA pr op ) CAPTURED AS INTEGRITY CONSTRAINTS   </p><p>Conference'21, June 21, Xi'an, Shaanxi, China Rana Alotaibi † , Bogdan Cautis ‡ , Alin Deutsch † , Ioana Manolescu § </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B SYSTEMML REWRITE RULES ENCODED AS INTEGRITY CONSTRAINTS</head><p>SystemML Algebraic Simplification Rule Integrity Constraints MMC St at Aдд simplifyRowWiseAgg rowSums(M)-&gt;M if x is col vector</p><p>G P ¬Opt AND P V iews PIPELINES REWRITES    </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<ptr target="https://www.monetdb.org/blog/embedded-pythonnumpy-monetdb" />
		<title level="m">Embedded</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<ptr target="https://numpy.org/" />
		<title level="m">NumPy</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">R</forename></persName>
		</author>
		<ptr target="https://www.r-project.org/other-docs.html" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<ptr target="https://www.kaggle.com/kaggle-survey-2019" />
		<title level="m">Kaggle Survey</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title/>
		<ptr target="https://nijianmo.github.io/amazon/index.html" />
	</analytic>
	<monogr>
		<title level="j">Amazon Review Data</title>
		<imprint>
			<date type="published" when="2018">2018. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Breeze</forename><surname>Wiki</surname></persName>
		</author>
		<ptr target="https://github.com/scalanlp/breeze/wiki" />
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<ptr target="https://www.kaggle.com/netflix-inc/netflix-prize-data" />
		<title level="m">Netflix movie rating dataset</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<ptr target="https://spark.apache.org/mllib" />
		<title level="m">Sparkmllib</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<ptr target="https://apache.github.io/systemds/native-backend" />
		<title level="m">Using Native Blas in SystemDS</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Tensorflow: A system for large-scale machine learning</title>
		<author>
			<persName><forename type="first">M</forename><surname>Abadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Barham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Devin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ghemawat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Irving</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Isard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">12th {USENIX} symposium on operating systems design and implementation ({OSDI} 16)</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="265" to="283" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Foundations of Databases</title>
		<author>
			<persName><forename type="first">S</forename><surname>Abiteboul</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Hull</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Vianu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995">1995</date>
			<publisher>Addison-Wesley</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Faq: questions asked frequently</title>
		<author>
			<persName><forename type="first">M</forename><surname>Khamis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">Q</forename><surname>Ngo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rudra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 35th ACM SIGMOD-SIGACT-SIGAI Symposium on Principles of Database Systems</title>
		<meeting>the 35th ACM SIGMOD-SIGACT-SIGAI Symposium on Principles of Database Systems</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="13" to="28" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Towards scalable hybrid stores: Constraint-based rewriting to the rescue</title>
		<author>
			<persName><forename type="first">R</forename><surname>Alotaibi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Bursztyn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Deutsch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Manolescu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zampetakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 International Conference on Management of Data</title>
		<meeting>the 2019 International Conference on Management of Data</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">ESTO-CADA: towards scalable polystore systems</title>
		<author>
			<persName><forename type="first">R</forename><surname>Alotaibi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Cautis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Deutsch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Latrache</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Manolescu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. VLDB Endow</title>
		<meeting>VLDB Endow</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="2949" to="2952" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Spark sql: Relational data processing in spark</title>
		<author>
			<persName><forename type="first">M</forename><surname>Armbrust</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">S</forename><surname>Xin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Lian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Huai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">K</forename><surname>Bradley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kaftan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Franklin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ghodsi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 ACM SIGMOD international conference on management of data</title>
		<meeting>the 2015 ACM SIGMOD international conference on management of data</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1383" to="1394" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Linear Algebra Done Right</title>
		<author>
			<persName><forename type="first">S</forename><surname>Axler</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015">2015</date>
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Tfx: A tensorflow-based production-scale machine learning platform</title>
		<author>
			<persName><forename type="first">D</forename><surname>Baylor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Breck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H.-T</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Fiedel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">Y</forename><surname>Foo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Haque</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Haykal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ispir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Koc</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
		<meeting>the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1387" to="1395" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Systemml: Declarative machine learning on spark</title>
		<author>
			<persName><forename type="first">M</forename><surname>Boehm</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">W</forename><surname>Dusenberry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Eriksson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">V</forename><surname>Evfimievski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">M</forename><surname>Manshadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Pansare</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Reinwald</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">R</forename><surname>Reiss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Sen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Surve</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the VLDB Endowment</title>
		<meeting>the VLDB Endowment</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="1425" to="1436" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Declarative machine learning-a classification of basic properties and types</title>
		<author>
			<persName><forename type="first">M</forename><surname>Boehm</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">V</forename><surname>Evfimievski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Pansare</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Reinwald</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1605.05826</idno>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">On optimizing operator fusion plans for large-scale machine learning in systemml</title>
		<author>
			<persName><forename type="first">M</forename><surname>Boehm</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Reinwald</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Hutchison</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Sen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">V</forename><surname>Evfimievski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Pansare</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the VLDB Endowment</title>
		<meeting>the VLDB Endowment</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">11</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Probabilistic demand forecasting at scale</title>
		<author>
			<persName><forename type="first">J.-H</forename><surname>Böse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Flunkert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gasthaus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Januschowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Lange</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Salinas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Schelter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Seeger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the VLDB Endowment</title>
		<meeting>the VLDB Endowment</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="1694" to="1705" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Optimal implementation of conjunctive queries in relational data bases</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Chandra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">M</forename><surname>Merlin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ninth annual ACM symposium on Theory of computing</title>
		<meeting>the ninth annual ACM symposium on Theory of computing</meeting>
		<imprint>
			<date type="published" when="1977">1977</date>
			<biblScope unit="page" from="77" to="90" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">The university of florida sparse matrix collection</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">A</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Hu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011">2011</date>
			<publisher>TOMS</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><surname>Deutsch</surname></persName>
		</author>
		<title level="m">Fol modeling of integrity constraints</title>
		<imprint/>
	</monogr>
	<note>dependencies</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Query reformulation with constraints</title>
		<author>
			<persName><forename type="first">A</forename><surname>Deutsch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Popa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Tannen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM SIGMOD Record</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="65" to="73" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">The BigDAWG polystore system</title>
		<author>
			<persName><forename type="first">J</forename><surname>Duggan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGMOD</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">The madlib analytics library: or mad skills, the sql</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Hellerstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Ré</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Schoppmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Fratkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gorajek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">S</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Welton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the VLDB Endowment</title>
		<meeting>the VLDB Endowment</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="1700" to="1711" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Kernel methods match deep neural networks on timit</title>
		<author>
			<persName><forename type="first">P.-S</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Avron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">N</forename><surname>Sainath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Sindhwani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Ramabhadran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="205" to="209" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Query rewriting using views : a theoretical and practical perspective</title>
		<author>
			<persName><forename type="first">I</forename><surname>Ileana</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014-10">Oct. 2014</date>
		</imprint>
		<respStmt>
			<orgName>Télécom ParisTech</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Theses</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Complete yet practical search for minimal query reformulations under constraints</title>
		<author>
			<persName><forename type="first">I</forename><surname>Ileana</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Cautis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Deutsch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Katsis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 ACM SIGMOD international conference on Management of data</title>
		<meeting>the 2014 ACM SIGMOD international conference on Management of data</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="1015" to="1026" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Bringing linear algebra objects to life in a column-oriented in-memory database</title>
		<author>
			<persName><forename type="first">D</forename><surname>Kernert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Köhler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Lehner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Memory Data Management and Analysis</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="44" to="55" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Data management in machine learning: Challenges, techniques, and systems</title>
		<author>
			<persName><forename type="first">A</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Boehm</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 ACM International Conference on Management of Data</title>
		<meeting>the 2017 ACM International Conference on Management of Data</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1717" to="1722" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Model selection management systems: The next frontier of advanced analytics</title>
		<author>
			<persName><forename type="first">A</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Mccann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Naughton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Patel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM SIGMOD Record</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="17" to="22" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">An intermediate representation for optimizing machine learning pipelines</title>
		<author>
			<persName><forename type="first">A</forename><surname>Kunft</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Katsifodimos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Schelter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Breß</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Rabl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Markl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the VLDB Endowment</title>
		<meeting>the VLDB Endowment</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="1553" to="1567" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Linear algebra: theory and applications</title>
		<author>
			<persName><forename type="first">K</forename><surname>Kuttler</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012">2012</date>
			<publisher>The Saylor Foundation</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Scalable linear algebra on a relational database system</title>
		<author>
			<persName><forename type="first">S</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gubanov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">L</forename><surname>Perez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Jermaine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Knowledge and Data Engineering</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1224" to="1238" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Optimization, maxent models, and conditional estimation without magic</title>
		<author>
			<persName><forename type="first">C</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Klein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2003 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology: Tutorials</title>
		<meeting>the 2003 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology: Tutorials</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="8" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Mllib: Machine learning in apache spark</title>
		<author>
			<persName><forename type="first">X</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bradley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Yavuz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Sparks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Venkataraman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Freeman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Amde</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Owen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1235" to="1241" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Rule-based production of mathematical expressions</title>
		<author>
			<persName><forename type="first">M</forename><surname>Milani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Hosseinpour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Pehlivan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mathematics</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="11" to="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Hidden technical debt in machine learning systems</title>
		<author>
			<persName><forename type="first">D</forename><surname>Sculley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Holt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Golovin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Davydov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Phillips</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Ebner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Chaudhary</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Young</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-F</forename><surname>Crespo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Dennison</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="2503" to="2511" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Mnc: Structure-exploiting sparsity estimation for matrix expressions</title>
		<author>
			<persName><forename type="first">J</forename><surname>Sommer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Boehm</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">V</forename><surname>Evfimievski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Reinwald</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Haas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 International Conference on Management of Data</title>
		<meeting>the 2019 International Conference on Management of Data</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1607" to="1623" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Automating model search for large scale machine learning</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">R</forename><surname>Sparks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Talwalkar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Haas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Franklin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kraska</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Sixth ACM Symposium on Cloud Computing</title>
		<meeting>the Sixth ACM Symposium on Cloud Computing</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="368" to="380" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">A comparative evaluation of systems for scalable linear algebra-based analytics</title>
		<author>
			<persName><forename type="first">A</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kumar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the VLDB Endowment</title>
		<meeting>the VLDB Endowment</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="2168" to="2182" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">The myria big data management and analytics system and cloud services</title>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Baker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Balazinska</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Halperin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Haynes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Howe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Hutchison</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Maas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Mehta</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">SPORES: sum-product optimization via relational equality saturation for large scale linear algebra</title>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">R</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Hutchison</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Leang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Howe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Suciu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
