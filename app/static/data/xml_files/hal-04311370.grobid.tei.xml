<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="fr">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">PSYCHIC: A Neuro-Symbolic Framework for Knowledge Graph Question-Answering Grounding</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Hanna</forename><forename type="middle">Abi</forename><surname>Akl</surname></persName>
							<email>hanna.abi-akl@dsti.institute</email>
							<affiliation key="aff0">
								<orgName type="department">Data ScienceTech Institute (DSTI)</orgName>
								<address>
									<addrLine>4 Rue de la Collégiale</addrLine>
									<postCode>75005</postCode>
									<settlement>Paris</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution" key="instit1">Université Côte d&apos;Azur</orgName>
								<orgName type="institution" key="instit2">Inria</orgName>
								<orgName type="institution" key="instit3">CNRS</orgName>
								<address>
									<region>I3S</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Hanna</forename><surname>Abi</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Akl</forename><surname>Psychic</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Manolis</forename><surname>Koubarakis</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Valentina</forename><surname>Ivanova</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Wen</forename><surname>Zhang</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Dimitris</forename><surname>Plexousakis</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Vassilis</forename><surname>Christophides</surname></persName>
						</author>
						<author>
							<persName><forename type="first">;</forename><surname>Heng</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Haofen</forename><surname>Wang</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Andrea</forename><surname>Nuzzolese</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Evgeny</forename><surname>Kharlamov</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Zoi</forename><surname>Kaoudi</surname></persName>
						</author>
						<author>
							<persName><forename type="first">;</forename><surname>Gong</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Heiko</forename><surname>Paulheim</surname></persName>
						</author>
						<author>
							<persName><forename type="first">;</forename><surname>Cogan</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Eleni</forename><surname>Tsalapati</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Ioannis</forename><surname>Chrysakis</surname></persName>
						</author>
						<author>
							<persName><forename type="first">George</forename><surname>Vouros</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Ioannis</forename><surname>Karatzanis</surname></persName>
						</author>
						<author>
							<persName><forename type="first">;</forename><surname>Lei</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Terry</forename><forename type="middle">R</forename><surname>Payne</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Valentina</forename><surname>Presutti</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Guilin</forename><surname>Qi</surname></persName>
						</author>
						<author>
							<persName><forename type="first">María</forename><surname>Poveda-Villalón</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Bo</forename><surname>Fu</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Giorgos</forename><surname>Stoilos</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Laura</forename><surname>Hollink</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Jose</forename><forename type="middle">Manuel</forename><surname>Gomez-Perez</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Daniel</forename><surname>Garijo</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Jeff</forename><forename type="middle">Z</forename><surname>Claudia D'amato</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Irini</forename><surname>Pan</surname></persName>
						</author>
						<author>
							<persName><surname>Fundulaki</surname></persName>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="institution">HannaAbiAkl</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="institution">Scholarly QALD at</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff4">
								<orgName type="department">⋆ Scholarly QALD</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">PSYCHIC: A Neuro-Symbolic Framework for Knowledge Graph Question-Answering Grounding</title>
					</analytic>
					<monogr>
						<idno type="ISSN">1613-0073</idno>
					</monogr>
					<idno type="MD5">B34A0779811E8A1451D60F6A8DE98497</idno>
					<note type="submission">Submitted on 28 Nov 2023</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-04-12T14:45+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Question Answering</term>
					<term>Knowledge Graphs</term>
					<term>Neuro-Symbolic Artificial Intelligence</term>
					<term>Entity Linking</term>
					<term>Linked Data</term>
					<term>Language Models</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>ou non, émanant des établissements d'enseignement et de recherche français ou étrangers, des laboratoires publics ou privés.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="fr">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Knowledge veracity has always been one of the key topics of the Web <ref type="bibr" target="#b0">[1]</ref>. The ability to present users with a body of factual information to refer to is a challenge that continues to defy the growth of the web <ref type="bibr" target="#b0">[1]</ref>. In particular, the plethora of available information is plagued by the non-structured nature of this knowledge <ref type="bibr" target="#b0">[1]</ref>.</p><p>One way the Semantic Web community addresses this issue is by constructing KGs which are structured repertoires of entities and relationships <ref type="bibr" target="#b0">[1]</ref>. These graphs encapsulate factual knowledge and allow users to retrieve it by navigating their different connections <ref type="bibr" target="#b0">[1]</ref>. The DBLP computer science bibliography is an example of such an effort that provides open bibliographic information on major computer science journals and proceedings <ref type="bibr" target="#b1">[2]</ref>.</p><p>Aside from consolidating bodies of information, KGs provide a platform for information retrieval <ref type="bibr" target="#b0">[1]</ref>. In artificial intelligence (AI), question answering refers to the task of asking an AI agent a question and receiving an answer in return <ref type="bibr" target="#b2">[3]</ref>. Large Language Models (LLMs) are popular agents that fill this role well due to their nature of ingesting huge amounts of information <ref type="bibr" target="#b3">[4]</ref>. However, this also makes them prone to giving out misinformation based on their inability to disseminate correct from incorrect knowledge <ref type="bibr" target="#b3">[4]</ref>.</p><p>Integrating LLMs and KGs has emerged as a solution to mitigate the shortcomings of large language models <ref type="bibr" target="#b3">[4]</ref>. By querying a factual base of information, LLMs gain a way to validate their responses before sending them back to users <ref type="bibr" target="#b3">[4]</ref>. It is in this scope that the Scholarly QALD challenge presents its two sub-tasks, DBLP-QuAD and SciQA. We focus on DBLP-QuAD, a QA task over the DBLP<ref type="foot" target="#foot_0">1</ref> KG. We distinguish two parts in the challenge: question answering, which requires participants to propose systems capable of retrieving specific information from the KG to answer a question, and entity linking, which requires participants to retrieve the list of entities related to a question.</p><p>In this paper, we show how a NS system can handle the tasks of QA and EL over a KG. The rest of the paper is organized as follows. In section 2, we discuss some of the related work. In section 3, we present the experimental setup. In section 4, we discuss the results. Finally, we present our conclusions in section 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>This section reviews some of the proposed systems designed for QA and EL over KGs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Question answering over knowledge graphs</head><p>Several techniques have emerged to tackle the problem of QA over KGs. Zheng and Zhang make use of structured query patterns which involve identifying query graph candidates in the KG using EL and disambiguation and transforming them to SPARQL queries <ref type="bibr" target="#b4">[5]</ref> to answer questions. Pramanik et al. employs a similar approach by proposing a model that draws from relevant RDF triples to generate all possible query context graphs from which queries are created to answer natural language questions. Their findings result in an advancement in graph-based methods but prove their approach to be highly noisy <ref type="bibr" target="#b5">[6]</ref>. Sima et al. improve on this approach by leveraging graph algorithms to identify and rank domain-specific query candidates based on the node centrality of the relevant entities <ref type="bibr" target="#b6">[7]</ref>. Zheng et al. go a step further in this direction by integrating semantic parsers to their query templates to refine the query-generation process. By aligning both natural language questions and query templates, they prove they can effectively answer complex and detailed questions <ref type="bibr" target="#b7">[8]</ref>.</p><p>Nikas et al. combine graph-based techniques with neural-based methods to create a NS QA system <ref type="bibr" target="#b8">[9]</ref>. In their work, they train a DistilBERT model based on an expected answer type to handle different kinds of questions <ref type="bibr" target="#b8">[9]</ref>. The neural network also leverages SPARQL queries to gather facts for entity enrichment and boost its performance in extracting the correct answer from the provided context <ref type="bibr" target="#b8">[9]</ref>. Cm et al. propose a similar pipeline by replacing the SPARQL endpoint with a supervised BERT model that performs relation extraction to add context information to the system <ref type="bibr" target="#b9">[10]</ref>.</p><p>Diomedi and Hogan propose a different approach by using neural machine translation to map the questions in natural language to SPARQL templates directly. They show that this method, coupled with tree-based entity disambiguation techniques, turns the QA problem to a slot-filling task and outperforms vanilla deep learning (DL) models <ref type="bibr" target="#b10">[11]</ref>. Aghaei et al. leverage a similar slot-filling pipeline on a domain-specific KG to demonstrate that it can reliably learn the pattern structures of the domain queries <ref type="bibr" target="#b11">[12]</ref>.</p><p>In their work, Mavromatis and Karypis and Li et al. leverage graph networks to compute graph embeddings and compare them with the input question embeddings to target the correct answer entities <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b13">14]</ref>. Dutt et al. utilize graph convolution networks to score questions based on similarity and derive their corresponding graph paths to answer new questions <ref type="bibr" target="#b14">[15]</ref>.</p><p>Saxena et al. and Zuo et al. demonstrate how using KG embeddings can help solve multi-hop questions <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b16">17]</ref>. Rony et al. propose a system whereby KG embeddings are stored in a vector database for faster retrieval and improved performance in answering complex questions <ref type="bibr" target="#b17">[18]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Entity linking over knowledge graphs</head><p>Shi et al. present a survey on the techniques seen in EL over KGs. They regroup approaches into rule-based, machine learning (ML) and DL EL methods <ref type="bibr" target="#b18">[19]</ref>. In their work, Dubey et al. use rule-based methods by leveraging global traveling salesman approximate solver algorithms to disambiguate entities in large KGs <ref type="bibr" target="#b19">[20]</ref>. Steinmetz employ abstract meaning representation, a series of text dependency parsing rules, to identify and group sentences having the same meaning but different structures <ref type="bibr" target="#b20">[21]</ref>. Using this technique, they perform data augmentation to enrich entity representation and achieve better performance on the EL task <ref type="bibr" target="#b20">[21]</ref>. In a similar fashion, Radhakrishnan et al. use co-occurrences from large corpora to enrich existing KGs with entity information and create dense KGs as a basis for EL <ref type="bibr" target="#b21">[22]</ref>.</p><p>Thawani et al. employ ML techniques by combining TF-IDF with Wikidata entries to generate feature vectors and score entity candidates accordingly <ref type="bibr" target="#b22">[23]</ref>. Li et al. make use of translating embeddings to encode entity-entity relationships and combine them with entity-relation embeddings to get better performance over KGs <ref type="bibr" target="#b23">[24]</ref>.</p><p>From a DL perspective, Huang et al. show that using BERT to calculate sentence embeddings over entities outperforms rule-based entity enrichment approaches <ref type="bibr" target="#b24">[25]</ref>. Banerjee et al. improve on this approach by concatenating entity embeddings with context using FastText embeddings in a pointer network entity linker structure designed to represent entities in a dense vector space and identify the correct one for any input entity <ref type="bibr" target="#b25">[26]</ref>.</p><p>Finally, Ding et al. propose a NS approach based on EL using SpaCy embeddings in a casebased reasoning by computing the cosine score between input entity embeddings and KG entity embeddings <ref type="bibr" target="#b26">[27]</ref>. The final entity is computed automatically according to the best matching embedding or manually labeled based on a threshold cosine score <ref type="bibr" target="#b26">[27]</ref>. Diomedi and Hogan experiment with a pipeline that integrates rule-based entity matching over DBpedia and Wikidata KGs and neural network models to associate the resulting entities to a fixed set from a designed KG <ref type="bibr" target="#b27">[28]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Dataset description</head><p>The dataset considered for this shared task is divided in two parts: the DBLP-QuAD<ref type="foot" target="#foot_2">2</ref> dataset which consists of 10000 question-SPARQL pairs and is answerable over the DBLP KG, and a dataset of 500 questions retaining the same format provided by the task organizers which will be referred to as seed data. We provide details for both datasets in the following subsections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.1.">DBLP-QuAD data</head><p>DBLP-QuAD is a scholarly KGQA dataset with 10,000 question-SPARQL query pairs targeting the DBLP KG. DBLP-QuAD was created using the OVERNIGHT approach where logical forms are first generated from a KG. Canonical questions are then generated from these logical forms. The dataset is split into 7,000 training, 1,000 validation and 2,000 test questions. Each question-SPARQL pair consists of the following data fields: the id of the question (id), a string containing the question (question), a paraphrased version of the question (paraphrased_question), a SPARQL query that answers the question (query), the type of the query (query_type), the template of the query (template_id), a list of entities in the question (entities), a list of relations in the question (relations), a boolean indicating whether the question contains a temporal expression (temporal) and a boolean indicating whether the question is held out from the training set (held_out). Sample data is shown in Figure <ref type="figure" target="#fig_0">1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.2.">Seed data</head><p>Participants are provided with seed data to evaluate the performance of their systems on the QA and EL sub-tasks. This data is curated by the task organizers and consists of 500 random question-SPARQL pairs that comply with the same format as the DBLP-QuAD data. For the final evaluation, the organizers provided an additional set of 500 random questions containing only the question and its paraphrase. This dataset was used exclusively to score the performance of the participant systems in both sub-tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">System description</head><p>This section introduces our proposed system. It presents the system architecture and describes the training process in our experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1.">PSYCHIC model</head><p>Since the challenge presents itself as a QA task, we selected the DistilBERT-base uncased<ref type="foot" target="#foot_3">3</ref> model to tackle it in an extractive QA setting. Extractive QA confines a model to selecting the appropriate answer chunk from a context given as input with the question. It also leverages some control over the model answers as opposed to generative QA which makes models generate the answer. Training a QA model involves giving the model an input composed of the question to be answered and a context that should contain the answer. In the scope of this shared task, we targeted two types of answers: the SPARQL query which should directly answer the given question and the list of entities for EL. We constructed the context to include both pieces of information and added information to guide the model regarding the nature of the question asked and the expected SPARQL answer: the query type and the template id provided in the DBLP-QuAD data. We also introduced symbolic information through a symbolic rule engine that inserts the special tokens [CLS] at the start of the context string and [SEP] between the different pieces of information in the context. These markers were added to ground the output of the model and enable it to discriminate between the different pieces of context information. The aim is to help the model learn the types of query structures and entities it will be asked to retrieve.</p><p>On the output side, we fine-tuned our PSYCHIC (Pre-trained SYmbolic CHecker In Context) model to return both the SPARQL query and the list of entities. We constructed the output as a string containing both pieces of information separated by the [SEP] token. We also introduced another symbolic rule engine which is a programmatic function designed to split the output string based on the [SEP] symbol to return the query and entities chunks separately. The PSYCHIC model architecture is presented in Figure <ref type="figure" target="#fig_1">2</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2.">Pipeline architecture</head><p>To answer both parts of the shared task, we need to return a result from a SPARQL query for the QA challenge and an entity list for the EL challenge. In that respect, the PSYCHIC model alone is not enough. The QA challenge defines an answer as the result of a SPARQL query, whereas PSYCHIC returns the queries themselves. This is a deliberate design choice since teaching a model to recognize patterned query structures is still an easier problem than teaching it to learn dynamic answers ranging from boolean values to lists of elements. Being able to correctly return the right query is essentially the hard part of the challenge, and the additional step to get the final answer consists in running the query returned by PSYCHIC using the SPARQL endpoint provided by the task organizers.</p><p>As such, we built the NS framework shown in Figure <ref type="figure" target="#fig_2">3</ref> to leverage the power of LLMs and symbolic reasoning. It takes as input the question-SPARQL pairs, processes them and prepares the question-context dataset needed for the PSYCHIC model. The model predicts the output in the form of a string containing the query, the separator [SEP] and the entity list. Two additional modules, the query and entity sanitizers, extract the relevant pieces of information from the output, namely the query and the entity list, by splitting the output string and validating the query and entity elements by matching them to their respective patterns. Through this sanitization process, these modules can perform error-correction to account for malformed strings returned by the model, e.g., transforming 'select distinct? answer where {? answer &lt; https : / / dblp. org / rdf / schema # authoredby &gt; &lt; https : / / dblp. org / pid / 00 / 2941 &gt; }' to 'select distinct ?answer where { ?answer &lt;https://dblp.org/rdf/schema#authoredBy&gt; &lt;https://dblp.org/pid/00/2941&gt; }' for the query and ['&lt; https : / / dblp. org / pid / 00 / 2941 &gt;'] to ['&lt;https://dblp.org/pid/00/2941&gt;'] for the entity list.</p><p>The resulting output from the query sanitizer module is a correctly-formed SPARQL query that is run using the SPARQL endpoint to return the expected final answer. The output of the entity sanitizer is the correctly-formed entity list. For the inference step, we distinguished two phases: the dev phase and the final phase. The dev phase corresponds to the phase when the first 500 random question-SPARQL pairs are made available by the organizers. The final phase represents the true system evaluation phase whereby the dataset used is the set of 500 random questions (and their paraphrases). The phases differ by the nature of the input given to the PSYCHIC model. In the dev phase, the context was constructed the same way as for DBLP-QuAD, i.e., following the [CLS] + QUERY_TYPE + [SEP] + TEMPLATE_ID + [SEP] + QUERY + [SEP] + ENTITIES pattern. In the final phase, since the only available information is the question and its paraphrase, we used an entity linker provided by the task organizers that leverages a t5-base language model with translating embeddings to return a list of predicted entities for each provided question. These results were concatenated using the symbolic rule engine to form a different context pattern, i.e., [CLS] + EL_RESULT1 + [SEP] + EL_RESULT2 + [SEP] + ... + [SEP] + EL_RESULTN for N returned entity results.</p><p>We used the F1-QA and F1-EL metrics, representing the F1 scores on each of the QA and EL sub-tasks respectively, to evaluate our system. All experiments were performed on a Dell G15 Special Edition 5521 hardware with 14 CPU Cores, 32 GB RAM and NVIDIA GeForce RTX 3070 Ti GPU.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Results</head><p>Table <ref type="table">1</ref> displays the training results of the PSYCHIC model. Over 3 epochs, the model learns consistently with a perfect loss of 0 by the third epoch. Having integrated symbolic knowledge through the insertion of special tokens in the context proves to be a sound way to represent the different context chunks we want the model to learn. By the end of training, PSYCHIC can reliably return a complex output constituted of a query and an entity list for an input question.</p><p>The results of Table <ref type="table">2</ref> seem to corroborate these findings. In the dev phase, the seed input structure is identical to that of DBLP-QuAD which means that PSYCHIC expects a similar context pattern. The model achieves a perfect score on both the QA and EL sub-tasks which suggests it is perfectly capable of discriminating query tokens from entity tokens. The results of the final phase are interesting in the sense that they seem to contradict this theory. The F1-QA score in particular suggests the model fails to predict any question query correctly. The reason for this bad performance lies in the fact that the input structure for the final phase set is radically different from the DBLP-QuAD and dev data as it contains no accompanying context for questions. Since PSYCHIC is an extractive QA model, it becomes very challenging for it to predict any kind of information without relevant context. We were not able to fill this context gap in the scope of this challenge. For the EL sub-task, we were able to fill the gap by using the entity linker predictions as missing context for the input questions. Because these context patterns were unseen by PSYCHIC during the training and dev phases, the F1-EL score achieved by the model is impressive since it reveals it can correctly identify valid entity pattern structures. This performance ranks PSYCHIC at third overall in the EL sub-task final standings as shown in Table <ref type="table" target="#tab_0">3</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Epoch Training Loss Step</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>In this shared task, we propose a NS framework to tackle QA and EL sub-tasks over a KG. We explore the effects of including symbolic learning in the context of LLMs and evaluate the overall performance on the sub-tasks for a changing context. In the future, we plan to extend these symbolic mechanisms to generative models such as retrieval augmented generation (RAG) pipelines.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Example of DBLP-QuAD data</figDesc><graphic coords="6,89.29,84.19,416.69,279.05" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: PSYCHIC model architecture</figDesc><graphic coords="7,89.29,84.19,416.69,269.98" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Solution system architecture</figDesc><graphic coords="8,89.29,177.36,416.71,133.10" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 3</head><label>3</label><figDesc>Final competition standings for the EL sub-task</figDesc><table><row><cell>Validation Loss</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>https://blog.dblp.org/2022/03/02/dblp-in-rdf/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_1"><p>This section describes the framework for our experiments in terms of data, system and training process.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_2"><p>https://huggingface.co/datasets/awalesushil/DBLP-QuAD</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_3"><p>https://huggingface.co/distilbert-base-uncased</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Knowledge graphs: Opportunities and challenges</title>
		<author>
			<persName><forename type="first">C</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Naseriparsa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Osborne</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence Review</title>
		<imprint>
			<biblScope unit="page" from="1" to="32" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<author>
			<persName><forename type="first">D</forename><surname>Banerjee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Awale</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Usbeck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Biemann</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2303.13351</idno>
		<title level="m">Dblp-quad: A question answering dataset over the dblp scholarly knowledge graph</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<author>
			<persName><forename type="first">K</forename><surname>Ishwari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Aneeze</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sudheesan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Karunaratne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Nugaliyadde</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Mallawarrachchi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1904.05276</idno>
		<title level="m">Advances in natural language question answering: A review</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">Z</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Razniewski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-C</forename><surname>Kalo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Singhania</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Dietze</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Jabeen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Omeliyanenko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lissandrini</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2308.06374</idno>
		<title level="m">Large language models and knowledge graphs: Opportunities and challenges</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Question answering over knowledge graphs via structural query patterns</title>
		<author>
			<persName><forename type="first">W</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1910.09760</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Uniqorn: unified question answering over rdf knowledge graphs and natural language text</title>
		<author>
			<persName><forename type="first">S</forename><surname>Pramanik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Alabi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">S</forename><surname>Roy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Weikum</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2108.08614</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Bio-soda ux: enabling natural language question answering over knowledge graphs with user disambiguation</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Sima</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Mendes De Farias</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Anisimova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Dessimoz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Robinson-Rechavi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Zbinden</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Stockinger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Distributed and Parallel Databases</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page" from="409" to="440" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Question answering over knowledge graphs: question understanding via template decomposition</title>
		<author>
			<persName><forename type="first">W</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">X</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Cheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the VLDB Endowment</title>
		<meeting>the VLDB Endowment</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="1373" to="1386" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Open domain question answering over knowledge graphs using keyword search, answer type prediction, sparql and pre-trained neural models</title>
		<author>
			<persName><forename type="first">C</forename><surname>Nikas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Fafalios</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Tzitzikas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Semantic Web-ISWC 2021: 20th International Semantic Web Conference, ISWC 2021, Virtual Event</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2021">October 24-28, 2021. 2021</date>
			<biblScope unit="page" from="235" to="251" />
		</imprint>
	</monogr>
	<note>Proceedings 20</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Question answering over knowledge graphs using bert based relation mapping</title>
		<author>
			<persName><forename type="first">S</forename><surname>Cm</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Prakash</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">K</forename><surname>Singh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Expert Systems</title>
		<imprint>
			<biblScope unit="page">13456</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Question answering over knowledge graphs with neural machine translation and entity linking</title>
		<author>
			<persName><forename type="first">D</forename><surname>Diomedi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Hogan</surname></persName>
		</author>
		<idno>arXiv.2107.02865</idno>
		<imprint>
			<date type="published" when="2021">2021. 2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Question answering over knowledge graphs: A case study in tourism</title>
		<author>
			<persName><forename type="first">S</forename><surname>Aghaei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Raad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Fensel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="69788" to="69801" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Rearev: Adaptive reasoning for question answering over knowledge graphs</title>
		<author>
			<persName><forename type="first">C</forename><surname>Mavromatis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Karypis</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2210.13650</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Improving question answering over knowledge graphs using graph summarization</title>
		<author>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">W</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">C</forename><surname>Fung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural Information Processing: 28th International Conference, ICONIP 2021</title>
		<meeting><address><addrLine>Sanur, Bali, Indonesia</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2021">December 8-12, 2021. 2021</date>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="489" to="500" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Perkgqa: Question answering over personalized knowledge graphs</title>
		<author>
			<persName><forename type="first">R</forename><surname>Dutt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Bhattacharjee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Gangadharaiah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Rose</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: NAACL 2022</title>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="253" to="268" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Improving multi-hop question answering over knowledge graphs using knowledge base embeddings</title>
		<author>
			<persName><forename type="first">A</forename><surname>Saxena</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Tripathi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Talukdar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th annual meeting of the association for computational linguistics</title>
		<meeting>the 58th annual meeting of the association for computational linguistics</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="4498" to="4507" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Improving question answering over knowledge graphs with a chunked learning network</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Zuo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Electronics</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page">3363</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Tree-kgqa: an unsupervised approach for question answering over knowledge graphs</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R A H</forename><surname>Rony</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Chaudhuri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Usbeck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lehmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="50467" to="50478" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Knowledge-graph-enabled biomedical entity linking: a survey</title>
		<author>
			<persName><forename type="first">J</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">World Wide Web</title>
		<imprint>
			<biblScope unit="page" from="1" to="30" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Earl: joint entity and relation linking for question answering over knowledge graphs</title>
		<author>
			<persName><forename type="first">M</forename><surname>Dubey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Banerjee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Chaudhuri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lehmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Semantic Web-ISWC 2018: 17th International Semantic Web Conference</title>
		<meeting><address><addrLine>Monterey, CA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2018">October 8-12, 2018. 2018</date>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="108" to="126" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Entity linking for kgqa using amr graphs</title>
		<author>
			<persName><forename type="first">N</forename><surname>Steinmetz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Semantic Web Conference</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="122" to="138" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Improved entity linking using densified knowledge graphs</title>
		<author>
			<persName><forename type="first">P</forename><surname>Radhakrishnan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Talukdar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Varma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elden</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1844" to="1853" />
		</imprint>
	</monogr>
	<note>Long Papers</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Entity linking to knowledge graphs to infer column types and properties</title>
		<author>
			<persName><forename type="first">A</forename><surname>Thawani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zafar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Divvala</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Qasemi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Szekely</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Pujara</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">semantic web challenge on tabular data to knowledge graph matching, iswc</title>
		<imprint>
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Improving entity linking by introducing knowledge graph structure information</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Dong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied Sciences</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page">2702</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<author>
			<persName><forename type="first">B</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<title level="m">Entity linking for short text using structured knowledge graph via multi-grained text matching</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Pnel: Pointer network based endto-end entity linking over knowledge graphs</title>
		<author>
			<persName><forename type="first">D</forename><surname>Banerjee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Chaudhuri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Dubey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lehmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Semantic Web-ISWC 2020: 19th International Semantic Web Conference</title>
		<meeting><address><addrLine>Athens, Greece</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020">November 2-6, 2020. 2020</date>
			<biblScope unit="page" from="21" to="38" />
		</imprint>
	</monogr>
	<note>Part I 19</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Jel: applying end-to-end neural entity linking in jpmorgan chase</title>
		<author>
			<persName><forename type="first">W</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">K</forename><surname>Chaudhri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Chittar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Konakanchi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="15301" to="15308" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Entity linking and filling for question answering over knowledge graphs</title>
		<author>
			<persName><forename type="first">D</forename><surname>Diomedi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Hogan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Natural Language Interfaces for the Web of Data (NLIWOD) Workshop</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
