<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Collaborative Ad Transparency: Promises and Limitations</title>
				<funder ref="#_9A2GTWh #_rbqbPkn #_MEM8pKj">
					<orgName type="full">Agence Nationale de la Recherche</orgName>
					<orgName type="abbreviated">ANR</orgName>
				</funder>
				<funder>
					<orgName type="full">Grenoble INP</orgName>
				</funder>
				<funder ref="#_HU6RwA8">
					<orgName type="full">EU</orgName>
				</funder>
				<funder ref="#_eRrPZtf #_Z2RpAJ6">
					<orgName type="full">unknown</orgName>
				</funder>
				<funder>
					<orgName type="full">CNRS</orgName>
				</funder>
				<funder>
					<orgName type="full">Inria</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Eleni</forename><surname>Gkiouzepi</surname></persName>
							<email>gkiouzepi@tu-berlin.de</email>
							<affiliation key="aff0">
								<orgName type="institution">Technical University of Berlin</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Athanasios</forename><surname>Andreou</surname></persName>
							<email>athanasios.andreou@ati.io</email>
							<affiliation key="aff1">
								<orgName type="department">Algorithmic Transparency Institute</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Oana</forename><surname>Goga</surname></persName>
							<email>oana.goga@cnrs.fr</email>
							<affiliation key="aff2">
								<orgName type="institution" key="instit1">CNRS</orgName>
								<orgName type="institution" key="instit2">Inria</orgName>
								<orgName type="institution" key="instit3">Institut Polytechnique de Paris</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Patrick</forename><surname>Loiseau</surname></persName>
							<email>patrick.loiseau@inria.fr</email>
							<affiliation key="aff3">
								<orgName type="institution" key="instit1">Inria</orgName>
								<orgName type="institution" key="instit2">FairPlay team</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Collaborative Ad Transparency: Promises and Limitations</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">7F3C5432A5238FB20C6AA9F3D4613CEF</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-04-12T14:45+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Several targeted advertising platforms offer transparency mechanisms, but researchers and civil societies repeatedly showed that those have major limitations. In this paper, we propose a collaborative ad transparency method to infer, without the cooperation of ad platforms, the targeting parameters used by advertisers to target their ads. Our idea is to ask users to donate data about their attributes and the ads they receive and to use this data to infer the targeting attributes of an ad campaign. We propose a Maximum Likelihood Estimator based on a simplified Bernoulli ad delivery model. We first test our inference method through controlled ad experiments on Facebook. Then, to further investigate the potential and limitations of collaborative ad transparency, we propose a simulation framework that allows varying key parameters. We validate that our framework gives accuracies consistent with real-world observations such that the insights from our simulations are transferable to the real world. We then perform an extensive simulation study for ad campaigns that target a combination of two attributes. Our results show that we can obtain good accuracy whenever at least ten monitored users receive an ad. This usually requires a few thousand monitored users, regardless of population size. Our simulation framework is based on a new method to generate a synthetic population with statistical properties resembling the actual population, which may be of independent interest.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>Online advertising platforms have access to massive amounts of user data, which allows them to provide advertisers with powerful ways to target specific users according to a detailed range of characteristics and delivery optimization techniques. Advertisers can target users interested in specific topics such as tennis and rock climbing (attribute-based targeting), that visited their website (retargeting), or that are similar to their customers (lookalike audiences), to name a few <ref type="bibr" target="#b0">[1]</ref>.</p><p>Governments and NGOs around the world <ref type="bibr" target="#b1">[2]</ref>- <ref type="bibr" target="#b6">[7]</ref>, have been pushing online platforms to make the inner workings of their advertising systems more transparent to the public. As a result, several ad platforms implemented transparency mechanisms, such as Facebook's "Why am I seeing this ad?". While this is a positive step, recent reports emphasize that the information provided in these explanations is limited and only shows one (of many) targeting parameters used by the advertiser <ref type="bibr" target="#b7">[8]</ref>- <ref type="bibr" target="#b10">[11]</ref>. Similar limitations exist in Political Ad Libraries (public repositories aggregating political ads run on the platform). For instance, Facebook only provides information about the location, age, and gender of users who received the ad and gives no information on the actual targeting parameters used by the advertisers. Hence, despite positive developments, we still lack grounded information about the targeting parameters used to deliver ads.</p><p>To increase the level of transparency of online platforms, researchers and lawmakers have called for independent auditing systems that allow citizens to participate in the process of building a healthier web by donating data about the content they see online <ref type="bibr" target="#b11">[12]</ref>, <ref type="bibr" target="#b12">[13]</ref>. There are several existing tools such as AdAnalyst <ref type="bibr" target="#b13">[14]</ref>, Ad Observer <ref type="bibr" target="#b14">[15]</ref>, and WhoTargetsMe <ref type="bibr" target="#b15">[16]</ref> that collect ads from volunteers and have been installed by thousands of users. These tools showed their utility on multiple occasions by providing data essential to show limitations with Ad Libraries <ref type="bibr" target="#b16">[17]</ref>, <ref type="bibr" target="#b17">[18]</ref>, or the existence of discriminating, manipulatory and illegal advertising <ref type="bibr" target="#b16">[17]</ref>, <ref type="bibr" target="#b18">[19]</ref>- <ref type="bibr" target="#b20">[21]</ref>.</p><p>In this paper, we investigate whether we can infer, through independent auditing and without the cooperation of ad platforms, the targeting parameters used by advertisers to target their ads. Specifically, we focus on attribute-based targeting where an advertiser targets users that satisfy a combination of selected attributes (called the targeting formula), and we investigate whether data collected from a set of volunteer monitored users (their attributes and the ads they receive) can be used to infer the targeting formula-we term this collaborative ad transparency. Such a solution would be practical because we can easily monitor the attributes of users (from their Ad Preferences page where platforms list all attributes they inferred about a user) and the ads they receive (through browser extensions such as AdAnalyst and Ad Observer). However, we currently do not know whether such inference can achieve reasonable accuracy and in which conditions.</p><p>Our methodological and experimental contributions are: <ref type="bibr" target="#b0">(1)</ref> We propose an estimator that infers the targeting formula by analyzing the attributes of users who received the ad and of users who did not (Section II). Our estimator uses the maximum likelihood principle based on a simplified Bernoulli model of ad delivery where all users satisfying the attributes in the targeting formula receive the ad with equal probability (encoding the ad campaign budget). To handle realistic cases where the campaign budget is unknown, we also propose an estimation procedure based on Expectation-Maximization. <ref type="bibr" target="#b1">(2)</ref> We propose an experimental setup that allows us to test the accuracy of our estimator in the real world (Section III). For this, we recruited 420 Facebook users and asked them to install a browser extension we developed that can monitor the ads they receive and the attributes Facebook inferred about them (their Ad Preference page). Then, we assume the role of the advertiser and create ad campaigns that target users with various attributes; this gives us access to the ground truth targeting formula. We performed 79 real-world controlled experiments on Facebook, out of which 45 reached three or more of our monitored users. Our results show that we infer the targeting formula correctly in 17 cases. However, if we only look at experiments where our ad has been received by ten or more monitored users, the accuracy increases to 65%. Hence, despite making a number of simplifying assumptions, the real-world experiments show an interesting potential for collaborative ad transparency, provided enough monitored users receive the ad.</p><p>(3) Providing a detailed understanding of the accuracy of collaborative ad transparency under different conditions (e.g., number of monitored users, prevalence of the targeting attributes) entails a significant difficulty: it is too costly to do it through controlled experiments on the real platform. To bypass this difficulty, we propose a simulation framework that enables us to analyze the impact of various parameters on inference accuracy extensively. The framework is based on a synthetic users population and a simplified Bernoulli model to generate ground truth data (i.e., simulate which users receive the ad).</p><p>A key challenge for obtaining results with external validity is to base the simulations on a synthetic population that resembles the real population (Section IV). We propose a method based on correlated binary vectors to generate a synthetic population of users such that the distribution of attributes matches a predefined distribution at second-order (probability of having any pair of attributes). We apply it to generate populations of 10 6 users that match the distribution of Facebook's population over 322 attributes. Our proposed method generates users that are i.i.d. and is suitable for generating high-dimensional data. Further, the population statistical characteristics match beyond second-order (third-order and number of attributes per user). <ref type="bibr" target="#b3">(4)</ref> To validate that our simulation framework captures advertising on the real platform soundly, we recreate the 45 real-world controlled ad experiments (Section V). Then, we confront the estimator's accuracy in the wild with the estimator's accuracy in our simulations. The accuracy is consistent in 82.2% of all ad experiments. Focusing on experiments where ads are received by 10 or more users, the simulation accuracy is 86.1% where it was only 65% in the Facebook experiments. However, recreating the simulations in a way that mimics the bias in the set of monitored users brings the accuracy down to 73.8%. Not only does it explain the major factor behind the accuracy discrepancy, but it also shows that our simulation framework allows quantifying the effect on accuracy of bias in the set of monitored users. Finally, this indicates that the Bernoulli model of ad delivery, while simplifying, does not majorly affect the estimated accuracy in our simulation study. <ref type="bibr" target="#b4">(5)</ref> We perform extensive simulations (Section VI). We consider the case where the targeting formula consists of the conjunction of two attributes (but the framework extends to more complex formulas), and we estimate the inference accuracy in relation to the targeting formula, ad budget, and number of monitored users. Our results show that our estimators remain equally accurate even if we do not know the real ad budget.</p><p>We observe an accuracy of over 75%, on average over a wide range of targeting formulas and ad budgets, as long as the ad campaign reaches 0.005 of the entire population while only monitoring 700 users. <ref type="foot" target="#foot_0">1</ref> We also see that if an ad is received by ten or more monitored users, we can expect an inference accuracy of over 90% irrespective of the number of monitored users. The number of monitored users plays an indirect role by impacting the likelihood for a given campaign that enough monitored users receive the ad. This is positive since (i) good accuracy may be achievable within reasonable circumstances and (ii) it allows us to evaluate the confidence in the inference from observed data. Finally, our results show that the number of monitored users required for good accuracy does not increase with the population size, which gives scalability.</p><p>Overall, the combination of our simulations and real-world experiments allows us to shed light on the conditions under which collaborative ad transparency may work and the challenges to get good accuracy. Our study is based on a number of simplifying assumptions that enable a rigorous analysis, in particular our Bernoulli ad delivery model. In practice, ad delivery is more complex. We provide a detailed discussion of the impact of these assumptions and of the limitations of collaborative ad transparency in Section VIII.</p><p>Our study is inspired by Facebook's ad platform, but it applies broadly as attribute-based targeting is common in online advertising. Understanding the promises and limits of collaborative ad transparency is necessary even if Facebook were to provide complete ad targeting explanations: (1) it applies to other less-cooperative ad platforms; (2) it is critical to continuously audit the platform-provided explanations.</p><p>All of our code is publicly available at https://gitlab.inria. fr/oagoga/collaborative-transparency-IEEE-SP2023/.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. MODEL AND INFERENCE METHOD</head><p>We start by abstracting the complexity of targeted advertising through a simplified representation of the ad platform's population, and the ad targeting and ad delivery processes. Our representation models advertising on Facebook, but it generalizes to other ad platforms. We then describe our method to infer the targeting formula from data observed from a set of monitored users based on the maximum likelihood principle.</p><p>This section makes several assumptions and simplifications. We discuss throughout the paper their implications on results, and discuss how realistic they are and how to extend them in Sec. VIII. Table <ref type="table">I</ref> (appendix) summarizes our notation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Representation of Targeted Advertising</head><p>1) The platform's user population: Facebook collects data from its users while they are browsing the Internet (e.g., web pages visited) and when they use Facebook (e.g., user-filled data, likes, clicks, comments) and infers various attributes about them, which can be demographic (e.g., education, place of birth), behavioral (e.g., users of mobile devices), or interests (e.g., hobbies, food preferences). For simplicity in our investigation, we restrict to interest attributes, which are often deemed more sensitive <ref type="bibr" target="#b21">[22]</ref>. The framework, however, remains general. We denote by A the set of all attributes, of size A = |A|. We will denote by a j (j = 1, • • • , A) the attributes.</p><p>Let us denote by N the population of Facebook's users, and by N = |N | its size. For every user i ∈ N , the platform infers a binary variable for each attribute a j ∈ A, which we denote by u i j : u i j = 1 if the user satisfies the attribute (i.e., the user is inferred to have the corresponding interest) and u i j = 0 otherwise. Hence, for the purpose of our study, each user i ∈ N simply corresponds to a binary (row) vector u i = [u i j ] j∈{1,••• ,A} of size A that encodes which attributes the user satisfies; and the population N is described as an</p><formula xml:id="formula_0">N ×A binary matrix U = [u i j ] i∈{1,••• ,N },j∈{1,••• ,A}</formula><p>where rows represent users and columns represent attributes.</p><p>2) The ad targeting process: We focus on attribute-based targeting where an advertiser selects a targeted audience by selecting the attributes it should satisfy (Facebook allows advertisers to choose from a predefined list of curated attributes). We restrict our investigation to cases where the targeting formula is a combination of two attributes: a j ∧a l , a j , a l ∈ A. Note, however, that the inference process we propose extends to other formulas without fundamental difficulty. We denote by T the set of all possible targeting formulas of this form.</p><p>When launching an ad campaign, besides the targeting formula, the advertiser specifies several additional parameters, including the campaign budget, bid cap, and campaign duration. We abstract these away in the simplest possible way: we assume that the advertiser defines an expected number K of users who will be shown the ad. We will usually express K as a percentage of the targeted audience (i.e., of N θ below).</p><p>3) The ad delivery process: Let us denote by θ ∈ T the targeting formula selected by the advertiser for the ad campaign, and let us denote by N θ ⊂ N the set of users who satisfy the targeting formula θ. For each user i ∈ N , we define a binary variable y i ∈ {0, 1} indicating whether or not the user is shown the ad, i.e., y i = 1 if the user is shown the ad and y i = 0 otherwise. We assume that y i = 0 for all i ∈ N \ N θ , that is, a user that does not satisfy the targeting formula cannot be shown the ad. We denote by K the set of users that are shown the ad (i.e., for which y i = 1).</p><p>With this formalism, our problem formulation is: Let N m ⊂ N be the set of monitored users. We assume that we can observe the attributes u i of users i ∈ N m as well as whether or not they receive an ad (i.e., the value of y i ). Then the problem is: given an ad observed by a user in N m , infer the targeting formula θ that the advertiser used to target the ad.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. The Bernoulli Model and Estimator</head><p>To solve the above problem, we propose a maximum likelihood estimator. To that end, we need a model of ad delivery that specifies for a given formula θ the probability, for each user in N θ (i.e., satisfying the targeting formula), to receive the ad. We propose a simple Bernoulli model.</p><p>1) The Bernoulli assumption: The central assumption we make in this paper is that each user satisfying the targeting formula has an equal probability of being shown the ad independent of other users. Formally, we assume that y i for all i ∈ N θ are mutually independent Bernoulli random variables y i ∼ Ber(p θ ) of probability p θ = K/N θ , where N θ = |N θ |. Note that, then, |K| is K in expectation. It follows that, for every user in N m,θ = N m ∩ N θ (i.e., monitored user satisfying the formula θ), y i is also a Bernoulli random variable with parameter p θ , independent of other users. For all users i ∈ N m \ N m,θ , we have y i = 0 with probability one by our earlier assumption that y i = 0 for all i ∈ N \ N θ .</p><p>2) The Maximum Likelihood Estimator: Consider a given ad for which we would like to infer the targeting formula. We assume first that parameter K is known for the inference and that we can access the distribution of attributes in the whole population (i.e., compute N θ for any θ); then for any given θ, it is possible to compute p θ . We explain below how to adapt the inference process when K and/or the N θ 's are unknown.</p><p>Let ŷi for all i ∈ N m be the values of the labels y i observed. With the Bernoulli model detailed above, the likelihood of observing</p><formula xml:id="formula_1">(ŷ i ) i∈Nm if the targeting formula is θ ∈ T is L(θ)= i∈Nm P (y i = ŷi |θ) =   i∈Nm\N m,θ 1 ŷi =0   •   i∈N m,θ p ŷi θ (1-p θ ) 1-ŷ i   ,</formula><p>where 1 denotes the indicator function. Intuitively this formula computes, for a particular targeting formula, the likelihood that users receiving/not receiving the ad correspond to what is actually observed. The first part ensures that the likelihood is zero if a user not satisfying the formula receives the ad.</p><p>The likelihood above does not depend on which users receive the ad, but only on how many users in N m,θ are shown the ad. To simplify the writing, let N m,r be the set of monitored users who are shown the ad (i.e., such that ŷi = 1). Then the likelihood is</p><formula xml:id="formula_2">L(θ) = 1 Nm,r⊆N m,θ • p Nm,r θ (1 -p θ ) N m,θ -Nm,r ,<label>(1)</label></formula><p>where, as per our usual notation convention, N m,r = |N m,r |.</p><p>The maximum likelihood estimator of the targeting formula, which can be computed from the observation ŷi for all i ∈ N m (or from the observation of the subset N m,r ), is defined as</p><formula xml:id="formula_3">θ = arg max θ∈T L(θ).<label>(2)</label></formula><p>We will call it the B-ML estimator (B stands for Bernoulli).</p><p>In practice, one does not need to check all possible targeting formulas while computing the arg max; all formulas θ such that one does not have N m,r ⊆ N m,θ lead to a likelihood zero, which cannot be the max. The set of all formulas that lead to a non-zero likelihood can be easily computed: we first compute the intersection of attributes shared by all users in N m,r , denoted A r ⊂ A; and then we construct all combinations of two such attributes, denoted T r ⊂ T . We denote by A r = |A r | and T r = |T r | the size of these sets. In practice, we expect that T r will be significantly smaller than T as soon as a few monitored users received the ad, since A r will constrain the possible targeting formulas. As T r is a discrete set, computing the arg max is simply done by computing the likelihood for any θ ∈ T r and taking the largest. We break ties at random.</p><p>3) The Expectation-Maximization Estimator: In practice, the value of K may not be known at inference time. To handle this case, we apply Expectation-Maximization (EM) <ref type="bibr" target="#b22">[23]</ref>. EM is a general method for maximum-likelihood estimation when dealing with missing values. Here, the missing values are K and the N θ for the corresponding targeting formula, which would enable computing the parameter p θ = K/N θ .</p><p>The EM algorithm runs as follows: we start with some initial value of the parameter p θ . Then we alternate between two steps. In the E-step, we compute the conditional expectation of the likelihood given the current value of p θ , which is the expected number of users receiving an ad and the expected number of users satisfying the ad given the current p θ . It is obtained by taking the inner product of the observed data N m,r and N m,θ with the current p θ . In the M-step, we maximize this conditional likelihood; for p θ it is simply obtained by dividing the expected number of users receiving the ad by the expected number of satisfying users calculated in E-step. This M-step gives a new parameter estimate. The E-step and M-step of the algorithm are repeated iteratively until convergence occurs. The tolerance in our experiments is set to Tol=10 -3 and the maximum number of iterations is 100. We will refer to the estimator that uses EM as B-EM estimator.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. EVALUATION OVER REAL-WORLD EXPERIMENTS</head><p>This section proposes measurement methodologies, experimental designs, and software that enable us to evaluate the accuracy of our estimators in the wild on an actual ad platform. We first describe how we collected the necessary data and then how we instrumented the ad platform to perform controlled ad experiments. All our experiments are run on Facebook.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Data Collection</head><p>To test our inference, we need a set of monitored users N m , for which we need to collect (i) the ads they see (i.e., the value of y i ) and (ii) the attributes they have (i.e., the u i for users i ∈ N m ). The B-ML estimator also requires knowledge on the number of Facebook users satisfying a formula (N θ ) for all θ. Ads and attributes of monitored users: To collect this data, we use the AdAnalyst monitoring tool we developed for <ref type="bibr" target="#b23">[24]</ref>-a Chrome extension that users can install on their computers, which is publicly available <ref type="bibr" target="#b13">[14]</ref>. After installation, the tool collects all the ads that the user receives while browsing Facebook using the technique proposed by Andreou et al. <ref type="bibr" target="#b7">[8]</ref>.</p><p>The tool also silently collects the user's Ad Preferences page's content-a page where Facebook lists all attributes they inferred about the user-once every two days. Then, to construct the profiles u i of those users (i.e., the list of attributes that the user has), we aggregate the attributes collected in the Ad Preference page during the data collection period.</p><p>One of the critical difficulties of this data collection is to recruit users to install our monitoring tool-the volunteer monitored users. We recruited users in Brazil in late 2018 (around the Presidential election) and managed to have 420 active users (in total) during a period ranging from 09/11/2018 to 29/03/2019 (where active means we collected at least one ad from them during the period). This recruitment campaign is the same as the (Brazilian) campaign of <ref type="bibr" target="#b23">[24]</ref>. We discuss our recruiting strategy in more details in Appendix D-A. As mentioned in the previous section, we restrict our analysis to interest-based attributes; there are 322 curated interest attributes in this period (i.e., A = 322). The median number of attributes per user in our data is 125 (ST D : 46.71). We call the dataset containing the 420 user profiles D attributes .</p><p>Population statistics: We collect the number of Facebook users satisfying a particular formula (N θ ) from the Facebook Ads Manager. When placing an ad, the platform provides the advertiser with an estimate of the audience (i.e., number of users N θ ) satisfying a given targeting formula θ (possibly in combination with other criteria such as gender or location). Hence, we queried the system with every possible combination of one or two attributes on 09/06/2019 and gathered its worldwide monthly active users estimates. We collected this data for the 322 curated interest attributes, hence in total, we collected 51, 681 N θ values. We call this dataset D p .</p><p>Datasets for the simulation framework: We use D p to generate synthetic populations for the simulations. The N θ 's for formulas with a single attribute and the matrix of N θ 's for all formulas of two attributes define the second-order attribute distribution (denoted p). To validate our population generation (Section IV-3) we also use D attributes to validate the number of attributes per user and the third-order probabilities. Ethics: We describe these aspects in detail in Appendix D-B.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Controlled Ad Experiments</head><p>The goal of the real-world ad experiments is to see whether, at least in a few cases, our estimators can infer the targeting formula correctly (and not to do a systematic and comprehensive study). In fact, there are many reasons to expect that the B-ML estimator and the B-EM estimator will not provide correct inferences in the wild: we make several simplifying assumptions about how ads are delivered (see Sec. II-B), we do not know how Facebook optimizes the ad delivery, we do not have control over what advertisers are competing and what users are active, and our data collection method is imperfect and depends on the correctness of the information provided by Facebook in the Ad Preference and Ad Manager pages.</p><p>1) General principles: We performed real-world ad experiments on Facebook from 09/11/18 to 29/03/19, where we took the role of an advertiser and targeted Brazilian users with ads to have ground-truth data on the targeting formula. In each experiment, we launch ad campaigns targeting users with various combinations of two attributes, i.e., θ = a j ∧ a l . Then using data we collect from the 420 monitored users, we infer the targeting formula using the B-ML estimator and the B-EM estimator and compare it with the actual targeting formula we defined in our ad campaign (i.e., the ground truth).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2) Experimental design:</head><p>To have successful ad experiments, we need our ad campaigns to reach several of our monitored users since we cannot make inferences otherwise. The simplest way to increase the likelihood of reaching our monitored users is to have large ad budgets that can be used to target a large fraction of the Facebook Brazilian users that satisfy our targeting formula. However, such a budget can quickly get prohibitive in an academic setting, especially if we need to perform multiple ad campaigns. To address this challenge, we devise three strategies to increase the chances of reaching our monitored users on an acceptable ad budget.</p><p>1. We launched ad campaigns using attributes picked from the most active users in the previous week and shared by most monitored users. The goal of these experiments is to see if it is possible to have correct inferences, at least in a few cases. Hence, hand-picking targeting formulas is not problematic. 2. We restrict the considered population in two ways: (i) Location-based experiments: We target only users from Belo Horizonte (the place with most active monitored users). (ii) Custom-audiences experiments: We target our exact monitored users by providing Facebook with the list of their emails. Both strategies restrict the considered population to a subset of the whole Facebook population (which is much smaller for custom-audiences experiments). Then, the targeting formula is applied only to this subpopulation which artificially boosts our budget per monitored user. From an inference perspective, restricting the targeting to a subpopulation does not affect the accuracy of the inference since the estimators only look at the attributes of the monitored users, as long as the subpopulation has similar statistical properties (i.e., second-order attribute distribution) as the whole population (which is the case). 3. We performed ad campaigns that span multiple days (between 3 and 6 days) to increase the chances more monitored users are active during the ad campaign, and we set high bid caps ranging from 10 to 40C per 1000 impressions, that are higher than the average-7 C <ref type="bibr" target="#b24">[25]</ref>-to outperform competitors.</p><p>3) Results: In total, 79 ad experiments reached at least one monitored user. Table <ref type="table">II</ref> (appendix) provides detailed information about the 45 experiments (16 location-based and 29 custom audience-based) that reached three or more monitored users. We omit the rest because we do not expect accurate inferences when only one or two monitored users received an ad. Table <ref type="table">II</ref> provides information about the parameters used in our ad experiments (θ), the parameters observed (N m , N m,θ , N m,r , A r , T r ), and information on the accuracy of our estimators (whether the B-ML estimator and the B-EM estimator inferred correctly the targeting formula, the inferred targeting formula, the rank of the correct targeting formula). Overall, the number of active monitored users during the different ad campaigns ranged from 193 to 280 (not all the 420 monitored users were active during all campaigns).</p><p>We observed several cases where some monitored users received our ad even if their u i did not contain all the targeting attributes we specified. This happened for 86 cases (out of a total of 1021 cases of users receiving an ad across the 45 ad campaigns). We believe this is likely a data collection problem rather than an ad delivery bug from Facebook. First, we do not continuously monitor the Ad Preference page (we collect it once every two days); hence, we might miss the period when the attribute was present on the page. Second, the information provided by Facebook on the Ad Preference page might be incomplete <ref type="bibr" target="#b7">[8]</ref>. For these cases, we artificially input the missing targeting attributes in u i . We acknowledge that this may artificially ease the inference and provide an optimistic estimate. However, we will see that these results are consistent with simulations; hence we believe the effect is minimal. We discuss further the practical problems in implementing collaborative ad transparency in Sec. VI.</p><p>For the B-ML estimator, we use D p to fill N θ . Since in the wild we do not have knowledge of K, we test the estimator with various K (we use a different notation to distinguish from the real K), where K ∈ {0.01, 0.05, 0.1, 0.15, 0.2, 0.25, 0.5, 0.75, 1}. The B-ML estimator achieves the highest accuracy when using K = 25%.</p><p>In terms of accuracy, both the B-ML estimator and B-EM estimator inferred correctly 0 out of the 16 locationbased ad experiments and 17 out of the 29 custom audiences experiments. While the aggregated accuracy overall might not seem high, these results are rather remarkable because they bring concrete proof that it is possible to infer the targeting formula in the real world despite the assumptions we make, and the complexity and the lack of control we have over the ad delivery process. In addition, we can see the inference difficulty as the values of T r are large; that is, our estimator can pick the correct formula out of a large number of valid options in a non-negligible fraction of cases.</p><p>Furthermore, the B-EM estimator gives the same accuracy as the B-ML estimator (that has a hand-picked optimal parameter K)-although the experiments with correct inference are not necessarily the same. This is also remarkable as the B-EM estimator does not need K and N θ as a parameter and can infer the targeting formula only from the observed data.</p><p>Table <ref type="table">II</ref> suggest that one likely reason why we achieve higher accuracy in the custom audience experiments is differences in N m,r which is much higher for custom audience (M ED : 27) than location-based experiments (M ED : 4). In fact, if we only look at ad experiments that reached 10 or more users, we make correct inferences in 65% of cases.</p><p>While these results are encouraging, they are limited by the number of experiments that are feasible on the real platform. To understand precisely under which conditions our method can provide reasonable accuracy, we resort to simulations that allow us to vary parameters much more freely while ensuring that the results are consistent with our real-world experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. GENERATION OF A REPRESENTATIVE SYNTHETIC POPULATION</head><p>In order to have realistic simulations, we need to base them on a synthetic population whose statistical characteristics mimic those of the true platform's population. In this section, we present and validate our method to solve this problem.</p><p>1) Problem formulation and approach: Given that each user i is defined by its binary vector of attributes</p><formula xml:id="formula_4">u i = [u i j ] j∈{1,••• ,A}</formula><p>, the statistical properties of the population N are entirely defined by the probability of every combination of attributes. For any attribute a j ∈ A we define p j = P (u j = 1) as the probability that an arbitrary user satisfies attribute a j (as this is independent of the user, we omit the exponent i). We denote by q j = (1 -p j ) = P (u j = 0) the complementary probability that a user does not satisfy a j . Then, for any two attributes a j , a l ∈ A, we define p jl = P (u j = 1, u l = 1) as the probability that a user satisfies both attributes a j and a l . Together with (p j ) j∈{1,••• ,A} , the matrix (p jl ) j,l∈{1,••• ,A} completely defines the second-order distribution. By abuse of notation, we refer to the first two orders together as simply p.</p><p>We need to generate a population of users such that their attributes distribution follows the one of actual users. While specifying the marginal probability of each attribute is insufficient to describe the population, specifying the probability of any combination of arbitrarily many attributes is impossible due to the curse of dimensionality. Hence, we focus on the first two orders (we will still discuss higher orders below).</p><p>Problem formulation: Generate a sequence of binary vectors</p><formula xml:id="formula_5">u i = [u i j ] j∈{1,••• ,A}</formula><p>, for i up to an arbitrary population size, such that the joint attribute probability matches up to the second order the distribution p from the true population.</p><p>Naive (non satisfying) approaches: A naive solution would be to find an algorithm that deterministically fills in the attributes in a large N × A matrix such that for any pair of attributes a j , a l , the fraction having it is p jl . However, this approach would create undesirable artificial deterministic patterns. Instead, we are looking for a method to generate each vector u i = [u i j ] j∈{1,••• ,A} as an i.i.d. random variable such that the joint probability of attributes is p. A standard method for generating multivariate i.i.d. random variables is the rejection method <ref type="bibr" target="#b25">[26]</ref>. However, it is not suitable for high-dimensional data. It would require generating uniform random variables over 2 A combinations, as well as making assumptions to compute whether to reject or not a given combination based only on the second-order distribution p.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Correlated binary vector approaches:</head><p>We turn our focus on methods to generate sequences of correlated binary variables: <ref type="bibr" target="#b26">[27]</ref> proposed a method that is able to accommodate efficiently a binary sequence that follows an arbitrary correlation structure; <ref type="bibr" target="#b27">[28]</ref> proposed another efficient algorithm for generating binary data by dichotomizing a Poisson distribution. The algorithm of <ref type="bibr" target="#b26">[27]</ref> allows for more general correlations (e.g., negative correlations that may occur in practice) and is faster when the dimension (i.e., number of attributes) is high. Hence, we adapt the algorithm based on <ref type="bibr" target="#b26">[27]</ref> and the package released by <ref type="bibr" target="#b28">[29]</ref> to our population generation problem.</p><p>2) Algorithm: As the correlated binary vector methods are largely unknown in our community, we describe how the algorithm of <ref type="bibr" target="#b26">[27]</ref> works and how to adapt it to our population generation problem where the original method may not directly apply. We believe this approach is valuable to our community beyond this specific paper. Original method: The general idea of the algorithm of <ref type="bibr" target="#b26">[27]</ref> is to generate an A-dimensional random vector from a normal distribution with mean µ and covariance matrix Σ and to transform it to binary values by thresholding. Implementing such a method requires µ and Σ adapted to the binary data that we want to generate-i.e., essentially to p-we explain next how this is done.</p><p>Let us consider a random vector (X 1 , . . . , X A ), normally distributed with mean µ and covariance matrix Σ and let us fix the transformation to binary as u j = 1 if and only if X j &gt; 0, for any j ∈ {1, • • • , A}. Then P (u j = 1) = P (X j &gt; 0) = P ((X j -µ j ) &gt; -µ j ) = Φ(µ j ), where Φ(•) is the standard normal distribution. Hence, to ensure that P (u j = 1) = p j , we take µ j = Φ -1 (p j )-the pth quantile-for all j ∈ {1, • • • , A}. Similarly, we have P (u j = 1, u l = 1) = Φ(µ j , µ l ; ρ jl ), where Φ(•, •; ρ) is the CDF of a bivariate standard normal random variable with correlation coefficient ρ and ρ jl is the correlation coefficient between X j and X l . To ensure that P (u j = 1, u l = 1) = p jl , the equations p jl = Φ(µ j , µ l ; ρ jl ) are solved for ρ jl . In solving those equations, the values Φ(µ j , µ l ; ρ) are obtained through Monte Carlo simulations. Adjustments: A drawback of the algorithm by <ref type="bibr" target="#b26">[27]</ref> is that, for an arbitrary p, there is no guarantee that the covariance matrix Σ derived from the ρ jl that we get from solving these equations is positive semi-definite-which we need to generate the normal random variables. In fact, in our experiments, it is not. To solve this issue, we take as the covariance matrix Σ the closest positive semi-definite matrix to Σ, approximated by applying the optimization algorithm <ref type="bibr" target="#b29">[30]</ref>-this preserves the dependence structure of the distribution. Then, in summary, to generate a user, we sample a random variable (X 1 , • • • , X A ) normally distributed with mean µ and covariance matrix Σ as computed above; and we transform it to binary by applying u j = 1 if and only if X j &gt; 0. To generate a whole population, we generate each user independently with the same process. The generation process is summarized in Algorithm 1. Code: We implemented Algorithm 1 in R, using the packages "bindata" <ref type="bibr" target="#b30">[31]</ref> and "Matrix" <ref type="bibr" target="#b31">[32]</ref>. The code for the generation process is public (see link in the introduction) and allows anyone to generate a synthetic population based on an arbitrary input of first and second-order probabilities.</p><p>3) Validation: To validate our population generation method, we use the dataset D attributes of 420 users (with A = 322 attributes) described in Section III-A. From this dataset, we estimate p, then we generate a population of N = 10 6 users using this p as an input.</p><p>Validation of statistical characteristics: To check that our generated population matches the statistical characteristics of the true population, we first compare the second-order distribution of attributes to the one that was imposed, i.e., to p. Specifically, for any j, l ∈ {1, • • • , A}, let pjl be the fraction, in N , of users who satisfy both a j and a l , i.e., for which u j = 1 and u l = 1. The maximal absolute deviation |p jl -pjl | observed in input : First and Second-order</p><formula xml:id="formula_6">(p j ) j∈{1,••• ,A} , (p jl ) j,l∈{1,••• ,A} output: A matrix of users N of size N × A 1 Set µ j = Φ -1 (p j ) for all j ∈ {1, • • • , A};</formula><p>2 Compute all ρ jl by solving p jl = Φ(µ j , µ l ; ρ jl ) and fill covariance Σ; 3 if Σ is not positive semi-definite then our population was 0.003. Hence, as expected, the generated synthetic population matches the attribute distribution of the true population up to the second order. Next, we compare the third-order probabilities, that is, the probabilities of the form p jlm for combinations of three attributes a j , a l , a m . Figure <ref type="figure">1a</ref> shows the ECDFs of all combinations taken in the lexicographic order for the true and synthetic population (that is, the ECDF of a random variable corresponding to the index of a given combination of three attributes in the lexicographic order). It shows that the third-order distribution of the synthetic generated population matches that of the true one-even though it is not prescribed by the generation method, which is an interesting property.</p><p>Validation of the number of attributes per user: To further increase our confidence that the synthetic population resembles the true one, we compare the number of attributes per user in both. This is interesting because the equality of the distribution of number of attributes is not implied by the equality of the second-order distribution. Figure <ref type="figure">1b</ref> shows the ECDF of the number of attributes per user for both the true population (of 420 users) and the generated population N . We observe that they are very close to each other. We also performed a twosample Kolmogorov-Smirnov, a Wilcoxon non-parametric test, and a permutation test on the two distributions; all show that we cannot reject the null hypothesis that the populations have identical distributions of the number of attributes. Hence, the synthetically generated population resembles the true one even beyond what is imposed by the generation method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. SIMULATION FRAMEWORK</head><p>As experiments on Facebook are costly, we complement them with simulations to study the accuracy of collaborative transparency. In this section, we present the framework we use to perform our simulation study; and we show that it gives results largely consistent with our real-world experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Key Pillars of the Simulation Framework</head><p>The goal of the simulation framework is to allow us to investigate the accuracy of our inference method in ad campaigns with various parameters (e.g., targeting formulas θ, budgets K) and where the inference is performed under various conditions (e.g., numbers of monitored users N m ); with the aim of understanding under which conditions collaborative ad transparency can provide satisfying accuracy. The simulation framework should then allow us to fix parameters arbitrarily, and then to simulate the ad delivery process in sufficient detail to test our estimator as in the controlled experiments.</p><p>Our simulation framework relies on two key pillars:</p><p>(i) A synthetic population. We will generate it with the method of Section IV based on dataset D p so that its statistical characteristics resemble that of the real Facebook population. (ii) An ad delivery process that specifies, given all the ad campaign parameters, which (synthetic) users receive the ad.</p><p>For this, we will use the same Bernoulli model proposed in Sec. II-B1 for constructing the estimator. That is, we assume that each each user in N θ receives the ad with the same probability, independent of other users. Equivalently, if the number of users receiving the ad (|K|) is fixed (i.e., we condition on a particular value of |K|), then the |K| users receiving the ad are drawn randomly from N θ .</p><p>Size of the synthetic population: In our simulation study, we use a synthetic population of size N = 10 6 users. We argue, however, that this size is irrelevant and does not affect our results for a fixed N m so long as the budget is scaled with the population size. Indeed, our estimator only looks at the set N m to do the inference. Hence, the size of the rest of the population is irrelevant as long as the probability for a user in N m to receive the ad is constant. For this to happen, we just need that the budget K scales with N (if K was fixed in absolute value, the probability would decrease as N grows), or equivalently with N θ (since N θ is proportional to N ). Since we express K in percentage of N θ , we this is easily guaranteed as long as this percentage remains the same. From the above argument, one can observe that it is in fact not necessary to simulate the ad delivery for the whole population N ; it is enough to simulate it for the set of monitored users. We still need a larger simulated population to be able to randomly draw multiple realizations of the monitored set (potentially under some constraints of N m,θ in the consistency experiments, next subsection). However, there is no need to try and simulate a population of the size of the real Facebook population, a much smaller size is enough for that purpose (and N = 10 6 is more than enough), because our population generation method generates i.i.d. users.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Consistency Real-World vs. Simulated Experiments</head><p>Before running our simulation study, it is crucial to verify that our simulation framework (in particular the two key pillars above) leads to results consistent with the real-world observations. We do this by creating 45 simulated ad experiments (using our simulation framework) that attempt to reproduce the precise conditions of the 45 real-world ad experiments that reached at least 3 users (Sec. III-B). Recall that we use a synthetic population N based on the dataset D p , which contains the same attributes as in the real-world experiments.</p><p>1) Simulations: For each of the real-world experiment in Table <ref type="table">II</ref>, we create a simulation that preserves the same θ, N m , N m,θ and N m,r by doing the following: a. We set θ to the targeting formula of the real-world experiment and get the corresponding set of users N θ . b. We construct the set N m,θ by randomly picking N m,θ users from N θ . c. We construct the set N m,r by randomly picking N m,r users from the previously constructed N m,θ set. d. To complete N m , we randomly choose N m -N m,θ users out of the N \ N m,θ set. Note that step c. of this process is equivalent to the Bernoulli model described in the previous subsection (key pillar (ii)), when conditioning on the value of N m,r (which is crucial for a meaningful comparison to the real-world experiments).</p><p>We perform ten independent runs of the above process for each ad experiment. For each run, we compute the estimated θ using the B-ML estimator (with K=25% of N θ as for the real-world experiments). This setup allows us to have in each run different users in N m and N m,θ , which leads to potentially different θ. We compute the accuracy over the ten iterations.</p><p>2) Results: Table <ref type="table">II</ref> presents the accuracy of the B-ML estimator in the simulation framework corresponding to each real-world ad experiment (column Sim. Acc.). For each of the 45 ad experiments, we consider that our simulation result is consistent with the real-world result if the real-world inference is correct (resp., incorrect) and the simulation accuracy is over 50% (resp., under 50%). With this definition, 72.4% of the custom-audience ad experiments and 100% of the location-based ad experiments are consistent (82.2% over all experiments), which is remarkable. In particular, we observe a qualitative consistency in the results; for instance, real-world experiments where few users receive the ad give poor accuracy and the same happens with simulations. If we restrict to the 26 (custom-audience) experiments for which N m,r ≥ 10, however, the average accuracy of simulation is 86.1%, while the real-world accuracy is only 65%. In the next subsection, we discuss in details the reasons for this discrepancy.</p><p>3) Discrepancy between real-world experiments and simulations: Recall that we restrict for this discussion to the 26 (custom-audience) experiments for which N m,r ≥ 10. First, the observed discrepancy in accuracy may be due to randomness. To test that, we run a one-sided statistical test where the null hypothesis is that the 26 experiments results are independent Bernoulli success/failure variables with parameter 0.861 (the alternative hypothesis is that the parameter is less than 0.861). The p-value is 0.0064, hence we reject this null hypothesis with a standard threshold of 5% (even 1%). This means that not all the discrepancy can be attributed to randomness.</p><p>To understand why real-world experiments give lower accuracy, it is useful to look at the quantity A r (number of attributes common to all users who received the ad). Intuitively, the larger A r , the more difficult to disambiguate the targeting attributes for inference. Table III (in appendix) shows the values of A r for the real-world experiments and corresponding simulations (averaged over ten runs). We see that A r is much smaller in the simulations, which explains that the accuracy is higher. There are two main factors to explain this:</p><p>(i) The bias in the set of monitored users. The set of monitored users N m can be biased, that is that its distribution of attributes is not representative of the global population. There can be multiple reasons for that. The recruitment strategy may lead to recruiting biased users, e.g., more active users with more attributes. A bias can also originate from the measurement methodology (and potential measurement errors). For instance, as the measured attributes profiles change over time, we take the union of all snapshots; this could lead to users having more attributes. Table <ref type="table">III</ref> indicates that, indeed, our set of monitored users is biased towards having more attributes. This can be seen from the fact that the median number of attributes in N m is higher in the real-world experiments than in the simulations based on the synthetic population N generated from D p (obtained from the global Facebook population estimates).</p><p>To test (and quantify) the effect of the bias in the set of monitored users on accuracy, we proceed as follows: for each of the 26 experiments, we generate a new synthetic population, still using the method of Sec. IV, but using as an input the empirical estimate of the second-order attribute probabilities observed in the set of monitored users active for that particular experiment (instead of the global Facebook estimates as in the population N ). This process attempts to mimic in the simulation the bias in the set of monitored users as closely as possible for each experiment. Then, we redo the 10 runs exactly as before. We refer to these simulations as the biased simulations; the results are displayed in Table <ref type="table">III</ref> (right columns). We observe that, indeed, the median number of attributes per users in the monitored set (134.9 on average) is now close to that of the real-world simulations (136.7 on average), consistently with our results of Sec. IV. The values of A r also became closer. As a result the average accuracy over the 26 experiment is now 73.8%. If we make the same one-sided statistical test as above with parameter 0.738, the p-value is now 0.22, hence we cannot reject anymore the null hypothesis that the discrepancy is purely due to randomness. Nevertheless, the accuracy is still higher than 65% (and the values of A r still smaller than in the real-world experiments), which is possibly also explained by the second reason below. (ii) The ad delivery optimization mechanisms. Our simulations use a Bernoulli model of ad delivery: every user satisfying the targeting formula has an equal probability of receiving the ad. <ref type="foot" target="#foot_1">2</ref> In practice, the probability might vary due to ad delivery optimizations performed by platforms and might be affected by bidding strategies of other competing advertisers. For example, previous work showed that ad delivery was skewed towards men when the image of an ad was showing a gym <ref type="bibr" target="#b32">[33]</ref>. More simply, ad delivery may be skewed towards users that are more active and therefore have more attributes. To verify that, Table <ref type="table">III</ref> displays the median number of attributes per user in both N m and N m,r (columns Ām and Ām,r ). We observe that while this median is essentially the same between the real-world experiments and the biased simulations for N m , it is larger in the real-world experiments for N m,r . <ref type="foot" target="#foot_2">3</ref> This means that, in the real-world experiments, users receiving the ads tend to have more attributes than in our (biased) simulations. This effect typically makes inference harder because it may lead to the set of monitored receiving the ad sharing more common attributes. This can be seen from Table <ref type="table">III</ref>, by observing that the values of A r in the real-world experiments are higher than those for the biased simulations that account for the bias in the monitored set. This effect may explain the remaining 9% discrepancy in accuracy (from 73.8% to 65%). Recall from above, however, that it is no longer statistically significant after taking into account the bias in the set of monitored users. This indicates that skews coming from ad optimizations and auctions only have a limited impact on the inference (at least in the setting of our real-world experiments). Note that skews towards a given attribute has an effect on the inference only if the attribute is shared by all (and not just some) of the users receiving the ad-which is not likely as long as sufficiently many monitored users receive a given ad.</p><p>4) Take-aways on consistency between simulations and real-world experiments: Our results show that the accuracy we obtain in our simulation framework is globally consistent with the accuracy in the real-world experiments, despite our simplifying assumptions. This gives us confidence that the accuracy computed in the simulation framework is realistic and therefore that the key high-level take-aways of our simulation study are transferable to the real-world-although we do not claim that the numbers from our simulations are exact predictions. The discrepancy between simulations and realworld experiments is well explained: the primary factor is the bias of the monitored users. It is important to take it into account when evaluating whether collaborative transparency can work well since it may decrease the accuracy. It is, however, possible to observe it and to compute its effect as we did above for any given set of monitored users (e.g., for ours, it decreased the accuracy by around 12%). A secondary factor is ad delivery optimizations. This is not under our control and may decrease the accuracy. Our results above, however, suggest that the effect is limited, so these optimizations are not a fundamental limitation of collaborative ad transparency, even though they should be kept in mind.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Setup of Simulated Ad Experiments</head><p>In the rest of the paper, we perform our simulation study according to the two key pillars described in Section V-A and validated in Section V-B. We detail here the precise simulation protocol, summarized in Algorithm 2. We use a synthetic population of N = 10 6 users created from dataset D p (Sec. III-A) over A = 322 attributes. Recall that, as discussed above, the actual size of the synthetic population is irrelevant, only values of N m and K will matter. From this population, we precompute N θ for all θ ∈ T (i.e., all combination of two attributes); this will be used for inference.</p><p>In each ad experiment, we can set three main parameters: (1) the targeting formula θ (which determines the number N θ of users who satisfy it); (2) a number K linked to the ad campaign budget (expressed in percentage of N θ );</p><p>(3) the number of monitored users N m . Then we perform n runs = 10 runs as follows: First, we uniformly randomly sample a set of monitored users N m with predefined size N m . Second, we randomly draw, for users in N m,θ , i.i.d. Bernoulli random variables with probability K. That defines the labels ŷi corresponding to which users are shown the ad in N m (i.e., this defines N m,r )-recall that users in N m \ N m,θ have ŷi = 0. If no user has ŷi = 1, i.e., N m,r is empty, then we resample the experiment. This is consistent with the fact that we want in practice to infer parameters of the ad campaigns only for ads that at least one monitored user receives. Note that we draw labels only for users in N m . Whether or not non-monitored users are shown the ad is irrelevant for our inference as discussed earlier, and this approach is computationally faster. Note also that by drawing labels as Bernoulli random variables according to our second key pillar, we no longer fix the value of N m,r , which allows exploring its impact on accuracy.</p><p>Finally, we compute the estimate of the targeting formula θ using the B-ML estimator as defined in (2) (as well as the B-EM estimator) for each run. As each run has a different (randomly sampled) N m and N m,r , this gives ten different estimates for a given set of parameters (θ, K, N m ). Note that computing the B-ML estimator requires a value of K. As the true value is often unknown at inference time, we use a value K that is passed as an input of Algorithm 2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. SIMULATION STUDY: RESULTS</head><p>In the real-world ad experiments, we tried limited values of θ (chosen to increase the likelihood that our monitored users receive our ads), K (we were only able to use small ad budgets), and N m (we were constrained by the number of users who installed our monitoring tool). This left unanswered the question of how the accuracy would change for other θ's, other ad budgets, or other numbers of monitored users. In this section, we exploit the simulation framework to look at the variations of accuracy for a wide range of θ, K, and N m in order to answer this question and gain a broader view on the potential and limits of collaborative ad transparency. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Simulation Dataset</head><p>Each simulation with a fixed tuple of parameters (θ, K, N m , K) is done according to Algorithm 2, with 10 runs. We vary these parameters as follows: θ: In total, there are 51, 681 possible values of θ in T (i.e., combinations of two attributes from the 322 we consider). Figure <ref type="figure">2</ref> shows the histogram of N θ (the x-axis is in log-scale). We see a wide range of N θ going from 10 to 801, 438. In the analysis, we split T (the set of all θ) in three categories: low θ (with N θ in the bottom 33.3% percentile, N θ &lt; 1.7%N ); medium θ (with N θ between the 33.3% and 66.6% percentile, N θ ∈ [1.7%N, 6.2%N )), and high θ (with N θ in the highest 33% percentile, N θ ≥ 6.2%N ). To keep simulations computationally feasible, we pick 1, 000 random θ to produce simulations results in this section.</p><p>K: Recall that we express K as a fraction of N θ (instead of the absolute value of reach estimate). That is, we investigate the expected accuracy for ad campaigns where the advertiser sets a budget to reach a given fraction (say 0.2, or 20%) of the users that satisfy a particular targeting formula. This way, our results are easily transferable to real-world settings with various populations sizes N (e.g., different countries). We consider a wide range of ad campaign budgets by varying K in {0.01, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0}.</p><p>N m : Finally, we consider different numbers of monitored users N m : 150, 200, 250, 300, 700, 1000, 2000, 3000. K and estimates: As we perform 10 runs for each unique combination of (θ, K, N m ), we have a total of 1, 000 • 11 • 8 • 10 = 880, 000 runs. In each run, Algorithm 2 outputs the estimated targeting formula θ using the B-ML estimator and the B-EM estimator. As K is usually unknown in the wild (we do not know budget used by the advertiser in the ad campaign), the B-ML estimator uses a value K as an input. We compute four estimates per run with: K = K (we assume we know the real K), K = 0.1N θ (we assume K is small), K = 0.25N θ (the value we used for real-world experiments), K = 0.9N θ (we assume K is high). Note that the B-EM estimator does not need an input K (which is what makes it appealing). Accuracy: For a precise set of parameters (θ, K, N m , K), we compute accuracy over the 10 runs as the fraction of times where θ = θ. Wherever relevant, we also aggregate runs with multiple values of a parameter to compute the accuracy. Note on results reporting: Unless otherwise specified, we report the results for N m = 700 (Sec. VI-C2 discusses the impact of N m ) and for the B-ML estimator with K = K (Sec. VI-B1 presents the analysis for other K and the B-EM estimator). Note on results transferability to the real-world: We recall that we use a synthetic population of size N = 10 6 , but that as discussed earlier, this does not impact transferability of our results to the real-world for a fixed N m as long as K remains constant expressed as a fraction of N θ . We refer the reader to our more detailed discussion in Section V-A on that aspect.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Accuracy and Ad Targeting Parameters</head><p>1) Accuracy as a function of K and K: The ad budget K is an essential parameter in the targeting as it controls the probability that a user of N θ receives the ad and, hence, could impact in a major way the accuracy of the inference. Figure <ref type="figure" target="#fig_4">3a</ref> shows how the accuracy varies with K. The plot compares the accuracy for the B-ML estimator with K = K (the ideal case) with the accuracy for the B-ML estimator with other values of K and for the B-EM estimator. The accuracy is computed by aggregating over the 1, 000 random θ we picked.</p><p>The first and most important observation is that the B-EM estimator as well as the B-ML estimator with K = 0.1 or K = 0.25 have an accuracy close to the ideal case K = K (although slightly smaller for large K). This is very positive as it means that not knowing the budget used by the advertiser does not pose any major issue for our inference accuracy (as long as we do not consider large values such as K = 0.9).</p><p>Figure <ref type="figure" target="#fig_4">3a</ref> also shows that the accuracy increases with K. That is expected since when K is high, more of the monitored users will receive the ad, which gives more information to compute the inference. We also see that if an advertiser uses an ad budget that is high enough to target 50% of the users satisfying θ, we observe an inference accuracy of 75% on average across θ (since the results are aggregated over 1, 000 random θ they represent an average and not an idealized easy case). This is very encouraging as we only use N m = 700 (recall again that it holds irrespective of the population size).   2) Accuracy as a function of θ: The targeting formula θ is clearly an important parameter as it affects the number of users that can receive the ad N θ , which in turn impacts the number of monitored users receiving the ad. Figure <ref type="figure" target="#fig_4">3b</ref> shows how the accuracy of the inference varies with N θ . The accuracy is aggregated across the different values of K to provide a fairer and broader picture. As expected, the accuracy generally increases as N θ increases. More interestingly, the plot shows an accuracy of over 75% for θ with N θ as small as 1.7%N , on average over campaign budgets.</p><p>3) Accuracy as a function of both K and θ: To investigate the effect of both K and θ on the accuracy, Figure <ref type="figure" target="#fig_4">3c</ref> plots the accuracy as a function of the estimated reach, i.e., the total number K × N θ of users an ad campaign reaches. The plot shows an average accuracy of over 75%, as long as the estimated reach is over 0.005 (i.e., 0.5%) of N . To give an idea, let us assume that we use collaborative ad transparency in France, hence we have an entire Facebook population of 38 million users. Let us also consider that the average cost for 1000 impressions is 7C <ref type="bibr" target="#b24">[25]</ref>. An ad that reaches 0.005 of the population (i.e., 190, 000 users) will cost 0.005 • 38, 000.000 • 7/1, 000 = 1, 330C. Hence, we can see that collaborative ad transparency can achieve good accuracy for campaigns with relatively small budgets while only monitoring 700 users. If we consider countries with larger populations, collaborative ad transparency will also achieve a 75% accuracy if the ad reaches 0.005 of the population, but this will translate into more expensive ad campaigns. The next section discusses how the number of monitored users impacts the ad campaigns for which we can expect good accuracy.</p><p>To disentangle better the effect of θ and K on the inference accuracy, Figure <ref type="figure" target="#fig_4">3d</ref> presents a heatmap of the accuracy for all the combinations of (K, θ) we consider. On the x-axis, we ordered the 1000 θ according to their N θ , and on the yaxis, we present K. For each combination of θ and K, we represent the accuracy over the ten runs as colored rectangle (where darker shades represent higher accuracy). The heatmap provides a complete picture of the cases where we can achieve high accuracy (and those where we cannot). For example, we can achieve high accuracy for formulas with high N θ (≥ 6.2%N ) even when K is as small as 0.2, but we need a K of over 0.9 for formulas with small N θ (&lt; 1.7%N ). This constraint bodes well with what we expect to happen in real-life: advertisers either set a broad nest of users they want to reach (N θ high), but only target a fraction of them as their overall ad budget is limited, or focus their whole budget on a small set of users with precise characteristics they think will lead to high conversion rate (N θ low), and target most of them. The ad campaigns for which the inference does not work well are the ones that reach only a small fraction of a small set of users with precise characteristics. We expect such ad campaigns to be small test drives and not generally represent advertisers' behavior in real life. Finally, the heatmap of Figure <ref type="figure" target="#fig_4">3d</ref> does not appear as a smooth color gradient, that is, we observe large color variations for points next to each other. This means that, for a fixed K, ads with very similar N θ but with different θ may lead to different accuracies. This may be due to the fact that two formulas with the same N θ can have attributes with different marginal probabilities, although the precise relationship to accuracy is more intricate. We observe, however, that this second-order effect vanishes in regions of very high (or very low) accuracy-hence our results based only on N θ in these regions are robust.</p><p>4) Takeaways: There are two key results in this section. First, the B-ML estimator and B-EM estimator remain almost equally accurate even if we do not know the real K. Second, we observe an accuracy of over 75% on average over a wide range of targeting formulas θ and ad budgets K as long as the ad campaign reaches 0.005 of the entire population while only monitoring 700 users in the location we study.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Accuracy and Collaborative Ad transparency Parameters</head><p>The parameter directly controlled in collaborative ad transparency is the number of monitored users N m . Naturally we expect that a larger number of monitored users will lead to a higher accuracy on average as we can observe more information. However, we saw in the real-world experiments (Sec. III-B) that for a similar number of monitored users, the inference accuracy varies significantly for different ad campaigns. Beyond the variation in the ad parameters, a key parameter seemed to be the number of users who received the ad in the monitored set N m,r (recall that when less than ten monitored users received our ad, we never inferred the targeting formula correctly). Therefore, in this section, we investigate separately the effect of N m,r and then of N m .</p><p>1) Accuracy as a function of N m,r : N m,r intuitively captures the "amount of information" available to make an inference. Figure <ref type="figure">4</ref> shows the inference accuracy as a function of N m,r . In this plot, we aggregate all simulations for the 1, 000 random θ, K ∈ {0.01, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0}, but we fix N m = 700. To compute the accuracy for a particular N m,r , we take all the simulations that reached that N m,r , irrespective of θ or K, and compute the fraction for which inferred correctly θ = θ. For a more detailed view, we compute accuracy across all 1000 θ together, as well as for low, mid, and high N θ separately. Figure <ref type="figure">4</ref> shows that the accuracy is close to zero if only a few monitored users received the ad, but that it rapidly increases with N m,r until N m,r is around eight, after which the increase is much slower. More importantly, the plot shows that we get an accuracy of over 90% on average for ads that reach ten or more monitored users. This is one of the central results of this paper. It is a promising result not only because ten is a relatively small number, but also because it provides predictability and confidence in the inference: since we can directly measure N m,r , we know when we can have confidence in our inference and when we cannot.</p><p>Figure <ref type="figure">4</ref> also shows that there are minor differences in accuracy for different values of N θ : the higher N θ , the lower the average accuracy. This is normal since we condition on N m,r : for a fixed value of N m,r , if N θ gets larger it means that we are in a particularly skewed realization of the random process where particularly few monitored users received the ad compared to what was expected. Nevertheless, for N m,r ≥ 10, all values of N θ give high accuracy-in fact, out of all simulations such that N m,r ≥ 10, 97% have correct inference. Hence, N m,r ≥ 10 is a remarkably robust signal of high accuracy. At this point, it is useful to recall once again that our results are transferable to the real world irrespective of its population size-hence this cutoff number of N m,r ≥ 10 to obtain reliably good accuracy would remain the same.</p><p>A key reason why N m,r has such an important effect on accuracy is that it directly impacts the number of attributes that are common between the users that received the ad A r , Fig. <ref type="figure">4</ref>: Accuracy for different values of N m,r (for all 1, 000 θ as well as for θ with low, mid, and high N θ ). Statistics computed for N m = 700, and aggregated over K ∈ {0.01, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0}. which in turn has an impact on the size of the set of targeting formulas T r that the maximum likelihood estimator considers. We show this in more detail in App. C-A.</p><p>2) Accuracy as a function of N m : To explore the effect of N m on accuracy we use the simulations with various N m ∈ {150, 200, 250, 300, 700, 1000, 2000, 3000}, still with 1, 000 random θ, and K ∈ {0.01, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0}. Figure <ref type="figure" target="#fig_6">5</ref> displays the accuracy (computed by aggregating across all θ and K) as a function of N m . The plot shows that the accuracy rapidly increases with N m until N m is around 1000, then the growth is much slower. Note that the accuracy does not reach 100% because we aggregate it over multiple K, including K = 0.01, which always has bad accuracy. These results suggest that we can expect collaborative ad transparency to provide accurate inferences if we can monitor 1000 users or more. To get a deeper understanding, we compute accuracy separately for simulations for which less than ten users received the ad and simulations for which ten or more users received the ad. We see that if N m,r ≥ 10, the accuracy is over 90% for any number of monitored users (e.g., as low as 300), while if N m,r &lt; 10, the accuracy is poor even if N m as high as 3000. These results confirm our previous findings that the most important parameter to determine the expected accuracy for a particular ad is N m,r .</p><p>We also plot the accuracy as a function of N m conditioned on N θ and K (the figures, Figures <ref type="figure">8a</ref> and<ref type="figure">8b</ref>, can be found in App. C-B). The plots show that higher values of N m are beneficial in terms of accuracy for small N θ or K. The reason for this is that while N m,r determines whether we can make an accurate inference or not for a particular ad, N m plays an essential role in increasing the number of ads for which we can make an accurate inference because it increases the number of ads for which N m,r is ten or more. To visualize the impact of N m on N m,r , Figure <ref type="figure">6</ref> presents a contour plot that shows for which combinations of (K, N θ ) we can expect to have a certain value of N m,r (10, 20, • • • ), when N m = 300 and when N m = 3000. We observe that the benefit of large values of N m is that it gives a much bigger range of values of N θ and/or K (in particular small values) for which N m,r is ten or more, hence we can have an accurate inference. (Note that the contours in this plot have a shape similar to the heatmap of Figure <ref type="figure" target="#fig_4">3d</ref>, which is normal since there is almost an equivalence 3) Takeaways: The results show that when an ad is received by ten or more monitored users, we observe an inference accuracy of over 90% irrespective of the number of monitored users N m . N m plays an indirect role in the accuracy by increasing or decreasing the likelihood for a particular ad campaign that enough monitored users will receive the ad. Increasing N m plays an essential role in getting high accuracy for ad campaigns that have either a θ with a small N θ or a small budget. Choosing the right number of monitored users depends, of course, on whether we want to use collaborative ad transparency in a best-effort way or we want to be comprehensive. One thousand monitored users seems to be a good enough number to achieve good accuracy for most ad campaigns, but we need 1, 000 active monitored users-which probably requires recruiting about twice as many.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VII. RELATED WORK</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Limits of transparency mechanisms provided by platforms.</head><p>To address the demand for more transparency, advertising platforms have developed three main transparency mechanisms. First, platforms started to provide ad explanations to users about why they received a specific ad <ref type="bibr" target="#b33">[34]</ref>- <ref type="bibr" target="#b35">[36]</ref>. However, in Facebook's case, Andreou et al. <ref type="bibr" target="#b7">[8]</ref>, showed in 2018 that these explanations are incomplete and only show one (out of many) micro-targeting parameters used by the advertiser to target an ad. Secondly, ad platforms started to offer online Ad Libraries <ref type="bibr" target="#b36">[37]</ref>- <ref type="bibr" target="#b38">[39]</ref> that can be used by the public to investigate-mostly-political ads. Several reports pointed out limitations and vulnerabilities with such Ad Libraries <ref type="bibr" target="#b16">[17]</ref>, <ref type="bibr" target="#b17">[18]</ref>, and many criticized them for not showing information about the precise targeting parameters used by the advertiser.</p><p>Finally, ad platforms provide users with Ad Preference Managers <ref type="bibr" target="#b39">[40]</ref>- <ref type="bibr" target="#b41">[42]</ref> that show what attributes the platform has inferred about them. Several works showed they might not include all information that can be used to target users both in the case of Google <ref type="bibr" target="#b42">[43]</ref>, <ref type="bibr" target="#b43">[44]</ref> and Facebook <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b44">[45]</ref>. In addition, several studies have investigated the inferred attributes and found that they deal with sensitive topics <ref type="bibr" target="#b21">[22]</ref>, and their accuracy in reflecting user's interest is questionable <ref type="bibr" target="#b45">[46]</ref>- <ref type="bibr" target="#b47">[48]</ref>. Irrespective of the quality of the inference process <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b48">[49]</ref>, <ref type="bibr" target="#b49">[50]</ref>, these are the attributes used by the advertiser to reach users. While ad platforms have since revamped Ad Preference Managers and ad explanations and now provide more comprehensive information, the vulnerabilities mentioned above show the importance of external auditing systems and the need for third-party efforts to bring more transparency.</p><p>Third-party efforts to infer ad targeting. To address this need, several early studies developed methodologies to infer whether an ad is contextual, re-targeted, or behavioral <ref type="bibr" target="#b42">[43]</ref>, <ref type="bibr" target="#b50">[51]</ref>- <ref type="bibr" target="#b53">[54]</ref> and see how the activities of a user influence the ads s/he receives <ref type="bibr" target="#b54">[55]</ref>- <ref type="bibr" target="#b56">[57]</ref>. Our scope is complementary and proposes to infer the actual targeting parameters used by the advertiser. These works are based on creating fake personas (e.g., creating a browsing profile with a clean slate browser) and monitoring the ads that these personas receive. While these techniques can pinpoint problems with the ad ecosystem, they rely on methods that cannot be applied at scale to infer why users receive some particular ads because they require the creation of multiple fake accounts, which is very costly in time and resources. One method that does not use fake personas is by <ref type="bibr" target="#b56">[57]</ref>, who developed a model using hypothesis testing to check if an ad is interest-based by monitoring the user's browsing behavior. Closest to our work is the study by Iordanou et al. <ref type="bibr" target="#b57">[58]</ref> that used ads donated by users to detect targeted ads by counting how often an ad appears across different users while keeping the ads and browsing history of users private. This study focuses on designing a privacy-preserving protocol that only infers if an ad was targeted and not the specific targeting attributes used by the advertiser.</p><p>Measurements of ad targeting. Several studies have looked at how advertisers use the system to target users and to which extent they use micro-targeting <ref type="bibr" target="#b23">[24]</ref>, <ref type="bibr" target="#b58">[59]</ref>. Such studies shed light on users' targeting but rely on the platform's transparency mechanisms for the data they utilize. Finally, in a different direction, Ali et al. <ref type="bibr" target="#b32">[33]</ref> showed how Facebook's ad delivery process affects who receives an ad and observed that the delivery of ads can be skewed across gender or racial lines, even when the advertisers did not intend it. A follow-up work focused on political ads <ref type="bibr" target="#b9">[10]</ref> also observed that the price of reaching a user differs according to their political alliance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VIII. DISCUSSION AND LIMITATIONS</head><p>In this paper, we investigate the accuracy of collaborative ad transparency in inferring the targeting formula specified by an advertiser, using a combination of real-world experiments and simulations based on a simple abstraction of the ad delivery process. Our study aims at laying the foundations of collaborative ad transparency by understanding in which conditions it can or cannot work. The precise results of our real-world experiments are likely biased by the specific population from which our monitored users are drawn (which also explains the discrepancy with our simulation results). More generally though, a key insight of our study is that bias in the set of monitored users may negatively affect accuracythis should be kept in mind for potential deployment-but it is possible to quantify this effect with our simulation framework. Limitations related to the targeting formulas we considered: Our study focuses on targeting formulas that consists of a combination of two attributes. This was intended to be rich enough compared to a single attribute but to remain simple to set clear foundations. Our framework, however, is generic and can handle more complex formulas. As we have seen, a key parameter to ensure the inference quality is T r , the number of targeting formulas compatible with the set of monitored users who received the ad. As T r is constrained by the intersection of attributes in this set, we expect that it would not increase too much when considering combinations of more attributes, hence that the accuracy would not drop drastically.</p><p>We also only considered curated attributes, which are only around 300. In principle, considering free-text attributes (with thousands of them) would be possible. Even though simulations might be too costly (i.e., the generation of a synthetic population), performing the real-world inference would presumably be possible since we only consider the attributes shared by all users that received an ad. However, the real challenge for inferring targeting formulas with free-text attributes is to have enough monitored users that received the ad. As we discussed, inferring targeting formulas with a small reach requires more users to monitor. Our framework can be used to calculate the number of monitored users needed for a desired accuracy and for a particular targeting formula.</p><p>Finally, ad platforms optimize ad delivery based on (potentially thousands) of internal signals and advanced data mining algorithms. While auditing how ad platforms deliver ads is important, the focus of this study is to infer the targeting formula specified by the advertiser. Having this information is an essential step in detecting ill-intentioned advertisers. Assumptions on the ad delivery: Our main simplifying assumption resides in the Bernoulli model of ad delivery-we discussed it in Section V-B. Another key limitation of our model is that it assumes that users who do not satisfy the targeting formula cannot receive the ad. If this assumption is not satisfied, our inference will be wrong. Nevertheless, it is unlikely that ad platforms would deliberately deliver ads to users that do not satisfy the criteria asked by paying advertisers. In the real-world experiments, several of our ads were received by users that did not have all the targeted attributes in their user vectors. As discussed, we believe this is a data collection problem rather than an ad delivery problem. Hence, our approach requires frequent monitoring of users' attributes to limit such cases. Alternatively, it would be possible to extend our model to allow a small probability of receiving the ad when not satisfying the targeting formula. Feasibility and access to the necessary data: Collaborative ad transparency requires gathering, for a set of monitored users, the ads they see and their attributes. While Facebook has attempted on numerous occasions to disrupt the data collection of similar tools <ref type="bibr" target="#b59">[60]</ref>, <ref type="bibr" target="#b60">[61]</ref>, the platforms are bound by law to mark posts paid by advertisers <ref type="bibr" target="#b61">[62]</ref>. Hence, it will always be theoretically possible (even if technically challenging) to collect this information. Our approach requires frequent monitoring of users' attributes. This information can be collected from the Ad Preference pages of users (other platforms such as Google and Twitter have similar pages) but may vary over time (in our study the first snapshot had an average of 78 attributes per user and during the 20 weeks we observed an average of 61 new attributes per user added and 64 attributes deleted). Finally, the B-ML estimator requires knowledge on the number of users satisfying all the considered targeting formulas. Currently, this information is available in the Ads Manager. Nevertheless, even if Facebook stopped making such information available, we can use the B-EM estimator which has similar accuracy and does not require this information.</p><p>One limitation of collaborative ad transparency is that we rely on data provided by the ad platform on the user attributes and reach estimates. If this information is wrong, the inferences will also be wrong. If the Ad Preference page is wrong but the ad delivery process uses the same wrong information, then our method would correctly infer the targeting formula set by the advertiser. However, if the Ad Preference page shows purposely incorrect information different from that used to deliver the ads, then our method would make an incorrect inference. It may be possible to ask users to describe their interests (e.g., via a survey) to make an inference based on those-this would not recover the advertiser's formula but rather the main characteristics of users receiving an ad.</p><p>Finally, advertisers can use dynamic content in ads, that makes ads appear different to different recipients. Linking ads that are part of the same ad campaign but have different creatives is not trivial but could be doable depending on the information provided by ad platforms. For example, the ad explanation ("Why am I seeing this") provided by Facebook has an id. From a few anecdotal experiments that we did, we observed that if two ads are part of the same campaign, they lead to ad explanations with the same id, hence allowing the linkage. A more comprehensive study would, however, be required to confirm that and to assess the prevalence of dynamic contents. Nevertheless, even if this information is not available, we can still infer the targeting formulas by groups of identical ads. Of course, it reduces the available data, making it less likely that ten or more monitored users receive the ad. Fig. <ref type="figure">8</ref>: Accuracy for different values of N m . The accuracy is aggregated over 1, 000 random θ, and K ∈ {0.01, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0}. in Brazil. Participants were not paid for the study, and they were volunteers. Their main motivation was to help understand ad targeting during the election. Our tool provided users with a graphical interface showing them statistics about the ads they have received. We managed to attract 420 users that were active from 09/11/2018 to 29/03/2019 (where active means we collected at least one ad from them during the study period).</p><p>With this recruiting strategy, most of our participants are users from Brazil. Focusing on a single country reduces the size of the population while having a reasonable amount of monitored users. This is useful for our experiments because it reduces the budget needed to reach users with our ad campaigns (for a fixed N m , the budget needs to scale with the population size, see Section V-A). <ref type="foot" target="#foot_3">4</ref> In addition, recruiting users is a very country-specific effort, and this effort must be replicated for each country with local specifics (such as language), which would be arduous.</p><p>Our recruitment strategy leads to a biased set of monitored users. First, Brazilian users may differ from the worldwide population. Second, and more importantly, the set of users who installed our tool may not be representative of the Brazil population, for instance because they will likely be active and more educated users. The bias in the set of monitored users may have impact at two levels:</p><p>(i) On the inference. The bias in the set of monitored users makes inference harder. We discuss that in details in Section V-B3. In short, our set of monitored users is biased towards users having more attributes and, through simulations recreating the bias, we can quantify that (in our experiments) it decreases the accuracy by about 12% compared to a monitored TABLE I: Summary of the notation. As a general convention, we use calligraphic letters for sets (e.g., N ) and the corresponding regular letter to denote its size (e.g., N = |N |). The distribution on attributes up to second order By abuse, the notation p covers both the first order probabilities p j = P (u j = 1) and second-order probabilities p jl = P (u j = 1, u l = 1) T All targeting formulas of the form a j ∧ a l θ ∈ T the targeting formula selected by the advertiser N θ ⊂ N</p><p>The set of users who satisfy the targeting formula θ</p><formula xml:id="formula_7">N θ = |N θ | K ⊂ N θ</formula><p>The set of users that are shown the ad |K| is K in expectation where K encodes the ad budget; for each user i ∈ N , y i ∈ {0, 1} indicates whether or not the user is shown the ad (y i = 1 iif i ∈ K)</p><p>Collaborative ad transparency parameters (we can set)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Nm ⊂ N</head><p>The set of monitored users This is a key design parameter and depends on the available resources and reach of collaborative transparency method. N m,θ ⊆ Nm</p><p>The set of monitored users that satisfy θ</p><formula xml:id="formula_8">N m,θ = Nm ∩ N θ ; N m,θ = |N m,θ | p θ = K/N θ</formula><p>The probability for a user in N θ to be shown the ad, identical for every user in N θ</p><p>Whether or not a user is shown the ad is assumed independent of other users and/or of other ads Nm,r ⊆ N m,θ</p><p>The set of monitored users who are shown the ad Nm,r = N m,θ ∩ K; Nm,r = |Nm,r|</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Collaborative ad transparency inferred variables</head><p>Ar ⊂ A Attributes shared by all users in Nm,r Tr ⊂ T All the possible targeting formulas derived from the pairwise combinations of Ar</p><p>The inference is choosing a targeting formula from the formulas available in this set θ</p><p>The inferred targeting formula θ ∈ Tr set totally unbiased. Of course, this number would change with a different set of monitored users. (ii) On the generation. In Section IV-3, we validate that our population generation method produces a synthetic population that has the same statistical characteristics as the characteristics we input (i.e., p), for a p corresponding to our biased 420 users. We do not see any reason to believe, however, that the validation is specific to that p. In fact, we also did it with other populations (some of up to 700 users, coming from a different set of experiments campaigns with different users not in Brazil) and had very similar results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Ethics considerations</head><p>To perform the study, we sought an IRB/ERB approval in 2017. The participants were made aware of the data being collected and had to give their consent for the collection, storing, and processing of their ad preferences, the ads they see, and consent to being targeted by our ads. The consent was initially written in English and translated to Portuguese to facilitate understanding for Brazilian users. It was done using 2017 standards in terms of ethics and data collection, which is less strict than post-GDPR standards. The study was initiated (and the ERB and consent form were made) pre-GDPR but not all data collection was done pre-GDPR. In 2019, we applied for a new ERB for the same type of data collection (with the major difference that PIIs were pseudonymized), with an updated GDPR-compliant consent, which was also approved. This approval also went through the Data Protection Officer (a new role created by the GDPR). The version of the monitoring tool active in 2018 (that collected all the data used in this paper) no longer exists as it was shut down in 2019.</p><p>The privacy concerns were handled primarily by having the data stored on a secure server behind a firewall, using the highest university security standards, and having a restricted set of people who can see/access the data.</p><p>Finally, in our study, we target users with ads. To minimize the impact such ads could have on participants, our ads were generic with neutral content. They made use of landscape stock photos provided by Facebook, and the accompanying text suggested users spend their vacation in Saarbrücken. We did not include any links or track conversions for any ad.</p><p>The 2017 ERB did not provide any specific recommendation. The 2019 ERB recommended to instruct new students working on the project about the sensitivity of the data, and to remove access to members that no longer work on the project.</p><p>Next, we describe some key differences between the ERB form and the user consent from 2017 (pre-GDPR) and 2019 (post-GDPR) versions. Both are accessible on our public repository (see link in the introduction).</p><p>1. Sensitive nature of data: Some of the data we collect, particularly the Facebook ad preferences, are of a potentially sensitive nature <ref type="bibr" target="#b21">[22]</ref>. Our 2017 ERB form and consent did not discuss this (as we were not fully aware of it at the time). This was one of the main points discussed in the 2019 version. 2. PIIs: For this study, we collected users' PIIs (email addresses and Facebook IDs). This was used to authenticate users to show statistics about the ads they received but was mostly needed to use the custom audience feature to target the participants with our ads. This was made clear to our 2017 ERB and approved, although one would today need to be more explicit and exhaustive on which PIIs are exactly collected. We only collected hashed versions of emails and Facebook IDs in subsequent data collections (in accordance with our 2019 ERB/consent form). These are sufficient to show ads statistics to users (but not to target users via custom TABLE II: Parameters used and observed in our real-world ad experiments. N m -number of active monitored users during the ad campaign; N m,θ -number of monitored users that satisfy θ; N m,r -number of monitored users that received our ad; A r -number of common attributes between users in N m,r ; T r -number of θ considered by the estimators; B-ML estimator output-1 for correct inference and 0 for incorrect inference; Rank-rank of the real θ with the B-ML estimator; B-EM estimator output-1 for correct inference and 0 for incorrect inference; Sim. Acc.-the accuracy obtained in the simulation study (based on the population N generated from D p ) for inferring θ to check consistency (Sec. V-B). </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>4</head><label></label><figDesc>Fig. 1: Comparison of ECDFs for actual platform users in D attributes and for the synthetic population generated.</figDesc><graphic coords="8,70.30,205.82,110.87,81.69" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>input: 1 while 3 4 if N m,θ = Ø then 5 repeat 6 For 8 until 9 Calculate 2 :Fig. 2 :</head><label>134568922</label><figDesc>Fig. 2: Histogram of N θ in the population N .</figDesc><graphic coords="11,67.15,269.41,241.02,105.55" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>Accuracy for different values of K (aggregated across θ). Accuracy for different values of N θ (aggregated across K).Estimated reach (as a fraction of N ) (c) Accuracy vs. estimated reach (K × N θ ).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Kθ</head><label></label><figDesc>(ordered by N θ ) (d) Accuracy vs. K and θ.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 3 :</head><label>3</label><figDesc>Fig. 3: Accuracy vs. targeting parameters. Statistics computed for N m = 700, over all 1000 random θ and for K ∈ {0.01, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0}.</figDesc><graphic coords="12,67.16,402.46,246.75,108.06" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>NmFig. 5 :</head><label>5</label><figDesc>Fig. 5: Accuracy for different values of N m . The accuracy is aggregated over 1, 000 random θ, and K ∈ {0.01, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0}.</figDesc><graphic coords="14,81.71,195.58,200.85,82.19" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc>Nm (b) Conditioned on N θ .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>A</head><label></label><figDesc>The set of available targeting attributesA = |A|; a j (j = 1, • • • , A) denotes the attributes N The population of users N = |N |; U = [u i j ] i∈{1,••• ,N },j∈{1,••• ,A} where u i = [u i j ] j∈{1,••• ,A}; where u i j = 1 if the user satisfies the attribute a j and 0 otherwise p</figDesc></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>Ads that reach 0.005 of users in a country with 40 million Facebook users would cost about 1, 330C.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>We are only referring to the Bernoulli assumption used in the simulation here. We also use it in the inference, but that is equally done for simulations and real-world experiments so it cannot create a discrepancy between the two.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2"><p>The difference between the median number of attributes in Nm and Nm,r in the biased simulations is explained by the conditioning on the targeting formulas. We verify that by checking that the median number of attributes is the same in Nm,r and N m,θ (columns Ām,r and Ām,θ in TableIII).</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3"><p>Note that we employ other strategies to further increase the chances of success of our experiments with a limited budget as described in Section III-B2.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>ACKNOWLEDGMENT</head><p>Part of this work was done when the authors were with <rs type="institution">Univ. Grenoble Alpes</rs>, <rs type="funder">CNRS</rs>, <rs type="funder">Inria</rs>, <rs type="funder">Grenoble INP</rs>, LIG. It was supported by <rs type="funder">ANR</rs> (<rs type="grantNumber">ANR-17-CE23-0014</rs>, <rs type="grantNumber">ANR-21-CE23-0031-02</rs>, <rs type="grantNumber">ANR-20-CE23-0007</rs>); by <rs type="funder">MIAI@Grenoble Alpes</rs> (<rs type="grantNumber">ANR-19-P3IA-0003</rs>); and by the <rs type="funder">EU</rs> (<rs type="grantNumber">101021377</rs> and <rs type="grantNumber">952215</rs>).</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_9A2GTWh">
					<idno type="grant-number">ANR-17-CE23-0014</idno>
				</org>
				<org type="funding" xml:id="_eRrPZtf">
					<idno type="grant-number">ANR-21-CE23-0031-02</idno>
				</org>
				<org type="funding" xml:id="_rbqbPkn">
					<idno type="grant-number">ANR-20-CE23-0007</idno>
				</org>
				<org type="funding" xml:id="_MEM8pKj">
					<idno type="grant-number">ANR-19-P3IA-0003</idno>
				</org>
				<org type="funding" xml:id="_HU6RwA8">
					<idno type="grant-number">101021377</idno>
				</org>
				<org type="funding" xml:id="_Z2RpAJ6">
					<idno type="grant-number">952215</idno>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>APPENDIX A SUMMARY OF NOTATIONS</head><p>See Table <ref type="table">I</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>APPENDIX B REAL-WORLD EXPERIMENTS AND SIMULATIONS DETAILS</head><p>See Table <ref type="table">II</ref> and Table <ref type="table">III</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>APPENDIX C ADDITIONAL RESULTS FROM THE SIMULATION STUDY</head><p>A. Effect of N m,r on T r Figure <ref type="figure">7</ref> presents the effect of N m,r on T r . T r , the number of targeting formulas compatible with the set N m,r that the maximum likelihood needs to distinguish is another important quantity that affects the inference accuracy. Intuitively, the smaller T r , the easier the inference; in the extreme when T r = 1 then there is only one formula and the maximization is guaranteed to find the true formula. Of course, quantities T r and N m,r are highly correlated and a higher N m,r will naturally lead to a smaller T r . Figure <ref type="figure">7</ref> shows how the values of T r are distributed according to N m,r . The box plots are obtained as follows: for each possible value of N m,r , we take separately for each targeting formula all experiments that have this value of T r . From this plots we observe that as long as N m,r ≥ 10 then T r is smaller than 100. This gives an extra confidence signal: for T r ≤ 100, we are almost guaranteed to get high accuracy.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Additional plots of accuracy as a function of N m</head><p>See Figure <ref type="figure">8</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>APPENDIX D DETAILS ON THE RECRUITMENT STRATEGY AND ETHICS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Additional details on the recruitment strategy</head><p>Our main strategy to recruit participants was to publish articles in mainstream media, encouraging users to install the monitoring tool. This was done during the presidential election  3. Duration of the data storage: Initially, the participants were not made aware of how long their data will be stored. The consent only informed users that the data would be anonymized after the project was completed (but without a specific timeframe). We have now indeed deleted the PIIs from the data collection of this study. In the 2019 ERB, we explain that data will be kept for six years and then anonymized before archiving (but, again, it is only pseudonymized PIIs in that case). The duration of six years was chosen according to a justified long-term scientific goal and was updated after iterations with our ERB from our initial consent form mentioning ten years (the maximum allowed by the GDPR). 4. User's fundamental rights: The 2019 user consent clearly states the fundamental rights provided by GDPR, e.g., why the data is collected, that the data collection is voluntary, who has access to the data, how long the data will be stored, users' rights to remove or update their data, and the right to send a complaint to local authorities. This information is legally required to appear post-GDPR. 5. Age: Legislation and ethics requirements when performing data collections from children and teenagers are understandably stricter; it is preferable to exclude such population from studies. In the 2019 user consent, the DPO instructed us to ask users to confirm they are 18 or older to participate. 6. Strengthened security: In 2019, to evaluate the security and privacy of the data collection, we performed an in-depth security homologation with the university engineers to ensure we handle potential attacks at every level of the data flow (from the front-end to the security and access of the database backups). We found a few weak points, notably at the backup level, and reinforced the security for this data collection.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<ptr target="https://www.facebook.com/business/ads" />
		<title level="m">Facebook ads manager</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Lawmakers Hint at Regulating Social Media During Hearing With Facebook and Twitter Execs</title>
		<author>
			<persName><forename type="first">K</forename><surname>Steinmetz</surname></persName>
		</author>
		<ptr target="https://time.com/5387560/senate-intelligence-hearing-facebook-twitter/" />
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><surname>De La Baume</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Scott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Kayali</surname></persName>
		</author>
		<ptr target="https://www.politico.eu/article/facebook-european-elections-advertising-political-social-media-europe/" />
		<title level="m">Facebook to cave to EU pressure after row over political ad rules</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Facebook, Google and Twitter in data regulators&apos; sights</title>
		<author>
			<persName><forename type="first">M</forename><surname>Wall</surname></persName>
		</author>
		<ptr target="https://www.bbc.com/news/business-48357772" />
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<ptr target="https://www.bbc.com/news/technology-46385050" />
		<title level="m">Facebook&apos;s UK political ad rules kick in</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<author>
			<persName><forename type="first">K</forename><surname>Bell</surname></persName>
		</author>
		<ptr target="https://mashable.com/article/facebook-political-advertising-rules-worldwide/" />
		<title level="m">Facebook pushes new rules for political advertising worldwide</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Foreign governments are fed up with social media-and threatening prison for tech employees</title>
		<author>
			<persName><forename type="first">D</forename><surname>Ingram</surname></persName>
		</author>
		<ptr target="https://nbcnews.to/3seP8RL" />
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Investigating ad transparency mechanisms in social media: A case study of Facebook&apos;s explanations</title>
		<author>
			<persName><forename type="first">A</forename><surname>Andreou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Venkatadri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Goga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Gummadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Loiseau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mislove</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
			<publisher>NDSS</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<ptr target="https://blog.mozilla.org/blog/2019/03/27/facebook-and-google-this-is-what-an-effective-ad-archive-api-looks-like/" />
		<title level="m">Facebook and Google: This is What an Effective Ad Archive API Looks Like</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Ad delivery algorithms: The hidden arbiters of political messaging</title>
		<author>
			<persName><forename type="first">M</forename><surname>Ali</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Sapiezynski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Korolova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mislove</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rieke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WSDM</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<ptr target="https://www.teamupturn.org/reports/2018/facebook-ads/" />
		<title level="m">Leveling the platform: Real transparency for paid messages on facebook</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Enlisting the public to build a healthier web information commons</title>
		<author>
			<persName><forename type="first">C</forename><surname>Wardle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WWW</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Vestager moves closer to the data heart of digital giants</title>
		<ptr target="https://politi.co/3iKNhRg" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<ptr target="https://adanalyst.mpi-sws.org/" />
		<title level="m">AdAnalyst: A tool to help you make sense of the ads you receive on Facebook</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title/>
		<ptr target="https://adobserver.org/" />
	</analytic>
	<monogr>
		<title level="j">Ad Observer</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<ptr target="https://whotargets.me/" />
		<title level="m">Who Targets Me</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Facebook ads monitor: An independent auditing system for political ads on facebook</title>
		<author>
			<persName><forename type="first">M</forename><surname>Silva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Santos De Oliveira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Andreou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">O</forename><surname>Vaz De Melo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Goga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Benevenuto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">TheWebConf</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">A security analysis of the facebook ad library</title>
		<author>
			<persName><forename type="first">L</forename><surname>Edelson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Lauinger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Mccoy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">S&amp;P</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Does facebook still sell discriminatory ads?</title>
		<author>
			<persName><forename type="first">J</forename><surname>Merrill</surname></persName>
		</author>
		<ptr target="https://bit.ly/3CMVfBn" />
	</analytic>
	<monogr>
		<title level="m">The Markup</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Merrill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Kozlowska</surname></persName>
		</author>
		<ptr target="https://qz.com/1751030/facebook-ads-lured-seniors-into-giving-savings-to-metals-com/" />
		<title level="m">How facebook fueled a precious-metal scheme targeting older conservatives</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
		<respStmt>
			<orgName>QUARTZ</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">How facebook&apos;s ad system lets companies talk out of both sides of their mouths</title>
		<author>
			<persName><forename type="first">J</forename><surname>Merrill</surname></persName>
		</author>
		<ptr target="https://bit.ly/3AE4XnZ" />
	</analytic>
	<monogr>
		<title level="j">The Markup</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Unveiling and quantifying facebook exploitation of sensitive personal data for advertising purposes</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">G</forename><surname>Cabañas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Á</forename><surname>Cuevas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Cuevas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">USENIX Security</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Maximum likelihood from incomplete data via the EM algorithm</title>
		<author>
			<persName><forename type="first">A</forename><surname>Dempster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Laird</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Rubin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Royal Statistical Society: Series B (Methodological)</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="22" />
			<date type="published" when="1977">1977</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Measuring the Facebook advertising ecosystem</title>
		<author>
			<persName><forename type="first">A</forename><surname>Andreou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Silva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Benevenuto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Goga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Loiseau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mislove</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
			<publisher>NDSS</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<ptr target="https://www.webfx.com/social-media/how-much-does-facebook-advertising-cost.html" />
		<title level="m">How Much Does Facebook Advertising Cost in 2021?</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<author>
			<persName><forename type="first">C</forename><surname>Robert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Casella</surname></persName>
		</author>
		<title level="m">Monte Carlo Statistical Methods</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">A method for generating highdimensional multivariate binary variates</title>
		<author>
			<persName><forename type="first">L</forename><surname>Emrich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Piedmonte</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The American Statistician</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="302" to="304" />
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">A simple method for generating correlated binary variates</title>
		<author>
			<persName><forename type="first">C</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Shin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The American Statistician</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="306" to="310" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">On the generation of correlated artificial binary data</title>
		<author>
			<persName><forename type="first">F</forename><surname>Leisch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Weingessel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Hornik</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998">1998</date>
		</imprint>
		<respStmt>
			<orgName>WU Vienna University of Economics and Business, Working Paper</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Computing the nearest correlation matrix-a problem from finance</title>
		<author>
			<persName><forename type="first">N</forename><surname>Higham</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IMA journal of Numerical Analysis</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="329" to="343" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">The bindata package</title>
		<author>
			<persName><forename type="first">F</forename><surname>Leisch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Weingessel</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Matrix: Sparse and Dense Matrix Classes and Methods</title>
		<author>
			<persName><forename type="first">D</forename><surname>Bates</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Maechler</surname></persName>
		</author>
		<ptr target="https://cran.r-project.org/package=Matrix" />
	</analytic>
	<monogr>
		<title level="j">R package version</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="2" to="18" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Discrimination through optimization: How facebook&apos;s ad delivery can lead to biased outcomes</title>
		<author>
			<persName><forename type="first">M</forename><surname>Ali</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Sapiezynski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bogen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Korolova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mislove</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rieke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CSCW</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<ptr target="https://www.facebook.com/help/562973647153813" />
		<title level="m">How does facebook decide which ads to show me?</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<ptr target="https://support.google.com/accounts/answer/1634057?" />
		<title level="m">Why you&apos;re seeing an ad -google account help</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<ptr target="https://help.twitter.com/en/why-are-you-seeing-this-ad" />
		<title level="m">Why you&apos;re seeing an ad</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Ad library</title>
		<ptr target="https://www.facebook.com/ads/archive/" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<ptr target="https://transparencyreport.google.com/political-ads/library" />
		<title level="m">Political advertising on google -google transparency report</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<ptr target="https://ads.twitter.com/transparency" />
		<title level="m">Ad transparency center</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Ad personalization</title>
		<ptr target="https://adssettings.google.com/" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Ad preferences</title>
		<ptr target="https://www.facebook.com/adpreferences" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<ptr target="http://bluekai.com/registry" />
		<title level="m">Want to see your data?</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Understanding what they do with what they know</title>
		<author>
			<persName><forename type="first">C</forename><surname>Wills</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Tatar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WPES</title>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Automated experiments on ad privacy settings</title>
		<author>
			<persName><forename type="first">A</forename><surname>Datta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">C</forename><surname>Tschantz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Datta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PETS</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<author>
			<persName><forename type="first">G</forename><surname>Venkatadri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Lucherini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Sapiezyński</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mislove</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Investigating sources of PII used in Facebook&apos;s targeted advertising</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Largescale analysis of user exposure to online advertising on facebook</title>
		<author>
			<persName><forename type="first">A</forename><surname>Galán</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Cabañas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Á</forename><surname>Cuevas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Calderón</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Cuevas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="11" to="959" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">Facebook algorithms and personal data</title>
		<author>
			<persName><forename type="first">P</forename><surname>Hitlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Rainie</surname></persName>
		</author>
		<ptr target="https://www.pewinternet.org/2019/01/16/facebook-algorithms-and-personal-data/" />
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Auditing offline data brokers via Facebook&apos;s advertising platform</title>
		<author>
			<persName><forename type="first">G</forename><surname>Venkatadri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Sapiezynski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Redmiles</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mislove</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Goga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mazurek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Gummadi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">WWW</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Tracking and tricking a profiler: Automated measuring and influencing of bluekai&apos;s interest profiling</title>
		<author>
			<persName><forename type="first">M</forename><surname>Degeling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Nierhoff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WPES</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<title level="m" type="main">Quantity vs. quality: Evaluating user interest profiles using ad preference managers</title>
		<author>
			<persName><forename type="first">M</forename><surname>Bashir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Farooq</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Shahid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zaffar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wilson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
			<publisher>NDSS</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Adreveal: improving transparency into online targeted advertising</title>
		<author>
			<persName><forename type="first">B</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sheth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Weinsberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chandrashekar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Govindan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">HotNets</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">I always feel like somebody&apos;s watching me: measuring online behavioural advertising</title>
		<author>
			<persName><forename type="first">J</forename><surname>Carrascosa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Mikians</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Cuevas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Erramilli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Laoutaris</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CoNEXT</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Challenges in measuring online advertising systems</title>
		<author>
			<persName><forename type="first">S</forename><surname>Guha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Francis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IMC</title>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Adscape: Harvesting and analyzing online display ads</title>
		<author>
			<persName><forename type="first">P</forename><surname>Barford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Canadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Krushevskaja</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Muthukrishnan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">WWW</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Sunlight: Fine-grained targeting detection at scale with statistical confidence</title>
		<author>
			<persName><forename type="first">M</forename><surname>Lecuyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Spahn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Spiliopolous</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Chaintreau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Geambasu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Hsu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CCS</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Xray: Enhancing the web&apos;s transparency with differential correlation</title>
		<author>
			<persName><forename type="first">M</forename><surname>Lécuyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Ducoffe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Papancea</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Petsios</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Spahn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Chaintreau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Geambasu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">USENIX Security</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Myadchoices: Bringing transparency and control to online advertising</title>
		<author>
			<persName><forename type="first">J</forename><surname>Parra-Arnau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Achara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Castelluccia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Web</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Beyond content analysis: Detecting targeted ads via distributed counting</title>
		<author>
			<persName><forename type="first">C</forename><surname>Iordanou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Kourtellis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Carrascosa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Soriente</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Cuevas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Laoutaris</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CoNEXT</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<monogr>
		<title level="m" type="main">Analyzing Facebook Political Advertisers&apos; Targeting</title>
		<author>
			<persName><forename type="first">A</forename><surname>Ghosh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Venkatadri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mislove</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
			<publisher>ConPro</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<monogr>
		<ptr target="https://www.propublica.org/article/facebook-blocks-ad-transparency-tools" />
		<title level="m">Facebook Moves to Block Ad Transparency Tools -Including Ours</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<monogr>
		<ptr target="https://www.theverge.com/2021/8/4/22609020/facebook-bans-academic-researchers-ad-transparency-misinformation-nyu-ad-observatory-plug-in" />
		<title level="m">Facebook bans academics who researched ad transparency and misinformation on Facebook</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<monogr>
		<title level="m" type="main">com Disclosures: How to Make Effective Disclosures in Digital Advertising</title>
		<ptr target="https://www.ftc.gov/sites/default/files/attachments/press-releases/ftc-staff-revises-online-advertising-disclosure-guidelines/130312dotcomdisclosures.pdf" />
		<imprint/>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
