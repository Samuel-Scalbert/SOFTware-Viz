<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Statistically Significant Discriminative Patterns Searching</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Hoang</forename><forename type="middle">Son</forename><surname>Pham</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">ICTEAM</orgName>
								<orgName type="institution" key="instit2">UCLouvain</orgName>
								<address>
									<country key="BE">Belgium</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Gwendal</forename><surname>Virlet</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution" key="instit1">Univ Rennes</orgName>
								<orgName type="institution" key="instit2">Inria</orgName>
								<orgName type="institution" key="instit3">CNRS</orgName>
								<orgName type="institution" key="instit4">IRISA</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Dominique</forename><surname>Lavenier</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution" key="instit1">Univ Rennes</orgName>
								<orgName type="institution" key="instit2">Inria</orgName>
								<orgName type="institution" key="instit3">CNRS</orgName>
								<orgName type="institution" key="instit4">IRISA</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Alexandre</forename><surname>Termier</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution" key="instit1">Univ Rennes</orgName>
								<orgName type="institution" key="instit2">Inria</orgName>
								<orgName type="institution" key="instit3">CNRS</orgName>
								<orgName type="institution" key="instit4">IRISA</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Statistically Significant Discriminative Patterns Searching</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">61A7A1CCB72236EDECF8A30FDC8C128B</idno>
					<idno type="DOI">10.1007/978-3-030-27520-4_8</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-04-12T14:46+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Discriminative patterns</term>
					<term>Discriminative Measures</term>
					<term>Statistical Significance</term>
					<term>Anti-Monotonicity</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper, we propose a novel algorithm, named SSDPS, to discover patterns in two-class datasets. The SSDPS algorithm owes its efficiency to an original enumeration strategy of the patterns, which allows to exploit some degrees of anti-monotonicity on the measures of discriminance and statistical significance. Experimental results demonstrate that the performance of the SSDPS algorithm is better than others. In addition, the number of generated patterns is much less than the number of the other algorithms. Experiment on real data also shows that SSDPS efficiently detects multiple SNPs combinations in genetic data.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Recently, the use of discriminative pattern mining (also known under other terms such as emerging pattern mining <ref type="bibr" target="#b0">[1]</ref>, contrast set mining <ref type="bibr" target="#b1">[2]</ref>) has been investigated to tackle various applications such as bioinformatics <ref type="bibr" target="#b2">[3]</ref>, data classification <ref type="bibr" target="#b3">[4]</ref>. In this paper, we propose a novel algorithm, named SSDPS, that discovers discriminative patterns in two-class datasets. This algorithm aims at searching patterns satisfying both discriminative scores and confidence intervals thresholds. These patterns are defined as statistically significant discriminative patterns. The SSDPS algorithm is based on an enumeration strategy in which discriminative measures and confidence intervals can be used as antimonotonicity properties. These properties allow the search space to be pruned efficiently. All patterns are directly tested for discriminative scores and confidence intervals thresholds in the mining process. Only patterns satisfying both of thresholds are considered as the target output. According to our knowledge, there doesn't exist any algorithms that combine discriminative measures and statistical significance as anti-monotonicity to evaluate and prune the discriminative patterns.</p><p>The SSDPS algorithm has been used to conduct various experiments on both synthetic and real genomic data. As a result, the SSDPS algorithm effectively deploys the anti-monotonic properties to prune the search space. In comparison with other well-known algorithms such as SFP-GROWTH <ref type="bibr" target="#b4">[5]</ref> or CIMCP <ref type="bibr" target="#b5">[6]</ref>, the SSDPS obtains a better performance. In addition the proportion of generated patterns is much smaller than the amount of patterns output by these algorithms.</p><p>The rest of this paper is organized as follows: Section 2 precisely defines the concept of statistically significant discriminative pattern, and Section 3 presents the enumeration strategy used by the SSDPS algorithm. In Section 4, the design of the SSDPS algorithm is described. Section 5 is dedicated to experiments and results. Section 6 concludes the paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Problem Definition</head><p>The purpose of discriminative pattern mining algorithms is to find groups of items satisfying some thresholds. The formal presentation of this problem is given in the following:</p><p>Let I be a set of m items I = {i 1 , ..., i m } and S 1 , S 2 be two labels. A transaction over I is a pair t i = {(x i , y i )}, where x i ⊆ I, y i ∈ {S 1 , S 2 }. Each transaction t i is identified by an integer i, denoted tid (transaction identifier). A set of transactions T = {t 1 , ..., t n } over I can be termed as a transaction dataset D over I. T can be partitioned along labels S 1 and S 2 into</p><formula xml:id="formula_0">D 1 = {t i | t i = (x i , S 1 ) ∈ T } and D 2 = {t i | t i = (x i , S 2 ) ∈ T }.</formula><p>The associated tids are denoted D 1 .tids and D 2 .tids.</p><p>For example, Table <ref type="table" target="#tab_0">1</ref> presents a dataset including 9 transactions (identified by 1..9) which are described by 10 items (denoted by a..j). The dataset is partitioned into two classes (class label 1 or 0). A set p ⊆ I is called an itemset (or pattern) and a set q ⊆ {1..n} is called a tidset. For convenience we write a tidset {1, 2, 3} as 123, and an itemset {a, b, c} as abc. The number of transactions in D i containing p is denoted by |D i (p)|. The relational support of p in class D i (denoted sup(p, D i )), and negative support of p in D i (denoted sup(p, D i )), are defined as follows:</p><formula xml:id="formula_1">sup(p, D i ) = |D i (p)| |D i | ; sup(p, D i ) = 1 -sup(p, D i )</formula><p>To evaluate the discriminative score of pattern p in a two-class dataset D, different measures are defined over the relational supports of p. The most popular discriminative measures are support difference, grown rate support and odds ratio support which are calculated by formulas 1, 2, 3 respectively.</p><formula xml:id="formula_2">SD(p, D) = sup(p, D 1 ) -sup(p, D 2 )</formula><p>(1)</p><formula xml:id="formula_3">GR(p, D) = sup(p, D 1 ) sup(p, D 2 ) (2) ORS(p, D) = sup(p, D 1 )/sup(p, D 1 ) sup(p, D 2 )/sup(p, D 2 )<label>(3)</label></formula><p>A pattern p is discriminative if its score is not less than a given threshold α. For example, let α = 2 be the threshold of growth rate support. Pattern abc is discriminative since GR(abc, D) = 2.4. Definition 1. (Discriminative pattern). Let α be a discriminative threshold, scr(p, D) be the discriminative score of pattern p in D. The pattern p is discriminative if scr(p, D) ≥ α.</p><p>In addition to the discriminative score, to evaluate the statistical significance of a discriminative pattern we need to consider the confidence intervals (CI). Confidence intervals are the result of a statistical measure. They provide information about a range of values (lower confidence interval (LCI) to upper confidence interval (U CI)) in which the true value lies with a certain degree of probability. CI is able to assess the statistical significance of a result <ref type="bibr" target="#b6">[7]</ref>. A confidence level of 95% is usually selected. It means that the CI covers the true value in 95 out of 100 studies.</p><p>Let</p><formula xml:id="formula_4">a = |D 1 (p)|, b = |D 1 | -|D 1 (p)|, c = |D 2 (p)|, d = |D 2 | -|D 2 (p)</formula><p>|, the 95% LCI and U CI of GR are estimated as formulas 4 and 5 repectively.</p><formula xml:id="formula_5">LCI GR = e (ln(GR)-1.96 √ 1 a -1 a+b + 1 c -1 c+d )<label>(4)</label></formula><p>U CI GR = e (ln(GR)+1.96</p><formula xml:id="formula_6">√ 1 a -1 a+b + 1 c -1 c+d )<label>(5)</label></formula><p>Similarly, the 95% LCI and U CI of OR are estimated as formulas 6 and 7 repectively.</p><formula xml:id="formula_7">LCI ORS = e ln(ORS)-1.96 √ 1 a + 1 b + 1 c + 1 d<label>(6)</label></formula><p>U CI ORS = e ln(ORS)+1.96</p><formula xml:id="formula_8">√ 1 a + 1 b + 1 c + 1 d<label>(7)</label></formula><p>For example, consider the pattern abc in the previous example, the 95%CI of GR are LCI GR = 0.37, U CI GR = 16.60. Thus the GR score of abc is statistically significant because this score lies between LCI and U CI values. Problem statement: Given a two-class dataset D, a discriminance score scr and two thresholds α and β, the problem is to discover the complete set of patterns P that are statically significant discriminative for dataset D, discriminative measure scr, discriminative threshold α and lower confidence interval threshold β.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Enumeration Strategy</head><p>The main practical contribution of this paper is SSDPS, an efficient algorithm for mining statistically significant discriminative patterns. This algorithm will be presented in the next section (Section 4).</p><p>SSDPS owes its efficiency to an original enumeration strategy of the patterns, which allows to exploit some degree of anti-monotonicity on the measures of discriminance and statistical significance. In pattern mining enumeration strategies, anti-monotonicity properties is an important component. When enumerating frequent itemsets, one can notice that if an itemset p is unfrequent (sup(p, D) &lt; min sup), then no super-itemsets p ⊃ p can be frequent (necessarily sup(p , D) &lt; sup(p, D) &lt; min sup). This allows to stop any further enumeration when an unfrequent itemset p is found, allowing a massive reduction in the search space <ref type="bibr" target="#b7">[8]</ref>. As far as we know, no such anti-monotonicity could be defined on measures of discriminance or statistical significance.</p><p>The enumeration strategy proposed in SSDPS also builds an enumeration tree. However, it is based on the tidsets and not the itemsets. Each node of the enumeration tree is a tidset (with the empty tidset at the root). For example, consider the node represented by 12 : 8 in Figure <ref type="figure" target="#fig_1">1</ref>: this node corresponds to the tidset 128 in which 12 ⊂ D 1 .tids, and 8 ⊂ D 2 .tids.</p><p>Before presenting details of the enumeration strategy we first explain how to recover the itemsets from the tidsets. This is a well known problem: itemsets and tidsets are in facts dual notions, and they can be linked by two functions that form a Galois connection <ref type="bibr" target="#b8">[9]</ref>. The main difference in our definition is that the main dataset can be divided into two parts (D = D 1 ∪ D 2 ), and we want to be able to apply functions of the Galois connection either in the complete dataset D or in any of its parts D 1 or D 2 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Definition 3 (Galois connection). For a dataset</head><formula xml:id="formula_9">D = D 1 ∪ D 2 :</formula><p>-For any tidset q ⊆ {1..n} and any itemset p ⊆ I, we define:</p><formula xml:id="formula_10">f (q, D) = {i ∈ I | ∀k ∈ q i ∈ t k }; g(p, D) = {k ∈ {1..n} | p ⊆ t k }</formula><p>-For any tidset q 1 ⊆ D 1 .tids and any itemset p ⊆ I, we define:</p><formula xml:id="formula_11">f 1 (q 1 , D 1 ) = {i ∈ I | ∀k ∈ q 1 i ∈ t k }; g 1 (p, D 1 ) = {k ∈ D 1 | p ⊆ t k }</formula><p>-For any tidset q 2 ⊆ D 2 .tids and any itemset p ⊆ I, we define:</p><formula xml:id="formula_12">f 2 (q 2 , D 2 ) = {i ∈ I | ∀k ∈ q 2 i ∈ t k }; g 2 (p, D 2 ) = {k ∈ D 2 | p ⊆ t k }</formula><p>Note that this definition marginally differs from the standard definition presented in <ref type="bibr" target="#b8">[9]</ref>: here for convenience we operate on the set of tids {1..n}, whereas the standard definition operates on the set of transaction {t 1 , ..., t n }.</p><p>In Figure <ref type="figure" target="#fig_1">1</ref>, under each tidset q, its associated itemset f (q, D) is displayed. For example for node 12:8 , the itemset f (128, D) = bci is displayed. One can verify in Table <ref type="table" target="#tab_0">1</ref> that bci is the only itemset common to the transactions t 1 , t 2 and t 8 . A closure operator can be defined over the use of the Galois connection.</p><p>Definition 4 (Closure operator). For a dataset D and any tidset q ⊆ {1..n}, the closure operator is defined as: c(q, D) = g • f (q, D). The output of c(q, D) is the tidset the closed itemset having the smallest tidset containing q.</p><p>We can similarly define</p><formula xml:id="formula_13">c 1 (q 1 , D 1 ) = g 1 • f 1 (q 1 , D 1 ) for q 1 ⊆ D 1 .tids and c 2 (q 2 , D 2 ) = g 2 • f 2 (q 2 , D 2 ) for q 2 ⊆ D 2 .tids.</formula><p>The basics of the enumeration have been given: the enumeration proceeds by augmenting tidsets (starting from the empty tidset), and for each tidset function f of the Galois connection gives the associated itemset. The specificity of our enumeration strategy is to be designed around statistically significant discriminative patterns. This appears first in our computation of closure: we divide the computation of closure in the two sub-datasets D 1 and D 2 . This intermediary step allows some early pruning. Second, most measures of discriminance require the pattern to have a non-zero support in D 2 (GR and ORS). The same condition apply for measures of statistical significance: in both cases we need to defer measures of interest of patterns until it has some tids in D 2 . Our enumeration strategy thus operates in two steps:</p><p>1. From the empty set, it enumerates closed tidsets containing only elements of D 1 (case group). 2. For each of those tidset containing only tids of D 1 , augmentations using only tids of D 2 are generated and their closure is computed. Any subsequent augmentation of such nodes will only be allowed to be augmented by tids of D 2 .</p><p>More formally, let q ⊆ {1..n} be a tidset, with q = q + ∪ q -, where q + ⊆ D 1 .tids and q -⊆ D 2 .tids. Then the possible augmentations of q are: -(Rule 1) if q -= ∅: q can either:</p><p>• (Rule 1a) be augmented with k ∈ D 1 .tids such that k &lt; min(q + ) • (Rule 1b) be augmented with k ∈ D 2 .tids -(Rule 2) if q -= ∅: q can only be augmented with tid k ∈ D 2 .tids such that k &lt; min(q -) This enumeration strategy allows to benefit from an anti-monotonicity property on the measures of statistical significance and discriminance.</p><p>Theorem 1 (Anti-monotonicity). Let q 1 and q 2 be two tidsets such as: q + 1 = q + 2 and q - 1 ⊂ q - 2 (we have q + 1 = ∅ and q - 2 = ∅). Let p 1 = f (q 1 , D) and p 2 = f (q 2 , D). Then:</p><p>1. scr(p 1 , D) &gt; scr(p 2 , D) with scr a discriminance measure in {SD, GR, ORS}. 2. lci(p 1 , D) &gt; lci(p 2 , D) with lci a lower confidence interval in {LCI ORS , LCI GR }.</p><p>Please refer to the full paper at https://arxiv.org/abs/1906.01581 for the detailed demonstration of this part.</p><p>This theorem provides pruning by anti-monotonicity in our enumeration strategy: for a node having a tidset with tids both from D 1 .tids and D 2 .tids, if the discriminance or statistical significance measures are below a given threshold, then necessarily its augmentations will also be under the threshold. Hence this part of the enumeration tree can be pruned. For example, node 2:8 has associated itemset bcei, and ORS(bcei, D) = 3/4. Suppose the ORS threshold α = 2 this node can be pruned and its augmentations need not be computed. This allows to significantly reduce the search space. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">SSDPS: Algorithm Design</head><p>This section presents the SSDPS algorithm which exploits the enumeration strategy presented in the Section 3.</p><p>As mentioned in the previous section, our algorithm is based on an enumeration of the tidsets. It discovers statistically significant discriminative closed patterns. The main procedure for enumerating tidsets is given in Algorithm 1. This procedure calls the recursive procedure positiveExpand (Algorithm 2) to find closed frequent itemsets in the positive class. Computing discriminative patterns relies on the recursive procedure negativeExpand (Algorithm 3).</p><p>Delving more into details, positiveExpand (Algorithm 2) is based on the principles of the LCM algorithm <ref type="bibr" target="#b9">[10]</ref>, the state of the art for mining closed frequent itemsets. positiveExpand takes as input the tidset t of a pattern that is closed in D 1 and a tid e ∈ D 1 .tids that can be used to augment t. This augmentation is performed on line 1, and the pattern p associated to the augmented tidset t + = t ∪ {e} is computed in line 2. If p = ∅, there are no items common to all transactions of t + so the enumeration can stop (test of line 3). Else, we can continue the enumeration by applying Rule 1 of enumeration presented in Section 3. Lines 4 to 9 apply the LCM principles of enumerating closed itemsets without redundancies (the interested reader in referred to <ref type="bibr" target="#b10">[11]</ref> Section 3.2 for a recent description of these principles). At this step of the enumeration, the closure is computed in D 1 (line 4). The test of line 5 verifies if the closure actually extends the tidset, requiring a further verification in line 6, and the construction of the new extended tidset (line 7).</p><p>Lines 8 to 10 implement Rule 1a of enumeration, allowing to grow the positive part of the tidset. Lines 11 to 12 implement Rule 1b of enumeration, stopping the growth of the positive part and starting to grow the negative part of the tidset. The same logic is followed in lines 14 to 18, in the case where the tidset is not extended by the closure (test of line 5 is false).</p><p>Algorithm 2: positiveExpand Function</p><formula xml:id="formula_14">1 t + ← t ∪ {e} 2 p ← f (t + , D) 3 if p is not empty then 4 t ext + ← c1(t + , D1) 5 if t ext + = t + then 6 if max(t ext + ) &lt; e then 7 q ← t + ∪ t ext + 8</formula><p>for each e + in D1.tids \ q do 9 if e + &lt; e then 10 positiveExpand(q, e + , D, α, β)</p><formula xml:id="formula_15">11</formula><p>for each e -in D2.tids do The final expansion of the tidset is handled by negativeExpand (Algorithm 3), that can only perform augmentations with negative tidsets. It is very similar to positiveExpand, with several key differences. The first obvious one is that the closure is this time computed in D 2 (line 4). The second one is that only Rule 2 of enumeration can be applied (lines 13 and 20). The third and most important difference is that because we have tidsets with positive and negative tids, we can compute discriminance as well as statistical significance measures. Hence, Theorem 1 can be applied to benefit from pruning by anti-monotonicity. This is done in line 3.</p><p>Algorithm 3: negativeExpand Function</p><formula xml:id="formula_16">1 t -← t ∪ {e} ; p ← f (t -, D) 2 if p is not empty then 3 if check signif icance(p, D, α, β) is true then 4 t ext -← c2(t -, D2) 5 if t ext -= t -then 6</formula><p>if max(t ext -) &lt; e then 7 q ← t -∪ t ext -; q ext ← c(q, D); p ← f (q, D) </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experimental Results</head><p>This section presents various experiments to evaluate the performance of the SSDPS algorithm. In addition, we apply the SSDPS to discover multiple SNPs combinations in a real genomic dataset. The details of the result was presented in the full paper which was published at https://arxiv.org/abs/1906.01581. All experiments have been conducted on a laptop with Core i7-4600U CPU @ 2.10GHz, 16GB memory and Linux operating system. A synthetic two-class data was created to evaluate the pruning strategy as well as compare SSDPS with other algorithms. This dataset includes 100 transactions (50 transactions for each class). Each transaction contains 262 items which are randomly set by value 0 or 1. The density of data is set up to 33%.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Pruning Efficiency Evaluation</head><p>To evaluate the pruning efficiency of the SSDPS algorithm, we executed 2 setups on the synthetic dataset.</p><p>-Setup 1: use OR as discriminative measure; the discriminative threshold α = 2. -Setup 2: use OR as discriminative measure and LCI of OR as statistically significant testing; the discriminative threshold α = 2, and LCI threshold β = 2.</p><p>As the result, the running time and the number of output patterns significantly reduce when applying LCI ORS . In particular, with the setup 1, the SS-DPS algorithm generates 179,334 patterns in 38.69 seconds while the setup 2 returns 18,273 patterns in 9.10 seconds. This result shows that a large amount of patterns is removed by using statistically significant testing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Comparison with Existing Algorithms</head><p>We compare the performance of the SSDPS algorithm with two well-known algorithms: CIMCP <ref type="bibr" target="#b11">[12]</ref> and SFP-Growth <ref type="bibr" target="#b4">[5]</ref>. Note that these algorithms deploy discriminative measures which are different from the measures of SSDPS . In particular, CIMCP uses one of measures such as chi-square, information-gain and gini-index as a constraint to evaluate discriminative patterns while SFP-GROWTH applies -log(p value). For this reason, the number of output patterns and the running times of these algorithms should be different. It is hence not fair to directly compare the performance of SSDPS with these algorithms. However, to have an initial comparison of the performance as well as the quantity of discovered patterns, we select these algorithms.</p><p>We ran three algorithms on the same synthetic data. The used parameters and results are given in Table <ref type="table" target="#tab_2">2</ref>. As the result, the SSDPS algorithm finds 49,807 patterns in 73.69 seconds; CIMCP discovers 5,403,688 patterns in 143 seconds. The SFP-GROWTH runs out of storage memory after 172 seconds. Hence the number of patterns isn't reported in this case.</p><p>In comparison with these algorithms the SSDPS gives a comparable performance, while the number of output patterns is much smaller. The reason is that the output patterns of SSDPS are tested for statistical significance by CI while other algorithms use only the discriminative measure. However, this amount of patterns is also larger for real biological analysis. Thus, searching for a further reduced number of significant patterns should be taken into account.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion and Perspectives</head><p>In this paper we propose a novel algorithm, called SSDPS, that efficiently discover statistically significant discriminative patterns from a two-class dataset. The algorithm directly uses discriminative measures and confidence intervals as anti-monotonic properties to efficiently prune the search space. Experimental results show that the performance of the SSDPS algorithm is better than other discriminative pattern mining algorithms. However, the number of patterns generated by SSDPS is still large for manual analysis. To reduce the amount of patterns our first perspective is to investigate a heuristic approach. Another perspective is to apply statistical techniques such as minimum description length or multiple hypothesis testing in order to further remove uninteresting patterns.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Definition 2 .</head><label>2</label><figDesc>(Statistically significant discriminative pattern). Given a discriminance score scr ∈ {GR, ORS}, a discriminative threshold α and a lower confidence interval threshold β, the pattern p is statistically significant discriminative in D if scr(p, D) ≥ α and lci scr (p, D) &gt; β.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 1 :</head><label>1</label><figDesc>Fig. 1: Tidset-itemset search tree</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Algorithm 1 :</head><label>1</label><figDesc>SSDPS algorithm input : D, α, β output: a set of statistically significant discriminative patterns 1 t = ∅ 2 for each transaction id e in positive class do 3 positiveExpand(t, e, D, α, β)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>12 negativeExpand</head><label>12</label><figDesc>(q, e -, D, α, β) 13 else 14 for each e + in D1.tids do 15 if e + &lt; min(t + ) then 16 positiveExpand(t + , e + , D, α, β) 17 for each e -in D2.tids do 18 negativeExpand(t + , e -, D, α, β)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Two-class data example</figDesc><table><row><cell>Tids</cell><cell></cell><cell cols="2">Items</cell><cell></cell><cell></cell><cell>Class</cell></row><row><cell cols="2">1 a b c</cell><cell></cell><cell>f</cell><cell cols="2">i j</cell><cell>1</cell></row><row><cell cols="2">2 a b c</cell><cell>e</cell><cell>g</cell><cell>i</cell><cell></cell><cell>1</cell></row><row><cell cols="2">3 a b c</cell><cell></cell><cell>f</cell><cell>h</cell><cell>j</cell><cell>1</cell></row><row><cell>4</cell><cell>b</cell><cell>d e</cell><cell>g</cell><cell cols="2">i j</cell><cell>1</cell></row><row><cell>5</cell><cell></cell><cell>d</cell><cell cols="3">f g h i j</cell><cell>1</cell></row><row><cell>6</cell><cell>b c</cell><cell>e</cell><cell cols="2">g h</cell><cell>j</cell><cell>0</cell></row><row><cell cols="2">7 a b c</cell><cell></cell><cell cols="2">f g h</cell><cell></cell><cell>0</cell></row><row><cell>8</cell><cell cols="2">b c d e</cell><cell></cell><cell>h i</cell><cell></cell><cell>0</cell></row><row><cell>9 a</cell><cell></cell><cell>d e</cell><cell cols="2">g h</cell><cell>j</cell><cell>0</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>Used parameters and results of 3 algorithms</figDesc><table><row><cell>Algorithms</cell><cell>Measure</cell><cell cols="2">Threshold #Patterns</cell><cell>Time(seconds)</cell></row><row><cell>SSDPS</cell><cell cols="2">OR, LCI ORS α = 2, β = 2</cell><cell>49,807</cell><cell>73.69</cell></row><row><cell>CIMCP</cell><cell>Chi-square</cell><cell>2</cell><cell>5,403,688</cell><cell>143</cell></row><row><cell cols="2">SFP-GROWTH -log(p value)</cell><cell>3</cell><cell cols="2">* &gt; 172 (out of memory)</cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Efficient mining of emerging patterns: Discovering trends and differences</title>
		<author>
			<persName><forename type="first">G</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Fifth ACM SIGKDD, ser. KDD &apos;99</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="43" to="52" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Detecting group differences: Mining contrast sets</title>
		<author>
			<persName><forename type="first">S</forename><surname>Bay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Pazzani</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001">2001</date>
			<publisher>Kluwer Academic Publishers</publisher>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="213" to="246" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Direct discriminative pattern mining for effective classification</title>
		<author>
			<persName><forename type="first">H</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">S</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ser. ICDE &apos;08</title>
		<meeting><address><addrLine>Washington, DC, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="169" to="178" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">A survey of emerging patterns for supervised classification</title>
		<author>
			<persName><forename type="first">M</forename><surname>Garca-Borroto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Martnez-Trinidad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Carrasco-Ochoa</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014">2014</date>
			<publisher>Springer Netherlands</publisher>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="page" from="705" to="721" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">An almost exhaustive search-based sequential permutation method for detecting epistasis in disease association studies</title>
		<author>
			<persName><forename type="first">L</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">L</forename><surname>Assimes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">B</forename><surname>Asadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Iribarren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Quertermous</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">H</forename><surname>Wong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Genetic Epidemiology</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="434" to="443" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Itemset mining: A constraint programming perspective</title>
		<author>
			<persName><forename type="first">T</forename><surname>Guns</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Nijssen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">D</forename><surname>Raedt</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011">2011</date>
			<publisher>Elsevier</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Statistics in medicine: Calculating confidence intervals for relative risks (odds ratios) and standardised ratios and rates</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Morris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Gardner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">British Medical Journal</title>
		<imprint>
			<biblScope unit="volume">296</biblScope>
			<biblScope unit="issue">6632</biblScope>
			<biblScope unit="page" from="1313" to="1316" />
			<date type="published" when="1988-05">May 1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Mining association rules between sets of items in large databases</title>
		<author>
			<persName><forename type="first">R</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Imieliński</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Swami</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIGMOD Rec</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="207" to="216" />
			<date type="published" when="1993-06">Jun. 1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Discovering frequent closed itemsets for association rules</title>
		<author>
			<persName><forename type="first">N</forename><surname>Pasquier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bastide</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Taouil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Lakhal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ser. ICDT &apos;99</title>
		<meeting><address><addrLine>London, UK, UK</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="398" to="416" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Lcm ver. 2: Efficient mining algorithms for frequent/closed/maximal itemsets</title>
		<author>
			<persName><forename type="first">T</forename><surname>Uno</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kiyomi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Arimura</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Workshop Frequent Item Set Mining Implementations</title>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Toppi: An efficient algorithm for item-centric mining</title>
		<author>
			<persName><forename type="first">V</forename><surname>Leroy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kirchgessner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Termier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Amer-Yahia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Inf. Syst</title>
		<imprint>
			<biblScope unit="volume">64</biblScope>
			<biblScope unit="page" from="104" to="118" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Itemset mining: A constraint programming perspective</title>
		<author>
			<persName><forename type="first">T</forename><surname>Guns</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Nijssen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">De</forename><surname>Raedt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">175</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1951" to="1983" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
