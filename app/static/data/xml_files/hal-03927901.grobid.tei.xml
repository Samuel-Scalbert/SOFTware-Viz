<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="fr">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Evaluation d&apos;explications pour la prédiction de liens dans les graphes de connaissances par des réseaux convolutifs</title>
				<funder ref="#_4xpWUY3">
					<orgName type="full">unknown</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Fabien</forename><surname>Gandon</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Inria de l&apos;Université Côte d&apos;Azur</orgName>
								<address>
									<settlement>I3S</settlement>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">CNRS</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Nicholas</forename><surname>Halliwell</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Inria de l&apos;Université Côte d&apos;Azur</orgName>
								<address>
									<settlement>I3S</settlement>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">CNRS</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Freddy</forename><surname>Lecue</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Inria de l&apos;Université Côte d&apos;Azur</orgName>
								<address>
									<settlement>I3S</settlement>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">CNRS</orgName>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="laboratory">CortAIx</orgName>
								<orgName type="institution">Thales</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Evaluation d&apos;explications pour la prédiction de liens dans les graphes de connaissances par des réseaux convolutifs</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">506D459AAA6343FBB5F29EE46DE2D1D5</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-04-12T14:52+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>prédiction de liens</term>
					<term>IA explicable</term>
					<term>graphes de connaissances</term>
					<term>réseaux de neurones</term>
					<term>évaluation d&apos;explication link prediction</term>
					<term>explainable AI</term>
					<term>knowledge graphs</term>
					<term>graph neural networks</term>
					<term>explanation evaluation</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Nous résumons ici l'article [1] dont l'approche permet de générer un jeu de test comparatif et fournit des métriques pour évaluer les explications de prédictions de liens dans les graphes de connaissances par des réseaux convolutifs pour les graphes relationnels et ceci en présence de plusieurs explications possibles.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="fr">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Les réseaux convolutifs dédiés aux graphes relationnels (RGCN) <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b2">3]</ref> sont utilisés sur des graphes de connaissances <ref type="bibr" target="#b3">[4]</ref> notamment pour prédire des liens manquants mais malheureusement comme des boîtes noires. Plusieurs méthodes de génération d'explications ont été proposées pour expliquer leurs prédictions. Cependant la performance des méthodes d'explication est difficile à évaluer en absence d'une vérité terrain. De plus, il peut y avoir plusieurs explications pour une même prédiction dans un graphe de connaissances. Jusqu'à présent, il n'existait aucun jeu de données où les observations avaient de multiples explications avec lesquelles se comparer. De plus, il n'existait pas de métrique standard pour comparer les explications prédites par rapport à de multiples explications possible. Dans l'article <ref type="bibr" target="#b0">[1]</ref>, nous avons proposé une méthode et un jeu de données (FrenchRoyalty-200k), pour évaluer les performances de systèmes d'explication des RGCN sur la tâche de prédiction de liens dans un graphe de connaissances en présence de plusieurs explications possibles. De plus nous avons mené une expérience où des utilisateurs ont évalué chaque type d'explication possible de la vérité terrain en fonction de leur compréhension de l'explication et ceci afin d'affiner l'évaluation de la qualité des explications choisies par un système. A partir de cette vérité terrain, nous proposons l'utilisation de plusieurs métriques utilisant des poids agrégeant les scores des utilisateurs pour chaque explication prédite. Pour valider notre approche, nous nous avons évalué sur ce jeu de données des méthodes d'explication récentes pour la prédiction de liens en utilisant les mesures proposées.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">De la nécessité d'évaluer les explications des prédictions de liens</head><p>Peu d'algorithmes existent pour aider à comprendre les prédictions des RGCN sur un graphe de connaissances. Ex-plaiNE <ref type="bibr" target="#b1">[2]</ref> mesure le changement du score de sa méthode dû à une petite perturbation dans la matrice d'adjacence du graphe pour évaluer l'importance de la présence ou l'absence d'un lien dans la prédiction d'un autre lien. ExplaiNE repose sur l'hypothèse qu'une explication peut être fournie en sélectionnant l'un des voisins de la prédiction. GNNExplainer <ref type="bibr" target="#b2">[3]</ref> explique les prédictions en apprenant un masque sur la matrice d'adjacence d'entrée pour y identifier le sousgraphe le plus impactant pour la prédiction. Une faiblesse de ces méthodes est l'évaluation de la qualité de l'explication. Les auteurs d'ExplaiNE reconnaissent eux-mêmes qu'il est difficile de mesurer la qualité de l'explication en l'absence de vérité terrain <ref type="bibr" target="#b1">[2]</ref>. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>liens dans un graphe de connaissances à partir de données du Web sémantique et dans le cas d'explications uniques pour chaque prédiction. Dans l'article<ref type="bibr" target="#b0">[1]</ref> nous avons consolidé et étendu ces résultats en fournissant un autre jeu de données incluant de multiples explications possibles pour une même prédiction et en introduisant des métriques permettant l'évaluation et la comparaison des méthodes de prédiction. reçu un score élevé de la part les utilisateurs. Ces deux mesures empêchent une méthode d'explication de prédire uniquement des explications peu intuitives tout en recevant un score élevé. La mesure F 1 généralisée fournit une vue d'ensemble de la performance. A partir des traces de règles appliquées à un jeu de données issu de DBpedia nous avons construit un graphe de connaissances de plus de 200 000 triplets avec différentes explications possibles et leurs scores. En utilisant les mesures introduites, nous obtenons un jeu de test permettant d'évaluer et comparer quantitativement différentes méthodes d'explication. Nous montrons que les méthodes d'explication n'essaient pas toujours de prédire la meilleure explication possible (i.e. celle avec le meilleur score des utilisateurs) et qu'elles tentent parfois de prédire des explications avec un score inférieur et n'y réussissent que partiellement. Le graphe de connaissance et son schéma nous permettent aussi d'effectuer une analyse d'erreur sur les prédictions les plus fréquentes et une comparaison des comportements en fonction des caractéristiques des liens (ex. symétriques, inverses, etc.). Au final, la méthode introduite dans l'article, son jeu de données et ses métriques permettent aux chercheurs de développer de nouvelles méthodes d'explication et d'évaluer quantitativement et qualitativement leurs résultats d'une manière qui leur était auparavant impossible.</figDesc><table><row><cell>3 Des traces d'inférences notées par</cell><cell></cell></row><row><cell>les utilisateurs comme explications</cell><cell></cell></row><row><cell>Dans un graphe de connaissances, la sémantique formelle</cell><cell></cell></row><row><cell>disponible nous permet de proposer comme vérité terrain</cell><cell></cell></row><row><cell>pour des explications de prédiction de liens la justifica-</cell><cell></cell></row><row><cell>tion implication logique de ce lien. Grâce à un raisonneur</cell><cell></cell></row><row><cell>sémantique open-source avec des capacités de traçage de</cell><cell></cell></row><row><cell>règles [6] nous avons généré automatiquement des explica-</cell><cell></cell></row><row><cell>tions pour des règles dérivant de nouveaux liens. Ce tra-</cell><cell></cell></row><row><cell>çage identifie les liens qui ont causé la génération d'un</cell><cell></cell></row><row><cell>autre lien que nous pouvons soumettre à des méthodes qui</cell><cell></cell></row><row><cell>tenteront à leur tour de le prédire et de s'en expliquer.</cell><cell></cell></row><row><cell>Cela nous permet de distinguer les explications qui sont in-</cell><cell></cell></row><row><cell>tuitives de celles qui ne le sont pas, sans nous appuyer sur</cell><cell></cell></row><row><cell>des hypothèses préalables. Au total, 42 utilisateurs ont ré-</cell><cell></cell></row><row><cell>pondu, de 11 nationalités différentes, issus de milieux infor-</cell><cell></cell></row><row><cell>matiques et non informatiques. Nous avons normalisé les</cell><cell></cell></row><row><cell>scores moyens entre 0 et 1 pour chaque explication pos-</cell><cell></cell></row><row><cell>sible, et les avons arrondis au dixième le plus proche pour</cell><cell></cell></row><row><cell>en faire des poids utilisables dans l'évaluation des expli-</cell><cell></cell></row><row><cell>cations choisies par un système. Toutes les ressources uti-</cell><cell></cell></row><row><cell>lisées et produites sont disponibles en ligne, y compris le</cell><cell></cell></row><row><cell>lien de téléchargement du raisonneur, le code et les jeux de</cell><cell></cell></row><row><cell>données 1 .</cell><cell></cell></row><row><cell>4 Métriques, évaluation et résultats</cell><cell>ExplaiNE mesure la qua-</cell></row><row><cell>Nous avons proposé d'évaluer les méthodes d'explication en adaptant la précision et le rappel généralisés [6] propo-sés à l'origine pour la recherche de documents. Nous défi-nissons aussi la mesure F 1 généralisée, comme la moyenne harmonique entre précision et rappel généralisés et nous proposons la métrique max-Jaccard pour identifier quelle explication a le plus de points communs avec une explica-tion prédite. La métrique max-Jaccard mesure à quel point</cell><cell>lité de ses explications en utilisant la similarité de Jaccard moyenne entre les genres pour un film recommandé donné, et l'ensemble des genres des 5 premières explications sé-lectionnées. Il s'agit d'une évaluation très limitée qui ne se généralise pas à d'autres tâche ou graphes facilement. De même, GNNExplainer n'a pas été évalué sur la tâche de prédiction de liens explicables sur les graphes de connais-sances. Les évaluations sont donc limitées et, a fortiori, ne</cell></row><row><cell>une méthode d'explication est capable de prédire avec pré-</cell><cell></cell></row><row><cell>cision une des explications possibles. La précision et le rap-</cell><cell></cell></row><row><cell>pel généralisés intègrent à quel point l'explication prédite</cell><cell></cell></row><row><cell>1. https ://github.com/halliwelln/multiple-explanations/</cell><cell></cell></row></table><note><p><p><p>permettent pas non plus de comparer les méthodes d'explication entre elles. Dans l'article</p><ref type="bibr" target="#b4">[5]</ref> </p>nous avions commencé par proposer une méthode et des ressources pour évaluer quantitativement et qualitativement les méthodes d'explication sur la tâche de prédiction de Cette approche générique de génération d'explications de la vérité du terrain peut être appliquée à de nombreux graphes de connaissances et à de nombreux ensembles de règles. De plus en multipliant les règles nous pouvons générer plusieurs explications possibles pour un lien. Certaines explications peuvent être plus faciles à comprendre que d'autres et l'évaluation d'une méthode devrait prendre cela en compte. Nous avons mené une expérience auprès d'utilisateurs pour noter chaque type d'explication possible. a</p></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Remerciements</head><p>Ce travail est soutenu par le <rs type="projectName">3IA Côte</rs> d'<rs type="grantNumber">Azur -ANR-19-P3IA-0002</rs></p></div>
<div><head>Références</head></div>
			</div>
			<listOrg type="funding">
				<org type="funded-project" xml:id="_4xpWUY3">
					<idno type="grant-number">Azur -ANR-19-P3IA-0002</idno>
					<orgName type="project" subtype="full">3IA Côte</orgName>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">User Scored Evaluation of Non-Unique Explanations for Relational Graph Convolutional Network Link Prediction on Knowledge Graphs</title>
		<author>
			<persName><forename type="first">N</forename><surname>Halliwell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Gandon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Lecue</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">InProceedings of the 11th on Knowledge Capture Conference</title>
		<imprint>
			<date type="published" when="2021-12-02">2021 Dec 2</date>
			<biblScope unit="page" from="57" to="64" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">ExplaiNE : An Approach for Explaining Network Embedding-based Link Predictions</title>
		<author>
			<persName><forename type="first">B</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lijffijt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">De</forename><surname>Bie</surname></persName>
		</author>
		<idno>CoRR abs/1904.12694</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">GNNExplainer : Generating Explanations for Graph Neural Networks</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Bourgeois</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zitnik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Dessine-moi un graphe de connaissances !</title>
		<author>
			<persName><forename type="first">F</forename><surname>Gandon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Binaire</title>
		<imprint>
			<date type="published" when="2021-10-05">5 Oct. 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Linked Data Ground Truth for Quantitative and Qualitative Evaluation of Explanations for Relational Graph Convolutional Network Link Prediction on Knowledge Graphs</title>
		<author>
			<persName><forename type="first">N</forename><surname>Halliwell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Gandon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Lecue</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IAT 2021 -20th IEEE/WIC/ACM Int. Conference on Web Intelligence and Intelligent Agent Technology</title>
		<meeting><address><addrLine>WI-</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">KGRAM Versatile Inference and Query Engine for the Web of Linked Data</title>
		<author>
			<persName><surname>Corby</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Gaignard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Faron Zucker</surname></persName>
		</author>
		<author>
			<persName><surname>Montagnat</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE/WIC/ACM Int. Conference on Web Intelligence</title>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
