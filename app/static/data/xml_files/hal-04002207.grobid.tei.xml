<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="fr">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Natural Language Explanatory Arguments for Correct and Incorrect Diagnoses of Clinical Cases</title>
				<funder>
					<orgName type="full">3IA Côte d&apos;Azur Investments</orgName>
				</funder>
				<funder>
					<orgName type="full">French government</orgName>
				</funder>
				<funder ref="#_CFh27mx #_FsRWD96">
					<orgName type="full">Agence Nationale de la Recherche</orgName>
					<orgName type="abbreviated">ANR</orgName>
				</funder>
				<funder ref="#_Pa8AZS5">
					<orgName type="full">CHIST-ERA</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Santiago</forename><surname>Marro</surname></persName>
							<email>santiago.marro@univ-cotedazur.fr</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Université Côte d&apos;Azur</orgName>
								<orgName type="institution" key="instit2">Inria</orgName>
								<orgName type="institution" key="instit3">CNRS</orgName>
								<address>
									<region>I3S</region>
									<country key="FR">France</country>
								</address>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Université Côte d&apos;Azur</orgName>
								<orgName type="institution" key="instit2">Inria</orgName>
								<orgName type="institution" key="instit3">CNRS</orgName>
								<address>
									<region>I3S</region>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Benjamin</forename><surname>Molinet</surname></persName>
							<email>benjamin.molinet@univ-cotedazur.fr</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Université Côte d&apos;Azur</orgName>
								<orgName type="institution" key="instit2">Inria</orgName>
								<orgName type="institution" key="instit3">CNRS</orgName>
								<address>
									<region>I3S</region>
									<country key="FR">France</country>
								</address>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Université Côte d&apos;Azur</orgName>
								<orgName type="institution" key="instit2">Inria</orgName>
								<orgName type="institution" key="instit3">CNRS</orgName>
								<address>
									<region>I3S</region>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Elena</forename><surname>Cabrio</surname></persName>
							<email>elena.cabrio@univ-cotedazur.fr</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Université Côte d&apos;Azur</orgName>
								<orgName type="institution" key="instit2">Inria</orgName>
								<orgName type="institution" key="instit3">CNRS</orgName>
								<address>
									<region>I3S</region>
									<country key="FR">France</country>
								</address>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Université Côte d&apos;Azur</orgName>
								<orgName type="institution" key="instit2">Inria</orgName>
								<orgName type="institution" key="instit3">CNRS</orgName>
								<address>
									<region>I3S</region>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Serena</forename><surname>Villata</surname></persName>
							<email>serena.villata@univ-cotedazur.fr</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Université Côte d&apos;Azur</orgName>
								<orgName type="institution" key="instit2">Inria</orgName>
								<orgName type="institution" key="instit3">CNRS</orgName>
								<address>
									<region>I3S</region>
									<country key="FR">France</country>
								</address>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Université Côte d&apos;Azur</orgName>
								<orgName type="institution" key="instit2">Inria</orgName>
								<orgName type="institution" key="instit3">CNRS</orgName>
								<address>
									<region>I3S</region>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Natural Language Explanatory Arguments for Correct and Incorrect Diagnoses of Clinical Cases</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">5261259DBF8412CA7AA69138B8C27903</idno>
					<idno type="DOI">10.5220/0011927000003393</idno>
					<note type="submission">Submitted on 23 Feb 2023</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-04-12T14:51+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Natural Language Processing</term>
					<term>Information Extraction</term>
					<term>Argument-based Natural Language Explanations</term>
					<term>Healthcare</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>des établissements d'enseignement et de recherche français ou étrangers, des laboratoires publics ou privés.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="fr">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Explanatory Artificial Intelligence (XAI) is a main topic in AI research nowadays, given, on the one side, the predominance of black box methods, and on the other side, the application of these methods to sensitive scenarios like medicine. Among the huge set of contributions in this area <ref type="bibr" target="#b46">(Tjoa and Guan, 2019;</ref><ref type="bibr" target="#b43">Saeed and Omlin, 2021)</ref>, some approaches highlight the need to build explanations which are clearly interpretable and possibly convincing, leading to the investigation of the generation of argument-based explanations <ref type="bibr" target="#b9">(Cyras et al., 2021)</ref>. These explanations are intended to be not only rational, but "manifestly" rational <ref type="bibr" target="#b20">(Johnson, 2000)</ref>, such that arguers can see for themselves the rationale behind inferential steps taken. This task becomes even more challenging if we target the generation of natural language argumentbased explanations <ref type="bibr" target="#b9">(Cyras et al., 2021;</ref><ref type="bibr" target="#b47">Vassiliades et al., 2021)</ref>.</p><p>In this paper, we tackle this challenging task, focusing on a specific application scenario, i.e., the generation of explanatory natural language arguments in medicine. More precisely, our goal is to automatically generate natural language argument-based explanations to be used for educational purposes to train medical residents. These students are trained through tests where first there is the description of a clinical case (i.e., symptoms experienced by the patient, results of clinical exams and analysis, and some further information concerning the patient herself like age, gender, or population group), and they need to answer the following question: "Which of the following is the most likely diagnosis?". The test is composed of a number of possible answers to this question, i.e., potential diagnoses, among which, one of them is the correct diagnosis, and the others are incorrect. The solution consists in selecting the correct answer. In addition, medical residents are asked to justify their answer through an explanation. In order to automatize this training phase, we address the task of automatically generating explanations of the kind: "The patient is affected by [diagnosis x ] because the following relevant symptoms have been identified: [correct diagnosis symptoms]. The [diagnosis y ] is incorrect because the patient is not showing the symptoms [incorrect diagnosis symptoms]".</p><p>To address this task, a full pipeline needs to be designed in order to (i) detect the symptoms in the clinical case description, (ii) match them with the symptoms, in a medical knowledge base, to identify to which diseases they are associated with, and what is their frequency, and finally, (iii) generate pattern-based natural language explanations employing the elements identified in the two previous steps.</p><p>To do so, we first annotate a new resource of 314 unique clinical cases in English, with the symptoms which are relevant to derive the correct and incorrect diagnoses. These symptoms are extracted from the Human Phenotype Ontology (HPO) knowledge base <ref type="bibr" target="#b23">(Köhler et al., 2021)</ref>, where each disease is associated with the list of symptoms that can be manifested in this disease.</p><p>Relying on contextual embedding search, our contribution is threefold: (i) we detect in the clinical case description, the symptoms from a newly annotated resource; (ii) we automatically match the symptoms with those available on HPO, with the aim to associate them to the correct and incorrect diagnoses, and (iii) natural language explanatory arguments are automatically generated. We address an extensive evaluation of this new full pipeline to generate natural language explanations for clinical cases, obtaining very promising results. The work we present in this paper is motivated by the lack of existing medical textual resources annotated with symptoms associated with diagnoses and the need for effective methods to address natural language explanations in medicine. To the best of our knowledge, this is the first approach to generate such a kind of natural language explanations in the medical domain for educational purposes, i.e., to train medical residents to generate effective natural language explanations about the correct and incorrect diagnosis of a clinical case.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head><p>Since the introduction of BERT <ref type="bibr" target="#b11">(Devlin et al., 2019)</ref>, transformer-based models have recently had a major impact on most NLP tasks. Multiple models evolved from it with different design choices, like RoBERTa <ref type="bibr" target="#b29">(Liu et al., 2019)</ref>, ELECTRA <ref type="bibr" target="#b8">(Clark et al., 2020)</ref> and ALBERT <ref type="bibr" target="#b26">(Lan et al., 2019)</ref>. These models are trained on a large amount of data from multiple sources and domains, which means that they are not necessarily prepared for the biomedical domain.</p><p>In recent years, a great number of resources and NLP tools have been developed specifically for the biomedical domain. For entity extraction, the most popular datasets are BC4CHEMD <ref type="bibr" target="#b24">(Krallinger et al., 2015)</ref>, B5CDR-Chem <ref type="bibr" target="#b28">(Li et al., 2016)</ref>, NCBI-Disease <ref type="bibr" target="#b12">(Dogan et al., 2014)</ref>, BC2GM <ref type="bibr" target="#b44">(Smith et al., 2008)</ref>, JNLPBA <ref type="bibr" target="#b22">(Kim et al., 2004)</ref>, where the annotations range from drug-disease interactions to the identification of diseases, genes, and molecular entities such as protein, DNA, RNA. Symptom detection, i.e., the task we address in this paper, can be seen as a sub-task of the broader task of medical entity extraction.</p><p>Off-the-shelf NLP tool-kits such as Spacy (Honnibal and Montani, 2017), MedSpacy <ref type="bibr" target="#b14">(Eyre et al., 2021)</ref> and CLAMP <ref type="bibr" target="#b45">(Soysal et al., 2018)</ref> provide multiple modules for text processing. In particular, MedSpacy is built on top of Spacy specifically for clinical natural language processing, while CLAMP offers a method for named entity recognition (NER) as well as a visual interface for annotating and labeling clinical text.</p><p>Most of the recent approaches treat NER as a sequence labeling task where specialized transformerbased models hold the best results. For example, <ref type="bibr" target="#b35">(Naseem et al., 2021)</ref> showed that pre-training the ALBERT model on a huge biomedical corpus ensured that the model captured better biomedical contextdependent NER. Results outperform non-specialized models obtaining SOTA results in a lot of datasets. Similar results can be seen in <ref type="bibr" target="#b40">(raj Kanakarajan et al., 2021)</ref>, where the authors pre-train a biomedical language model using biomedical text and vocabulary with the technique proposed by ELECTRA. Other specialized models based on BERT have been proposed by <ref type="bibr" target="#b2">(Beltagy et al., 2019)</ref>, <ref type="bibr" target="#b27">(Lee et al., 2020)</ref> and <ref type="bibr" target="#b16">(Gu et al., 2020)</ref> and <ref type="bibr">BioMed-RoBERTa (Gururangan et al., 2020)</ref> based on RoBERTa. <ref type="bibr" target="#b31">(Michalopoulos et al., 2020)</ref> propose UmlsBERT, a contextual embedding model that integrates domain knowledge from the Unified Medical Language System (UMLS) <ref type="bibr" target="#b3">(Bodenreider, 2004)</ref>, taking into consideration structured expert domain knowledge. They show that UmlsBERT can associate different clinical terms with similar meanings in the UMLS knowledge base and create meaningful input embeddings by leveraging information from the semantic type of each word. In our work, we compare the representation of the symptoms found in the clinical case with different contextual embeddings with the goal to find a representation which matches the one provided in the Human Phenotype Ontology (HPO).</p><p>Ngai et al. <ref type="bibr" target="#b36">(Ngai and Rudzicz, 2022</ref>) also tackle the problem of finding relevant clinical information, where among the entities they also identify symptoms. In contrast to our work, they only focus on 6 specific diagnoses. Furthermore, their goal is to predict the correct diagnosis and explain these predictions using feature attribution methods, whilst ours is to generate high-quality explanations in natural language for educational purposes, i.e., to improve medical residents' skills in explaining their answer to the test.</p><p>Besides detecting symptoms from clinical cases, in our work, we also aim to accurately map them to medical ontologies, such as the Human Phenotype Ontology (HPO), to identify the relationship between the symptoms (originally described in layperson terms) and diseases. Recent work by <ref type="bibr" target="#b30">(Manzini et al., 2022)</ref> proposes a tool for automatically translating between layperson terminology and HPO, using a vector space and a neural network to create vector representations of medical terms and compare them to layperson versions. However, this approach has a limitation in that it translates layperson terms without considering their context, potentially missing relevant information that may change the semantics of the term. In our work, we propose a method that takes into account the context in which the layperson term is introduced, leading therefore to an accurate mapping to an HPO term.</p><p>Natural language explanation generation has received a lot of attention in recent years, grounding on the progress of generative models to train specific models for explanations. <ref type="bibr" target="#b5">(Camburu et al., 2018)</ref> generate explanations by justifying a relation (entailment, contradiction or neutral) for a premise-hypothesis pair by training a Bi-LSTM on their e-SNLI dataset, i.e., the Stanford Natural Language Inference <ref type="bibr" target="#b4">(Bowman et al., 2015)</ref> dataset augmented with an explanation layer which explains the SLNI relations. <ref type="bibr" target="#b25">(Kumar and Talukdar, 2020)</ref> propose to generate short explanations with GPT-2 <ref type="bibr" target="#b38">(Radford et al., 2019)</ref>, learned together with the input by a classifier to improve the final label prediction, using e-SNLI <ref type="bibr" target="#b5">(Camburu et al., 2018)</ref>. These solutions are not applicable to our use case given that explaining a medical diagnosis is a more challenging task than restraining the explanations to the three basic relations considered by <ref type="bibr" target="#b5">(Camburu et al., 2018)</ref> and <ref type="bibr" target="#b25">(Kumar and Talukdar, 2020)</ref>. <ref type="bibr" target="#b34">(Narang et al., 2020)</ref> propose an approach based on the T5 model <ref type="bibr" target="#b39">(Raffel et al., 2019)</ref> to generate an explanation after prediction. Again, this solution is not applicable to the specific medical scenario we target, where explanations require to be structured following precise argumentative structures <ref type="bibr" target="#b21">(Josephson and Josephson, 1994;</ref><ref type="bibr" target="#b7">Campos, 2011;</ref><ref type="bibr" target="#b13">Dragulinescu, 2016)</ref> and to ground on medical knowledge, like the one we inject through the HPO.</p><p>Other approaches use explanations via tem-plates <ref type="bibr" target="#b42">(Reiter and Dale, 1997)</ref>, e.g., <ref type="bibr" target="#b0">(Abujabal et al., 2017)</ref> uses templates and inject the reasoning steps and query of their Q&amp;A system. To the best of our knowledge, no related work generates natural language post-hoc explanations for the medical domain.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">DATASET</head><p>To train and evaluate the proposed approach to build natural language explanatory arguments, we rely on the MEDQA dataset <ref type="bibr" target="#b19">(Jin et al., 2021)</ref>, which contains a set of clinical case descriptions together with a set of possible questions and answers on the correct diagnosis. The questions and their associated answers were collected from the National Medical Board Examination in the USA (USMLE), Mainland China (MCMLE), and Taiwan (TWMLE). In this work, we only focus on the clinical cases and the questions in English (i.e., USMLE). In total, the MEDQA-USMLE dataset consists of 12,723 unique questions on different topics, ranging from questions like "Which of the following symptoms belongs to schizophrenia?" to questions about the most probable diagnosis, treatment or outcomes for a certain clinical case which is described <ref type="bibr" target="#b19">(Jin et al., 2021)</ref>. To reach our goal, we extract the clinical cases belonging to the latter group, which are intended to test medical residents to make the correct diagnosis. We end up with 314 unique clinical cases associated with the list of possible diagnoses.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Annotation of the MEDQA-USMLE Clinical</head><p>Cases. To annotate the clinical cases from the MEDQA-USMLE dataset, we rely on the labels from the Unified Medical Language System (UMLS) (Bodenreider, 2004) Semantic Types, making it consistent with standard textual annotations in the medical domain <ref type="bibr" target="#b6">(Campillos-Llanos et al., 2021;</ref><ref type="bibr" target="#b1">Albright et al., 2013;</ref><ref type="bibr" target="#b33">Mohan and Li, 2019)</ref>. In particular, we annotate the following elements in the clinical case descriptions: Sign or Symptom, Finding, No Symptom Occurrence, Population Group, Age Group, Location and Temporal Concept. In this paper, we use only the symptoms, but we addressed a complete annotation to employ these data for future work. Quantifiers defining a symptom have not been annotated (e.g., we can find "moderate pain", where we only annotate "pain"). The labels Sign or Symptom and No Symptom Occurrence are associated only to the text snippet defining the symptom in a sentence. Findings consist of such information discovered by direct observation or measurement of an organism's attribute or condition. For instance, components in "Her tem-perature is 39.3°C (102.8°F), pulse is 104/min, respirations are 24/min, and blood pressure is 135/88 mm Hg". Location refers to the location of a symptom in the human body, and Temporal Concept is used to tag time-related information, including duration and time intervals. Population Group and Age Group highlight information on the age and gender of the patient.</p><p>To address the annotation process of the MEDQA-USMLE dataset, we first carried out a semi-automatic annotation relying on the UMLS database. We processed each clinical case through the UMLS database and obtained all the entities detected along their Concept Unique Identifiers (CUI) and their semantic type. The semantic type is then used to disambiguate the entities and generate the pre-annotated files. After the definition of the detailed annotation guidelines (summarized above) in collaboration with clinical doctors, three annotators with a background in computational linguistics carried out the annotation of the 314 clinical cases. To ensure the reliability of the annotation task, the inter-annotator agreement (IAA) has been calculated on an unseen shared subset of 10 clinical cases annotated by four annotators, obtaining a Fleiss' kappa <ref type="bibr" target="#b15">(Fleiss, 1971</ref>) of 0.70 for all of the annotated labels, 0.61 for Sign or Symptom, 0.94 for Location, 0.71 for Population Group, 0.66 for Finding, 0.96 for Age Group and 0.96 for No Symptoms Occurrence. We can see a substantial agreement for Sign or Symptom, Finding and Population Group, and an almost perfect agreement for Location, Age Group and No Symptoms Occurrence.</p><p>Table <ref type="table" target="#tab_0">1</ref> reports on the statistics of the final dataset, named MEDQA-USMLE-Symp. <ref type="foot" target="#foot_0">1</ref> The accuracy of the annotations provided by the three annotators has been validated from a medical perspective with a clinical doctor. Of the seven entity labels, only three contain medical vocabulary (Sign or Symptom, Finding, and No Symptom Occurrence) and they have been evaluated by this expert. More specifically, we randomly sampled 10% of the data (i.e., 30 cases) and we asked the clinician to verify whether the entity was correctly labeled and whether there were any missing or extra words. The results of the validation showed that 98% of the data was labeled correctly. Less than 2% of the instances were evaluated as incorrectly labeled (e.g., a Finding that was labeled as a Sign or Symptom or vice versa).</p><p>Knowledge Base of Diseases and Relevant Symptoms. To collect the medical knowledge needed to define whether a detected symptom is relevant with </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">PROPOSED FRAMEWORK</head><p>An overview of the framework we propose to address automatic symptom relevancy assessment and matching to build our natural language explanations is visualized in Figure <ref type="figure" target="#fig_0">1</ref>. Starting from the clinical cases in which the correct and incorrect diagnosis are already identified, the goal is to assess the relevant symptoms present in the case such that these symptoms can be used to explain why a certain diagnosis is the correct one and why the incorrect ones have to be discarded. In order to accurately diagnose a patient's condition, it is important to identify the symptoms that are most relevant to the possible diagnoses. This means looking at all of the symptoms that have been detected and determining which ones are most likely to be related to the underlying cause of the patient's condition. This can be done by considering the individual symptoms and their potential connections to the possible diagnoses. It is also important to consider any additional information that may be available, such as the patient's medical history and other relevant factors, in order to be able to fully explain the diagnosis. Our work focuses on identifying relevant symptoms in order to accurately diagnose a patient's condition.</p><p>The relevancy assessment model associates, when possible, the pertinent symptoms mentioned in the clinical case description with a symptom of a diagnosis found in the HPO knowledge base. The proposed framework consists of two different steps, where: (i) we retrieve from HPO the required diagnosis information (i.e., the symptoms and how common they are), then the symptoms in the case are detected and extracted using an attention-based neural architecture which relies on the clinical case text only; (ii) the relevancy of each symptom is assessed by matching the detected symptoms with the ones retrieved from HPO. The matched symptoms are then used to generate natural language argument-based explanations for correct and incorrect diagnoses. In the following, we explain in detail each sub-task in the pipeline: Symptoms Detection, consisting in detecting the different symptoms described in the clinical case (medical terms or symptoms described by the patient's own words). In order to detect these entities, we propose a neural approach based on pre-trained Transformer Language Models. Symptoms Alignment, to align a symptom detected in the clinical case with an identical term in HPO. We first compute an embedding vector for each found symptom and then calculate the cosine distance with each term in HPO. We then assign the closest concept to that symptom. We evaluated both static and contextual embedding methods. Explanation Generation We propose templatebased explanations based solely on the symptoms that are relevant to explain the diagnosis. To do this we propose several templates that tackle different kinds of explanations, going from explaining why a patient was given a certain diagnosis to explaining why the alternatives cannot be considered viable options. We support our explanations with statistical information obtained from HPO such as the frequency of each symptom incidence, and we propose to look for possible symptoms that were not detected by the system but are frequent for a certain disease.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">EXPERIMENTS</head><p>In this section, we report on the experimental setup, the obtained results and the error analysis for the symptom detection and symptom alignment methods.</p><p>Setup. For the symptom detection task, we experimented with different transformer-based Language Models (LMs) such as BERT <ref type="bibr" target="#b11">(Devlin et al., 2019)</ref>, SciBERT <ref type="bibr" target="#b2">(Beltagy et al., 2019)</ref>, BioBERT <ref type="bibr" target="#b27">(Lee et al., 2020)</ref>, PubMedBERT <ref type="bibr" target="#b16">(Gu et al., 2020)</ref> and Umls-BERT <ref type="bibr" target="#b31">(Michalopoulos et al., 2020)</ref> initialized with their respective pre-trained weights. All the models we employ are specialized in the biomedical domain, with the exception of BERT which will serve us as a baseline. We cast the symptom detection problem as a sequence tagging task. Following the BIOtagging scheme, each token is labeled as either being at the Beginning, Inside or Outside of a component. This translates into a sequence tagging problem with three labels, i.e., B-Sign-or-Symptom, I-Sign-or-Symptom and Outside. To fine-tune the LMs, we use the PyTorch implementation of huggingface <ref type="bibr">(Wolf et al., 2020) (v4.18)</ref>. For BERT, we use the uncased base model with 12 transformer blocks, a hidden size of 768, 12 attention heads, and a learning rate of 2.5e-5 with Adam optimizer for 3 epochs. The same configuration was used to fine-tune SciBERT BioBERT, PubMedBERT and UmlsBERT. For SciB-ERT, we use both the cased and uncased versions, and for BioBERT we use version 1.2. Batch size was 8 with a maximum sequence length of 128 subword tokens per input example.</p><p>Regarding the matching module, we experimented with two different methods to align our detected symptoms with terms in HPO by (i) directly comparing the computed embeddings of the detected symptoms with the embeddings of the terms in HPO, and (ii) by taking into account the context in which the symptoms are detected and applying the same context to every term in HPO.</p><p>To align our detected symptoms (in the clinical case) with the equivalent HPO terms, we calculate the cosine distance of each embedding of the HPO terms with respect to the embedding of the detected symptom. In the experimental setting of (i) and (ii), we use the static pre-trained embeddings GloVe 6B as well as BERT, SciBERT, BioBERT and UmlsBERT in the same configurations as in the symptom detection task. For (ii), it is necessary to calculate the context embeddings "on the fly" because each context is unique and depends on the clinical case where it was detected. It is not reasonable to recalculate all HPO term embeddings on the fly for each new context since the ontology contains 10,319 unique terms, so we propose to generate all the HPO terms embedding at once and save them. Therefore, this module takes as input the symptoms detected by the previous module and finds the context<ref type="foot" target="#foot_4">5</ref> of these symptoms in the clinical case. The context C is embedded using sentence embedding methods and saved separately from the symptom S, and the two embeddings are added together (C + S) to form the reference R. This same context embedding C is added in the same way to each HPO term embedding T 1 , T 2 , . . . , T i to form the candidates C 1 ,C 2 , . . . ,C i .</p><p>We compute and retrieve the five best cosine distances between C and R to address a fair comparison with other systems.</p><p>We defined a test set of 23 cases where (i) we retrieved from HPO the symptoms related to the diseases for each case, and (ii) we manually aligned the annotated symptoms in the case to the concepts from HPO. This resulted in 162 symptoms aligned to a specific term in HPO that serve us as a testing set for our matching module.</p><p>As mentioned in Section 2, the system proposed by <ref type="bibr" target="#b30">(Manzini et al., 2022)</ref> offers a similar approach to translating layperson terms to medical terms in HPO. However, their work does not take into account the context in which a symptom is found. To the best of our knowledge, this system constitutes the stateof-the-art when translating layperson terms to HPO terms so we decided to compare our proposal with theirs. However, due to the unavailability of their model, we rely on their online demo, which outputs only the top 5 ranking of the HPO terms that are closest to the input symptom. To perform a comparison with our pipeline, we first compute the accuracy of the aligned symptoms using our symptoms alignment module and then replaced it with <ref type="bibr" target="#b30">(Manzini et al., 2022)</ref> proposed system (DASH). Results are shown in Table <ref type="table" target="#tab_3">4</ref>.</p><p>Since a symptom can be composed of several words (e.g., "shortness of breath"), we split the symptom and the entire clinical case.</p><p>symptom into words that we encode by either using each word as an input on Glove <ref type="bibr" target="#b37">(Pennington et al., 2014)</ref>, or extracting directly from the contextualized models the representation of the symptom by summarizing the hidden states of the last four layers in the model. We then sum the vectors of each word to get an n-gram representation of the symptom. We also explore sentence embeddings, by making use of Sentence-BERT <ref type="bibr" target="#b41">(Reimers and Gurevych, 2019)</ref>, a new model that derives semantically meaningful sentence embeddings (i.e., semantically similar sentences are close in vector space) that can be compared using cosine similarity. Sentence-BERT can be used with different pretrained models, in this work we focus on the models BERT <ref type="bibr" target="#b11">(Devlin et al., 2019)</ref> , SciBERT <ref type="bibr" target="#b2">(Beltagy et al., 2019)</ref>, UMLSBERT <ref type="bibr" target="#b31">(Michalopoulos et al., 2020)</ref> and S-PubMedBert by <ref type="bibr" target="#b10">(Deka et al., 2022)</ref>. The first represents a competitive baseline in our experiments since it is the SOTA model for comparing sentences crossdomain, while the three latter models are pre-trained on scientific or medical data or both.</p><p>To tackle both tasks we make use of our annotated dataset (Section 3). The annotations are converted into two datasets, one for each part of the pipeline. The first dataset is used for the symptom detection task, and it is in the CoNLL format for token-wise labels. The second dataset, for the symptom alignment task, is converted into a csv format, where each symptom in the clinical case description and available related knowledge (i.e., the list of symptoms and their frequencies for each possible diagnosis associated with the case) extracted from HPO are paired.</p><p>Results. Results for the symptom detection task are shown in Table <ref type="table" target="#tab_1">2</ref> in macro multi-class precision, recall, and F1 score. We can observe that all models Overall, SciBERT uncased is the best-performing model (in bold) with a macro F1-score of 0.86, outperforming the other approaches for each of the categories. In Table <ref type="table" target="#tab_2">3</ref> we report the performances for each entity with the best-performing model. The Sign or Symptom detection task obtains a 0.82 F1 score. In the work of <ref type="bibr" target="#b36">(Ngai and Rudzicz, 2022)</ref>, the authors also detect symptoms obtaining an F1 score of 0.61. However, these results can not be directly compared since the datasets on which both models were fine-tuned are different: we train on clinical cases, while they use dialogues between doctors and patients. Moreover, given that the dataset they use is not released, we can not evaluate our approach to their data.</p><p>The results of the symptoms alignment module experiments are summarised in Table <ref type="table" target="#tab_3">4</ref>. As baseline models, we propose to use the same methods but without the context of the symptom, similarly to <ref type="bibr" target="#b30">(Manzini et al., 2022)</ref> DASH. In Table <ref type="table" target="#tab_3">4</ref> we show only the bestperforming baseline PubMedBERT no context obtaining similar results to DASH (0.41 and 0.37, respectively). Adding contextual representation to the embeddings results in a significant improvement (up to 0.53 in accuracy) supporting the hypothesis that context plays an important role when translating layperson terms to formal medical terms. Error Analysis. HPO has limitations with respect to the number of symptoms associated with each diagnosis. For some diagnoses, we have multiple symptoms, while for others we can have only one or none. We notice that in those cases where the diagnosis is a mental disease, the model tends to make more mistakes. Inspecting HPO for this kind of diagnoses, we find that either the diagnosis does not appear in the HPO ontology or the symptoms tend to be more general, including a lot of common symptoms like changes in appetite or low energy, that alone may not be relevant but all together indicate a precise diagnosis. Moreover, some relevant symptoms may not be described explicitly but encoded in the clinical cases as Findings. These findings often refer to a relevant symptom that is not explicitly mentioned in the case, like in the example introduced in Section 3 about findings, where we have "respirations are 24/min" that, combined with the fact that the patient is a 34-yearold woman, means that she has dyspnea. Automatically deriving this implicit knowledge remains an open challenging issue. Given that we rely on HPO only, some diseases or diagnoses are not present in the knowledge base, preventing us to generate the associated explanations. Combining HPO with more specialized medical knowledge bases is a future direction for this work, both to complete the information we have, and also to integrate new diagnoses. EXPLANATION GENERATION</p><p>In the previous section, we described the first steps of our pipeline for automatically identifying the relevant symptoms which occur in the clinical case description and then matching them with the symptoms associated with the diseases in the medical knowledge base HPO. We move now to the last step of the pipeline, i.e., the generation of natural language explanatory arguments, according to the identified relevant symptoms for the correct and incorrect diagnoses. Given the specificity of the clinical data we are dealing with, we decide to address this task by generating explanations through the definition of explanatory patterns <ref type="bibr" target="#b21">(Josephson and Josephson, 1994;</ref><ref type="bibr" target="#b7">Campos, 2011;</ref><ref type="bibr" target="#b13">Dragulinescu, 2016)</ref>. We have therefore defined different patterns which take into account the different requirements of our use case scenario, where we aim at (i) explaining the correct answer by the detected symptoms and their frequency, (ii) explaining why the incorrect options cannot hold, and (iii) highlighting the relevant symptoms not explicitly mentioned in the clinical case. Let us consider the following clinical case, where in bold we highlight the symptoms and we underline the relevant symptoms supporting the correct answer.</p><p>Clinical Case. A previously healthy 34-year-old woman is brought to the physician because of fever and headache for 1 week. She has not been exposed to any disease. She takes no medications. Her temperature is 39.3°C (102.8°F), pulse is 104/min, respirations are 24/min, and blood pressure is 135/88 mm Hg. She is confused and oriented only to person. Examination shows jaundice of the skin and conjunctivae. There are a few scattered petechiae over the trunk and back. There is no lymphadenopathy. Physical and neurologic examinations show no other abnormalities. Test of the stool for occult blood is positive. Laboratory studies show: Hematocrit 32% with fragmented and nucleated erythrocytes Leukocyte count 12,500/mm3 Platelet count 20,000/mm3 Prothrombin time 10 sec Partial thromboplastin time 30 sec Fibrin split products negative Serum Urea nitrogen 35 mg/dL Creatinine 3.0 mg/dL Bilirubin Total 3.0 mg/dL Direct 0.5 mg/dL Lactate dehydrogenase 1000 U/L Blood and urine cultures are negative. A CT scan of the head shows no abnormalities. Which of the following is the most likely diagnosis?</p><p>The correct diagnosis is Thrombotic thrombocytopenic purpura, whilst the other (incorrect) options are Disseminated intravascular coagulation, Immune thrombocytopenic purpura, Meningococcal meningitis, Sarcoidosis and Systemic lupus erythematosus.</p><p>Why Pattern. We focus here on the correct diagnosis explanation pattern, which allows explaining why this is the correct diagnosis. We define the following template to generate our natural language explanations: In Template 1, the <ref type="bibr">[CORRECT DIAGNOSIS]</ref> represents the correct answer to the question "Which of the following is the most likely diagnosis?" and therefore the correct diagnosis of the described disease. The <ref type="bibr">[SYMPTOMS]</ref> in bold represent the symptoms automatically detected through the first module of our pipeline, and they are also underlined when they are considered as relevant by our matching module, i.e., they are listed among the symptoms for the disease in the HPO knowledge base. Both [PERFECT MATCHED SYMPTOMS] and [MATCHED SYMPTOMS] in Template 1 are considered relevant but they differ in the confidence level the system assigns to the matched symptoms. This allows us to integrate a notion of granularity in our explanations and to rely on the symptoms detected in the clinical case that strongly match with a symptom in HPO. If the system does not detect any relevant symptom, no explanation is generated for the correct answer. Furthermore, we employ the information about the symptom frequencies (retrieved through HPO) in the [OBLIGATORY SYMPTOMS] and [VERY FREQUENT SYMPTOMS] to generate stronger evidence to support our natural language argumentative explanations. Sometimes the frequencies are not available in the HPO, in which case we do not display them in our final explanation.</p><p>We present now some examples of explanatory arguments automatically generated by our system. Why not Template. Explaining why a diagnosis is the correct one is important, but it is also necessary to be able to say why the other options are not correct as possible diagnoses for the clinical case under investigation <ref type="bibr" target="#b32">(Miller, 2019)</ref> Example 2 shows the NL explanation of why the possible answer [Meningococcal meningitis] is not the correct diagnosis given the symptoms discussed in the clinical case description. In case the disease is not found in HPO, we do not generate the associated explanation.</p><p>Additional Explanatory Arguments. In order to enrich our explanations with additional explanatory arguments to improve critical thinking in the medical residents, we also generate another template. Indeed, in some clinical cases, it is possible that the symptoms are not sufficient to explain the diagnosis or sometimes the symptom has to be combined with vital signs or other characteristics of the patient to be correctly interpreted. Some of these signs represent potentially important symptoms for the diagnosis, as in the previous example, where the sentence respirations are 24/min could be associated with the symptom of Dyspnea in HPO. Template 3 aims at drawing the medical residents' attention to (statistically) important symptoms that are missing or not explicitly mentioned in the clinical case description: Template 3. Furthermore, [CORRECT DIAGNOSIS VERY FREQUENT SYMPTOMS (MINUS MATCHED SYMPTOMS)] are also frequent symptoms for [CORRECT DIAGNOSIS] and could be found in the findings of the clinical case.</p><p>Example 3 is generated by our system and brings attention to Dyspnea. This additional explanatory argument complements the explanation we generate for the correct and incorrect diagnoses in the case presented at the beginning of this section. Example 3. Furthermore, [Dyspnea, Thrombocytopenia, Generalized muscle weakness, Reticulocytosis, and Microangiopathic hemolytic anemia] are also frequent symptoms for [Thrombotic thrombocytopenic purpura] and could be found in the findings of the clinical case.</p><p>Limitations. Our work aims to generate templatebased natural language explanations to explain from a symptomatic point of view why a diagnosis is correct and why the remaining ones are incorrect. Templatebased explanations are limited in several ways. First, they are design-dependent, which means that if the templates are not well-designed, they are not helping the user in getting a better understanding of the reason behind a correct/incorrect diagnosis. This can reduce the user's overall satisfaction with the program and make it less effective at achieving its intended goals, i.e. supporting medical residents' training. In our case, we tried to build our template in collaboration with doctors to have a result compliant with their expectations and requirements. Templates are also inflexible and are fixed in advance, they may not be able to adapt to changing circumstances or to new information. This can make them less effective in dynamic or rapidly-changing environments. Again, this is not a serious issue in our case because we are using only the symptoms as the source of data for the moment, which are not evolving.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">CONCLUSION</head><p>In this paper, we present a full pipeline to generate natural language explanatory arguments for correct and incorrect diagnoses in clinical cases. More precisely, based on a novel annotated linguistic resource, our pipeline first automatically identifies in a clinical case description the relevant symptoms and matches them to the HPO medical knowledge base terms to associate symptoms to the correct and incorrect diagnoses proposed as potential answers to the test, and second, automatically generates a natural language explanatory argument which highlights why a certain answer is the correct diagnoses and why the others are not. Extensive experiments on a dataset of 314 clinical cases in English on various diseases show good results (0.86 F1-Score on symptom detection and 0.53 Accuracy on relevant symptom alignment for Top 5 matches), outperforming competitive baselines and SOTA approaches.</p><p>Several future work lines arise from this work. First, we plan to address a user evaluation with medical residents. Even though clinical doctors have been involved in the definition of the annotation guidelines we defined, a user evaluation with medical residents is required to get their feedback on our explanatory arguments. Second, we plan to make these explanations interactive to address a rule-based dialogue with the student to focus on precise aspects of the clinical case and go into more precise or generic explanations if required by the student.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Overview of our full pipeline for symptom prediction and alignment, and NL explanation generation module.</figDesc><graphic coords="7,73.70,98.93,447.90,161.02" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>Template 1. (Why for correct diagnosis) The patient is showing a [CORRECT DIAGNOSIS] as these following symptoms [PERFECT MATCHED SYMPTOMS, MATCHED SYMPTOMS] are direct symptoms of [COR-RECT DIAGNOSIS]. Moreover, [OBLIGATORY SYMPTOMS] are obligatory symptoms (always present, i.e., in 100% of the cases) and [VERY FREQUENT SYMPTOMS] are very frequent symptoms (holding on 80% to 99% of the cases) for [COR-RECT DIAGNOSIS] and are present in the case description. 6</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Example 1 .</head><label>1</label><figDesc>The patient is showing a [Thrombotic thrombocytopenic purpura] as these following symptoms [Headache, Fever, Confusion (Oriented to persons) and Reticulocytosis (Jaundice of the skin)] are direct symptoms of [Thrombotic thrombocytopenic purpura]. Moreover [Reticulocytosis (Jaundice of the skin)] are very frequent symptoms (holding on 80% to 99% of the cases) for [Thrombotic thrombocytopenic purpura] and are present in the case description. 1, we inject only the symptoms matched in the HPO for the [PERFECT MATCHED SYMPTOMS], and we combine the HPO symptoms with the symptoms detected in the case description for the [MATCHED SYMPTOMS] in this form: [matched symptom in HPO (detected symptom in the clinical case)] (e.g., in Example 1: Confusion (Oriented to persons) and Reticulocytosis (Jaundice of the skin))</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Statistics of the MEDQA-USMLE-Symp dataset.</figDesc><table><row><cell>Label</cell><cell># Entities</cell></row><row><cell>Sign or Symptom</cell><cell>1579</cell></row><row><cell>Finding</cell><cell>1169</cell></row><row><cell>Temporal Concept</cell><cell>567</cell></row><row><cell>Location</cell><cell>498</cell></row><row><cell>Population Group</cell><cell>364</cell></row><row><cell>Age Group</cell><cell>304</cell></row><row><cell>No Symptom Occurrence</cell><cell>264</cell></row><row><cell cols="2">respect to a given disease, we employ the HPO knowl-</cell></row><row><cell cols="2">edge base to retrieve (i) the relevant information of</cell></row><row><cell cols="2">each diagnosis which is proposed as an option to an-</cell></row><row><cell cols="2">swer the question "Which of the following is the most</cell></row><row><cell cols="2">likely diagnosis?", and (ii) the symptoms (named</cell></row><row><cell cols="2">terms in HPO) associated to each diagnosis. This</cell></row><row><cell cols="2">knowledge base also includes information on the fre-</cell></row><row><cell cols="2">quency 2 of the occurrence of symptoms, defined in</cell></row><row><cell cols="2">collaboration with ORPHA 3 as follows: Excluded</cell></row><row><cell cols="2">(0%); Very rare (1-4%); Occasional (5-29%); Fre-</cell></row><row><cell cols="2">quent (30-79%); Very frequent (99-80%). Obligate</cell></row><row><cell cols="2">(100%); HPO integrates different sources of symp-</cell></row><row><cell cols="2">toms, including ORPHA and OMIM</cell></row></table><note><p><p>4 </p>. This knowledge base is quite rich and contains also links and hierarchical links between symptoms (Symptom S2 subclass of Symptom S1), genes or definitions.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Results for entity recognition in macro multi-class precision, recall, and F1-score. some cases, it outperforms them. This may be due to the fact that the clinical cases from our dataset are written for medical exams at the med school. They contain some technical specialized words, but overall the symptoms are described in layperson terms.It is worth noticing that the majority of our labels do not pertain to medical terminology (e.g. Age and Population Group, Location and Temporal Concept). Sign or Symptom and Finding are the only labels that require specialized vocabulary.</figDesc><table><row><cell>Model</cell><cell>P</cell><cell>R</cell><cell>F1</cell></row><row><cell>BERT</cell><cell cols="3">0.85 0.84 0.84</cell></row><row><cell>BioBERT v1.2</cell><cell cols="3">0.84 0.85 0.84</cell></row><row><cell>UmlsBERT</cell><cell cols="3">0.85 0.85 0.85</cell></row><row><cell cols="4">PubMedBERTbase 0.83 0.84 0.83</cell></row><row><cell>SciBERT cased</cell><cell cols="3">0.85 0.85 0.85</cell></row><row><cell>SciBERT uncased</cell><cell cols="3">0.85 0.86 0.86</cell></row><row><cell cols="4">perform similarly, with the best results from the spe-</cell></row><row><cell cols="4">cialized SciBERT (Beltagy et al., 2019) model. The</cell></row><row><cell cols="4">biggest difference in performance is given by com-</cell></row><row><cell cols="4">paring SciBERT uncased with PubMedBERT, with</cell></row><row><cell cols="4">the SciBERT model performing better. Interestingly,</cell></row><row><cell cols="4">BERT performs closely to the specialized models,</cell></row><row><cell>and, in</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 :</head><label>3</label><figDesc>Results for entity recognition using our best performing model (SciBERT uncased) in P, R, and F1-score.</figDesc><table><row><cell>Entity</cell><cell>P</cell><cell>R</cell><cell>F1</cell></row><row><cell>Other</cell><cell cols="3">0.93 0.91 0.92</cell></row><row><cell>Age Group</cell><cell cols="3">1.00 0.97 0.98</cell></row><row><cell>Finding</cell><cell cols="3">0.85 0.88 0.86</cell></row><row><cell>Location</cell><cell cols="3">0.74 0.80 0.77</cell></row><row><cell cols="4">No Symptom Occurrence 0.79 0.72 0.75</cell></row><row><cell>Population Group</cell><cell cols="3">0.88 0.95 0.91</cell></row><row><cell>Sign or Symptom</cell><cell cols="3">0.83 0.82 0.82</cell></row><row><cell>Temporal Concept</cell><cell cols="3">0.78 0.87 0.82</cell></row><row><cell>Weighted avg</cell><cell cols="3">0.89 0.89 0.89</cell></row><row><cell>Macro avg</cell><cell cols="3">0.85 0.86 0.86</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 :</head><label>4</label><figDesc>Results for DASH and our symptom alignment method using different embeddings with and without context (accuracy score).</figDesc><table><row><cell>Model</cell><cell>Accuracy</cell></row><row><cell>DASH</cell><cell>0.37</cell></row><row><cell>PubMedBERT no context</cell><cell>0.41</cell></row><row><cell>BERT + context</cell><cell>0.38</cell></row><row><cell>SciBERT + context</cell><cell>0.39</cell></row><row><cell>UMLSBERT + context</cell><cell>0.44</cell></row><row><cell>S-PubMedBERT + context</cell><cell>0.53</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc>. We, therefore, propose to provide explanations based on the relevant symptoms for the incorrect options by contrasting them with the clinical case at hand.</figDesc><table><row><cell>or CSF pleocytosis, Increased CSF protein, Hypoglycor-</cell></row><row><cell>rhachia] symptoms.</cell></row><row><cell>Despite [Petechiae, Fever, Headache] symptoms</cell></row><row><cell>shared with the [Thrombotic thrombocytopenic purpura]</cell></row><row><cell>correct diagnosis, the [Meningococcal meningitis] diagno-</cell></row><row><cell>sis is based on [Stiff neck, Nuchal rigidity or CSF pleocy-</cell></row><row><cell>tosis, Increased CSF protein and Hypoglycorrhachia].</cell></row><row><cell>Moreover, [Stiff neck, Nuchal rigidity, CSF pleocy-</cell></row><row><cell>tosis, Increased CSF protein or Hypoglycorrhachia] are</cell></row><row><cell>very frequent symptoms (holding on 80% to 99% of the</cell></row><row><cell>cases) for [Meningococcal meningitis] and are not present</cell></row><row><cell>in the case description.</cell></row><row><cell>Template 2. (Why not for incorrect diagnosis) Con-</cell></row><row><cell>cerning the [INCORRECT DIAGNOSIS] diagnosis, it has</cell></row><row><cell>to be discarded because the patient in the case descrip-</cell></row><row><cell>tion is not showing [INCORRECT DIAGNOSIS SYMP-</cell></row><row><cell>TOMS FROM HPO (MINUS DETECTED SYMPTOMS</cell></row><row><cell>IN CASE)] symptoms.</cell></row><row><cell>Despite [SHARED CORRECT SYMPTOMS] symp-</cell></row><row><cell>toms shared with the [CORRECT DIAGNOSIS] correct</cell></row><row><cell>diagnosis, the [INCORRECT DIAGNOSIS] diagnosis is</cell></row><row><cell>based on [INCORRECT DIAGNOSIS SYMPTOMS].</cell></row><row><cell>Moreover, [OBLIGATORY SYMPTOMS] are obliga-</cell></row><row><cell>tory symptoms (always present, i.e., in 100% of the cases)</cell></row><row><cell>and [VERY FREQUENT SYMPTOMS] are very frequent</cell></row><row><cell>symptoms (holding on 80% to 99% of the cases) for [IN-</cell></row><row><cell>CORRECT DIAGNOSIS], and they are not present in the</cell></row><row><cell>case description.</cell></row><row><cell>Template 2 can be applied to each incorrect pos-</cell></row><row><cell>sible answer of the case, individually. The incor-</cell></row><row><cell>rect answer corresponds to the [INCORRECT DIAG-</cell></row><row><cell>NOSIS] and [INCORRECT DIAGNOSIS SYMP-</cell></row><row><cell>TOMS] are all relevant symptoms associated with</cell></row><row><cell>this disease in the HPO knowledge base, without the</cell></row><row><cell>symptoms in common with the correct answer. Again,</cell></row><row><cell>in the template, we use the frequencies provided by</cell></row><row><cell>HPO to provide further evidence to make our explana-</cell></row><row><cell>tory arguments more effective. The template includes</cell></row><row><cell>therefore with [OBLIGATORY SYMPTOMS] and</cell></row><row><cell>[VERY FREQUENT SYMPTOMS] the mandatory</cell></row><row><cell>and very frequent symptoms of the incorrect diagno-</cell></row><row><cell>sis, which are missing in the clinical case description.</cell></row><row><cell>The following explanations are automatically gener-</cell></row><row><cell>ated for (one of) the incorrect diagnoses of the clinical</cell></row><row><cell>case we introduced at the beginning of this section.</cell></row><row><cell>Example 2. Concerning the [Meningococcal meningitis]</cell></row><row><cell>diagnostic, it has to be discarded because the patient in the</cell></row><row><cell>case description is not showing [Stiff neck, Nuchal rigidity</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>https://github.com/Wimmics/ MEDQA-USMLE-Symp</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>https://hpo.jax.org/app/browse/term/HP:0040279</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2"><p>https://www.orpha.net/consor/cgi-bin/index.php?lng= FR</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3"><p>https://www.omim.org/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_4"><p>The context consists of the sentence(s) containing the</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_5"><p>Sources from HPO: https://hpo.jax.org/app/browse/ term/HP:0040279</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>ACKNOWLEDGEMENTS</head><p>This work has been supported by the <rs type="funder">French government</rs>, through the <rs type="funder">3IA Côte d'Azur Investments</rs> in the Future project managed by the <rs type="funder">National Research Agency (ANR)</rs> with the reference number <rs type="grantNumber">ANR-19-P3IA-0002</rs>. This work was supported by the <rs type="funder">CHIST-ERA</rs> grant of the <rs type="programName">Call XAI 2019</rs> of the <rs type="funder">ANR</rs> with the grant number Project<rs type="grantNumber">-ANR-21-CHR4-0002</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_CFh27mx">
					<idno type="grant-number">ANR-19-P3IA-0002</idno>
				</org>
				<org type="funding" xml:id="_Pa8AZS5">
					<orgName type="program" subtype="full">Call XAI 2019</orgName>
				</org>
				<org type="funding" xml:id="_FsRWD96">
					<idno type="grant-number">-ANR-21-CHR4-0002</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Quint: Interpretable question answering over knowledge bases</title>
		<author>
			<persName><forename type="first">A</forename><surname>Abujabal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">S</forename><surname>Roy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Yahya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Weikum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing: System Demonstrations</title>
		<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing: System Demonstrations</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="61" to="66" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Towards comprehensive syntactic and semantic annotations of the clinical narrative</title>
		<author>
			<persName><forename type="first">D</forename><surname>Albright</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Lanfranchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Fredriksen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">V</forename><surname>Styler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">F</forename><surname>Warner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Hwang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Dligach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Nielsen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">D</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Medical Informatics Association</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="922" to="930" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Scibert: A pretrained language model for scientific text</title>
		<author>
			<persName><forename type="first">I</forename><surname>Beltagy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Lo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Cohan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1903.10676</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">The unified medical language system (umls): integrating biomedical terminology</title>
		<author>
			<persName><forename type="first">O</forename><surname>Bodenreider</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nucleic acids research</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">suppl 1</biblScope>
			<biblScope unit="page" from="267" to="D270" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">A large annotated corpus for learning natural language inference</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">R</forename><surname>Bowman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Angeli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Potts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1508.05326</idno>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">e-snli: Natural language inference with natural language explanations</title>
		<author>
			<persName><forename type="first">O.-M</forename><surname>Camburu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Rocktäschel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Lukasiewicz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Blunsom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A clinical trials corpus annotated with umls entities to enhance the access to evidence-based medicine</title>
		<author>
			<persName><forename type="first">L</forename><surname>Campillos-Llanos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Valverde-Mateos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Capllonch-Carrión</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Moreno-Sandoval</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC medical informatics and decision making</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="19" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">On the distinction between peirce&apos;s abduction and lipton&apos;s inference to the best explanation</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">G</forename><surname>Campos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Synthese</title>
		<imprint>
			<biblScope unit="volume">180</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="419" to="442" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<author>
			<persName><forename type="first">K</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M.-T</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2003.10555</idno>
		<title level="m">Electra: Pre-training text encoders as discriminators rather than generators</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Argumentative xai: A survey</title>
		<author>
			<persName><forename type="first">K</forename><surname>Cyras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rago</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Albini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Baroni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Toni</surname></persName>
		</author>
		<idno>ArXiv, abs/2105.11266</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Improved methods to aid unsupervised evidence-based fact checking for online health news</title>
		<author>
			<persName><forename type="first">P</forename><surname>Deka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Jurek-Loughrey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Deepak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Data Intelligence</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="474" to="504" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">BERT: Pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M.-W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NAACL-HLT 2019</title>
		<meeting>NAACL-HLT 2019</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="4171" to="4186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Ncbi disease corpus: a resource for disease name recognition and concept normalization</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">I</forename><surname>Dogan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Leaman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of biomedical informatics</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="page" from="1" to="10" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Inference to the best explanation and mechanisms in medicine</title>
		<author>
			<persName><forename type="first">S</forename><surname>Dragulinescu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Theoretical medicine and bioethics</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="211" to="232" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Launching into clinical space with medspacy: a new clinical text processing toolkit in python</title>
		<author>
			<persName><forename type="first">H</forename><surname>Eyre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">B</forename><surname>Chapman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">S</forename><surname>Peterson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">R</forename><surname>Alba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">L</forename><surname>Box</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">L</forename><surname>Duvall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><forename type="middle">V</forename><surname>Patterson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AMIA Annual Symposium Proceedings</title>
		<imprint>
			<publisher>American Medical Informatics Association</publisher>
			<date type="published" when="2021">2021. 2021</date>
			<biblScope unit="page">438</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Measuring nominal scale agreement among many raters</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Fleiss</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological bulletin</title>
		<imprint>
			<biblScope unit="volume">76</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page">378</biblScope>
			<date type="published" when="1971">1971</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Domain-specific language model pretraining for biomedical natural language processing</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Tinn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lucas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Usuyama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Naumann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Poon</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Don&apos;t stop pretraining: Adapt language models to domains and tasks</title>
		<author>
			<persName><forename type="first">S</forename><surname>Gururangan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Marasović</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Swayamdipta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Lo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Beltagy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Downey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">spaCy 2: Natural language understanding with Bloom embeddings, convolutional neural networks and incremental parsing</title>
		<author>
			<persName><forename type="first">M</forename><surname>Honnibal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Montani</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note>To appear</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">What disease does this patient have? a large-scale open domain question answering dataset from medical exams</title>
		<author>
			<persName><forename type="first">D</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Oufattole</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W.-H</forename><surname>Weng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Szolovits</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied Sciences</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">14</biblScope>
			<biblScope unit="page">6421</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Manifest Rationality: A Pragmatic Theory of Argument</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">H</forename><surname>Johnson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000">2000</date>
			<publisher>Lawrence Earlbaum Associates</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Josephson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">G</forename><surname>Josephson</surname></persName>
		</author>
		<title level="m">Abductive inference: Computation, Philosophy, Technology</title>
		<imprint>
			<publisher>Cambridge University Press</publisher>
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Introduction to the bio-entity recognition task at jnlpba</title>
		<author>
			<persName><forename type="first">J.-D</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Ohta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Tsuruoka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Tateisi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Collier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the international joint workshop on natural language processing in biomedicine and its applications</title>
		<meeting>the international joint workshop on natural language processing in biomedicine and its applications</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="70" to="75" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">The human phenotype ontology in 2021</title>
		<author>
			<persName><forename type="first">S</forename><surname>Köhler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gargano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Matentzoglu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">C</forename><surname>Carmody</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Lewis-Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">A</forename><surname>Vasilevsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Danis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Balagura</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Baynam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Brower</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nucleic acids research</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="issue">D1</biblScope>
			<biblScope unit="page" from="1207" to="D1217" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">The chemdner corpus of chemicals and drugs and its annotation principles</title>
		<author>
			<persName><forename type="first">M</forename><surname>Krallinger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Rabal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Leitner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Vazquez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Salgado</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Leaman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Lowe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of cheminformatics</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="17" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Nile: Natural language inference with faithful natural language explanations</title>
		<author>
			<persName><forename type="first">S</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Talukdar</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2005.12116</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Albert: A lite bert for self-supervised learning of language representations</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Goodman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Gimpel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Soricut</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1909.11942</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Biobert: a pre-trained biomedical language representation model for biomedical text mining</title>
		<author>
			<persName><forename type="first">J</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Yoon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">H</forename><surname>So</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1234" to="1240" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Biocreative v cdr task corpus: a resource for chemical disease relation extraction</title>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Sciaky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-H</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Leaman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">P</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J</forename><surname>Mattingly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">C</forename><surname>Wiegers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Database</title>
		<imprint>
			<date type="published" when="2016">2016. 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Stoyanov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1907.11692</idno>
		<title level="m">Roberta: A robustly optimized bert pretraining approach</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Mapping layperson medical terminology into the human phenotype ontology using neural machine translation models</title>
		<author>
			<persName><forename type="first">E</forename><surname>Manzini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Garrido-Aguirre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Fonollosa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Perera-Lluna</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Expert Systems with Applications</title>
		<imprint>
			<biblScope unit="volume">204</biblScope>
			<biblScope unit="page">117446</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Umlsbert: Clinical domain knowledge augmentation of contextual embeddings using the unified medical language system metathesaurus</title>
		<author>
			<persName><forename type="first">G</forename><surname>Michalopoulos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Kaka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Wong</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2010.10391</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Explanation in artificial intelligence: Insights from the social sciences</title>
		<author>
			<persName><forename type="first">T</forename><surname>Miller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artif. Intell</title>
		<imprint>
			<biblScope unit="volume">267</biblScope>
			<biblScope unit="page" from="1" to="38" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Medmentions: A large biomedical corpus annotated with umls concepts</title>
		<author>
			<persName><forename type="first">S</forename><surname>Mohan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Li</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1902.09476</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><surname>Narang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Raffel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Fiedel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Malkan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2004.14546</idno>
		<title level="m">Wt5?! training text-to-text models to explain their predictions</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Bioalbert: A simple and effective pre-trained language model for biomedical named entity recognition</title>
		<author>
			<persName><forename type="first">U</forename><surname>Naseem</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Khushi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">B</forename><surname>Reddy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Rajendran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Razzak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Joint Conference on Neural Networks (IJCNN)</title>
		<imprint>
			<date type="published" when="2021">2021. 2021</date>
			<biblScope unit="page" from="1" to="7" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Doctor XAvIer: Explainable diagnosis on physician-patient dialogues and XAI evaluation</title>
		<author>
			<persName><forename type="first">H</forename><surname>Ngai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Rudzicz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 21st Workshop on Biomedical Language Processing</title>
		<meeting>the 21st Workshop on Biomedical Language Processing<address><addrLine>Dublin, Ireland</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="337" to="344" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Glove: Global vectors for word representation</title>
		<author>
			<persName><forename type="first">J</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP 2014</title>
		<meeting>EMNLP 2014</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="1532" to="1543" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Language models are unsupervised multitask learners</title>
		<author>
			<persName><forename type="first">A</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Child</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Amodei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">OpenAI blog</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page">9</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<author>
			<persName><forename type="first">C</forename><surname>Raffel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Narang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Matena</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Liu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1910.10683</idno>
		<title level="m">Exploring the limits of transfer learning with a unified text-to-text transformer</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Bioelectra: pretrained biomedical text encoder using discriminators</title>
		<author>
			<persName><forename type="first">K</forename><surname>Raj Kanakarajan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Kundumani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sankarasubbu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 20th Workshop on Biomedical Language Processing</title>
		<meeting>the 20th Workshop on Biomedical Language Processing</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="143" to="154" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Sentence-bert: Sentence embeddings using siamese bert-networks</title>
		<author>
			<persName><forename type="first">N</forename><surname>Reimers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Gurevych</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1908.10084</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Building applied natural language generation systems</title>
		<author>
			<persName><forename type="first">E</forename><surname>Reiter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Dale</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Natural Language Engineering</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="57" to="87" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">Explainable ai (xai): A systematic meta-survey of current challenges and future opportunities</title>
		<author>
			<persName><forename type="first">W</forename><surname>Saeed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">W</forename><surname>Omlin</surname></persName>
		</author>
		<idno>ArXiv, abs/2111.06420</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Overview of biocreative ii gene mention recognition</title>
		<author>
			<persName><forename type="first">L</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">K</forename><surname>Tanabe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-J</forename><surname>Kuo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-N</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y.-S</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Klinger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">M</forename><surname>Friedrich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Ganchev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Torii</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Genome biology</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1" to="19" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Clamp-a toolkit for efficiently building customized clinical natural language processing pipelines</title>
		<author>
			<persName><forename type="first">E</forename><surname>Soysal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Pakhomov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Medical Informatics Association</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="331" to="336" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">A survey on explainable artificial intelligence (XAI): towards medical XAI</title>
		<author>
			<persName><forename type="first">E</forename><surname>Tjoa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Guan</surname></persName>
		</author>
		<idno>CoRR, abs/1907.07374</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Argumentation and explainable artificial intelligence: a survey</title>
		<author>
			<persName><forename type="first">A</forename><surname>Vassiliades</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Bassiliades</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Patkos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Knowledge Engineering Review</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page">e5</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Transformers: State-of-the-art natural language processing</title>
		<author>
			<persName><forename type="first">T</forename><surname>Wolf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Debut</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Sanh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chaumond</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Delangue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Moi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Cistac</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Rault</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Louf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Funtowicz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Davison</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Shleifer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Von Platen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Jernite</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Plu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">L</forename><surname>Scao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gugger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Drame</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Lhoest</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Rush</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations</title>
		<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="38" to="45" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
