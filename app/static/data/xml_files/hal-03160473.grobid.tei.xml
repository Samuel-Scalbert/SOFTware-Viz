<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Privacy-Preserving and Bandwidth-Efficient Federated Learning: An Application to In-Hospital Mortality Prediction</title>
				<funder>
					<orgName type="full">NRDI</orgName>
				</funder>
				<funder ref="#_XgbGCz4">
					<orgName type="full">EU/EFPIA Innovative Medicines Initiative 2 Joint Undertaking</orgName>
				</funder>
				<funder ref="#_hk4t8C4">
					<orgName type="full">Ministry of Innovation and Technology NRDI Office</orgName>
				</funder>
				<funder ref="#_yuhRKEg #_EmEum2E">
					<orgName type="full">Agence Nationale de la Recherche</orgName>
					<orgName type="abbreviated">ANR</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Raouf</forename><surname>Kerkouche</surname></persName>
							<email>raouf.kerkouche@inria.fr</email>
						</author>
						<author>
							<persName><surname>Gergely</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Claude</forename><surname>Castelluccia</surname></persName>
							<email>claude.castelluccia@inria.fr</email>
						</author>
						<author>
							<persName><forename type="first">Pierre</forename><surname>GenevÃ¨s</surname></persName>
							<email>pierre.geneves@cnrs.fr</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Privatics team</orgName>
								<orgName type="institution" key="instit1">Univ. Grenoble Alpes</orgName>
								<orgName type="institution" key="instit2">Inria</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">BME-HIT</orgName>
								<orgName type="laboratory">Crysys Lab</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="department">Privatics team</orgName>
								<orgName type="institution" key="instit1">Univ. Grenoble Alpes</orgName>
								<orgName type="institution" key="instit2">Inria</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="laboratory">Tyrex team</orgName>
								<orgName type="institution" key="instit1">Univ. Grenoble Alpes</orgName>
								<orgName type="institution" key="instit2">CNRS</orgName>
								<orgName type="institution" key="instit3">Inria</orgName>
								<address>
									<settlement>Grenoble</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff4">
								<orgName type="laboratory">INP</orgName>
								<orgName type="institution">LIG</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Privacy-Preserving and Bandwidth-Efficient Federated Learning: An Application to In-Hospital Mortality Prediction</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">AD17D12C0CA5C3C13AC57E5DE1E9E8ED</idno>
					<idno type="DOI">10.1145/3450439.3451859</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-04-12T14:47+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Machine Learning, and in particular Federated Machine Learning, opens new perspectives in terms of medical research and patient care. Although Federated Machine Learning improves over centralized Machine Learning in terms of privacy, it does not provide provable privacy guarantees. Furthermore, Federated Machine Learning is quite expensive in term of bandwidth consumption as it requires participant nodes to regularly exchange large updates. This paper proposes a bandwidth-efficient privacy-preserving Federated Learning that provides theoretical privacy guarantees based on Differential Privacy. We experimentally evaluate our proposal for in-hospital mortality prediction using a real dataset, containing Electronic Health Records of about one million patients. Our results suggest that strong and provable patient-level privacy can be enforced at the expense of only a moderate loss of prediction accuracy.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>An Electronic Health Record (EHR) is a digital version of the patient's medical information. EHR data open new perspectives, especially with the development of machine learning. EHR data can be used to train predictive models in order to predict patient's medical conditions and help medical doctors to develop appropriate care <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b35">36]</ref>.</p><p>However, medical data is considered as sensitive information that can lead to some real and serious damage to the patient if any leakage happens. For example, medical data can be exploited by insurance companies to adapt their insurance fees, by banks to deny loans, or by politicians to discredit their opponents. Therefore, the privacy of such kind of sensitive data must be guaranteed and privacy-preserving predictive models are needed.</p><p>Predictive models are typically built using machine learning algorithms that are trained on centralized datasets. When a model is trained on multiple datasets, collected for example by several hospitals, the centralization of all datasets on a single server introduces additional, and often unacceptable, privacy risks. To mitigate this problem, Federated learning (FL) was proposed as a new learning protocol. Federated Learning consists of distributing the learning process on the different entities providing data: instead of aggregating the data on a single server, the training is performed locally by each participating entities and the models are then shared and aggregated <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b37">38]</ref>. Although Federated Learning mitigates the privacy risks by design, recent results have shown that some attacks, such as membership and property inference attacks, are still possible <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b32">33]</ref>. Moreover, complete training samples can also be reconstructed purely from the captured gradients <ref type="bibr" target="#b42">[43,</ref><ref type="bibr" target="#b43">44]</ref>.</p><p>Furthermore, since participating entities must collaborate by exchanging their model updates, the required bandwidth during the training phase is often significant and prohibitive <ref type="bibr" target="#b21">[22]</ref>.</p><p>Contribution. This paper proposes a bandwidth-efficient privacypreserving Federated Learning scheme that provides theoretical privacy guarantees. Our proposal guarantees Differential Privacy with practical utility even on highly imbalanced training data. This is challenging as imbalanced data increases the injected noise required by Differential Privacy and hence substantially degrades model quality. Our solution relies on the extreme quantization of the gradients in order to reduce communication costs as well as on downsampling of mini-batches to diminish the noise needed for Differential Privacy. We experimentally evaluate the performance of our solution for in-hospital mortality prediction using real EHR data, containing about one million records of patients. Our results suggest that patient-level privacy can be enforced at the expense of only a moderate loss of prediction accuracy. Outline. We describe the background in Section 2. We introduce our privacy-preserving scheme in Section 3. We report on experiments with real-world data in Section 4. Finally we discuss related works in Section 5 before concluding in Section 7.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">BACKGROUND 2.1 Federated Learning (FL-STANDARD)</head><p>In federated learning <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b37">38]</ref>, multiple parties (clients) build a common machine learning model on the union of their training data without sharing them with each other. At each round of the training, some clients retrieve the global model from the parameter server, update the global model based on their own training data, and send back their updated model to the server. The server aggregates the updated models of all clients to obtain a global model that is re-distributed to some selected parties in the next round.</p><p>In particular, a subset K of all ğ‘ clients are randomly selected at each round to update the global model, and ğ¶ = |K|/ğ‘ denotes the fraction of selected clients. At round ğ‘¡, a selected client ğ‘˜ âˆˆ K executes ğ‘‡ gd local gradient descent iterations on the common model w ğ‘¡-1 using its own training data ğ· ğ‘˜ (ğ· = âˆª ğ‘˜ âˆˆK ğ· ğ‘˜ ), and obtains the updated model w ğ‘¡ , where the number of weights is denoted by ğ‘› (i.e., |w ğ‘¡ | = |Î”w ğ‘¡ | = ğ‘› for all ğ‘˜ and ğ‘¡). Each client ğ‘˜ submits the update Î”w ğ‘¡ = w ğ‘¡w ğ‘¡-1 to the server, which then updates the common model as follows:</p><formula xml:id="formula_0">w ğ‘¡ = w ğ‘¡ -1 + ğ‘˜ âˆˆK |ğ· ğ‘˜ | ğ‘— |ğ· ğ‘— | Î”w ğ‘˜ ğ‘¡ ,</formula><p>where |ğ· ğ‘˜ | is known to the server for all ğ‘˜ (a client's update is weighted with the size of its training data). The server stops training after a fixed number of rounds ğ‘‡ cl , or when the performance of the common model does not improve on a held-out data.</p><p>Note that each ğ· ğ‘˜ may be generated from different distributions (i.e., Non-IID case), that is, any client's local dataset may not be representative of the population distribution <ref type="bibr" target="#b26">[27]</ref>. This can happen, for example, when not all output classes are represented in every client's training data. The federated learning of neural networks is summarized in Alg. 1. In the sequel, each client is assumed to use the same model architecture. </p><formula xml:id="formula_1">12 w ğ‘˜ ğ‘¡ = SGD(ğ· ğ‘˜ , w ğ‘˜ ğ‘¡ -1 ,ğ‘‡ gd ) Output: Model update (w ğ‘˜ ğ‘¡ -w ğ‘˜ ğ‘¡ -1 )</formula><p>The motivation of federated learning is three-fold: first, it aims to provide confidentiality of each participant's training data by However, several prior works have demonstrated that model updates do leak potentially sensitive information <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b32">33]</ref>. Hence, simply not sharing training data per se is not enough to guarantee their confidentiality.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Differential Privacy</head><p>Differential privacy allows a party to privately release information about a dataset: a function of an input dataset is perturbed, so that any information which can differentiate a record from the rest of the dataset is bounded <ref type="bibr" target="#b16">[17]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Definition 2.1 (Privacy loss).</head><p>Let A be a privacy mechanism which assigns a value in Range(A) to a dataset ğ·. The privacy loss of A with datasets ğ· and ğ· â€² at output ğ‘‚ âˆˆ Range(A) is a random variable P (A, ğ·, ğ· â€² , ğ‘‚) = log</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Pr[ A (ğ·)=ğ‘‚ ]</head><p>Pr[ A (ğ· â€² )=ğ‘‚ ] where the probability is taken on the randomness of A. Definition 2.2 ((ğœ–, ğ›¿)-Differential Privacy <ref type="bibr" target="#b16">[17]</ref>). A privacy mechanism A guarantees (ğœ€, ğ›¿)-differential privacy if for any database ğ· and ğ· â€² , differing on at most one record, Pr ğ‘‚âˆ¼A (ğ·) [P (A, ğ·, ğ· â€² , ğ‘‚) &gt; ğœ€] â‰¤ ğ›¿.</p><p>Intuitively, this guarantees that an adversary, provided with the output of A, can draw almost the same conclusions (up to ğœ€ with probability larger than 1 -ğ›¿) about any record no matter if it is included in the input of A or not <ref type="bibr" target="#b16">[17]</ref>. That is, for any record owner, a privacy breach is unlikely to be due to its participation in the dataset. Moments Accountant. Differential privacy maintains composition; the privacy guarantee of the ğ‘˜-fold adaptive composition of A 1:ğ‘˜ = A 1 , . . . , A ğ‘˜ can be computed using the moments accountant method <ref type="bibr" target="#b1">[2]</ref>. In particular, it follows from Markov's inequality that Pr[P (A, ğ·, ğ· â€² , ğ‘‚) â‰¥ ğœ€] â‰¤ E[exp(ğœ†P (A, ğ·, ğ· â€² , ğ‘‚))]/exp(ğœ†ğœ€) for any output ğ‘‚ âˆˆ Range(A) and ğœ† &gt; 0. This implies that A is (ğœ€, ğ›¿)-DP with ğ›¿ = min ğœ† exp(ğ›¼ A (ğœ†) -ğœ†ğœ€), where ğ›¼ A (ğœ†) = max ğ·,ğ· â€² log E ğ‘‚âˆ¼A (ğ·) [exp(ğœ†P (A, ğ·, ğ· â€² , ğ‘‚))] is the log of the moment generating function of the privacy loss. The privacy guarantee of the composite mechanism A 1:ğ‘˜ can be computed using that ğ›¼ A 1:ğ‘˜ (ğœ†) â‰¤ ğ‘˜ ğ‘–=1 ğ›¼ A ğ‘– (ğœ†) <ref type="bibr" target="#b1">[2]</ref>. Gaussian Mechanism. There are a few ways to achieve DP, including the Gaussian mechanism <ref type="bibr" target="#b16">[17]</ref>. A fundamental concept of all of them is the global sensitivity of a function <ref type="bibr" target="#b16">[17]</ref>. The Gaussian Mechanism <ref type="bibr" target="#b16">[17]</ref> consists of adding Gaussian noise to the true output of a function. In particular, for any function ğ‘“ : D â†’ R ğ‘› , the Gaussian mechanism is defined as adding i.i.d Gaussian noise with variance (Î” 2 ğ‘“ â€¢ğœ) 2 and zero mean to each coordinate value of ğ‘“ (ğ·). Recall that the pdf of the Gaussian distribution with mean ğœ‡ and variance ğœ‰ 2 is</p><formula xml:id="formula_2">pdf G (ğœ‡,ğœ‰) (ğ‘¥) = 1 âˆš 2ğœ‹ğœ‰ exp - (ğ‘¥ -ğœ‡) 2 2ğœ‰ 2<label>(1)</label></formula><p>In fact, the Gaussian mechanism draws vector values from a multivariate spherical (or isotropic) Gaussian distribution which is described by random variable G(ğ‘“ (ğ·), Î” 2 ğ‘“ â€¢ ğœI ğ‘› ), where ğ‘› is omitted if its unambiguous in the given context.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">TOWARD FEDERATED LEARNING RECORD-LEVEL PRIVACY 3.1 The FL-SIGN Protocol</head><p>In the FL-STANDARD scheme, presented in Section 2.1, each selected client sends its updated model to the central server. As discussed previously, this scheme has several drawbacks in terms of bandwidth and privacy. We propose to limit these drawbacks by quantizing the model weights as in <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b20">21]</ref>. More specifically, in the new scheme, referred to as FL-SIGN in the rest of this paper, each client sends only the sign of every coordinate value in its parameter update vector. The server takes the sign of the sum of signs per coordinate and scales down the result with a fixed constant ğ›¾ (which is in the order of 10 -3 in practice) in order to limit the contribution of each client and adjust convergence. This scaled aggregated updates are added to the global model. More specifically, FL-SIGN (see Alg. 3) differs from the standard federated scheme FL-STANDARD (see Alg. 1) as follows:</p><p>(1) Each client returns s ğ‘˜ ğ‘¡ = sign(ww ğ‘˜ ğ‘¡ -1 ) instead of (ww ğ‘˜ ğ‘¡ -1 ), where sign : R ğ‘› â†’ {-1, 1} ğ‘› returns the sign of each coordinate value of the input vector if it is non-zero and a sign chosen uniformly at random otherwise. (2) The server sums the sign vectors s ğ‘˜ ğ‘¡ sent by each client ğ‘˜ and computes the sign vector of this sum as sign ğ‘˜ s ğ‘˜ ğ‘¡ . This is equivalent to take the median of all clients' signs at every position of the update vectors. Unlike in Alg. 1, the update s ğ‘˜ ğ‘¡ is not weighted with client ğ‘˜'s data size |ğ· ğ‘˜ |, since that would require the client to send |ğ· ğ‘˜ | to the server which would enable the adversary to maliciously scale up its sign vector by sending a fabricated size of its training data.</p><p>The extreme quantization performed by FL-SIGN reduces the communication costs of federated learning by a factor of 32 (since only one bit is sent per parameter instead of 32 bits). Note also that, if the quantized update vector is sparse, other lossless or lossy compression techniques can further improve communication efficiency <ref type="bibr" target="#b21">[22]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Privacy-Preserving FL-SIGN (FL-SIGN-DP)</head><p>In FL-SIGN, a participant only sends the signs of its updates, as opposed to their actual values, hence it intuitively reveals less information about the client's dataset than the original FL-STANDARD scheme. In order to experimentally validate this intuition, we implemented the inference attack described in <ref type="bibr" target="#b28">[29]</ref> on FL-STANDARD and FL-SIGN <ref type="foot" target="#foot_1">1</ref> . Results showed that the attack accuracy dropped from 92% for FL-STANDARD to 50% for FL-SIGN. While these results suggest that privacy could be preserved in practice, they do not provide any strong guarantee.</p><p>To reason about the general privacy guarantee of FL-SIGN more rigorously, consider the sign vector s ğ‘˜ ğ‘¡ = sign(w ğ‘˜ ğ‘¡w ğ‘˜ ğ‘¡ -1 ). Several attacks have demonstrated <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b32">33]</ref> that Î”w ğ‘˜ ğ‘¡ = w ğ‘˜ ğ‘¡w ğ‘˜ ğ‘¡ -1 can be used to infer the membership of individual records in the training data due to the strong memorization property of neural networks, and overfitting in general. As taking the sign of Î”w ğ‘˜ ğ‘¡ is a deterministic operation and depends on the value of s ğ‘˜ ğ‘¡ , there is no guarantee that s ğ‘˜ ğ‘¡ does not leak any sensitive information. In order to obtain theoretically private schemes, we extend FL-SIGN with Differential Privacy. Our goal is to design a differentially private scheme that is accurate and also bandwidth efficient (even for small ğœ€ values).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">Privacy and Adversarial Models.</head><p>We consider an adversary, or a set of colluding adversaries, who can access any update vector sent by the server or any clients at each round of the protocol. The adversary is computationally unbounded but passive (i.e., honestbut-curious), that is, it follows the learning protocol faithfully and does not modify any update vector. A plausible adversary is a participating entity, i.e. a malicious client or server, that wants to infer the training data used by other participants.</p><p>We aim at developing a solution that protects each record of the clients' training datasets. For example, in the scenario of collaborating hospitals we aim at protecting each individual patient record of all hospital datasets. </p><formula xml:id="formula_3">11 wğ‘˜ ğ‘¡ = DPSGD(ğ· ğ‘˜ , w ğ‘˜ ğ‘¡ -1 , ğ‘†, ğœ,ğ‘‡ gd ) Output: sign( wğ‘˜ ğ‘¡ -w ğ‘˜ ğ‘¡ -1 )</formula><p>The adversary should not be able to learn from the received model or its updates whether any particular record was used to train the model by any other participants.</p><p>We believe that this adversarial model is reasonable for the medical application that we consider in this paper: it is very unlikely that a participating hospital will take the risk of manipulating the updates that it sends to the server. However, we want to make sure that it can not infer any sensitive information from the models that it receives from the server. In other words, we make the assumption that hospitals may be "curious", but are "honest".</p><p>We use Differential Privacy (DP) because it was proposed to achieve this goal. DP guarantees plausible deniability. Therefore, any negative privacy impact on an individual, i.e. a patient in the dataset, cannot be attributed to his involvement in the training phase (up to ğœ€ and ğ›¿). For example, if an insurance company accesses the model updates or the common model and decides to increase the price of a patient's insurance fee, it cannot be because of the patient's data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2">Operation.</head><p>To guarantee differential privacy for any individual record of a training data, we propose FL-SIGN-DP, depicted in Alg. 4, which is a synergy of FL-SIGN and differentially private gradient descent (DPSGD) from <ref type="bibr" target="#b1">[2]</ref>. In particular, instead of running traditional SGD on its local training data, every client executes DPSGD (depicted in Alg. 6), which guarantees that its output wğ‘˜ ğ‘¡ does not leak any information that is specific to a single training sample (up to ğœ€ and ğ›¿) by clipping the ğ¿ 2 -norm of the gradients and perturbing the result with Gaussian noise. The noise scale is calibrated to ğ‘† and ğœ, where the latter directly gives ğœ€ and ğ›¿ as shown below. Hence, any further computation which uses wğ‘˜ ğ‘¡ is also differentially private.</p><p>Notice that the batch is created using downsampling <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b30">31]</ref> (see Alg. 7) in order to overcome the imbalanced classes of the training data. Downsampling guarantees that every batch contains identical number of samples from every class, and therefore they have similar magnitude of gradients on average.</p><p>Likewise FL-SIGN, FL-SIGN-DP also sends only signs for aggregation, and hence is equally bandwidth efficient.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.3">Privacy analysis.</head><p>The privacy guarantee of FL-SIGN-DP is quantified using the moments accountant method from <ref type="bibr" target="#b1">[2]</ref>. Let   </p><formula xml:id="formula_4">B â€² = Downsampling(B) 4 for each record ğ‘Ÿ in B â€² do 5 âˆ‡ f (ğ‘Ÿ, w) = âˆ‡ğ‘“ (ğ‘Ÿ, w)/max 1, ||âˆ‡ğ‘“ (ğ‘Ÿ,w) || 2 ğ‘† 6 end 7 w = w -(ğœ‚/ |B â€² |) ğ‘Ÿ âˆˆB â€² âˆ‡ f (ğ‘Ÿ ; w) + G (0,</formula><formula xml:id="formula_5">= min( |C 1 |, |C 2 |) 3 B 1 â† select ğ‘  min samples from C 1 uniformly at random 4 B 2 â† select ğ‘  min samples from C 2 uniformly at random Output: Balanced batch B 1 âˆª B 2 ğœ‚ 0 (ğ‘¥ |ğœ‰, ğ‘) = pdf G (0,ğœ‰) (ğ‘¥) and ğœ‚ 1 (ğ‘¥ |ğœ‰, ğ‘) = (1 -ğ‘)pdf G (0,ğœ‰) (ğ‘¥) + ğ‘pdf G (1,ğœ‰) (ğ‘¥)</formula><p>where ğ‘ is the sampling probability of a single record in a single round. Let</p><formula xml:id="formula_6">ğ›¼ G (ğœ†|ğ‘) = log max(ğ¸ 1 (ğœ†, ğœ‰, ğ‘), ğ¸ 2 (ğœ†, ğœ‰, ğ‘))<label>(2)</label></formula><p>where</p><formula xml:id="formula_7">ğ¸ 1 (ğœ†, ğœ‰, ğ‘) = âˆ« R ğœ‚ 0 (ğ‘¥ |ğœ‰, ğ‘) â€¢ ğœ‚ 0 (ğ‘¥ |ğœ‰, ğ‘) ğœ‚ 1 (ğ‘¥ |ğœ‰, ğ‘) ğœ† ğ‘‘ğ‘¥ and ğ¸ 2 (ğœ†, ğœ‰, ğ‘) = âˆ« R ğœ‚ 1 (ğ‘¥ |ğœ‰, ğ‘) â€¢ ğœ‚ 1 (ğ‘¥ |ğœ‰, ğ‘) ğœ‚ 0 (ğ‘¥ |ğœ‰, ğ‘) ğœ† ğ‘‘ğ‘¥ Theorem 3.1 (Privacy of FL-SIGN-DP). For any ğ›¿ &gt; 0, FL-SIGN- DP is (min ğœ† (ğ‘‡ cl â€¢ğ›¼ G (ğœ†|ğ‘ 1 ) +ğ‘‡ cl â€¢ (ğ‘‡ gd -1) â€¢ğ›¼ G (ğœ†|ğ‘ 2 ) -log ğ›¿)/ğœ†, ğ›¿)-DP, where ğ›¼ G is defined in Eq. (2), ğ‘ 1 = ğ¶ â€¢ |B| min ğ‘˜ |ğ· ğ‘˜ | , and ğ‘ 2 = |B | min ğ‘˜ |ğ· ğ‘˜ | . FL-SIGN-DP ğ‘‚ ğ‘›ğ‘†ğœ âˆš ğ‘‡ cl ğ¶ğ‘ Table 1: Convergence rates when ğ›¾ = ğ‘‚ (1/ âˆš ğ‘‡ cl ), ğ‘‡ gd = 1, |B| = ğ‘‡ cl</formula><p>The proof follows from Theorem 2 in <ref type="bibr" target="#b1">[2]</ref> and the fact that a record is sampled in the very first SGD iteration of every round if (1) the corresponding client is sampled, which has a probability of ğ¶, and (2) the batch sampled locally at this client contains the record, which has a probability of at most |B| min ğ‘˜ |ğ· ğ‘˜ | . However, the adaptive composition of consecutive SGD iterations are considered where the output of a single iteration depends on the output of the previous iterations. Therefore, the sampling probability for the very first batch is . Compared to FL-SIGN (see Table <ref type="table">1</ref>), the convergence rate is increased with a factor of ğ‘›ğ‘†ğœ which is attributed to the Gaussian noise and can be considered as the "cost of privacy".</p><formula xml:id="formula_8">ğ‘ 1 = ğ¶ â€¢ |B | min ğ‘˜ |ğ· ğ‘˜ | ,</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">EXPERIMENTAL RESULTS</head><p>The goal of this section is to evaluate the performance of our proposed FL-SIGN-DP scheme on a realistic in-hospital mortality prediction scenario. We aim at evaluating its performance with different levels of privacy (i.e. different values of ğœ–) and comparing it with the performance of the following learning protocols:</p><formula xml:id="formula_9">â€¢ (Non-federated) CENTRALIZED training:</formula><p>The training data of all hospitals are merged and a single model is trained on this merged data without any privacy guarantee. â€¢ FL-STANDARD is described in Section 2.1.</p><p>â€¢ FL-SIGN is described in Section 3.1.</p><p>â€¢ FL-STANDARD-DP is specified in Alg. 5. It has the same privacy guarantee as FL-SIGN-DP<ref type="foot" target="#foot_2">2</ref> but is less bandwith efficient. Specifically, unlike in FL-SIGN-DP, each client sends the original (non-quantized) update vector</p><formula xml:id="formula_10">s ğ‘˜ ğ‘¡ = w ğ‘˜ ğ‘¡ -w ğ‘˜ ğ‘¡ -1</formula><p>to the server, which computes the model update as</p><formula xml:id="formula_11">w ğ‘¡ = w ğ‘¡ -1 + 1 |K | ğ‘˜ s ğ‘˜ ğ‘¡ .</formula><p>Both FL-SIGN-DP and FL-STANDARD-DP use downsampling (in Alg. 7) to create batches.</p><p>In order to improve the reproducibility of our results, we published all the code used in our experiments 3 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">The In-hospital Mortality Prediction Scenario</head><p>The ability to accurately predict the risks in the patient's perspectives of evolution is a crucial prerequisite in order to adapt the care that certain patients receive <ref type="bibr" target="#b17">[18]</ref>. We consider the scenario where several hospitals are collaborating to train models for in-hospital mortality prediction using our Federated Learning schemes. This well-studied real-world problem consists in trying to precisely identify the patients who are at risk of dying from complications during their hospital stay <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b35">36]</ref>. As commonly found in the literature <ref type="bibr" target="#b17">[18]</ref>, for such predictions, we focus on hospital admissions of adults hospitalized for at least 3 days, excluding elective admissions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">The Premier Healthcare Database</head><p>We used EHR data from the Premier healthcare database <ref type="foot" target="#foot_4">4</ref> which is one of the largest clinical databases in the United States, collecting information from millions of patients over a period of 12 months from 415 hospitals in the USA <ref type="bibr" target="#b17">[18]</ref>. These hospitals are supposedly representative of the United States hospital experience <ref type="bibr" target="#b17">[18]</ref>. Each hospital in the database provides discharge files that are dated records of all billable items (including therapeutic and diagnostic procedures, medication, and laboratory usage) which are all linked to a given patient's admission <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b23">24]</ref>.</p><p>The initial snapshot of the database used in our work (before pre-processing step) comprises the EHR data of 1,271,733 hospital admissions. Electronic Health Record (EHR) is a digital version of a patient's paper chart readily available in hospitals. For developing supervised learning and specifically deep learning models, we focus on a specific set of features from EHR data. The features of interest that capture the patients information are summarized in Table <ref type="table" target="#tab_4">2</ref>. There is a total of 24,428 features per patient, mainly due to the variety of drugs possibly served.</p><p>The Medication regimen complexity index (MRCI) <ref type="bibr" target="#b25">[26]</ref> is an aggregate score computed from a total of 65 items, whose purpose is to indicate the complexity of the patient's situation. The minimum MRCI score for a patient is 1.5, which represents a single tablet or capsule taken once a day as needed (single medication). However the maximum is not defined since the number of medications increases the score <ref type="bibr" target="#b25">[26]</ref>. In our case, after statistical analysis of our dataset, we consider the MRCI score as ranging from 2 to 60.</p><p>Most real datasets like ours are generally imbalanced with a skewed distribution between the classes. In our case, the positive cases (patients who die during their hospital stay) represent only 3% of all patients. Table <ref type="table" target="#tab_5">3</ref> gives more details about this distribution after the pre-processing step which is discussed in 4.3.1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Data pre-processing &amp; experimental setup</head><p>This section describes the experimental setting which is used to evaluate the accuracy and the privacy of our proposals.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.1">Preprocessing.</head><p>(1) Features normalization: we extract from the dataset the values of each feature represented in Table <ref type="table" target="#tab_4">2</ref>. For gender, we </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Drugs and ICD9 codes</head><p>Drugs given to the patient on the 1 ğ‘ ğ‘¡ day of hospitalization. The ICD9 codes <ref type="bibr" target="#b15">[16]</ref> are composed of procedures and diagnosis codes, the first gives details about the medical procedures performed on the patient and the second about the doctor's diagnosis of the patient. There is a total of 24,419 possible drugs and ICD9 codes.  <ref type="foot" target="#foot_5">5</ref> . For drugs, we extract 24,419 features which correspond to the different drugs (name and dosage). A given patient receives only a few of the possible drugs served, resulting in a very sparse patient's record. We use a MinMax normalization for age and MRCI in order to rescale the values of these features between 0 and 1 (using MinMaxScaler class of scikit-learn <ref type="foot" target="#foot_6">6</ref> ). The labels that we consider are boolean: true means that the patient died during his hospital stay while false means she survived. (2) Hospitals filtering: The dataset contains 415 hospitals, however, we choose to consider only hospitals with at least 1,000 patients, which results at the end in 314 hospitals. The reason is to have enough data per hospital for both training and testing. We split randomly the dataset of each hospital into disjoint training and testing data (80% and 20% respectively). We merge the test data of all hospitals for the evaluation, which we consider fairer than averaging the metrics over all the clients (hospitals). The final dataset for testing contains 244,627 patients, with 7,891 deceased patients and 236,736 non-deceased patients (see Table <ref type="table" target="#tab_5">3</ref>). The statistics on the size of the clients' dataset are depicted in Table <ref type="table" target="#tab_6">4</ref>. (3) Patients filtering: We consider patient and drug information of the first day at the hospital so that we can make predictions 24 hours after admission (as commonly found in the literature <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b35">36]</ref>). We filter out the pregnant and new-born patients because the medication types and admission services are not the same for theses two categories of patients. Our model prediction is built without patients' historical medical data. This has the advantage to require minimum patient's information and to work for new patients.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.2">Imbalanced data.</head><p>The dataset of each hospital is imbalanced because the proportion of patients that leave the hospital alive is, fortunately, much larger than in-hospital dead patients. To deal with this well-known problem, a standard solution is to use the Weighted loss function technique or different sampling techniques <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b30">31]</ref>.</p><p>In <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b40">41]</ref> the authors compare empirically the performance of the weighted loss technique and the sampling techniques, however, they were not able to define a clear winner as the results differ for each dataset. In our case, weighted loss<ref type="foot" target="#foot_7">7</ref> outperforms downsampling <ref type="foot" target="#foot_8">8</ref>technique with FL-STANDARD and FL-SIGN. However, weighting the loss function results in very inaccurate models with Differential Privacy. Indeed, the gradients of the underrepresented class (dead patients) are boosted and are therefore larger than the gradients of the other class. The larger the gap between the gradients of the two classes, the more difficult to choose a single clipping threshold ğ‘† to guarantee Differential Privacy. In particular, if ğ‘† is calibrated to large gradients (i.e., that of samples from the under-represented class), the added Gaussian noise, whose variance is ğ‘† 2 ğœ 2 , will also be large yielding poor model accuracy. On the other hand, if ğ‘† is calibrated to the small gradients (i.e., that of samples from the over-represented class), then samples from the under-represented class will have very small impact on the training which eventually also results in weak model accuracy (the model will be biased towards the majority class).</p><p>Instead, as it is described in Section 3.2, we use downsampling <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b30">31]</ref> which does not require re-weighting the loss and hence overcomes the above artifact caused by clipping (see Alg. 7 for more details). We used downsampling in our experiments with all differentially private learning protocols (FL-STANDARD-DP and FL-SIGN-DP) in Section 4.4 <ref type="foot" target="#foot_9">9</ref> .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.3">Model architecture.</head><p>As in <ref type="bibr" target="#b4">[5]</ref>, we use a fully connected neural network model with the following architecture: two hidden layers of 200 units, which use a ReLU activation function followed by an output layer of 1 unit with sigmoid activation function and a binary  <ref type="table">5</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.4">Computational environment.</head><p>Our experiments were performed on a server running Ubuntu 18.04 LTS equipped with a Intel(R) Xeon(R) Silver 4114 CPU @ 2.20GHz, 192GB RAM, and two NVIDIA Quadro P5000 GPU card of 16 Go each. We use Keras 2.2.0 <ref type="bibr" target="#b12">[13]</ref> with a TensorFlow backend 1.12.0 <ref type="bibr" target="#b0">[1]</ref> and NumPy 1.14.3 <ref type="bibr" target="#b33">[34]</ref> to implement our models and experiments. We use Python 3.6.5 and our code runs on a Docker container to simplify reproducibility.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.5">Performance Metrics.</head><p>We use the following metrics:</p><formula xml:id="formula_12">â€¢ Balanced accuracy [10] [7] is computed as 1/2 â€¢ ( TP P + TN N ) = TPR +TNR 2</formula><p>and is mainly used with imbalanced data. Here, TPR is the True Positive Rate and TNR is the True Negative Rate; which is calculated as: TPR = TP P and TNR = TN N , where P and N are the number of positive and negative instances, respectively, and TP and TN are the number of true positive and true negative instances. We note that traditional ("non-balanced") accuracy metrics such as TP +TN P +N can be misleading for very imbalanced data <ref type="bibr" target="#b2">[3]</ref>: in our dataset, the minority class has only 3% of all the training samples (see Table <ref type="table" target="#tab_5">3</ref>), which means that a biased (and totally useless) model always predicting the majority class would have a (non-balanced) accuracy of 97%.</p><p>â€¢ The Area under the receiver operating characteristic curve <ref type="bibr" target="#b31">[32]</ref> (AuROC ) is also a frequently used accuracy metric <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b34">35]</ref>. The ROC curve is calculated by varying the prediction threshold from 1 to 0, when TPR and FPR are calculated at each threshold. The area under this curve is then used to measure the quality of the predictions. A random guess has an AuROC value of 0.5, whereas a perfect prediction has the largest AuROC value of 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.6">Hyperparameters selection.</head><p>For each scheme, ğœ‚ was tuned from 0.01 to 0.09 with an increment value of 0.01. The batch |B| is selected from [50,100,400,800,|ğ· ğ‘˜ |], where client ğ‘˜'s data size |ğ· ğ‘˜ | differs for each client; the number of epochs ğ¸ğ‘ğ‘œğ‘â„ğ‘  is selected from <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b19">20]</ref> for each federated scheme, and from <ref type="bibr">[100,</ref><ref type="bibr">150,</ref><ref type="bibr">200,</ref><ref type="bibr">250,</ref><ref type="bibr">300,</ref><ref type="bibr">350,</ref><ref type="bibr">400]</ref> for the centralized case. For the federated schemes, we have an additional parameter which is the number of global rounds ğ‘‡ cl , which is selected from <ref type="bibr">[100,</ref><ref type="bibr">150,</ref><ref type="bibr">200,</ref><ref type="bibr">250,</ref><ref type="bibr">300,</ref><ref type="bibr">350,</ref><ref type="bibr">400]</ref>. The sensitivity ğ‘† was selected from the reasonable set of [0.5,1,1.5,2,2.5,3]. As in <ref type="bibr" target="#b20">[21]</ref>, we set ğ›¾ to 0.001 for the non-private scheme FL-SIGN, and we increase it to 0.005 for the private extension FL-SIGN-DP.</p><p>The number of hospitals used in the federated schemes are selected from <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b4">5]</ref>. We have to choose one which is large enough to not slow down the convergence and at the same time small enough in order to not deteriorate privacy by increasing the sampling probability, which is one of the principal parameter used in the moments accountant method <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b29">30]</ref> to compute ğœ–.</p><p>The values of ğœ can be 1.08, 0.81, 0.63, such that we can reach an ğœ– budget of 1, 2, 4 respectively, after ğ‘‡ cl = 300 rounds, which is needed for convergence.</p><p>We reported for each scheme in Table <ref type="table">5</ref> the best parameters and also the best technique used to handle the imbalanced data problem.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.7">Evaluation</head><p>Method. We perform ğ‘˜-fold cross validation with ğ‘˜ = 5; first, we split randomly the dataset of each hospital into disjoint training and testing data (80% and 20% respectively). An entire federated run is executed with this split, and all the metrics are evaluated in every round on the union of all clients' testing data. All metric values of the round with the best balanced metric are recorded. The whole run is repeated 4 times each with a new random split of training and testing data, and the minimum and maximum of the recorded performance metrics over all the 5 runs are reported.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Results</head><p>The results are summarized in Table <ref type="table">6</ref>. A single federated run is composed of 300 rounds, and the best and the worst value of each performance metric over the 5 federated runs are reported. In each round, 3 hospitals are selected randomly for aggregation. Three privacy levels are considered with FL-SIGN-DP and FL-STANDARD-DP:</p><formula xml:id="formula_13">ğœ€ = 1, 2, 4 each with ğ›¿ = 1/max ğ‘— |ğ· ğ‘— | â‰¤ 1.3 â€¢ 10 -5</formula><p>. These values of ğœ€ requires to add Gaussian noise to the gradients with ğœ = 1.08, 0.81, 0.63, respectively 10 .</p><p>We make several observations:</p><p>â€¢ As mentioned in <ref type="bibr" target="#b13">[14]</ref>, the performance of FL-STANDARD and CENTRALIZED are close: the balanced accuracy is 0.74 and 0.77, respectively, which confirms experimentally that Federated Learning is a viable approach for our medical application. These results are consistent with the results reported in <ref type="bibr" target="#b17">[18]</ref>, which uses the same dataset with the same features to train a logistic regression model in a centralized manner (see results of ğ· 1 , Table <ref type="table">II</ref>, in <ref type="bibr" target="#b17">[18]</ref>). For example, Au-ROC is 77.2% -77.7% in <ref type="bibr" target="#b17">[18]</ref>  <ref type="table">6</ref>: Summary of results. The worst and best value of each metric over 5 federated runs are reported.</p><p>82% -84%, 79% -81% and 76% -77% with CENTRALIZED, FL-STANDARD and FL-SIGN, respectively.</p><p>â€¢ The performance of FL-SIGN is slightly worse than the performance of FL-STANDARD; the balanced accuracy is 0.70 for FL-SIGN and 0.74 for FL-STANDARD. However, FL-SIGN and FL-SIGN-DP reduce the bandwidth consumption by a factor of 32. Table <ref type="table" target="#tab_8">7</ref> shows that each client sends only 1.76 Megabytes with FL-SIGN and FL-SIGN-DP, while 56.48 Megabytes are sent with FL-STANDARD and FL-STANDARD-DP. The bandwidth consumption is calculated by measuring the average number of bits sent by a client to the server over the rounds when the client is selected for aggregation. This is computed as (ğ¶ â€¢ ğ‘‡ cl â€¢ model_size) for FL-SIGN and FL-SIGN-DP, and (32 â€¢ ğ¶ â€¢ ğ‘‡ cl â€¢ model_size) for FL-STANDARD and FL-STANDARD-DP, where model_size is the number of model parameters (i.e., 4,926,201). â€¢ FL-SIGN-DP performs very similarly to FL-STANDARD-DP, which means that bandwidth efficiency has no real cost when Differential Privacy is also applied. In fact, the performance gap between FL-STANDARD and FL-STANDARD-DP is larger than between FL-SIGN and FL-SIGN-DP especially with stronger privacy guarantee (i.e., smaller ğœ€). This shows that taking the sign of the noisy update and then the median of the noisy signs over all clients on the server (in Line 8 of Alg.4) is more robust against perturbation than taking the simple average of the noisy update vectors (in Line 8 of Alg. 5). â€¢ The results show in general that strong privacy protection can be provided at the cost of a relatively small performance degradation. In fact, the balanced accuracy drops by only 10% when ğœ€ = 1 with FL-SIGN-DP. Furthermore, the performance degrades very smoothly as the value of ğœ€ decreases (i.e. as the privacy guarantee gets stronger): the balanced accuracy of FL-SIGN-DP is 0.66 for ğœ€ = 4, and only drops to 0.64 when ğœ€ = 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">RELATED WORK</head><p>This section describes the related work to our proposal. We start by presenting the work related to the use of machine learning in medical applications. We then summarize the work related to differentially private federated learning. Finally, we consider the </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Medical prediction</head><p>The paper <ref type="bibr" target="#b4">[5]</ref> investigates possibilities offered by the use of Deep Learning and Electronic Health Record (EHR) in order to provide and improve the quality of end-of-life care for hospitalized patients.</p><p>Having the information about the patients one year before the date of the prediction, the authors define four uneven slices windows. The information collected during the slices windows are used as features to train a model. The model is then used to predict all causes of mortality within a period 3-12 month after the date of the prediction. The authors of <ref type="bibr" target="#b35">[36]</ref> also use predictive deep learning models with EHR data (provided by two hospitals) for tasks such as predicting inhospital mortality, 30-day unplanned readmission, prolonged length of stay and all of a patient's final discharge diagnoses. The EHR data of each hospital are used separately, and two personalized models are trained. The EHR data include the data of adult patients who are hospitalized for at least 24 hours.</p><p>In <ref type="bibr" target="#b27">[28]</ref>, a binary logistic regression analysis is performed in order to predict which patients will need Palliative Care Needs (PCNs) based on six risk factors which are: cancer, metastases, age, absence of relatives, liver cirrhosis, and high level of care at admission. During the discharge, the treating physician had to report if the patient had PCNs or not.</p><p>The paper <ref type="bibr" target="#b17">[18]</ref> develops interpretable models for predicting the risk of complications during hospital stays. The predictive models are based on stacked logistic regressions specifically designed to leverage the evolution of the drugs served during hospital stays. The models can scale with very large volumes of EHR data but they do not consider privacy-related issues.</p><p>The paper <ref type="bibr" target="#b13">[14]</ref> proposes to use Federated learning with DP, more precisely, it uses objective perturbation <ref type="bibr" target="#b10">[11]</ref> <ref type="bibr" target="#b11">[12]</ref>. An empirical evaluation using two real-world health datasets is performed. However, using objective perturbation implies to deal with convex optimization problems. Hence, logistic regression, perceptron and SVM models are used for the learning tasks. The paper highlights also that the performance of FL without DP are close to the performance of the traditional learning protocol, where the data is shared and centralized in the same place for the training.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Bandwidth Optimization in Federated Learning</head><p>Different quantization methods have been proposed to save the bandwidth and reduce the communication costs in federated learning. They can be divided into two main groups: unbiased and biased methods. The unbiased approximation techniques use probabilistic quantization schemes to compress the stochastic gradient and attempt to approximate the true gradient value as much as possible <ref type="bibr" target="#b3">[4]</ref>[42][40] <ref type="bibr" target="#b21">[22]</ref>. However, biased approximations of the stochastic gradient can still guarantee convergence both in theory and practice <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b36">37]</ref>. In signSGD <ref type="bibr" target="#b7">[8]</ref>, all the clients calculate the stochastic gradient based on a single mini-batch and then send the sign vector of this gradient to the server. The server calculates the aggregated sign vector by taking the median (majority vote) and sends the signs of the aggregated signs back to each client. The main differences between our scheme (FL-SIGN) and signSGD are as follows:</p><p>â€¢ FL-SIGN aims to train a common model that is distributed to a random subset of all clients in every round. However, in signSGD, all clients start with the same initialized common model and the server sends the same aggregated model update to every client at each round. Selecting only a random subset of clients in each round has at least three benefits. First, FL-SIGN becomes more robust against temporary node failures. Second, FL-SIGN reduces the communication costs upstream to the server. Finally, sampling boosts privacy due to the uncertainty that a specific user's or client's data is used for training or not. â€¢ In FL-SIGN, each client can perform multiple SGD iterations locally using multiple mini-batches before computing the model update. In contrast, signSGD always performs one local SGD iteration with a single mini-batch at every client. â€¢ As all the clients participate at each round in signSGD, the server only transfers the sign of the aggregated signs to the clients in every round. Therefore, only a single bit is transferred per parameter downstream to the clients. In FL-SIGN, the whole model is transferred but only to a random subset of clients.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Differentially Private Federated Learning</head><p>Similarly to our FL-SIGN-DP algorithm, another approach <ref type="bibr" target="#b38">[39]</ref> also uses DPSGD <ref type="bibr" target="#b1">[2]</ref> in order to hide the record of each client's dataset, but the noise is generated in a distributed manner, that is, untrusted server is assumed. Indeed, the noise is added by each client during the training, and then the noisy update is sent to the server. The sum of these noisy updates is sufficiently noised to provide differential privacy. To protect individual updates which are not differentially private, homomorphic encryption is used to guarantee that the adversary can only access the aggregated update which is sufficiently noised. Notice that the noise can be generated distributively, because each client performs only a single minibatch to compute their model update (i.e., ğ‘‡ gd = 1). By contrast, our approach (FL-SIGN-DP) works even if ğ‘‡ gd &gt; 1 at the cost of adding larger magnitude of noise and sends only signs for aggregation.</p><p>The paper <ref type="bibr" target="#b19">[20]</ref> proposed a solution which faithfully follows the SignSGD protocol but is not based on federated learning protocol. The authors use local DP to guarantee client-level-DP. However, it is widely accepted that the large noise needed for local DP decreases accuracy significantly, as the aggregation of the DP updates increases the noise variance. The paper <ref type="bibr" target="#b20">[21]</ref> adapts the SignSGD protocol to federated learning for a client-level-DP guarantee. The proposed scheme adds noise in a distributed manner such that the final noise after the aggregation corresponds to the minimum noise needed to ensure DP. However, their proposal, that uses a discrete Gaussian mechanism and needs several bits per parameter, is less bandwidth efficient than <ref type="bibr" target="#b19">[20]</ref> that only sends one bit per parameter.</p><p>Our solution is based on <ref type="bibr" target="#b20">[21]</ref> but considers record-level guarantee instead of client-level guarantee. It therefore requires less perturbations and reduces bandwidth by sending only one bit per parameter.</p><p>Differential Private Federated Machine Learning has been studied in the context of medical applications to provide client-level privacy guarantee <ref type="bibr" target="#b34">[35]</ref> or record-level privacy guarantee <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b14">15]</ref>. Our solution improves the state of the art as it provides record-level privacy guarantee and optimizes bandwidth efficiency by sending only one bit per parameter. Furthermore, as opposed to most published papers that use public, often synthetic, datasets with limited size, we evaluated our scheme using a large cohort of real-world data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">ETHICAL CONSIDERATIONS</head><p>Our study was approved by our Institutional Review Board (IRB) process before any research activity began. The EHR dataset is stored on a server whose security was audited by Inria security teams.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">CONCLUSIONS</head><p>Real-world data are generally highly imbalanced, our solution aims to handle this well-known problem while it provides both bandwidth efficiency and differentially private guarantee. We experimentally evaluate the performance of our solution for in-hospital mortality prediction using the Premier Healthcare database, containing about one million records of patients. We consider a scenario where 314 hospitals are collaborating to train, using our Federated Learning scheme, a prediction model without exchanging any of their patients' data. Our scheme guarantees that no internal or external adversary that has access to the final model, intermediate updates or even all the messages that are exchanged during the training phase can infer any information about any of the patient data that were used by each hospital.</p><p>The accuracy performance results are very encouraging. They show in general that strong privacy protection can be provided at the cost of a relatively small performance degradation. Furthermore, our scheme reduces the bandwidth consumption by a factor of 32 compared to standard federated learning schemes, reducing it from 56.48 to 1.76 Megabytes.</p><p>We believe that this paper reports the first large-scale experimental assessment in favor of using privacy-preserving federated learning for the purpose of in-hospital mortality prediction. We demonstrate that it is possible to benefit from the power of machine learning without sacrificing the privacy of patients. Hospitals, and other medical institutions, are reluctant to collaborate because they often consider their patient medical records as their own intellectual properties. Our scheme protects these intellectual properties of participating entities on record-level.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A APPENDIX A.1 Convergence Proofs</head><p>The convergence proof of FL-SIGN can be found in <ref type="bibr" target="#b8">[9]</ref>, whereas the proof of FL-SIGN-DP is a simple adaptation of Theorem 2 from <ref type="bibr" target="#b8">[9]</ref>. Here we outline only the main deviations from the proof of that theorem.</p><p>Assumptions:</p><p>(1) Lower bound: For all ğ‘¥ and some constant ğ‘“ * , ğ‘“ (ğ‘¥) â‰¥ ğ‘“ * , where ğ‘“ denotes the loss/objective function. Proof. The primary focus of the proof is to bound the probability that a client computes the sign of a parameter update correctly. Let ğ‘€ = ğ¶ğ‘ . As in <ref type="bibr" target="#b8">[9]</ref>, let ğ‘ ğ‘– âˆˆ [0, ğ‘€] denote the number of correct sign bits received by the aggregator for parameter ğ‘–, and ğ‘ denotes the probability that a honest client computes the correct bit. Let ğœ” = ğ‘ - </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Algorithm 1 : 2 Initialize common model ğ‘¤ 0 3 for ğ‘¡ = 1 to ğ‘‡ cl do 4 Select K clients uniformly at random 5 for 7 end 8 w 9 end Output: Global model w ğ‘¡ 10 11</head><label>1234578910</label><figDesc>FL-STANDARD: Federated Learning1 Server: each client ğ‘˜ in K do 6 Î”w ğ‘˜ ğ‘¡ = Client ğ‘˜ (w ğ‘¡ -1 ) ğ‘¡ = w ğ‘¡ -1 + ğ‘˜ |ğ· ğ‘˜ | ğ‘— |ğ· ğ‘— | Î”w ğ‘˜ğ‘¡ Client ğ‘˜ (w ğ‘˜ ğ‘¡ -1 ):</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Algorithm 2 : 3 w</head><label>23</label><figDesc>Stochastic Gradient Descent Input: ğ· : training data, ğ‘‡ gd : local epochs, w : weights 1 for ğ‘¡ = 1 to ğ‘‡ gd do 2 Select batch B from ğ· randomly = w -ğœ‚ âˆ‡ğ‘“ (B; w) 4 end Output: Model w sharing only model updates instead of potentially sensitive training data. Second, in order to decrease communication costs, clients can perform multiple local SGD iterations before sending their update back to the server. Third, in each round, only a few clients are required to perform local training of the common model, which further diminishes communication costs and makes the approach especially appealing with a large number of clients.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Definition 2 . 3 (</head><label>23</label><figDesc>Global ğ¿ ğ‘ -sensitivity). For any function ğ‘“ : D â†’ R ğ‘› , the ğ¿ ğ‘ -sensitivity of ğ‘“ is Î” ğ‘ ğ‘“ = max ğ·,ğ· â€² ||ğ‘“ (ğ·) -ğ‘“ (ğ· â€² )|| ğ‘ , for all ğ·, ğ· â€² differing in at most one record, where || â€¢ || ğ‘ denotes the ğ¿ ğ‘ -norm.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Algorithm 4 : 2 Initialize common model ğ‘¤ 0 3 for 4 Select K clients randomly 5 for 7 end 8 w 9 end 10</head><label>4234578910</label><figDesc>FL-SIGN-DP: Bandwidth-Efficient Federated Learning with Differential Privacy 1 Server: ğ‘¡ = 1 to ğ‘‡ cl do each client ğ‘˜ in K do 6 s ğ‘˜ ğ‘¡ = Client ğ‘˜ (w ğ‘¡ -1 ) ğ‘¡ = w ğ‘¡ -1 + ğ›¾ sign ğ‘˜ s ğ‘˜ ğ‘¡ Client ğ‘˜ (w ğ‘˜ ğ‘¡ -1 ):</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Algorithm 5 : 4 Select K clients randomly 5 for 7 end 8 w</head><label>54578</label><figDesc>FL-STANDARD-DP: Federated Learning with Differential Privacy 1 Server: 2 Initialize common model ğ‘¤ 0 3 for ğ‘¡ = 1 to ğ‘‡ cl do each client ğ‘˜ in K do 6 s ğ‘˜ ğ‘¡ = Client ğ‘˜ (w ğ‘¡ -1 ) ğ‘¡ = w ğ‘¡ -1 +</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Table 5 :</head><label>5</label><figDesc>Parameter settings. ğ‘‡ cl is the number of federated runs, ğ‘‡ gd is the number of gradient descent iterations per federated run. ğ‘‡ gd = ğ¸ğ‘ğ‘œğ‘â„ğ‘  â€¢ |ğ· ğ‘˜ | |B| for client ğ‘˜ in federated learning, where ğ¸ğ‘ğ‘œğ‘â„ğ‘  is fixed for all clients. Algorithms Parameters FL-SIGN-DP ğ‘ = 314; ğ¶ = 3/314; |B| = 300; ğ·ğ‘ƒğ‘†ğºğ· (ğœ‚ = 0.05); ğ‘† = 2; ğ‘‡ cl = 300; ğ‘‡ gd = 1; ğ›¾ = 0.005; with downsampling FL-STANDARD-DP ğ‘ = 314; ğ¶ = 3/314; |B| = 300; ğ·ğ‘ƒğ‘†ğºğ· (ğœ‚ = 0.05); ğ‘† = 2; ğ‘‡ cl = 300; ğ‘‡ gd = 1; with downsampling FL-STANDARD ğ‘ = 314; ğ¶ = 3/314; |B| = 100; ğ‘†ğºğ· (ğœ‚ = 0.01); ğ¸ğ‘ğ‘œğ‘â„ğ‘  = 5; ğ‘‡ cl = 300; with weighted loss function FL-SIGN ğ‘ = 314; ğ¶ = 3/314; |B| = |ğ· ğ‘˜ |; ğ‘†ğºğ· (ğœ‚ = 0.01); ğ¸ğ‘ğ‘œğ‘â„ğ‘  = 5; ğ‘‡ cl = 300; ğ‘‡ gd = 5; ğ›¾ = 0.001; with weighted loss function CENRALIZED |ğ· | = 977927; |B| = 100; ğ‘†ğºğ· (ğœ‚ = 0.01); ğ¸ğ‘ğ‘œğ‘â„ğ‘  = 300; with weighted loss function cross entropy loss function. This results in 4,926,201 parameters in total. The hyperparameters used by each of the considered schemes are summarized in Table</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>( 2 ) 2 ğ‘– 2 ( 3 )</head><label>2223</label><figDesc>Smoothness: Let ğ‘”(ğ‘¥) denote the gradient of the objective function ğ‘“ evaluated at ğ‘¥. Then, for all ğ‘¥, ğ‘¦ and some non-negative constant L = (ğ¿ 1 , ğ¿ 2 , . . . , ğ¿ ğ‘› ), |ğ‘“ (ğ‘¦) -[ğ‘“ (ğ‘¥) + ğ‘”(ğ‘¥) T (ğ‘¦ -ğ‘¥)] | â‰¤ 1/ğ¿ ğ‘– (ğ‘¦ ğ‘– -ğ‘¥ ğ‘– ) Variance bound: Upon receiving query ğ‘¥ âˆˆ R ğ‘› , the stochastic gradient oracle gives us an independent, unbiased estimate Ä that has bounded variance per coordinate:E[ Ä(ğ‘¥)] = ğ‘”(ğ‘¥), E[( Ä(ğ‘¥) ğ‘– -ğ‘”(ğ‘¥) ğ‘– ) 2 ] â‰¤ ğœ 2ğ‘– for a vector of non-negative constants ğ‰ = (ğœ 1 , ğœ 2 , . . . , ğœ ğ‘› ). (4) Unimodal, symmetric gradient noise: At any given point ğ‘¥, each component of the stochastic gradient vector Ä(ğ‘¥) has unimodal distribution that is also symmetric about the mean. Note that adding extra Gaussian noise to each gradient component for the purpose of differential privacy will not violate Assumption 4. Theorem A.1. If |B| = ğ‘‡ cl , ğ‘‡ gd = 1, and ğ›¾ = ğ‘“ 0 -ğ‘“ * | |L| | 1 ğ‘‡ cl | 1 (ğ‘“ 0 -ğ‘“ * )</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>1 2 .</head><label>2</label><figDesc>According to Theorem 2 in<ref type="bibr" target="#b8">[9]</ref>,P [ğ‘ ğ‘– â‰¤ ğ‘€/2] â‰¤ E[( gğ‘– -ğ‘” ğ‘– ) 2 ]âˆš ğ‘€ |ğ‘” ğ‘– | where g is the noisy stochastic gradient. Observe that g has two sources of randomness; (1) the stochasticity of the sampling mechanism which is modelled by the stochastic gradient oracle (see Assumption 3), and (2) the Gaussian noise that is introduced in order to guarantee DP. Importantly, these are independent sources of randomness. Therefore, the probability that a vote fails for the ğ‘– ğ‘¡â„ parameter is bounded asP [ğ‘ ğ‘– â‰¤ ğ‘€/2] â‰¤ E[( gğ‘– -ğ‘” ğ‘– ) 2 ] âˆš ğ‘€ |ğ‘” ğ‘– | â‰¤ ğœ 2 ğ‘– + ğ‘† 2 ğœ 2 âˆš ğ‘€ |ğ‘” ğ‘– | (by independence) â‰¤ ğœ ğ‘– + ğ‘†ğœ âˆš ğ‘€ |ğ‘” ğ‘– |where the second inequality follows from Assumption 3 and the fact that the variance of the Gaussian noise is ğ‘† 2 ğœ. The rest of the derivation is identical to the proof of Theorem 2 in<ref type="bibr" target="#b8">[9]</ref>. â–¡</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Algorithm 3: FL-SIGN: Sign Federated Learning 1 Server: 2 Initialize common model ğ‘¤ 0 3 for ğ‘¡ = 1 to ğ‘‡ cl do 4 Select K clients uniformly at random</head><label></label><figDesc></figDesc><table><row><cell>5</cell><cell>for each client ğ‘˜ in K do</cell></row><row><cell>6</cell><cell>s ğ‘˜ ğ‘¡ = Client ğ‘˜ (w ğ‘¡ -1 )</cell></row><row><cell>7</cell><cell>end</cell></row><row><cell>8</cell><cell>w ğ‘¡ = w ğ‘¡ -1 + ğ›¾ sign ğ‘˜ s ğ‘˜ ğ‘¡</cell></row><row><cell>9</cell><cell>end</cell></row><row><cell></cell><cell>Output: Global model w ğ‘¡</cell></row><row><cell>10</cell><cell></cell></row><row><cell cols="2">11 Client ğ‘˜ (w ğ‘– ğ‘¡ -1 ):</cell></row><row><cell>12</cell><cell>w ğ‘˜ ğ‘¡ = SGD(ğ· ğ‘˜ , w ğ‘˜ ğ‘¡ -1 ,ğ‘‡ gd )</cell></row><row><cell></cell><cell>Output: Model update sign(w ğ‘˜ ğ‘¡ -w ğ‘˜ ğ‘¡ -1 )</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>Partition B into C 1 and C 2 , where all samples in C 1 has label ğ¿ 1 and all samples in C 2 has label ğ¿ 2 2 ğ‘  min</figDesc><table /><note><p>ğœğ‘†I) 8 end Output: Model parameters w Algorithm 7: Downsampling(B) Input: Batch B with labels ğ¿ 1 and ğ¿ 2 1</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>while the sampling probability for every subsequent SGD iteration within the same round is at most ğ‘ 2 = |B| min ğ‘˜ |ğ· ğ‘˜ | conditioned on the result of the first iteration (see the proof of Theorem 2 in<ref type="bibr" target="#b1">[2]</ref>).Given a fixed value of ğ›¿, ğœ€ is computed numerically as in<ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b29">30]</ref>.</figDesc><table /><note><p>3.2.4 Convergence analysis. In Appendix A.1, we analytically pute that FL-SIGN-DP has a convergence rate of ğ‘‚ ğ‘›ğ‘†ğœ âˆš ğ‘‡ cl ğ¶ğ‘</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 2 :</head><label>2</label><figDesc>Descriptions of featuresFeatures DescriptionsAge Value in the range of 15 and 89 Gender Male, Female or Unknown Admission type Emergency, Urgent, Trauma Center: visits to a trauma center/hospital or Unknown MRCI Medication regimen complexity index score (ranging from 2 to 60)</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 3 :</head><label>3</label><figDesc>Number of instances for our case study.</figDesc><table><row><cell cols="4">Data Positive cases Negative cases Ratio</cell><cell>Total</cell></row><row><cell>Train</cell><cell>30,775</cell><cell>947,152</cell><cell cols="2">3.15% 977,927</cell></row><row><cell>Test</cell><cell>7,891</cell><cell>236,736</cell><cell cols="2">3.23% 244,627</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 4 :</head><label>4</label><figDesc>Statistics on the size of the training and testing data over all the clients</figDesc><table><row><cell cols="2">Data Min Max</cell><cell>Mean</cell><cell>Std</cell></row><row><cell cols="4">Train 804 12,447 3,114.42 1,913.39</cell></row><row><cell>Test</cell><cell>201 3,112</cell><cell>779.07</cell><cell>478.39</cell></row></table><note><p>use one-hot encoding: Male, Female and Unknown. Similarly, for admission type we use 4 features: Emergency, Urgent, Trauma Center, and Unknown</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head></head><label></label><figDesc>, whereas we get an AuROC of</figDesc><table><row><cell>Privacy</cell><cell>Algorithms</cell><cell>AuROC</cell><cell cols="2">Performance Balanced Accuracy</cell></row><row><cell>ğœ€ = 1</cell><cell cols="3">FL-SIGN-DP FL-STANDARD-DP (0.65,0.68) (0.67,0.68)</cell><cell>(0.63,0.64) (0.61,0.63)</cell></row><row><cell>ğœ€ = 2</cell><cell cols="3">FL-SIGN-DP FL-STANDARD-DP (0.68,0.69) (0.68,0.71)</cell><cell>(0.64,0.66) (0.62,0.64)</cell></row><row><cell>ğœ€ = 4</cell><cell cols="3">FL-SIGN-DP FL-STANDARD-DP (0.70,0.72) (0.71,0.72)</cell><cell>(0.65,0.66) (0.64,0.66)</cell></row><row><cell></cell><cell>FL-SIGN</cell><cell cols="2">(0.76,0.77)</cell><cell>(0.68,0.70)</cell></row><row><cell>N/A</cell><cell>FL-STANDARD</cell><cell cols="2">(0.79,0.81)</cell><cell>(0.73,0.74)</cell></row><row><cell></cell><cell>CENTRALIZED</cell><cell cols="2">(0.82,0.84)</cell><cell>(0.76,0.77)</cell></row><row><cell>Table</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 7 :</head><label>7</label><figDesc>Average bandwidth consumption from a client to the server.</figDesc><table><row><cell>Scheme</cell><cell>Bandwidth consumption (Megabytes)</cell></row><row><cell>FL-SIGN and</cell><cell></cell></row><row><cell></cell><cell>1.76</cell></row><row><cell>FL-SIGN-DP</cell><cell></cell></row><row><cell>FL-STANDARD and</cell><cell></cell></row><row><cell></cell><cell>56.48</cell></row><row><cell>FL-STANDARD-DP</cell><cell></cell></row><row><cell cols="2">work related to the problem of bandwidth reduction in Federated</cell></row><row><cell>Learning.</cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>Privacy-Preserving and Bandwidth-Efficient Federated Learning: An Application to In-Hospital Mortality Prediction</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_1"><p>A model was trained for gender classification on the LFW dataset. The adversary's goal is to infer from the model updates whether a specific group of individuals in a client's dataset are black.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_2"><p>the privacy analysis in Section</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_3"><p>3.2.3 also applies to FL-STANDARD-DP 3 https://github.com/raouf-kerkouche/Privacy-preserving-and-Bandwith-Efficient-Federated-Learning-An-Application-to-In-Hospital-Mortality</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_4"><p>https://www.premierinc.com/newsroom/education/premier-healthcare-databasewhitepaper</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_5"><p>https://www.resdac.org/cms-data/variables/claim-inpatient-admission-type-codeffs</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_6"><p><ref type="bibr" target="#b5">6</ref> https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_7"><p>https://scikit-learn.org/stable/modules/generated/sklearn.utils .class_weight.compute_class_weight.html</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8" xml:id="foot_8"><p>oversampling is not considered because of the privacy constraint.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="9" xml:id="foot_9"><p>We report only the results of the best sampling technique for each scheme (see Table5for details).</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head n="8">ACKNOWLEDGMENTS</head><p>This article was developed in the framework of the Grenoble Alpes Data Institute, supported by the <rs type="funder">French National Research Agency</rs> under the "<rs type="programName">Investissements d'avenir" program</rs> (<rs type="grantNumber">ANR-15-IDEX-02</rs>). The research was supported by the <rs type="funder">NRDI</rs> fund of the <rs type="funder">Ministry of Innovation and Technology NRDI Office</rs>, and also within the framework of the <rs type="projectName">Artificial Intelligence National Laboratory Program</rs>. This project has received support from the <rs type="funder">EU/EFPIA Innovative Medicines Initiative 2 Joint Undertaking</rs> (<rs type="grantName">MELLODDY grant</rs> ğ‘› â€¢ <rs type="grantNumber">831472</rs>). This project has received support from the <rs type="funder">ANR</rs> project <rs type="grantNumber">ANR-16-CE25-0010</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_yuhRKEg">
					<idno type="grant-number">ANR-15-IDEX-02</idno>
					<orgName type="program" subtype="full">Investissements d&apos;avenir&quot; program</orgName>
				</org>
				<org type="funded-project" xml:id="_hk4t8C4">
					<orgName type="project" subtype="full">Artificial Intelligence National Laboratory Program</orgName>
				</org>
				<org type="funding" xml:id="_XgbGCz4">
					<idno type="grant-number">831472</idno>
					<orgName type="grant-name">MELLODDY grant</orgName>
				</org>
				<org type="funding" xml:id="_EmEum2E">
					<idno type="grant-number">ANR-16-CE25-0010</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">TensorFlow: Large-Scale Machine Learning on Heterogeneous Systems</title>
		<author>
			<persName><forename type="first">MartÃ­n</forename><surname>Abadi</surname></persName>
		</author>
		<ptr target="http://tensorflow.org/Softwareavailablefromtensorflow.org" />
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Deep Learning with Differential Privacy</title>
		<author>
			<persName><forename type="first">Martin</forename><surname>Abadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andy</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ian</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">Brendan</forename><surname>Mcmahan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Mironov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kunal</forename><surname>Talwar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Li</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM CCS</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Predictive accuracy: a misleading performance measure for highly imbalanced data</title>
		<author>
			<persName><forename type="first">Josephine</forename><surname>Akosa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the SAS Global Forum</title>
		<meeting>the SAS Global Forum</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="2" to="5" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">QSGD: Randomized Quantization for Communication-Optimal Stochastic Gradient Descent</title>
		<author>
			<persName><forename type="first">Dan</forename><surname>Alistarh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jerry</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ryota</forename><surname>Tomioka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Milan</forename><surname>Vojnovic</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1610.02132</idno>
		<ptr target="http://arxiv.org/abs/1610.02132" />
		<imprint>
			<date type="published" when="2016">2016. 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Improving palliative care with deep learning</title>
		<author>
			<persName><forename type="first">Anand</forename><surname>Avati</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kenneth</forename><surname>Jung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephanie</forename><surname>Harman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lance</forename><surname>Downing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Nigam</surname></persName>
		</author>
		<author>
			<persName><surname>Shah</surname></persName>
		</author>
		<idno type="DOI">10.1186/s12911-018-0677-8</idno>
		<ptr target="https://doi.org/10.1186/s12911-018-0677-8" />
	</analytic>
	<monogr>
		<title level="j">BMC Medical Informatics and Decision Making</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">122</biblScope>
			<date type="published" when="2018-12-12">2018. 12 Dec 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Privacy-Preserving Distributed Deep Learning for Clinical Data</title>
		<author>
			<persName><forename type="first">K</forename><surname>Brett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><surname>Beaulieu-Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Samuel</forename><forename type="middle">G</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhiwei</forename><forename type="middle">Steven</forename><surname>Finlayson</surname></persName>
		</author>
		<author>
			<persName><surname>Wu</surname></persName>
		</author>
		<idno>arXiv:cs.LG/1812.01484</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Evaluation measures for models assessment over imbalanced data sets</title>
		<author>
			<persName><forename type="first">Mohamed</forename><surname>Bekkar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hassiba</forename><surname>Djema</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">A</forename><surname>Alitouche</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Information Engineering and Applications</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">01</biblScope>
			<biblScope unit="page" from="27" to="38" />
			<date type="published" when="2013">2013. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">signSGD: compressed optimisation for non-convex problems</title>
		<author>
			<persName><forename type="first">Jeremy</forename><surname>Bernstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yu-Xiang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kamyar</forename><surname>Azizzadenesheli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anima</forename><surname>Anandkumar</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1802.04434</idno>
		<ptr target="http://arxiv.org/abs/1802.04434" />
		<imprint>
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">signSGD with Majority Vote is Communication Efficient And Byzantine Fault Tolerant</title>
		<author>
			<persName><forename type="first">Jeremy</forename><surname>Bernstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiawei</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kamyar</forename><surname>Azizzadenesheli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anima</forename><surname>Anandkumar</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.05291</idno>
		<ptr target="http://arxiv.org/abs/1810.05291" />
		<imprint>
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">The balanced accuracy and its posterior distribution</title>
		<author>
			<persName><forename type="first">Kay</forename><surname>Henning Brodersen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Soon</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Klaas</forename><surname>Ong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joachim</forename><forename type="middle">M</forename><surname>Enno Stephan</surname></persName>
		</author>
		<author>
			<persName><surname>Buhmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2010 20th International Conference on Pattern Recognition</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="3121" to="3124" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Privacy-preserving logistic regression</title>
		<author>
			<persName><forename type="first">Kamalika</forename><surname>Chaudhuri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Claire</forename><surname>Monteleoni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in neural information processing systems</title>
		<imprint>
			<biblScope unit="page" from="289" to="296" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Differentially private empirical risk minimization</title>
		<author>
			<persName><forename type="first">Kamalika</forename><surname>Chaudhuri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Claire</forename><surname>Monteleoni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anand</forename><forename type="middle">D</forename><surname>Sarwate</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="1069" to="1109" />
			<date type="published" when="2011-03">2011. Mar (2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<author>
			<persName><forename type="first">FranÃ§ois</forename><surname>Chollet</surname></persName>
		</author>
		<ptr target="https://keras.io" />
		<title level="m">Keras</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Differential Privacy-enabled Federated Learning for Sensitive Health Data</title>
		<author>
			<persName><forename type="first">Olivia</forename><surname>Choudhury</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aris</forename><surname>Gkoulalas-Divanis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Theodoros</forename><surname>Salonidis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Issa</forename><surname>Sylla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoonyoung</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Grace</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amar</forename><surname>Das</surname></persName>
		</author>
		<idno>arXiv:cs.LG/1910.02578</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Differential Privacy-enabled Federated Learning for Sensitive Health Data</title>
		<author>
			<persName><forename type="first">Olivia</forename><surname>Choudhury</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aris</forename><surname>Gkoulalas-Divanis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Theodoros</forename><surname>Salonidis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Issa</forename><surname>Sylla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoonyoung</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Grace</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amar</forename><surname>Das</surname></persName>
		</author>
		<idno>arXiv:cs.LG/1910.02578</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<author>
			<persName><forename type="first">Terron</forename><surname>Marta</surname></persName>
		</author>
		<author>
			<persName><surname>Cuadrado</surname></persName>
		</author>
		<ptr target="https://ec.europa.eu/cefdigital/wiki/display/EHSEMANTIC/ICD-9-CM%3A+International+Classification+of+Diseases%2C+Ninth+Revision%2C+Clinical+Modification" />
		<title level="m">ICD-9-CM: International Classification of Diseases, Ninth Revision, Clinical Modification</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">The Algorithmic Foundations of Differential Privacy</title>
		<author>
			<persName><forename type="first">Cynthia</forename><surname>Dwork</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aaron</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Foundations and Trends in Theoretical Computer Science</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="3" to="4" />
			<date type="published" when="2014">2014. 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Scalable and Interpretable Predictive Models for Electronic Health Records</title>
		<author>
			<persName><forename type="first">A</forename><surname>Fejza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>GenevÃ¨s</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>LayaÃ¯da</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bosson</surname></persName>
		</author>
		<idno type="DOI">10.1109/DSAA.2018.00045</idno>
		<ptr target="https://doi.org/10.1109/DSAA.2018.00045" />
	</analytic>
	<monogr>
		<title level="m">IEEE 5th International Conference on Data Science and Advanced Analytics (DSAA)</title>
		<imprint>
			<date type="published" when="2018">2018. 2018</date>
			<biblScope unit="page" from="341" to="350" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Learning from imbalanced data</title>
		<author>
			<persName><forename type="first">Haibo</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Edwardo</forename><forename type="middle">A</forename><surname>Garcia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on knowledge and data engineering</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1263" to="1284" />
			<date type="published" when="2009">2009. 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Stochastic-Sign SGD for Federated Learning with Theoretical Guarantees</title>
		<author>
			<persName><forename type="first">Richeng</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yufan</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaofan</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tianfu</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Huaiyu</forename><surname>Dai</surname></persName>
		</author>
		<idno>arXiv:cs.LG/2002.10940</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Federated Learning in Adversarial Settings</title>
		<author>
			<persName><forename type="first">Raouf</forename><surname>Kerkouche</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gergely</forename><surname>Ãcs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Claude</forename><surname>Castelluccia</surname></persName>
		</author>
		<idno>arXiv:cs.CR/2010.07808</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Federated Learning: Strategies for Improving Communication Efficiency</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">Brendan</forename><surname>Jakub KonecnÃ½</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Felix</forename><forename type="middle">X</forename><surname>Mcmahan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ananda</forename><surname>RichtÃ¡rik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dave</forename><surname>Theertha Suresh</surname></persName>
		</author>
		<author>
			<persName><surname>Bacon</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1610.05492</idno>
		<ptr target="http://arxiv.org/abs/1610.05492" />
		<imprint>
			<date type="published" when="2016">2016. 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Deep Gradient Compression: Reducing the Communication Bandwidth for Distributed Training</title>
		<author>
			<persName><forename type="first">Yujun</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Song</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Huizi</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bill</forename><surname>Dally</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=SkhQHMW0W" />
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<meeting><address><addrLine>ICLR</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Transforming the Premier PerspectiveÂ® Hospital Database into the Observational Medical Outcomes Partnership (OMOP) Common Data Model</title>
		<author>
			<persName><forename type="first">Rupa</forename><surname>Makadia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Patrick</forename><forename type="middle">B</forename><surname>Ryan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014">2014</date>
			<publisher>EGEMS</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Does cost-sensitive learning beat sampling for classifying rare classes?</title>
		<author>
			<persName><forename type="first">Kate</forename><surname>Mccarthy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bibi</forename><surname>Zabar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gary</forename><surname>Weiss</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1st international workshop on Utility-based data mining</title>
		<meeting>the 1st international workshop on Utility-based data mining</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="69" to="77" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Automating the medication regimen complexity index</title>
		<author>
			<persName><forename type="first">Margaret</forename><surname>Mcdonald</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Timothy</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sridevi</forename><surname>Sridharan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Janice</forename><surname>Foust</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Polina</forename><surname>Kogan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liliana</forename><surname>Pezzin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Penny</forename><surname>Feldman</surname></persName>
		</author>
		<idno type="DOI">10.1136/amiajnl-2012-001272</idno>
		<ptr target="https://doi.org/10.1136/amiajnl-2012-001272" />
	</analytic>
	<monogr>
		<title level="j">Journal of the American Medical Informatics Association : JAMIA</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">12</biblScope>
			<date type="published" when="2012">2012. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Communication-Efficient Learning of Deep Networks from Decentralized Data</title>
		<author>
			<persName><forename type="first">H</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Brendan</forename><surname>Mcmahan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eider</forename><surname>Moore</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Ramage</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Seth</forename><surname>Hampson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Blaise</forename><surname>AgÃ¼era Y Arcas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AISTATS</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Identification of hospital patients in need of palliative care -a predictive score</title>
		<author>
			<persName><forename type="first">Cornelia</forename><surname>Meffert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gerta</forename><surname>RÃ¼cker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Isaak</forename><surname>Hatami</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gerhild</forename><surname>Becker</surname></persName>
		</author>
		<idno type="DOI">10.1186/s12904-016-0094-7</idno>
		<ptr target="https://doi.org/10.1186/s12904-016-0094-7" />
	</analytic>
	<monogr>
		<title level="j">BMC Palliative Care</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">12</biblScope>
			<date type="published" when="2016">2016. 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Inference Attacks Against Collaborative Learning</title>
		<author>
			<persName><forename type="first">Luca</forename><surname>Melis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Congzheng</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Emiliano</forename><surname>De Cristofaro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vitaly</forename><surname>Shmatikov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1805.04049</idno>
		<ptr target="http://arxiv.org/abs/1805.04049" />
		<imprint>
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">RÃ©nyi Differential Privacy of the Sampled Gaussian Mechanism</title>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Mironov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kunal</forename><surname>Talwar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Li</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1908.10530</idno>
		<ptr target="http://arxiv.org/abs/1908.10530" />
		<imprint>
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<author>
			<persName><forename type="first">Ajinkya</forename><surname>More</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1608.06048</idno>
		<title level="m">Survey of resampling techniques for improving classification performance in unbalanced datasets</title>
		<imprint>
			<date type="published" when="2016">2016. 2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<author>
			<persName><forename type="first">Sarang</forename><surname>Narkhede</surname></persName>
		</author>
		<ptr target="https://towardsdatascience.com/understanding-auc-roc-curve-68b2303cc9c5" />
		<title level="m">Understanding AUC -ROC Curve</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Comprehensive Privacy Analysis of Deep Learning: Passive and Active White-box Inference Attacks against Centralized and Federated Learning</title>
		<author>
			<persName><forename type="first">Milad</forename><surname>Nasr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Reza</forename><surname>Shokri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amir</forename><surname>Houmansadr</surname></persName>
		</author>
		<idno type="DOI">10.1109/SP.2019.00065</idno>
		<ptr target="https://doi.org/10.1109/SP.2019.00065" />
	</analytic>
	<monogr>
		<title level="m">IEEE Symposium on Security and Privacy</title>
		<imprint>
			<date type="published" when="2019">2019. 2019</date>
			<biblScope unit="page" from="739" to="753" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<author>
			<persName><forename type="first">Travis</forename><forename type="middle">E</forename><surname>Oliphant</surname></persName>
		</author>
		<title level="m">A guide to NumPy</title>
		<imprint>
			<publisher>Trelgol Publishing USA</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Federated and Differentially Private Learning for Electronic Health Records</title>
		<author>
			<persName><forename type="first">Stephen</forename><forename type="middle">R</forename><surname>Pfohl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><forename type="middle">M</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Katherine</forename><surname>Heller</surname></persName>
		</author>
		<idno>arXiv:cs.LG/1911.05861</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Scalable and accurate deep learning with electronic health records</title>
		<author>
			<persName><forename type="first">Alvin</forename><surname>Rajkomar</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41746-018-0029-1</idno>
		<idno type="arXiv">arXiv:1801.07860</idno>
		<ptr target="https://doi.org/10.1038/s41746-018-0029-1url" />
	</analytic>
	<monogr>
		<title level="j">npj Digital Medicine</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">18</biblScope>
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">1-bit stochastic gradient descent and its application to data-parallel distributed training of speech DNNs</title>
		<author>
			<persName><forename type="first">Frank</forename><surname>Seide</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hao</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jasha</forename><surname>Droppo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dong</forename><surname>Yu</surname></persName>
		</author>
		<idno>1058-1062</idno>
		<ptr target="http://www.isca-speech.org/archive/interspeech_2014/i14_1058.html" />
	</analytic>
	<monogr>
		<title level="m">INTERSPEECH 2014</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Privacy-Preserving Deep Learning</title>
		<author>
			<persName><forename type="first">Reza</forename><surname>Shokri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vitaly</forename><surname>Shmatikov</surname></persName>
		</author>
		<idno type="DOI">10.1145/2810103.2813687</idno>
		<ptr target="https://doi.org/10.1145/2810103.2813687" />
	</analytic>
	<monogr>
		<title level="m">ACM SIGSAC Conference on Computer and Communications Security</title>
		<imprint>
			<date type="published" when="2015">2015. 2015</date>
			<biblScope unit="page" from="1310" to="1321" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">A Hybrid Approach to Privacy-Preserving Federated Learning</title>
		<author>
			<persName><forename type="first">Stacey</forename><surname>Truex</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1812.03224</idno>
		<ptr target="http://arxiv.org/abs/1812.03224" />
		<imprint>
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">ATOMO: Communication-efficient Learning via Atomic Sparsification</title>
		<author>
			<persName><forename type="first">Hongyi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Scott</forename><surname>Sievert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shengchao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zachary</forename><forename type="middle">B</forename><surname>Charles</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dimitris</forename><forename type="middle">S</forename><surname>Papailiopoulos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephen</forename><surname>Wright</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Cost-sensitive learning vs. sampling: Which is best for handling unbalanced classes with unequal error costs?</title>
		<author>
			<persName><forename type="first">Kate</forename><surname>Gary M Weiss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bibi</forename><surname>Mccarthy</surname></persName>
		</author>
		<author>
			<persName><surname>Zabar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Dmin</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">24</biblScope>
			<date type="published" when="2007">2007. 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">TernGrad: Ternary Gradients to Reduce Communication in Distributed Deep Learning</title>
		<author>
			<persName><forename type="first">Wei</forename><surname>Wen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1705.07878</idno>
		<ptr target="http://arxiv.org/abs/1705.07878" />
		<imprint>
			<date type="published" when="2017">2017. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">iDLG: Improved Deep Leakage from Gradients</title>
		<author>
			<persName><forename type="first">Bo</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Konda</forename><surname>Reddy Mopuri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hakan</forename><surname>Bilen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2001.02610</idno>
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Deep Leakage from Gradients</title>
		<author>
			<persName><forename type="first">Ligeng</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhijian</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Song</forename><surname>Han</surname></persName>
		</author>
		<ptr target="http://papers.nips.cc/paper/9617-deep-leakage-from-gradients" />
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 32: Annual Conference on Neural Information Processing Systems 2019</title>
		<editor>
			<persName><forename type="first">M</forename><surname>Hanna</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Hugo</forename><surname>Wallach</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Alina</forename><surname>Larochelle</surname></persName>
		</editor>
		<editor>
			<persName><surname>Beygelzimer</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Emily</forename><forename type="middle">B</forename><surname>Florence D'alchÃ©-Buc</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Roman</forename><surname>Fox</surname></persName>
		</editor>
		<editor>
			<persName><surname>Garnett</surname></persName>
		</editor>
		<meeting><address><addrLine>NeurIPS; Vancouver, BC, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019-08-14">2019. 2019. 8-14 December 2019</date>
			<biblScope unit="page" from="14747" to="14756" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
