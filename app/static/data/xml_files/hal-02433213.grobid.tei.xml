<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Separation of Alpha-Stable Random Vectors $</title>
				<funder ref="#_wNNxACw">
					<orgName type="full">Agence Nationale de la Recherche</orgName>
					<orgName type="abbreviated">ANR</orgName>
				</funder>
				<funder>
					<orgName type="full">French State agency</orgName>
				</funder>
				<funder ref="#_BkBYtCF">
					<orgName type="full">unknown</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Mathieu</forename><surname>Fontaine</surname></persName>
							<email>fontaine.mathieu2@gmail.com</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Université de Lorraine</orgName>
								<orgName type="institution" key="instit2">CNRS</orgName>
								<orgName type="institution" key="instit3">Inria</orgName>
								<orgName type="institution" key="instit4">LORIA</orgName>
								<address>
									<postCode>F-54000</postCode>
									<settlement>Nancy</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Roland</forename><surname>Badeau</surname></persName>
							<email>roland.badeau@telecom-paris.fr</email>
							<affiliation key="aff1">
								<orgName type="laboratory">LTCI</orgName>
								<orgName type="institution" key="instit1">Télécom Paris</orgName>
								<orgName type="institution" key="instit2">Institut Polytechnique de Paris</orgName>
								<address>
									<settlement>Paris</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Antoine</forename><surname>Liutkus</surname></persName>
							<email>antoine.liutkus@inria.fr</email>
							<affiliation key="aff2">
								<orgName type="laboratory" key="lab1">Inria</orgName>
								<orgName type="laboratory" key="lab2">LIRMM</orgName>
								<orgName type="institution">University of Montpellier</orgName>
								<address>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Separation of Alpha-Stable Random Vectors $</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">7E21434C06FF121E6B7255020ED11586</idno>
					<note type="submission">Preprint submitted to Signal Processing November 19, 2019</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-04-12T14:53+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>alpha-stable distribution</term>
					<term>separation theory</term>
					<term>additive models</term>
					<term>measure theory</term>
					<term>optimization</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Source separation aims at decomposing a vector into additive components. This is often done by first estimating source parameters before feeding them into a filtering method, often based on ratios of covariances. The whole pipeline is traditionally rooted in some probabilistic framework providing both the likelihood for parameter estimation and the separation method. While Gaussians are ubiquitous for this purpose, many studies showed the benefit of heavy-tailed models for estimation. However, there is no counterpart filtering method to date exploiting such formalism, so that related studies revert to covariance-based filtering after estimation is finished.</p><p>Here, we introduce a new multivariate separation technique, that fully exploits the flexibility of α-stable heavy-tailed distributions. We show how a spatial representation can be exploited, which decomposes the observation as an infinite sum of contributions originating from all directions. Two methods for separation are derived. The first one is non-linear and similar to a beamforming technique, while the second one is linear, but minimizes a covariation criterion, which is the counterpart of the covariance for α-stable vectors. We evaluate the proposed techniques in a large number of challenging and adverse situations on synthetic experiments, demonstrating their performance for the extraction of signals from strong interferences.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Source separation is the task that consists in decomposing a signal into additive components. It is a very active research area in signal processing, notably because of its numerous applications. In audio for instance, it is the natural paradigm for denoising <ref type="bibr">(Godsill and Rayner [17]</ref>, Godsill et al. <ref type="bibr" target="#b15">[16]</ref>, Fontaine et al. <ref type="bibr" target="#b13">[14]</ref>) or for the demixing of music and speech recordings (Rafii et al. <ref type="bibr" target="#b32">[33]</ref>, Vincent et al. <ref type="bibr" target="#b38">[39]</ref>). It also finds applications in image processing and biological signal processing (Damon et al. <ref type="bibr" target="#b9">[10]</ref>, Cavalcant et al. <ref type="bibr" target="#b7">[8]</ref>), to name just a few (Comon and Jutten <ref type="bibr" target="#b8">[9]</ref>).</p><p>Although there was some successful recent research on end-to-end methods that directly produce source estimates when fed with a mixture (Wang et al. <ref type="bibr" target="#b41">[42]</ref>, Venkataramani et al. <ref type="bibr" target="#b37">[38]</ref>), the most common separation processing pipeline consists in two steps done sequentially. First, the mixture is fed into some estimation system. This results in a set of parameters that are used in a second step to design a source-specific filter, which is applied to the mixture to produce estimates. Formally, this filtering operation boils down to computations performed on many mixture vectors in an independent manner. For instance, the observed (multivariate) mixture samples may directly be assumed independent as routinely done in biological signal processing. In other cases like audio where temporal dependencies cannot be neglected, it is common to apply some Time-Frequency (TF) analysis first and then to assume independence in this transformed domain <ref type="bibr">(Benaroya et al. [4]</ref>, Duong et al. <ref type="bibr" target="#b10">[11]</ref>, Liutkus et al. <ref type="bibr" target="#b21">[22]</ref>).</p><p>Separating an observed vector into additive components requires further assumptions that are usually encoded into a probabilistic model permitting inference. More precisely, the required feature of such a model is to allow derivation of the posterior distribution of one source given the observation of the mixture and the knowledge of the model parameters. An ubiquitous example of such a model is the Gaussian case, for which each source is described through a covariance matrix, and separation is easily performed in an analytical form. It turns out that such a model subsumes the popular, yet degenerate case where each source lies in a linear subspace, corresponding to its direction of arrival (Duong et al. <ref type="bibr" target="#b10">[11]</ref>). In any case, this whole linear estimation theory enjoys a rich history whose roots can be traced back to the work of N. Wiener in the 1940s <ref type="bibr">(Wiener [43]</ref>). From a broader perspective, we see that the core challenge faced by most source separation methods is strongly related to additive probabilistic models (Duvenaud et al. <ref type="bibr" target="#b11">[12]</ref>, Febrero-Bande and González-Manteiga <ref type="bibr" target="#b12">[13]</ref>, Wood et al. <ref type="bibr" target="#b43">[44]</ref>, Marra and Wood <ref type="bibr" target="#b24">[25]</ref>). The particular twist in this respect is that the models chosen for separation should provide a way to recover the additive sources.</p><p>Although covariance modeling for source separation has enjoyed a strong popularity due to the simplicity and effectiveness of the separation procedure, experience shows that it also suffers from some weaknesses. First and foremost, Gaussian processes realizations may not explore more than a few standard deviations, which means that Bayesian inference in these models is intrinsically very sensitive to initialization, since the probability mass is almost everywhere negligible. A common workaround is to further constrain covariance models through shallow (Ozerov et al. <ref type="bibr" target="#b30">[31]</ref>) or deep (Nugraha et al. <ref type="bibr" target="#b29">[30]</ref>) parametric constraints, but another complementary route is to simply opt for heavy-tail models, for which much more robust inference is possible. For instance, multivariate Laplace filters (Wang et al. <ref type="bibr" target="#b40">[41]</ref>) were successfully used for robust detection and result from Bayesian inference in a state-space model where some variables are Laplace distributed. In the same vein, a Student's t filter (Roth et al. <ref type="bibr" target="#b33">[34]</ref>) was also proposed for a tracking scenario and exploits the heavy-tailed nature of the Student's t distribution. Likewise, this distribution was also already considered for robust estimation of source separation parameters (Kitamura et al. <ref type="bibr" target="#b19">[20]</ref>, Yoshii et al. <ref type="bibr" target="#b44">[45]</ref>).</p><p>Although the Laplace and Student's t distributions mentioned above are characterized as featuring heavy tails and are thus suitable for robust estimation of sources parameters, their density is not stable under convolution, which means that the distribution of sums of such random variables does not belong to the same family. As a consequence, they do not straightforwardly lead to convenient filters that may be used for the separation stage. In this context, a natural solution is to take the target signal as deterministic, and only pick a heavytailed distribution for the noise term. However, such an approach breaks down when uncertainty is to be considered for the target, that becomes stochastic, or when more than two components are mixed, which is for instance common in source separation. Consequently, the strategy employed, e.g. in <ref type="bibr">(Kitamura et al. [20]</ref>, Yoshii et al. <ref type="bibr" target="#b44">[45]</ref>) is to use robust models for estimation only, and then revert to a covariance separation approach. The only principled separation method we are aware of, that is based on heavy tailed modeling, is the α-Wiener filter presented in (Liutkus and Badeau <ref type="bibr" target="#b20">[21]</ref>) and further developed in (Fontaine et al. <ref type="bibr" target="#b13">[14]</ref>). It is based on α-stable distributions but is however restricted to the scalar case.</p><p>In this paper, we build on the scalar α-Wiener filter (Liutkus and Badeau <ref type="bibr" target="#b20">[21]</ref>) to extend it to the multivariate case and hence propose for the first time a filter based on multivariate α-stable distributions. Doing so, we enable the use of such heavy-tail models not only for parameter estimation, but also for separation. The α-stable distributions and processes (Samoradnitsky and Taqqu <ref type="bibr" target="#b34">[35]</ref>) are defined as the only class of distributions that are stable under convolution, and thus under addition of independent realizations. They hence naturally appear in the generalized version of the central limit theorem, which is applicable even when the random variables under consideration do not have finite moments. This is useful for modeling very volatile noise or signals, or to allow iterative parameter estimation strategies even with bad initialization. They were first put forward by Mandelbrot to model financial time series <ref type="bibr">(Mandelbrot [24]</ref>) and have found widespread applications ever since: impulse noise modeling in landline connections <ref type="bibr">(Stuck and Kleiner [36]</ref>), modeling of background speckle patterns in SAR images (Achim et al. <ref type="bibr" target="#b0">[1]</ref>), and audio noise modeling (Bassiou et al. <ref type="bibr" target="#b1">[2]</ref>), to name a few.</p><p>The dependencies between the entries of α-stable random vectors are not encoded in covariance matrices as in the Gaussian case. Instead, they are described through a unique measure defined on the hypersphere (Hardin J. <ref type="bibr" target="#b17">[18]</ref>), which can be understood as providing the strength of each direction of arrival. This makes the expressive power of the model much larger than in the Gaussian case, that is limited to ellipsoidal profiles. Throughout this paper, we call this object the spatial density 1 . That object regularly attracts some attention. It has for instance been considered for independent component analysis (Kidmose <ref type="bibr" target="#b18">[19]</ref>, Wang et al. <ref type="bibr" target="#b39">[40]</ref>), for exchange rates estimation in financial data (Nolan et al. <ref type="bibr" target="#b28">[29]</ref>), and more recently for audio source localization (Fontaine et al. <ref type="bibr" target="#b14">[15]</ref>). As a mathematical object defined on the hypersphere, some authors also proposed alternative equivalent representations, notably through spherical harmonics (Pivato and Seco <ref type="bibr" target="#b31">[32]</ref>).</p><p>In this paper, we show how to design digital filters specifically for α-stable random vectors. For this purpose, we go further than both (Kidmose <ref type="bibr" target="#b18">[19]</ref>), that focused on linear determined mixtures, and (Liutkus and Badeau <ref type="bibr" target="#b20">[21]</ref>), which is limited to the scalar case. First, we present some theoretical results in Section 2, that develop a spatial spectrum representation for α-stable random vectors. Based on this representation, we propose two different filtering methods. In Section 3, multivariate observations are decomposed into their spatial spectrum, whose components are then filtered individually for reconstruction. An alternative approach is presented in Section 4, where the sources are estimated directly as a combination of linear filters, but with a design involving the spatial density. Both methods are evaluated in Section 5 and compared to their Gaussian counterpart.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Notation</head><p>Throughout the paper, scalars are denoted with a normal, light font, e.g. α ∈ (0, 2) or K ∈ N. Vectors are indicated with bold lowercase letters, e.g. x ∈ C K and matrices with bold uppercase letters, e.g. P ∈ C K×K . We furthermore use the following notation:</p><formula xml:id="formula_0">• K : denotes either C or R. • K K : set of K-valued vectors of dimension K. • S K = (θ 1 . . . θ K ) ∈ K K , K k=1 |θ k | 2 = 1 : K -1 dimensional hyper- sphere.</formula><p>• B S K : set of Borelian sets on S K . 1 In the literature, the spatial density is rather called spectral measure (Samoradnitsky and Taqqu <ref type="bibr" target="#b34">[35]</ref>). We have deliberately chosen to avoid the term "spectral" here for two reasons. First, we believe that it may bring some confusion for a signal processing audience. Second, we think that calling it spatial better highlights the fact that it encodes dependencies between covariates.</p><p>• θ: vector from the hypersphere θ ∈ S K , also called a direction, with entries θ k .</p><p>• Θ: A partition {Θ 1 , . . . , Θ P } of S K , for which:</p><p>-All cells Θ p have the same area ∆ Θ .</p><p>θ p ∈ Θ p denotes an element of cell Θ p .</p><p>• : real part of a complex number.</p><p>• . : Hermitian transposition (resp. conjugation) of a complex vector (resp. complex number).</p><p>• ., . : inner product on K K : w, x = w x.</p><p>• y jk : k th component of a vector y j .</p><p>• e k : k th vector from the canonical basis.</p><p>• . . : signed power function (Samoradnitsky and Taqqu <ref type="bibr" target="#b34">[35]</ref>, Nikias and Shao <ref type="bibr" target="#b27">[28]</ref>): ∀z ∈ K, z α = z |z| α-1</p><p>• : "equal by definition to".</p><p>• ←: assignment of a value to a variable in an algorithm.</p><p>2. The multivariate α-stable probabilistic model p (x) An isotropic (circular) symmetric α-stable scalar random variable x ∼ SαS 1 c (σ x ) can be defined by its characteristic function (chf.) ϕ x : u ∈ K → E (exp (i (u x))) as follows:</p><formula xml:id="formula_1">α = 1.0 α = 1.4 α = 1.8 α = 2</formula><formula xml:id="formula_2">∀u ∈ K, ϕ x (u) = exp (-|u| α σ α x )</formula><p>where σ x is called a scale factor. The real number α ∈ (0, 2] is called the characteristic exponent and defines the heaviness of the tails in a stable distribution: the smaller α, the heavier the tails. Examples of probability density functions (pdf.) for such scalar random variables are represented in the real case in Fig. <ref type="figure" target="#fig_0">1</ref>.</p><p>It is remarkable that such a pdf. is not available in closed-form in general, but only in some particular cases, like the Cauchy (α = 1) and Gaussian (α = 2) distributions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">α-stable random vectors</head><p>In this paper, we limit our attention to symmetric α-stable random vectors, i.e. α-stable random vectors x such that x and -x have the same distribution, defined as in (Samoradnitsky and Taqqu <ref type="bibr" target="#b34">[35]</ref>): Definition 1. Let x be a random vector in K K associated to its characteristic function ϕ x : u ∈ K K → E (exp (i u, x )). A symmetric isotropic α-stable distribution with α ∈ (0, 2) is fully described by the unique representation:</p><formula xml:id="formula_3">∀u ∈ K K , ϕ x (u) = exp - θ∈S K | u, θ | α Γ x (dθ) ,<label>(1)</label></formula><p>where Γ x is a symmetric measure on the sphere S K called the spatial density 2 . Henceforth, we note x ∼ SαS K c (Γ x ) whenever x follows a symmetric α-stable distribution with spatial density Γ x . 3   Remark 2. A symmetric α-stable vector x ∼ SαS K c (Γ x ) belongs to a larger class: the elliptically multivariate contoured (EMC) distribution (Cambanis et al. <ref type="bibr" target="#b5">[6]</ref>). In many cases, the sum of EMC vectors x, y, respectively associated to the so-called scatter matrices R x and R y , is still an EMC vector. However, the parameter R x+y called scatter matrix of the mix is usually not equal to R x + R y . In the α-stable case, Definition 1 ensures that the spatial density of the mix Γ x+y is equal to Γ x + Γ y .</p><p>We highlight the fact that the Gaussian (α = 2) case is omitted in Definition 1, because the representation (1) is not unique in that case.</p><p>2 See Footnote 1 on page 4. 3 Γx is a symmetric measure on S K in the sense that for any continuous function f defined on S K and for any z ∈ K such that |z| = 1, we have</p><formula xml:id="formula_4">θ∈S K f (θ) Γx (zdθ) = θ∈S K f (θ) Γx (dθ).</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">Spatial spectrum and spatial representation</head><p>In this section, we show how the spatial density Γ x , featured in Definition 1, of a symmetric α -stable distribution can be understood through a so-called spatial representation, which is central to the filtering methods we propose later in Sections 3 and 4.</p><p>Let X be an independently scattered α-stable random measure on S K , with control measure Γ x (Samoradnitsky and Taqqu <ref type="bibr" target="#b34">[35]</ref>). This means that:</p><p>1. for any Borelian set A ⊂ B S K , the scalar random variable</p><formula xml:id="formula_5">X (A) ∈ K is distributed as X (A) ∼ SαS c (Γ x (A)), 2. X (A) is independent from X (B) whenever A∩B = ∅ for any two Borelian subsets A and B ⊂ B S K .</formula><p>We call X the spatial spectrum of the distribution SαS K c (Γ x ). Remark 3. In (Ma and Nikias <ref type="bibr" target="#b22">[23]</ref>), the α-spectrum terminology is used in a different way as the spatial spectrum. It describes the so-called covariation (see Section 4.1 for further details) between the input single-channel signal and the output single-channel signal.We have the following first result:</p><formula xml:id="formula_6">Theorem 4. Let x ∼ SαS K c (Γ x )</formula><p>, with spatial density Γ x . Then x admits the following spatial representation:</p><formula xml:id="formula_7">x d = θ∈S K θX (dθ) ,<label>(2)</label></formula><p>where d = means "equal in distribution" and X is the spatial spectrum with control measure Γ x .</p><p>The proof of this result is given in Appendix 1. The representation theorem means that an SαS K c random vector is distributed as the sum of infinitely many contributions, coming from all directions θ ∈ S K on the sphere. Γ x (dθ) may thus be interpreted as the scale factor of the contributions pointing in direction θ. Very interestingly, the spatial representation in Theorem 4 provides a straightforward way to generate samples from SαS K c (Γ x ) random vectors: first, generate the spatial spectrum X , and then use (2) to construct the SαS K c random vector x. The method is summarized in Algorithm 1.</p><p>The integration over the real or complex sphere, appearing in (2), is replaced by finite sums. This is done by simply constructing a regular partition Θ of the sphere S K , and substituting the integration by the corresponding sum carried over the Θ p 's. Let f be a function defined on the hypersphere and M be a measure on the sphere. For P large enough, the approximation goes as:</p><formula xml:id="formula_8">S K θf (θ) M (dθ) ≈ p θ p f (θ p ) M (Θ p ) ,<label>(3)</label></formula><p>where M (Θ p ) may further be approximated as m (θ p ) ∆ Θ (where ∆ Θ is the Lebesgue measure of Θ p ), whenever M is dominated by the Lebesgue measure and thus equal to M (dθ) = m (θ) dθ for some measurable function m.</p><p>Algorithm 1 Sampling of SαS K c (Γ x ) random vectors through their spatial representation.</p><p>1. Input</p><p>• Number N of desired realizations</p><p>• Partition Θ = {Θ 1 , . . . , Θ P } of S K as described in Section 1</p><formula xml:id="formula_9">• Characteristic exponent α ∈ (0, 2) • Spatial density Γ x 2. Spatial spectrum generation ∀n, p, X np ∼ SαS c (Γ x (Θ p )) where Γ x (Θ p ) is the restriction of Γ x to the set Θ p up to renormalization. 3. Synthesis ∀n, x n ← p θ p X np</formula><p>Given our model for α-stable vectors, we now discuss the distribution of mixtures of such random vectors. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.">Mixtures of α-stable random vectors</head><formula xml:id="formula_10">∼ SαS K c (Γ 1 ) (in green) and y 2 ∼ SαS K c (Γ 2 ) (in red)</formula><p>, where the maxima of Γ 1 and Γ 2 are reached for 5π 8 , 5π 8 + π 3 and 5π 8 + π 6 , 5π 8 + π 2 . These plots show the influence of the spatial density on the dependence patterns between covariates. On the right, a density plot for the mixture x = y 1 + y 2 shows the additive property of spatial densities.</p><p>In the filtering and signal processing literature, it is common to assume that the observed vector x ∈ K K is the sum of J components y j ∈ K K that we want to recover. Here, we take each component y j ∼ SαS K c (Γ j ) as described above, with its own spatial density Γ j :</p><formula xml:id="formula_11">x = J j=1 y j ∀j, y j ∼ SαS K c (Γ j ) . (<label>4</label></formula><formula xml:id="formula_12">)</formula><p>Because x is the sum of α-stable vectors, then x itself follows an α-stable distribution, with the following spatial density:</p><formula xml:id="formula_13">x ∼ SαS K c (Γ x ) Γ x = j Γ j .</formula><p>By invoking the spatial representation Theorem 4 on each latent vector y j , we get: ∀j, y j d = θ∈S K θY j (dθ), where Y j denotes the spatial spectrum of y j . Moreover, X j Y j also defines a spatial spectrum associated to x. Informally, it simply means that x is also the sum of infinitely many contributions X (dθ), coming from all directions θ ∈ S K on the sphere, each one of them being in turn the sum of the contributions Y j (dθ) for all components that come from this particular direction. An illustration of the relationships between the spatial densities Γ x , Γ j is given in Fig. <ref type="figure" target="#fig_2">2</ref>.</p><p>The next two sections make different uses of this spatial representation to devise filters, which aim at estimating the latent vectors y j given x, provided the spatial densities Γ j , which are parameters, are known. This allows us to dissociate the actual filtering problem from the question of estimating signal parameters. This strategy is for instance classical in the literature focusing on Wiener-based filter design (Wiener <ref type="bibr" target="#b42">[43]</ref>, Duong et al. <ref type="bibr" target="#b10">[11]</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Spatial spectrum filter (SSF)</head><p>Our objective is to estimate each latent vector y j , such that y j = x. The strategy we discuss here proceeds in two steps. Firstly, we estimate the spatial spectrum X of the mixture, as described in Section 3.1. Secondly, this estimate is used to reconstruct the desired latent vectors y j , as detailed in Section 3.2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Spatial spectrum estimation</head><p>We assume that the observation x ∼ SαS K c (Γ x ) and its spatial density Γ x are known. The first step in the filter we discuss here is to estimate the spatial spectrum X . For this purpose, we choose the a posteriori expectation X (dθ) of X (dθ) given x, defined in the following sense: for any continuous function ψ on S K , satisfying θ∈S K |ψ (θ)| α Γ x (dθ) &lt; +∞, we have:</p><formula xml:id="formula_14">E θ∈S K ψ (θ)X (dθ) | x = θ∈S K ψ (θ) X (dθ) .<label>(5)</label></formula><p>Note that it is such that θ∈S K θ X (dθ) = x. It turns out that in the particular case of an SαS K c (Γ x ) observation x, X (dθ) has the following form:</p><p>Proposition 5. Under the previous assumptions, X (dθ) can be rewritten as:</p><formula xml:id="formula_15">X (dθ) = g X (x, θ) Γ x (dθ) a.s.<label>(6)</label></formula><p>with:</p><formula xml:id="formula_16">∀θ ∈ S K , g X (x, θ) = N (x, θ) D (x) ,<label>(7)</label></formula><p>where</p><formula xml:id="formula_17">N (x, θ) = αi u∈K K θ, u α-1 ϕ x (u) e -i ( u,x ) du<label>(8)</label></formula><p>and</p><formula xml:id="formula_18">D (x) = u∈K K ϕ x (u) e -i ( u,x ) du.<label>(9)</label></formula><p>If α &gt; 1, the density g X (x, θ) is a continuous map on S K , and hence the measure X (dθ) is dominated by Γ x (dθ).</p><p>Proposition 5 is proved in Appendix 2. Although g X (x, θ) has the closed-form expression <ref type="bibr" target="#b6">(7)</ref>, its computation is not straightforward because it requires two integrations over K K . Let I x (u) ln (ϕ x (u)) be the Levy exponent of x (Unser and Tafti <ref type="bibr" target="#b36">[37]</ref>). From (1), it is given by:</p><formula xml:id="formula_19">I x (u) = θ∈S K | u, θ | α Γ x (dθ).</formula><p>We have the following result, with proofs given in Appendix 2:</p><formula xml:id="formula_20">Proposition 6. Let β = 1 if K = R, or β =2 if K = C. Then (8) is equivalent to N (x, θ) = θ ∈S K θ, θ α-1 θ , x I x (θ ) βK+α α η | θ , x | 2 I x (θ ) 2 α dθ ,<label>(10)</label></formula><p>where:</p><formula xml:id="formula_21">η (ρ) = +∞ n=0 (-1) n f Γ 2n+βK+α α 2 2n+1 n! (n + 1)! ρ n . (<label>11</label></formula><formula xml:id="formula_22">)</formula><p>with f Γ the Gamma function. In the same way, (9) is equivalent to</p><formula xml:id="formula_23">D (x) = S K θN (x, θ) Γ x (dθ) 1 x 1 . (<label>12</label></formula><formula xml:id="formula_24">)</formula><p>Proposition 6 is proved in Appendix 2. Note that in <ref type="bibr" target="#b11">(12)</ref>, any norm could be picked for the computation and yield the same result. The 1 -norm . 1 turns out to be a good compromise between computational cost and numerical stability.</p><p>Equations ( <ref type="formula" target="#formula_20">10</ref>) and ( <ref type="formula" target="#formula_23">12</ref>) in Proposition 6 provide an estimator of g X , which is computationally tractable via integrations on the compact set S K , as opposed to (7) that requires integration over K K .</p><p>The quantity η (ρ) is a power series with an infinite radius of convergence when α &gt; 1. It is a smooth function of ρ and independent of the data and the model parameters. It can hence be computed beforehand.</p><p>The main computational burden for this method lies in the computation of the alternating power series η in <ref type="bibr" target="#b10">(11)</ref>. It converges slowly and goes through extreme values, requiring a fairly large numerical precision in practice. However, there are some cases where a closed-form expression is available, for instance when α = 2, K = 2, β = 2, where η (ρ) = 1  16 ρ 2 -20ρ + 64 e -ρ/4 . Inspired by this result, we decided to approximate η in all cases as:</p><formula xml:id="formula_25">η (ρ) ≈ η (ρ) = aρ 2 + bρ + c e -dρ<label>(13)</label></formula><p>where a, b, c, d ∈ R are model parameters. Using such a parameterized version allows us to avoid the on-demand time-consuming evaluations of η. We estimated the parameters that minimize the mean-square-error (MSE) ηη 2 2 . We highlight that both the choice of this parametric model <ref type="bibr" target="#b12">(13)</ref> and the choice of the MSE criterion are driven by ad-hoc considerations, indeed, there is no theoretical result we are aware of that would justify the convergence of the power series to an exponential function. However, the plots for η and η for β = 1 are displayed in Fig. <ref type="figure" target="#fig_4">3(a)</ref>, and the error of fit for η for β = 2 as a function of α is displayed in Fig. <ref type="figure" target="#fig_4">3(b</ref>) and quality is very good. Results were similar in the real and complex cases. η was computed for 50 regularly spaced values α ∈ (1, 2), and for ρ ∈ (0, 10), because ρ only has positive values in <ref type="bibr" target="#b9">(10)</ref>. For getting a suitable convergence, η was calculated up to order 10 5 .  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Signal reconstruction</head><p>Once the spatial spectrum X (dθ) of the observation is estimated, or equivalently g X (x, θ) is computed through <ref type="bibr" target="#b6">(7)</ref>, <ref type="bibr" target="#b9">(10)</ref> and <ref type="bibr" target="#b11">(12)</ref>, our next step is to construct an estimate for the components y j of interest. We pick the a posteriori expectation: y j E y j | x , which is given as follows:</p><p>Theorem 7. Let x be the sum of SαS K c random vectors y j ∼ SαS K c (Γ j ), each with known spatial density Γ j . Then the a posteriori expectation of each component y j given x is:</p><formula xml:id="formula_26">y j E y j | x = θ∈S K θg X (x, θ) Γ j (dθ) ,<label>(14)</label></formula><p>where g X was defined in <ref type="bibr" target="#b6">(7)</ref>. The proof of this theorem is also in Appendix 2. A summary of this filtering technique is given in Algorithm 2:</p><p>Algorithm 2 α-SSF: multivariate α-stable filtering through a spatial spectrum estimation.</p><p>1.</p><formula xml:id="formula_27">Input • Observation x of size K • Regular partition Θ = {Θ 1 , . . . , Θ P } of S K • Characteristic exponent α ∈ (1, 2)</formula><p>• spatial densities Γ j</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Spatial spectrum estimation</head><p>• Using η in (13), compute ∀p, N (x, θ p ) in (10)</p><formula xml:id="formula_28">• Compute D (x) in (12) • Compute g X (x, θ p ) = N (x,θp) D(x)</formula><p>3. Reconstruction: y j = p θ p g X (x, θ p ) Γ j (Θ p )</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Covariation-minimizing filter (CMF)</head><p>Despite a relatively simple expression of g X , the estimation technique in Section 3 is computationally demanding, due to several numerical integrations. In this section, the spatial representation in Theorem 4 will be exploited differently, leading to a faster filtering method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Covariation between stable variables</head><p>Many signal processing studies exploit second-order statistics for the design of digital filters (Cardoso <ref type="bibr" target="#b6">[7]</ref>, Duong et al. <ref type="bibr" target="#b10">[11]</ref>, Moussaoui et al. <ref type="bibr" target="#b26">[27]</ref>). This convenient strategy finds a straightforward probabilistic interpretation through Gaussian processes (α = 2), that are characterized by their covariance functions. However, this strategy breaks down for α-stable processes with α &lt; 2, because the moments of order p ≥ α are infinite. For this reason, the covariation was introduced (Samoradnitsky and Taqqu <ref type="bibr" target="#b34">[35]</ref>, Nikias and Shao <ref type="bibr">[28, p. 87]</ref>) as a substitute of the covariance, with many similar properties. Definition 8. The covariation between two random variables (x 1 , x 2 ), jointly distributed as:</p><formula xml:id="formula_29">(x 1 , x 2 ) x ∼ SαS 2 c (Γ x ) for α &gt; 1, is defined as: [x 1 , x 2 ] α z=(z1,z2)∈S 2 z * 1 z α-1 2 Γ x (dz) .</formula><p>Moreover, the covariation norm (Samoradnitsky and Taqqu [35, p 95]) of u ∼ SαS 1 c is:</p><formula xml:id="formula_30">u α = ([u, u] α ) 1/α . Remark 9.</formula><p>The covariation is always anti-linear in its left argument. It is also linear in the right argument if and only if all terms of the linear combination on the right-hand side are mutually independent: if (x, x 1 , x 2 ) are jointly SαS 3 c with x 1 and x 2 independent, then [x,</p><formula xml:id="formula_31">x 1 + x 2 ] α = [x, x 1 ] α + [x,</formula><p>x 2 ] α . In addition, if x 1 and x 2 are independent then [x 1 , x 2 ] α = 0, and if x ∼ SαS 1 c (σ x ), then x α = σ x .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Covariation minimization filtering (CMF) technique</head><p>Our objective in this section is to build a filter to extract the component y j from the mixture x. Motivated by <ref type="bibr">(Masry [26]</ref>), we seek filtering vectors w jk ∈ K K such that y jk = w jk , x minimizes the covariation norm y jky jk α α . Additionally, we enforce j w jk = e k to guarantee perfect reconstruction of the mixture: x = j y j . For each k, this results in the following optimization problem with linear equality constraints:</p><formula xml:id="formula_32">minimize j y jk -w jk , x α α w.r.t. w jk subject to j w jk = e k .<label>(15)</label></formula><p>The constraints and covariation norm have convenient properties. Firstly, the constraints are linear. Secondly, the criterion is a differentiable function whose derivative is continuous, and it is convex. Thirdly, the covariation norm is coercive. By invoking the Karush, Khun and Tucker theorem (Boyd and Vandenberghe <ref type="bibr" target="#b4">[5]</ref>), this optimization problem thus has a unique solution.</p><p>We apply the spatial representation in Theorem 4 to get</p><formula xml:id="formula_33">x d = θX (dθ)</formula><p>and y j d = θY j (dθ), with integrations done over S K . The Lagrangian of the problem ( <ref type="formula" target="#formula_32">15</ref>) is</p><formula xml:id="formula_34">L {w jk } j , λ k = j y jk -w jk , x α α + α   λ * k   j w jk -e k     (<label>16</label></formula><formula xml:id="formula_35">)</formula><p>where the factor α in the second line is introduced to simplify the following calculations. Now, thanks to properties of the covariation given in Remark 9, the development of y jky jk α α for all j, k yields:</p><formula xml:id="formula_36">y jk -y jk α α = y jk - j w jk , y j α α = θ k -w jk , θ Y j (dθ) α α + j =j w jk , θ Y j (dθ) α α = θ k -w jk , θ α Γ j (dθ) + j =j w jk , θ α Γ j (dθ) = θ k -w jk , θ α -w jk , θ α Γ j (dθ) + w jk , θ α Γx(dθ).<label>(17)</label></formula><p>By substituting <ref type="bibr" target="#b16">(17)</ref> in <ref type="bibr" target="#b15">(16)</ref>, and by zeroing the gradient of L w.r.t. w jk , we get for all j:</p><formula xml:id="formula_37">λ k = θ (θ * k -θ, w jk ) α-1 + θ, w jk α-1 Γj (dθ) -θ θ, w jk α-1 Γx (dθ) . (<label>18</label></formula><formula xml:id="formula_38">)</formula><p>By noting that z α-1 = z |z| 2-α , (18) can be written as:</p><formula xml:id="formula_39">λ k = -P jk w jk + r jk ,<label>(19)</label></formula><p>where the K × K matrix R jk and the vector r jk ∈ K K are defined as:</p><formula xml:id="formula_40">P jk = θθ |θ k -w jk , θ | 2-α - θθ | w jk , θ | 2-α Γj (dθ) + θθ | w jk , θ | 2-α Γx (dθ) . (<label>20</label></formula><formula xml:id="formula_41">)</formula><formula xml:id="formula_42">r jk = θθ k |θ k -w jk , θ | 2-α Γj (dθ) . (<label>21</label></formula><formula xml:id="formula_43">)</formula><p>Therefore w jk is a fixed point of the following equation:</p><formula xml:id="formula_44">w jk = P -1 jk (r jk -λ k ) .<label>(22)</label></formula><p>A sum over j in <ref type="bibr" target="#b21">(22)</ref> leads to:</p><formula xml:id="formula_45">λ k =   j P -1 jk   -1     j P -1 jk r jk   -e k   . (<label>23</label></formula><formula xml:id="formula_46">)</formula><p>Putting together the above results, we propose to design the filters w jk based on a fixed-point approach where P jk in <ref type="bibr" target="#b19">(20)</ref>, w jk in <ref type="bibr" target="#b21">(22)</ref> and λ k in <ref type="bibr" target="#b22">(23)</ref> are updated in turn. This is summarized in Algorithm 3. The integrals are replaced by a discrete sum as in <ref type="bibr" target="#b2">(3)</ref>.</p><formula xml:id="formula_47">Algorithm 3 α-CMF: multivariate α-stable filtering through covariation min- imization 1. Input • Observation x of size K • Regular partition Θ = {Θ 1 , . . . , Θ P } of S K • Characteristic exponent α ∈ (1, 2)</formula><p>• Spatial densities Γ j</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Initialization</head><p>• ∀j, k, w jk = 1 J e k • ∀j, k, the entries of P j,k are independently drawn from the standard normal distribution</p><p>• ∀k, λ k = 0</p><p>3. Updates of P jk , w j,k and λ k</p><p>• ∀j, k, update P jk as in (20)</p><formula xml:id="formula_48">• ∀k, λ k ← λ k + j P -1 jk -1 j w jk -e k</formula><p>• ∀j, k, update w jk as in ( <ref type="formula" target="#formula_44">22</ref>) and ( <ref type="formula" target="#formula_42">21</ref>)</p><p>4. Reconstruction: ∀j, k, y jk = w jk , x</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">The Gaussian case (α = 2)</head><p>Although the derivations done above focus on the case α ∈ (1, 2), it is interesting to note the limiting behaviour of the proposed filtering method when α → 2. We get:</p><formula xml:id="formula_49">∀j, k, P jk = P = θθ Γ x (dθ) ,<label>(24)</label></formula><p>which is the covariance matrix of the mixture x. Indeed, exploiting the chf. representation in (1), we have:</p><formula xml:id="formula_50">∀u ∈ K K , ϕ x (u) = exp -| u, θ | 2 Γ x (dθ) , = exp (-u P u) ,</formula><p>which is the chf. of a Gaussian vector of covariance matrix P . It is straightforward to show that P = P j , where P j is the covariance matrix of the j th component, given as in <ref type="bibr" target="#b23">(24)</ref> but by integrating against Γ j :</p><formula xml:id="formula_51">P j = θθ Γ j (dθ) . (<label>25</label></formula><formula xml:id="formula_52">)</formula><p>Then, r jk in ( <ref type="formula" target="#formula_42">21</ref>) becomes the k th column of P j . Consequently, when α → 2, the estimates y j for the components become:</p><formula xml:id="formula_53">y j = P j   j P j   -1 x,<label>(26)</label></formula><p>which is exactly the classical multichannel Wiener filter (MWF), but with parameters computed by exploiting the spatial densities Γ j . This is the linear filtering method which minimizes the MSE between the sources and their estimates when second-order moments are available. As expected, the CMF technique presented in Section 4.2 is a generalization of the MWF to α-stable distributions.</p><p>Finally, we will propose a last estimator, which is another generalization of the MWF to α-stable distributions. Because second-order moments are not defined for α &lt; 2, matrices P j cannot be defined through P j = E y j y j as in the case α = 2. Nevertheless, it is remarkable that the expression (25) remains computable whatever α ∈ (1, 2), making it an interesting method to estimate the parameters of what becomes an ad-hoc filter <ref type="bibr" target="#b25">(26)</ref>, which we call MWF through an abuse of notation, since it is only equivalent to MWF when α = 2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Evaluation</head><p>In this section, we assess the performance of the three filtering methods presented in Sections 3, 4.2 and 4.3. In this regard, we stress that this paper only addresses the design of filters associated to α-stable processes with known parameters Γ j . Hence, the estimation of those parameters is kept out of the scope of the present study. The reader can however find spatial measure estimation techniques in (Nolan et al. <ref type="bibr" target="#b28">[29]</ref>) and (Pivato and Seco <ref type="bibr" target="#b31">[32]</ref>). The rationale for disentangling filtering and parameter estimation is to provide a grounded basis for the last filtering step of whole processing pipelines involving α-stable processes, as is routinely done for Gaussian processes with the MWF (Duong et al. <ref type="bibr" target="#b10">[11]</ref>, Liutkus et al. <ref type="bibr" target="#b21">[22]</ref>).</p><p>Consequently, this evaluation focuses on the performance of the proposed filters on synthetic data only. The procedure is always the same: firstly, we generate the realizations y j according to multivariate symmetric α-stable distributions with known spatial densities Γ j as in Algorithm 1, then, these realizations are summed to produce the observations x to be filtered, and the performance scores are computed by comparing the true y j with their estimates. That said, the set of parameters considered spans a wide range of configurations of various difficulties, allowing us to assess the strengths and weaknesses of the proposed methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Experimental setup</head><p>Evaluated methods. We investigate the performance of α-SSF, as presented in Section 3, and of α-CMF with 50 iterations, as presented in Section 4.2. We compare them with the MWF method described in Section 4.3, i.e. with parameters P j computed as in (25) using the true Γ j .</p><p>Metrics. Because α &gt; 1, the relative root mean-square error does not exist (except for α = 2). Thus, we only consider the relative mean-absolute error (MAE) defined as:</p><formula xml:id="formula_54">MAE (y, y) = j E y j -y j j E y j ,<label>(27)</label></formula><p>where expectations are approximated by the empirical mean.</p><p>The Von-Mises Fisher distribution. As mentioned above, we evaluate all methods in the case of known spatial densities Γ j . As a running example, we will take the Γ j as mixtures of Von-Mises Fisher (VMF) distributions, written V µ,κ , which are defined as:</p><formula xml:id="formula_55">V µ,κ (dθ) ∝ exp κµ θ dθ,<label>(28)</label></formula><p>where µ ∈ S K is the mean direction and κ &gt; 0 is a concentration parameter, which is higher when the mass concentrates close to µ. Since the spatial densities are symmetric, we sample them on the hyper-hemisphere only. Although any other choice of a distribution over S K could be made, we picked the VMF because it is the maximum entropy distribution of a random variable on the sphere with known location and spread parameters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Performance versus the spatial distance of components</head><p>In this first round of experiments, we focus on the spatial resolution of each algorithm, because filtering out components that are spatially close has many applications, e.g. in audio processing. For this purpose, we study the filtering performance of mixtures of J = 2 real-valued sources of dimension K = 2, so that a direction θ ∈ S K can be understood as a point on the unit circle.</p><p>We take each component y j as originating mostly from one direction µ j , with both components sharing the same concentration parameter κ = 15, so  that Γ j = V µ j ,κ . Depending on the choice of the directions µ j , this allows us to create some overlap between the Γ j 's. We set a 0.2 step-size for α ∈ [1.2, 2], and the mean directions µ j for the sources are separated by {5, 15, . . . , 85} degrees, with µ 1 randomly positioned on the semi-circle. An example is given in Fig. <ref type="figure" target="#fig_6">4</ref>.</p><formula xml:id="formula_56">V 2 µ,κ (θ) Γ 1 (θ) Γ 2 (θ)</formula><p>Algorithms α-SSF and α-CMF were run with partitions Θ composed of P = 180 regions. For each configuration of the µ j , the performance of all methods was evaluated on the filtering of N = 2000 independent realizations. 100 different such experiments were conducted to report the scores.</p><p>The corresponding MAE <ref type="bibr" target="#b26">(27)</ref> values for α = 1.6 are displayed in Fig. <ref type="figure" target="#fig_7">5</ref>. As can be seen on this figure, α-SSF globally outperforms the other methods for all the angular distances between the sources, followed by α-CMF. While these two methods behave similarly, they both outperform MWF.</p><p>In Fig. <ref type="figure" target="#fig_8">6</ref>, we show the evolution of these scores as a function of α, for a fixed deviation of 25 degrees between the sources. As can be seen, smaller values for α lead to a degradation of the performance, due to the extremely heavy tails of the distributions. However, we notice that all proposed methods remain quite robust. Hence, even MWF, the proposed approach that exploits the spatial densities Γ j to build the MWF filters as discussed in Section 4.3, is remarkably effective. In practice, decreasing P often causes instability for MWF, while increasing P does not significantly change scores.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.">Performance versus the number of components</head><p>In this second set of experiments, we evaluate our proposed filtering methods in the complex case with K = 2. Our objective here is to assess the performance with a varying number J of components to separate. Hence, for J ∈ {2, . . . , 8}, α ∈ [1.2, 2], and N = 2000 independent realizations, we run 100 independents   experiments, where the spatial densities are VMF distributions with random parameters κ j and µ j .</p><p>Regarding the computation of our integrals as in (3) for this complex case, they were performed with P = 400 values for the partition Θ.</p><p>The results shown in Fig. <ref type="figure" target="#fig_9">7</ref> are in line with those for J = 2 reported above, and suggest that the α-SSF method globally outperforms the three other methods for all configurations.</p><p>MWF α-CMF α-SSF J = 2 0.02 0.18 1.02 J = 3 0.02 0.20 1.11 J = 5 0.02 0.45 1.12 J = 8 0.02 0.65 1.16 Now, we show that this increase of performance comes at the price of an increased computational cost. Indeed, the computational complexity of the α-SSF method is O P 4 P 4 K 5 N 3 + JP 3 K 2 N , where P is the number of samples for the discretization of integrals in <ref type="bibr" target="#b9">(10)</ref> wrt. the Lebesgue measure, while for α-CMF it is O IJK 4 P 4 N , where I denotes the number of iterations performed in Algorithm 3. The number P and P of cells used to sample S K inherently depends on K, and increase exponentially according to the curse of dimensionality (see Bellman <ref type="bibr" target="#b2">[3]</ref>). This explains why evaluations are only performed when K = 2, and suggests an important research direction to scale the proposed method to higher spatial dimensions. In Table <ref type="table" target="#tab_0">1</ref>, we report the average computing time for the different methods to process N = 2000 samples, as observed with our Python implementation running on a regular small laptop computer with an i7-4810MQ CPU and 32 GB of RAM. We observe that the MWF method is the fastest, followed by α-CMF and by α-SSF. Analyzing the methods further, we observe that a large part of the computing time for α-SSF is spent on computing g X (x, θ), so that separating additional components J doesn't yield a significant increase in computational load, as for MWF.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4.">Filtering spatially scattered sources</head><p>In the preceding sections, we estimated components whose spatial density Γ j was a simple VMF distribution, hence corresponding to only one direction of arrival µ j , with some variations brought in by the concentration parameter κ j . We now investigate more diverse spatial densities, where each (real) source is characterized by several directions of arrival. This is done by taking each Γ j as a mixture of C VMF distributions:</p><formula xml:id="formula_57">∀j, Γ j (dθ) = c w jc V µ jc ,κjc (dθ) ,</formula><p>where V µ jc ,κjc is defined in <ref type="bibr" target="#b27">(28)</ref> and w jc ∈ [0, 1] are weight parameters, such that ∀j, c w jc = 1. Examples of realizations for such models are depicted in Fig. <ref type="figure" target="#fig_2">2</ref> for K = 2.</p><p>We considered 5 regularly spaced α ∈ [1.2, 2] and the separation of N = 2000 i.i.d. samples from J = 4 components, whose spatial densities Γ j are mixtures of C = 2, 3, 4 VMF distributions, with parameters w jc , µ jc and κ jc drawn randomly anew for each of the 100 experiments. The circle is uniformly divided into P = 360 arcs. Results for this experiment are depicted in Fig. <ref type="figure" target="#fig_10">8</ref>, giving the MAE as a function of the number C of directions of arrivals for each component. We see that α-SSF slightly outperforms the other proposed methods and that the performance is overall not so sensitive to the number of components. We believe that the slight gain brought in by α-SSF can be explained by the fact that it is a non-linear filter and may hence better handle more sophisticated spatial models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusion &amp; Future works</head><p>In this paper, we showed how the multivariate symmetric α-stable (SαS) distribution can be used in filtering applications.</p><p>An SαS distribution features remarkably heavy tails, that permit the modeling of signals with very large dynamics. As we showed, an SαS vector is characterized by a spatial density, that indicates the amount of energy originating from every direction in space. It hence naturally relaxes the common assumption of deterministic directions of arrival made for multivariate observations. One key asset of this model is then to straightforwardly extend to mixtures of such vectors, owing to the stability property of their distributions.</p><p>Equipped with such a powerful multivariate probabilistic model, we proposed several filters able to recover SαS vectors from the observation of their sum. The first one relies on a spatial spectrum decomposition and may be understood as the combination of a nonlinear beamformer followed by a scalar filter. The second one enforces linear filtering and minimizes the covariation of the difference between estimates and target. As we show, these filters generalize the classical multivariate Wiener filter to heavy-tailed signals.</p><p>Throughout the paper, we considered the separation of real and complex SαS vectors. A very straightforward application of these developments is the filtering of multivariate time series, via their short-time Fourier transforms. Indeed, this would simply mean generalizing the recently proposed α-harmonizable processes (Liutkus and Badeau <ref type="bibr" target="#b20">[21]</ref>) to the multivariate case.</p><p>A natural route for future work is the combination of such filters with effective parameter estimation techniques similar to those presented in (Fontaine et al. <ref type="bibr" target="#b14">[15]</ref>). All together, they would form a principled processing pipeline for heavy-tailed and impulsive multivariate signals. Furthermore, finding a way to proceed to the required integrations over the hypersphere without a bruteforce partitioning as done here would allow the use of the proposed method in high-dimensional settings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>AppendixA. Proofs</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>1-Proof of spatial representation theorem</head><p>If K = C, by substituting in the theorem 6.3.4. in (Samoradnitsky and Taqqu <ref type="bibr">[35, p. 284]</ref>), the terms:</p><formula xml:id="formula_58">E = S K , x = θ, M (dx) = X (dθ) , m (dx) = Γ x (dθ) , d = K, j = k, z j = u k , T = [1 . . . K] , t j = k, f tj (x) = x tj = θ k</formula><p>we get that the chf. of θ∈S K θX (dθ) is:</p><formula xml:id="formula_59">∀u ∈ C K , E exp i u, S K θ X (dθ) = exp - S K | u, θ | α Γx (dθ) . (A.1)</formula><p>The right side of (A.1) is exactly the chf. of x. This identification achieves the proof of Theorem 4.</p><p>If K = R, (2) can be demonstrated by applying the theorem 3.5.6. in (Samoradnitsky and Taqqu <ref type="bibr">[35, p 131]</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2-Proof of spatial spectrum estimation Proof of Proposition 5</head><p>Let ∀v ∈ K, c (v) ϕ θ∈S K ψ(θ)X (dθ)|x (v). Note that if the first derivative exists (in the sense of the Wirtinger derivatives), we have:</p><formula xml:id="formula_60">E θ∈S K ψ (θ) X (dθ) | x = -i dc dv (v = 0) . (A.2)</formula><p>In order to find a suitable form of c, we start by calculating the joint chf. of θ∈S K ψ (θ) X (dθ) and x, ∀v ∈ K, ∀u ∈ K K : ϕ ( θ∈S K ψ(θ)X (dθ),x) (v, u) E e i (v * θ∈S K ψ(θ) X (dθ)+ u,x )</p><p>= E e i ( θ∈S K (v * ψ(θ)+ u,θ ) X (dθ))</p><p>= ϕ θ∈S K (v * ψ(θ)+ u,θ ) X (dθ) (1) = e -θ∈S K |v * ψ(θ)+ u,θ | α Γx(dθ) , where the last equality holds because θ∈S K (v * ψ (θ) + u, θ ) X (dθ) ∼ SαS K c θ∈S K |v * ψ(θ) + u, θ | α Γ x (dθ) . Thus, c has the following form: ∀v ∈ K, c(v) = u∈K K ϕ θ∈S K ψ(θ)X (dθ),x (v, u) e -i ( u,x ) du u∈K K ϕ x (u) e -i ( u,x ) du = u∈K K e -θ∈S K |v * ψ(θ)+ u,θ | α Γx(dθ) e -i ( u,x ) du u∈K K ϕ x (u) e -i ( u,x ) du .</p><p>(A.</p><p>3)</p><p>The existence of dc dv (v = 0) is because ν → u∈K K ϕ θ∈S K ψ(θ)X (dθ),x (v, u) e -i ( u,x ) du is the Fourier transform of a characteristic function whose first derivative exists because α &gt; 1 (if a random vector admits a 1 st order moment, then its characteristic function is continuously differentiable at zero). Consequently, by using the differentiation under the integral sign theorem (the domination is induced by the fact that a chf. is bounded by 1) and by combining (A.2) and (A.3) we obtain:</p><formula xml:id="formula_61">E θ∈S K ψ (θ) X (dθ) | x</formula><p>= αi u∈K K ( θ∈S K ψ(θ) θ,u α-1 Γx(dθ))ϕx(u)e -i ( u,x ) du u∈K K ϕx(u)e -i ( u,x ) du = θ∈S K ψ (θ)</p><p>αi u∈K K θ,u α-1 ϕx(u) e -i ( u,x ) du u∈K K ϕx(u) e -i ( u,x ) du Γ x (dθ) = θ∈S K ψ (θ) g X (x, θ) Γ x (dθ) .</p><p>(A.4)</p><p>where we have used <ref type="bibr" target="#b6">(7)</ref>. Equation ( <ref type="formula" target="#formula_15">6</ref>) is obtained by identifying (A.4) with ( <ref type="formula" target="#formula_14">5</ref>) for any continuous function ψ (θ).</p><p>Proof of Proposition 5 about continuity ∀u ∈ K K , θ → h (θ, u) = θ, u α-1 ϕ x (u) e -i ( u,x ) is a continuous function. Moreover, the probability density function (pdf.) of an SαS c (nondegenerated) distribution is infinitely continuous. As a result, the characteristic function ϕ x (u) for all u ∈ K K (which is the Fourier transform of a pdf.) decreases faster than any power of u (where . is any norm on K K ). In particular, u → f (u) = u α-1 |ϕ x (u)| is integrable. Besides, ∀θ ∈ S K , θ, u α-1 ≤ u α-1 and ∀u ∈ K K , |h (θ, u)| ≤ f (u). By applying the theorem of continuity under the integral sign, we conclude that g X (x, θ) is a continuous function of θ.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Proof of Proposition 6</head><p>We consider the numerator N (x, θ) of g X (x, θ) in ( <ref type="formula" target="#formula_17">8</ref>) and apply the change of variables u rθ ∈ K K where r ∈ R + and θ ∈ S K , which is such that du = r βK-1 drdθ . Then we get:</p><formula xml:id="formula_62">N (x, θ) = i θ ∈S K θ, θ α-1 r∈R + αr α-1 e -r α Ix(θ )</formula><p>r βK-1 e -ir ( θ ,x ) dr dθ .</p><p>Applying an integration by parts to r∈R + αr α-1 e -r α Ix(θ ) r βK-1 e -ir ( θ ,x ) dr yields:</p><p>N (x, θ) = A (θ, x) + (βK -1) iB (θ, x) which permits us to deduce the chf. of y j given x, ∀v ∈ K K : ϕ y j |x (v) = u∈K K e -θ∈S K | v+u,θ | α Γ j (dθ)j =j θ∈S K | u,θ | α Γ j (dθ) e -i ( u,x ) du u∈K K ϕx(u)e -i ( u,x ) du .</p><p>The proof of the existence of ∇ v ϕ y j |x is exactly the same as in Proposition 5. Thus, we get:</p><formula xml:id="formula_63">E y j | x = -i∇ v ϕ y j |x (v = 0) = θ∈S K</formula><p>θ αi u∈K K u, θ α-1 ϕx (u) e -i ( u,x ) du u∈K K ϕx (u) e -i ( u,x ) du</p><formula xml:id="formula_64">Γ j (dθ) = θ∈S K θ g X (x, θ) Γ j (dθ) ,</formula><p>which completes the proof.</p><p>------</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>2. 1 .</head><label>1</label><figDesc>Isotropic symmetric α-stable random variables</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: SαS 1 c density probability functions in the real case with σ = 1</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Spatial densities in the real case with K = 2. On the left, density plots of y 1 ∼ SαS K c (Γ 1 ) (in green) and y 2 ∼ SαS K c (Γ 2 ) (in red), where the maxima of Γ 1 and Γ 2 are reached for 5π 8 , 5π 8 + π</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>α = 1.3 η R , α = 1.3(a) η and η for α = 1.3 and β = 1 . MSE as a function of α.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Performance of a parametric fit η for η in (11) .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Two Spatial Von-Mises densities Γ 1 , Γ 2 on the semicircle with respective mean directions µ 1 = π 3 , µ 2 = π 2 and concentration κ = 15. The red area indicates the overlap between the spatial densities.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 5 :</head><label>5</label><figDesc>Figure5: MAE box plot (lower is better) of MWF, α-CMF and α-SSF methods for several angular deviations between spatial densities and α = 1.6. The box plots shows the minimum and maximum for whiskers, and 75th/25th percentiles for boxes.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: MAE performance (lower is better) as a function of α, for a distance of 25 degrees between the sources.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: MAE averaged over all sources for α ∈ [1.2, 2]. The solid lines display the median, and the light areas the standard deviation of each method.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 8 :</head><label>8</label><figDesc>Figure 8: MAE boxplot for α = 1.4.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Elapsed time (in sec., lower is better) for each filtering method.</figDesc><table /></figure>
		</body>
		<back>

			<div type="funding">
<div><p>$ This work was partly supported by the research programmes <rs type="projectName">KAMoulox</rs> (<rs type="grantNumber">ANR-15-CE38-0003-01</rs>) and <rs type="projectName">EDiSon3D</rs> (<rs type="grantNumber">ANR-13-CORD-0008-01</rs>) funded by <rs type="funder">ANR</rs>, the <rs type="funder">French State agency</rs> for research.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funded-project" xml:id="_BkBYtCF">
					<idno type="grant-number">ANR-15-CE38-0003-01</idno>
					<orgName type="project" subtype="full">KAMoulox</orgName>
				</org>
				<org type="funded-project" xml:id="_wNNxACw">
					<idno type="grant-number">ANR-13-CORD-0008-01</idno>
					<orgName type="project" subtype="full">EDiSon3D</orgName>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>where</p><p>r βK-1 e -r α Ix(θ ) e -ir ( θ ,x ) dr dθ</p><p>r βK-2 e -r α Ix(θ ) e -ir ( θ ,x ) dr dθ .</p><p>By developing the complex exponential as a power series and by applying the identity +∞ 0</p><p>x</p><p>to both integrals A (θ, x) and B (θ, x), we get:</p><p>where</p><p>. Finally, we remark from <ref type="bibr" target="#b7">(8)</ref> that N (zx, θ) = zN (x, θ) , ∀z ∈ S 1 K , which shows that in (A.5), all odd values of n, and all values of k different from n 2 +1, can be discarded (the corresponding terms vanish when integrated). In the same way, in (A.6), all even values of n, and all values of k different from n+1 2 , can be discarded, which finally leads to <ref type="bibr" target="#b9">(10)</ref> and <ref type="bibr" target="#b10">(11)</ref>. Equation (11) defines a power series with an infinite radius of convergence when α &gt; 1, which is smooth and independent the mixing model.</p><p>The estimate of x → D (x) is obtained by noting that:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Proof of Theorem 7</head><p>We first determine the joint chf. of y j and x: ∀v, u ∈ K K , ϕ (y j ,x) (v, u) E e i ( v,y j + u,x )</p><p>= E e i ( v+u,y j + j =j u,y j ) = ϕ y j (v + u) j =j ϕ y j (u) = e -θ∈S K | v+u,θ | α Γj (dθ)-j =j θ∈S K | u,θ | α Γ j (dθ) ,</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">SAR image filtering based on the heavy-tailed Rayleigh model</title>
		<author>
			<persName><forename type="first">A</forename><surname>Achim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">E</forename><surname>Kuruoglu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zerubia</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="2686" to="2693" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Greek folk music denoising under a symmetric α-stable noise assumption</title>
		<author>
			<persName><forename type="first">N</forename><surname>Bassiou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Kotropoulos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Pitas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">10th International Conference on Heterogeneous Networking for Quality, Reliability, Security and Robustness (QShine)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="18" to="23" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Dynamic programming</title>
		<author>
			<persName><forename type="first">R</forename><surname>Bellman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013">2013</date>
			<publisher>Courier Corporation</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Audio source separation with a single sensor</title>
		<author>
			<persName><forename type="first">L</forename><surname>Benaroya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Bimbot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Gribonval</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Audio, Speech, and Language Processing</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="191" to="199" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Convex optimization</title>
		<author>
			<persName><forename type="first">S</forename><surname>Boyd</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Vandenberghe</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004">2004</date>
			<publisher>Cambridge university press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">On the theory of elliptically contoured distributions</title>
		<author>
			<persName><forename type="first">S</forename><surname>Cambanis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Simons</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Multivariate Analysis</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="368" to="385" />
			<date type="published" when="1981">1981</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Blind signal separation: statistical principles</title>
		<author>
			<persName><forename type="first">J.-F</forename><surname>Cardoso</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="volume">86</biblScope>
			<biblScope unit="page" from="2009" to="2025" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Unmixing dynamic pet images: combining spatial heterogeneity and non-gaussian noise</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Cavalcant</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Oberlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Dobigeon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Févotte</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Stute</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Taube</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICASSP 2019-2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1373" to="1377" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Handbook of Blind Source Separation: Independent component analysis and applications</title>
		<author>
			<persName><forename type="first">P</forename><surname>Comon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Jutten</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010">2010</date>
			<publisher>Academic press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Non-negative matrix factorization for single-channel eeg artifact rejection</title>
		<author>
			<persName><forename type="first">C</forename><surname>Damon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Liutkus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gramfort</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Essid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2013 IEEE International Conference on Acoustics, Speech and Signal Processing</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="1177" to="1181" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Under-determined reverberant audio source separation using a full-rank spatial covariance model</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">Q K</forename><surname>Duong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Vincent</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Gribonval</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010-09">Sept. 2010</date>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="1830" to="1840" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Additive gaussian processes</title>
		<author>
			<persName><forename type="first">D</forename><surname>Duvenaud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Nickisch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Rasmussen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in neural information processing systems</title>
		<imprint>
			<biblScope unit="page" from="226" to="234" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Generalized additive models for functional data</title>
		<author>
			<persName><forename type="first">M</forename><surname>Febrero-Bande</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>González-Manteiga</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Test</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="278" to="292" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Explaining the parameterized Wiener filter with alpha-stable processes</title>
		<author>
			<persName><forename type="first">M</forename><surname>Fontaine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Liutkus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Girin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Badeau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of Workshop on Applications of Signal Processing to Audio and Acoustics (WAS-PAA)</title>
		<meeting>of Workshop on Applications of Signal essing to Audio and Acoustics (WAS-PAA)</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Scalable source localization with multichannel alpha-stable distributions</title>
		<author>
			<persName><forename type="first">M</forename><surname>Fontaine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Vanwynsberghe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Liutkus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Badeau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of 25th European Signal Processing Conference (EUSIPCO)</title>
		<meeting>of 25th European Signal essing Conference (EUSIPCO)</meeting>
		<imprint>
			<date type="published" when="2017-08">Aug. 2017</date>
			<biblScope unit="page" from="11" to="15" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Digital audio restoration. Applications of digital signal processing to audio and acoustics</title>
		<author>
			<persName><forename type="first">S</forename><surname>Godsill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Rayner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Cappé</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="133" to="194" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">A Bayesian approach to the restoration of degraded audio signals</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Godsill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J W</forename><surname>Rayner</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995">1995</date>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="267" to="278" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">On the spectral representation of symmetric stable processes</title>
		<author>
			<persName><forename type="first">J</forename><surname>Hardin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">D</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Multivariate Analysis</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="385" to="401" />
			<date type="published" when="1982">1982</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Blind separation of heavy tail signals</title>
		<author>
			<persName><forename type="first">P</forename><surname>Kidmose</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001">2001</date>
			<pubPlace>Denmark</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Technical University of Denmark, Kongens Lyngby</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D. thesis</note>
	<note>Institute of Mathematical Modelling</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Student&apos;s t multichannel nonnegative matrix factorization for blind source separation</title>
		<author>
			<persName><forename type="first">K</forename><surname>Kitamura</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bando</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Itoyama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Yoshii</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2016 IEEE International Workshop on Acoustic Signal Enhancement (IWAENC)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="1" to="5" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Generalized Wiener filtering with fractional power spectrograms</title>
		<author>
			<persName><forename type="first">A</forename><surname>Liutkus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Badeau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of International Conference on Acoustics, Speech and Signal Processing (ICASSP)</title>
		<meeting>of International Conference on Acoustics, Speech and Signal essing (ICASSP)</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="266" to="270" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Gaussian processes for underdetermined source separation</title>
		<author>
			<persName><forename type="first">A</forename><surname>Liutkus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Badeau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Richard</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="page" from="3155" to="3167" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Parameter estimation and blind channel identification in impulsive signal environments</title>
		<author>
			<persName><forename type="first">X</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Nikias</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on signal processing</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2884" to="2897" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">The Pareto-Lévy law and the distribution of income</title>
		<author>
			<persName><forename type="first">B</forename><surname>Mandelbrot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Economic Review</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="79" to="106" />
			<date type="published" when="1960-05">May 1960</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Practical variable selection for generalized additive models</title>
		<author>
			<persName><forename type="first">G</forename><surname>Marra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wood</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Statistics &amp; Data Analysis</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="2372" to="2387" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Alpha-stable signals and adaptive filtering</title>
		<author>
			<persName><forename type="first">E</forename><surname>Masry</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="page" from="3011" to="3016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">On the decomposition of Mars hyperspectral data by ICA and Bayesian positive source separation</title>
		<author>
			<persName><forename type="first">S</forename><surname>Moussaoui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Hauksdottir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Schmidt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Jutten</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chanussot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Brie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Douté</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Benediktsson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">71</biblScope>
			<biblScope unit="issue">10-12</biblScope>
			<biblScope unit="page" from="2194" to="2208" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Signal processing with alpha-stable distributions and applications</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">L</forename><surname>Nikias</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Shao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Adaptive and learning systems for signal processing, communications, and control</title>
		<imprint>
			<publisher>Wiley</publisher>
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Estimation of stable spectral measures</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Nolan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Panorska</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Mcculloch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mathematical and Computer Modelling</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1113" to="1122" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Deep neural network based multichannel audio source separation</title>
		<author>
			<persName><forename type="first">A</forename><surname>Nugraha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Liutkus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Vincent</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Audio Source Separation</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="157" to="185" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">An introduction to multichannel nmf for audio source separation</title>
		<author>
			<persName><forename type="first">A</forename><surname>Ozerov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Févotte</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Vincent</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Audio Source Separation</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="73" to="94" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Estimating the spectral measure of a multivariate stable distribution via spherical harmonic analysis</title>
		<author>
			<persName><forename type="first">M</forename><surname>Pivato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Seco</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Multivariate Analysis</title>
		<imprint>
			<biblScope unit="volume">87</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="219" to="240" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">An overview of lead and accompaniment separation in music</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Rafii</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Liutkus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F.-R</forename><surname>Stoter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mimilakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Fitzgerald</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Pardo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE/ACM Transactions on Audio, Speech and Language Processing (TASLP)</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1307" to="1335" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">A Student&apos;s t filter for heavy tailed process and measurement noise</title>
		<author>
			<persName><forename type="first">M</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Özkan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Gustafsson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of International Conference on Acoustics, Speech and Signal Processing (ICASSP)</title>
		<meeting>of International Conference on Acoustics, Speech and Signal essing (ICASSP)</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="5770" to="5774" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Stable non-Gaussian random processes: stochastic models with infinite variance</title>
		<author>
			<persName><forename type="first">G</forename><surname>Samoradnitsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Taqqu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1994">1994</date>
			<publisher>CRC Press</publisher>
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">A statistical analysis of telephone noise</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">W</forename><surname>Stuck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Kleiner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bell Labs Technical Journal</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1263" to="1320" />
			<date type="published" when="1974">1974</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">An introduction to sparse stochastic processes</title>
		<author>
			<persName><forename type="first">M</forename><surname>Unser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Tafti</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014">2014</date>
			<publisher>Cambridge University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">End-to-end source separation with adaptive front-ends</title>
		<author>
			<persName><forename type="first">S</forename><surname>Venkataramani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Casebeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Smaragdis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2018 52nd Asilomar Conference on Signals, Systems, and Computers</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="684" to="688" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Audio source separation and speech enhancement</title>
		<author>
			<persName><forename type="first">E</forename><surname>Vincent</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Virtanen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gannot</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
			<publisher>John Wiley &amp; Sons</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Ica by maximizing non-stability</title>
		<author>
			<persName><forename type="first">B</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Kuruoglu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Independent Component Analysis and Signal Separation</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="179" to="186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Multivariate Laplace filter: a heavytailed model for target tracking</title>
		<author>
			<persName><forename type="first">D</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of 19th International Conference on Pattern Recognition (ICPR)</title>
		<meeting>of 19th International Conference on Pattern Recognition (ICPR)</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="1" to="4" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<author>
			<persName><forename type="first">Z.-Q</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Roux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hershey</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1804.10204</idno>
		<title level="m">End-to-end speech separation with unfolded iterative phase reconstruction</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Extrapolation, interpolation, and smoothing of stationary time series</title>
		<author>
			<persName><forename type="first">N</forename><surname>Wiener</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1949">1949</date>
			<publisher>MIT press</publisher>
			<biblScope unit="volume">7</biblScope>
			<pubPlace>Cambridge, MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Generalized additive models for large data sets</title>
		<author>
			<persName><forename type="first">S</forename><surname>Wood</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Goude</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Shaw</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Royal Statistical Society: Series C (Applied Statistics)</title>
		<imprint>
			<biblScope unit="volume">64</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="139" to="155" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Student&apos;s t nonnegative matrix factorization and positive semidefinite tensor factorization for single-channel audio source separation</title>
		<author>
			<persName><forename type="first">K</forename><surname>Yoshii</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Itoyama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Goto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2016 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="51" to="55" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
