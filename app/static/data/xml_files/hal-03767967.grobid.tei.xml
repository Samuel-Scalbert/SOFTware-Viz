<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Abstra: Toward Generic Abstractions for Data of Any Model</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Nelly</forename><surname>Barret</surname></persName>
							<email>nelly.barret@inria.fr</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Inria</orgName>
								<orgName type="institution" key="instit2">Institut Polytechnique de Paris</orgName>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Inria</orgName>
								<orgName type="institution" key="instit2">Institut Polytechnique de Paris</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Ioana</forename><surname>Manolescu</surname></persName>
							<email>~ioana.manolescu@inria.fr</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Inria</orgName>
								<orgName type="institution" key="instit2">Institut Polytechnique de Paris</orgName>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Inria</orgName>
								<orgName type="institution" key="instit2">Institut Polytechnique de Paris</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Prajna</forename><surname>Upadhyay</surname></persName>
							<email>~prajna-devi.upadhyay@inria.fr</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Inria</orgName>
								<orgName type="institution" key="instit2">Institut Polytechnique de Paris</orgName>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Inria</orgName>
								<orgName type="institution" key="instit2">Institut Polytechnique de Paris</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Abstra: Toward Generic Abstractions for Data of Any Model</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">CE10D814246A43FE2E780D654DE109C6</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-04-12T14:46+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Digital data sharing leads to unprecedented opportunities to develop data-driven systems for supporting economic activities, the social and political life, and science. Many open-access datasets are RDF (Linked Data) graphs, but others are JSON or XML documents, CSV files, Neo4J property graphs, etc.</p><p>Potential users need to understand a dataset in order to decide if it is useful for their goal. While some published datasets come with a schema and/or documentation, this is not always the case.</p><p>We demonstrate Abstra, a dataset abstraction system, which applies on a large variety of data models. Abstra computes a description meant for humans, and integrates Information Extraction to classify dataset content among a set of categories of interest to the user. Our abstractions are conceptually close to Entity-Relationship diagrams, but our entities can have deeply nested structure.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Open-access data being shared over the Internet enabled the development of new businesses, economic opportunities and applications; it also leads to circulating knowledge on health, education, environment, the arts, science, news, etc.</p><p>The World Wide Web Consortium's recommended data sharing format is as RDF (Linked data) graphs. However, in practice, other formats are also widely used. For instance, bibliographic notices on PubMed, a leading medical scientific site, are available in XML; JSON is increasingly used, e.g., on social networks; CSV files are shared on portals such as Kaggle. Relational databases are sometimes shared as dumps, including schema constraints such as primary and foreign keys, or as CSV files; property graphs <ref type="bibr" target="#b2">[3]</ref> (PGs, in short, such as pioneered by Neo4J) are used to share Offshore leaks, a journalistic database of offshore companies, etc.</p><p>Users who must decide whether to use a dataset in an application need a basic understanding of its content and the suitability to their need. Towards this goal, schemas may be available to describe the data structure, yet they have some limitations. (ùëñ) Schemas are often unavailable for semistructured datasets (XML, JSON, RDF, PGs). Even when a schema is supplied with or extracted from the data, e.g., <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b22">23]</ref>. (ùëñùëñ) Schema syntactic details, such as regular expressions, etc., are hard to interpret for non-expert users. (ùëñùëñùëñ) A schema focuses primarily on the dataset structure, not on its content. It does not exploit the linguistic information encoded in node names, in the string values the dataset may contain, etc. (ùëñùë£) Schemas employ the data producer's terminology, not the concepts of interest to users. (ùë£) Schemas do not quantitatively reflect the dataset, whereas knowing "what is the main content of a dataset" can be very helpful for a first acquaintance with it. Data summaries can be built from semistructured data, e.g., <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b11">12]</ref>, but they may still be quite large, and they do not reflect user interest. An RDF dataset may come with an ontology describing its semantics, which is a step toward lifting limitation (ùëñùëñùëñ); but, all the others still apply. Mining for patterns <ref type="bibr" target="#b14">[15]</ref> allows to find popular motifs, e.g., items often purchased together. This avoids shortcomings (ùëñ) and (ùë£), but not the others. Dataset documentation, when well-written, is most helpful. However, it still suffers from the issues (ùëñ) and (ùëñùë£) above: it is often lacking, and it reflects the producer's view. In a data lake context, <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b19">20]</ref> discovers, extracts, and summarizes structural metadata, and annotates data and metadata with semantic information. However, they focus on rooted or hierarchical data, while we also handle graphs (RDF or PGs) that may be cyclic, and our abstractions can also capture such cyclic relationships when present in the data.</p><p>We propose to demonstrate Abstra, a all-in-one system for abstracting any relational, CSV, XML, JSON, RDF or PG dataset. Abstra is based on the idea that any dataset comprises some records, typically grouped in collections (which we view as sets). Records describe entities or relationships in the classical conceptual database design sense <ref type="bibr" target="#b20">[21]</ref>; Abstra entities can have deeply nested structure. When several collections of entities co-exist in a dataset, relationships typically connect them. Abstra proceeds as follows.</p><p>(1). Given any dataset, Abstra models it as a graph, and identifies collections of equivalent nodes, leveraging graph structural summarization, as we describe in Section 2.</p><p>(2). Among the collections, Abstra detects a few main collections, which together, hold a large part of the dataset contents. Each collection contains a set of similar, potentially deeply nested records. The challenge here is to detect, in the data graph, the nodes and edges that are "part of" each main collection record, and to do so efficiently even if the graph has complex, cyclic structure. This is addressed by introducing a notion of data weight and exploiting it as we describe in Section 3.</p><p>(3). Abstra attempts to classify each main collection into a given semantic category, such as Person, Product, Geographi-calPosition, etc., based on semantic resources resulting from prior work <ref type="bibr" target="#b15">[16]</ref>. The classification also leverages Information Extraction to detect the presence of entities in the data values, as well as language models to detect proximity between the dataset vocabulary, and the target categories (Section 4).</p><p>Abstra outputs a Entity-Relationship style diagram of the main, classified collections, together with the possible relationships in which they participate; this description is free of any data modelspecific details. For instance, given an XMark <ref type="bibr" target="#b21">[22]</ref> XML document describing an online auctions site, containing 2.3M nodes with 80 different labels, Abstra returns: "A collection of Person entities, a collection of Product, and a collection of category" (the latter are used to describe the items for sale). Users can explore entities, and/or sample entity instances, through an interactive GUI (see <ref type="bibr">Section 5)</ref>.</p><p>Below, we describe the abstraction steps and outline the demonstration scenarios before concluding. Abstra examples and a video can be found at: https://team.inria.fr/cedar/projects/abstra/.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">BUILDING A COLLECTION GRAPH</head><p>We first explain how any dataset is converted in a graph representation (Section 2.1), before partitioning it and constructing the central tool of our method, the collection graph (Section 2.2).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Graph representation of any dataset</head><p>The graph representation we start from has been introduced in ConnectionLens [2, 9], a graph-based heterogeneous data integration system, to which we bring some modifications. Any relational, XML, JSON, RDF, or PG dataset is turned into a directed graph ùê∫ 0 = (ùëÅ 0 , ùê∏ 0 , ùúÜ 0 ) where ùê∏ 0 ‚äÜ ùëÅ 0 √ó ùëÅ 0 is a set of directed edges, and ùúÜ 0 is a function labeling each node and edge with a string label, that could in particular be ùúñ (the empty label). XML trees and RDF graphs naturally map into this modeling. JSON documents are modeled as trees. To the extent possible, we attach meaningful, non-empty names to nodes, as illustrated in Figure <ref type="figure" target="#fig_0">1</ref> on a sample JSON snippet. We move the labels of edges which connect a map parent to its children, on the child nodes, and we label the children of an array node with label of their parent, to which we concatenate . (a dot).</p><p>Below, we focus only on the most irregular data formats, i.e. XML, JSON and RDF. CSV files, relational databases and PGs are easily converted into graphs <ref type="bibr" target="#b1">[2]</ref> and can be similarly handled.</p><p>In ùê∫ 0 , some edges have empty (ùúñ) labels, while other edges are labeled. For uniformity, Abstra transforms ùê∫ 0 into a normalized graph ùê∫, copying all the nodes of ùê∫ 0 and all its ùúñ-label edges, and replacing each ùê∫ 0 edge of the form ùëõ 1 ùëô -‚Üí ùëõ 2 where ùëô ‚â† ùúñ by two unlabeled edges ùëõ 1 ‚Üí ùë• ùëô , ùë• ùëô ‚Üí ùëõ 2 where ùë• ùëô is a new intermediary node labeled ùëô. All subsequent Abstra steps apply on the normalized graph ùê∫.</p><p>Figure <ref type="figure" target="#fig_1">2</ref> shows a sample bibliographic data graph ùê∫. It depicts three papers (one partially shown), which are published in (pIn) conferences. The papers are written by (wb) authors, described by their name and email. Note the inverse "has written" (hW) edges going from papers to their authors. Author 21 is invited (inv) by the conference organizers. As Figure <ref type="figure" target="#fig_1">2</ref> shows, the graph may contain: (ùëñ) nodes such as papers, whose information content is deeply </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Partitioning nodes into collections</head><p>To leverage structural information present in ùê∫, we partition the graph nodes ùëÅ into a set of pairwise disjoint node sets ùê∂ ùëñ .We say the nodes from a given set ùê∂ ùëñ are equivalent, and call ùê∂ ùëñ an equivalence class. Many node partitioning schemes, a.k.a. quotient summaries, exist <ref type="bibr" target="#b7">[8]</ref>. We need a method that is robust to heterogeneity, i.e., it can recognize the various papers in Figure <ref type="figure" target="#fig_1">2</ref> even though they have heterogeneous structure, and efficiently computed (ideally in linear time in the size of ùê∏). For RDF graphs, we use Type Strong summarization <ref type="bibr" target="#b10">[11]</ref>, which satisfies these requirements; it leverages RDF types when available, but can also identify interesting equivalence classes without them. We extend it also to PGs and graphs derived from CSV files and relational databases. For graphs derived from XML or JSON as discussed in Section 2.1, we simply partition the nodes by their labels. On the graph in Figure <ref type="figure" target="#fig_1">2</ref>, the equivalence classes are: {1, 40}; {6, 8, 38}; {20, 21, 23}, etc.; there is one class for each distinct label of non-leaf nodes, and one class for each set of leaf nodes whose parents are equivalent.</p><p>We call collection graph the graph whose nodes are the collections ùê∂ ùëñ , and having an edge ùê∂ ùëñ ‚Üí ùê∂ ùëò if and only if for some nodes ùëõ ùëñ ‚àà ùê∂ ùëñ , ùëõ ùëó ‚àà ùê∂ ùëó , ùëõ ùëñ ‚Üí ùëõ ùëó ‚àà ùê∏. Figure <ref type="figure" target="#fig_2">3</ref> shows the collection graph corresponding to the graph in Figure <ref type="figure" target="#fig_1">2</ref>. Here, in each collection, all nodes have the same label, shown in the collection; this does not hold in general, e.g., in a collection of RDF nodes, each node has a different label. The label year# is used to denote the collection of text children of the nodes from the collection with the label year and similarly for the others whose label end in #. The dw attributes will be discussed in Section 3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">IDENTIFYING THE MAIN ENTITIES TO REPORT AND THEIR RELATIONSHIPS</head><p>Among the collections C, some are more representative of the dataset than others, e.g., in Figure <ref type="figure" target="#fig_2">3</ref>, paper seems a better candidate than its child collection year. However, we cannot select "the parent (or root) collection(s)", as the collection graph may lack a root node, if it is cyclic as in Figure <ref type="figure" target="#fig_2">3</ref> (cycle edges are shown in red). Even if a root collection exists, it may not be the best choice. For instance, consider XHTML search results grouped in pages, of the form ‚ü®top‚ü© ‚ü®page‚ü© ‚ü®result‚ü©...‚ü®/result‚ü© ‚ü®result‚ü©... ‚ü®/result‚ü© ‚ü®/page‚ü© ‚ü®page‚ü©... ‚ü®/page‚ü© ... ‚ü®/top‚ü©. Here, the top collection is that of pages, but the actual data is in the results, thus, "a collection of results" is a better abstraction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Overview of the method</head><p>A high-level view of our method is the following (concrete details will be provided below):</p><p>(1) Selecting the main entities (Section 3.2): (a) We assign to each collection a weight, and to each edge in the collection graph, a transfer factor. (b) We propagate weights in the collection graph, based on the weights and transfer factors, to assign to each collection a score that reflects not only its own weight, but also its position in the graph. (c) In a greedy fashion, we select the main entities by repeating: (i) Select the collection node ùê∂ ùê∏ currently having the highest score, as a root of a main entity; (ii) Determine the boundary of the entity ùê∂ ùê∏ : this is a connected subgraph of the collection graph, containing ùê∂ ùê∏ . We consider all this subgraph as part of ùê∂ ùê∏ , which will be reported to users including all its boundary; (iii) Update the collection graph to reflect the selection of ùê∂ ùê∏ and its boundaries, and recompute the collection scores; until a certain maximum number ùê∏ ùëöùëéùë• of entities have been selected, or these entities together cover a sufficient fraction ùëêùëúùë£ ùëöùëñùëõ of the data.</p><p>(2) Selecting relationships between the main entity collections. These relationships will also be reported as part of the abstraction (Section 3.3).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Main entity selection</head><p>We assign to each leaf node in ùê∫ an own data weight (ùëúùë§) equal to the number of edges incoming that node. In tree data formats, ùëúùë§ is 1; in RDF, for instance, a literal that is the value of many triples may have ùëúùë§ &gt; 1. We leverage this to define the ùëúùë§ of a leaf collection as the sum of the ùëúùë§ of its nodes, e.g., in Figure <ref type="figure" target="#fig_2">3</ref>, ùëúùë§ (title#) = 2, ùëúùë§ (name#) = 5 etc. For each edge ùê∂ ùëñ ‚Üí ùê∂ ùëó in the collection graph, we define the edge transfer factor ùëì ùëó,ùëñ as the fraction of nodes in ùê∂ ùëó having a parent node in ùê∂ ùëñ ; 0 &lt; ùëì ùëñ,ùëó ‚â§ 1. Intuitively, ùëì ùëñ,ùëó of ùê∂ ùëó 's weight can also be seen as belonging to its parent ùê∂ ùëñ . For instance, there are 5 name nodes, but two belong to conferences, thus the transfer factor from name to conf is ùëì = 2/5.</p><p>We implemented two weight propagation methods.</p><p>‚Ä¢ We run the PageRank <ref type="bibr" target="#b6">[7]</ref> algorithm on the collection graph with the edge direction inverted, so that each node transfers ùëì ùëñ,ùëó of its weight to its parent. Initially, only leaf collections have non-zero ùëúùë§, but successive PageRank iterations spread their weights across the graph. We call this method PR ùëúùë§ . ‚Ä¢ Our second method, denoted prop ùëëùë§ , propagates weights still backwards, but only outside of the collection graph cycles.</p><p>Specifically, we assign to each collection a data weight ùëëùë§, which on leaf collection is initialized to ùëúùë§, and on others, to 0. Then, for each non-leaf ùê∂ ùëñ , and non cyclic path from ùê∂ ùëñ to a leaf collection ùê∂ ùëò , we increase ùëëùë§ (ùê∂ ùëñ ) by ùëì ùëò,ùëñ ‚Ä¢ ùëúùë§ (ùê∂ ùëò ).</p><p>For instance, using the second method, the collection author in Figure <ref type="figure" target="#fig_2">3</ref> obtains ùëëùë§ = 6, corresponding to 3 transferred from mail, and 3 transferred from name. The intuition behind prop ùëëùë§ is that edges that are part of cycles may have a meaning closer to "symmetric relationships between entities", than to "including a collection in another collection's boundary".</p><p>To determine entity boundaries, we proceed as follows:</p><p>‚Ä¢ When using prop ùëëùë§ , we consider part of the boundary of an entity ùê∂ ùëñ , any entity ùê∂ ùëò that transferred some weight to ùê∂ ùëñ , and all the edges along which such transfers took place. In Figure <ref type="figure" target="#fig_2">3</ref>, mail and name are within the boundary of author. "can be assimilated to an attribute of ùê∂ ùëñ ", rather than being "independent of it".</p><p>Finally, to update the graph after selecting one main entity ùê∂ ùê∏ , each leaf collection in the boundary of ùê∂ ùê∏ substracts from its own weight ùëúùë§ the fraction (at most 1.0) that it propagated to ùê∂ ùê∏ . For instance, once author is selected with name in its boundary, the ùëúùë§ of name decreases to 2. Then, the scores of all graph collections (ùëëùë§, respectively, PageRank score based on ùëúùë§) are recomputed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Relationship selection</head><p>Having selected the main entities {ùê∂ 1 ùê∏ , . . . , ùê∂ ùëöùëéùë• ùê∏ ùê∏ } and their boundaries, every oriented path in the collection graph that goes from a given ùê∂ ùëñ ùê∏ to another ùê∂ ùëó ùê∏ is reported as a relationship. For instance, in Figure <ref type="figure" target="#fig_2">3</ref>, if the main entities are author (a), with mail and name in its boundary, and paper (p) with year, title and abstract in its boundary, the relationships are: p wB ---‚Üí a, a hW ---‚Üí p, and p pIn.conf.inv ---------‚Üí a. If the scores lead to reporting three main entities, the two above and also conf (c) with name and inv in its boundary, the relationships </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Discussion</head><p>Abstra may return different results on a given dataset, depending on the scoring method used (prop ùëëùë§ or PR ùëúùë§ ), as well as the parameters: ùê∏ ùëöùëéùë• and ùëêùëúùë£ ùëöùëñùëõ (Section 3.1), and ùëì ùëöùëñùëõ (Section 3.2). Empirically, we have used ùê∏ ùëöùëéùë• ‚àà {3, 5}, ùëêùëúùë£ ùëöùëñùëõ = 0.8 and ùëì ùëöùëñùëõ = 0.3. More generally, classical Entity-Relationship (E-R) modeling is known to include a subjective factor, and for a given database, several E-R models may be correct. Our focus is on not missing any essential component of the dataset, while allowing users to limit the amount of information with ùê∏ ùëöùëéùë• , and classifying the main entities into categories, to make them as informative as possible (Section 4). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">MAIN ENTITY CLASSIFICATION</head><p>To each main entity ùê∂ thus identified, we want to associate a category from a predefined set K of semantic classes, and using also a set P of semantic properties, which have known domain and range constraints connecting them to the classes in K. We build our K and P by leveraging GitTables <ref type="bibr" target="#b15">[16]</ref>, a repository of 1.5M tables extracted from Github. For each attribute name encountered in a table, it provides candidate properties from DBPedia <ref type="bibr" target="#b3">[4]</ref> and/or schema.org (https://schema.org/); it also provides the domain and range triples corresponding to these properties. For instance, GitTable's entry for gender is:</p><p>"id":"schema:gender", "label":"gender", "range": ["schema:GenderType"], "domain":["schema:Person", "schema:SportsTeam"],</p><p>GitTables have been populated using SHERLOCK <ref type="bibr" target="#b16">[17]</ref>, a state-ofthe-art deep learning semantic annotation technique. From GitTables, we derive 4.187 P properties; 3.687 among them have domain information, and 3.898 have range statements.</p><p>The overall classification process is outlined in Figure <ref type="figure" target="#fig_4">4</ref>; solid arrows connect associated data items and trace the classification process, while dotted arrows go from a set to one of its elements.</p><p>We exploit two kinds of information attached to ùê∂:</p><p>(1) We consider each data property ùëëùëù ùëñ that ùê∂ has, such as mail for the author collection in Figure <ref type="figure" target="#fig_2">3</ref>. Out of all the values that ùëëùëù ùëñ takes on a node from ùê∂, we compute an entity profile ùúé ùê∂,ùëëùëù ùëñ , reflecting the entities extracted from these values. For instance, ùúé author, mail states that each value of the property mail contains an email (blue highlight in Figure <ref type="figure" target="#fig_1">2</ref>), and that overall, 100% of the length of these values is part of an email entity. In general, a profile may reflect the presence of entities of several types, which may span over only a small part of the property values.  the form http://ns.com/Author123, from which we extract the component after the last /, eliminate all but alphabet letters, and use the result(s), weighted by their support among ùê∂ nodes, in a similar fashion.</p><p>Finally, ùê∂ is classified with the class ùëò * ‚àà K having received the highest sum of votes. The process resembles domain inference using RDF Schema ontology constraints, with the difference that our "votes" are quantified by similarity and support, and, to keep things simple for the users, we select a single class.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">SYSTEM AND SCENARIOS</head><p>Abstra is implemented in Java, leveraging the graph creation (including entity extraction) and Postgres-based store of Connection-Lens <ref type="bibr" target="#b1">[2]</ref>. All Abstra steps scale up linearly in the data size, which we experimentally verified on datasets of up to tens of millions of edges. The main memory needs are in TypedStrong partitioning, namely ùëÇ (|ùëÅ |); other operations are implemented in SQL and benefit from Postgres' optimizations.</p><p>We have computed abstractions of dozens of synthetic benchmark datasets used in the data management literature, such as XMark <ref type="bibr" target="#b21">[22]</ref>, BSBM <ref type="bibr" target="#b5">[6]</ref>, LUBM <ref type="bibr" target="#b12">[13]</ref>, and real-life datasets about cooking, NASA flights, clean energy production, Nobel prizes, CSV datasets from Kaggle, etc. varying the data model, the number of collections and entity complexity, the presence of relations, etc. During the demonstration, users will be able to: (ùëñ) change the system parameters (Section 3.4), and see the impact on the classification results; (ùëñùëñ) edit the semantic information K and P to influence the entity classification; (ùëñùëñùëñ) edit a set of small RDF, JSON and XML examples, then abstract them to see the impact.</p><p>Abstractions are shown both as HTML text and as a lightweight E-R diagram of the main entity collections and their relationships (see Figure <ref type="figure" target="#fig_5">5</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">CONCLUSION</head><p>Abstra extracts the main entities and relationships from heterogeneousstructure datasets, leveraging Information Extraction, language models, knowledge bases, and user input to generate compact, easyto-understand abstractions, and categorize them according to user's interest. Abstra complements schema extraction <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b22">23]</ref> or data profiling <ref type="bibr" target="#b0">[1]</ref>, aimed at more technical uses and users; Abstra aims to help novice, first-time users discover and start interacting with the data. More advanced visualization techniques then be used once, see, for instance, <ref type="bibr" target="#b17">[18]</ref> for RDF graphs.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: JSON fragment (top) and its original graph representation in Abstra (bottom).</figDesc><graphic coords="3,53.80,144.04,240.23,125.26" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Sample normalized graph.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Sample collection graph corresponding to Figure 2. nested, and (ùëñùëñ) several cycles (in-cycle edges are shown in red). Within each leaf (value) node, ConnectionLens extracts named entities such as: persons (highlighted in yellow), dates (pink highlight), emails (light blue), etc. Abstra leverages these in order to classify the main entity collections (Section 4).</figDesc><graphic coords="3,340.86,83.69,192.20,149.53" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Entity classification outline.</figDesc><graphic coords="5,317.96,83.69,240.23,205.50" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Sample screenshot of the Abstra GUI.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>‚Ä¢</head><label></label><figDesc>When using PR ùëúùë§ , to determine the boundary of ùê∂ ùëñ , we traverse the graph edges starting from ùê∂ ùëñ and include its neighbor node ùê∂ ùëó if and only if (ùëñ) the edge ùê∂ ùëñ ‚Üí ùê∂ ùëó has a transfer factor of at least ùëì ùëöùëñùëõ , or (ùëñùëñ) each node from ùê∂ ùëñ has at most one child in ùê∂ ùëó . The intuition for (ùëñùëñ) is that ùê∂ ùëó</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>We compare ùëëùëù ùëñ and ùúé ùê∂,ùëëùëù ùëñ to each property ùëù ‚àà P and the classes in the range of ùëù. If the property name ùëëùëù ùëñ is sufficiently similar (through word embeddings) with some property ùëù ‚àà P, and that ùúé ùê∂,ùëëùëù ùëñ is similarly sufficiently similar to a class ùëò ùëñ ‚àà K, e.g., EmailAddress, that is in the range of ùëù, this leads to a vote of ùëëùëù ùëñ for classifying ùê∂, in every classes ùëò ‚àà K such that ùëò is in the domain of ùëù. Each property ùëëùëù ùëñ may "vote" in favor of several classes, via different domain constraints; the higher the similarity between ùëëùëù ùëñ and ùëù, the more frequent ùëëùëù ùëñ is on ùê∂ nodes, the fewer domain and range constraints ùëù has, the stronger the vote is.(2) The labels of ùê∂ nodes may also "vote" toward classifying collection ùê∂. All ùê∂ nodes may have the same label, e.g.,</figDesc><table /><note><p>author, which may resemble the name of a class, e.g., Author. Or, ùê∂ nodes may all have different names, e.g., RDF URIs of</p></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Data Profiling</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Abedjan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Golab</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Naumann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Papenbrock</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Synthesis Lectures on Data Management</title>
		<imprint>
			<publisher>Morgan &amp; Claypool Publishers</publisher>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Graph integration of structured, semistructured and unstructured data for data journalism</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Anadiotis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Balalau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Conceicao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Galhardas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">Y</forename><surname>Haddad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Manolescu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Merabti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>You</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021-07">July 2021</date>
		</imprint>
		<respStmt>
			<orgName>Information Systems</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">The property graph database model</title>
		<author>
			<persName><forename type="first">R</forename><surname>Angles</surname></persName>
		</author>
		<ptr target="-WS.org" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12th Alberto Mendelzon International Workshop on Foundations of Data Management</title>
		<title level="s">CEUR Workshop Proceedings. CEUR</title>
		<editor>
			<persName><forename type="first">D</forename><surname>Olteanu</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">B</forename><surname>Poblete</surname></persName>
		</editor>
		<meeting>the 12th Alberto Mendelzon International Workshop on Foundations of Data Management<address><addrLine>Cali, Colombia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018">May 21-25, 2018. 2100. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">DBpedia: A nucleus for a web of open data</title>
		<author>
			<persName><forename type="first">S</forename><surname>Auer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Semantic Web</title>
		<meeting><address><addrLine>Berlin, Heidelberg; Berlin Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="722" to="735" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Human-in-the-loop schema inference for massive JSON datasets</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Baazizi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Berti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Colazzo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Ghelli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Sartiani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EDBT</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">The Berlin SPARQL benchmark</title>
		<author>
			<persName><forename type="first">C</forename><surname>Bizer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Schultz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJSWIS</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1" to="24" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">The anatomy of a large-scale hypertextual web search engine</title>
		<author>
			<persName><forename type="first">S</forename><surname>Brin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Page</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Networks</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">1-7</biblScope>
			<biblScope unit="page" from="107" to="117" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Summarizing Semantic Graphs: A Survey</title>
		<author>
			<persName><forename type="first">S</forename><surname>Cebiric</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Goasdou√©</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Kondylakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Kotzinos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Manolescu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Troullinou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zneika</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The VLDB Journal</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2019-06">June 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">ConnectionLens: Finding connections across heterogeneous data sources (demonstration)</title>
		<author>
			<persName><forename type="first">C</forename><surname>Chanial</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Dziri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Galhardas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Leblay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">L</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Manolescu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PVLDB</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">12</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Schemas for safe and efficient XML processing</title>
		<author>
			<persName><forename type="first">D</forename><surname>Colazzo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Ghelli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Sartiani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICDE</title>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">RDF graph summarization for first-sight structure discovery</title>
		<author>
			<persName><forename type="first">F</forename><surname>Goasdou√©</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Guzewicz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Manolescu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The VLDB Journal</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">5</biblScope>
			<date type="published" when="2020-04">Apr. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">DataGuides: Enabling query formulation and optimization in semistructured databases</title>
		<author>
			<persName><forename type="first">R</forename><surname>Goldman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Widom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">VLDB</title>
		<imprint>
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">LUBM: A benchmark for OWL knowledge base systems</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Heflin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Web Semantics</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">2-3</biblScope>
			<biblScope unit="page" from="158" to="182" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Constance: An intelligent data lake system</title>
		<author>
			<persName><forename type="first">R</forename><surname>Hai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Geisler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Quix</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 international conference on management of data</title>
		<meeting>the 2016 international conference on management of data</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="2097" to="2100" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Data mining concepts and techniques</title>
		<author>
			<persName><forename type="first">J</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kamber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Pei</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012">2012</date>
			<publisher>Morgan Kaufmann Publishers</publisher>
		</imprint>
	</monogr>
	<note>third edition</note>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">GitTables: A large-scale corpus of relational tables</title>
		<author>
			<persName><forename type="first">M</forename><surname>Hulsebos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">√á</forename><surname>Demiralp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Groth</surname></persName>
		</author>
		<idno>CoRR, abs/2106.07258</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Sherlock: A Deep Learning Approach to Semantic Data Type Detection</title>
		<author>
			<persName><forename type="first">M</forename><surname>Hulsebos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bakker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Zgraggen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Satyanarayan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kraska</surname></persName>
		</author>
		<author>
			<persName><forename type="first">√á</forename><surname>Demiralp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A</forename><surname>Hidalgo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGKDD Explorations</title>
		<imprint>
			<date type="published" when="2019-05">May 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Visualization systems for linked datasets</title>
		<author>
			<persName><forename type="first">M</forename><surname>Krommyda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Kantere</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2020 IEEE 36th International Conference on Data Engineering (ICDE)</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="1790" to="1793" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Schema inference for property graphs</title>
		<author>
			<persName><forename type="first">H</forename><surname>Lbath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bonifati</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Harmer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EDBT. OpenProceedings.org</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Metadata extraction and management in data lakeswith gemms</title>
		<author>
			<persName><forename type="first">C</forename><surname>Quix</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Hai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Vatov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Complex Syst. Informatics Model. Q</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="67" to="83" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Database Management Systems</title>
		<author>
			<persName><forename type="first">R</forename><surname>Ramakhrishnan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gehrke</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003">2003</date>
			<publisher>McGraw-Hill</publisher>
		</imprint>
	</monogr>
	<note>3rd edition</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Xmark: A benchmark for XML data management</title>
		<author>
			<persName><forename type="first">A</forename><surname>Schmidt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Waas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">L</forename><surname>Kersten</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Carey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Manolescu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Busse</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PVLDB</title>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Reducing ambiguity in JSON schema discovery</title>
		<author>
			<persName><forename type="first">W</forename><surname>Spoth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><forename type="middle">A</forename><surname>Kennedy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Hammerschmidt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">H</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGMOD</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
