<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Empowering Investigative Journalism with Graph-based Heterogeneous Data Management</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Angelos-Christos</forename><surname>Anadiotis</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">École Polytechnique</orgName>
								<orgName type="institution" key="instit2">EPFL &amp;IPP</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Oana</forename><surname>Balalau</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">IPP</orgName>
								<orgName type="institution">Inria</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Théo</forename><surname>Bouganim</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">IPP</orgName>
								<orgName type="institution">Inria</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Francesco</forename><surname>Chimienti</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">IPP</orgName>
								<orgName type="institution">Inria</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Helena</forename><surname>Galhardas</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">INESC-ID &amp; IST</orgName>
								<orgName type="institution">Univ. Lisboa</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Mhd</forename><surname>Yamen Haddad</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">IPP</orgName>
								<orgName type="institution">Inria</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Stéphane</forename><surname>Horel</surname></persName>
							<affiliation key="aff3">
								<orgName type="institution">Le Monde</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Ioana</forename><surname>Manolescu</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">IPP</orgName>
								<orgName type="institution">Inria</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Youssr</forename><surname>Youssef</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">IPP</orgName>
								<orgName type="institution">Inria</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Empowering Investigative Journalism with Graph-based Heterogeneous Data Management</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">6768A5CFE2F932C5E7546F785B6CB6B1</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-04-12T14:49+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Investigative Journalism (IJ, in short) is staple of modern, democratic societies. IJ often necessitates working with large, dynamic sets of heterogeneous, schema-less data sources, which can be structured, semi-structured, or textual, limiting the applicability of classical data integration approaches. In prior work, we have developed ConnectionLens, a system capable of integrating such sources into a single heterogeneous graph, leveraging Information Extraction (IE) techniques; users can then query the graph by means of keywords, and explore query results and their neighborhood using an interactive GUI. Our keyword search problem is complicated by the graph heterogeneity, and by the lack of a result score function that would allow to prune some of the search space.</p><p>In this work, we describe an actual IJ application studying conflicts of interest in the biomedical domain, and we show how ConnectionLens supports it. Then, we present novel techniques addressing the scalability challenges raised by this application: one allows to reduce the significant IE costs while building the graph, while the other is a novel, parallel, in-memory keyword search engine, which achieves orders of magnitude speed-up over our previous engine. Our experimental study on the real-world IJ application data confirms the benefits of our contributions.</p><p>1</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Journalism and the press are a critical ingredient of any modern society. Like many other industries, such as trade, or entertainment, journalism has benefitted from the explosion of Web technologies, which enabled instant sharing of their content with the audience. However, unlike trade, where databases and data warehouses had taken over daily operations decades before the Web age, many newsrooms discovered the Web and social media, long before building strong information systems where journalists could store their information and/or ingest data of interest for them. As a matter of fact, journalists' desire to protect their confidential information may also have played a role in delaying the adoption of data management infrastructures in newsrooms.</p><p>At the same time, highly appreciated journalism work often requires acquiring, curating, and exploiting large amounts of digital data. Among the authors, S. Horel co-authored the "Monsanto Papers" series which obtained the European Press Prize Investigative Reporting Award in 2018 <ref type="bibr" target="#b0">[1]</ref>; a similar project is the "Panama Papers" (later known as "Offshore Leaks") series of the International Consortium of Investigative Journalists <ref type="bibr" target="#b1">[2]</ref>. In such works, journalists are forced to work with heterogeneous data, potentially in different data models (structured such as relations, semistructured such as JSON or XML documents, or graphs, including but not limited to RDF, as well as unstructured text). We, the authors, are currently collaborating on such an Investigative Journalism (IJ, in short) application, focused on the study of situations potentially leading to conflicts of interest<ref type="foot" target="#foot_0">1</ref> (CoIs, in short) between biomedical experts and various organizations: corporations, industry associations, lobbying organizations or front groups. Information of interest in this setting comes from: scientific publications (in PDF) where authors declare e.g., "Dr. X. Y. has received consulting fees from ABC"; semi-structured metadata (typically XML, used for instance in PubMed), where authors may also specify such connections; a medical association, say, French cardiology, may build its own disclosure database which may be relational, while a company may disclose its ties to specialists in a spreadsheet.</p><p>This paper builds upon our recent work <ref type="bibr" target="#b2">[3]</ref>, where we have identified a set of requirements (R) and the constraints (C) that need to be addressed to efficiently support IJ applications. We recall them here for clarity and completeness: R1. Integral source preservation and provenance: in journalistic work, it is crucial to be able to trace each information item back to the data source from which it came. This enables adequately sourcing information, an important tenet of quality journalism. R2. Little to no effort required from users: journalists often lack time and resources to set up IT tools or data processing pipelines. Even when they are able to use a tool supporting one or two data models (e.g., most relational databases provide some support for JSON data), handling other data models remains challenging. Thus, the data analysis pipeline needs to be as automatic as possible. C1. Little-known entities: interesting journalistic datasets feature some extremely well-known entities (e.g., world leaders in the pharmaceutical industry) next to others of much smaller notoriety (e.g., an expert consulted by EU institutions, or a little-known trade association). From a journalistic perspective, such lesserknown entities may play a crucial role in making interesting connections among data sources, e.g., the association may be created by the industry leader, and it may pay the expert honoraries. C2. Controlled dataset ingestion: the level of confidence in the data required for journalistic use excludes massive ingestion from uncontrolled data sources, e.g., through large-scale Web crawls. R3. Performance on "off-the-shelf" hardware: The efficiency of our data processing pipeline is important; also, the tool should run on general-purpose hardware, available to users like the ones we consider, without expertise or access to special hardware.</p><p>Further, IJ applications' data analysis needs entail: R4. Finding connections across heterogeneous datasets is a core need. In particular, it is important for our approach to be tolerant of inevitable differences in the organization of data across sources. Heterogeneous data integration works, such as <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b5">6]</ref>, and recent heterogeneous polystores, e.g., <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b8">9]</ref> assume that sources have well-understood schemas; other recent works, e.g., <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b11">12]</ref> focus on analyzing large sets of Open Data sources, all of which are tabular. IJ data sources do not fit these hypothesis: data can be semi-structured, structured, or simply text. Therefore, we opt for integrating all data sources in a heterogeneous graph (with no integrated schema), and for keyword-based querying where users specify some terms, and the system returns subtrees of the graph, that connect nodes matching these terms. C3. Lack of single, well-behaved answer score: After discussing several journalistic scenarios, no unique method (score) for deciding which are the best answers to a query has been identified. Instead: (i) it appears that "very large" answers (say, of more than 20 edges) are of limited interest; (ii) connections that "state the obvious", e.g., that a French scientist is connected to a French company through their nationality, are not of interest. Therefore, unlike prior keyword search algorithms, which fix a score function and exploit it to prune the search, our algorithm must be orthogonal and work it with any score function.</p><p>Building upon our previous work, and years-long discussions of IJ scenarios, this paper makes the following contributions:</p><p>• We describe the CoI IJ application proposed by S. Horel (Section 2), we extract its technical requirements and we devise an end-to-end data analysis pipeline addressing these requirements (Section 3).</p><p>• We provide application-driven optimizations, inspired from the CoI scenario but reusable to other contexts, which speeds up the graph construction process (Section 4).</p><p>• We introduce a parallel, in-memory version of the keyword search algorithm described in <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b2">3]</ref>, and we explain our design in both the physical database layout and the parallel query execution (Section 5).</p><p>• We evaluate the performance of our system on synthetic and real-world data, we demonstrate its scalability, and demonstrate performance improvements of several orders of magnitude over our prior work, thereby enabling the journalists to perform interactive exploration of their data (Section 6).</p><p>2 Use case: conflicts of interest in the biomedical domain</p><p>The topic. Biomedical experts such as health scientists and researchers in life sciences play an important role in society, advising governments and the public on health issues. They also routinely interact with industry (pharmaceutical, agrifood etc.), consulting, collaborating on research, or otherwise sharing work and interests. To trust advice coming from these experts, it is important to ensure the advice is not unduly influenced by vested interests. Yet, IJ work, e.g. <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b15">16]</ref>, has shown that disclosure information is often scattered across multiple data sources, hindering access to this information. We now illustrate the data processing required to gather and collectively exploit such information. Sample data. Figure <ref type="figure" target="#fig_0">1</ref> shows a tiny fragment of data that can be used to find connections between scientists and companies. For now, consider only the nodes shown as a black dot or as a text label, and the solid, black edges connecting them; these model directly the data. The others are added by ConnectionLens as we discuss in Section 3.1. (i) Hundreds of millions of bibliographic notices (in XML) are published on the PubMed web site; the site also links to research (in PDF). In recent years, PubMed has included an optional CoIStatement element where authors can declare (in free text) their possible links with industrial players; less than 20% of recent papers have this element, and some of those present, are empty ("The authors declare no conflict of interest"). (ii) Within the PDF papers themselves, paragraphs titled, e.g., "Acknowledgments", "Disclosure statement" etc. may contain such information, even if the CoIStatement is absent or empty. This information is accessible if one converts the PDF in a format such as JSON.</p><p>In Figure <ref type="figure" target="#fig_0">1</ref>, Alice declares her consulting for ABCPharma in XML, yet the "Acknowledgments" paragraph in her PDF paper mentions HealthStar<ref type="foot" target="#foot_2">2</ref> . (iii) A (subset of a) knowledge base (in RDF) such as WikiData describes well-known entities, e.g., ABCPharma; however, less-known entities of interest in an IJ scenario are often missing from such KGs, e.g., HealthStar in our example. (iv) Specialized data sources, such as a trade catalog or a Wiki Web site built by other investigative journalists, may provide information on some such actors: in our example, the PharmaLeaks Web site shows that HealthStar is also funded by the industry. Such a site, established by a trusted source (or colleague), even if it has little or no structure, is a gold mine to be reused, since it saves days or weeks of tedious IJ work.</p><p>In this and many IJ scenarios, sources are highly heterogeneous, while time, skills, and resources to curate, clean, or structure the data are not available. Sample query. Our application requires the connections of specialists in lung dis-eases, working in France, with pharmaceutical companies. In Figure <ref type="figure" target="#fig_0">1</ref>, the edges with green highlight and those with yellow highlight, together, form an answer connecting Alice to ABCPharma (spanning over the XML and RDF sources); similarly, the edges highlighted in green together with those in blue, spanning over XML, JSON and HTML, connect her to HealthStar.</p><p>The potential impact of a CoI database. A database of known relationships between experts and companies, built by integrating heterogeneous data sources, would be a valuable asset. In Europe, such a database could be used, e.g., to select, for a committee advising EU officials on industrial pollutants, experts with few or no such relationships. In the US, the Sunshine Act <ref type="bibr" target="#b16">[17]</ref>, just the French 2011 law, require manufacturers of drugs and medical devices to declare such information, but this does not extend to companies from other sectors.</p><p>3 Investigative journalism pipeline The pipeline we have built for IJ is outlined in Figure <ref type="figure" target="#fig_1">2</ref>. First, we recall Con-nectionLens graph construction (Section 3.1), which integrates heterogeneous data into a graph, stored and indexed in PostgreSQL. On this graph, the GAM keyword search algorithm (recalled in Section 3.2) answers queries such as our motivating example; these are both detailed in <ref type="bibr" target="#b2">[3]</ref>. The modules on yellow background in Figure <ref type="figure" target="#fig_1">2</ref> are the novelties of this work, and will be introduced below: scenariodriven performance optimizations to the graph construction (Section 4), and an in-memory, parallel keyword search algorithm, called P-GAM (Section 5).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">ConnectionLens graph construction</head><p>ConnectionLens integrates JSON, XML, RDF, HTML, relational or text data into a graph, as illustrated in Figure <ref type="figure" target="#fig_0">1</ref>. Each source is mapped to the graph as close to its data model as possible, e.g., XML edges have no labels while internal nodes all have names, while in JSON conventions are different etc. Next, Connection-Lens extracts named entities from all text nodes, regardless the data source they come from, using trained language models. In the figure, blue, green, and orange nodes denote Organization, Location, and Person entities, respectively. Each such Entity nodes are shared across the graph, e.g., Person:Alice has been found in three data sources, Org:BestPharma in two sources etc. ConnectionLens includes a disambiguation module which avoids mistakenly unifying entities with the same labels but different meanings. Finally, nodes with similar labels are compared, and if their similarity is above a threshold, a sameAs (red) edge is introduced connecting them, labeled with the similarity value.</p><p>A sameAs edge with similarity 1.0 is called an equivalence edge. Then, p equivalent nodes, e.g., the entity ABCPharma and the identical-label RDF literal, would lead to p(p -1)/2 equivalence edges. To keep the graph compact, one of the p nodes is declared the representative of all p nodes, and instead, we only store the p -1 equivalence edges adjacent to the representative. Details on the graph construction steps can be found in <ref type="bibr" target="#b2">[3]</ref>.</p><p>Formally, a ConnectionLens graph is denoted G = (N, E), where nodes can be of different types (URIs, XML elements, JSON nodes etc., but also extracted entities) and edges encode: data source structure, entities extracted from text, and node label similarity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">The GAM keyword search algorithm</head><p>We view our motivating query, on highly heterogeneous content with no a-priori known structure, as a keyword search query over a graph. Formally, a query Q = {w 1 , w 2 , . . . , w m } is a set of m keywords, and an answer tree (AT, in short) is a set t of G edges which (i) together, form a tree, and (ii) for each w i , contain at least one node whose label matches w i . We are interested in minimal answer trees, that is answer trees which satisfy the following properties: (i) removing an edge from the tree will make it lack at least one keyword match, and (ii) if more than one nodes match a query keyword, then all matching nodes are related through sameAs links with similarity 1.0. In the literature (see <ref type="bibr">Section 7)</ref>, a score function is used to compute the quality of an answer, and only the best k ATs are returned, for a small integer k. Our problem is harder since: (i) our ATs may span over different data sources, even of different data models; (ii) they may traverse an edge in its original or in the opposite direction, e.g., to go from JSON to XML through Alice; this brings the search space size in O(2 |E| ), where |E| is the number of edges; and (iii) no single score function serves all IJ needs since, depending on the scenario, journalists may favor different (incompatible) properties of an AT, such as "being characteristic of the dataset" or, on the contrary, "being surprising". Thus, we cannot rely on special properties of the score function, to help us prune unpromising parts of the search space, as done in prior work (see <ref type="bibr">Section 7)</ref>. Intuitively, tree size could be used to limit the search: very large answer trees (say, of more than 100 edges) generally do not represent meaningful connections. However, in heterogeneous, complex graphs, users find it hard to set a size limit for the exploration. Nor is a smaller solution always better than a larger one. For instance, an expert and a company may both have "nationality" edges leading to "French" (a solution of 2 edges), but that may be less interesting than finding that the expert has written an article specifying in its CoIStatement funding from the company (which could span over 5 edges or more).</p><p>Our Grow-and-Aggressive-Merge (GAM) algorithm <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b2">3]</ref> enumerates trees exhaustively, until a number of answers are found, or a time-out. First, it builds 1node trees from the nodes of G which match 1 or more keywords, e.g., t 1 , t 2 , t 3 in Figure <ref type="figure" target="#fig_2">3</ref>, showing some partial trees built when answering our sample query. The keyword match in each node label appears in bold. Then, GAM relies on two steps. Grow adds to the root of a tree one of its adjacent edges in the graph, leading to a new tree: thus t 4 is obtained by Grow on t 1 , t 5 by Grow on t 4 , and successive Grow steps lead from t 2 to t 15 . Similarly, from t 3 , successive Grow's go from the HTML to the JSON data source (the HealthStar entity occurs in both), and then to the XML one, building t 20 . Second, as soon as a tree is built by Grow, it is Merged with all the trees already found, rooted in the same node, matching different keywords and having disjoint edges wrt the given tree. For instance, assuming t 15 is built after t 5 , they are immediately merged into the tree t 16 , having the union of their edges. Each Merge result is then merged again with all qualifying trees (thus the "agressive" in the algorithm name). For instance, when Grow on t 20 builds a tree rooted in the PubMedArticle node (not shown; call it t A ), Merge(t 16 , t A ) is immediately built, and is exactly the answer highlighted with green and blue in Figure <ref type="figure" target="#fig_0">1</ref>.</p><p>Together, Grow and Merge are guaranteed to generate all solutions. If m = 2, Grow alone is sufficient, while m ≥ 3 also requires Merge. GAM may build a tree in several ways, e.g., the answer above could also be obtained as Merge(Merge(t 15 , Grow(t 20 )), t 5 ); GAM keeps a history of already explored trees, to avoid repeating work on them. Importantly, GAM can be used with any score function. Its details are described in <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b2">3]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Use case-driven optimization</head><p>In this section, we present an optimization we brought to the graph construction process, guided by our target application.</p><p>In the experiments we ran, Named Entity Recognition (NER) took up to 90% of the time ConnectionLens needs to integrate data sources into a graph. The more textual the sources are, the more time is spent on NER. Our application data lead us to observe that:</p><p>• Some text nodes, e.g., those found on the path PubMedArticle.Authors.Author.Name, always correspond to entities of a certain type, in our example, Person. If this information is given to ConnectionLens, it can create a Person entity node, like the Alice node in Figure <ref type="figure" target="#fig_0">1</ref>, without calling the expensive NER procedure.</p><p>• Other text nodes may be deemed uninteresting for the extraction, journalists think no interesting entities appear there. If ConnectionLens is aware of this, it can skip the NER call on such text nodes. Observe that the input data, including all its text nodes, is always preserved; we only avoid extraction effort deemed useless (but which can still be applied later if application requirements evolve).</p><p>To exploit this insight, we introduced a notion of context, and allow users to specify (optional) extraction policies. A context is an expression designating a set of text nodes in one or several data sources. For instance, a context specified by the rooted path PubMedArticle.Authors.Author.Name designates all the text values of nodes found on that path in an XML data source; the same mechanism applies to an HTML or JSON data source. In a relational data source containing table R with attribute a, a context of the form R.a designates all text nodes in the ConnectionLens graph obtained from a value of the attribute a in relation R.</p><p>Finally, an RDF property p used as context designates all the values o such that a triple (s, p, o) is ingested in a ConnectionLens graph.</p><p>Based on contexts, an extraction policy takes one of the following form: (i) c force T e where c is a context and T e is an entity type, e.g., Person, states that each node designated by the context is exactly one instance of T e ; (ii) c skip, to indicate that NER should not be performed on the text nodes designated by c; (iii) as syntactic sugar, for hierarchical data models (e.g., XML, JSON etc.), c skipAll allows stating that NER should not be performed on the text nodes designated by c, nor on any descendant of their parent. This allows larger-granularity control of NER on different portions of the data.</p><p>Observe that our contexts (thus, our policies) are specified within a data model; this is because the regularity that allows defining them can only be hoped for within data sources with identical structure. Policies allow journalists to state what is obvious to them, and/or what is not interesting, in the interest of graph construction speed. Force policies may also improve graph quality, by making sure NER does not miss any entity designated by the context.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">In-memory parallel keyword search</head><p>We now describe the novel keyword search module that is the main technical contribution of this work. A in-memory graph storage model specifically designed for our graphs and with keyword search in mind (Section 5.1) is leveraged by a a multi-threaded, paralell algorithm, called P-GAM (Section 5.2), and which is a parallel extension of our original GAM algorithm, outlined in Section 3.2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Physical in-memory database design</head><p>The size of the main memory in modern servers has grown significantly over the past decade. Data management research has by now led to several DB engines running entirely in main memory, such as Oracle Database In-Memory, SAP HANA, and Microsoft SQL Server with Hekaton. Moving the data from the hard disk to the main memory significantly boosts performance, avoiding disk I/O costs. However, it introduces new challenges on the optimization of the data structures and the execution model for a different bottleneck: the memory access <ref type="bibr" target="#b17">[18]</ref>.</p><p>We have integrated P-GAM inside a novel in-memory graph database, which we have built and optimized for P-GAM operations. The physical layout of a graph database is important, given that graph processing is known to suffer from random memory accesses <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b21">22]</ref>. Our design (i) includes all the data needed by applications as described in Section 2, while also (ii) aiming at high-performance, parallel query execution in modern scale-up servers, in order to tackle huge search spaces (Section 3.2).</p><p>We start with the scalability requirements. Like GAM, P-GAM also performs Grow and Merge operations (recall Figure <ref type="figure" target="#fig_2">3</ref>). To enumerate possible Grow steps, P-GAM needs to access all edges adjacent to the root of a tree, as well as the representative (Section 3.1) of the root, to enable growing with an equivalence edge. Further, as we will see, P-GAM (as well as GAM) relies on a simple edge metric, called specificity, derived from the number of edges with the same label adjacent to a given node, to decide the best neighbor to Grow to. For instance, if a node has 1 spouse and 10 friend edges, the edge going to the spouse is more specific than one going to a friend. A Merge does not need more information than available in its input trees; instead, it requires specific run-time data structures, as we describe below.</p><p>In our memory layout, we split the data required for search, from the rest, as the former are critical for performance; we refer to the latter as metadata. Figure <ref type="figure" target="#fig_3">4</ref> depicts the memory tables that we use. The Node table includes the ID of the data source where the node comes from, and references to each node's: (i) representative, (ii) K neighbors, if they exist (for a fixed K -static allocation), (iii) metadata, and (iv) other neighbors, if they exist (dynamic allocation). We separate the allocation of neighbors into static and dynamic, to keep K neighbors in the main Node structure, while the rest are placed in a separate heap area, stored in the Node connections table. This way, we can allocate a fixed size to each Node, efficiently supporting the memory accesses of P-GAM. In our implementation, we set K = 5; in general, it can be set based on the average degree of the graph vertices. The Node metadata table includes information about the type of each node (e.g., JSON, HTML, etc.) and its label, comprising the keywords that we use for searching the graph. The Edge table includes a reference to the source and the target node of every edge, the edge specificity, and a reference to the edge metadata. The Edge metadata table includes the type and the label of each edge. Finally, we use a keywordIndex, which is a hash-based map associating every node with its labels. P-GAM probes the keywordIndex when a query arrives to find the references to the Node table that match the query keywords and start the search from there. The labels are encoded in order to achieve a more compact representation, while also indexed to allow prefix matching, following the work in <ref type="bibr" target="#b22">[23]</ref>. Among all the Algorithm 1: P-GAM Input: G = (N, E), query Q={w 1 , . . ., w m }, maximum number of solutions M , maximum time limit Output: Answer trees for Q on G 1 pQueue i ← new priority queue of (tree, edge) pairs, 1 ≤ i ≤ nt; 2 N Q ← ∪ w i ∈Q keywordIndex.lookup(w i ); 3 for n ∈ N Q , e edge adjacent to n do 4 push (n, e) on some pQueue j (distribute equally) 5 end 6 launch nt P-GAM Worker (Algorithm 2) threads; 7 return solutions structures, only Node connections (singled out by a dark background in Figure <ref type="figure" target="#fig_3">4</ref>) is in a dynamically allocated area; all the others are statically allocated.</p><p>The above storage is row (node) oriented, even though column storage often speeds up greatly analytical processing; this is due to the nature of the keyword search problem, which requires traversing the graph from the nodes matching the keywords, in BFS style. Since we consider ad-hoc queries (any keyword combinations), there are no guarantees about the order of the nodes P-GAM visits. Therefore, in our setting, the vertically selective access patterns, which are exploited by column-stores, do not apply. Instead, the crucial optimization here is to find the neighbors of every node fast. This is leveraged by our algorithm, as we explain below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">P-GAM: parallel keyword query execution</head><p>Our P-GAM (Parallel GAM) query algorithm builds a set of data structures, which are exploited by concurrent workers (threads) to produce query answers. We split these data structures to shared and private to the workers. We start with the shared ones. The history data structure holds all trees built during the exploration, while treesByRoot gives access to all trees rooted in a certain node. As the search space is huge, history and treesByRoot grow very much. Specfically, for history, P-GAM first has to make sure that an intermediate AT has not been considered before (i.e. browse the history) before writing a new entry. Similar, treesByRoot is updated only when a tree changes its root or if there is a Merge of two trees; however, it is probed several times for Merge candidates. Therefore, we have implemented these data structures as lock-free hash-based maps to ensure high concurrency and prioritize read accesses. Observe that, given the high degree of data sharing, keeping these data structures thread-private would not yield any benefit.</p><p>Moving to the thread-private data structures, each thread, say number i, has a priority queue pQueue i , in which are pushed (tree, edge) pairs, such that the edge is adjacent to the root of the tree. Priority in this queue is determined as follows: we prefer the pairs whose nodes match most query keywords; to break a tie, we prefer smaller trees; and to break a possible tie among these, we prefer the pair where the edge has the highest-specificity. This is a simple priority order we chose empirically; any other priority could be used, with no change to the algorithm. P-GAM keyword search is outlined in Algorithm 1. It creates the shared structures, and nt threads (as many as available based on the availability of computing hardware resources). The search starts by looking up the nodes N Q matching at least one query keywords (line 2); we create a 1-node tree from each such node, and push it together with an adjacent edge (line 4), in one of the pQueue's (distributing them in round-robin).</p><p>Next, nt worker threads run in parallel Algorithm 2, until a global stop condition: time-out, or until the maximum number of solutions has been reached, or all the queues are empty. Each worker repeatedly picks the highest-priority (tree, edge) pair on its queue (line 2), and applies Grow on it (line 3), leading to a 1-edge larger tree (e.g., t 5 obtained from t 4 in Figure <ref type="figure" target="#fig_2">3</ref>). Thus, the stack priority orders the possible Grow steps at a certain point during the search; it tends to lead to small solutions being found first, so that users are not surprised by the lack of a connection they expected (and which usually involves few links). If the Grow result tree had not been found before (this is determined from the history), the worker tries to Merge it with all compatible trees, found within treesByRoot (line 6). The Merge partners (e.g., t 5 and t 15 in Figure <ref type="figure" target="#fig_2">3</ref>) should match different (disjoint) keywords; this condition ensures minimality of the solution. Merge results are repeatedly Merge'd again; the thread switches back to Grow only when no new Merge on the same root is possible. Any newly created tree is checked and, if it matches all query keywords, added to the solution set (and not pushed in any queue). Finally, to balance the load among the workers, if one has exhausted his queue, it retrieves the highest-priority (tree, edge) pair from the queue with most entries, pushing the possible results in its own queue.</p><p>As seen above, the threads intensely compete for access to history and trees-ByRoot. As we demonstrate in Section 6.3, our design allows excellent scalability as the number of threads increases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Experimental evaluation</head><p>We now present the results of our experimental evaluation. Section 6.1 presents the hardware and data used in our application. Section 6.2 studies the impact of extrac- By introducing the policy, the extraction time went down from 1199s (no policy) to 716s, yielding a speed-up of about 40%. The total loading time was reduced from 1461s to 929s, translating to 34% speed-up. As a point of reference, we also noted the time to load (and index) the graph nodes and edges in PostgreSQL; extraction strongly dominates the total time, confirming the practical interest of application-driven policies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Scalability analysis</head><p>The scalability analysis is performed on synthetic graphs, whose size and topology we can fully control. We focus on two aspects that impact scalability: (i) contention in concurrent access to data structures, and (ii) size of the graph (which impacts the search space). To analyze the behavior of concurrent data structures, we use chain k graphs, because they yield a big number of intermediate results, shared across threads, even for a small graph. This way, we can isolate the size of the graph from the size of the intermediate results. We repeat every experiment five times, and we report the average query execution time.</p><p>We use two shapes of graphs (each with 1 associated query), leading to very different search space sizes (Figure <ref type="figure" target="#fig_4">5</ref>). In both graphs, all the kwd i for 0 ≤ i are distinct keywords, as well as the labels of the node(s) where the keyword is shown; no other node label matches these keywords. Chain k has 2k edges; on it, {kwd 0 , kwd 1 } has 2 k solutions, since any two neighbor nodes can be connected by an a i or by a b i edge; further, 2 k+1 -2 partial (non-solution) trees are built, each containing one keyword plus a path growing toward (but not reaching) the other. Star p,k has p branches, each of which is a line of length k; at one extremity each line has a keyword kwd i , 1 ≤ i ≤ p, while at the other extremity, all lines have  Table <ref type="table">1</ref>: Single-thread P-GAM vs. GAM performance on chain graphs. kwd 0 . As explained in Section 3.1, these nodes are equivalent, one is designated their representative (in the Figure, the topmost one), and the others are connected to it through equivalence edges, shown in red. On this graph, the query {kwd 0 , kwd 1 , . . ., kwd p } has exactly 1 solution which is the complete graph; there are O(k + 1)2 p partial trees. Single-thread P-GAM vs. GAM. We start by comparing P-GAM, using only 1 thread, with the (single-threaded) Java-based GAM, accessing graph edges from a PostgreSQL database. We ran the two algorithms on the synthetic graphs and queries, with a time-out of 15 minutes; both could stop earlier if they exhausted the Table <ref type="table">2</ref>: Single-thread P-GAM vs. GAM performance on star graphs.</p><p>search space. Tables <ref type="table">1</ref> and<ref type="table">2</ref> show: the number of solutions S, the time T 1-clean P GAM</p><p>(ms) until the internal data structures have been cleaned and properly prepared for queried, the time T 1-query P GAM (ms) until the first solution is found by P-GAM and its total running time T P GAM (s) that includes both cleaning and querying for all solutions, as well as the corresponding times T 1 and T for GAM (Java on Postgres). On these tiny graphs, both algorithms found all the expected solutions, however, even without parallelism, P-GAM is 10× to more than 100× faster. Further, on all but the 3 smallest graphs, GAM did not exhaust its search space in 15 minutes. This experiment demonstrates and validates the expected speed-up of a carefully designed in-memory implementation, even without parallelism (since we restricted P-GAM to 1 thread). Parallel P-GAM. In the following, we omit the time required for cleaning up the data structures after every iteration, as we want to focus on the scalability of the algorithm. Nevertheless, the time for the maintenance of internal data structures takes less than 5% of the query time for large graphs. On the graphs chain k for 12 ≤ k ≤ 15, we report the exhaustive search time (Figure <ref type="figure" target="#fig_6">6a</ref>) for query {kwd 0 , kwd 1 } as we increase the number of worker threads from 1 to 20. We see a clear speedup as the number of threads increases, which is around 13x for the graph sizes that we report. The speedup is not linear, because as the size of the intermediate results grows, it exceeds the size of the CPU caches, while threads need to access them at every iteration. Our profiling revealed that, as several threads access the shared data structures, they evict content from the CPU cache that would be useful to other threads. Instead, we did not notice overheads from our synchronization mechanisms. Therefore, we observe that our parallelization approach using concurrent data structures is beneficial for parallel processing, while partitioningoblivious.</p><p>To study the scalability of the algorithm with the graph size, we use star 4,k for k ∈ {1K, 2K, 3K, 4K, 5K} and the query {kwd 1 , kwd 2 , kwd 3 , kwd 4 }. Figure <ref type="figure" target="#fig_6">6b</ref> shows the exhaustive search time of P-GAM on these graphs of up to 20.000 nodes, using 1 to 4 threads. We obtain an average speed-up of 3.2× with 4 threads, regardless the size of the graph, which shows that P-GAM scales well for different graph models and graph sizes. After profiling, we observed that the size of the intermediate results impacts the performance, similar to the previous case of the chain graph.</p><p>In the above star 4,k experiments, we used up to 4 threads since the graph has a symmetry of 4 (however, threads share the work with no knowledge of the graph structure). When keyword matches are poorly connected, e.g., at the end of simple paths, as in our star graphs, P-GAM search starts by exploring these paths, moving farther away from each keyword; if N nodes match query keywords, up to N threads can share this work. In contrast, as soon as these explored paths inter- sect, Grow and Merge create many opportunities that can be exploited by different threads. On chain k , the presence of 2 edges between any adjacent nodes multiplies the Grow and Merge opportunities, work which can be shared by many threads. This is why on chain k , we see scalability up to 20 worker threads, which is the maximum that our server supports.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4">P-GAM in Conflict of Interest application</head><p>We now describe experiments on actual application data. The graph. We selected sources based on S. Horel's expertise and suggestions, as follows. (i) We loaded more than 450.000 PubMed bibliographic notices (XML), corresponding to articles from 2019 and 2020; they occupy 934 MB on disk. We used the same extraction policy as in Section 6.2 to perform only the necessary extraction. (ii) We downloaded almost 42.000 PDF articles corresponding to these notices (those that were available in Open Access), transformed them into JSON using an extraction script we developed, and preserved only those paragraphs starting with a set of keywords ("Disclosure", "Competing Interest", "Acknowlegments" etc.) which have been shown <ref type="bibr" target="#b0">[1]</ref> to encode potentially interesting participation of people (other than authors) and organizations in an article. Together, these JSON fragments occupy 340 MB on disk. The JSON and the XML content from the same paper are connected (at least) through the URI of that paper, as shown in Figure <ref type="figure" target="#fig_0">1</ref>. (iii) We crawled 781 HTML Web pages from a set of Web sites describing people and organizations previously involved in scientific expertise on sensitive topics (such as tobacco or endocrine disruptors), including: www.desmogblog.com, tobaccotactics.org, www.wikicorporates.org and www.sourcewatch.org. These pages total 24 MB. Querying the graph. Table <ref type="table" target="#tab_3">4</ref> shows the results of executing 15 queries, until 1000 solutions or for at most 1 minute, using P-GAM. From left to right, the columns show: the query number, the query keywords, the time T 1 until the first solution is found, the time T last until the last solution is found, the total running time T , the number of solutions found, and some statistics on the number of data sources participating in the solutions found (#DS, see below). All times are in milliseconds. We have anonymized the keywords that we use, not to single out individuals or corporations, and since the queries are selected aiming not at them, but at a large variety of P-GAM behavior. We use the following codes: A for author, H for hospital, P for country, and I for industry (company). A #DS value of the form "2-10, 6" means that P-GAM found solutions spanning at least 2 and at most 10 data sources, while most solutions spanned over 6 sources. We make several observations based on the results. The stop conditions were set here based on what we consider as an interactive query response time, and a number of solutions which allow further exploration by the users (e.g., through an interactive GUI we developed). Further, solutions span over several datasets, demonstrating the interest of multi-dataset search enabled, and that P-GAM exploits this possibility. Finally, we report results after performing queries including different numbers of keywords and the system remains responsive within the same time bounds, despite the increasing query complexity.</p><formula xml:id="formula_0"># Keywords T 1 T last T S # DS 1 A1, A2<label>200</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Related Work and Conclusion</head><p>In this paper, we presented a complete pipeline for managing heterogeneous data for IJ applications. This innovates upon recent work <ref type="bibr" target="#b2">[3]</ref> where we have addressed the problems of integrating such data in a graph and querying it, as follows: (i) we present a complete data science application with clear societal impact, (ii) we show how extraction policies improve the graph construction performance, and (iii) we introduce a parallel search algorithm which scales across different graph models and sizes. Below, we discuss prior work most relevant wrt the contributions we made here; more elements of comparison can be found in <ref type="bibr" target="#b2">[3]</ref>.</p><p>Our work falls into the data integration area <ref type="bibr" target="#b3">[4]</ref>; our IJ pipeline starts by ingesting data into an integrated data repository, deployed in PostgreSQL. The first platform we proposed to Le Monde journalists was a mediator <ref type="bibr" target="#b23">[24]</ref>, resembling polystores, e.g., <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b24">25]</ref>. However, we found that: (i) their datasets are changing, text-rich and schema-less, (ii) running a set of data stores (plus a mediator) was not feasible for them, (iii) knowledge of a schema or the capacity to devise integration plan was lacking. ConnectionLens' first iteration <ref type="bibr" target="#b25">[26]</ref> lifted (iii) by introducing keyword search, but it still kept part of the graph virtual, and split keyword queries into subqueries sent to sources. Consolidating the graph in a single store, and the centralized GAM algorithm <ref type="bibr" target="#b2">[3]</ref> greatly sped up and simplified the tool, whose performance we again improve here. We share the goal of exploring and connecting data, with data discovery methods <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b9">10]</ref>, which have mostly focused on tabular data. While our data is heterogeneous, focusing on an IJ application partially eliminates risks of ambiguity, since in our context, one person or organization name typically denote a single concept.</p><p>Keyword search has been studied in XML <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b30">31]</ref>, graphs (from where we borrowed Grow and Merge operations for GAM) <ref type="bibr" target="#b31">[32,</ref><ref type="bibr" target="#b32">33]</ref>, and in particular RDF graphs <ref type="bibr" target="#b33">[34,</ref><ref type="bibr" target="#b34">35]</ref>. However, our keyword search problem is harder in several aspects: (i) we make no assumption on the shape and regularity of the graph; (ii) we allow answer trees to explore edges in both directions; (ii) we make no assumption on the score function, invalidating Dynamic Programming (DP) methods such as <ref type="bibr" target="#b30">[31]</ref> and other similar prunings. In particular, we show in <ref type="bibr" target="#b12">[13]</ref> that edges with a confidence lower than 1, such as similarity and extraction edges in our graphs, compromise, for any "reasonable" score function which reflects these confidences, the optimal substructure property at the core of DP. Works on parallel keyword search in graphs either consider a different setting, returning a certain class of subgraphs instead of trees <ref type="bibr" target="#b35">[36]</ref> or standard graph traversal algorithms like BFS <ref type="bibr" target="#b36">[37,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b38">39]</ref>. To the best of our knowledge, GAM is the first keyword search algorithm for the specific problem that we consider in this paper. Accordingly, in this paper we have parallelized GAM, into P-GAM, by drawing inspiration and addressing common challenges raised in graph processing systems in the literature, in particular concerning the CPU efficiency while interacting with the main memory <ref type="bibr" target="#b39">[40,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b21">22]</ref>.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Graph data integration in ConnectionLens.</figDesc><graphic coords="6,135.05,129.78,340.16,214.43" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Investigative Journalism data analysis pipeline.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Trees built by GAM for our sample query.</figDesc><graphic coords="8,125.80,122.70,283.46,126.42" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Physical graph layout in memory.</figDesc><graphic coords="12,161.66,129.78,286.93,96.53" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Synthetic graphs: chain k , star p,k</figDesc><graphic coords="16,215.46,129.78,179.33,95.61" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>(a) Chain graph scaling (b) Star graph scaling</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Synthetic graphs performance</figDesc><graphic coords="17,316.04,139.74,161.38,90.69" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 3 :</head><label>3</label><figDesc>Statistics on Conflict of Interest application graph.</figDesc><table><row><cell>Data model</cell><cell>|E|</cell><cell>|N |</cell><cell>|N P |</cell><cell>|N O |</cell><cell>|N L |</cell></row><row><cell>XML</cell><cell cols="5">35,318,110 22,204,487 1,561,352 718,434 147,256</cell></row><row><cell>JSON</cell><cell>2,800,959</cell><cell>998,013</cell><cell cols="2">133,794 147,431</cell><cell>9,822</cell></row><row><cell>HTML</cell><cell>232,675</cell><cell>174,849</cell><cell>5,144</cell><cell>4,479</cell><cell>581</cell></row><row><cell>Total</cell><cell cols="5">38,351,744 23,377,349 1,700,290 870,344 157,659</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>Table 3 shows the numbers of edges |E|, of nodes |N |, and, respectively, of Person, Organization and Location entities (|N P |, |N O |, |N L |), split by the data model, and overall.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 :</head><label>4</label><figDesc>P-GAM performance on CoI real-world graph.</figDesc><table><row><cell>4840</cell><cell>4840 1000</cell><cell>1-6, 5</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>According to the</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2011" xml:id="foot_1"><p>French transparency law, "A conflict of interest is any situation where a public interest may interfere with a public or private interest, in such a way that the public interest may be, or appear to be, unduly influenced."</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_2"><p>This example is inspired from prior work of S. Horel where she identified (manually inspecting thousands of documents) an expert supposedly with no industrial ties, yet who authored papers for which companies had supplied and prepared data.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><p>Acknowledgments. The authors thank <rs type="person">M. Ferrer</rs> and the <rs type="institution">Décodeurs team (Le Monde</rs>) for introducing us, and for many insightful discussions.</p></div>
			</div>			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Algorithm 2: P-GAM Worker (thread number i out of nt) 1 repeat 2 pop (t, e), the highest-priority pair in pQueue i (or, if empty, from the pQueue j having the most entries); tion policies (Section 4). Section 6.3 analyzes the scalability of P-GAM, focusing on its interaction with the hardware, and demonstrates its significant gains wrt GAM. Section 6.4 demonstrates P-GAM scalability on a large, real-world graph built for our CoI IJ application.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Hardware and software setup</head><p>We used a server with 2x10-core Intel Xeon E5-2640 v4 CPUs clocked at 2.4GHz, and 192GB of DRAM. We do not use Hyper-Threads, and we bind every CPU core to a single worker thread. As shown in Figure <ref type="figure">2</ref>, we use ConnectionLens (90% Java, 10% Python) to construct a graph out of our data sources, and store it in PostgreSQL. Following the processing pipeline, we migrate the graph to our novel in-memory graph engine, which implements P-GAM. The query engine is a NUMA-aware, multi-threaded C++ application.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Impact of extraction policies</head><p>In this experiment, we loaded a set of 20.000 Pubmed XML bibliographic notices <ref type="bibr">(38.4 MB on disk)</ref>. This dataset inspired an extraction policy stating that: the text content of any PubMedArticle.Authors.Author.Name is a Person entity, and that</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m">European Press Prize: the Monsanto Papers</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m">Offshore Leaks</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Graph integration of structured, semistructured and unstructured data for data journalism</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">G</forename><surname>Anadiotis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Balalau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Conceic ¸ão</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Galhardas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">Y</forename><surname>Haddad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Manolescu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Merabti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>You</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note>Under minor revision in Information Systems</note>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><surname>Doan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">Y</forename><surname>Halevy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">G</forename><surname>Ives</surname></persName>
		</author>
		<title level="m">Principles of Data Integration</title>
		<imprint>
			<publisher>Morgan Kaufmann</publisher>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">MASTRO-I: efficient integration of relational data through DL ontologies</title>
		<author>
			<persName><forename type="first">D</forename><surname>Calvanese</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">D</forename><surname>Giacomo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lenzerini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Lembo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Poggi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Rosati</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">DL Workshop</title>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Obi-wan: Ontologybased RDF integration of heterogeneous data</title>
		<author>
			<persName><forename type="first">M</forename><surname>Buron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Goasdoué</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Manolescu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mugnier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. VLDB Endow</title>
		<meeting>VLDB Endow</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="2933" to="2936" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">The BigDAWG polystore system</title>
		<author>
			<persName><forename type="first">J</forename><surname>Duggan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Elmore</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Stonebraker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Balazinska</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Howe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kepner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Madden</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Maier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Mattson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">B</forename><surname>Zdonik</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015">2015</date>
			<publisher>SIGMOD</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Towards scalable hybrid stores: Constraint-based rewriting to the rescue</title>
		<author>
			<persName><forename type="first">R</forename><surname>Alotaibi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Bursztyn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Deutsch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Manolescu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zampetakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGMOD</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Enabling rich queries over heterogeneous data from diverse sources in healthcare</title>
		<author>
			<persName><forename type="first">A</forename><surname>Quamar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Straube</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Tian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIDR</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Data-driven domain discovery for structured datasets</title>
		<author>
			<persName><forename type="first">M</forename><surname>Ota</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Mueller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Freire</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Srivastava</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. VLDB Endow</title>
		<meeting>VLDB Endow</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="953" to="965" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Pytheas: Pattern-based table discovery in CSV files</title>
		<author>
			<persName><forename type="first">C</forename><surname>Christodoulakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Munson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gabel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">D</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Miller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. VLDB Endow</title>
		<meeting>VLDB Endow</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="2075" to="2089" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Organizing data lakes for navigation</title>
		<author>
			<persName><forename type="first">F</forename><surname>Nargesian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">Q</forename><surname>Pu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">G</forename><surname>Bashardoost</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Miller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGMOD</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Graph-based keyword search in heterogeneous data sources</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">G</forename><surname>Anadiotis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">Y</forename><surname>Haddad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Manolescu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Bases de Données Avancés</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note>informal publication</note>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<author>
			<persName><forename type="first">N</forename><surname>Oreskes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Conway</surname></persName>
		</author>
		<title level="m">Merchants of Doubt</title>
		<imprint>
			<publisher>Bloomsbury Publishing</publisher>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Lobbytomie</title>
		<author>
			<persName><forename type="first">S</forename><surname>Horel</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
			<publisher>La Découverte</publisher>
		</imprint>
	</monogr>
	<note>In French</note>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Petites ficelles et grandes manoeuvres de l&apos;industrie du tabac pour réhabiliter la nicotine</title>
		<author>
			<persName><forename type="first">S</forename><surname>Horel</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note>In French</note>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m">Physician Payments Sunshine Act</title>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Database architecture optimized for the new bottleneck: Memory access</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">A</forename><surname>Boncz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Manegold</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">L</forename><surname>Kersten</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">VLDB</title>
		<imprint>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Large-scale graph processing on emerging storage devices</title>
		<author>
			<persName><forename type="first">N</forename><surname>Elyasi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sivasubramaniam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">USENIX FAST</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">A scalable processing-inmemory accelerator for parallel graph processing</title>
		<author>
			<persName><forename type="first">J</forename><surname>Ahn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yoo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Mutlu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Choi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ISCA</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">X-stream: edge-centric graph processing using streaming partitions</title>
		<author>
			<persName><forename type="first">A</forename><surname>Roy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Mihailovic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zwaenepoel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SOSP</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">PGX.D: a fast distributed graph processing engine</title>
		<author>
			<persName><forename type="first">S</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Depner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Manhardt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">V D</forename><surname>Lugt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Verstraaten</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Chafi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015">2015</date>
			<publisher>SC</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Dictionary-based order-preserving string compression for main memory column stores</title>
		<author>
			<persName><forename type="first">C</forename><surname>Binnig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Hildenbrand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Färber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGMOD</title>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Mixed-instance querying: a lightweight integration architecture for data journalism</title>
		<author>
			<persName><forename type="first">R</forename><surname>Bonaque</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">D</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Cautis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Goasdoué</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Letelier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Manolescu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Mendoza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ribeiro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Tannier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Thomazo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. VLDB Endow</title>
		<meeting>VLDB Endow</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="1513" to="1516" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Cloudmdsql: querying heterogeneous cloud data stores with a common language</title>
		<author>
			<persName><forename type="first">B</forename><surname>Kolev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Valduriez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Bondiombouy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Jiménez-Peris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Pau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Pereira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Distributed Parallel Databases</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="463" to="503" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Connectionlens: Finding connections across heterogeneous data sources</title>
		<author>
			<persName><forename type="first">C</forename><surname>Chanial</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Dziri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Galhardas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Leblay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">L</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Manolescu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. VLDB Endow</title>
		<meeting>VLDB Endow</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="2030" to="2033" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Finding related tables</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">D</forename><surname>Sarma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">Y</forename><surname>Halevy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Xin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGMOD</title>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Aurum: A data discovery system</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">C</forename><surname>Fernandez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Abedjan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Koko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Madden</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Stonebraker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICDE</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Seeping semantics: Linking datasets using word embeddings for data discovery</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">C</forename><surname>Fernandez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Mansour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Qahtan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Elmagarmid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">F</forename><surname>Ilyas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Madden</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ouzzani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Stonebraker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICDE</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">XRANK: ranked keyword search over XML documents</title>
		<author>
			<persName><forename type="first">L</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Botev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Shanmugasundaram</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGMOD</title>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Identifying meaningful return information for XML keyword search</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGMOD</title>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Finding top-k min-cost connected trees in databases</title>
		<author>
			<persName><forename type="first">B</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">X</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICDE</title>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">BLINKS: ranked keyword searches on graphs</title>
		<author>
			<persName><forename type="first">H</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">S</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGMOD</title>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Keyword search over RDF graphs</title>
		<author>
			<persName><forename type="first">S</forename><surname>Elbassuoni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Blanco</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIKM</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Scalable keyword search on large RDF data</title>
		<author>
			<persName><forename type="first">W</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kementsietsidis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Duan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Knowl. Data Eng</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2774" to="2788" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">An efficient parallel keyword search engine on knowledge graphs</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">V</forename><surname>Jagadish</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K H</forename><surname>Tung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICDE</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Efficient parallel graph exploration on multi-core CPU and GPU</title>
		<author>
			<persName><forename type="first">S</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Oguntebi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Olukotun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">PACT</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Julienne: A framework for parallel graph algorithms using work-efficient bucketing</title>
		<author>
			<persName><forename type="first">L</forename><surname>Dhulipala</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Blelloch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Shun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SPAA</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">A work-efficient parallel breadth-first search algorithm (or how to cope with the nondeterminism of reducers</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">E</forename><surname>Leiserson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">B</forename><surname>Schardl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SPAA</title>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Everything you always wanted to know about multicore graph processing but were afraid to ask</title>
		<author>
			<persName><forename type="first">J</forename><surname>Malicevic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Lepers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zwaenepoel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">USENIX ATC</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
