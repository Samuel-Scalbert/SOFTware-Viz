<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Engineering Annotations to Support Analytical Provenance in Visual Exploration Processes</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Maroua</forename><surname>Tikat</surname></persName>
							<email>[maroua.tikat@inria.fr</email>
							<affiliation key="aff0">
								<orgName type="laboratory">UMR 7271</orgName>
								<orgName type="institution" key="instit1">University C么te d&apos;Azur</orgName>
								<orgName type="institution" key="instit2">CNRS</orgName>
								<orgName type="institution" key="instit3">Inria</orgName>
								<address>
									<region>I3S (</region>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Aline</forename><surname>Menin</surname></persName>
							<email>aline.menin@inria.fr</email>
							<affiliation key="aff0">
								<orgName type="laboratory">UMR 7271</orgName>
								<orgName type="institution" key="instit1">University C么te d&apos;Azur</orgName>
								<orgName type="institution" key="instit2">CNRS</orgName>
								<orgName type="institution" key="instit3">Inria</orgName>
								<address>
									<region>I3S (</region>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Michel</forename><surname>Buffa</surname></persName>
							<email>michel.buffa@inria.fr</email>
							<affiliation key="aff0">
								<orgName type="laboratory">UMR 7271</orgName>
								<orgName type="institution" key="instit1">University C么te d&apos;Azur</orgName>
								<orgName type="institution" key="instit2">CNRS</orgName>
								<orgName type="institution" key="instit3">Inria</orgName>
								<address>
									<region>I3S (</region>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Marco</forename><surname>Winckler</surname></persName>
							<email>marco.winckler]@inria.fr</email>
							<affiliation key="aff0">
								<orgName type="laboratory">UMR 7271</orgName>
								<orgName type="institution" key="instit1">University C么te d&apos;Azur</orgName>
								<orgName type="institution" key="instit2">CNRS</orgName>
								<orgName type="institution" key="instit3">Inria</orgName>
								<address>
									<region>I3S (</region>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Engineering Annotations to Support Analytical Provenance in Visual Exploration Processes</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">71DB1F04BC51F33749C3054144464A83</idno>
					<idno type="DOI">10.1007/978-3-031-09917-5_14</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-04-12T14:44+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>annotations</term>
					<term>provenance analysis</term>
					<term>visual exploration</term>
					<term>information visualization</term>
					<term>data quality</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper focuses on the fundamental role played by annotations to support provenance analysis in visual exploration processes of large datasets. Particularly, we investigate the use of annotations during the visual exploration of semantic datasets assisted by chained visualization techniques. In this paper, we identify three potential uses of annotations: (i) documenting findings (including errors in the dataset), (ii) supporting collaborative reasoning among teammates, and (iii) analysing provenance during the exploratory process. To demonstrate the feasibility of our approach, we implemented it as a tool support, while illustrating its usage and effectiveness through a series of use case scenarios. We identify the attributes and meta-data that describe the dependencies between annotations and visual representations, and we illustrate these dependencies through a domain-specific model.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The amount and complexity of digital data has increased exponentially during the last couple of decades. These data contain valuable information to support decision-making processes in several application domains. Nevertheless, the value of these data depends on the ability of decision makers to find relevant information that describes the phenomenon embedded in data. In this context, visual analytics is a suitable and widely adopted solution as it supports human reasoning through interactive tools that embed visual representations to highlight and reveal any relationships within data. Some examples of widely adopted tools for data analytic processes are kibana <ref type="bibr">[9]</ref> and Tableau <ref type="bibr" target="#b20">[20]</ref>. Even with the help of visual analytics tools, the exploration and analysis of large data sets is not a straightforward process. Although, visual analytics helps to show the tendencies and patterns within the data, data analysts must be able to interpret the findings in order to produce decisions. Moreover, it is not unusual that, during the exploration process, a data analyst is confronted with many sorts of errors (e.g., missing, duplicated, inconsistent data) <ref type="bibr" target="#b10">[11]</ref>, which should be fixed in order to complete the analysis. In this context, it becomes part of the data analyst's duties the task of checking the integrity and validity of data For this reason, some authors <ref type="bibr" target="#b3">[4]</ref> suggests that "the expertise to analyse and make informed decisions about these information-rich datasets is often best accomplished by a team". In fact, most of real-world analytical environments require the participation of multiple analysts of different backgrounds and that play different roles during the analytical process <ref type="bibr" target="#b12">[13]</ref>.</p><p>Annotations are a suitable solution to record and process design decisions made by teams as they can compliment existing information with a rationale. Previous works <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b17">17]</ref> have shown that annotations are useful as a means to disclosure hidden relationships between data, to record the results of discussion and decisions made by team members, gather internal and external feedback on artefacts produced, to connect pieces of information such as results of usability evaluations and the design artefacts, to document and to justify design choices by describing them retrospectively.</p><p>Nonetheless, the ISO standard 9241-210 is very silent about how to record and process design decisions. To the best of our knowledge, there is no study investigating the use of annotations to record the visual exploration process of data. Inspired by these previous works we investigate the use of annotations to support decision-making processes through the visual exploration. We show that annotations can support analytical provenance studies by allowing data analysts to reason with various evidences collected during the exploration process and also trace back the results to the source of findings <ref type="bibr" target="#b15">[15,</ref><ref type="bibr" target="#b21">21]</ref>. Despite the concept of annotation being simple to understand, implementing has many implications on the design and development of tools. In this paper, we focus on annotations that can embedded with provenance data, thus, supporting the tracking of use context of annotations, while supporting collaborative tasks around annotations. Our approach is implemented as a plug-in embedded into a visualization tool called MGExplorer <ref type="bibr" target="#b15">[15]</ref>. The usage of our tools are illustrated through a set of use case scenarios describing the exploration of the Wasabi dataset <ref type="bibr" target="#b1">[2]</ref>, a large dataset describing music data.</p><p>The remainder of this document is organized as follows. The section 2 presents the concepts of annotation and provenance analysis. The 3 provides an overview of similar works highlighting the lack of studies investigating the use of annotations in visual exploratory processes. The section 4 introduces the rational of our approach and presents a proposal for extending the W3C annotation model to support the idiosyncrasies of exploration process using visualization tools. The section 5 describes a set of relevant use case scenarios (including annotation of multiple types of views and objects, and collaborative use of annotations) that demonstrate the utility of our approach. Finally, section 6 presents our conclusions and future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Foundations</head><p>In this section we revise two key-concepts for understanding our approach: annotations and analytical provenance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Annotations</head><p>The first studies on annotations were focused on paper textbooks and then transposed to electronic documents <ref type="bibr" target="#b13">[14]</ref>. Annotating allows the interaction between distinct pieces of information to serve different purposes: description (placing data in a context, add sources of information, etc.), evaluation (reporting quality issues, questions or concerns, etc.) or a combination of both.</p><p>According to the W3C Recommendation, an annotation is defined as a set of connected resources featuring a body and a target that are interrelated. This approach supports interoperability as it allows annotations to be shared across different systems. The Figure <ref type="figure" target="#fig_0">1</ref> shows the W3C's annotation model, where the target corresponds to the element we want to annotate, and the content of the body would usually regard the target. The annotation might contain meta-data that contextualizes the body's contents. Annotations can assume many forms (e.g., text, sketching, highlighting, etc.) and be attached to different artefacts (e.g., documents, images, data sets, etc.) <ref type="bibr" target="#b6">[7]</ref>, which are not covered by the W3C specification and must be extended according to the application domain. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Analytical provenance</head><p>Analytical provenance is a means to understand users' reasoning processes while exploring data through visualization <ref type="bibr" target="#b18">[18]</ref>. It studies users' interactions while using a visualization system to extract exploration patterns that can explain how users explore data visually. The outcomes of analytical provenance can assist the evaluation of systems and algorithms, building adaptive systems, model steering, replicating, reporting and storytelling <ref type="bibr" target="#b23">[23]</ref>.</p><p>In this work, we are particularly interested in provenance data of visualization, describing the history of graphical views and visualization states <ref type="bibr" target="#b19">[19]</ref>, which can assist users on recreating their analytical reasoning process, while supporting verification, replication, reapplication, and sharing of exploration paths. In visualization systems, these data are often represented through history trees as in VisTrails <ref type="bibr" target="#b2">[3]</ref> which allows users to create, change, and compare visualizations by exploring the graphical representation of the exploration flow.</p><p>Typically, provenance data is visually encoded as a sequence of actions indicating users' interactions <ref type="bibr" target="#b23">[23]</ref>. The data is then encoded as a graph where nodes are entities (or concepts) that change state during the exploration process connected through line segments that indicates their previous state. Graph encoding allows the user to navigate in the exploration path, while interacting directly with the history graph to generate a story of their analysis <ref type="bibr" target="#b5">[6]</ref>. Tools such as MGExplorer <ref type="bibr" target="#b15">[15]</ref> and GraphTrail <ref type="bibr" target="#b4">[5]</ref> represent the workflow through segment lines connecting different views of data, allowing users to understand the actions performed from one view to another.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Related Work</head><p>Annotations could be used on different types of data, be it to illustrate a drawing in order to provide an explanation, or using engineering annotations to support the design process of interactive systems. They could also support decisionmaking processes by being used as decision cards <ref type="bibr" target="#b11">[12]</ref>. As shown in <ref type="bibr" target="#b16">[16]</ref>, there are multiple tools available to annotate documents, images or textual data. In this work, we focus on annotating result sets from queries, expressed and explored through visualizations. Furthermore, we should be able to support recording of users' findings during an exploration process, as well as sharing of annotations with fellow data analysts to support collaborative data analysis. Hereafter, we present some of the existing annotation tools in the literature.</p><p>The SenseMap <ref type="bibr" target="#b17">[17]</ref> tool supports browser-based online sensemaking through analytic provenance. The tool provide data curation to indicate relevance of nodes (views in the graph) through an interactive annotation process: : if node is completely irrelevant, the user can remove it ; if a node is not quite relevant but the user wants to keep it to have a look at some point, they can minimize it ; if a node is very relevant, the user can favor it.</p><p>The Glozz <ref type="bibr" target="#b22">[22]</ref> environment for annotation and exploration of a corpus is based on a generic model that can conform (by instantiation) to any annotation paradigm. The tool allows the manual annotation of texts that may have been previously annotated, as well as the annotation and visualization of simple or complex structures (units, relations and patterns (or clusters)). It also allows the exploration of annotations.</p><p>The UAM corpus tool <ref type="bibr" target="#b11">[12]</ref> is a software for corpus annotation and exploration that allows to annotate text and images.</p><p>The GATE (General Architecture for Text Engineering) <ref type="bibr" target="#b7">[8]</ref> is an open-source infrastructure that provides a set of language engineering tools for collaborative corpus annotation.</p><p>The ANALEC <ref type="bibr" target="#b9">[10]</ref> tool combines corpus annotation, visualization and query management. It allows ergonomic annotation via the concept of view and the use of elaborate filtering of the available information, frequency calculations, search for correlations, and generation of tables, figures and diagrams.</p><p>Our approach differs from previous works by allowing an annotation to be linked to the data represented in a view.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Our Approach</head><p>Our ultimate goal is to allow users to create annotations for recording decisions during the visual exploration process of data. We assume that annotations should formalize the relationship between the users' intentions (ex. insights, questions, etc.) and actual artefacts of the visualization (those being annotated), such as a particular visual representation of the data. In order to accomplish this goal, we followed four steps:</p><p>1. Create an annotation model describes the concepts covered by an annotation and the procedure to use the model together with visualization tools. Subsection 4.1 presents our proposed model. 2. Define the dependencies between the annotations and the visualizations being annotated. As described in subsection 4.2, the dependencies might refer to the scope and the diverse elements in the display (e.g., views, queries, set of itemsets, etc.). 3. Identify the attributes of provenance data that allows to store and restore annotations in the context, as shown in subsection 4.3 4. Development of tool support that implement annotations in the context of visualization. Our implementation of the annotation model is presented in section 5 along with a set of use case scenarios to demonstrate the usage and feasibility of our tool.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Extending the conceptual model of annotations</head><p>Visualization techniques can be generalized as complex artefacts comprising a query, which serve to fetch data from the data set, a dashboard that can host one or more views (each view featuring a visualization technique) that are composed of a subset of objects making reference to a particular itemset in the data set. This general definition can be applied to any visualization tool. It defines a scope where annotations created by the users can be connected to visual representation of data. The section 5 shows different use case scenarios where annotations require a connection to views, objects, dashboard, and queries. We also assume that an annotation might be a follow-up comment to a preexisting annotation, so an annotation can be annotated. It might also be the case that an annotation is not connected to anything in particular, or be left over to be connected to an target later on by the user.</p><p>In order to accommodate all these scenarios, we have extended the W3C annotation's model, as shown in Fig. <ref type="figure" target="#fig_1">2</ref>. First of all, we create a new class called Artefact that is used to refine and explicitly describe any idiosyncrasies of what is annotated, i.e. an information visualization. Such a class allows us to differentiate annotations created on other artefacts (ex. documents, drawings, etc). The other extensions inherit from the class Target and refer to the type of selector that can be used to annotate the different elements. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Dependencies between annotation and visualizations</head><p>The annotation model described in the previous sections allow to describe annotations as singleton class mge-annotation, as shown in Fig. <ref type="figure">3</ref>. The class mgeannotation is not connected to any other element, which grants independence of implementation of the approach from a particular visualization tool. The other classes at Fig. <ref type="figure">3</ref> refer to the model used to describe the components of the tool MGExplorer that is used to illustrate the approach. Fig. <ref type="figure">4</ref> shows the mapping between the singleton class mge-annotation and the other classes of MGExplorer.</p><p>It is worthy of note the connections between the class view-annotation and the sub-set of data a view might contain, handled by the class object-annotaiton, and the class InfoVis technique that refers to the actual visualization technique in the display. Further illustrations on how these connections are made at the tool level are illustrated in the section 5. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Attributes in data provenance</head><p>An annotation has a body and it also might have a meta-data. Whilst some of the body's contents is given by the users (ex. comments), other body attributes can be automatically collected from the context. Tab. 1 provides an exhaustive view of body attributes that can be captured when connecting different types of the target. These attributes are available through the classes in the mapping model shown (but not detailed) in Fig. <ref type="figure">4</ref>. For example, when the user created a free annotation (i.e. target None in Tab. 1), we can only capture its id, body provided by the user, and the timestamp. However, when a user decides to connect the annotation to a target such as Object, it is possible to include other attributes automatically such as views' title (which describe the name of the window holding the data item), the view's visualization technique (which refers to the particular visualization being used to show data in the view), the object or the set of views' subset (corresponding to data items in the view). Such as a combination of different attributes allows to determine the full context for data in the display and hence the data provenance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Use Case Scenarios and Tool Support</head><p>The use case scenarios presented hereafter, demonstrate the use of annotations when exploring the WASABI <ref type="bibr" target="#b1">[2]</ref> data set, a SPARQL endpoint which consists of more than 2 million commercial songs retrieved from multiple sources on the web. In our scenarios we employ two queries. The first query retrieves data of a collaboration network of a particular artist described by type (producer, writer, performer) of collaboration. The second query retrieves data describing a network of artists by the genre of their productions. The approach is implemented as a plugin for the tool MGExplorer <ref type="bibr" target="#b15">[15]</ref>. This tool uses chained views to assist the exploration of multidimensional and multivariate graphs, which allows to depict analytical provenance via a sequence of views connected through line segments to represent their dependency, while supporting one or more visualization techniques applied to one or more datasets. Figure <ref type="figure" target="#fig_3">5</ref> depicts the exploration process as follows: 1. From a query panel, the user selects a SPARQL endpoint and executes a predefined query that retrieves a network data set describing a particular phenomena (co-authorship, co-occurrence, etc) (Figure <ref type="figure" target="#fig_3">5a</ref>). 2. The resulting data set is visualized through a node-link diagram featuring a network (Figure <ref type="figure" target="#fig_3">5b</ref>). The nodes are interactive allowing to create new views (five techniques are available: network, clusters, pairwise relationships, temporal distribution, and listing of items) from data subsets (Figure <ref type="figure" target="#fig_3">5c</ref>). This subsetting operation is available in all visualization techniques, allowing the user to further explore the data set through different perspectives. 3. Upon each subsetting operation, a new view is created and linked to the previous view through a line segment. The provenance data regarding this operation is automatically included in a history panel (Figure <ref type="figure" target="#fig_3">5d</ref>). 4. The views can be moved around, allowing the user to rearrange the visualization space in meaningful ways. Further, users can hide any of the currently displayed views (Figure <ref type="figure" target="#fig_3">5e</ref>), which they may revisit later using the history panel, thus cleaning the display area in a way that helps them to focus on what is relevant to the task at hand. 5. The user can import new data by adding query panels, which resulting data can be explored seamlessly as the initial data set.</p><p>For the sake of coherence and to support analytical provenance, the annotation technique was implemented as a view that can be instantiated anytime and then connected to a view, an object, or the dashboard through line segments, or yet represented as a singleton when the annotation is free of context.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Overview of annotations</head><p>While visually exploring the collaboration network of the artist Michael Jackson (Figure <ref type="figure" target="#fig_4">6a</ref>), we noticed a collaboration between him and Justin Timberlake. We decided then to further investigate it by displaying the list of songs that define this collaboration (Figure <ref type="figure" target="#fig_4">6b</ref>). We observe that the song on which these artists collaborated was released in 2014, which collaboration could not be possible since Michael Jackson died in 2009. To report this issue, we create a free annotation (Figure <ref type="figure" target="#fig_4">6c</ref>), where we indicate that "Michael Jackson died in 2009".</p><p>We continue inspecting other collaborations of this same artist. We notice in the node-link diagram, a collaboration between Michael Jackson and Pitbull. The list of (Figure <ref type="figure" target="#fig_4">6d</ref>) shows that they worked together on the song "Bad" released in 2007. However, this cannot be true; Pitbull made a remix of the song "Bad" in 2012 but he never collaborated with Michael Jackson. To report the problem, we will annotate the whole exploration process by creating an annotation on the dashboard (Figure <ref type="figure" target="#fig_4">6e</ref>) indicating a "Problem with Michael Jackson's collaborations in the dataset. Pitbull did a remix of "Bad" in 2012". This annotation is not linked to any particular element of the dashboard, but it rather retrieves the history (provenance data) of exploration. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Managing multiple annotations</head><p>When annotations are not connected to a particular item, we have to go through the whole data set to find the actual item causing issues. Alternatively, we can connect the annotation to the view causing the issue; as in Figure <ref type="figure" target="#fig_5">7</ref>.a featuring a node-edge connected to the annotation "Error: Pitbull didn't collaborate with Michael Jackson in 2007. He performed in a remix of the song "Bad" in 2012". This issue refers to two views in the display and we can connect both views to the annotation to reinforce our concerns. For that, by selecting those two views in the annotation window as shown at Figure <ref type="figure" target="#fig_5">7b</ref>, we create an annotation that connects to the two views through two line segments. Then we create a new annotation to report a duplicated song in the list of songs. Along the exploration process, the dashboard might become full of views. Thus, to reduce visual cluttering, we close this last annotation (Figure <ref type="figure" target="#fig_5">7e</ref>) which nonetheless remains in the history panel allowing us to retrace the exploration path and reopen the view if needed.</p><p>To analyze the evolution of members in the group "The Jackson 5", we try a new query. We try to launch a new query from the node-link diagram (Figure <ref type="figure" target="#fig_5">7d</ref>) but we notice that query does not exist. Since this analysis is important for us, we create an annotation "I need a query to explore the temporal evolution of the members of a group" connecting the query view (Fig. <ref type="figure" target="#fig_5">7e</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Annotating objects in a view</head><p>Our approach also allows the user to annotate a specific item on a view. In this scenario, we demonstrate how to retrieve a data item causing issues with respect to the two collaborations of Michael Jackson seen in the previous scenarios. When exploring the node-link diagram, we first create an annotation and connect it to both links indicating the collaborations of Michael Jackson with Justin Timberlake and with the rapper Pitbull. As shown by Figure <ref type="figure" target="#fig_6">8a</ref>, the annotation view displays a description of the objects and it is linked to the view where the objects appear through a line segment. This approach works in every visualization technique. For instance, we further explore the collaboration between Michael Jackson and Pitbull using a different visualization technique, the Clus-terViz. Here, we can create an annotation and link to the objects representing this collaboration (Figure <ref type="figure" target="#fig_6">8b</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Exporting annotations</head><p>To export the data describing the annotations, we can use the button at the bottom of the annotation view (Figure <ref type="figure">9b</ref>). This action produces a json file (Figure <ref type="figure">9a</ref>), containing the attributes of the annotation, as shown in Table <ref type="table" target="#tab_0">1</ref> and a link that allows the user to reopen the graphical annotation view.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5">Collaborative use of annotations</head><p>In this scenario, we demonstrate how annotations can be shared among teammates in order to support collaborative analysis of data sets. For that, we explore a data set describing the relationship network of artists based on the genre of their productions. We analyse the relationships using the node-link diagram (Figure <ref type="figure" target="#fig_7">10a</ref>), using the search bar under the visualization technique to locate the artist "Madonna" by. We found that Madonna produced songs of the same genre as other four artists. We use the visualization technique called IRIS (Figure <ref type="figure" target="#fig_7">10b</ref>) to identify what genres they have in common. The width of colored bars in IRIS represent the number of songs where Madonna have a genre in common with every other artist (in the periphery). By studying this chart, we notice an issue with the visualization: all bars have the same height and colors. However, as we hover over the bar between Madonna and one of the artists, the information box that appears shows that there is no song under the genre "dance" between those artists. We create an annotation on the dashboard to raise the issue (Figure <ref type="figure" target="#fig_7">10d</ref>) stating that "Genres with no data shouldn't appear in the visualizations". Our colleague, John Doe could disambiguate or fix the issue. For that, our tool provides a shareable link of the dashboard, so that John Doe can open on their own browser and continue the exploration. When John Doe finds an answer to the issue, he replies by creating a new annotation "It's a problem related to the system and not the dataset. It's fixed now." which it connected to our the initial annotation raising the question (Figure <ref type="figure" target="#fig_7">10c</ref>). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.6">Tracking provenance analysis</head><p>From the previous scenario, the user John Doe has an overview of the whole schema produced by us, including the data set, the query and the annotation created during the exploratory stages. This allows John Doe to track the path explored and retrieve the origin of the annotated data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Discussion, conclusions and future work</head><p>Annotation is a concept familiar on paper but it is often hard to implement and seldom fully exploited, beyond tools for annotating digital document. At the best of our knowledge, we could not find methods for annotating individual elements during the visual exploration of data sets. In this paper we discuss some of the problems for engineering annotations for supporting representation of provenance when exploring large data sets. On one hand, our approach allows to encode information about data provenance (i.e. sequence of data exploration) as part of the annotations, so when analyzing annotations it is possible to restore the full sequence of actions allowing users to go from queries to data in the display. On the other hand, annotations should help users to explain insights and decisions, which is necessary to perform provenance analysis on data. The validation of the approach is made by construction, which means that we demonstrate its feasibility by creating a tool and illustrating its use by a set of relevant scenarios.</p><p>Through the scenarios, we have shown how annotations can be used to provide information to complete the data set, point errors and mistakes, express user's needs, compare results, and share insights with other users. These examples are not exhaustive but yet representative for the use of annotations. We also have demonstrated how annotations can be extracted from the tools and yet include subsets of data and sequence of actions, thus become available to support analysis of provenance using other tools. It is interesting to notice that users might report issues with the data set using different combinations of annotations and views.</p><p>The originality of this paper concerns aspects for engineering annotation beyond digital document. As discussed here, we need to consider the specific context of the use of annotations (data sets and visualizations) for building the appropriate tools. We introduce a new topic and we want to level the discussion about the importance of having annotations to support the exploration process; for that we need innovative tools including the analysis of the provenance. Whilst the plug-in developed is specific to the visualization tool MGExplporer, we consider that the steps described in the approach are generic enough and can be adapted to support the development of other annotating tools.</p><p>We also demonstrated how to share annotations with other teammates to discuss findings. We want to advertise our tool to collect data from real users, not only for assessing the usability of the tool but also for collecting data enabling further investigations about analysis of provenance. In the future, we also consider to extend the possibility for including other annotation formats thus allowing to create annotations using highlighting of elements, support drawings, symbols, speech as replacement of text. Other improvements involve the synchronous edition and annotations.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. The annotation model proposed by the W3C Recommendation.</figDesc><graphic coords="4,222.64,408.66,170.08,97.81" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Extended W3C annotation's model</figDesc><graphic coords="7,134.77,249.17,345.84,165.20" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .Fig. 4 .</head><label>34</label><figDesc>Fig. 3. MGExplorer model</figDesc><graphic coords="8,152.06,253.43,311.25,104.93" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. Visualization tool</figDesc><graphic coords="9,152.06,440.25,311.23,176.23" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. Overview of annotations: choosing annotation's targets</figDesc><graphic coords="11,134.77,115.84,345.82,181.55" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 7 .</head><label>7</label><figDesc>Fig. 7. Managing multiple annotations</figDesc><graphic coords="12,134.77,115.84,345.81,178.53" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 8 .</head><label>8</label><figDesc>Fig. 8. Annotation of objects</figDesc><graphic coords="13,134.77,148.51,345.83,234.12" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 10 .</head><label>10</label><figDesc>Fig. 10. Annotation sharing: collaborative use of annotations</figDesc><graphic coords="14,134.77,294.23,345.80,174.26" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>Annotation attributes</figDesc><table><row><cell>Body attributes</cell><cell cols="5">Targets Object View Query Dashboard None</cell></row><row><cell>Id</cell><cell>x</cell><cell>x</cell><cell>x</cell><cell>x</cell><cell>x</cell></row><row><cell>View's title</cell><cell>x</cell><cell>x</cell><cell>x</cell><cell></cell><cell></cell></row><row><cell>View's visualisation technique</cell><cell>x</cell><cell>x</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Object</cell><cell>x</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Object's type</cell><cell>x</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>View's subset</cell><cell>x</cell><cell>x</cell><cell>x</cell><cell>x</cell><cell></cell></row><row><cell>Body</cell><cell>x</cell><cell>x</cell><cell>x</cell><cell>x</cell><cell>x</cell></row><row><cell>Timestamp</cell><cell>x</cell><cell>x</cell><cell>x</cell><cell>x</cell><cell>x</cell></row><row><cell>Path sequence</cell><cell></cell><cell></cell><cell></cell><cell>x</cell><cell></cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><surname>Agosti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Orio</surname></persName>
		</author>
		<title level="m">Annotations as a tool for disclosing hidden relationships between illuminated manuscripts</title>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">The WASABI dataset: cultural, lyrics and audio analysis metadata about 2 million popular commercially released songs</title>
		<author>
			<persName><forename type="first">M</forename><surname>Buff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ESWC 2021: The Semantic Web</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Vistrails: Visualization meets data management</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">P</forename><surname>Callahan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Freire</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Santos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">E</forename><surname>Scheidegger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">T</forename><surname>Silva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">T</forename><surname>Vo</surname></persName>
		</author>
		<idno type="DOI">10.1145/1142473.1142574</idno>
		<ptr target="https://doi.org/10.1145/1142473.1142574" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2006 ACM SIGMOD International Conference on Management of Data</title>
		<meeting>the 2006 ACM SIGMOD International Conference on Management of Data<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="745" to="747" />
		</imprint>
	</monogr>
	<note>SIGMOD &apos;06</note>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<author>
			<persName><forename type="first">D</forename><surname>Cernea</surname></persName>
		</author>
		<ptr target="http://kluedo.ub.uni-kl.de/frontdoor/index/index/docId/4051" />
		<title level="m">User-Centered Collaborative Visualization</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
		<respStmt>
			<orgName>University of Kaiserslautern</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Graphtrail: Analyzing large multivariate, heterogeneous networks while supporting exploration history</title>
		<author>
			<persName><forename type="first">C</forename><surname>Dunne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Henry Riche</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Metoyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Robertson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the SIGCHI conference on human factors in computing systems</title>
		<meeting>the SIGCHI conference on human factors in computing systems</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="1663" to="1672" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">From visual exploration to storytelling and back again</title>
		<author>
			<persName><forename type="first">S</forename><surname>Gratzl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Lex</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Gehlenborg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Cosgrove</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Streit</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Graph. Forum</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="491" to="500" />
			<date type="published" when="2016-06">Jun 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">PANDA: prototyping using annotation and decision analysis</title>
		<author>
			<persName><forename type="first">J</forename><surname>Hak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Winckler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Navarre</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EICS 2016</title>
		<editor>
			<persName><forename type="first">K</forename><surname>Luyten</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><forename type="middle">A</forename><surname>Palanque</surname></persName>
		</editor>
		<meeting>EICS 2016</meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Language engineering tools for collaborative corpus annotation</title>
		<author>
			<persName><forename type="first">H</forename><surname>Cunningham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Tablan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Bontcheva</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Corpus Linguistics</title>
		<meeting>Corpus Linguistics</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page">9</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title/>
		<author>
			<persName><surname>Kibana</surname></persName>
		</author>
		<ptr target="https://www.elastic.co/kibana" />
		<imprint>
			<date type="published" when="2022-01">2022. January 2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">ANALEC: a new tool for the dynamic annotation of textual data</title>
		<author>
			<persName><forename type="first">F</forename><surname>Landragin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Poibeau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Victorri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Language Resources and Evaluation (LREC 2012)</title>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A Survey on Data Quality: Classifying Poor Data</title>
		<author>
			<persName><forename type="first">N</forename><surname>Laranjeiro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">N</forename><surname>Soydemir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bernardino</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings -2015 IEEE 21st Pacific Rim International Symposium on Dependable Computing</title>
		<meeting>-2015 IEEE 21st Pacific Rim International Symposium on Dependable Computing</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Capturing Design Decision Rationale with Decision Cards</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">G</forename><surname>Lopez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Rovelo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Haesen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Luyten</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Coninx</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IFIP Conference on Human-Computer Interaction</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Analytic provenance in practice: The role of provenance in real-world visualization and data analysis environments</title>
		<author>
			<persName><forename type="first">K</forename><surname>Madanagopal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">D</forename><surname>Ragan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Benjamin</surname></persName>
		</author>
		<idno type="DOI">10.1109/MCG.2019.2933419</idno>
		<ptr target="https://doi.org/10.1109/MCG.2019.2933419" />
	</analytic>
	<monogr>
		<title level="j">IEEE Computer Graphics and Applications</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="30" to="45" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Annotation: From paper books to the digital library</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">C</forename><surname>Marshall</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Second ACM International Conference on Digital Libraries</title>
		<meeting>the Second ACM International Conference on Digital Libraries</meeting>
		<imprint>
			<biblScope unit="page" from="131" to="140" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<idno type="DOI">10.1145/263690.263806</idno>
		<ptr target="https://doi.org/10.1145/263690.263806" />
		<title level="m">DL &apos;97</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Towards a Visual Approach for Representing Analytical Provenance in Exploration Processes</title>
		<author>
			<persName><forename type="first">A</forename><surname>Menin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Cava</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">M D S</forename><surname>Freitas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Corby</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Winckler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">25th International Conference Information Visualisation</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">An extensive review of tools for manual annotation of documents</title>
		<author>
			<persName><forename type="first">M</forename><surname>Neves</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>eva</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Briefings in bioinformatics</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Sensemap: Supporting browser-based online sensemaking through analytic provenance</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">H</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bardill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Salman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Herd</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">W</forename><surname>Wong</surname></persName>
		</author>
		<idno type="DOI">10.1109/VAST.2016.7883515</idno>
		<ptr target="https://doi.org/10.1109/VAST.2016.7883515" />
	</analytic>
	<monogr>
		<title level="m">2016 IEEE Conference on Visual Analytics Science and Technology (VAST)</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="91" to="100" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Analytic provenance: process+ interaction+ insight</title>
		<author>
			<persName><forename type="first">C</forename><surname>North</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Endert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Dou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>May</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Pike</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Fink</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CHI Extended Abstracts Human Factors in Computing Systems</title>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="33" to="36" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Characterizing provenance in visualization and data analysis: an organizational framework of provenance types and purposes</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">D</forename><surname>Ragan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Endert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sanyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on visualization and computer graphics</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="31" to="40" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title/>
		<author>
			<persName><surname>Tableau</surname></persName>
		</author>
		<ptr target="https://www.public.tableau.com/s" />
		<imprint>
			<date type="published" when="2022-01">2022. January 2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Supporting reasoning with different types of evidence in intelligence analysis</title>
		<author>
			<persName><forename type="first">A</forename><surname>Toniolo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">J</forename><surname>Norman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Etuk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Cerutti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">W</forename><surname>Ouyang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Oren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Dropps</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Allen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Sullivan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 International Conference on Autonomous Agents and Multiagent Systems</title>
		<meeting>the 2015 International Conference on Autonomous Agents and Multiagent Systems</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="781" to="789" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">The Glozz platform: a corpus annotation and mining tool</title>
		<author>
			<persName><forename type="first">A</forename><surname>Widl枚cher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Mathet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">DocEng &apos;12: Proceedings of the 2012 ACM symposium on Document engineering</title>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Survey on the analysis of user interactions and visualization provenance</title>
		<author>
			<persName><forename type="first">K</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ottley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Walchshofer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Streit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wenskovitch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics Forum</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="757" to="783" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
