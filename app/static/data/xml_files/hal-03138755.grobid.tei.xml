<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Ensuring the Consistency between User Requirements and Task Models: A Behavior-Based Automated Approach</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Rocha</forename><surname>Thiago</surname></persName>
							<email>thiago.silva@lero.ie</email>
						</author>
						<author>
							<persName><surname>Silva</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Marco</forename><surname>Winckler</surname></persName>
							<email>winckler@unice.fr</email>
						</author>
						<author>
							<persName><forename type="first">Thiago</forename><surname>Rocha</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Lero -The Irish Software Research Centre</orgName>
								<orgName type="institution">University of Limerick (UL)</orgName>
								<address>
									<country key="IE">Ireland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="laboratory">SPARKS-I3S</orgName>
								<orgName type="institution">Université Nice Sophia Antipolis (Polytech)</orgName>
								<address>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="department">IDI</orgName>
								<orgName type="laboratory">HALLVARD TRAETTEBERG</orgName>
								<orgName type="institution">Norwegian University of Science and Technology (NTNU)</orgName>
								<address>
									<country key="NO">Norway</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="department">Lero -The Irish Software Research Centre</orgName>
								<orgName type="institution">University of Lim-erick (UL)</orgName>
								<address>
									<settlement>Limerick</settlement>
									<country key="IE">Ireland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff4">
								<orgName type="laboratory">SPARKS-I3S</orgName>
								<orgName type="institution">Université Nice Sophia Antipolis (Polytech)</orgName>
								<address>
									<settlement>Sophia Antipolis</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff5">
								<orgName type="institution">Norwegian University of Science and Technology (NTNU)</orgName>
								<address>
									<settlement>Trondheim</settlement>
									<country key="NO">Norway</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Ensuring the Consistency between User Requirements and Task Models: A Behavior-Based Automated Approach</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">10FAA36C1673C6918FD66F301CA346AB</idno>
					<idno type="DOI">10.1145/3394979</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-04-12T14:47+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Human-centered computing → User centered design</term>
					<term>• Software and its engineering → Software verification and validation Behavior-Driven Development (BDD)</term>
					<term>User Stories</term>
					<term>Task Models</term>
					<term>Automated Requirements Assessment</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Evaluating and ensuring the consistency between user requirements and modeling artifacts is a long-time issue for model-based software design. Conflicts in requirements specifications can lead to many design errors and have a decisive impact on the quality of systems under development. This article presents an approach based on Behavior-Driven Development (BDD) to provide automated assessment for task models, which are intended to model the flow of user and system tasks in an interactive system. The approach has been evaluated by exploiting user requirements described by a group of experts in the domain of business trips. Such requirements gave rise to a set of BDD stories that have been used to automatically assess scenarios extracted from task models that were reengineered from an existing web system for booking business trips. The results have shown our approach, by performing a static analysis of the source files, was able to identify different types of inconsistencies between the user requirements and the set of task models analyzed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CCS Concepts: •</head></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Modeling is recognized as a crucial activity to manage the abstraction and the inherent complexity of developing software systems. Several aspects of information, from the macro business goals until the most detailed information about user tasks, are taken into account while modeling. The outcomes of modeling activities are registered by means of software artifacts. Artifacts encode a particular interpretation of a problem situation and a particular set of solutions for the perceived problem <ref type="bibr" target="#b10">[10]</ref>.</p><p>Requirements and artifacts are also expected to evolve along the project according to the users' changing perception about their own needs. In iterative processes, the cycle of producing and evolving requirements artifacts permeates all the phases of system development, from requirements and business analysis until software testing. Artifacts are useful even after the software development has finished, for software maintenance and evolution purposes, since they encompass models describing the record of implemented requirements, which strategies were used to implement the features, how the system architecture has been structured, and so on. Therefore, requirements should be described in a consistent way across multiples versions of artifacts which is a quite challenging activity <ref type="bibr" target="#b51">[51]</ref>. Requirements specifications should not, for example, describe a given requirement in a User Story that is conflicting with its representation in a task model.</p><p>Behavior-Driven Development (BDD) <ref type="bibr" target="#b4">[5]</ref> has stood out in the software engineering community as an effective approach to provide automated acceptance testing by specifying natural language user requirements and their tests in a single textual artifact. BDD benefits from a requirements specification based on User Stories (US) <ref type="bibr" target="#b6">[7]</ref> which are easily understandable for both technical and non-technical stakeholders. In addition, User Stories allow specifying "executable requirements", i.e. requirements that can be directly tested from their textual specification. Despite its benefits providing automated testing of user requirements, BDD and other testing approaches focus essentially on assessing fully implemented versions of the system. Since long time ago, it is a peaceable argument that providing early assessment is very helpful for detecting errors before making strong commitments with the software implementation <ref type="bibr" target="#b49">[49]</ref>. Nonetheless, as far as early artifacts such as task models are concerned, current approaches offer no support for automated assessment.</p><p>Motivated by such a gap, this article presents an approach based on BDD and User Stories to support the automated assessment of the consistency between user requirements and task models. The common-ground of concepts for describing the artifacts and verifying their consistency is provided by means of an ontology <ref type="bibr" target="#b35">[35]</ref>, <ref type="bibr" target="#b38">[38]</ref>. The following sections present the foundations and related work, the proposed approach with its technical implementation, and the results we got by assessing the reengineered task models from an existing web system to book business trips.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">FOUNDATIONS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Behavior-Driven Development and User Stories</head><p>According to Smart <ref type="bibr" target="#b41">[41]</ref>, BDD is a set of software engineering practices designed to help teams focus their efforts on identifying, understanding, and building valuable features that matter to businesses. BDD practitioners use conversations around concrete examples of system behavior to help understand how features will provide value to the business. BDD encourages business analysts, software developers, and testers to collaborate more closely by enabling them to express requirements in a more testable way, in a form that both the development team and business stakeholders can easily understand. BDD tools can help turn these requirements into automated tests that help guide the developer, verify the feature, and document the application.</p><p>BDD specification is based on User Stories and scenarios which allows to specify executable requirements and test specifications by means of a Domain-Specific Language (DSL) provided by Gherkin <ref type="bibr" target="#b15">[15]</ref>. User Stories were firstly proposed by Cohn <ref type="bibr" target="#b6">[7]</ref>. BDD added the description of scenarios to the User Stories in order to provide, in a single artifact, the requirements specification along with the set of acceptance criteria which is required to assess whether the system behaves in accordance with such requirements. North <ref type="bibr" target="#b27">[27]</ref> proposed a template for this particular kind of User Story and named it as "BDD story" (Figure <ref type="figure" target="#fig_18">1</ref>).</p><p>According to this template, a BDD story is described with a title, a narrative and a set of scenarios representing acceptance criteria, giving concrete examples about what need to be tested to consider a given feature as done. The title provides a general description of the story, referring to a feature this story represents. The narrative describes the referred feature in terms of the role that will benefit from the feature, the feature itself, and the benefit it will bring to the business. The acceptance Fig. <ref type="figure" target="#fig_18">1</ref>. "BDD story" template <ref type="bibr" target="#b27">[27]</ref> criteria are defined through a set of scenarios, each one with a title and three main clauses: "Given" to provide preconditions for the scenario, "When" to describe an event that will trigger the scenario and "Then" to present outcomes that might be checked to verify the proper behavior of the system. Each one of these clauses can include an "And" statement to provide multiple contexts, events and/or outcomes. Each statement in this representation is called a "step".</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Task Models</head><p>Task models (TM) provide a goal-oriented description of interactive systems but avoiding the need for the level of detail required for a full description of the user interface. Tasks can be specified at various abstraction levels, describing an activity that has to be carried out to fulfil the user's goals. By modeling tasks, designers are able to describe activities in a fine granularity, for example, covering the temporal sequence of tasks to be carried out by the user or system, as well as any preconditions for each task <ref type="bibr" target="#b30">[30]</ref>. The use of task models serves as multiple purposes such as better understanding the application under development (and in particular its use), being a "record" of multidisciplinary discussions between multiple stakeholders, helping the design, the usability evaluation, the performance evaluation, and the user in performing the tasks (acting as a contextual help). Task models are also useful as documentation of requirements both related with content and structure.</p><p>By manipulating task models, we can obtain scenarios that represent the valid interaction paths in the system. This characteristic is particularly useful when identifying test scenarios for the system. Being scenarios a description of a specific use in a specific context, and task models descriptions of possible activities and their relationships, scenarios support task development while task models can support the identification of scenarios.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.1">An Overview of HAMSTERS. Human-centered Assessment and Modeling to Support Task</head><p>Engineering for Resilient Systems (HAMSTERS) <ref type="bibr" target="#b25">[25]</ref> is a notation inspired by other existing ones for task modeling, especially CTT <ref type="bibr" target="#b29">[29]</ref>. HAMSTERS includes extensions such as preconditions associated with task executions, data flow across task models, and more detailed interactive tasks. HAMSTERS' models can be edited and simulated in a dedicated environment which also provides a dedicated API for observing, editing, and simulating events, making it possible to connect task models to system models.</p><p>Tasks representation in HAMSTERS can be of several types as illustrated in Figure <ref type="figure" target="#fig_0">2</ref>. Abstract task is a task that involves sub-tasks of different types. System task is a task performed only by the system. User task is a generic task describing a user activity. It can be specialized as a motor task (e.g. a physical activity), a cognitive task (e.g. decision making, analysis), or perceptive task (e.g. perception of alert). Finally, interactive task represents an interaction between the user and the system; it can be refined into input task when the users provide input to the system, output task when the system provides an output to the user and input/output task which is a mix of both but performed in an atomic way. Tasks can also have properties. Tasks may be optional, iterative or both optional and iterative. In addition, minimum and maximum execution time can also be set for tasks, and particularly for iterative tasks, it can also be set the information flows. Temporal relationships between tasks are represented by means of operators. The operator "Enable" (&gt;&gt;), for example, describes that the tasks T1 and T2 occur sequentially, one after the other. Other operators such as "Concurrent" (|||), "Choice" ([]), and "Order independent" (|=|) describe respectively that tasks can be held simultaneously, the choice of one implies that the other will be disabled, or that the user can choose whether he will perform one or another task first.</p><p>The use of operators to link tasks in the model allows extracting the possible scenarios to be performed in the system. This is done by following the multiple achievable paths in the model, with each combination of them generating an executable scenario. HAMSTERS tool supports innately the extraction of scenarios from task models, by simulating their execution and extracting the possible achievable paths. By extracting all the possible scenarios that could be performed in the model, we have a big picture about what (in terms of tasks) can be done with the system. HAMSTERS also provides detailed means for describing data that is required and manipulated in order to accomplish tasks. By using the HAMSTERS' simulation mode, we can set test data at runtime when performing an input task that points to an object in the model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">An Ontology for Supporting Automated Assessment of GUI-related artifacts</head><p>Our approach for supporting automated assessment is based on our previous works which explore an ontology to describe common behaviors with a standard vocabulary for writing BDD stories <ref type="bibr" target="#b35">[35]</ref>, <ref type="bibr" target="#b38">[38]</ref>. The main benefit of this strategy is that BDD stories using this common vocabulary can support specification and execution of automated test scenarios on GUI-related artifacts. The ontology covers concepts related to presentation and behavior of interactive components used in web and mobile applications. It also models concepts describing the structure of BDD stories, tasks, scenarios, and GUIs.</p><p>The dialog part of a GUI is described by means of concepts borrowed from abstract state machines. The BDD scenario meant to be run in a given GUI is represented as a transition. States are used to represent the original and resulting GUIs after a transition occur. Scenarios in the transition state always have at least one or more conditions (represented in scenarios by the "Given" clause), one or more events (represented in scenarios by the "When" clause), and one or more actions (represented in scenarios by the "Then" clause). The presentation part of a GUI is described in the ontology through interaction elements which represent an abstraction of the different widgets commonly used in web and mobile user interfaces.</p><p>The interactive behaviors in the ontology describe textually how users are supposed to interact with the system whilst manipulating interaction graphical elements of the user interface. An example of behavior specification is illustrated by Figure <ref type="figure" target="#fig_1">3</ref>. The specification of behaviors encompasses when the interaction can be performed (using "Given", "When" and/or "Then" clauses), and which interaction elements (i.e. CheckBoxes, TextFields, Buttons, etc.) can be affected. Altogether, interactive behaviors and interaction elements are used to implement the test of the expected system behavior. In the example of Figure <ref type="figure" target="#fig_1">3</ref>, the behavior "I choose '&lt;value&gt;' referring to '&lt;field&gt;'" has two parameters: "&lt;value&gt;" and "&lt;field&gt;". The first parameter is associated to data, whilst the second parameter refers to the name given to one of the interaction elements supported by this behavior, which in this example are Radio Buttons, CheckBoxes, Calendars and Links. In green is highlighted the interactive behavior itself (in this case, named in the ontology as chooseReferringTo) which will be used for assessing the task name after applying a formatting rule described in Section 5.1. The ontological model describes only behaviors that report steps performing actions directly on the user interface through interaction elements. This is a powerful resource because it allows keeping the ontological model domain-free, which means it is not subject to particular business characteristics in the BDD stories, promoting the reuse of steps in multiple scenarios. Thus, steps can be easily reused to build different behaviors for different scenarios in different business domains. When representing the various interaction elements that can attend a given behavior, the ontology also allows extending multiple design solutions for the GUI while still keeping the consistency of the interaction. This kind of flexibility leaves the designer free for choosing the best solutions in a given time of the project, without modifying the behavior specified for the system. The current version of the ontology covers more than 60 interactive behaviors and almost 40 interaction elements for both web and mobile user interfaces. A full list of interactive behaviors and interaction elements covered by the ontology can be found in Silva et al. <ref type="bibr" target="#b38">[38]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">RELATED WORK</head><p>Since the early 90's, diverse approaches for improving quality have been studied mainly in the context of viewpoints, both for assessment of requirements acquisition <ref type="bibr" target="#b17">[17]</ref>, <ref type="bibr" target="#b18">[18]</ref> as well as in the context of specification consistency <ref type="bibr" target="#b28">[28]</ref>. Viewpoints Oriented Requirements Definition (VORD) was proposed by Kotonya and Somerville <ref type="bibr" target="#b17">[17]</ref> as a method to tackle requirements engineering from a viewpoint level. Interactive systems, whose operations involve a degree of user interaction, have a serious problem in identifying and ensuring that all the clients' needs are recognized in a valid way. The VORD method is useful in detecting these user needs, and also identifying the services that a user expects from the system by providing a structured method for collecting, documenting, analyzing, and specifying viewpoints and their requirements <ref type="bibr" target="#b31">[31]</ref>. These methods, however, were targeted to improve the quality and ensure some level of consistency within the requirements specification itself and not between the requirements and other software development artifacts as proposed by our approach.</p><p>Even with these and other efforts, artifacts other than final versions of user interfaces are not commonly tested. A common argument is that they cannot be "executed" in order to be tested. Artifacts like task models are usually only inspected manually in an attempt to verify its adequacy <ref type="bibr" target="#b44">[44]</ref>. Inspections can be of different types including formal technical reviews, walkthroughs, peer desk check, informal ad-hoc feedback, and so on <ref type="bibr" target="#b45">[45]</ref>. When evaluation of the user requirements representation on such artifacts is considered, requirements traceability techniques are employed as a way to trace such requirements along their multiple versions (horizontal traceability) or along their representation in another artifacts (vertical traceability) <ref type="bibr" target="#b12">[12]</ref>.</p><p>Like in our approach which extracts scenarios from task models, other authors <ref type="bibr" target="#b40">[40]</ref>, <ref type="bibr" target="#b1">[2]</ref>, <ref type="bibr" target="#b2">[3]</ref> have studied means of manipulating task models for obtaining test scenarios. Since a task model describes the whole set of tasks a user can perform in the system, besides providing the set of multiple paths that users are able to follow to accomplish such a task, test cases are obtained by going through these multiple paths, gathering a different execution scenario for each possible path. Therefore, all notations and tools for task modeling provide some kind of mechanism for extracting the set of possible scenarios by simulating a model execution. However, unlike these authors which exploit these multiple paths extracted from task models to generate test scenarios, we use these paths in our approach to allow a direct comparison with the scenarios specified in the BDD stories (which, by the way, already include test scenarios) and then to point out the inconsistencies between them.</p><p>There is also an intrinsic relationship between task modeling and user interface design. Wolff et al. <ref type="bibr" target="#b52">[52]</ref> proposes to link GUI specifications to abstract dialogue models. Specifications are linked to task models describing behavioral characteristics. Prototypes of interactive systems are refined and interactively generated using a GUI editor. The design cycle goes from task model to abstract user interfaces and finally to a concrete user interface. It is an interesting approach to have a mechanism to control changes in interface elements according to the task to which they are associated in the task models. A similar work is proposed by Luyten et al. <ref type="bibr" target="#b22">[22]</ref>. The authors present an algorithm to partially extract the dialog model from the task model. A State Transition Network is proposed to formalize the activity chain which can be partially extracted out of the task specification. The approach allows to verify whether the task and dialog model are consistent. This approach is also useful in automatic user interface generation where several different dialogs are involved. These approaches, however, are oriented to the generation of prototypes and/or dialog models from specifications instead of assessing and verifying the consistency of these models and prototypes with behavior-based user requirements.</p><p>Martinie et al. <ref type="bibr" target="#b24">[24]</ref>, followed by Campos et al. <ref type="bibr" target="#b3">[4]</ref>, propose a tool-supported framework and a model-based testing approach to support linking task models to an existing, executable, and interactive application. The framework allows developers to define a systematic correspondence between the user interface elements and user tasks. The problem with this approach is that it only covers the interaction of task models with a concrete fully-functional user interface, not covering the assessment of task models concerning user requirements specifications. Another problem is that it requires too much intervention of developers to prepare the source code to support the integration, making it difficult to be adopted in applications that cannot receive interventions at the code level.</p><p>As far as a common vocabulary is a concern (such as defined in the supporting ontology of our approach), the W3C published a glossary of recurrent terms for presentation components called MBUI (Model-based User Interface) <ref type="bibr" target="#b32">[32]</ref> on which our work was based. For the dialog component, SWC <ref type="bibr" target="#b50">[50]</ref> and SXCML (State Chart XML: State Machine Notation for Control Abstraction) <ref type="bibr" target="#b0">[1]</ref> have offered a language based on the state machine concepts. Some authors have also tried to establish a linguistic task modeling for designing user interfaces. Khaddam et al. <ref type="bibr" target="#b16">[16]</ref> presented a linguistic task model and notation. The model aims to separate the task and the semantic levels by adopting a well-defined set of task identification criteria. The provided notation enables identification of task input elements based on the task state diagram that is configured on each task. The notation also addressed the dynamic aspect of modeling by introducing dynamic tasks and pumping tasks. This work differs from ours by being focused on the quality of the task specification itself whilst our approach is focused on assessing whether the task specification is consistent with the user requirements specification provided by the BDD stories.</p><p>Finally, BDD is nowadays one of the primary software development methods for specifying automated natural language user requirements. Efforts to specify requirements in natural language are not recent though. Language Extended Lexicon (LEL) <ref type="bibr" target="#b19">[19]</ref>, for example, has been studied since the 90's. The authors propose a lexical analysis of requirements descriptions in order to integrate scenarios into a requirements baseline, making possible tracing their evolution. They were followed by other attempts to identify test cases from requirements specified in natural language <ref type="bibr" target="#b42">[42]</ref>, <ref type="bibr" target="#b11">[11]</ref>.</p><p>BDD stories have been also evaluated <ref type="bibr" target="#b20">[20]</ref> and the characteristics analyzed and studied <ref type="bibr" target="#b43">[43]</ref>, <ref type="bibr" target="#b13">[13]</ref> by several authors. In different contexts from those investigated by our approach, studies have also been conducted to explore the use of BDD as part of empirical analysis of acceptance test-driven development <ref type="bibr" target="#b26">[26]</ref>. Other studies have concentrated in the use of automated acceptance testing to support BDD traceability <ref type="bibr" target="#b21">[21]</ref>, or in analyzing its compatibility with business modeling <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b9">[9]</ref>, enterprise modeling <ref type="bibr" target="#b47">[47]</ref>, <ref type="bibr" target="#b48">[48]</ref>, <ref type="bibr" target="#b46">[46]</ref> and with BPMN <ref type="bibr" target="#b23">[23]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">THE PROPOSED APPROACH</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Strategy for Assessing Task Models</head><p>Both task models and BDD stories support the description of multiple sequences of tasks or actions to be performed by the user/system by means of scenarios. This fact allows us to compare these corresponding sequences in the artifacts and identify whether a given sequence in an artifact can be seen as conflicting with an equivalent sequence in another one. This kind of assessment is illustrated in Figure <ref type="figure" target="#fig_2">4</ref>.</p><p>In the example illustrated in Figure <ref type="figure" target="#fig_2">4</ref>, we can notice the steps A-G from different scenarios of different stories being assessed against a task model and a scenario extracted from it. Therein, the step A at the first position of the first US scenario finds a corresponding task A in the task model once this task could be extracted at the same first position in the TM scenario. In the sequence, the step B at the second position of the first US scenario finds a corresponding task B in the task model which drives the scenario to a specific path in the task model. This task B could be extracted at the same second position in the TM scenario. The other steps and tasks can be analyzed in a similar manner. Notice that the path represented by the sequence of tasks A-B-D-F-G in the task model is only one of the possible combinations of tasks giving origin to the respective TM extracted scenarios presented in the figure.</p><p>Therefore, our strategy for assessment is to analyze both the match between step and task names and their respective position in both scenarios. As the steps in BDD scenarios usually contain more information than it is present in the task names, we firstly apply a formatting rule to the step name before comparing it to a task name. This process is described in detail in Section 5.1. After getting the name of the task to be assessed, we search for that task in the set of scenarios extracted from the task models and if it is found, we evaluate the position in which it has been found in the TM scenario comparing to the position of the corresponding step in the BDD scenario. In this case, an inconsistency would be identified if, for example, the step D (which is at the third position in the BDD scenario) found its corresponding task D at the fourth position in the TM scenario. Thus, in summary, we consider there is an inconsistency when: i We do not find a corresponding task in the TM scenario to match the formatted name of the corresponding step in the BDD scenario, or ii We find a corresponding task in the TM scenario but at a different position of the corresponding step in the BDD scenario.</p><p>The complete automated assessment process to identify these inconsistencies in the TM scenarios is presented in Section 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Preconditions for Assessment</head><p>Task models can be designed through a diverse set of notations and tools. For being assessed under our approach though, they need to comply with two premises:</p><p>i Allow extraction of scenarios, and ii Export source files of both reference model and extracted scenarios in a markup language.</p><p>The assessment of task models can be performed by either a static or a co-execution approach. The static assessment implies analyzing the source files of the model without actually simulating the execution of the model, whilst co-execution approaches execute it step-by-step providing a visual feedback of the tasks that are being under execution at a given time. Our strategy for testing performs a static assessment of the source files by means of a syntactic and semantic analysis of the targeted source files. An advantage of this strategy is that, unlike co-execution approaches where artifacts under testing must be prepared for assessment by annotating or modifying their source files, in our approach we have no need to intervene in the source code of the target artifacts, i.e. artifacts do not need to be prepared for testing by designers, so task models and requirements specifications can be assessed in their original state.</p><p>In this article, we make use of task models modeled by HAMSTERS once the notation and tool fit our two premises stated above. HAMSTERS exports its task models and extracted scenarios using the XML standard, a well-adopted markup language, so recognized by our approach. The task modeling and the extraction of scenarios that will be presented hereafter has been made by using the HAMSTERS tool, whilst the implementation of the assessment has been made by using the respective XML source files produced by the HAMSTERS tool for each model.</p><p>Figure <ref type="figure" target="#fig_3">5</ref> shows elements from the HAMSTERS meta-model (left-side of the figure) and how they relate to the elements from the BDD story meta-model (right-side of the figure). As the tasks are analyzed only after being extracted from the task models for a given TM scenario, the comparison between elements from the meta-models is made only between the Task element (from the HAMSTERS meta-model) and the Step element (from the BDD story meta-model). After the step is formatted following the rule presented in Section 5.1, the corresponding behavior should match one of the interactive behaviors described in the ontology. BDD stories and task models must also be at the same abstraction level in order to be assessed, i.e. at the interaction level. At the beginning of a software development project, a single and more comprehensive model can initially be used to represent a higher abstraction level, but at some point, it should be refined to the interaction level in order to be assessed by our approach. Hence, to guarantee the validity of the input and in order to ensure the BDD stories and the scenarios extracted from task models are actually comparable, the designers must, first of all, ensure that both artifacts have the same granularity and level of detail.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Steps for Performing the Approach</head><p>Depending on the project phase, our approach can be applied in two ways. The first one is applied when the project is running, and task models have already been designed. In such a case, our approach can be used to assess such artifacts, indicating where they are not in accordance with the specified requirements. The second one refers to a project in the beginning, where no task models have been designed yet. In this case, by using the proposed set of interactive behaviors from the ontology, they can be modeled in a consistent way from the beginning.  Notice that regardless the path chosen, the extraction of scenarios from task models (which may be a manual or an automated process depending on the tool used) is only possible after having designed the task models (a manual process), and the identification of requirements (a manual process as well) is a precondition for all the other activities. Finally, to run the assessment on the task models (a fully automated process), it is required to have extracted scenarios from them and written the formatted BDD stories. After running the assessment, the inconsistencies identified can be fixed by redesigning either the task models or the BDD stories (black dotted lines). The approach is intended to benefit requirements engineers and interaction designers in the first place; thus, they are the main stakeholders involved who are responsible to gather and writing the BDD stories besides modeling the task models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Challenges associated with the extraction of scenarios</head><p>Task models can be tricky to manipulate once the number of possible scenarios can scale exponentially due to the complexity of the model. Different operators, the presence of optional tasks, the number of times an interactive task can be executed, etc. make the extraction of scenarios for testing a very complex activity. Campos et al. <ref type="bibr" target="#b2">[3]</ref> illustrate this problem and propose a catalog of strategies for modifying the models in order to manage the complexity of the resulting set of extracted scenarios. An easy-to-see consequence of such kind of strategy is that models are not fully manipulated, i.e. the reference model for extracting test scenarios is a simplified instance (a subset) of the original model. Consequently, several nuances of modeling (such as the use of multiple operators, non-interactive tasks, etc.), which allow task models being a rich representation of human activities when interacting with the system, are lost and cannot be verified or even taken into account when obtaining scenarios.</p><p>In order to exemplify this problem, Figure <ref type="figure" target="#fig_6">7</ref> takes an example of our current approach for extracting scenarios from task models. The model presents a short extract of some tasks (1 in Figure <ref type="figure" target="#fig_6">7</ref>) involved in the process of booking flight tickets through a generic flight booking system. Therein, an abstract task named "Provide Data" generalizes a sequence of 5 tasks that can be performed in any order. This attribute is signalized by the operator "Order Independent" (|=|) placed between "Provide Date" and the other 5 tasks. Thus, one of the possible scenarios that could be extracted from this model is presented further (3 in Figure <ref type="figure" target="#fig_6">7</ref>). Therein, tasks are performed in the order they are visually presented in the model, i.e. first the user informs a destination and a departure, then he/she chooses the number of passengers, sets the departure date, and finally chooses his/her trip type.</p><p>Notice that the XML source file of the extracted scenario (4 in Figure <ref type="figure" target="#fig_6">7</ref>) is just a sequential description of tasks in the model that have been settled for execution. The file brings for each task only a reference for its ID (it does not even bring the name of the task), the source task model, and the date/time of execution. The XML source file of the task model itself (2 in Figure <ref type="figure" target="#fig_6">7</ref>) is, on the other hand, a richer description of task modeling elements, including tasks of several types, operators, constraints related to the number of iterations each task supports, tasks that are optional, maximum and minimum time of execution, levels of criticality and so on.</p><p>Therefore, we can easily realize that the manipulation of XML source files of task models brings us a full range of challenges. For example, as pointed out by Campos et al. <ref type="bibr" target="#b2">[3]</ref>, the presence of "order independent" operators between subtasks is a major contributor to the state explosion in the state machine generated from a task model. Considering a simple example in Figure <ref type="figure" target="#fig_6">7</ref>, although the task model has only five subtasks following the abstract task "Provide Data", the resultant number of possible combinations of tasks (resulting in scenarios) is equal to 120. This happens because we must consider all the permutations of the five tasks' execution. By following all the leaves in a task model with multiple operators, we notice that the number of possible scenarios for extraction gets exponential in function of the types of these operators. That is the reason by which authors working with task model exploitation for generating scenarios or test cases usually control such an extraction, in order to reduce the complexity and the resultant number of combinations. This becomes especially challenging if task models specify collaborative activities with several instances of the same role.</p><p>Like other authors, we have also followed a strategy based on the extraction of scenarios from task models for obtaining test scenarios to check the quality of such models, but unlike other approaches, we have not controlled such an extraction, which allowed us to keep important aspects of the interaction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">IMPLEMENTATION</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Formatting Rule for Task Names</head><p>As task models are designed to support the multiple paths that users may accomplish to perform their tasks, assessing such models in a scenario-based approach involves initially extracting the possible scenarios that are supposed to be tested at a given time. It means that after modeling, designers should define which branches of the model will be tested. The equivalence of steps in BDD stories and tasks in scenarios extracted from task models is supported by our aforementioned ontology <ref type="bibr" target="#b35">[35]</ref>, <ref type="bibr" target="#b38">[38]</ref> which provides the set of interactive behaviors supported. Our testing algorithm retrieves the respective behavior from the ontology and performs a formatting rule in the step name as exemplified in Figure <ref type="figure" target="#fig_7">8</ref> in order to verify whether a behavior described in a step has an equivalent task to model it in the task model. This rule aims to eliminate unnecessary components of the step name that do not need to be present in the task. In the example, the component "When" refers to the transition in the state machine which is not addressed in a task model. The subject "I" signalizes that is the user who performs the task. Task models already encompass the definition of user role, so the statement "I" refers to any users that might correspond to the role assigned to the task model. The verb "set" indicates the action (interactive behavior) that will be performed by the user, so it begins to name the task in the task model. The value "Valid Departure Date" indicates the test data domain that Signalizes that an interaction component (a "field" in this case) will be called.</p><p>Not used because it is just a complement of the interactive behavior name and usually does not compose the task name.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>"Departure</head><p>Date" (Interaction Element Name)</p><p>Indicates the name of the interaction element that will be affected by this task.</p><p>Used for composing the final name of the task in the task model. will be used to perform and test the task (in this example, any valid value for a departure date of a flight). This is an information which is not present in the task name and it is provided only at runtime when simulating the execution of the task model. The interactive behavior complement "in the field" just signalizes that an interaction element (a "field" in this case) will be referenced in the sequence. This component is optional and it is not present in all interactive behaviors described in the ontology, so these complements are just dismissed when found. Finally, the target field "Departure Date" indicates the name of the interaction element that will be affected by this task, so it composes the final name of the task to be assessed in the task model. Table <ref type="table" target="#tab_0">1</ref> below summarizes the use of such components for forming the task names to be searched from the step names.</p><p>Table <ref type="table" target="#tab_1">2</ref> provides some examples of task names to be assessed after applying the formatting rule discussed above. Notice, for example, that the step And I inform "Departure City" and choose "Departure Airport" in the field "Departure", which actually encompasses two actions to be performed (inform "Departure City" and choose "Departure Airport"), is broken into two task names: "Inform Departure" and "Choose Departure". Notice also that for steps described in the passive voice (which is usual when describing outcomes to be verified in the clause "Then"), the resultant task name to be assessed is described in the active voice from the system point of view ("Display List of Available Flights", for example). This kind of task is usually described as an output task in the task model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Pre-formatting HAMSTERS Source Files</head><p>The automated assessment of task models is made by parsing the resultant XML source files of the extracted TM scenarios produced by the HAMSTERS tool. To do so, we have implemented an integrated algorithm in Java using JDOM and JUnit for parsing and testing the BDD stories against these artifacts. The first step for assessing the set of scenarios extracted from task models is to preformat their XML files. As each task model notation and tool has its own way to implement and export scenarios and models, and there is no such a standard for that, each notation would demand a different preformatting to be tested by our approach. We have implemented a solution for HAMSTERS in its current version (v4.0), but we have designed a flexible and open architecture where other notations could benefit from our approach by just implementing a new preformatting Java class in accordance with their own patterns to implement scenarios and models.</p><p>As mentioned before, HAMSTERS tool exports scenarios with only a reference to the task ID and the object ID that compose the flow. As such, we have to prepare the files for testing. So, before starting the assessment, we edit each XML file of the TM scenario to add:</p><p>• The name of the task referenced by each task ID.</p><p>• The information about the optionality of each referenced task.</p><p>• The object value associated with each task, if it has been provided during the task execution. All the information is recovered from the reference task model source file that actually contains the whole set of information about each task that has been modeled. Figure <ref type="figure">9</ref> illustrates an extract of the original (left side) XML scenario file, and the resultant (right side) XML scenario file after the process of preformatting.</p><p>Besides preformatting the XML files of the extracted scenarios, our algorithm also adds, for each scenario, an equivalent scenario without the optional tasks. This is made due to a limitation in the current version of the HAMSTERS tool that does not allow to extract scenarios without the optional tasks. The tool necessarily includes both optional and non-optional tasks present in the model during the process of extracting scenarios. Thus, in order to obtain scenarios without the optional tasks, we algorithmically generate new scenarios eliminating all the tasks signalized as optional in the set of scenarios extracted from HAMSTERS. Such new scenarios are named as "No Optional" followed by the original name of the scenario extracted from HAMSTERS. As a result, for each scenario extracted from HAMSTERS (necessarily including all optional tasks), we generate an additional similar scenario, but without all the optional tasks. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Performing the Assessment</head><p>The assessment of BDD scenarios and scenarios extracted from task models consists of verifying, for each step in the BDD scenario, if there are one or more corresponding tasks for such a step in the XML source files of the scenarios extracted from the task models. Corresponding tasks are searched after applying the formatting rule described in Section 5.1 to the name of the step in the BDD scenario. To do so, our algorithm illustrated below fixes a step in the BDD scenario ("Given I go to 'Find Flights'" for example) to be verified in the task model, following the mapping presented in Figure <ref type="figure" target="#fig_18">10</ref> ("Go to 'Find Flights'" in the example). Then we parse each task of each scenario in the XML source file looking for one or more correspondences to that step. If matches are found, then a list of matches is created, keeping the position in each scenario-task where the match has been found. The algorithm 1 presented below implements such a strategy.</p><p>The results of testing are shown in a log indicating, for each step of the BDD scenario, if and where a given step has found an equivalent task in the XML file analyzed, and once it carries an object value associated, which value it is. As scenarios in BDD stories and scenarios in task models may be ordered differently, the algorithm checks the whole set of XML files to ensure we are looking for all the instances of the searched task. Due to that, if there are several XML files of scenarios, the results in the log will show where a corresponding task has been found in each one Result: ListOfMatches for each step from the BDD scenarios do 𝑡𝑎𝑠𝑘𝑇𝑜𝐹𝑖𝑛𝑑 ← corresponding task from the ontology ; for each task from each XML source file do if the attribute taskname is equal to taskToFind then 𝐿𝑖𝑠𝑡𝑂 𝑓 𝑀𝑎𝑡𝑐ℎ𝑒𝑠 ← position(scenario,task); end end end Algorithm 1: Testing algorithm for assessing scenarios extracted from task models.</p><p>of them. In summary, the log of results shows, for each step of the BDD scenario, the results of searching in each TM scenario file (".scen"). Each line of results brings then:</p><p>• the name of the scenario in which the search has been carried out,</p><p>• the task name that has been searched for,</p><p>• the position in which the task has been found (if so), otherwise is shown the message "Task not found!", and • the object value associated with each task (if any), otherwise is shown the message "No Value".</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Tool Support</head><p>The testing algorithm we have just described above has been implemented in Java. The project has been structured in two packages. The first one encompasses the classes for implementing the solution. This package contains four classes: MySteps, MyTest, MyXML and PrepareFiles. MySteps implements the mapping between the interactive behaviors described in the ontology and the assertion that should be made when checking scenarios from task models. MyXML implements methods for parsing scenario files extracted from task models in their XML files. MyTest is the JUnit class that triggers the set of BDD stories that have been selected for assessment. Finally, PrepareFiles is the class in charge of preformatting the scenario source files extracted from task models, as described in Section 5.2.</p><p>The second package encompasses the resources demanded for running the assessment. Two folders "stories" and "scenarios" encompass respectively the set of BDD (User) stories text files that have been specified for the project (with a ".story" extension), and the current scenario's XML files extracted from task models under assessment before and after the process of preformatting. Finally, a third folder named "task models" keeps the reference XML source files for the task models under assessment. Such files are useful to allow the process of preformatting.</p><p>Figure <ref type="figure" target="#fig_9">11</ref> represents the flow of calls we have designed in our algorithm for running a battery of tests on task model scenarios. The flow starts with the class "MyTest.java". First of all, this class instantiates an object from "PrepareFiles.java" (flow 1) in order to trigger the process of preformatting mentioned before. Such a process runs on the package of task model scenarios (flow 2), naming the extracted tasks and adding useful complementary information for testing. For that, the process asks the reference source file (".hmst") of the corresponding task model mentioned by each task in the scenario. After getting the scenario files formatted, "MyTest.java" includes the BDD (User) story (or the set of BDD stories) that will be assessed (flow 3).</p><p>Each one of the steps in the BDD (User) story under testing makes a call to the class "MySteps.java" (flow 4) that knows which behaviors are supported by the ontology. Based on the behavior referenced by the step, this class makes a call to the class "MyXML.java" (flow 5) in charge of parsing all the set of task model scenarios (flow 6). This parsing aims to check if the behavior addressed by the step is also present in the same position in at least one of the scenarios extracted from the task models. The result of this parsing is then returned to the class "MySteps.java" (flow 7). At this point, based on the algorithm presented in the previous section, a list of all the matches found during the parsing for each step is presented as a result. Finally, the class "MySteps.java" returns the result to the class "MyTest.java" (flow 8) that made the original call.</p><p>Notice the independence of the components assigned at the core of the structure represented in Figure <ref type="figure" target="#fig_9">11</ref> (highlighted in yellow). Those components are related to the particularities of test implementation for HAMSTERS task models and scenarios. As mentioned before, "PrepareFiles.java" is in charge of preformatting the extracted scenario files and reading the reference source file of task models, while "MyXML.java" is in charge of parsing the scenario files, searching for the elements under testing. Therefore, we deliver a flexible architecture allowing, in the future, that task models and scenarios modeled by other modeling tools (or even by other versions of HAMSTERS) could also be tested by just implementing new interfaces for this core.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5">Setup and Running</head><p>Considering the presented architecture, to setup and run a battery of tests, we must: i place the set of task model scenario files (".scen") that will be assessed in the package "Task Model Scenarios", ii place the set of task model files (".hmst") that will support the assessment in the package "Task Models", iii place the set of BDD story files (".story") that will be assessed in the package "User Stories", iv indicate in the "MyTest" class which BDD story will be assessed, or which folder ("/stories") contains all the BDD stories that will be assessed, and finally v run the "MyTest" class as a JUnit Test. Thus, for running the assessment, the "MyTest" class is triggered. This JUnit class specifies exactly which BDD story (or which set of BDD stories) will be run. Results are shown in the console highlighting, for each step of the BDD scenario, whether and where some corresponding task has been found and which value was associated to it (if any).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">CASE STUDY</head><p>To evaluate our approach, we have conducted a case study with an existing web system for booking business trips in a French research institute. In a previous study <ref type="bibr" target="#b33">[33]</ref>, domain experts from the department of business trips were invited to produce User Stories (following the "BDD story" template) to describe a feature they considered important to that system. This exercise had as objective evaluating the usage of predefined interactive behaviors, by potential Product Owners (POs), for writing BDD stories. For the present study, the BDD stories produced by the participants have been used to identify examples of relevant scenarios to the domain. Based on that, we refined such stories to get a representative set of user requirements to be assessed on task models of the existing system. To obtain such task models, we have studied the current implementation of the existing system, and by applying a manual reverse engineering <ref type="bibr" target="#b5">[6]</ref>, we redesigned the targeted models in HAMSTERS. The aim of this software reengineering was to have such artifacts to run our tests and examine which types of inconsistencies our approach would be able to identify.</p><p>To perform the assessment, we firstly developed an initial version of BDD stories and their test scenarios to act as our user requirements and acceptance criteria. We then reengineered initial versions of the respective task models. After getting ready a first version of task models, we extracted a representative set of scenarios from them. By following our strategy for assessment, we run this initial version of BDD stories to the initial set of scenarios extracted from task models. Results were then evaluated, and we could observe the type of inconsistency we succeeded identifying. As the strategy we follow for assessing scenarios in both task models and BDD stories parses all the steps of each scenario at once, the first round of results is obtained with a single battery of tests.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Task Modeling</head><p>Task models have been developed for this study by using the HAMSTERS tool. As we have focused on the process of searching and demanding a booking of flights, the four models below have been divided to cover the processes of searching the flights, informing a flight leg (or a new flight leg in case of a multidestination trip), and choosing and confirming (or declining) the selected trip. They are presented as sub-models in the abstraction level required to perform the assessment (i.e. the interaction level), which allows a direct comparison with each one of the BDD stories considered.</p><p>Figure <ref type="figure" target="#fig_10">12</ref> presents the task model for searching flights using Travel Planet (the current booking system). All the tasks have been designed to be performed by end users of the system, i.e. researchers from the institute booking their own flights, or the travel department team booking flights on behalf of the researchers. The Search Flight feature encompasses accessing the search flight page (task "Go to Book Flights"), informing at least one flight leg (abstract task "Inform a Flight Leg"), providing flight data for searching (abstract task "Provide Data to Search"), submitting the search (task "Submit Search"), and verifying the resultant list of flights (abstract task "Verify List of Flights"). These four tasks are supposed to be performed exactly in this sequence, so the operator "Enable" has been used.</p><p>To inform a flight leg (Figure <ref type="figure" target="#fig_11">13</ref>), the user is supposed to inform departure and destination data. Such data include informing a departure and arrival cities and based on a list of available airports in those cities, selecting the ones he/she wants. Both tasks are mandatory and should be performed sequentially, so the operator "Enable" has been used. After selecting the airports of departure and arrival, the user must set in any order the departure date and the departure time frame, being this last one an optional task.  Going back to providing flight data to search, the user can perform in any order (operator "Order independent") the following tasks: "Choose Trip Type", "Adjust Timeframe", "Select Direct Flights Only", "Define Flight Class", and "Define Companies", being the last four tasks optional. For choosing trip types, the user has three options. If a round-trip is chosen, then a sequence of two order-independent tasks can be performed by the user: "Set Arrival Date" and "Set Arrival Time Frame", being this last one optional. If a multidestination trip is chosen, then the user must inform at least one more flight leg (abstract task "Inform a New Flight Leg"), performing the same interactive tasks from "Inform a Flight Leg". Finally, if a one-way trip is chosen, there is no additional tasks to perform for the abstract task of choosing a trip type. For all the input tasks, notice that the data handling is shown with information being provided as input for the task and objects being the output of these tasks.</p><p>After providing the data, the user can submit the search and get, as a result, a list of available flights matching his/her criteria. At this point, the system returns such a list and the user can then pick one of the available flights and confirm or decline his/her booking. For performing such tasks, the abstract task "Choose Flights" has been modeled (Figure <ref type="figure" target="#fig_12">14</ref>). To get it done, the user must first evaluate the availability of flights (which is a cognitive analysis task), choose the desired flight (which is a cognitive decision task), and then select the desired flight (which is indeed an interactive input task). Optionally the user can change the fare profile for the flight he/she has chosen, and then submit his/her choice. Lastly, the user checks the selected flights (a cognitive task) and verify the fare conditions (a perceptive task). He/she then finally chooses between decline the booking or conclude it.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Assessing Task Models</head><p>In total, we set up for assessment 3 BDD stories with 15 different scenarios and extracted 10 scenarios to be assessed from the task models presented above. The first TM scenario (illustrated in Figure <ref type="figure" target="#fig_14">16</ref>) is intended to book a regular roundtrip (return trip) without including any test data, whilst the second one is intended to the same purpose but providing test data for the objects values during the execution. The third scenario is intended to book a one-way trip, the fourth one to decline a one-way trip, and the fifth one to book a multidestination trip. Each one of these five scenarios is accompanied by similar ones that do not include the optional tasks, which totalizes the 10 scenarios to be assessed. Figure <ref type="figure" target="#fig_13">15</ref> brings an example of a sequence of BDD scenarios for successfully booking a return trip which is supposed to match the scenario "Successful Return Trip -Regular Case" extracted from the task models.</p><p>Testing results are shown in a log indicating, for each step of the BDD scenario, (i) if and where a given step has found an equivalent task in the XML file analyzed, and (ii) once it carries an object value associated, which value it is. Figure <ref type="figure" target="#fig_15">17</ref> (and its corresponding chart in Figure <ref type="figure" target="#fig_16">18</ref>) brings the results produced by our algorithm when searching for the position of each one of the tasks that composes the scenario. So, the lines of the table (and the legend of the chart) bring the steps in the BDD scenarios, and the columns (and the series of the chart) bring the XML files of the scenarios extracted from the task models. Zeros (0) in the table indicate that a corresponding task for a given step has not been found in the target file. Values different than zero indicate the position where a corresponding task has been found in the target file. We highlighted in gray at the  table which columns bring the most suitable target files where the correspondence with the BDD scenario was supposed to be found. For a fully consistent model, it would be necessary that each step in the BDD scenario has found its corresponding task in the same position in the target file. So, in this case, a straight vertical line of points would be seen in the chart below, indicating that a sequential correspondence for each step was found. In the first tested scenario presented above, such a correspondence was supposed to be found in the target file "No Optional Successful Return Trip -Regular Case" once, theoretically, it represents the same user activities in the task model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.1">First Scenario.</head><p>Analyzing the results of this first round of tests, we can notice that most of the steps have not found a corresponding task in the target files, i.e. steps in the BDD scenarios and tasks in the task models are not consistent somehow. The step at the position 1 ("Given I go to 'Flight Search'") has not found a corresponding task in any target file because, in the task model, the equivalent task has been modeled as "Go to Book Flights", so an inconsistency has been found in the name, despite the position is correct. The step at the position 2 ("When I select 'Round Trip'") has not found a corresponding task in any target file due to a different reason. As the interactive task "Select Round Trip" in the task model (see Figure <ref type="figure" target="#fig_10">12</ref>) has been modeled as a parent task of two leaf tasks ("Set Arrival Date" and "Set Arrival Time Frame"), when extracting scenarios from such a model, due to a limitation of the HAMSTERS tool, only the leaf tasks are kept, so the extracted scenario does never show the interactive task "Select Round Trip" which is a non-leaf task. Particularly in this case, even if the non-leaf tasks were extracted, another inconsistency would also have been found:  the position in which such a task would appear would not be the second one since it is not among the first user tasks according to the model.</p><p>Steps at the positions 3-4 and 5-6 concern respectively the set informing/choosing departure and informing/choosing destination. Such tasks have been modeled (and extracted to scenarios) as the triad "Inform Departure City / Provide List of Airports / Choose Departure Airport" and "Inform Arrival City / Provide List of Airports / Choose Arrival Airport". The intermediate task "Provide List of Airports" (that models the output of the system to the user) has not been modeled in the BDD stories, so the step is just composed by the informing and choosing activities. For this reason, such sequence would never find a correspondence in the model, which inevitably would break the forward sequence of tasks in the scenarios. Additionally, another inconsistency that would be identified is that the task model brings tasks named "Inform Departure (Arrival) City" and "Choose Departure (Arrival) Airport", while the algorithm would search for tasks named "Inform Departure (Destination)" and "Choose Departure (Destination)".</p><p>The step at the position 7 ("And I set 'Sam, Déc 1, 2018' in the field 'Departure Date'") has found a corresponding task in all the target files, almost always at the position 8. This one-position gap is due to the absence of the task "Choose Round Trip" that was not exported to the scenario as explained above. Besides that, such a step has found two (instead of one) corresponding tasks in the same file. This happened in the target files "Successful Multidestination Trip -Regular Case" and "No Optional Successful Multidestination Trip -Regular Case", exactly the two ones that describe scenarios for a multidestination trip. As in a multidestination trip, the user must inform at least two flight legs, he/she necessarily needs to inform a "Departure Date" two times, one for each flight leg. That is the reason the algorithm finds the corresponding task "Set Departure Date" two times in these two target files. In the first one, such a task has been found at the positions 8 and 16, and in the second one at the positions 8 and 15. The second occurrence of the task in these files has been marked as "(Copy)" in the table of results presented above. Notice that the associated value informed during the extraction of scenario can also be checked with the value specified in the step. The extracted scenario "Return Trip With Data" in both versions (with and without optional tasks) brings the associated value "Sam, Déc 1, 2018" in the results, that is exactly the same value informed for the corresponding step in the User Story.</p><p>The step at the position 8 ("When I set 'Lun, Déc 10, 2018' in the field 'Arrival Date'") has found a corresponding task at the position 9 in the target files "No Optional Return Trip With Data" and "No Optional Successful Return Trip -Regular Case", and at the position 10 in the target files "Successful Return Trip -Regular Case" and "Return Trip With Data". The task "Set Arrival Date" has been found only in those four files because it is only performed in scenarios involving roundtrips (return trips), where an arrival data should be informed. Concerning the position where this task has been found, in the "no-optional" files, it has been found at the position 9 because despite the absence of the task "Choose Round Trip" (which would bring the task "Set Arrival Date" to the position 7), the presence of the two tasks "Provide List of Airports" to inform both departure and destination brings the task "Set Arrival Date" two positions forward, putting it at the position 9. The position 10 in the target files with optional tasks is due to the presence of the optional task "Set Departure Time Frame" right before the task "Set Arrival Date".</p><p>The step at the position 9 ("And I submit 'Search'") has found a corresponding task at different positions in all the target files. The task "Submit Search" has been found at the position 11 in the "no-optional" files (except for the multidestination case that involves informing another flight leg). Looking at the roundtrip case, it highlights an important inconsistency between the scenario presented in the BDD story and those extracted from the task model. Apart from the aforementioned absence of the task "Choose Round Trip" and the presence of the two tasks "Provide List of Airports" (which would bring the task "Submit Search" to the position 10), the fact of being found at the position 11 is due to the presence of a previous task named "Choose Number of Passengers" intended to choose the number of passengers that will be included in the booking. This is a mandatory task in the task model but has not been specified as a step in the BDD scenario. It is up to requirements engineers and designers to analyze the models and identify if such a task has been correctly modeled as a mandatory task (so the task model would be correct, and the error would be in the BDD stories), or if it is not the case and such a task should be marked as optional in the task model (so the error would be in the task model and not in the BDD stories).</p><p>Steps from the position 10 until 19 have not found a corresponding task in any target file. At the position 10, it was expected the task "Display 2. Sélectionner un voyage" and the task model brings the task "Present List of Available Flights". Actually, the task model describes the system task intent which is to present the resulting list of available flights after the search. However, the step in the BDD scenario has specified a given message that would be seen after submitting the search. We can infer that the overall goal of both is the same, but they were specified differently, so there is an inconsistency anyway. At the position 11, it was expected the task "Display Availability Page" and the task model brings the task "Request for Choosing a Flight". The system action of requesting the user to choose a flight is performed in the availability page, so both tasks could eventually aim at the same purpose, but they are not equivalent once they use different specification strategies. The same occurs with the previous tasks discussed right before.</p><p>At the positions 12 and 13, the searched tasks "Click on No Bag" and "Click on No Bag" would find a correspondence with the task "Select the Desired Flight", but as they specify different behaviors, they cannot be recognized as equivalent. At the position 14, it was expected the task "Click on Book" and the task model brings the task "Submit the Choice". Due to the use of different semantic behaviors and the lack of context when analyzing only the tasks individually, it is hard to conclude if both tasks intend actually to model the same behavior.</p><p>Steps at the positions 15, 16, 17 and 19 do not have tasks modeling the same behaviors in the task model. The searched task "Click on Finalize the trip" at the position 18, just like the ones at the positions from 12 until 14, would find a correspondence with the task "Conclude the Booking" extracted from the task model, however they actually specify different behaviors, so they cannot be recognized as equivalent. Notice finally that the tasks "Evaluate the Availability of Flights", "Choose the Desired Flight" and "Check the Selected Flights", both of them included in the scenarios extracted from the task models, are cognitive tasks, so they would not be identifiable by the steps anyway. Table <ref type="table" target="#tab_2">3</ref> summarizes the main reasons of failure discussed above for each step of the BDD scenarios.</p><p>6.2.2 Further Scenarios. The sequence of figures <ref type="bibr">19, 20, 21, and 22</ref> shows the testing results for the remaining scenarios. The second scenario "Confirm a Flight Selection (Full Version)" (Figure <ref type="figure" target="#fig_17">19</ref>) describes the same roundtrip booking but using all the optional fields. Notice that this scenario brings some fixtures for the inconsistency problems identified with the testing of the previous scenario. For example, the first step has been modified to "Given I go to 'Book Flights'" instead of "Given I go to 'Flight Search'", and the step describing the roundtrip selection has been moved forward. Other remarks can be made, notice that as this scenario describes a roundtrip by using the full range of search options, optional steps are never found in the "no optional" target files.</p><p>Also notice that despite finding a corresponding task in all the target files, we can see that the step "And I choose the option of value '2' in the field 'Number of Passengers'" sets the value "2" for the field "Number of Passengers" while in the target file "Return Trip With Data" in its both versions (with and without optional tasks), it has been informed the value "1" during the execution. Considering that values specified for test cases are generally representative of a data domain that may point out some failure in the system, it is important to look carefully at such kind of inconsistency in the assessed artifacts. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Step</head><p>Main reason of failure As task models are not designed to model user's errors, scenarios from the BDD stories that test error situations were not assessed with the extracted task model scenarios. As user errors are not part of a user goal, they are usually omitted from tasks descriptions, making this kind of test fail. Means of representing these potential errors on task models is being recently studied <ref type="bibr" target="#b14">[14]</ref>. Once it is implemented in the model, tests could run using the same approach to identify this kind of error.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">DISCUSSION</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1">Types of Inconsistencies Identified</head><p>By summarizing the results presented above, we can categorize the types of inconsistencies found by our approach when assessing the task models. These types were additionally classified by their level of criticality, i.e. the impact of the inconsistency in the system design and the effort that would  be required to fix the problem. These aspects are exemplified and discussed in detail below. We use the symbol (+) to signalize a low-level of criticality, (++) to signalize a medium-level of criticality, and (+++) to signalize a high-level of criticality. We succeeded identifying 8 different types of inconsistencies in the assessed scenarios. The most common ones were the "different number of tasks sequences in the task model", "unpaired behaviors", and "equivalent behaviors missing". The first type occurs when there are more tasks in the task model scenario than steps in the BDD scenario to accomplish the same behavior. In the example presented in section 6.2.1, to inform a departure (or a destination) there was a sequence of 3 tasks in the scenario extracted from the task model, while in the step of the BDD scenario, a double action of informing and choosing was enough. For the second type, "unpaired behaviors" refers to tasks that would find a correspondence with the steps in the BDD scenarios, but as they actually specify different behaviors (e.g. "Define &lt;something&gt;" instead of "Select &lt;something&gt;"), they cannot be recognized as such. "Equivalent behaviors missing" refers to behaviors that are actually missing in the extracted task model scenario, like steps that are present in the BDD scenario but cannot find corresponding tasks in the task model.</p><p>"Different specification strategies" comes next as the type of inconsistency incurred from specification of behaviors that could eventually aim at the same purpose, but were specified using different strategies, i.e. requiring to perform (or verify) different actions. An example from this case study is the situation in which a step of a BDD scenario had described a behavior in which the system showed a message introducing a list of available flights, and the task model, a behavior in which the system provided the aforementioned list. Even with the resultant state of the system being the same in this case, the specified behaviors could not be considered equivalents once they use different specification strategies.</p><p>Tasks in "wrong positions" comes next being the type of error related to tasks that are found in different positions than their equivalent steps in BDD scenarios. As scenarios in different conceptions are being compared when assessing BDD stories and task models, we consider that errors found in the sequence of tasks in the task models (compared with BDD stories) are generally the most sensitive type of error, once it impacts in all other tasks in the sequence. A simple change of task positions at the beginning of a scenario invalidates the whole scenario because all the tasks in the sequence would be in wrong positions. A correction to a simple error like this would include finding the root of the problem, redesign either the step (that would impact the consistency in other artifacts) or the task model (that would imply in extracting new scenarios for testing) and run a complete battery of regression tests again. Considering that there are no other types of inconsistencies in the model, by fixing this issue (either by updating the BDD scenarios to comply with the scenario extracted from the task model or updating the task model to comply with the sequence of steps from the BDD scenarios), both scenarios would become fully consistent.</p><p>"Conflicts between specification and modeling" refers to tasks modeled in the task model (and consequently exported to its scenarios) that are not present in the requirements specification in the BDD stories. The contrary can occur as well. This kind of inconsistency generally puts in evidence important conflicts between what is specified in the user requirements and what is effectively modeled in the artifacts. "Tasks with different names" and "Tasks not extracted to the scenario" complete the list of type of errors encountered during the tests. The first one refers to tasks that are present both in the task model and in the BDD scenario but written with a different name. The second one refers to tasks that are effectively modeled in the task model but, due to the type of operators used or the presence (or not) of other refined tasks after them in the model, causes that, during the extraction process, such tasks are not taken to the extracted scenarios.</p><p>By analyzing the variety of inconsistency problems that have been identified in this case study, we can remark that some types of inconsistencies have shown to be more critical than others. While simple inconsistencies like differences in names of tasks and fields are easy to be solved, some other inconsistencies can reveal crucial problems of modeling or important incompatibilities between the requirements specification and its modeling in the artifacts. For example, "tasks with different names" would be an easy-to-solve problem, i.e. either the task or the BDD step could be easily renamed to get it sorted out, and this does not heavily affect the design quality and consistency as a whole. This kind of problem could be also easily avoided with, for example, the use of a dictionary. "Conflicts between specification and modeling" along with "different specification strategies" for task models, on the other hand, compose a more critical group of problems and must be prioritized.</p><p>"Unpaired behaviors" and "equivalent behaviors missing" on task models are inconsistencies directly related to the variety of interactive behaviors modeled in the ontology since the assessment is limited by the set of currently supported behaviors. By supporting new interactive behaviors in the future, the ontology would increase its capacity of recognizing other task descriptions. "Tasks not extracted to the scenario", "different number of task sequences in the task model", and the presence of tasks in wrong positions are problems that can have the same origin in scenarios extracted from task models, i.e. due to tasks not extracted to scenarios, those ones that have been extracted may be placed in wrong positions which will affect how many sequences of tasks the scenario lists. So, by fixing the root cause, the designer can avoid three kinds of different problems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2">Limitations</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2.1">Limitations of the Case Study.</head><p>As limitations of this study, we point out that it has been conducted performing a manual reverse engineering of the existing system currently in production to obtain the respective task models for testing. Therefore, as a manual process, it was expected that inconsistencies would be naturally introduced during the modeling. Indeed, these inconsistencies were identified and that allowed us to evaluate our approach. Nonetheless, if an automated approach of reverse engineering had been used instead, such inconsistencies would probably not have taken place since the task model would be generated already fully consistent with the current system and, by consequence, with the set of BDD stories used to implement it. Future studies should confirm this hypothesis. We also acknowledge a possible modeling bias in the study once both the conduction of the study and the interpretation and analysis of the results have been made by one of the authors. To mitigate that, the results were cross-checked by independent reviewers, experts in interactive systems modeling. They examined both the reengineered task models and the testing results, then they performed a qualitative analysis of the types of inconsistencies identified. The results presented in this article are thus a consolidated and revised version of the testing outcomes. 7.2.2 Limitations of the Approach. As an automated approach, in principle, there is no limitation regarding the size of the model and/or the operators included, nor regarding the complexity of the possible scenarios to be generated. However, the need for extracting scenarios for assessing the task models imposes some limitations. Figure <ref type="figure" target="#fig_22">23</ref> illustrates the flow of activities we have performed so far to obtain scenarios for testing based on the current approaches in the literature. Notice that the source file of a task model is manipulated only for extracting scenarios (continuous black line at the top). Such a feature is usually included in tool-supported notations for designing task models.</p><p>After such an extraction, the resultant source files of scenarios are manipulated and formatted to obtain a given scenario for testing (continuous black line at the right). This approach, regardless of keeping important aspects of the interaction during the extraction process, has limitations once it is still fully dependent on the extraction of scenarios, i.e. it does not allow us to manipulate the source file of task models directly. An approach that does not necessarily pass through extracted scenarios (dotted red line at the left) would allow us to manipulate the model with its full capabilities, opening a wide range of opportunities to assess the quality of such models and obtain no-simplified scenarios for testing. This could also solve the problem of not being able to assess non-leaf tasks in the task model. In short, being able to manipulate and check the consistency of task models directly in their source files (instead of passing by the process of extracting scenarios) could represent a crucial step towards a solution that includes a complete and no-simplified assessment strategy. This should be addressed in future works.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">CONCLUSION</head><p>Our approach for assessing task models has the main advantage of signalizing a wide range of inconsistencies that should be fixed to ensure a reliable correspondence between such models and the user requirements specified by stakeholders through BDD stories. Despite the limitations related to the process of extracting scenarios from task models, the strategy we have chosen has many advantages. Especially in environments requiring high availability of tests to be executed continuously throughout multiple iterations, our approach benefits from an instantaneous consistency checking, allowing the analysis of several hundreds of scenario files at the same time.</p><p>Unlike our approach (which is based on a static analysis), co-execution approaches have the benefit of allowing simulating the execution of models simultaneously with visual feedback in real-time about the correspondence of entities that are being assessed in each model. However, such approaches demand a high investment to prepare the models before, annotating the source code/files or even modifying its structure to support the co-execution. Besides that, as the great benefit of co-execution is providing visual feedback during the execution signalizing which entity is being assessed in each model at a given time, this process is usually slow and requires an evaluation being conducted manually to reveal its benefits. Another benefit of our approach, when compared with others, is that we defined an open and flexible architecture where different notations and tools for designing task models could fit in the future. For that, it is enough to implement a new core interface for describing the way such notations and tools deal with tasks and scenarios, and how they can be identified in their source files.</p><p>The approach has also been extended and adapted to assess other early artifacts such as GUI prototypes and late artifacts such as final GUIs <ref type="bibr" target="#b39">[39]</ref>, <ref type="bibr" target="#b34">[34]</ref>, <ref type="bibr" target="#b37">[37]</ref>, <ref type="bibr" target="#b36">[36]</ref>, <ref type="bibr" target="#b40">[40]</ref>. As an integrated approach, the same set of BDD stories is assigned to automatically assess task models, GUI prototypes in different levels of abstraction, and final GUIs, ensuring a consistent verification, validation and testing (VV&amp;T) approach for interactive systems with high availability of tests and instantaneous feedback about the consistency of artifacts regarding the user requirements. Strategies for running automated tests over software artifacts indeed define a step forward within the process of software verification. Such a process, that is usually conducted manually by just inspecting or reviewing the artifacts in an attempt to identify inconsistencies and modeling errors, can benefit from an automated approach giving high available instantaneous feedback about the consistency of artifacts with the user requirements all along the iterations.</p><p>Our future works include evolving this approach to manipulate and check the consistency of task models directly in their source files, besides evaluating the impact of maintaining and successively evolving the task models throughout a real software development process. Another improvement in the task model assessment that is in the pipeline consists of implementing a better technique to assess "displaying" tasks, i.e. tasks that involve the system displaying a message to the user, or the user checking that such a message has been displayed. In the current implementation, we search for a task named "Display &lt;message&gt;", but indeed it is not a common practice to describe system messages literally in a task name, so this kind of tasks are never matched with the equivalent steps in the BDD stories. Our first strategy in mind is to look for a generic task named "Display message", for example, and then check the actual message in the object value associated to this task. While this strategy solves the matching of equivalent tasks, if the designer skips informing the actual message when extracting a scenario from the task model, such a task would still be unidentifiable. Anyway, so far it seems to be the best strategy to address such a problem.</p><p>We are also refining our set of tools to better support the creation, visualization and execution of the tests. An important improvement as future works concerns the presentation of the task model assessment results. Despite being useful to locate exactly where the corresponding tasks have been found, a presentation based on a detailed list of matching tasks, positions and values tends to be hard to read with the growing number of scenarios. An interactive interface allowing, for example, to select and visualize only the points of inconsistencies in the models might probably help designers to evaluate and better analyzing the results.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Task types in HAMSTERS.</figDesc><graphic coords="6,104.98,195.84,276.06,112.53" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Structure of an interactive behavior as specified in the ontology.</figDesc><graphic coords="7,85.26,336.49,315.48,59.80" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Task Models Assessment from BDD Stories and Scenarios.</figDesc><graphic coords="10,144.41,84.68,197.17,236.68" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. Relationship between the HAMSTERS meta-model and the BDD story meta-model.</figDesc><graphic coords="11,45.83,325.98,394.34,163.79" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 6 .</head><label>6</label><figDesc>Fig.6. The graph of options for performing our approach (colors are used to visually identify the different paths).</figDesc><graphic coords="12,124.70,149.18,236.61,170.42" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 6</head><label>6</label><figDesc>Figure6illustrates the resultant graph of options considered. The colored lines indicate the possible paths to be taken in the workflow. The yellow path indicates the design of task models before writing formatted BDD stories. The green path indicates the opposite, while the blue path indicates both activities in parallel. Notice that regardless the path chosen, the extraction of scenarios from task models (which may be a manual or an automated process depending on the tool used) is only possible after having designed the task models (a manual process), and the identification of requirements (a manual process as well) is a precondition for all the other activities. Finally, to run the assessment on the task models (a fully automated process), it is required to have extracted scenarios from them and written the formatted BDD stories. After running the assessment, the inconsistencies identified can be fixed by redesigning either the task models or the BDD stories (black dotted lines). The approach is intended to benefit requirements engineers and interaction designers in the first place; thus, they are the main stakeholders involved who are responsible to gather and writing the BDD stories besides modeling the task models.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 7 .</head><label>7</label><figDesc>Fig. 7. Task model (1), extracted scenario (3), and their respective source files (2 and 4).</figDesc><graphic coords="13,45.83,84.68,394.35,199.52" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 8 .</head><label>8</label><figDesc>Fig. 8. Formatting rule for assessing steps and tasks.</figDesc><graphic coords="14,104.98,337.55,276.03,204.24" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 9 .Fig. 10 .</head><label>910</label><figDesc>Fig. 9. Extract of an original (left side) and a resultant (right side) scenario XML files after the process of preformatting.</figDesc><graphic coords="17,45.83,84.68,394.34,119.12" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 11 .</head><label>11</label><figDesc>Fig. 11. Flow of calls for running tests on task model scenarios.</figDesc><graphic coords="19,124.70,84.68,236.61,204.87" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Fig. 12 .</head><label>12</label><figDesc>Fig. 12. Task Model for Searching Flights using Travel Planet.</figDesc><graphic coords="21,45.83,84.68,394.34,258.35" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Fig. 13 .</head><label>13</label><figDesc>Fig. 13. Task Model for Informing a Flight Leg in Travel Planet.</figDesc><graphic coords="21,45.83,378.96,394.34,156.44" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Fig. 14 .</head><label>14</label><figDesc>Fig. 14. Task Model for Choosing a Flight in Travel Planet.</figDesc><graphic coords="22,45.83,84.68,394.35,107.47" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Fig. 15 .</head><label>15</label><figDesc>Fig. 15. Sequence of BDD scenarios for successfully booking a return trip.</figDesc><graphic coords="23,45.83,84.68,256.31,272.29" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>Fig. 16 .</head><label>16</label><figDesc>Fig. 16. The scenario "Successful Return Trip -Regular Case" extracted from the task models.</figDesc><graphic coords="23,305.60,144.71,131.12,141.28" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head>Fig. 17 .</head><label>17</label><figDesc>Fig. 17. Test results of the scenario "Confirm a Flight Selection" on the task models.</figDesc><graphic coords="24,45.83,84.68,394.35,147.03" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_16"><head>Fig. 18 .</head><label>18</label><figDesc>Fig. 18. Results of matching: scenario "Confirm a Flight Selection".</figDesc><graphic coords="24,45.83,267.88,394.35,159.55" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_17"><head>Fig. 19 .</head><label>19</label><figDesc>Fig. 19. Results of matching: scenario "Confirm a Flight Selection (Full Version)".</figDesc><graphic coords="26,45.83,84.68,394.35,159.24" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_18"><head>1 -</head><label>1</label><figDesc>Given I go to 'Flight Search' Task with different name 2 -When I select 'Round Trip' Task not extracted to the scenario 3 -And I inform 'Toulouse'... Triple and not double sequence of tasks in the task model 4 -...and choose 'Toulouse, Blagnac (TLS)' in the field 'Departure' Triple and not double sequence of tasks in the task model 5 -When I inform 'Paris'... Triple and not double sequence of tasks in the task model 6 -...and choose 'Paris, Charles-de-Gaulle (CDG)' in the field 'Destination' Triple and not double sequence of tasks in the task model 7 -And I set 'Sam, Déc 1, 2018' in the field 'Departure Date' Wrong position 8 -When I set 'Lun, Déc 10, 2018' in the field 'Arrival Date' Wrong position 9 -And I submit 'Search' Inconsistency between modeling and specification 10 -Then will be displayed '2. Sélectionner un voyage' Different specification strategy 11 -Given 'Availability Page' is displayed Different specification strategy 12 -When I click on 'No Bag' referring to 'Air France 7519' Unpaired behaviors 13 -And I click on 'No Bag' referring to 'Air France 7522' Unpaired behaviors 14 -When I click on 'Book' Unpaired behaviors 15 -Then will be displayed 'J'accepte les Conditions d'achat concernant le(s) tarif(s) aérien(s). ' Equivalent behavior missing 16 -Given 'Confirmation Page' is displayed Equivalent behavior missing 17 -When I choose 'J'accepte les Conditions d'achat concernant le(s) tarif(s) aérien(s). ' Equivalent behavior missing 18 -And I click on 'Finalize the trip' Unpaired behaviors 19 -Then will be displayed 'Votre voyage a été confirmé!' Equivalent behavior missing Results of the remaining scenarios, including scenarios to confirm and decline a one-way trip, and confirm a multidestination trip, are shown below in figures 20, 21 and 22.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_19"><head>Fig. 20 .</head><label>20</label><figDesc>Fig. 20. Results of matching: scenario "Confirm a Flight Selection for a One-Way Trip".</figDesc><graphic coords="28,45.83,274.81,394.35,159.24" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_20"><head>Fig. 21 .</head><label>21</label><figDesc>Fig. 21. Results of matching: scenario "Confirm a Flight Selection for a Multidestination Trip".</figDesc><graphic coords="28,45.83,464.93,394.35,159.24" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_21"><head>•</head><label></label><figDesc>Task with different names (+) • Task not extracted to the scenario (++) • Different number of tasks sequences in the task model (++) • Wrong position (++) • Conflict between specification and modeling (+++) • Different specification strategies (+++) • Unpaired behaviors (++) • Equivalent behaviors missing (++)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_22"><head>Fig. 23 .</head><label>23</label><figDesc>Fig. 23. Flow of activities to get scenarios for testing.</figDesc><graphic coords="31,164.13,149.99,157.74,95.66" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>Task name components construction.</figDesc><table><row><cell cols="2">Component</cell><cell>Description</cell><cell>Usage for naming tasks</cell></row><row><cell cols="2">When (Transition Ele-</cell><cell>Refers to a transition element of</cell><cell>Not used because these elements</cell></row><row><cell>ment)</cell><cell></cell><cell>the state machine.</cell><cell>are not addressed in task names.</cell></row><row><cell>I (Subject)</cell><cell></cell><cell>Signalizes it is the user who per-</cell><cell>Not used because other task</cell></row><row><cell></cell><cell></cell><cell>forms the task.</cell><cell>model elements already encom-</cell></row><row><cell></cell><cell></cell><cell></cell><cell>pass the definition of user role.</cell></row><row><cell cols="2">set (Interactive Behav-</cell><cell>Indicates the action (interactive be-</cell><cell>Used for beginning to name the</cell></row><row><cell>ior)</cell><cell></cell><cell>havior) that will be performed by</cell><cell>task in the task model.</cell></row><row><cell></cell><cell></cell><cell>the user.</cell><cell></cell></row><row><cell>"Valid</cell><cell>Departure</cell><cell>Indicates a data domain (or the ac-</cell><cell>Not used because test data are</cell></row><row><cell cols="2">Date" (Test Data)</cell><cell>tual test data) that will be used to</cell><cell>provided only at runtime when</cell></row><row><cell></cell><cell></cell><cell>perform and simulate the task ex-</cell><cell>simulating the task model and are</cell></row><row><cell></cell><cell></cell><cell>ecution.</cell><cell>not part of the task name.</cell></row><row><cell cols="2">in the field (Interac-</cell><cell></cell><cell></cell></row><row><cell cols="2">tive Behavior Comple-</cell><cell></cell><cell></cell></row><row><cell>ment)</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 .</head><label>2</label><figDesc>Examples of task names to be assessed after applying the formatting rule</figDesc><table><row><cell>Interactive behavior from the</cell><cell>Step in the BDD scenario</cell><cell>Task name to be as-</cell></row><row><cell>ontology</cell><cell></cell><cell>sessed</cell></row><row><cell>goTo</cell><cell>Given I go to "Find Flights"</cell><cell>Go to Find Flights</cell></row><row><cell>chooseReferringTo</cell><cell>When I choose "One way" refer-</cell><cell>Choose Trip Type</cell></row><row><cell></cell><cell>ring to "Trip Type"</cell><cell></cell></row><row><cell>informAndChooseInTheField</cell><cell>And I inform "Departure City"</cell><cell>Inform Departure /</cell></row><row><cell></cell><cell>and choose "Departure Airport"</cell><cell>Choose Departure</cell></row><row><cell></cell><cell>in the field "Departure"</cell><cell></cell></row><row><cell>chooseTheOptionOfValueInTheField</cell><cell>And I choose the option of value</cell><cell>Choose Number of Pas-</cell></row><row><cell></cell><cell>"2" in the field "Number of Pas-</cell><cell>sengers</cell></row><row><cell></cell><cell>sengers"</cell><cell></cell></row><row><cell>setInTheField</cell><cell>And I set "Valid Departure Date"</cell><cell>Set Departure Date</cell></row><row><cell></cell><cell>in the field "Departure Date"</cell><cell></cell></row><row><cell>submit</cell><cell>And I submit "Search"</cell><cell>Submit Search</cell></row><row><cell>willBeDisplayed</cell><cell>Then will be displayed "List of</cell><cell>Display List of Avail-</cell></row><row><cell></cell><cell>Available Flights"</cell><cell>able Flights</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 .</head><label>3</label><figDesc>Type of inconsistencies identified in scenarios extracted from task models.</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>Proc. ACM Hum.-Comput. Interact., Vol. 4, No. EICS, Article 77. Publication date: June 2020.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_1"><p>Proc. ACM Hum.-Comput. Interact., Vol. 4, No. EICS, Article 77. Publication date: June 2020.Ensuring the Consistency between User Requirements and Task Models: A Behavior-Based Automated Approach 77:7</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_2"><p>Proc. ACM Hum.-Comput. Interact., Vol. 4, No. EICS, Article 77. Publication date: June 2020.Ensuring the Consistency between User Requirements and Task Models: A Behavior-Based Automated Approach 77:13</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_3"><p>Proc. ACM Hum.-Comput. Interact., Vol. 4, No. EICS, Article 77. Publication date: June 2020. Ensuring the Consistency between User Requirements and Task Models: A Behavior-Based Automated Approach 77:21</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">State Chart XML (SCXML): State Machine Notation for Control Abstraction</title>
		<author>
			<persName><forename type="first">Jim</forename><surname>Barnett</surname></persName>
		</author>
		<ptr target="http://www.w3.org/TR/scxml/" />
	</analytic>
	<monogr>
		<title level="m">W3C</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">UI-driven test-first development of interactive systems</title>
		<author>
			<persName><forename type="first">Judy</forename><surname>Bowen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Steve</forename><surname>Reeves</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 3rd ACM SIGCHI symposium on Engineering interactive computing systems</title>
		<meeting>the 3rd ACM SIGCHI symposium on Engineering interactive computing systems</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="165" to="174" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A more intelligent test case generation approach through task models manipulation</title>
		<author>
			<persName><forename type="first">José</forename><surname>Creissac Campos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Camille</forename><surname>Fayollas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marcelo</forename><surname>Gonçalves</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Célia</forename><surname>Martinie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Navarre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Philippe</forename><surname>Palanque</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Miguel</forename><surname>Pinto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM on Human-Computer Interaction</title>
		<meeting>the ACM on Human-Computer Interaction</meeting>
		<imprint>
			<publisher>EICS</publisher>
			<date type="published" when="2017">2017. 2017</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">9</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Systematic automation of scenario-based testing of user interfaces</title>
		<author>
			<persName><forename type="first">Camille</forename><surname>José C Campos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Célia</forename><surname>Fayollas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Martinie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Philippe</forename><surname>Navarre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Miguel</forename><surname>Palanque</surname></persName>
		</author>
		<author>
			<persName><surname>Pinto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 8th ACM SIGCHI Symposium on Engineering Interactive Computing Systems</title>
		<meeting>the 8th ACM SIGCHI Symposium on Engineering Interactive Computing Systems</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="138" to="148" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">The RSpec Book: Behaviour-driven Development with RSpec, Cucumber, and Friends</title>
		<author>
			<persName><forename type="first">D</forename><surname>Chelimsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Astels</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010">2010</date>
			<publisher>Pragmatic Bookshelf</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Reverse engineering and design recovery: A taxonomy</title>
		<author>
			<persName><forename type="first">Elliot</forename><forename type="middle">J</forename><surname>Chikofsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><forename type="middle">H</forename><surname>Cross</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE software</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="13" to="17" />
			<date type="published" when="1990">1990. 1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">User Stories Applied: For Agile Software Development</title>
		<author>
			<persName><forename type="first">Mike</forename><surname>Cohn</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004">2004</date>
			<publisher>Addison-Wesley Professional</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Mapping Business Process Modeling constructs to Behavior Driven Development Ubiquitous Language</title>
		<author>
			<persName><forename type="first">Rogerio</forename><surname>Atem De Carvalho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fernando</forename><surname>Luiz De Carvalho E Silva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rodrigo</forename><surname>Soares</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Manhaes</forename></persName>
		</author>
		<idno type="arXiv">arXiv:1006.4892</idno>
	</analytic>
	<monogr>
		<title level="j">Proc. ACM Hum.-Comput. Interact</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<date type="published" when="2010-06">2010. June 2020</date>
			<publisher>EICS</publisher>
		</imprint>
	</monogr>
	<note>cs.SE. Publication date</note>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Ensuring the Consistency between User Requirements and Task Models: A Behavior-Based Automated Approach</title>
		<imprint>
			<biblScope unit="volume">77</biblScope>
			<biblScope unit="page">31</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Filling the Gap between Business Process Modeling and Behavior Driven Development</title>
		<author>
			<persName><forename type="first">Rogerio</forename><surname>Atem De Carvalho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rodrigo</forename><surname>Soares Manhães</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fernando</forename><surname>Luis De Carvalho E Silva</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1005.4975</idno>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
	<note>cs.SE</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Semiotic engineering: bringing designers and users together at interaction time</title>
		<author>
			<persName><forename type="first">Clarisse</forename><surname>Sieckenius</surname></persName>
		</author>
		<author>
			<persName><forename type="first">De</forename><surname>Souza</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Interacting with Computers</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="317" to="341" />
			<date type="published" when="2005">2005. 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Litmus: Generation of Test Cases from Functional Requirements in Natural Language</title>
		<author>
			<persName><forename type="first">Anurag</forename><surname>Dwarakanath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shubhashis</forename><surname>Sengupta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 17th International Conference on Applications of Natural Language Processing and Information Systems</title>
		<meeting>the 17th International Conference on Applications of Natural Language Processing and Information Systems<address><addrLine>Groningen, The Netherlands; Berlin, Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="58" to="69" />
		</imprint>
	</monogr>
	<note>NLDB&apos;12)</note>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Global software and IT: a guide to distributed development, projects, and outsourcing</title>
		<author>
			<persName><forename type="first">Christof</forename><surname>Ebert</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011">2011</date>
			<publisher>John Wiley &amp; Sons</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A Literature Review of Behavior Driven Development using Grounded Theory</title>
		<author>
			<persName><forename type="first">Abigail</forename><surname>Egbreghts</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">27th Twente Student Conference on IT</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Enhanced task modelling for systematic identification and explicit representation of human errors</title>
		<author>
			<persName><forename type="first">Racim</forename><surname>Fahssi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Célia</forename><surname>Martinie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Philippe</forename><surname>Palanque</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Human-Computer Interaction</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="192" to="212" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<author>
			<persName><surname>Gherkin</surname></persName>
		</author>
		<ptr target="https://cucumber.io/docs/gherkin/reference/" />
		<title level="m">Gherkin Reference</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Towards task-based linguistic modeling for designing GUIs. In 27ème conférence francophone sur l&apos;Interaction Homme-Machine</title>
		<author>
			<persName><forename type="first">Iyad</forename><surname>Khaddam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nesrine</forename><surname>Mezhoudi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jean</forename><surname>Vanderdonckt</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015">2015</date>
			<publisher>ACM</publisher>
			<biblScope unit="volume">17</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Requirements engineering with viewpoints</title>
		<author>
			<persName><forename type="first">G</forename><surname>Kotonya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Sommerville</surname></persName>
		</author>
		<idno type="DOI">10.1049/sej.1996.0002</idno>
		<ptr target="https://doi.org/10.1049/sej.1996.0002" />
	</analytic>
	<monogr>
		<title level="j">Software Engineering Journal</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="5" to="18" />
			<date type="published" when="1996-01">1996. Jan 1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Requirements Validation Through Viewpoint Resolution</title>
		<author>
			<persName><forename type="first">Julio</forename><surname>Cesar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sampaio</forename><surname>Do</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Prado</forename><surname>Leite</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><forename type="middle">A</forename><surname>Freeman</surname></persName>
		</author>
		<idno type="DOI">10.1109/32.106986</idno>
		<ptr target="https://doi.org/10.1109/32.106986" />
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Softw. Eng</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="1253" to="1269" />
			<date type="published" when="1991-12">1991. Dec. 1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">A client oriented requirements baseline</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C S P</forename><surname>Leite</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">P</forename><surname>Oliveira</surname></persName>
		</author>
		<idno type="DOI">10.1109/ISRE.1995.512551</idno>
		<ptr target="https://doi.org/10.1109/ISRE.1995.512551" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of 1995 IEEE International Symposium on Requirements Engineering (RE&apos;95)</title>
		<meeting>1995 IEEE International Symposium on Requirements Engineering (RE&apos;95)</meeting>
		<imprint>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page" from="108" to="115" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Evaluation of Behavior-Driven Development</title>
		<author>
			<persName><forename type="first">John</forename><surname>Horn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lopes</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
		<respStmt>
			<orgName>Delft University of Technology</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Master&apos;s thesis</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Behavior-Driven Requirements Traceability via Automated Acceptance Tests</title>
		<author>
			<persName><forename type="first">G</forename><surname>Lucassen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Dalpiaz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M E M V D</forename><surname>Werf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Brinkkemper</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zowghi</surname></persName>
		</author>
		<idno type="DOI">10.1109/REW.2017.84</idno>
		<ptr target="https://doi.org/10.1109/REW.2017.84" />
	</analytic>
	<monogr>
		<title level="m">IEEE 25th International Requirements Engineering Conference Workshops (REW)</title>
		<imprint>
			<date type="published" when="2017">2017. 2017</date>
			<biblScope unit="page" from="431" to="434" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Derivation of a Dialog Model from a Task Model by Activity Chain Extraction</title>
		<author>
			<persName><forename type="first">Kris</forename><surname>Luyten</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tim</forename><surname>Clerckx</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Karin</forename><surname>Coninx</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jean</forename><surname>Vanderdonckt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Interactive Systems. Design, Specification, and Verification</title>
		<editor>
			<persName><forename type="first">Joaquim</forename><forename type="middle">A</forename><surname>Jorge</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Nuno Jardim</forename><surname>Nunes</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">João</forename><surname>Falcão E Cunha</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin Heidelberg, Berlin, Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="203" to="217" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Modeling Test Cases in BPMN for Behavior-Driven Development</title>
		<author>
			<persName><forename type="first">D</forename><surname>Lübke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Van Lessen</surname></persName>
		</author>
		<idno type="DOI">10.1109/MS.2016.117</idno>
		<ptr target="https://doi.org/10.1109/MS.2016.117" />
	</analytic>
	<monogr>
		<title level="j">IEEE Software</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="15" to="21" />
			<date type="published" when="2016-09">2016. Sep. 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">A generic tool-supported framework for coupling task models and interactive applications</title>
		<author>
			<persName><forename type="first">Célia</forename><surname>Martinie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Navarre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Philippe</forename><surname>Palanque</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Camille</forename><surname>Fayollas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 7th ACM SIGCHI Symposium on Engineering Interactive Computing Systems</title>
		<meeting>the 7th ACM SIGCHI Symposium on Engineering Interactive Computing Systems</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="244" to="253" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Structuring and Composition Mechanisms to Address Scalability Issues in Task Models</title>
		<author>
			<persName><forename type="first">Célia</forename><surname>Martinie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Philippe</forename><surname>Palanque</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marco</forename><surname>Winckler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IFIP Conference on Human-Computer Interaction</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="589" to="609" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Empirical Analyses of Executable Acceptance Test Driven Development</title>
		<author>
			<persName><forename type="first">Grigori</forename><surname>Igorovych</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Melnik</forename></persName>
		</author>
		<idno>AAINR33806</idno>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
		<respStmt>
			<orgName>University of Calgary</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D. Dissertation</note>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<author>
			<persName><forename type="first">Dan</forename><surname>North</surname></persName>
		</author>
		<ptr target="http://dannorth.net/whats-in-a-story/" />
		<title level="m">What&apos;s in a Story?</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">A framework for expressing the relationships between multiple views in requirements specification</title>
		<author>
			<persName><forename type="first">B</forename><surname>Nuseibeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kramer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Finkelstein</surname></persName>
		</author>
		<idno type="DOI">10.1109/32.328995</idno>
		<ptr target="https://doi.org/10.1109/32.328995" />
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Software Engineering</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="760" to="773" />
			<date type="published" when="1994-10">1994. Oct 1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">ConcurTaskTrees: An Engineered Notation for Task Models</title>
		<author>
			<persName><forename type="first">Fabio</forename><surname>Paternò</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The handbook of task analysis for human-computer interaction</title>
		<imprint>
			<date type="published" when="2004">2004. 2004</date>
			<biblScope unit="page" from="483" to="503" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<author>
			<persName><forename type="first">Fabio</forename><surname>Paternò</surname></persName>
		</author>
		<ptr target="http://www.w3.org/TR/task-models/" />
		<title level="m">W3C, MBUI -Task Models</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Requirement analysis using VORD</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Pozgaj</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ITI 2000. Proceedings of the 22nd International Conference on Information Technology Interfaces (Cat</title>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="volume">00</biblScope>
			<biblScope unit="page" from="105" to="110" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<author>
			<persName><forename type="first">Jaroslav</forename><surname>Pullmann</surname></persName>
		</author>
		<ptr target="https://www.w3.org/TR/mbui-glossary/" />
		<title level="m">MBUI -Glossary -W3C</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Evaluating the usage of predefined interactive behaviors for writing user stories: an empirical study with potential product owners</title>
		<author>
			<persName><forename type="first">Thiago</forename><surname>Rocha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Silva</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Marco</forename><surname>Winckler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cédric</forename><surname>Bach</surname></persName>
		</author>
		<idno type="DOI">10.1007/s10111-019-00566-3</idno>
		<ptr target="https://doi.org/10.1007/s10111-019-00566-3" />
	</analytic>
	<monogr>
		<title level="j">Cognition, Technology &amp; Work</title>
		<imprint>
			<date type="published" when="2019-05-16">2019. 16 May 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Definition of a Behavior-Driven Model for Requirements Specification and Testing of Interactive Systems</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">R</forename><surname>Silva</surname></persName>
		</author>
		<idno type="DOI">10.1109/RE.2016.12</idno>
		<ptr target="https://doi.org/10.1109/RE.2016.12" />
	</analytic>
	<monogr>
		<title level="m">IEEE 24th International Requirements Engineering Conference</title>
		<imprint>
			<date type="published" when="2016">2016. 2016</date>
			<biblScope unit="page" from="444" to="449" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">A Behavior-Based Ontology for Supporting Automated Assessment of Interactive Systems</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">R</forename><surname>Silva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Winckler</surname></persName>
		</author>
		<idno type="DOI">10.1109/ICSC.2017.73</idno>
		<ptr target="https://doi.org/10.1109/ICSC.2017.73Proc" />
	</analytic>
	<monogr>
		<title level="m">IEEE 11th International Conference on Semantic Computing (ICSC)</title>
		<imprint>
			<publisher>EICS</publisher>
			<date type="published" when="2017-06">2017. 2017. June 2020</date>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="250" to="257" />
		</imprint>
	</monogr>
	<note>Publication date</note>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">An Approach for Multi-Artifact Testing Through an Ontological Perspective for Behavior-Driven Development</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">R</forename><surname>Silva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J-L</forename><surname>Hak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Winckler</surname></persName>
		</author>
		<idno type="DOI">10.7250/csimq.2016-7.05</idno>
		<ptr target="https://doi.org/10.7250/csimq.2016-7.05" />
	</analytic>
	<monogr>
		<title level="j">Complex Systems Informatics and Modeling Quarterly</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="81" to="107" />
			<date type="published" when="2016-06">2016. June/July 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Testing Prototypes and Final User Interfaces Through an Ontological Perspective for Behavior-Driven Development</title>
		<author>
			<persName><forename type="first">Thiago</forename><surname>Rocha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Silva</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Jean-Luc</forename><surname>Hak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marco</forename><surname>Winckler</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-319-44902-9_7</idno>
		<ptr target="https://doi.org/10.1007/978-3-319-44902-9_7" />
	</analytic>
	<monogr>
		<title level="m">Human-Centered and Error-Resilient Systems Development</title>
		<editor>
			<persName><forename type="first">Cristian</forename><surname>Bogdan</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Jan</forename><surname>Gulliksen</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Stefan</forename><surname>Sauer</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Peter</forename><surname>Forbrig</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Marco</forename><surname>Winckler</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Chris</forename><surname>Johnson</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Philippe</forename><surname>Palanque</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Regina</forename><surname>Bernhaupt</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Filip</forename><surname>Kis</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="86" to="107" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">A Formal Ontology for Describing Interactive Behaviors and Supporting Automated Testing on User Interfaces</title>
		<author>
			<persName><forename type="first">Thiago</forename><surname>Rocha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Silva</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Jean-Luc</forename><surname>Hak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marco</forename><surname>Winckler</surname></persName>
		</author>
		<idno type="DOI">10.1142/S1793351X17400219</idno>
		<ptr target="https://doi.org/10.1142/S1793351X17400219" />
	</analytic>
	<monogr>
		<title level="j">International Journal of Semantic Computing</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">04</biblScope>
			<biblScope unit="page" from="513" to="539" />
			<date type="published" when="2017">2017. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Towards Automated Requirements Checking Throughout Development Processes of Interactive Systems</title>
		<author>
			<persName><forename type="first">Thiago</forename><surname>Rocha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Silva</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Marco</forename><surname>Winckler</surname></persName>
		</author>
		<ptr target="CEUR-WS.org" />
	</analytic>
	<monogr>
		<title level="m">Joint Proceedings of the 22nd International Conference on Requirements Engineering: Foundation for Software Quality</title>
		<meeting><address><addrLine>REFSQ</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016">2016. 2016</date>
			<biblScope unit="volume">1564</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">A Scenario-Based Approach for Checking Consistency in User Interface Design Artifacts</title>
		<author>
			<persName><forename type="first">Thiago</forename><surname>Rocha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Silva</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Marco</forename><surname>Winckler</surname></persName>
		</author>
		<idno type="DOI">10.1145/3160504.3160506</idno>
		<ptr target="https://doi.org/10.1145/3160504.3160506" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the XVI Brazilian Symposium on Human Factors in Computing Systems</title>
		<meeting>the XVI Brazilian Symposium on Human Factors in Computing Systems<address><addrLine>Joinville, Brazil) (IHC; New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2017">2017. 2017</date>
			<biblScope unit="page">10</biblScope>
		</imprint>
	</monogr>
	<note>Article 3</note>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">BDD in Action: Behavior-driven development for the whole software lifecycle</title>
		<author>
			<persName><forename type="first">John</forename><surname>Ferguson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Smart</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2014">2014</date>
			<publisher>Manning Publications</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Testing against Natural Language Requirements</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">M</forename><surname>Sneed</surname></persName>
		</author>
		<idno type="DOI">10.1109/QSIC.2007.4385524</idno>
		<ptr target="https://doi.org/10.1109/QSIC.2007.4385524" />
	</analytic>
	<monogr>
		<title level="m">Seventh International Conference on Quality Software (QSIC 2007)</title>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="380" to="387" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">A Study of the Characteristics of Behaviour Driven Development</title>
		<author>
			<persName><forename type="first">C</forename><surname>Solis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<idno type="DOI">10.1109/SEAA.2011.76</idno>
		<ptr target="https://doi.org/10.1109/SEAA.2011.76" />
	</analytic>
	<monogr>
		<title level="m">37th EUROMICRO Conference on Software Engineering and Advanced Applications</title>
		<imprint>
			<date type="published" when="2011">2011. 2011</date>
			<biblScope unit="page" from="383" to="387" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Software evaluation problem situations</title>
		<author>
			<persName><forename type="first">Ioannis</forename><surname>Stamelos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexis</forename><surname>Tsoukias</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">European Journal of Operational Research</title>
		<imprint>
			<biblScope unit="volume">145</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="273" to="286" />
			<date type="published" when="2003">2003. 2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Software quality engineering: testing, quality assurance, and quantifiable improvement</title>
		<author>
			<persName><forename type="first">Jeff</forename><surname>Tian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Chapter Software Inspection</title>
		<imprint>
			<publisher>John Wiley &amp; Sons</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="237" to="250" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Bridging Enterprise and Software Engineering Through an User-Centered Design Perspective</title>
		<author>
			<persName><forename type="first">Pedro</forename><surname>Valente</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thiago</forename><surname>Silva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marco</forename><surname>Winckler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nuno</forename><surname>Nunes</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-319-48743-4_28</idno>
		<ptr target="https://doi.org/10.1007/978-3-319-48743-4_28" />
	</analytic>
	<monogr>
		<title level="m">Web Information Systems Engineering -WISE 2016</title>
		<editor>
			<persName><forename type="first">Wojciech</forename><surname>Cellary</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Mohamed</forename><forename type="middle">F</forename><surname>Mokbel</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Jianmin</forename><surname>Wang</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Hua</forename><surname>Wang</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Rui</forename><surname>Zhou</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Yanchun</forename><surname>Zhang</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="349" to="357" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">The Goals Approach: Agile Enterprise Driven Software Development</title>
		<author>
			<persName><forename type="first">Pedro</forename><surname>Valente</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thiago</forename><surname>Silva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marco</forename><surname>Winckler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nuno</forename><surname>Nunes</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-319-52593-8_13</idno>
		<ptr target="https://doi.org/10.1007/978-3-319-52593-8_13" />
	</analytic>
	<monogr>
		<title level="m">Complexity in Information Systems Development</title>
		<editor>
			<persName><forename type="first">Jerzy</forename><surname>Goluchowski</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Malgorzata</forename><surname>Pankowska</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Henry</forename><surname>Linger</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Chris</forename><surname>Barry</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Michael</forename><surname>Lang</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Christoph</forename><surname>Schneider</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="201" to="219" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">The Goals Approach: Enterprise Model-Driven Agile Human-Centered Software Engineering</title>
		<author>
			<persName><forename type="first">Pedro</forename><surname>Valente</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thiago</forename><forename type="middle">Rocha</forename><surname>Silva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marco</forename><surname>Winckler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nuno Jardim</forename><surname>Nunes</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-319-44902-9_17</idno>
		<ptr target="https://doi.org/10.1007/978-3-319-44902-9_17" />
	</analytic>
	<monogr>
		<title level="m">Human-Centered and Error-Resilient Systems Development</title>
		<editor>
			<persName><forename type="first">Cristian</forename><surname>Bogdan</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Jan</forename><surname>Gulliksen</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Stefan</forename><surname>Sauer</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Peter</forename><surname>Forbrig</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Marco</forename><surname>Winckler</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Chris</forename><surname>Johnson</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Philippe</forename><surname>Palanque</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Regina</forename><surname>Bernhaupt</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Filip</forename><surname>Kis</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="261" to="280" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Costs and benefits of early defect detection: experiences from developing client server and host applications</title>
		<author>
			<persName><forename type="first">Rudolf</forename><surname>Van</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Megen</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Dirk</forename><forename type="middle">B</forename><surname>Meyerhoff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Software Quality Journal</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="247" to="256" />
			<date type="published" when="1995">1995. 1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">StateWebCharts: A Formal Description Technique Dedicated to Navigation Modelling of Web Applications</title>
		<author>
			<persName><forename type="first">Marco</forename><surname>Winckler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Philippe</forename><surname>Palanque</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Interactive Systems. Design, Specification, and Verification</title>
		<meeting><address><addrLine>Berlin Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="61" to="76" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Models as Representations for Supporting the Development of e-Procedures</title>
		<author>
			<persName><forename type="first">Marco</forename><surname>Winckler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Philippe</forename><surname>Palanque</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Usability in Government Systems</title>
		<imprint>
			<publisher>Elsevier</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="301" to="315" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Linking GUI elements to tasks: supporting an evolutionary design process</title>
		<author>
			<persName><forename type="first">Andreas</forename><surname>Wolff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Forbrig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anke</forename><surname>Dittmar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Reichart</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 4th international workshop on Task models and diagrams</title>
		<title level="s">Proc. ACM Hum.-Comput. Interact.</title>
		<meeting>the 4th international workshop on Task models and diagrams</meeting>
		<imprint>
			<publisher>EICS</publisher>
			<date type="published" when="2005-10">2005. Received October 2019. November 2019. December 2019. June 2020</date>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="27" to="34" />
		</imprint>
	</monogr>
	<note>Publication date. View publication stats View publication stats</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
