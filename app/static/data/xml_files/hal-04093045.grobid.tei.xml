<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Reflex-in: Generate Music on the Web with Real-time Brain Wave</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Shihong</forename><surname>Ren</surname></persName>
							<email>shihong.ren@univ-st-etienne.fr</email>
						</author>
						<author>
							<persName><forename type="first">Michel</forename><surname>Buffa</surname></persName>
							<email>buffa@univ-cotedazur.fr</email>
						</author>
						<author>
							<persName><forename type="first">Gerwin</forename><surname>Schalk</surname></persName>
							<email>gerwin.schalk@shanda.com</email>
						</author>
						<author>
							<persName><forename type="first">Chrissy</forename><surname>Chen</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Laurent</forename><surname>Pottier</surname></persName>
							<email>laurent.pottier@univ-st-etienne.fr</email>
						</author>
						<author>
							<persName><forename type="first">Yang</forename><surname>Yu</surname></persName>
							<email>yuyang@shcmusic.edu.cn</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Shanghai Conservatory of Music</orgName>
								<orgName type="institution">SKLMA Université Jean Monnet</orgName>
								<address>
									<settlement>ECLLA China</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution" key="instit1">University Côte d&apos;Azur</orgName>
								<orgName type="institution" key="instit2">CNRS</orgName>
								<orgName type="institution" key="instit3">INRIA France</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="institution">Institute</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="institution" key="instit1">Université Jean Monnet</orgName>
								<orgName type="institution" key="instit2">ECLLA France</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff4">
								<orgName type="institution">Shanghai Conservatory of Music</orgName>
								<address>
									<country>SKLMA China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Reflex-in: Generate Music on the Web with Real-time Brain Wave</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">87D38D1EB1A6809DAF15C7D203E78EE8</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-04-12T14:53+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract/>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The music generated from the algorithm -mapping brain wave signal to musical events -aims to produce a form of furniture music that is relaxing and meditative, possibly therapeutic. This effect can be further enhanced through binaural beats or other forms of auditory stimulation, also known as "digital drugs," which can be enabled through the user interface. The system represents a potential avenue for the development of closed-loop brain-computer interfaces by using the listener's own brain waves as the source of musical stimuli, which can be used for therapeutic or medical purposes. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CCS CONCEPTS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">ABOUT THE WORK</head><p>Generative music from physiological sensors or EEG devices (brain wave) has been implemented since the middle of the 20th century. <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b11">12]</ref> Controlling a human-computer interface using these signals is often more challenging than using gestures or physical objects due to the need for greater precision and the presence of measurement noise. The difficulty and complexity of the music creation process has hindered its development in recent decades.</p><p>However, this type of music may have potential benefit for human health. Its impact has been explored through various perspectives, including the famous "Mozart effect." <ref type="bibr" target="#b5">[6]</ref> By using physiological measurements to assess changes in symptoms of illnesses, emotions, and sleep, researchers are able to conduct more precise experiments on the ways music can impact human health.</p><p>EEG signal is one of the main measurement tools for sleep and brain related diseases. Analysis of brain waves enables the direct identification of different sleep cycles, making it easier to conduct research on sleep quality. This property facilitates the quantitative research on sleep quality and makes the effect of auditory stimulation or music on sleep measurable in real time. <ref type="bibr" target="#b1">[2]</ref> Based on this context, our work aims to use Web technologies to transform smart devices into a brain-controlled music box. Our previous researches focused on web-based DSP techniques, sound design systems, visual programming languages for real-time audio processing and interactive music <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b10">11]</ref>, and led to the design and implementation of a "patcher" web application named JSPatcher <ref type="bibr" target="#b9">[10]</ref>, a high-level visual language similar to the one of Max/MSP <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b4">5]</ref>, that enables users to visually, interactively, construct audio graphs using the Web Audio API. For this new project, we also rely on JSPatcher. Users can graphically design and execute DSP algorithms using domain-specific languages (DSL) for audio processing such as Faust or Gen. These algorithms are executed in a dedicated high-priority thread called an AudioWorklet. This application can also be utilized to design interactive programs and shareable digital artworks online, incorporating other JavaScript language features, Web APIs, web-based audio plugins, or external JavaScript modules.</p><p>Typical BCI software such as BCI2000 <ref type="bibr" target="#b12">[13]</ref> or OpenBCI<ref type="foot" target="#foot_1">1</ref> can be used for transferring brain wave data through the UDP network protocol with the OSC format. We first forward the data through WebSocket protocol, possibly with a local server, then capture it in the browser. The peaks in the brain wave signal are then used to trigger the web-based synthesizer built in JSPatcher, which has access to the WebSocket API for processing the incoming brain wave signal.</p><p>To process the signal, a patcher is created with a web browser using the JSPatcher web application<ref type="foot" target="#foot_3">2</ref> . When a patcher is hosted on an online server, a URL can be used to prompt JSPatcher to open the patcher program in run-time mode, displaying user interface elements and providing a usable application for end-users, as opposed to the "editing mode. "</p><p>The generated web application<ref type="foot" target="#foot_4">3</ref> can be used to adjust the rhythm, harmony, and timbre of the sound. These adjustments can be performed manually (using GUI elements like buttons, knobs, and sliders, etc.) or automatically over time.</p><p>The synthesizer part is created from Faust DSP. Faust is a functional, synchronous, domain-specific programming language designed for real-time audio signal processing and synthesis <ref type="bibr" target="#b2">[3]</ref>. Thanks to the Emscripten transpiler and the WebAssembly format, the Faust compiler is available as a JavaScript module named faustwasm <ref type="bibr" target="#b6">[7]</ref> which can compile Faust code to a fully functional WebAudio AudioWorklet node, directly in the browser. The main Faust DSP in this work is a a 16-voice additive synthesizers with envelopes, frequency modulators and amplitude modulators, Parameters affecting timbres can be controlled from the user interface.</p><p>A real-time WebGL visualization is displayed as the background of the user interface. The graphics are generated using the three.js library <ref type="foot" target="#foot_5">4</ref> and are based on the brain wave and the music generated. Two real-time signal analyzers are used for reporting the peak values of the brain wave signal and the audio signal. The values are used by the WebGL shaders to modify the position of the particles rendered as a real-time 2-dimensional waveform visualization.</p><p>Reflex-in is an original creation experience, implementing a set of standard web technologies. It shows that it is possible to develop original audio/musical applications with the web platform. It has mainly been designed as an artwork, while we also discussed its potential therapeutic applications. This work is a prototype for people who need to hear a real-time musical feedback from their brain wave in order to eventually improve the sleep quality. It will be tested soon with neuroscientists to assess its effect with different music parameters on a closed-loop BCI system. This work is commissioned by Shanghai Conservatory of Music and Shanghai Key Laboratory for Music Acoustics.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Diagram of the proposed medical use of Reflex-in</figDesc><graphic coords="2,53.80,259.65,504.40,283.73" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>•</head><label></label><figDesc>Human-centered computing → Interaction design; • Information systems → Web applications.</figDesc><table><row><cell>KEYWORDS</cell></row><row><cell>music, brain wave, web audio, visual programming language</cell></row><row><cell>ACM Reference Format:</cell></row><row><cell>Shihong Ren, Michel Buffa, Gerwin Schalk, Laurent Pottier, and Yang Yu.</cell></row><row><cell>2023. Reflex-in: Generate Music on the Web with Real-time Brain Wave. In</cell></row><row><cell>Proceedings of The Web Conference 2023 (Conference WWW '23). ACM, New</cell></row><row><cell>York, NY, USA, 3 pages. https://doi.org/XXXXXXX.XXXXXXX</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>Conference WWW '23, April 30-May 4, 2023, Austin TX, USA Ren, et al.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_1"><p>OpenBCI homepage: https://openbci.com/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_2"><p>We propose to present this artwork at the conference, using a large display, ideally large TV with touch screen. For the demonstration/exhibition of the artwork We can simulate real-time brain wave by replaying EEG recordings on the computer.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_3"><p>We call a "patcher" a program written online using the JSPatcher web application. JSPatcher can run a patcher in "editing mode" that allows editing the program, or in "run-time mode" that shows the patcher like a web application.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_4"><p>A live demo can be found at https://jspat.shren.site/dist/?projectZip=https://static. shren.site/reflex-in/project.zip&amp;file=main.jspat&amp;runtime=1</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_5"><p>Three.js Homepage: https://threejs.org/</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<author>
			<persName><forename type="first">Alvin</forename><surname>Lucier</surname></persName>
		</author>
		<title level="m">Music for a Solo Performer, live performance</title>
		<imprint>
			<date type="published" when="1965">1965. 1965</date>
		</imprint>
		<respStmt>
			<orgName>Brandeis University</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Auditory Closed-Loop Stimulation of the Sleep Slow Oscillation Enhances Memory</title>
		<author>
			<persName><forename type="first">V</forename><surname>Hong-Viet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Ngo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jan</forename><surname>Martinetz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthias</forename><surname>Born</surname></persName>
		</author>
		<author>
			<persName><surname>Mölle</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.neuron.2013.03.006</idno>
		<ptr target="https://doi.org/10.1016/j.neuron.2013.03.006" />
	</analytic>
	<monogr>
		<title level="j">Neuron</title>
		<imprint>
			<biblScope unit="volume">78</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="545" to="553" />
			<date type="published" when="2013-05">2013. May 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">FAUST : an Efficient Functional Approach to DSP Programming</title>
		<author>
			<persName><forename type="first">Yann</forename><surname>Orlarey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dominique</forename><surname>Fober</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stéphane</forename><surname>Letz</surname></persName>
		</author>
		<ptr target="https://hal.archives-ouvertes.fr/hal-02159014" />
	</analytic>
	<monogr>
		<title level="m">New Computational Paradigms for Computer Music</title>
		<meeting><address><addrLine>Paris, France</addrLine></address></meeting>
		<imprint>
			<publisher>Editions Delatour France</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="65" to="96" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">The patcher</title>
		<author>
			<persName><surname>Miller Puckette</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Computer Music Conference</title>
		<meeting>the International Computer Music Conference<address><addrLine>San Francisco, United States</addrLine></address></meeting>
		<imprint>
			<publisher>Computer Music Association</publisher>
			<date type="published" when="1986">1986</date>
			<biblScope unit="page" from="420" to="429" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<author>
			<persName><forename type="first">Miller</forename><surname>Puckette</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename></persName>
		</author>
		<title level="m">Max/msp</title>
		<meeting><address><addrLine>Cycling</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1990">1990. 1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Music and spatial task performance</title>
		<author>
			<persName><forename type="first">Frances</forename><forename type="middle">H</forename><surname>Rauscher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gordon</forename><forename type="middle">L</forename><surname>Shaw</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Catherine</forename><forename type="middle">N</forename><surname>Ky</surname></persName>
		</author>
		<idno type="DOI">10.1038/365611a0</idno>
		<ptr target="https://doi.org/10.1038/365611a0" />
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">365</biblScope>
			<biblScope unit="page" from="611" to="611" />
			<date type="published" when="1993-10">1993. Oct. 1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Modernized Toolchains to Create JSPatcher Objects and WebAudioModules from Faust Code</title>
		<author>
			<persName><forename type="first">Stéphane</forename><surname>Shihong Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yann</forename><surname>Letz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dominique</forename><surname>Orlarey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Romain</forename><surname>Fober</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michel</forename><surname>Michon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Laurent</forename><surname>Buffa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yang</forename><surname>Pottier</surname></persName>
		</author>
		<author>
			<persName><surname>Yu</surname></persName>
		</author>
		<idno type="DOI">10.5281/zenodo.6767596</idno>
		<ptr target="https://doi.org/10.5281/zenodo.6767596" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Web Audio Conference</title>
		<meeting>the International Web Audio Conference<address><addrLine>Université Côte d&apos;Azur, Cannes, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">From Diagram to Code: a Web-based Interactive Graph Editor for Faust DSP Design and Code Generation</title>
		<author>
			<persName><forename type="first">Shihong</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Laurent</forename><surname>Pottier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michel</forename><surname>Buffa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Functional Audio Stream (Faust) Conference</title>
		<meeting>the International Functional Audio Stream (Faust) Conference<address><addrLine>Saint-Denis / Virtual, France</addrLine></address></meeting>
		<imprint>
			<publisher>GRAME</publisher>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Build WebAudio and JavaScript Web Applications using JSPatcher: A Web-based Visual Programming Editor</title>
		<author>
			<persName><forename type="first">Shihong</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Laurent</forename><surname>Pottier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michel</forename><surname>Buffa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Web Audio Conference (WAC &apos;21), Luis Joglar-Ongay</title>
		<editor>
			<persName><forename type="first">Xavier</forename><surname>Serra</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Frederic</forename><surname>Font</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Philip</forename><surname>Tovstogan</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Ariane</forename><surname>Stolfi</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Albin</forename><forename type="middle">A</forename><surname>Correya</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Antonio</forename><surname>Ramires</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Dmitry</forename><surname>Bogdanov</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Angel</forename><surname>Faraldo</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Xavier</forename><surname>Favory</surname></persName>
		</editor>
		<meeting>the International Web Audio Conference (WAC &apos;21), Luis Joglar-Ongay<address><addrLine>Barcelona, Spain</addrLine></address></meeting>
		<imprint>
			<publisher>UPF</publisher>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">JSPatcher, a Visual Programming Environment for Building High-Performance Web Audio Applications</title>
		<author>
			<persName><forename type="first">Shihong</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Laurent</forename><surname>Pottier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michel</forename><surname>Buffa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yang</forename><surname>Yu</surname></persName>
		</author>
		<idno type="DOI">10.17743/jaes.2022.0056</idno>
		<ptr target="https://doi.org/10.17743/jaes.2022.0056" />
	</analytic>
	<monogr>
		<title level="j">Journal of the Audio Engineering Society</title>
		<imprint>
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="page" from="938" to="950" />
			<date type="published" when="2022-11">2022. Nov. 2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Making Computer Music on the Web with JSPatcher</title>
		<author>
			<persName><forename type="first">Shihong</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Laurent</forename><surname>Pottier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michel</forename><surname>Buffa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yang</forename><surname>Yu</surname></persName>
		</author>
		<idno type="DOI">10.5281/zenodo.6573552</idno>
		<ptr target="https://doi.org/10.5281/zenodo.6573552" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Sound and Music Computing Conference</title>
		<editor>
			<persName><forename type="first">Romain</forename><surname>Michon</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Laurent</forename><surname>Pottier</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Yann</forename><surname>Orlarey</surname></persName>
		</editor>
		<meeting>the Sound and Music Computing Conference<address><addrLine>Saint-Etienne, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="541" to="548" />
		</imprint>
		<respStmt>
			<orgName>SMC Network</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">The Performing Brain</title>
		<author>
			<persName><forename type="first">David</forename><surname>Rosenboom</surname></persName>
		</author>
		<idno type="DOI">10.2307/3680116</idno>
		<ptr target="https://doi.org/10.2307/3680116" />
	</analytic>
	<monogr>
		<title level="j">Computer Music Journal</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">48</biblScope>
			<date type="published" when="1990">1990. 1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">BCI2000: a general-purpose brain-computer interface (BCI) system</title>
		<author>
			<persName><forename type="first">Gerwin</forename><surname>Schalk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dennis</forename><forename type="middle">J</forename><surname>Mcfarland</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thilo</forename><surname>Hinterberger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Niels</forename><surname>Birbaumer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><forename type="middle">R</forename><surname>Wolpaw</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on biomedical engineering</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1034" to="1043" />
			<date type="published" when="2004">2004. 2004</date>
			<publisher>IEEE</publisher>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
