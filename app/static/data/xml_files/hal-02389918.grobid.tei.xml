<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Injection of Automatically Selected DBpedia Subjects in Electronic Medical Records to boost Hospitalization Prediction</title>
				<funder ref="#_ZFaqMCX">
					<orgName type="full">Agence Nationale de la Recherche</orgName>
					<orgName type="abbreviated">ANR</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Raphaël</forename><surname>Gazzotti</surname></persName>
							<email>raphael.gazzotti@unice.fr</email>
						</author>
						<author>
							<persName><forename type="first">Catherine</forename><surname>Faron-Zucker</surname></persName>
							<email>catherine.faron@unice.fr</email>
						</author>
						<author>
							<persName><forename type="first">Fabien</forename><surname>Gandon</surname></persName>
							<email>gandon.fabien@inria.fr</email>
						</author>
						<author>
							<persName><forename type="first">Virginie</forename><surname>Lacroix-Hugues</surname></persName>
						</author>
						<author>
							<persName><forename type="first">David</forename><surname>Darmon</surname></persName>
							<email>david.darmon@unice.fr</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Université Côte d&apos;Azur</orgName>
								<orgName type="institution" key="instit2">Inria</orgName>
								<orgName type="institution" key="instit3">CNRS</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">I3S</orgName>
								<address>
									<settlement>Sophia-Antipolis</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="institution">SynchroNext</orgName>
								<address>
									<settlement>Nice</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="institution" key="instit1">Université Côte d&apos;Azur</orgName>
								<orgName type="institution" key="instit2">Inria</orgName>
								<orgName type="institution" key="instit3">CNRS</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff4">
								<orgName type="institution">I3S</orgName>
								<address>
									<settlement>Sophia-Antipolis</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff5">
								<orgName type="institution" key="instit1">Inria</orgName>
								<orgName type="institution" key="instit2">Université Côte d&apos;Azur</orgName>
								<orgName type="institution" key="instit3">CNRS</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff6">
								<orgName type="institution">I3S</orgName>
								<address>
									<settlement>Sophia-Antipolis</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff7">
								<orgName type="department">Département d&apos;Enseignement et de Recherche en Médecine Générale</orgName>
								<orgName type="laboratory">RETINES</orgName>
								<orgName type="institution">Université Côte d&apos;Azur</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff8">
								<orgName type="department">Faculté de médecine</orgName>
								<address>
									<settlement>Nice</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff9">
								<orgName type="department">Département d&apos;Enseignement et de Recherche en Médecine Générale</orgName>
								<orgName type="laboratory">RETINES</orgName>
								<orgName type="institution">Université Côte d&apos;Azur</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff10">
								<orgName type="department">Faculté de médecine</orgName>
								<address>
									<settlement>Nice</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Injection of Automatically Selected DBpedia Subjects in Electronic Medical Records to boost Hospitalization Prediction</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">E77CCDA197B2DF71D14EF772751B066F</idno>
					<idno type="DOI">10.1145/3341105.3373932</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-04-12T14:53+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>• Applied computing → Health informatics</term>
					<term>• Theory of computation → Semantics and reasoning</term>
					<term>• Computing methodologies → Information extraction</term>
					<term>Feature selection</term>
					<term>Information extraction, Predictive model, Electronic medical record, Knowledge graph</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Although there are many medical standard vocabularies available, it remains challenging to properly identify domain concepts in electronic medical records. Variations in the annotations of these texts in terms of coverage and abstraction may be due to the chosen annotation methods and the knowledge graphs, and may lead to very different performances in the automated processing of these annotations. We propose a semi-supervised approach based on DBpedia to extract medical subjects from EMRs and evaluate the impact of augmenting the features used to represent EMRs with these subjects in the task of predicting hospitalization. We compare the impact of subjects selected by experts vs. by machine learning methods through feature selection. Our approach was experimented on data from the database PRIMEGE PACA that contains more than 600,000 consultations carried out by 17 general practitioners (GPs).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CCS CONCEPTS</head></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Electronic medical records (EMRs) contain vital information about a patient's state of health, and their analysis should enable preventing pathologies that may affect a patient in the future. Their exploitation through automated approaches makes it possible to discover patterns that, once addressed, are likely to improve the living conditions of the population. However, linguistic variability and tacit knowledge hinder automated processing, as they can lead to erroneous conclusions. In this paper we extract entities that help predict the hospitalization of patients from their electronic medical records and linked DBpedia<ref type="foot" target="#foot_0">1</ref> entities. DBpedia employs Semantic Web standards and structures Wikimedia project data with the Resource Description Framework (RDF). However, given the amount of general information available on DBpedia, it is challenging to filter knowledge specific to the healthcare domain. This is especially the case when it comes to identify concept relevant to the prediction of hospitalized patients. To answer this problem, we estimate the relevance of concepts and select the most promising ones to construct the vector representation of EMRs used to predict hospitalization.</p><p>As a field of experimentation, we used a dataset extracted from the PRIMEGE PACA relational database <ref type="bibr" target="#b14">[15]</ref> which contains more than 600,000 consultations in French by 17 general practitioners (Table <ref type="table" target="#tab_0">1</ref>). In this database, text descriptions written by general practitioners are available with international classification codes of prescribed drugs, pathologies and reasons for consultations, as well as the numerical values of the different medical examination results obtained by a patient.</p><p>In that context, our main research question is: How to extract knowledge relevant for the prediction of the occurrence of an event?</p><p>In our case study, we extract subjects related to hospitalization using knowledge from DBpedia and EMRs. In this paper, we focus on the following sub-questions:</p><p>• How to filter relevant domain knowledge from a general knowledge source? • How to deal with subjectivity in the annotation process? To answer these questions, we survey the related work (section 2) and position our contribution. We then introduce the proposed method for knowledge extraction from texts and specify the filters used to retrieve medical knowledge (section 3). Subsequently, we present the experimental protocol to compare the impact of knowledge selected by experts and automatic selection, and we discuss the results obtained (section 4). Finally, we conclude and provide our perspectives for this study (section 5).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head><p>In <ref type="bibr" target="#b5">[6]</ref>, to address data insufficiency and interpretation of deep learning models for the prediction of rarely observed diseases, the authors established a neural network with graph-based attention model that exploits ancestors extracted from the OWL-SKOS representations of ICD Disease, Clinical Classifications Software (CCS) and Systematized Nomenclature of Medicine Clinical Terms (SNOMED-CT). In order to exploit the hierarchical resources of these knowledge graphs in their attention mechanism, the graphs are transformed using GloVe embeddings <ref type="bibr" target="#b18">[19]</ref>. The results show that the proposed model outperforms a standard recurrent neural network when identifying pathologies that are rarely observed in the training data, at the same time also generalising better when only few training instances are available.</p><p>In <ref type="bibr" target="#b19">[20]</ref>, to improve accuracy in the recognition of daily living activities, the authors extract knowledge from the dataset of <ref type="bibr" target="#b16">[17]</ref> and structure it with a knowledge graph developed for this purpose. Then, they automatically deduce new class expressions, with the objective of extracting their attributes to recognize activities of daily living using machine learning algorithms. The authors highlight better accuracy and results than with traditional approaches, regardless of the machine learning algorithm on which this task has been addressed (up to 1.9% on average). Although they exploit solely the knowledge graph developed specifically for the purpose of discovering new rules, without trying to exploit other knowledge sources where a mapping could have been done. Their study shows the value of structured knowledge in classification tasks.</p><p>The SIFR Bioportal project <ref type="bibr" target="#b20">[21]</ref> provides a web service based on the NCBO BioPortal <ref type="bibr" target="#b22">[23]</ref> to annotate clinical texts in French with biomedical knowledge graphs. This service is able to handle clinical notes involving negations, experiencers (the patient or members of his family) and temporal aspects in the context of the entity references. However, the adopted approach involves domain specific knowledge graphs, while general resources like EMRs require general repositories such as, for instance, DBpedia.</p><p>In <ref type="bibr" target="#b9">[10]</ref>, the authors show that combining bag-of-words (BOW), biomedical entities and UMLS (the Unified Medical Language System 2 ) improve classification results in several tasks such as information retrieval, information extraction and text summarization regardless of the classifier. We intend here to study the same kind of impact but from a more general repository like DBpedia and on a domain-specific prediction task: we also propose a method to select relevant domain knowledge in order to boost hospitalization prediction.</p><p>In <ref type="bibr" target="#b10">[11]</ref>, we studied the contributions of different knowledge graphs (ATC, ICPC-2, NDF-RT, Wikidata and DBpedia) for hospitalization prediction. Compared to <ref type="bibr" target="#b10">[11]</ref>, this paper explores in more depth the impact of knowledge enrichment using DBpedia while relying on the same prediction method. Our goal is to provide a method to solve the problem of retrieving relevant knowledge in the medical domain from general knowledge source. The intuition behind the use of DBpedia is that general knowledge is only available on general repositories, and the way knowledge is structured differs from specialized referentials. To achieve this purpose, we propose a method that relies on semi-supervised learning to extract subject candidates. Selecting concepts relevant for a specific domain problem is both an expert and subjective task <ref type="bibr" target="#b11">[12]</ref> for which an automated solution could help develop new applications.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">KNOWLEDGE EXTRACTION AND REPRESENTATION OF EMR 3.1 Extraction of candidate subjects from DBpedia to predict hospitalization</head><p>The first step of our approach consists in recognizing named entities from the medical domain part of DBpedia within French texts contained in EMRs. This is performed by an instance of the semantic annotator DBpedia Spotlight <ref type="bibr" target="#b7">[8]</ref> that was deployed locally and pretrained with a French model. 3 To ensure that the retrieved entities belong to the medical domain, we enforce two constraints on the resources identified by DBpedia Spotlight. The first constraint requires that the identified resources belong to the medical domain of the French chapter of DBpedia. The second one does the same  with the English chapter in order to filter and select health domainrelated subjects and to overcome the defects of the French version in which property rdf:type is poorly used. This involves calling two SERVICE clauses in a SPARQL query,<ref type="foot" target="#foot_1">4</ref> each one implementing a constraint according to the structure of the French and English chapter it remotely queries. The workflow is represented in Figure <ref type="figure" target="#fig_0">1</ref> and the query in Listing 1.</p><p>From the URIs of the identified resources, the first part of the query (lines 9-29) accesses the French chapter of DBpedia to check that the value of their property dcterms:subject<ref type="foot" target="#foot_2">5</ref> belongs to one of the hierarchies of SKOS concepts (skos:broader, skos:narrower) having for roots the French terms for disease, health, medical genetics, medicine, urgency, treatment, anatomy, addiction and bacteria.</p><p>The second part of the query (lines 31-41) checks that the identified resources from the French DBpedia have for its English equivalent (owl:sameAs) at least one of the following types (rdf:type) <ref type="foot" target="#foot_3">6</ref> : dbo:Disease, dbo:Bacteria, yago:WikicatViruses, yago:WikicatRetroviruses, yago:WikicatSurgicalProcedures, yago:WikicatSurgicalRemovalProcedures.</p><p>We do not consider some other types like dbo:Drug, dbo:ChemicalCoumpound, dbo:ChemicalSubstance, dbo:Protein, or yago:WikicatMedicalTreatments, as they generate answers related to chemical compounds: the retrieved resources can thus range from drugs to plants, to fruits. We do not consider either types referring to other living beings like umbel-rc:BiologicalLivingObject or dbo:Species which are too general to return relevant results. We do not consider either many biomedical types in the yago namespace which URI ends by an integer (e.g., http://dbpedia.org/class/yago/Retrovirus101336282), which are too numerous and too close from each other. The type dbo:AnatomicalStructure is also non-relevant with this second constraint since it retrieves subjects related to different anatomical parts which are not human specific. The list of labels of concepts thus extracted allows to construct a vector representation of EMRs used to identify hospitalized patients.</p><p>In order to improve DBpedia Spotlight's detection capabilities, words or abbreviated expressions within medical reports are added to text fields using a symbolic approach, with rules and dictionaries. For instance the abbreviation "ic" which means "heart failure" is not recognized by DBpedia Spotlight, but is correctly identified by our rule-based approach. This method to retrieve classification labels was applied on all the textual fields of our dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Injection of concepts in the vector representation of EMRs</head><p>A domain specific corpus like PRIMEGE contains very specialized jargon, and which have a meaning adapted to its context. This is why we chose to use a bag-of-words (BOW) representation to avoid out of vocabulary issues. It allows us to generate our own textual representation of EMRs since it does not require a large amount of data. This model also enables to identify the contribution of each term to distinguish patients to hospitalize or not, thus answering algorithm explanation issues. Additionally, the integration of heterogeneous data is facilitated since it is sufficient to concatenate other attributes to this model without removing the meaning of the terms previously represented in this way. Moreover, loss of information is intrinsic to more advanced data representation models. We have opted for a BOW in order to remain able to provide general practitioners with the closest information available in their files.</p><p>In order to mimic the structure of the PRIMEGE database and to prevent wrong conclusions, we have introduced provenance prefixes during the creation of the bag-of-words to trace the contribution of the different fields. This allows to distinguish some textual data from each other in the vector representation of EMRs, e.g., a patient's personal history and his family history.</p><p>Subjects label from DBpedia are considered as a token in a textual message. When an entity is identified in a patient's medical record, the label of his corresponding subject is added to a concept vector. This attribute will have as value the number of occurrences of this subject within the patient's health record (e.g., the subjects 'Organ failure' and 'Medical emergencies' -among other conceptsare identified for 'pancréatite aiguë', acute pancreatitis, and the value for these attributes in our concept vector will be equal to 1). Let V i = {w i 1 , w i 2 , ..., w i n } be the bag-of-words obtained from the textual data in the EMR of the i t h patient. Let C i = {c i 1 , c i 2 , ..., c i m } be the bag of concepts for the i t h patient resulting from the extraction of labels of concepts belonging to DBpedia after analysis of his consultations from semi-structured data such as text fields listing drugs, pathologies, and unstructured data from free texts such as observations. The vector representation of the i t h patient is the sum of V i and C i or a sub-vector of it, as detailed in the next section. Figure <ref type="figure" target="#fig_2">2</ref> represents the general workflow used to generate vector representations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Alternative vector representations: manual vs. automatic selection of relevant subjects</head><p>To decide on the optimal vector representation of a patient's EMR, we considered further filtering the list of the labels of concepts extracted from DBpedia, depending on their relevancy for the targeted prediction task. We first submitted the list of the 285 extracted labels of concepts to human medical experts who were asked to assess their relevance for studying patients' hospitalization risks from their EMRs. Alternatively, we considered automatically selecting the concepts relevant for studying hospitalization by using a feature selection algorithm applied on a training set of vector representations of patients in the C i form.</p><p>As a result we generated the following alternative vector representations that should be compared when used to predict hospitalization.</p><p>• baseline: represents our basis of comparison where no enrichment with DBpedia concepts is made on EMR data, i.e., only text data in the form of bag-of-words: V i • α: refers to an enrichment of V i with the labels of concepts automatically extracted from the DBpedia knowledge base:</p><formula xml:id="formula_0">V i + C i .</formula><p>• β: refers to an enrichment of V i with a subset of the labels of concepts in C i acknowledged as relevant by at least one expert human annotator. • γ : refers to an enrichment of V i with a subset of the labels of concepts in C i acknowledged as relevant by all the experts human annotators. • ϵ: refers to an enrichment of V i with a subset of the labels of concepts in C i output by the automatic feature selection algorithm. We chose the Lasso algorithm <ref type="bibr" target="#b21">[22]</ref> and we executed it within the internal loop of the nested cross-validation in the global machine learning algorithm chosen to predict hospitalization. For the Lasso algorithm, we chose the default parameters (and the number of folds used for cross-validating in that context, fixed at F = 3).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">EXPERIMENTS AND RESULTS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Dataset and protocol</head><p>The extraction of labels of concepts described in Section 3.1 was performed on a sample of 1446 patients, DS B , a balanced dataset. This dataset contains data on 714 patients hospitalized and 732 patients not hospitalized. Then, we introduce these concepts in the vector representation of EMRs with the same dataset and classify them to predict the future hospitalization of patients or not.</p><p>To construct V i we consider the following EMR fields: sex, birth year, long term condition, risk factors, allergies, reasons of consultation with their associated codes, medical observations, diagnoses with their associated codes, care procedures, drugs prescribed with their associated codes and reasons of the prescription, patient's history, the family history, past problems and symptoms of the patient. Most of the concepts in C i are extracted from the field "reasons of consultation" that is very short and the field "medical observations" which length generally goes from 50 to 300 characters. By default, C i does not use the following fields: patient's history, the family history, past problems and symptoms of the patient.</p><p>An alternative vector representation of EMRs, ζ , uses for C i the following additional fields: patient's history, the family history, past problems and symptoms of the patient are processed. Note that the symptom field as the observation field is used by physicians for various purposes. ζ is constructed similarly to ϵ when considering these additional data.</p><p>Since we evaluate our vector representation with non-sequential machine learning algorithms, we aggregated all patients' consultations to overcome the temporal dimension specific to EMRs. All consultations occurring before hospitalization are aggregated into a vector representation of the patients' medical file. For patients who have not been hospitalized, all their consultations are aggregated. Thus, the text fields contained in patients' records are transformed into vectors.</p><p>We evaluated the vector representations by nested crossvalidation <ref type="bibr" target="#b3">[4]</ref>, with an outer loop with a K = 10, and an inner loop with L = 3. The exploration of hyperparameters was performed by random search <ref type="bibr" target="#b1">[2]</ref> over 150 iterations.</p><p>The different experiments were conducted on an HP EliteBook 840 G2, 2.6 GHz, 16 GB RAM with a virtual environment under Python 3.6.3. The creation of vector representations was done on the HP EliteBook and on this same machine were deployed DBpedia Spotlight and Corese Semantic Web Factory <ref type="bibr" target="#b6">[7]</ref>,<ref type="foot" target="#foot_4">7</ref> a software platform for the Semantic Web that implements RDF, RDFS, SPARQL 1.1 Query &amp; Update, and OWL RL.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Inter-rater reliability of subject annotation</head><p>Two general practitioners and one biologist have independently annotated the 285 subjects extracted from DBpedia. The annotations were transformed in vectors with a size of 285. Then, we compared with the Krippendorff's α metric vectors resulting from human annotation. We compare up to 3 vectors with Krippendorff's α metric, i. e. with the biologist and physicians, and up to 2 vectors to compare only the physicians' annotations. The correlation metric was used to compare different pairs of vectors resulting either from human or machine annotation. The Figure <ref type="figure" target="#fig_3">3</ref> shows the workflow used to assess inter-rater reliability.</p><p>Annotations have been evaluated towards the Krippendorff's α metric <ref type="bibr" target="#b13">[14]</ref> and obtained a score of 0.51, the annotation score between the two general practitioners is of 0.27.</p><p>Even by excluding some subjects involving a terminological conflict in their naming, since if someone annotates the beginning of a label of concept as relevant towards the hospitalization of a patient (the opposite is also true) all the labels of concepts starting with the same expression will be annotated in the same way. In doing so, the three annotators obtained a score of 0.66, and 0.52 for the inter-rater reliability between the two general practitioners. The subjects excluded started by 'Biology', 'Screening and diagnosis', 'Physiopathology', 'Psychopathology', 'Clinical sign', 'Symptom' and 'Syndrome' which brings us back to a new total of 243 concepts.</p><p>On average, 198 subjects were annotated by experts as relevant to the study of patients' hospitalization risks, respectively 217 and 181 for the general practitioners and 196 for the biologist among the 285 subjects proposed with the extraction based on the SPARQL query displayed in Section 3.1.</p><p>As discussed by <ref type="bibr" target="#b0">[1]</ref>, a score within this range of values is insufficient to drawn conclusions and it shows the difficulty of this task, both because identifying entities involved in patient hospitalization is subject to interpretation and because it is complex to find consensus in this task that could be seen at first sight as simplistic by an expert in the field.</p><p>The union of labels of concepts identified with the ζ approach counts 51 different subjects (63 if the provenance prefix is considered as a different subjects) and the intersection of labels of concepts identified with ζ counts 14 different subjects (19 if the provenance prefix is considered as a different subject). Table <ref type="table">2</ref> displays correlation metric values between experts and machine annotators (its value ranges from 0 to 2, meaning that 0 is a perfect correlation, 1 no correlation and 2 perfect negative correlation). This metric was computed by comparing among the 285 subjects, if they are deemed relevant, irrelevant or not annotated (in the case of human annotation) to study the patient's hospitalization risks from their EMRs, thus vectors are compared in pairs in this table.</p><p>Table <ref type="table">2</ref> shows up a wide variation between human annotators and machine annotators (maximum of 1.1399 between A 1 and M 4 ), whereas between annotators of a specific group this margin is not significant (maximum of 0.6814 for humans and maximum of 0.4185 for machines). The union of subjects U 1 retrieved by machine annotators is really similar to M 5 , since they have a correlation score of 0.12.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Selected machine learning algorithms</head><p>We performed the hospitalization prediction task with different state of the art algorithms available in the Scikit-Learn library <ref type="bibr" target="#b17">[18]</ref>. The optimized hyperparameters determined by nested cross-validation are as follows:</p><p>• SVC, C-Support Vector Classifier, which implementation is based on the libsvm implementation <ref type="bibr" target="#b4">[5]</ref>: The regularization coefficient C, the kernel used by the algorithm and the gamma coefficient of the kernel. • RF , Random Forest classifier <ref type="bibr" target="#b2">[3]</ref>: The number of trees in the forest, the maximum depth in the tree, the minimum number</p><formula xml:id="formula_1">Table 2: Correlation metric (1 - (u-ū).(v-v) ∥u-ū ∥ 2 ∥v-v ∥ 2</formula><p>, with ū, the mean of elements of u, and respectively v, the mean of elements of v) computed on the 285 subjects. A 1 to A 3 refers to human annotators and M 1 to M 10 refers to machine learning through feature selection annotation on the ζ approach (considering the 10 K-Fold). U 1 is the union of subjects from the sets M 1 to M 10 . of samples required to split an internal node, the minimum number of samples required to be at a leaf node and the maximum number of leaf nodes. • Loд, Logistic Regression classifier <ref type="bibr" target="#b15">[16]</ref>: The regularization coefficient C and the penalty used by the algorithm.</p><formula xml:id="formula_2">A 1 A 2 A 3 M 1 M 2 M 3 M 4 M 5 M 6 M 7 M 8 M 9 M 10 U 1 A 1 \ 0.</formula><p>One of the motivations for using these algorithms is because logistic regression and random forest are widely used in order to predict risk factors in EMR <ref type="bibr" target="#b12">[13]</ref>. These machine learning algorithms are able to provide a native interpretation of their decisions. The reasons leading to a patient's hospitalization are thus reported to the physician, as well as the factors on which the physician can intervene to prevent this event from occurring. Moreover, the limited size of our dataset excluded neural networks approaches.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Results</head><p>We used the F tp,f p metric <ref type="bibr" target="#b8">[9]</ref> to evaluate the performance of machine learning algorithms. Let T N be the number of negative instances correctly classified (True Negative), F P the number of negative instances incorrectly classified (False Positive), F N the number of positive instances incorrectly classified (False Negative) and T P the number of positive instances correctly classified (True Positive). K represents the number of loops used to cross-validate (in our context this number is fixed at 10) and the notation f is used to distinguish a fold related metric like the amount of true positives to the sum of true positives across all folds.</p><formula xml:id="formula_3">T P f = K i=1 T P (i) F P f = K i=1 F P (i) F N f = K i=1 F N (i) F tp,f p = 2.T P f 2.T P f + F P f + F N f</formula><p>The comparison of the different features sets is presented in Table <ref type="table" target="#tab_3">3</ref>. Results with only bag of concepts were not included (no feature from the baseline), since with the 285 subjects, C i , and the logistic regression algorithm we obtained a F tp,f p of 0.6778.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Generalization of concepts vector</head><p>Following the list of labels of concepts extracted for each fold with the ζ approach, we evaluate the effect of a global vector of concepts since with our experimentation setup the selected features can be different from one fold to another, i.e., a same vector of concepts across all folds. Thus, we generate different stable vector of concepts based on the number of intersections of subjects and union of subjects with the hyperparameters identified with the ζ approaches.</p><p>The intersection of all the subjects gets a score of 0.8662 and the union of all subjects encountered for each fold obtains a score of 0.8714 which is better than the baseline (by more than 2%) and even better than the ζ approach. For the generalization of concepts vector, the main gain is shown on the right of the Table <ref type="table" target="#tab_5">5</ref> with the increase of true positives and therefore reduction of false negatives.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6">Discussion</head><p>The SPARQL query in Listing 1 allowed to extract a list of medical subjects from DBpedia considered relatively relevant to the issue of hospitalization since approximately 198 subjects out of 285 were annotated in this way by experts.</p><p>The best performing approach, ζ , selected a much smaller number of subjects with a feature selection process, this implies that the selected subjects are more precise in order to distinguish hospitalized patients from other ones (Tables <ref type="table" target="#tab_4">4</ref> and<ref type="table" target="#tab_5">5</ref>) by improving both the detection of true positives and true negatives. The union of subjects also improves the number of true positives in comparison to the ζ approach. That means that a step involving a feature selection algorithm allows to retrieve the most relevant labels of concepts in a context where the training dataset is small and may help with annotation procedures. Although this requires a more specific selection, comparing the results obtained with ϵ and ζ approach shows that subjects not directly related to the patient's own case helps to predict his hospitalization.</p><p>Among the 51 labels of concepts selected with the union of subjects, more generic knowledge was selected like 'Terme médical' (respectively 'Medical Terminology'), one possibility could be that the general practitioner uses a technical terminology in a situation involving a complex medical case. Numerous concepts related to patient's mental state (like 'Antidépresseur', 'Dépression (psychiatrie)', 'Psychopathologie', 'Sémiologie psychiatrique', 'Trouble de l'humeur') appear to be a cause of hospitalization. Different concepts related to the allergy ('Allergologie', 'Maladie pulmonaire d'origine allergique') and infectious diseases ('Infection ORL', 'Infection urinaire', 'Infection virale', 'Virologie médicale') were selected. Concepts related to the cardiovascular system are widely represented within this set ('Dépistage et diagnostic du système cardiovasculaire', 'Maladie cardio-vasculaire', 'Physiologie du système cardio-vasculaire', 'Signe clinique du système cardio-vasculaire', 'Trouble du rythme cardiaque'). The only concept retrieved in the family history of the patient, at the exception of 'Medical Terminology', is 'Diabète' (respectively 'Diabetes'). Among the labels of concepts selected by machine learning through feature selection, rare concepts considered irrelevant at first sight toward the problem of hospitalization such as 'Medical Terminology' could find an explanation. Also, a feature selection step helps to improve the prediction of hospitalization by adding knowledge indirectly related to the patient's condition, such as family history (approach ζ ).</p><p>Although the number of subjects considered as relevant by experts is quite high, their integration into a vector representation reduced the performance obtained in comparison to the baseline, one of the possibilities for this result is the limited size of our annotated corpus. One of the weaknesses of this approach is that a knowledge base like DBpedia may be incomplete (incompleteness of properties dcterms:subjects, owl:sameAs and rdf:type), which would justify in order to obtain better results to proceed to the content curation of such knowledge base.</p><p>The incompleteness of medical records implies a huge variety between patient and from one consultation to another for the same patient according to the level of information provided by the general practitioner. Also, joint medical care by a fellow specialist with sometimes little information about these cares is another negative factor. Moreover, the patient may not have been detected as being particularly at risk or may not be very observant and does not come a lot to consultations, this shows the interest of being able to work on patient trajectories and to set up a health data warehouse combining several sources.</p><p>Reports of the consultations contain abbreviations of experts and thus it would lead to significant improvements in the knowledge extraction task to be able to distinguish abbreviations and their meanings in a given medical context. We plan to detect negation and experiencer in future work since a pathology affecting a patient's relationship or the negation of a pathology does not carry the same meaning when it comes to predict a patient's hospitalization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">CONCLUSION</head><p>In this paper, we have presented a method to extract from the DBpedia knowledge base, subjects related to the medical domain. Then, we evaluated their performance with different machine learning algorithms to predict hospitalization when they are injected in the vector representation of EMRs. Deciding the relevancy of given subjects for a specific prediction task appeared to be quite difficult and subjective for human experts, with a high variability in their annotations. To overcome this problem, we integrated an automatic step allowing annotators to confirm their thoughts. We generated different vector representations coupling concepts vectors and bagof-words and then evaluated their performance for prediction with different machine learning algorithms and computed inter-rater reliability metrics for different sets of concepts whether selected by the human or the machine. Our contributions are in the automatic extraction of DBpedia subjects and injection of the latter into EMRs representation, the coupling with a feature selection method to select relevant resources towards hospitalization risks, the selection and evaluation of subjects by both human and machine annotators.</p><p>As future work, we plan to train our own model of DBpedia Spotlight in order to further avoid noise with named entities from other domains. We also intend to investigate different depth levels of subjects, since so far, we only integrated the knowledge on the direct subject, and to deal with the recognition of complex expressions, experiencer and entity negation.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Listing 1 :</head><label>1</label><figDesc>SPARQL query to extract subjects related to the medical domain from DBpedia.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Workflow used to extract candidate subjects from EMR.</figDesc><graphic coords="4,317.96,83.69,240.25,343.56" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Workflow used to generate vector representations integrating ontological knowledge alongside with textual information.</figDesc><graphic coords="5,317.96,85.61,240.22,108.13" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Workflow used to compute inter-rater reliability for both human and machine annotations.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Data collected in the PRIMEGE PACA database.</figDesc><table><row><cell>Category</cell><cell>Data collected</cell></row><row><cell>GPs</cell><cell>Sex, birth year, city, postcode</cell></row><row><cell>Patients</cell><cell>Sex, birth year, city, postcode</cell></row><row><cell></cell><cell>Socio-professional category, occupation</cell></row><row><cell></cell><cell>Number of children, family status</cell></row><row><cell></cell><cell>Long term condition (Y/N)</cell></row><row><cell></cell><cell>Personal history</cell></row><row><cell></cell><cell>Family history</cell></row><row><cell></cell><cell>Risk factors</cell></row><row><cell></cell><cell>Allergies</cell></row><row><cell cols="2">Consultations Date</cell></row><row><cell></cell><cell>Reasons of consultation</cell></row><row><cell></cell><cell>Symptoms related by the patient</cell></row><row><cell></cell><cell>and medical observation</cell></row><row><cell></cell><cell>Further investigations</cell></row><row><cell></cell><cell>Diagnoses</cell></row><row><cell></cell><cell>Drugs prescribed (dose, number of boxes,</cell></row><row><cell></cell><cell>reasons of the prescription)</cell></row><row><cell></cell><cell>Paramedical prescriptions (biology/imaging)</cell></row><row><cell></cell><cell>Medical procedures</cell></row><row><cell cols="2">• Is automatic extraction and selection of knowledge efficient</cell></row><row><cell cols="2">in that context?</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 :</head><label>3</label><figDesc>F tp,f p for the different vector sets considered on the balanced dataset DS B .</figDesc><table><row><cell cols="2">Features set SVC</cell><cell>RF</cell><cell>Loд</cell><cell>Average</cell></row><row><cell>baseline</cell><cell cols="3">0.8270 0.8533 0.8491</cell><cell>0.8431</cell></row><row><cell>α</cell><cell cols="3">0.8214 0.8492 0.8388</cell><cell>0.8365</cell></row><row><cell>β</cell><cell cols="3">0.8262 0.8521 0.8432</cell><cell>0.8405</cell></row><row><cell>γ</cell><cell cols="3">0.8270 0.8467 0.8445</cell><cell>0.8394</cell></row><row><cell>ϵ</cell><cell cols="3">0.8363 0.8547 0.8642</cell><cell>0.8517</cell></row><row><cell>ζ</cell><cell cols="3">0.8384 0.8541 0.8689</cell><cell>0.8538</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4 :</head><label>4</label><figDesc>Confusion matrix of the random forest algorithm (on the left) and the logistic regression (on the right) on the baseline ('H' stands for Hospitalized and 'Not H' for 'Not Hospitalized').</figDesc><table><row><cell></cell><cell cols="2">H Not H</cell><cell></cell><cell cols="2">H Not H</cell></row><row><cell>Predicted</cell><cell></cell><cell></cell><cell>Predicted</cell><cell></cell><cell></cell></row><row><cell>as 'H'</cell><cell>599</cell><cell>91</cell><cell>as 'H'</cell><cell>588</cell><cell>83</cell></row><row><cell>Predicted</cell><cell></cell><cell></cell><cell>Predicted</cell><cell></cell><cell></cell></row><row><cell cols="2">as 'Not H' 115</cell><cell>641</cell><cell cols="2">as 'Not H' 126</cell><cell>649</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 5 :</head><label>5</label><figDesc>Confusion matrix of ζ (on the left) and the union of subjects under ζ conditions (on the right) approaches under the logistic regression algorithm ('H' stands for Hospitalized and 'Not H' for 'Not Hospitalized').</figDesc><table><row><cell></cell><cell cols="2">H Not H</cell><cell></cell><cell cols="2">H Not H</cell></row><row><cell>Predicted</cell><cell></cell><cell></cell><cell>Predicted</cell><cell></cell><cell></cell></row><row><cell>as 'H'</cell><cell>600</cell><cell>67</cell><cell>as 'H'</cell><cell>603</cell><cell>67</cell></row><row><cell>Predicted</cell><cell></cell><cell></cell><cell>Predicted</cell><cell></cell><cell></cell></row><row><cell cols="2">as 'Not H' 114</cell><cell>665</cell><cell cols="2">as 'Not H' 111</cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>DBpedia is a crowd-sourced extraction of structured data from Wikimedia projects http://dbpedia.org</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_1"><p>https://www.w3.org/TR/sparql11-query/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_2"><p>Namespace: http://purl.org/dc/terms/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_3"><p>Namespaces: http://dbpedia.org/ontology/, http://dbpedia.org/class/yago/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_4"><p>http://corese.inria.fr</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>ACKNOWLEDGMENTS</head><p>This work is partly funded by the <rs type="funder">French government labelled</rs> <rs type="programName">PIA program</rs> under its <rs type="projectName">IDEX UCAJEDI</rs> project (<rs type="grantNumber">ANR-15-IDEX-0001</rs>).</p></div>
			</div>
			<listOrg type="funding">
				<org type="funded-project" xml:id="_ZFaqMCX">
					<idno type="grant-number">ANR-15-IDEX-0001</idno>
					<orgName type="project" subtype="full">IDEX UCAJEDI</orgName>
					<orgName type="program" subtype="full">PIA program</orgName>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Inter-coder agreement for computational linguistics</title>
		<author>
			<persName><forename type="first">Ron</forename><surname>Artstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Massimo</forename><surname>Poesio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="555" to="596" />
			<date type="published" when="2008">2008. 2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Random search for hyper-parameter optimization</title>
		<author>
			<persName><forename type="first">James</forename><surname>Bergstra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="281" to="305" />
			<date type="published" when="2012-02">2012. Feb (2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Random forests</title>
		<author>
			<persName><forename type="first">Leo</forename><surname>Breiman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine learning</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="5" to="32" />
			<date type="published" when="2001">2001. 2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">On over-fitting in model selection and subsequent selection bias in performance evaluation</title>
		<author>
			<persName><forename type="first">C</forename><surname>Gavin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicola Lc</forename><surname>Cawley</surname></persName>
		</author>
		<author>
			<persName><surname>Talbot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="2079" to="2107" />
			<date type="published" when="2010-07">2010. Jul (2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">LIBSVM: a library for support vector machines</title>
		<author>
			<persName><forename type="first">Chih-Chung</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chih-Jen</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM transactions on intelligent systems and technology (TIST)</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">27</biblScope>
			<date type="published" when="2011">2011. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">GRAM: graph-based attention model for healthcare representation learning</title>
		<author>
			<persName><surname>Choi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
		<meeting>the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="787" to="795" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">The KGRAM abstract machine for knowledge graph querying</title>
		<author>
			<persName><forename type="first">Olivier</forename><surname>Corby</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Catherine</forename><forename type="middle">Faron</forename><surname>Zucker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Web Intelligence and Intelligent Agent Technology (WI-IAT)</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="338" to="341" />
			<date type="published" when="2010">2010</date>
			<publisher>IEEE</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Improving Efficiency and Accuracy in Multilingual Entity Extraction</title>
		<author>
			<persName><forename type="first">Joachim</forename><surname>Daiber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Max</forename><surname>Jakob</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Hokamp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pablo</forename><forename type="middle">N</forename><surname>Mendes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 9th International Conference on Semantic Systems (I-Semantics)</title>
		<meeting>the 9th International Conference on Semantic Systems (I-Semantics)</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Apples-to-apples in cross-validation studies: pitfalls in classifier performance measurement</title>
		<author>
			<persName><forename type="first">George</forename><surname>Forman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Martin</forename><surname>Scholz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM SIGKDD Explorations Newsletter</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="49" to="57" />
			<date type="published" when="2010">2010. 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">A machine learning approach for identifying disease-treatment relations in short texts</title>
		<author>
			<persName><forename type="first">Oana</forename><surname>Frunza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Diana</forename><surname>Inkpen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Tran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on knowledge and data engineering</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="801" to="814" />
			<date type="published" when="2011">2011. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Injecting Domain Knowledge in Electronic Medical Records to Improve Hospitalization Prediction</title>
		<author>
			<persName><forename type="first">Raphaël</forename><surname>Gazzotti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Catherine</forename><forename type="middle">Faron</forename><surname>Zucker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fabien</forename><surname>Gandon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Virginie</forename><surname>Lacroix-Hugues</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Darmon</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-21348-0_8</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-21348-0_8" />
	</analytic>
	<monogr>
		<title level="m">ESWC 2019 -The 16th Extended Semantic Web Conference</title>
		<title level="s">Lecture Notes in Computer Science)</title>
		<meeting><address><addrLine>Portorož, Slovenia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">11503</biblScope>
			<biblScope unit="page" from="116" to="130" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Are we modeling the task or the annotator? an investigation of annotator bias in natural language understanding datasets</title>
		<author>
			<persName><forename type="first">Mor</forename><surname>Geva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoav</forename><surname>Goldberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Berant</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1908.07898</idno>
		<imprint>
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Opportunities and challenges in developing risk prediction models with electronic health records data: a systematic review</title>
		<author>
			<persName><forename type="first">Ann</forename><forename type="middle">Marie</forename><surname>Benjamin A Goldstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><forename type="middle">J</forename><surname>Navar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Pencina</surname></persName>
		</author>
		<author>
			<persName><surname>Ioannidis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Medical Informatics Association</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="198" to="208" />
			<date type="published" when="2017">2017. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Estimating the reliability, systematic error and random error of interval data</title>
		<author>
			<persName><forename type="first">Klaus</forename><surname>Krippendorff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Educational and Psychological Measurement</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="61" to="70" />
			<date type="published" when="1970">1970. 1970</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Creation of the First French Database in Primary Care Using the ICPC2: Feasibility Study</title>
		<author>
			<persName><forename type="first">David</forename><surname>Lacroix-Hugues</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Darmon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pascal</forename><surname>Pradier</surname></persName>
		</author>
		<author>
			<persName><surname>Staccini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Studies in health technology and informatics</title>
		<imprint>
			<biblScope unit="volume">245</biblScope>
			<biblScope unit="page" from="462" to="466" />
			<date type="published" when="2017">2017. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Generalized linear models</title>
		<author>
			<persName><forename type="first">Peter</forename><surname>Mccullagh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><forename type="middle">A</forename><surname>Nelder</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1989">1989</date>
			<publisher>CRC press</publisher>
			<biblScope unit="volume">37</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Activity recognition using hybrid generative/discriminative models on home environments using binary sensors</title>
		<author>
			<persName><forename type="first">Javier</forename><surname>Fco</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paula</forename><surname>Ordónez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Araceli</forename><surname>De Toledo</surname></persName>
		</author>
		<author>
			<persName><surname>Sanchis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sensors</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="5460" to="5477" />
			<date type="published" when="2013">2013. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Scikit-learn: Machine Learning in Python</title>
		<author>
			<persName><forename type="first">F</forename><surname>Pedregosa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Varoquaux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gramfort</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Michel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Thirion</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Grisel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Blondel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Prettenhofer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Dubourg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Vanderplas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Passos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Cournapeau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Brucher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Perrot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Duchesnay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2825" to="2830" />
			<date type="published" when="2011">2011. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Glove: Global vectors for word representation</title>
		<author>
			<persName><forename type="first">Jeffrey</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP)</title>
		<meeting>the 2014 conference on empirical methods in natural language processing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="1532" to="1543" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Using Ontologies for the Online Recognition of Activities of Daily Living</title>
		<author>
			<persName><forename type="first">Alberto</forename><forename type="middle">G</forename><surname>Salguero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Macarena</forename><surname>Espinilla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pablo</forename><surname>Delatorre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Javier</forename><surname>Medina</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sensors</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">1202</biblScope>
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">SIFR annotator: ontology-based semantic annotation of French biomedical text and clinical notes</title>
		<author>
			<persName><forename type="first">Andon</forename><surname>Tchechmedjiev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amine</forename><surname>Abdaoui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vincent</forename><surname>Emonet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stella</forename><surname>Zevio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Clement</forename><surname>Jonquet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC bioinformatics</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">405</biblScope>
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Regression shrinkage and selection via the lasso</title>
		<author>
			<persName><forename type="first">Robert</forename><surname>Tibshirani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Royal Statistical Society: Series B (Methodological)</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="267" to="288" />
			<date type="published" when="1996">1996. 1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">BioPortal: enhanced functionality via new Web services from the National Center for Biomedical Ontology to access and use ontologies in software applications</title>
		<author>
			<persName><forename type="first">Patricia</forename><forename type="middle">L</forename><surname>Whetzel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Natalya</forename><forename type="middle">F</forename><surname>Noy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Nigam</surname></persName>
		</author>
		<author>
			<persName><surname>Shah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Csongor</forename><surname>Paul R Alexander</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tania</forename><surname>Nyulas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><forename type="middle">A</forename><surname>Tudorache</surname></persName>
		</author>
		<author>
			<persName><surname>Musen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nucleic acids research</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="541" to="W545" />
			<date type="published" when="2011">2011. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
