<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">UniRank: Unimodal Bandit Algorithm for Online Ranking</title>
				<funder ref="#_TJk7wcM">
					<orgName type="full">Inria Project Lab</orgName>
				</funder>
				<funder ref="#_Fzeh7b4">
					<orgName type="full">EU</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Camille-Sovanneary</forename><surname>Gauthier</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Equal contribution Vuitton</orgName>
								<address>
									<addrLine>1 Louis</addrLine>
									<postCode>F-75001</postCode>
									<settlement>Paris</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="laboratory">IRISA UMR 6074</orgName>
								<orgName type="institution">INRIA rba</orgName>
								<address>
									<postCode>F-35000</postCode>
									<settlement>Rennes</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Romaric</forename><surname>Gaudel</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Equal contribution Vuitton</orgName>
								<address>
									<addrLine>1 Louis</addrLine>
									<postCode>F-75001</postCode>
									<settlement>Paris</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Ensai</orgName>
								<orgName type="laboratory">CREST -UMR 9194</orgName>
								<orgName type="institution" key="instit1">Univ Rennes</orgName>
								<orgName type="institution" key="instit2">CNRS</orgName>
								<address>
									<postCode>F-35000</postCode>
									<settlement>Rennes</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Elisa</forename><surname>Fromont</surname></persName>
							<affiliation key="aff1">
								<orgName type="laboratory">IRISA UMR 6074</orgName>
								<orgName type="institution">INRIA rba</orgName>
								<address>
									<postCode>F-35000</postCode>
									<settlement>Rennes</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="institution">Univ. Rennes 1</orgName>
								<address>
									<postCode>F-35000</postCode>
									<settlement>Rennes</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
							<affiliation key="aff4">
								<orgName type="institution">Institut Universitaire de France.E.S.R.I</orgName>
								<address>
									<postCode>F-75231</postCode>
									<settlement>Paris</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Elisa</forename><forename type="middle">Fromont</forename><surname>Unirank</surname></persName>
						</author>
						<title level="a" type="main">UniRank: Unimodal Bandit Algorithm for Online Ranking</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">B1E7C95AD27D5C599113CF2A31F32982</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-04-12T14:44+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We tackle, in the multiple-play bandit setting, the online ranking problem of assigning L items to K predefined positions on a web page in order to maximize the number of user clicks. We propose a generic algorithm, UniRank, that tackles state-of-the-art click models. The regret bound of this algorithm is a direct consequence of the unimodality-like property of the bandit setting with respect to a graph where nodes are ordered sets of indistinguishable items. The main contribution of UniRank is its O (L/∆ log T ) regret for T consecutive assignments, where ∆ relates to the reward-gap between two items. This regret bound is based on the usually implicit condition that two items may not have the same attractiveness. Experiments against state-of-the-art learning algorithms specialized or not for different click models, show that our method has better regret performance than other generic algorithms on real life and synthetic datasets.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>We consider Online Recommendation Systems (ORS) which choose K relevant items among L potential ones (L ≥ K), such as songs, ads or movies to be displayed on a website. The user feedbacks, such as listening time, clicks, rates, etc., reflecting the user's appreciation with respect to each displayed item, are collected after each recommendation. As these feedbacks are only available for the items which were actually presented to the user, this setting corresponds to an instance of the multi-armed bandit problem with semi-bandit feedback <ref type="bibr" target="#b9">(Gai et al., 2012;</ref><ref type="bibr" target="#b1">Chen et al., 2013)</ref>. Besides, some displayed items are not looked at and lead to a negative feedback while they would be appreciated by the user. It raises a specific challenge related to ranking: the attention toward a displayed item is impacted by its position. Numerous approaches have been proposed to handle this partial attention <ref type="bibr" target="#b24">(Radlinski et al., 2008;</ref><ref type="bibr" target="#b5">Combes et al., 2015;</ref><ref type="bibr" target="#b19">Lagrée et al., 2016)</ref> referred to as multiple-play bandit or online learning to rank. Several models of partial attention, a.k.a. click models, are considered in the state of the art <ref type="bibr" target="#b25">(Richardson et al., 2007;</ref><ref type="bibr" target="#b7">Craswell et al., 2008)</ref> and have been transposed to the bandit framework <ref type="bibr">(Kveton et al., 2015a;</ref><ref type="bibr" target="#b16">Komiyama et al., 2017)</ref>. In current paper, in the same line as <ref type="bibr" target="#b28">(Zoghi et al., 2017;</ref><ref type="bibr" target="#b20">Lattimore et al., 2018)</ref> we propose an algorithm which handles multiple state-of-the-art click models.</p><p>The main contribution of our work is a new bandit algorithm, UniRank, dedicated to a generic online learning to rank setting. UniRank takes inspiration from unimodal bandit algorithms <ref type="bibr" target="#b4">(Combes &amp; Proutière, 2014;</ref><ref type="bibr">Gauthier et al., 2021b)</ref>: we implicitly consider a graph G on the partitions of the item-set such that the considered bandit setting is unimodal w.r.t. G, and UniRank chooses each recommendation in the G-neighborhood of an elicited partition. Thanks to this restricted exploration, UniRank is the first algorithm dedicated to a generic setting with a O(L/∆ log T ) regret upper-bound, while previous state-of-the-art algorithms were suffering a O(LK/∆ log T ) regret. Note that this O(L/∆ log T ) upper-bound requires all items' attractiveness to be different, which is a usual assumption satisfied by real world applications. Otherwise, UniRank recovers the O(LK/∆ log T ) bound. From an application point of view, UniRank has several interesting features: it handles multiple state-of-the-art click models altogether; it is simple to implement and efficient in terms of computation time; it does not require the knowledge of the time horizon T ; and it exhibits a smaller empirical regret than other generic algorithms by leaning on the different attractiveness property when this property is satisfied.</p><p>As an indirect contribution, UniRank demonstrates that unimodality is a key tool to analyze the intrinsic complexity of some combinatorial semi-bandit problems. We also demonstrate the flexibility of unimodal bandit algorithms and of the proof of their regret upper-bound. In particular, we extend <ref type="bibr" target="#b4">(Combes &amp; Proutière, 2014)</ref>'s analysis to a graph which is Table <ref type="table">1</ref>. Required click model and upper-bound on cumulative regret for T consecutive recommendations for some well-known recommender algorithms that chose K items among L. The exact definition of ∆ is specific to each algorithm. The symbol * means that Assumption 3.1 * , defined in Section 3.1, is satisfied. κ κ κ denotes the vector of observation-probabilities of PBM, and γ is the degree of the graph explored by the unimodal bandit algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm</head><p>Click model Regret UniRank (our algorithm) CM * O ((L -K)/∆ log T ) PBM * , . . . O (L/∆ log T ) PBM, CM, . . . O (LK/∆ log T ) TopRank <ref type="bibr" target="#b20">(Lattimore et al., 2018)</ref> PBM, CM, . . . O (LK/∆ log T )</p><p>CascadeKL-UCB <ref type="bibr">(Kveton et al., 2015a)</ref> CM O ((L -K)/∆ log T ) GRAB <ref type="bibr">(Gauthier et al., 2021b)</ref> PBM * O (L/∆ log T ) PB-MHB <ref type="bibr">(Gauthier et al., 2021a)</ref> PBM (κ κ κ 1 = 0) unknown PBM-PIE <ref type="bibr" target="#b19">(Lagrée et al., 2016)</ref> PBM (κ κ κ known) O ((L -K)/∆ log T ) SAM <ref type="bibr" target="#b26">(Sentenac et al., 2021)</ref> Matching * O (L log L/∆ log T ) OSUB <ref type="bibr" target="#b4">(Combes &amp; Proutière, 2014)</ref> Unimodal O (γ/∆ log T )</p><p>unimodal in a weaker sense: (i) UniRank takes its decisions given an optimistic index which is not based on the expected reward but on the probability for an item to be more attractive than another one and (ii) some sub-optimal nodes in the graph have no better node in their neighborhood.</p><p>The paper is organized as follows: Section 2 presents the related work and Section 3 defines our target setting. We then introduce UniRank in Section 4, and theoretical guarantees and empirical performance are presented respectively in Section 5 and Section 6. We conclude in Section 7.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>Table <ref type="table">1</ref> shows a comparison of the assumptions and the regret upper-bounds of the most related algorithms.</p><p>Several bandit algorithms are designed to handle the online learning to rank setting while the user follows one of the currently defined click models, namely the position based model (PBM) <ref type="bibr" target="#b15">(Komiyama et al., 2015;</ref><ref type="bibr" target="#b19">Lagrée et al., 2016;</ref><ref type="bibr" target="#b16">Komiyama et al., 2017;</ref><ref type="bibr">Gauthier et al., 2021a;</ref><ref type="bibr">b)</ref> or the cascading model (CM) <ref type="bibr">(Kveton et al., 2015a;</ref><ref type="bibr">b;</ref><ref type="bibr" target="#b5">Combes et al., 2015;</ref><ref type="bibr" target="#b29">Zong et al., 2016;</ref><ref type="bibr" target="#b14">Katariya et al., 2016;</ref><ref type="bibr" target="#b22">Li et al., 2016;</ref><ref type="bibr" target="#b2">Cheung et al., 2019)</ref>. To the best of our knowledge, only the algorithms BatchRank <ref type="bibr" target="#b28">(Zoghi et al., 2017)</ref>, TopRank <ref type="bibr" target="#b20">(Lattimore et al., 2018)</ref>, and BubbleRank <ref type="bibr">(Li et al., 2019a)</ref> handle users following a general model covering both behaviors. These three algorithms exhibit a regret upper-bound for T consecutive recommendations of at least O(LK/∆ log T ), where ∆ depends on the attraction probability θ θ θ of items.</p><p>One ingredient of TopRank and BubbleRank is a statistic to compare two items independently of the position at which they are displayed. The algorithm we propose also makes use of this statistic. However, we define an exploration strategy which does not require the knowledge of the time-horizon T and which induces a O(L/∆ log T ) regret upperbound when items have strictly different attractiveness.</p><p>UniRank also builds upon an extension of the unimodal bandit setting <ref type="bibr" target="#b4">(Combes &amp; Proutière, 2014;</ref><ref type="bibr">Gauthier et al., 2021b)</ref>. This setting assumes the knowledge of a graph G on the set A of bandit arms, such that the expected reward µ a a a associated to each arm a a a satisfies the following assumption:</p><p>Assumption 2.1 (Unimodality<ref type="foot" target="#foot_0">1</ref> ). There exists a unique arm a a a * ∈ A with highest expected reward, and for any arm a a a ∈ A, either (i) a a a = a a a * , or (ii) there exists a a a + in the neighborhood N G (a a a) of a a a given G such that µ a a a + &gt; µ a a a .</p><p>The unimodal bandit algorithms are aware of G, but ignore the weak order induced by the edges of G. However, they rely on G to efficiently browse the arms up to the best one. Typically, the algorithm OSUB <ref type="bibr" target="#b4">(Combes &amp; Proutière, 2014)</ref> selects at each iteration t, an arm a a a(t) in the neighborhood N G (ã a a(t)) given G of the current best arm ã a a(t) (a.k.a. the leader). By restricting the exploration to this neighborhood, the regret suffered by OSUB scales in O(γ/∆ log T ), where γ is the maximum degree of G, to be compared with O(|A|/∆ log T ) if the arms were independent. OSUB is designed for the standard bandit setting and makes use of estimators of the expected reward of arms to select the leader and chose the arm to play. In comparison, UniRank extends OSUB's idea to the semi-bandit setting, relies on a new variant of the unimodality property (see Lemma 5.4), selects the leader and the recommended arm based on other statistics, and does not require the 'forced exploitation' step which consists in recommending the leader each γ-th iteration.</p><p>Finally, <ref type="bibr">(Gauthier et al., 2021b</ref>) also builds upon the unimodality framework to solve a learning to rank problem in the bandit setting. However, the corresponding algorithm (GRAB) is dedicated to the PBM click model. In this model, there is a natural statistic to look at to measure the quality of an item and a position: the probability of click when presenting item i in position k. This statistic is independent of the items at other positions. Within a CM model, such a statistic does not exist. Instead, we refer to a statistic related to the relative attractiveness of items i and j (which we denote ŝi,j ). Secondly, in the PBM model, only weak assumptions are needed to guarantee a unique optimal recommendation, which is required to get the unimodality property. With a CM model, any recommendation including the K best items leads to the optimal reward. To recover the unicity of the best arm, our algorithm is not targeting the best reward, but the best ranking of items (which implies the best reward). However, when facing PBM model, our algorithm requires an assumption which is omitted by GRAB: the position are indexed from the most look-at position to the least one.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Learning to Rank in a Semi-Bandit Setting</head><p>We consider the following online learning to rank (OLR) problem with clicks feedback. For any integer n, let [n] denote the set {1, . . . , n}. A recommendation a a a = (a 1 , . . . , a K ) is a permutation of K distinct items among L, where a k is the item displayed at position k and a a a([K]) := {a k : k ∈ [K]} is the set of all displayed items. We denote P L K the set of such permutations. Throughout the paper, we will use the terms permutation and recommendation interchangeably to denote an element of P L K . An instance of our OLR problem is a tuple (L, K, ρ), where L is the number of available items, K L is the number of positions to display the items, and ρ is a function from P L K × [K] to (0, 1] such that for any recommendation a a a and position k, ρ(a a a, k) is the probability for a user to click on the item displayed at position k when recommending a a a.</p><p>A recommendation algorithm is only aware of L and K and has to deliver T consecutive recommendations. At each iteration t ∈ [T ], the algorithm recommends a permutation a a a(t) and observes the values c a1(t) (t), . . . , c a K (t) (t), where for any position k, c a k (t) (t) equals 1 whenever the user clicks on the item a k (t), and 0 otherwise. To keep notations simple, we also define c i (t) = 0 for each undisplayed item i ∈ [L] \ a a a(t) <ref type="bibr">([K]</ref>). Note that the recommendation at time t is only based on previous recommendations and observations. While the individual clicks are observed, the reward of the algorithm is their sum r(t</p><formula xml:id="formula_0">) := K k=1 c a k (t) (t) = L i=1 c i (t).</formula><p>Let µ a a a denote the expectation of r(t) when the recommendation is a a a(t) = a a a, and µ * := max a a a∈P L K µ a a a the highest expected reward. The aim of the algorithm is to minimize the cumulative regret</p><formula xml:id="formula_1">R(T ) = E T µ * - T t=1 µ a a a(t) ,<label>(1)</label></formula><p>where the expectation is taken w.r.t. the recommendations from the algorithm and the clicks.</p><p>Illustration 3.1 (Click model PBM). With the click model PBM, at each iteration t, the user looks at the position k with probability κ k , independently of the displayed items a a a(t). Moreover, whenever she observes the position k, she clicks on the corresponding item a k (t) with probability θ a k (t) , independently of her other actions. Overall, the clicks c a k (t) (t) are independent and ρ(a a a(t</p><formula xml:id="formula_2">), k) = E c a k (t) (t) = κ k θ a k (t) .</formula><p>Therefore, the optimal recommendation consists in displaying the item i with the -th highest value θ i at the position k with the -th highest value θ k . Hence, if</p><formula xml:id="formula_3">θ 1 &gt; θ 2 &gt; • • • &gt; θ K &gt; max K&lt;k L θ k and κ 1 &gt; κ 2 &gt; • • • &gt; κ K , µ * = K k=1 κ k θ k .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Modeling Assumption</head><p>Up to now, an OLR problem assumes two main properties: (i) a click at a position is a random variable only conditioned by the recommendation and the position, and (ii) the expectation of the corresponding distribution is fixed. We now introduce the three assumptions required by UniRank, which are fulfilled by PBM and CM click models.</p><p>We first assume an order on items. Note that the existence of an order on item is a weak assumption by itself (we may chose any random order). The strength of this assumption derives from Assumptions 3.2 and 3.3 which enforces this order to relate with expected reward.</p><p>Assumption 3.1 (Strict weak order). There exists a preferential attachment function g : [L] → R on items, and for any pair of items (i, j),</p><p>• if g(i) &gt; g(j), item i is said more attractive than item j, which we denote i j;</p><p>• if g(i) = g(j), item i is said equivalent to item j, which we denote i ∼ j.</p><p>Illustration 3.2 (Strict weak order with PBM). With PBM, a typical choice for the function g is g : i → θ i .</p><p>Assumption 3.1 ensures the existence of a strict weak order on items: the items may be ranked by attractiveness, some items being equivalent. A typical example with L = 4 would be 1 2 ∼ 3 4, meaning item 1 is more attractive than any other item, and items 2 and 3 are equivalent and more attractive than item 4. Such situation may also be represented with an ordered partition: ({1}, {2, 3}, {4}), where if the subset E is listed before the subset F , then for any item i ∈ E and any item j ∈ F , i j. In the rest of the paper we will use either the preferential attachment function, or its associated strict weak order, or the corresponding ordered partition depending on the most appropriate representation.</p><p>The strongest results of the theoretical analysis require the slightly stronger assumption which ensures that the K best items are uniquely defined. This assumption is equivalent to any of both hypothesis: (i) the order is total on the K best items and the K-ith item is strictly more attractive than remaining L -K items, and (ii) each of the K first subsets of the ordered partition is composed of only one item.</p><p>Assumption 3.1 * (Strict total order on top-K items). There exists a preferential attachment function g : [L] → R and a permutation a a a</p><formula xml:id="formula_4">∈ P L K s.t. g(a 1 ) &gt; g(a 2 ) &gt; • • • &gt; g(a K ) and for any item j ∈ [L] \ a a a([K]), g(a K ) &gt; g(j).</formula><p>Our next assumption states that recommending the items according to the order associated to the preferential attachment leads to an optimal recommendation. Definition 3.1 (Compatibility with a strict weak order). Let be a strict weak order on items, and a a a be a recommendation. The recommendation a a a is compatible with if 1. for any position k ∈ [K -1], either a k a k+1 or a k ∼ a k+1 ; 2. for any item j ∈ [L] \ a a a([K]), either a K j or a K ∼ j. Assumption 3.2 (Optimal reward). Any recommendation a a a compatible with is optimal, meaning µ a a a = µ * . Illustration 3.3 (Optimal reward with PBM). With PBM, if the positions are ranked by decreasing observation probabilities and g(i) = θ i , this assumption means that the recommendation placing the k-th most attractive item at the k-th most observed position is optimal, which indeed is true. Assumption 3.2 is of utmost importance for UniRank as it means that identifying a partition of the items coherent with is sufficient to ensure optimal recommendations.</p><p>Let us now consider the last assumption which regards the expectation of the random variable c i (t) -c j (t).</p><p>Definition 3.2 (Expected click difference). Let i and j be two items, and a a a a recommendation. The probability of difference and the expected click difference between items i and j w.r.t. the recommendation a a a are respectively:</p><p>δi,j (a a a) = P a a a(t)∼U ({a a a,(i,j)•a a a}) [c i (t) = c j (t)] and ∆i,j (a a a) = E a a a(t)∼U ({a a a,(i,j)•a a a})</p><formula xml:id="formula_5">[c i (t) -c j (t) | c i (t) = c j (t)] ,</formula><p>where (i, j) • a a a is the permutation a a a such that items i and j have been swapped, and U(S) is the uniform distribution on the set S. If only i (respectively j) belongs to a a a, (i, j) • a a a is draw the recommendation a a a(t) uniformly at random in A (P P P (t))</p><p>5:</p><p>observe the clicks vector c c c(t) 6: end for the permutation a a a where item i is replaced by item j (resp. j by i). If neither i nor j belongs to a a a, (i, j) • a a a is a a a.</p><p>Assumption 3.3 (Order identifiability). The strict weak order on items is identifiable, meaning that for any couple of items (i, j) in [L] 2 s.t. i j, and for any recommendation a a a ∈ P L K s.t. at least one of both items is displayed, δi,j (a a a) = 0 and ∆i,j (a a a) &gt; 0 .</p><p>Illustration 3.4 (Expected click difference with PBM). With the click model PBM, if the positions are ranked by decreasing observation probabilities, for any recommendation a a a, any position k ∈ [K] and any position ∈ [L] \ {k}, denoting i and j the items at respective positions k and , δi,j (a a a) = 1 2 (θ i + θ j ) (κ k + κ ) -2θ i θ j κ k κ and ∆i,j (a a a) = θi-θj θi+θj d i,j (a a a), where d i,j (a a a) &gt; 1. Therefore, if g(i) = θ i , Assumption 3.3 is fulfilled.</p><p>The expected click difference reflects the fact that an item leads to more clicks than another independently of the position of both items (other items being unchanged). Hence, Assumption 3.3 points out that when an item is more attractive than another one, it has a higher probability to be clicked upon, all other things being equal. This assumption is natural and ensures that the order on items may be recovered from the expected click difference, which is observed.</p><p>Finally, the following lemma, proven in Appendix D, states that both CM and PBM models fulfill our assumptions.</p><p>Lemma 3.1. Let (L, K, ρ) be an online learning to rank problem with users following CM or PBM model with positions ranked by decreasing observation probabilities. Then Assumptions 3.1, 3.2, and 3.3 are fulfilled. Furthermore, Assumption 3.1 * is fulfilled if, for any top-K item i and any item j in [L] \ {i}, either i j or j i.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">UniRank Algorithm</head><p>Our algorithm, UniRank, is detailed in Algorithm 1, and Figure 1 unfolds one of its iterations. This algorithm takes inspiration from the unimodal bandit algorithm OSUB <ref type="bibr" target="#b4">(Combes &amp; Proutière, 2014</ref>) by selecting at each iteration t an arm to play P P P (t) in the neighborhood of the current best one  <ref type="bibr">)</ref>, where P4 = {6, 7} gathers remaining items as the 3 first partitions contain more than K items. Then, we assume that max( s3,1, s3,2) &gt; max <ref type="bibr">(max( s4,3, s5,3), max( s6,4, s6,5)</ref>, max( s7,4, s7,5), 0). Therefore, UniRank plays the optimistic partition P P P = ({1, 2}, {3, 4, 5}, {6, 7}). Finally the recommendation a a a is obtained by concatenating a random permutation of P1 = {1, 2} with a random permutation of 2 items from P2 = {3, 4, 5}. P P P (t) (a.k.a. the leader). However, UniRank's arms are not recommendations but sets of recommendations represented by ordered partitions. Hence, the recommendation a a a(t) is drawn uniformly at random in the subset A(P P P (t)) of recommendations compatible with P P P (t).</p><p>Let us now first define the notations used by UniRank and then present its concrete behaviour.</p><p>Statistic ŝi,j (t) UniRank's choices are based on the statistic ŝi,j (t) and the optimistic estimator of its expected value: the Kullback-Leibler-based one denoted si,j (t). ŝi,j (t)</p><formula xml:id="formula_6">is the average value of c i (s) -c j (s) for s in [t -1],</formula><p>where we restrict ourselves to iterations at which items i and j are in the same subset of the played partition P P P (s) = P 1 (s), . . . , P d(s) (s) , and</p><formula xml:id="formula_7">c i (s) = c j (s). Specifically, ŝi,j (t) := 1 T i,j (t) t-1 s=1 O i,j (s) (c i (s) -c j (s)) ,</formula><p>where O i,j (s) := 1 ∃c, (i, j) ∈ P c (s) 2 1{c i (s) = c j (s)} denotes that the difference between items i and j is observable at iteration s, T i,j (t) := t-1 s=1 O i,j (s), and ŝi,j (t) := 0 when T i,j (t) = 0. Note that ŝi,j (t) is antisymmetric (ŝ i,j (t) = -ŝ j,i (t)) and ŝi,j (t) &gt; 0 (equivalent to ŝj,i (t) &lt; 0) indicates that i is probably more attractive than j.</p><p>The statistics ŝi,j (t) are paired with their respective opti-</p><formula xml:id="formula_8">mistic indices si,j (t) := 2 * f 1 + ŝi,j (t) 2 , T i,j (t), t P P P (t) (t) -1, where f is a function from [0, 1] × N × N to [0, 1] and f (μ, N, t) := sup{µ ∈ [μ, 1] : N × kl(μ, µ) ≤ log(t) + 3 log(log(t))}, with kl(p, q) := p log p q + (1 -p) log 1-p 1-q</formula><p>the Kullback-Leibler divergence (KL) from a Bernoulli distribution of mean p to a Bernoulli distribution of mean q; f (μ, N, t) := 0 when μ = 1, N = 0, or t = 0; and t P P P (t) (t) is the number of iterations the partition at which P P P has previously been the leader. This optimistic index is the one used for KL-based bandit algorithms, after a rescaling of ŝi,j (t) to the interval [0, 1]. Note that, unlike ŝi,j (t), si,j (t) is not antisymmetric, and sj,i (t) 0 while ŝi,j (t) &gt; 0 indicates that it is unclear whether i is more attractive than j or not.</p><p>Leader Elicitation At each iteration, UniRank first builds a partition P P P (t) = ( P1 (t), . . . , P d(t)) using Algorithm 2 (see. Appendix C). This partition is coherent with ŝi,j (t), meaning that for any couple of items (i, j) in [L] 2 , if ŝi,j (t) &gt; 0 then either i belongs to a subset Pc (t) ranked before the subset of j, or there exists a cycle (i 1 , i 2 , . . . , i N ) such that i 1 = i N = i, i 2 = j, and for any n ∈ [N -1], ŝin,in+1 (t) &gt; 0. We also ensure that the d -1 first subsets of P P P (t) gather at least K items:</p><formula xml:id="formula_9">d-2 c=1 | Pc (t)| &lt; K d-1 c=1 | Pc (t)|.</formula><p>This means that the items in P d(t) are the ones which are never displayed by the recommendations in A( P P P (t)). Note that the subset P d(t) may be empty.</p><p>The partition P P P (t) is built by repeating the process of (i) identifying the smallest subset of items dominating all other items (meaning the items i for which ŝi,j (t) &gt; 0 for any remaining item j), and (ii) removing this subset. A special care is taken to gather in the same subset remaining items as soon as the first subsets contain more than K items.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Optimistic Partition Elicitation</head><p>The partition P P P (t) plays the role of leader, meaning that at each iteration, UniRank solves an exploration-exploitation dilemma and picks either P P P (t) or a permutation P P P (t) in the neighborhood N ( P P P (t)) of P P P (t), where N ( P</p><formula xml:id="formula_10">P P ) := P1, . . . , Pc-1, Pc ∪ Pc+1, Pc+2, . . . P d : c ∈ [ d -2] ∪ P1, . . . , P d-2 , P d-1 ∪ {j}, P d \ {j} : j ∈ P d .</formula><p>This neighborhood results either (i) from the merge of two consecutive subsets Pc (t) and Pc+1 (t) of the partition P P P (t), or (ii) from the addition to P d-1 (t) of an item j from the last subset. For each neighbor P P P of type (i), the optimistic index b P P P (t) is max (i,j)∈ Pc(t)× Pc+1(t) sj,i (t) to reflect whether or not at least one of the items in Pc+1 (t) may potentially be more attractive than one of the items in Pc (t). Similarly, for each neighbor P P P of type (ii), the optimistic index b P P P (t) is max i∈ P d-1 (t) sj,i (t).</p><p>Remark 4.1 (Recommendation chosen at random). Taking a random permutation is required to control the statistic ŝi,j (t). Indeed, the theoretical analysis requires the probability for i to be ranked before j in the recommendation to be even. Overall, the aim is to identify a partition P P P * such that any permutation in A (P P P * ) is compatible with the unknown strict weak order on items.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Theoretical Analysis</head><p>The proof of the upper-bound on the regret of UniRank follows a similar path as the proof of OSUB <ref type="bibr" target="#b4">(Combes &amp; Proutière, 2014</ref>): (i) apply a standard bandit analysis to control the regret under the condition that the leader P P P (t) is an optimal partition, and (ii) upper-bound by O(log log T ) the expected number of iterations such that P P P (t) is not an optimal partition. However, both steps differ from <ref type="bibr" target="#b4">(Combes &amp; Proutière, 2014)</ref>. First, UniRank handles partitions instead of recommendations. Secondly, it builds upon ŝi,j (t) instead of estimators of the expected reward. While ŝi,j (t) is the average of dependent random variables with different expected values, these expected values are greater than some non-negative constant ∆i,j when i j, which is sufficient to lower-bound ŝi,j (t) away from 0 as required by the proof of the regret upper-bound (see Appendices E.1, E.2, and E.3 for details). Finally, the proof is adapted to handle the fact that T i,j (t) randomly increases when we play items i and j due to the exploration-exploitation rule, which is unusual in the bandit literature. Up to our knowledge, this explorationexploitation strategy and its analysis are new in the bandit community. We believe that it opens new perspectives for other semi-bandit settings.</p><p>Note that, as in <ref type="bibr" target="#b26">(Sentenac et al., 2021)</ref> and <ref type="bibr">(Gauthier et al., 2021b)</ref>, we restrict the theoretical analysis to the setting where the order on top-items is total, meaning we use Assumption 3.1 * . Without loss of generality, we also assume that 1 2</p><formula xml:id="formula_11">• • • K [L] \ [K]</formula><p>to shorten the notations. Hence the only partition P P P * which is such that, any permutation a a a in A (P P P * ) is compatible with the unknown strict order on items, is</p><formula xml:id="formula_12">({1}, . . . , {K}, [L] \ [K]).</formula><p>We now propose the main theorem that upper-bounds the regret of UniRank.</p><p>Theorem 5.1 (Upper-bound on the regret of UniRank assuming a total order on top-K items). Let (L, K, ρ) be an OLR problem satisfying Assumptions 3.1 * , 3.2, and 3.3 and such that 1 2</p><formula xml:id="formula_13">• • • K [L] \ [K]. Denoting P P P * = ({1}, . . . , {K}, [L] \ [K]</formula><p>) the optimal partition associated to this order, when facing this problem, UniRank</p><formula xml:id="formula_14">fulfills ∀k ∈ [L] \ {1}, E T t=1 1 P P P (t)=P P P * , ∃c,Pc(t)={min(k-1,K),k} 16 δ * k ∆2 k log T + O (log log T ) (2) and E T t=1 1{ P P P (t) = P P P * } = O (log log T ) ,<label>(3)</label></formula><p>and hence</p><formula xml:id="formula_15">R(T ) L k=2 8∆ k δ * k ∆2 k log T +O (log log T ) = O L ∆ log T ,</formula><p>where for any position k &gt; 1, denoting := min(k -1, K), δ * k := min P P P ∈N (P P P * ):∃c,( ,k)∈P 2 c P a a a(t)∼U (A(</p><formula xml:id="formula_16">P P P )) [c (t) = c k (t)] , ∆k := min a a a∈P L K :{ ,k}∩a a a([K]) =∅ ∆ ,k (a a a), ∆ k := µ (1,...,K) -µ ( ,k)•(1,...,K) , and ∆ := min k∈{2,...,L} δ * k ∆2 k /∆ k .</formula><p>The first upper-bound (Equation ( <ref type="formula">2</ref>)) controls the expected number of iterations at which UniRank explores while the leader is the optimal partition. Both types of exploration are covered: the merging of two consecutive subsets of P P P (t), and the addition of a sub-optimal arm to the last subset of the chosen partition P P P (t). The second upper-bound (Equation (3)) deals with the expected number of iterations at which the leader is not the optimal partition. Let us now express the same bounds while assuming one of the state-of-the-art click models. Corollary 5.2 (Facing CM * ). Under the hypotheses of Theorem 5.1, with the clik-model CM with probability θ i to click on item i when it is observed, UniRank fulfills</p><formula xml:id="formula_17">R(T ) L k=K+1 16 θ K + θ k θ K -θ k log T + O (log log T ) = O (L -K) θ K + θ K+1 θ K -θ K+1 log T .</formula><p>Corollary 5.3 (Facing PBM * ). Under the hypotheses of Theorem 5.1, if the user follows PBM with the probability θ i of clicking on item i when it is observed and the probability κ k of observing the position k, then UniRank fulfills</p><formula xml:id="formula_18">R(T ) = O L ∆ log T ,</formula><p>where</p><formula xml:id="formula_19">∆ := min{ θ K -θ K+1 θ K +θ K+1 , min k∈{2,...,K} ((κ k-1 +κ k )(θ k-1 +θ k )-4κ k-1 κ k θ k-1 θ k )(θ k-1 -θ k ) (κ k-1 -κ k )(θ k-1 +θ k ) 2 }.</formula><p>Note that the regret upper-bound reduces to O((L -K)/∆ log T ) with CM since, with this model, the recommendation is optimal as soon as optimal items are displayed.</p><p>A more detailed version of these corollaries is given in the appendix, together with their proofs and Theorem 5.1's proof. These proofs builds upon the following pseudounimodality property.</p><p>Lemma 5.4 (Pseudo-unimodality assuming a total order on top-K items). Under the hypotheses of Theorem 5.1, for any ordered partition of the items P P P = P1 , . . . , P d = P P P * ,</p><formula xml:id="formula_20">• either ∃c ∈ [ d], such that |P c | &gt; 1 and i * argmax j∈Pc\{i * } g(j)</formula><p>, where i * = argmax i∈Pc g(i);</p><formula xml:id="formula_21">• or ∃c ∈ [ d -1], ∃(i, j) ∈ Pc × Pc+1 , such that j i.</formula><p>The first alternative implies that the subset Pc should be split, which will be discovered by recommending permutations compatible with either P P P or one of its neighbors. The second alternative implies that j should be in a subset ranked before the subset containing i, which will be discovered by recommending the permutation in the neighborhood of P P P which puts i and j in the same subset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Discussion</head><p>We gather here some remarks regarding the optimality of the theoretical results and their extension to a weak order. Remark 5.1 (Optimality of UniRank's upper-bound).</p><p>While deriving the exact lower-bound on the expected regret in this setting is out of the scope of our paper, we believe that this bound takes the form</p><formula xml:id="formula_22">O K k=2 µ * -µ k kl(ν * k ,ν k ) log(T ) + L k=K+1 µ * -µ k kl(ν * k ,ν k ) log(T ) ,</formula><p>where for k ∈ {2, . . . , K} (respectively k ∈ {K + 1, . . . , L}), µ k , ν * k , and ν k result from the best partition and the best random variables to compare item k to item k -1 (resp. to item K).</p><p>In <ref type="bibr" target="#b5">(Combes et al., 2015)</ref> (Propositions 1 and 2) and in <ref type="bibr" target="#b19">(Lagrée et al., 2016)</ref> (Theorem 6) a bound with only the second sum is proven. The first sum is missing as both papers consider more restricting settings where the comparison between items k ∈ {2, . . . , K} and k -1 is free in terms of regret: CM for <ref type="bibr" target="#b5">(Combes et al., 2015)</ref>, and PBM with κ κ κ known for <ref type="bibr" target="#b19">(Lagrée et al., 2016)</ref>.</p><p>We also believe that TopRank's upper-bound on the regret with our additional hypothesis either remains O(KL/∆ log(T )) or reduces to O(L log L/∆ log(T )).<ref type="foot" target="#foot_2">2</ref> Indeed, while UniRank reduces the exploration by only comparing each item k to the item min(k -1, L), in the worst case scenario TopRank compares each item k to each item k ∈ {1, . . . , min(k -1, L)} in order to conclude that k should not be at one of the top-min(k -1, L) positions. Therefore, as in <ref type="bibr" target="#b19">(Lagrée et al., 2016)</ref>, we only explore through local changes in the recommendation. Note that these local changes are also more "user-friendly": as soon as the right leader has been identified, a sub-optimal item is always tried at the bottom of the recommendation, which is less surprising for users than a sub-optimal item displayed as the top recommendation. Remark 5.3 (Upper-bound on the regret of UniRank assuming a weak order on items). If the order on the best items is not total, the proof of Theorem 5.1 may be adapted to get a O (LK/∆ log T ) bound. Indeed, under the strict weak order assumption, there exists a set of optimal partitions, and therefore, any permutation compatible with a neighbor of any of these partitions may be recommended O (1/∆ log T ) times. In the worst case scenario, K items are equivalent and strictly more attractive than the L -K remaining items, and the set of the permutations compatible with a neighbor partition is composed of K(L -K) permutations, which translates into a O (LK/∆ log T ) regret bound. Note that <ref type="bibr" target="#b20">(Lattimore et al., 2018)</ref> proves a Ω (LK/∆ log T ) lowerbound on the regret assuming that the best items have the same attractiveness which means that the upper-bound of UniRank for this specific setting is optimal.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Experiments</head><p>In this section, we compare UniRank to TopRank <ref type="bibr" target="#b20">(Lattimore et al., 2018)</ref>, PB-MHB <ref type="bibr">(Gauthier et al., 2021a)</ref>, GRAB <ref type="bibr">(Gauthier et al., 2021b)</ref>, and CascadeKL-UCB <ref type="bibr">(Kveton et al., 2015a)</ref>. The experiments are conducted on the KDD Cup 2012 track 2 dataset, on the Yandex dataset <ref type="bibr">(Yandex, 2013)</ref>, and on a model with artificial parameters. We use the cumulative regret to evaluate the performance of each algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.">Experimental Settings</head><p>In order to evaluate our algorithm, we design six experiments inspired by the ones conducted in <ref type="bibr" target="#b20">(Lattimore et al., 2018)</ref>. The standard metric used is the expected cumulative regret (see Equation (1)), denoted as regret, which is the sum, over T consecutive recommendations, of the difference between the expected reward of the best answer and of the answer of a given ORS. The best algorithm is the one with the lowest regret. We use two click models for our experiments: the Position Based Model (PBM) and the Cascading Model (CM). To play according to those models, we extract the parameters of the chosen model from the KDD Cup 2012 track 2 (KDD for short) database and the Yandex database (Yandex, 2013), and we experiment with a set of parameters (denoted Simul) chosen to highlight the O (L/∆ log T ) regret of UniRank: L = 10, K = 5, θ θ θ = [0.1, 0.08, 0.06, 0.04, 0.02, 10 -4 , 10 -4 , 10 -4 , 10 -4 , 10 -4 ], and κ κ κ = [1, 0.9, 0.83, 0.78, 0.75].</p><p>Yandex database comes from fully anonymized real-life logs of actions toward the Yandex search engine. It contains 703 million items displayed among 65 million search queries and sharing 167 million hits (clicks). We consider the 10 most frequent queries in our experiments. We use the GPL3 Pyclick library <ref type="bibr" target="#b3">(Chuklin et al., 2015)</ref> to infer the CM and PBM parameters of each query with the expectation maximization algorithm. Depending on the query, this leads to θ i values ranging from 0.51 to 0.94, and κ i values ranging from 0.71 to 1.00 when considering PBM and θ i values ranging from 0.03 to 0.50 for CM.</p><p>We also extract parameters from the KDD dataset. Due to the type of data contained in this dataset, we can only extract parameters for the PBM model. This dataset consists of session logs of soso.com, a Tencent's search engine. It tracks clicks and displays of advertisements on a search engine result web-page, w.r.t. the user query. For each query, 3 positions are available for a various number of ads to display. Each of the 150M lines contains information about the search (UserId, QueryId. . . ) and the ads displayed (AdId, Position, Click, Impression). We are looking for the best ads per query, namely the ones with a higher probability to be clicked. To follow previous works, instead of looking for the probability to be clicked per display, we target the probability to be clicked per session. This amounts to discarding the information Impression. We also filter the logs to restrict the analysis to (query, ad) couples with enough information: for each query, ads are excluded if they were displayed less than 1,000 times at any of the 3 possible positions. Then, we filter queries that have less than 5 ads satisfying the previous condition. We end up with 8 queries and from 5 to 11 ads per query. The overall process leads to θ i values ranging from 0.004 to 0.149, and κ k values ranging from 0.10 to 1.00, depending on the query.</p><p>Then we simulate the users' interactions given these parameters as it is commonly done in bandits settings. Similarly to <ref type="bibr" target="#b20">(Lattimore et al., 2018)</ref>, we look at the results averaged on the queries, while displaying K items among the L most attractive ones selected among all items possible for each query. With Yandex dataset, K = 5 and L = 10, while with KDD dataset K = 3 and L varies from 5 to 11. We run our experiments on an internal cluster to compute 20 independent sets of 10 7 consecutive recommendations for each of the 10 most frequent Yandex queries and each of the 8 KDD queries. It leads respectively to 200 games per set- </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm</head><p>Computation Time (ms) UniRank 1.0 ± 0.2 TopRank 0.7 ± 0.3 PB-MHB 13.9 ± 4.9 GRAB 0.9 ± 0.3 CascadeKL-UCB 0.9 ± 0.0 ting and algorithm for Yandex and 160 games for KDD. As TopRank requires the knowledge of the horizon T , we test the impact of this parameter by setting it to the right value (10 7 ), to a too high value (10 12 ), and to a too small value (10 5 ) with doubling trick. To tune PB-MHB, we use the values recommended by <ref type="bibr">(Gauthier et al., 2021a</ref>) for these datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.">Results</head><p>Our results are shown in Figure <ref type="figure" target="#fig_0">2</ref>. As expected, CascadeKL-UCB (respectively PB-MHB) outperforms other algorithms in the CM (resp. PBM) model for which it is designed. However, PB-MHB is computationally expensive (see Table <ref type="table" target="#tab_2">2</ref>) and lacks a theoretical analysis. Surprisingly, although GRAB is designed for PBM model, it suffers a high regret when confronted to the query 8107157 of Yandex and to Simul with PBM model.</p><p>Secondly, UniRank and TopRank enjoy a logarithmic regret in all settings and our algorithm UniRank outperforms TopRank for the models such that the K best items do not have the same attractiveness θ i : query 8107157 of Yandex, simul PBM, and simul CM. When confronted to other models, UniRank has a regret strictly smaller than TopRank before the iteration t = 10 6 , and smaller or equal to TopRank at the horizon. Moreover, as already explained, TopRank is aware of the horizon T and may stop (over)exploring early, as can be observed in the CM model after iteration 10 5 . If TopRank targets a horizon T = 10 12 or uses the doubling trick it suffers a higher regret than UniRank.</p><p>Regarding the computational complexity, as shown in Table 2, PB-MHB is significantly slower with a computation time per recommendation ten times higher than any other algorithm. These other algorithms have a similar computation time of approximately 1 ms per recommendation.</p><p>Overall, as TopRank, UniRank is consistent over all settings, and require a reasonable computation time. Moreover, contrary to TopRank, (i) UniRank drastically decreases its regret by taking advantage of the differences of attractiveness between items, and (ii) UniRank does not require the knowledge of the horizon T .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Conclusion</head><p>We have presented UniRank, a unimodal bandit algorithm for online ranking. The regret bound in O (L/∆ log T ) of our algorithm, is a direct consequence of the unimodalitylike property of the bandit setting with respect to a graph where nodes are ordered partitions of items. Even though the proof is inspired by OSUB <ref type="bibr" target="#b4">(Combes &amp; Proutière, 2014)</ref>, the fact that UniRank handles partitions instead of recommendations, uses different estimators and builds upon an unusual exploration-exploitation strategy makes it original, and we believe that our theoretical analysis opens new perspectives for other semi-bandit settings. Experiments against state-of-the-art learning algorithms show that our method is consistent in all settings, enjoys a smaller regret than TopRank and GRAB on specific settings, and has a much smaller computation time than PB-MHB.</p><p>While in industrial applications, contextual information is also used to build recommendations <ref type="bibr">(Li et al., 2019b;</ref><ref type="bibr" target="#b0">Chen et al., 2019;</ref><ref type="bibr" target="#b8">Ermis et al., 2020;</ref><ref type="bibr" target="#b10">Gampa &amp; Fujita, 2021)</ref>, in this paper we restricted ourselves to independent arms to simplify the presentation of the approach. However, the integration of unimodal bandit algorithms working on parametric spaces <ref type="bibr" target="#b6">(Combes et al., 2020)</ref> should bridge the gap between both approaches.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Ethical Statement</head><p>Regarding the societal impact of the proposed approach, it is worth mentioning that the approach aims at identifying and recommending the most popular items. Therefore, the approach may increase the monopoly effects: the most attractive items are displayed more often, so their reputation increases, and then they may become even more attractive. . . However bandit algorithms continuously explore and therefore continuously offer an opportunity to less popular items to increase their reputation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Organisation of the Appendix</head><p>The appendix is organized as follows. After listing most of the notations used in the paper in Appendix B, we prove Lemma 3.1 in Appendix D. Then we prove some technical lemmas in Appendix E, which are required by the proof of Theorem 5.1 in Appendix F. Finally, we discuss the regret upper-bound of UniRank for some specific settings in Appendix G.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Notations</head><p>Table <ref type="table" target="#tab_5">4</ref> summarizes the notations used throughout the paper and the appendix. Below are additional notations necessary for the proofs. Definition B.1 (Specific notations to count events and observations). The proofs are based on the concentration of the statistic ŝi,j (t) which is the average over T i,j (t) observations. The number T i,j (t) itself is a sum: the sum of the random variables 1{c i (s) = c j (s)} | ∃c, (i, j) ∈ P c (s) 2 , where s is in [t]. To discuss the concentration of this sum, for any iteration t in [T ], we denote t i,j (t) := t-1 s=1 1 ∃c, (i, j) ∈ P c (s) 2 the number of iterations at which the random variable is observed. Definition B.2 (Recommended subset). Let (L, K, ρ) be an online learning to rank problem, P P P be an ordered partition of [L] in d subsets, and c ∈ [d] the index of one of these subsets. The subset P c is recommended (denoted Rec(P c )) if the recommendations compatible with P P P include some items from P c . More specifically, the subset</p><formula xml:id="formula_23">P c is recommended if | ∈[c-1] P | &lt; K. Definition B.</formula><p>3 (Expectations on clicks). let i and j be two different items.</p><p>We denote δi,j := min P P P :∃c,(i,j)∈P 2 c ∧Rec(Pc)</p><p>P a a a(t)∼U (A(P</p><formula xml:id="formula_24">P P )) [c i (t) = c j (t)]</formula><p>the smallest probability for c i (t) to be different from c j (t) while both items are in the same subset of the chosen partition P P P (t) (and may potentially be clicked upon). If we assume 1 2 • • • L, we also denote δ * i := min P P P ∈N (({1},...,{K},{K+1,...,L})):∃c,(min(i-1,K),i)∈P 2 c P a a a(t)∼U (A(P</p><formula xml:id="formula_25">P P )) c min(i-1,K) (t) = c i (t)</formula><p>the smallest probability for c min(i-1,K) (t) to be different from c i (t) while both items min(i -1, K) and i are in the same subset of the chosen partition P P P (t) (and may potentially be clicked upon), and P P P (t) is in the neighborhood of the optimal partition P P P * = ({1}, . . . , {K}, {K + 1, . . . , L}).</p><p>If i j, we denote ∆i,j := min</p><formula xml:id="formula_26">P P P :∃c,(i,j)∈P 2 c ∧Rec(Pc)</formula><p>E a a a(t)∼U (A(P</p><formula xml:id="formula_27">P P )) [c i (t) -c j (t) | c i (t) = c j (t)] = min a a a∈P L K :{i,j}∩a a a([K]) =∅ ∆i,j (a a a),</formula><p>the smallest expected difference of clicks between items i and j while both items are in the same subset of the chosen partition P P P (t) (and may potentially be clicked upon).</p><p>Symmetrically, if j i, we denote ∆i,j := max</p><formula xml:id="formula_28">P P P :∃c,(i,j)∈P 2 c ∧Rec(Pc) E a a a(t)∼U (A(P P P )) [c i (t) -c j (t) | c i (t) = c j (t)] = max a a a∈P L K :{i,j}∩a a a([K]) =∅ ∆i,j (a a a),</formula><p>the greatest expected difference of clicks between items i and j while both items are in the same subset of the chosen partition P P P (t) (and may potentially be clicked upon).</p><p>Lemma E.1 in Appendix E.1 ensures the proper definition of these notations under Assumptions 3.1, 3.2, and 3.3, and states that δi,j = δj,i &gt; 0 and ∆i,j = -∆j,i &gt; 0 if i j. Definition B.4 (Reward gap). Let (L, K, ρ) be an OLR problem satisfying Assumption 3.2 and such that the order on items is a total order. Without loss of generality, let us assume that 1 2 • • • L.. Denoting P P P * = ({1}, . . . , {K}, {K + 1, . . . , L}) the optimal partition associated to this order and taking c 2, the reward gap of item c is PROBABILITY OF DIFFERENCE, δi,j (a a a) = P a a a ∼U ({a a a,(i,j)•a a a})</p><formula xml:id="formula_29">∆ c := ρ (a a a * , min(c -1, K)) + ρ (a a a * , c) -ρ ((min(c -1, K), c) • a a a * , min(c -1, K)) -ρ ((min(c -1, K), c) • a a a * , c)</formula><formula xml:id="formula_30">[ci = cj ] ∆i,j (a a a) EXPECTED CLICK DIFFERENCE, ∆i,j (a a a) = E a a a ∼U ({a a a,(i,j)•a a a}) [ci -cj | ci = cj ] ŝi,j (t) UNIRANK'S MAIN STATISTIC TO INFER THAT i j, ŝi,j (t) := 1 T i,j (t) t-1 s=1 1 ∃c, (i, j) ∈ Pc(s) 2 (ci(s) -cj (s)) sj,i(t) KULLBACK-LEIBLER BASED OPTIMISTIC ESTIMATOR, sj,i(t) := 2 * f 1+ŝ i,j (t) 2</formula><p>, Ti,j (t), t P  Algorithm 2 Elicitation of the leader partition P P P (t)</p><formula xml:id="formula_31">P P (t) -1 f KULLBACK-LEIBLER INDEX FUNCTION, f (μ, T, t) := inf{µ ∈ [0, μ] : T × kl(μ, µ) ≤ log(t) + 3 log(log(t))}, kl(p, q) KULLBACK-LEIBLER DIVERGENCE FROM A BERNOULLI DISTRIBUTION OF MEAN p TO A BERNOULLI DISTRIBUTION OF MEAN q, kl(p, q) = p log p q + (1 -p) log 1-p 1-q U (S)</formula><p>Require: number of items L, number of positions K, iteration index t, statistics ŝi,j (t)</p><formula xml:id="formula_32">1: d ← 1; R ← [L]; n ← L 2: repeat 3: for each i ∈ R, S i ← | {j ∈ R : ŝi,j (t) &gt; 0} | 4: sort items in R by S i : S i1 &gt; S i2 &gt; • • • &gt; S in 5: ← min ∈ [n] : ∀k &lt; , ∀k : ŝi k ,i k (t) &gt; 0 6: B ← {i 1 , . . . , i -1 }; P d(t) ← B 7: d ← d + 1; R ← R \ B; n ← |R| 8: until d c=1 Pc (t) K 9: d ← d + 1 ; P d(t) ← R 10: return P P P (t) Note that for c K, ∆ c := ρ(a a a * , c -1) + ρ(a a a * , c) -ρ((c -1, c) • a a a * , c -1) -ρ((c -1, c) • a a a * , c), and for c K + 1, ∆ c = ρ(a a a * , K) -ρ((K, c) • a a a * , K).</formula><p>C. Algorithm for the Elicitation of the leader partition P P P (t)</p><p>D. Proof of Lemma 3.1 (PBM and CM Fulfills Assumptions 3.1, 3.2, and 3.3)</p><p>For both CM and PBM click models, we note θ i the click probability of item i. For PBM we have κ k the probability that a user see the position k.</p><p>Proof. Let us begin with some preliminary remarks.</p><p>First, with PBM model, the positions are ranked by decreasing observation probability, meaning that</p><formula xml:id="formula_33">κ a1 κ a2 • • • κ a K .</formula><p>Secondly, by definition, ρ(k, a a a) &gt; 0 for any position k and recommendation a a a, which implies that:</p><p>• min i θ i &gt; 0 and max i θ i &lt; 1 in CM model;</p><formula xml:id="formula_34">• κ K &gt; 0 in PBM model.</formula><p>Let us now prove that Assumptions 3.1, 3.2 and 3.3 are fulfilled by PBM and CM click models with the strict weak order defined by i j ⇐⇒ θ i &gt; θ j .</p><p>By definition of , Assumption 3.1 is fulfilled taking the the preferential attachment function g : i → θ i , and Assumption 3.1 * is fulfilled as soon as θ i = θ j for any item i in top-K items and any item j = i.</p><p>For Assumption 3.2, we have to prove that having a a a compatible with is optimal, meaning µ a a a = µ * .</p><p>Let a a a be a permutation compatible with .</p><p>In the case of CM, µ a a a = 1</p><formula xml:id="formula_35">- K k=1 (1 -θ a k ).</formula><p>In order to maximize µ a a a , one has to select the K higher values of θ θ θ. As a a a is compatible with , which is defined based on values θ i , it satisfies this property. Hence, CM fulfills Assumption 3.2.</p><formula xml:id="formula_36">For PBM, µ a a a = K k=1 θ a k κ k . As the series (κ k ) k∈[K] is non-increasing, µ a a a is maximized if (θ k ) k∈[K]</formula><p>is also nonincreasing and if θ K max k K+1 θ k . These properties are ensured by the fact that a a a is compatible with and that is defined based on values θ i . Hence, PBM fulfills Assumption 3.2.</p><p>We now prove that CM and PBM fulfill Assumption 3.3. Let i and j be two distinct items such that i j and a a a ∈ P L K be a recommendation such that at least one of both items is displayed.</p><p>First, E a a a ∼U ({a a a,(i,j)•a a a}) [c i (t) = c j (t) | a a a(t) = a a a ] is non-null with PBM model as c i (t) and c j (t) are independent and as at least one of the four variables c i (t) | a a a(t) = a a a, c i (t) | a a a(t) = (i, j) • a a a, c j (t) | a a a(t) = a a a, c j (t) | a a a(t) = (i, j) • a a a has an expectation which is non-zero and strictly smaller than 1 (due to κ K &gt; 0 and θ i &gt; θ j ).</p><p>Similarly, E a a a ∼U ({a a a,(i,j)•a a a}) [c i (t) = c j (t) | a a a(t) = a a a ] is non-null with CM model as at most one of both items can be clicked at each iteration and the shown item has non-zero probability to be clicked (by definition of ρ).</p><p>Then, we consider ∆i,j (a a a) as ∆i,j (a a a) = P a a a ∼U ({a a a,(i,j)•a a a}) (c i = 1, c j = 0) -P a a a ∼U ({a a a,(i,j)•a a a}) (c i = 0, c j = 1) P a a a ∼U ({a a a,(i,j)•a a a}) (c i = 1, c j = 0) + P a a a ∼U ({a a a,(i,j)•a a a}) (c i = 0, c j = 1)</p><p>We want to control the sign of ∆i,j (a a a), which is also the sign of its numerator, as its denominator (noted D ∆i,j (a a a) ) is non-negative.</p><p>The recommendation a a a is drawn uniformly in {a a a, (i, j) • a a a} thus P a a a ∼U ({a a a,(i,j)•a a a})</p><formula xml:id="formula_37">(c i = 1, c j = 0) = 1 2 P a a a (c i = 1, c j = 0) + 1 2 P (i,j)•a a a (c i = 1, c j = 0).</formula><p>When considering a CM click model, we have P a a a (c i = 1,</p><formula xml:id="formula_38">c j = 0) = k-1 p=1 (1 -θ ap )θ i and P a a a (c i = 0, c j = 1) = l-1</formula><p>p=1 (1 -θ ap )θ j when i and j ∈ a a a. In that case, we have:</p><formula xml:id="formula_39">∆i,j (a a a) = 1 2 k-1 p=1 (1 -θ ap )θ i + 1 2 l-1 p=1 (1 -θ ap )θ i -1 2 l-1 p=1 (1 -θ ap )θ j + 1 2 k-1 p=1 (1 -θ ap )θ j D ∆i,j (a a a)</formula><p>which can be simplified in:</p><formula xml:id="formula_40">∆i,j (a a a) = 1 2 k-1 p=1 (1 -θ ap ) + l-1 p=1 (1 -θ ap ) (θ i -θ j ) D ∆i,j (a a a)</formula><p>.</p><formula xml:id="formula_41">Since max i θ i &lt; 1, k-1 p=1 (1 -θ ap ) + l-1</formula><p>p=1 (1 -θ ap ) &gt; 0, thus the sign of ∆i,j (a a a) is the sign of (θ i -θ j ) and ∆i,j (a a a) &gt; 0 ⇐⇒ θ i &gt; θ j ⇐⇒ i j.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Now if i /</head><p>∈ a a a then P a a a (c i = 1, c j = 0) = 0 as the position is not seen. We have:</p><formula xml:id="formula_42">∆i,j (a a a) = 1 2 ( l-1 p=1 (1 -θ ap ))(θ i -θ j ) D ∆i,j (a a a)</formula><p>which leads to the same conclusion as the previous case. By symmetry, we have the same conclusion with j / ∈ a a a.</p><p>Now with a PBM click model, we have P a a a (c i = 1, c j = 0) = κ k θ i (1 -κ l θ j ) as c i = 1 and c j = 0 are independant events.</p><p>Thus, we have:</p><formula xml:id="formula_43">∆i,j (a a a) = 1 2 κ k θ i (1 -κ l θ j ) + 1 2 κ l θ i (1 -κ k θ j ) -1 2 κ l θ j (1 -κ k θ i ) + 1 2 κ k θ j (1 -κ l θ i ) D ∆i,j (a a a)</formula><p>which can be simplified in:</p><formula xml:id="formula_44">∆i,j (a a a) = 1 2 (κ k + κ l )(θ i -θ j ) D ∆i,j (a a a)</formula><p>As κ k or κ l is positive if i or j is presented, similarly to the CM case we have ∆i,j (a a a) &gt; 0 ⇐⇒ θ i &gt; θ j ⇐⇒ i j.</p><p>This proof can be extended to i or j / ∈ a a a by taking κ k = 0 when k &gt; K.</p><p>We can conclude that both CM and PBM fulfills Assumption 3.3.</p><p>E. Technical Lemmas Required by the Proof of Theorem 5.1</p><p>In this section, we gather technical Lemmas required to prove the regret upper-bound of UniRank. These lemmas regard the concentration away from zero of the statistic ŝi,j (t) (Appendices E.1 and E.2), and the sufficient optimism brought by sj,i (t) (Appendix E.3).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E.1. Minimum Expected Click Difference</head><p>Assumption 3.3 builds upon ∆i,j (a a a) which measures the difference of attractiveness between i and j while all other items are at fixed positions. In the theoretical analysis of UniRank, we handle situations where other items may also change in position thanks to the following Lemma.</p><p>Lemma E.1 (Minimum expected click difference). Let (L, K, ρ) be an OLR problem satisfying Assumptions 3.2 and 3.3 with the order on items, and let i and j be two items such that i j. Then, for any partition of items P P P , if there exists c such that (i, j) ∈ P 2 c and E a a a(t)∼U (A(</p><formula xml:id="formula_45">P P P )) [c i (t) = c j (t)] = 0, then E a a a(t)∼U (A(P P P )) [c i (t) -c j (t) | c i (t) = c j (t)</formula><p>] &gt; 0 and therefore δi,j &gt; 0 and ∆i,j &gt; 0.</p><p>Symmetrically, if j i, for any partition of items P P P , if there exists c such that (i, j) ∈ P 2 c and E a a a(t)∼U (A(P</p><formula xml:id="formula_46">P P )) [c i (t) = c j (t)] = 0, then E a a a(t)∼U (A(P P P )) [c i (t) -c j (t) | c i (t) = c j (t)] &lt; 0 and therefore δi,j &gt; 0 and ∆i,j &lt; 0.</formula><p>Proof. The proof consists in writing E a a a(t)∼U (A(P P P )) [c i (t) = c j (t)] = 0 two times as a sum other a a a(t) ∈ U(A (P P P )), and in reindexing one of both sums by (i, j) • a a a(t) ∈ U(A (P P P )). Then, adding the terms of both sums we get a sum of terms ∆i,j (a a a) which by assumption 3.3 are positive. Hence this sum is positive, which concludes the proof.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E.2. Upper-bound on the Number of High Deviations for Variables with Lower-Bounded Mean</head><p>The Proof of Theorem 5.1 requires the control of the expected number of high deviations of the statistic ŝi,j (t). We control this expectation through Lemma E.4 which derives from the application of Lemmas E.2 and E.3 to ŝi,j (t) and Ti,j (t).</p><p>Hereafter, we express and prove the three lemmas. Note that Lemmas E.2 and E.3 are extensions of Lemmas 4.3 and B.1 of <ref type="bibr" target="#b4">(Combes &amp; Proutière, 2014)</ref> to a setting where the handled statistic is a mixture of variables following different laws of bounded expectation.</p><p>Lemma E.2 (Concentration bound with lower-bounded mean). Let (X a t ) t 1 with a ∈ R, be |R| &lt; ∞ independent sequences of independent random variables bounded in [0, B] defined on a probability space (Ω, F, P). Let F t be an increasing sequence of σ-fields of F such that for each t, σ((X a 1 ) a∈R , . . . , (X a t ) a∈R ) ⊂ F t and for s &gt; t and a a recommendation, X a s is independent from F t . Consider |R| previsible sequences ( a t ) t≥1 of Bernoulli variables (for all t &gt; 0, a t is F t-1 -mesurable) such that for all t &gt; 0, i a t ∈ {0, 1}. Let δ &gt; 0 and for every t ∈ {1, . . . , n} let</p><formula xml:id="formula_47">S(t) = t s=1 i i s (X i s -E[X i s ]), T (t) = t s=1 i i s , μ(t) = S(t) N (t) .</formula><p>Define φ ∈ {t 0 , . . . , T + 1} a F-stopping time such that either T (φ) s or φ = T + 1.</p><p>Then</p><formula xml:id="formula_48">P (S(φ) T (φ)δ, φ T ) exp(- 2nδ 2 B 2 ).</formula><p>Proof. Let λ &gt; 0, and define G t = exp(λ(S(t) -δT (t)))1{t T }. We have that:</p><formula xml:id="formula_49">P(S(φ) T (φ)δ, φ T ) = P(exp(λ(S(φ) -δT (φ))1{φ T } 1) = P(g φ 1) E[G φ ].</formula><p>Next we provide an upper bound for E[G φ ]. We define the following quantities:</p><formula xml:id="formula_50">Y i s = ε i s (λ(X i s -E[X i s ]) -λ 2 B 2 /8) Gt = exp t s=1 i Y i s 1{t T }.</formula><p>Taking λ = 4δ/B 2 , G t can be written:</p><formula xml:id="formula_51">G t = Gt exp(-T (t)(λδ -λ 2 B 2 /8) = Gt exp(-2T (t)δ 2 /B 2 ).</formula><p>As T (t) n if φ T we can upper bound G φ by:</p><formula xml:id="formula_52">G φ = Gφ exp(-2T (φ)δ 2 /B 2 ) Gφ exp(-2nδ 2 /B 2 ).</formula><p>It is noted that the above inequality holds even when φ = T + 1, since G T +1 = GT +1 = 0. Hence:</p><formula xml:id="formula_53">E[G φ ] E[ Gφ ] exp(-2nδ 2 /B 2 )</formula><p>We prove that Gt t is a super-martingale. We have that</p><formula xml:id="formula_54">E[ GT +1 | F T ] = 0 GT . For s T -1, since B t+1 is F measurable: E[ Gt+1 | F t ] = Gt ((1 - i ε i t+1 ) + i ε i t+1 E[exp(Y i t+1 )]).</formula><p>As proven in <ref type="bibr">(Hoeffding, 1963)[eq. 4.16</ref>] since X i t+1 ∈ [0, B]:</p><formula xml:id="formula_55">E[exp(λ(X i t+1 -E[X i t+1 ])] exp(λ 2 B 2 /8), so E[exp(Y i t+1 )] 1 and Gt t is a super-martingale: E[ Gt+1 | F t ]</formula><p>Gt . Since φ T + 1 almost surely, and Gt t is a supermartingale, Doob's optional stopping theorem yields: E[ Gφ ] E[ G0 ] = 1, and so</p><formula xml:id="formula_56">P(S(φ) T (φ)δ, φ T ) E[G φ ] E[ Gφ ] exp(-2nδ 2 /B 2 ) exp(-2nδ 2 /B 2 ),</formula><p>which concludes the proof Lemma E.3 (Expected number of large deviation with lower-bounded mean). Let (L, K, ρ) be an OLR problem, F t the natural σ-algebra generated by the OLR problem, and F = (F t ) t∈Z the corresponding filtration. We denote O t := (a a a(1), c c c(1), . . . , a a a(t -1), c c c(t -1)) the set of random values observed up to time t -1. Let Z t ∈ [0, B] and B t ∈ {0, 1} be two F t-1 -measurable random variables, Λ ⊆ N be a random set of instants, and ε &gt; 0. For any t ∈ Z, we denote</p><formula xml:id="formula_57">S(t) := t s=0 B s Z s and T (t) := t s=0 B s . If for any t &gt; 0, E [Z t | O t , B t = 1]</formula><p>δ and there exists a sequence of random sets (Λ(n)) n&gt;0 such that (i) Λ ⊆ n&gt;0 Λ(n), (ii) for all n &gt; 0 and all t ∈ Λ(n), T (t) εn, (iii) |Λ(n)| 1, and (iv) the event t</p><formula xml:id="formula_58">∈ Λ(n) is F-measurable. Then E   t≥1 1{t ∈ Λ : S(t) &lt; δ 2 T (t)}   ≤ 2B 2 δ 2 Proof. Let T ∈ N. For all n ∈ N, |Λ(n)| 1, we define Φ n as T + 1 if Λ(n) ∩ [T ] is empty and {Φ n } = Λ(n) otherwise. Since Λ ⊆ n&gt;0 Λ(n), we have T t=1 1 t ∈ Λ : S(t) &lt; δ 2 T (t) n 1 1 S(Φ n ) &lt; δ 2 T (Φ n ), Φ n T .</formula><p>Taking expectations,</p><formula xml:id="formula_59">E T t=1 1 t ∈ Λ : S(t) &lt; δ 2 T (t) n 1 P S(Φ n ) &lt; δ 2 T (Φ n ), Φ n T For any t ∈ N, denote S (t) := t s=0 B s (Z s -E [Z s | 0 s , B s = 1]). As for any s ∈ N, E [Z s | 0 s , B s = 1] &gt; δ, S (t) &lt; S(t) -T (t)δ. Therefore, for any n ∈ N P S(Φ n ) &lt; δ 2 T (Φ n ), Φ n T P S (Φ n ) &lt; - δ 2 T (Φ n ), Φ n T and E T t=1 1 t ∈ Λ : S(t) &lt; δ 2 T (t) n 1 P S (Φ n ) &lt; - δ 2 T (Φ n ), Φ n T</formula><p>By Lemma E.2, since Φ n is a stopping time upper bounded by T + 1, and T (Φ n ) εn,</p><formula xml:id="formula_60">E T t=1 1 t ∈ Λ : S(t) &lt; δ 2 T (t) n 1 exp - εnδ 2 2B 2 2B 2 εδ 2 ,</formula><p>where the last inequality drives from the n 1 exp (-nw)</p><p>+∞ 0 exp (-uw) du = 1 w . This upper-bound is valid for any T , which concludes the proof.</p><p>Lemma E.4 (Expected number of large deviation for our statistics). Let (L, K, ρ) be an OLR problem satisfying Assumptions 3.2 and 3.3 with the order on items, and let i and j be two items. If there exists a sequence of random sets (Λ(n)) n&gt;0 such that (i) Λ ⊆ n&gt;0 Λ(n), (ii) for all n &gt; 0 and all t ∈ Λ(n), t i,j (t + 1) εn, (iii) |Λ(n)| 1, and (iv) the event</p><formula xml:id="formula_61">t ∈ Λ(n) is F-measurable. Then, E   t≥1 1 t ∈ Λ, T i,j (t) &lt; δi,j 2 t i,j (t)   = O(1)<label>(4)</label></formula><p>and</p><formula xml:id="formula_62">E   t≥1 1 t ∈ Λ, ŝi,j (t) ∆i,j &lt; 1 2   = O(1), meaning E   t≥1 1 t ∈ Λ, ŝi,j (t) &lt; ∆i,j 2   = O(1)</formula><p>, if i j;</p><p>(5)</p><formula xml:id="formula_63">E   t≥1 1 t ∈ Λ, ŝi,j (t) &gt; ∆i,j 2   = O(1) , if j i.<label>(6)</label></formula><p>Proof. Let assume i j. We first prove Claim (4) and then prove Claim (5) using Claim (4).</p><p>For any t 1, we define both following F t-1 -measurable random variables</p><formula xml:id="formula_64">Z t := 1 {c i (t) = c j (t)} B t := 1 ∃c, (i, j) ∈ P c (t) 2 ,</formula><p>and we denote O t := (a a a(1), c c c(1), . . . , a a a(t -1), c c c(t -1)) the set of random values observed up to time s -1. Note that T i,j (t + 1) = </p><formula xml:id="formula_65">E   t≥1 1{t ∈ Λ : T i,j (t + 1) &lt; δi,j 2 t i,j (t + 1)}   2 δ2 i,j , meaning E   t≥1 1{t ∈ Λ : T i,j (t) &lt; δi,j 2 t i,j (t)}   1 + 2 δ2 i,j = O(1),</formula><p>which corresponds to Claim (4).</p><p>Let now prove Claim (5) using the following decomposition</p><formula xml:id="formula_66">E T t=1 1 t ∈ Λ, ŝi,j (t) &lt; ∆i,j 2 E T t=1 1 t ∈ Λ, ŝi,j (t) &lt; ∆i,j 2 T i,j (t) &lt; δi,j 2 t i,j (t) + E T t=1 1 t ∈ Λ, ŝi,j (t) &lt; ∆i,j 2 , T i,j (t) δi,j 2 t i,j (t) ,</formula><p>Where the first right-hand side term is smaller than E t≥1 1 t ∈ Λ, T i,j (t) &lt; δi,j 2 t i,j (t) and therefore is a O(1). We control the second term by applying again Lemma E.3.</p><p>For any t 1, we define both following F t-1 -measurable random variables</p><formula xml:id="formula_67">Z t := c i (t) -c j (t) B t := 1 ∃c, (i, j) ∈ P c (t) 2 , c i (t) = c j (t) , Note that Z t ∈ [-1, 1], ŝi,j (t + 1)T i,j (t + 1) = t s=1 B s Z s , T i,j (t + 1) = t s=1 B s , and E [Z t | 0 t , B t = 1] &gt; ∆i,j by Lemma E.1 as i j.</formula><p>We also define A := Λ ∩ t ∈ N : T i,j (t) δi,j 2 t i,j (t) and for any n ∈ N, A(n) := Λ(n) ∩ t ∈ N : T i,j (t) δi,j 2 t i,j (t) . Then, (i) as Λ ⊆ n&gt;0 Λ(n), A ⊆ n&gt;0 A(n), (ii) for all n &gt; 0 and all t ∈ A(n), T i,j (t) δi,j</p><formula xml:id="formula_68">2 t i,j (t) δi,j 2 εn, (iii) |A(n)| |Λ(n)| 1, and (iv) the event t ∈ A(n) is F-measurable. Therefore by Lemma E.3 E   t≥1 1{t ∈ A : ŝi,j (t + 1)T i,j (t + 1) &lt; ∆i,j 2 T i,j (t + 1)}   8 δi,j ε ∆2 i,j , meaning E   t≥1 1 t∈Λ,ŝi,j (t)&lt; ∆i,j 2 , Ti,j (t) δi,j 2 ti,j (t)   1 + 8 δi,j ε ∆2 i,j = O(1).</formula><p>Overall, E This section presents two results aiming at upper-bounding the number of iterations at which ∆j,i is lower-estimated by sj,i (t) if j i. These new results are extensions of Lemma 9 and Theorem 10 of <ref type="bibr" target="#b11">(Garivier &amp; Cappé, 2011)</ref> to a setting where the handled statistic is a mixture of variables following different laws of bounded expectation. Lemma E.5. Let X be a random variable taking value in [0, 1] and let µ ≤ E[X]. then for all λ &lt; 0,</p><formula xml:id="formula_69">E[exp(λX)] ≤ 1 -µ + µ exp(λ), Proof. The function f : [0, 1] R -→ defined by f (x) = exp(λx) -x(exp(λ) -1) -1 is convex and such that f (0) = f (1) = 0, hence f (x) ≤ 0 for all x ∈ [0, 1]. Consequently, E[exp(λX)] ≤ E[X(exp(λ) -1) + 1] = E[X](exp(λ) -1) + 1 As λ &lt; 0 and µ ≤ E[X], we have E[X](exp(λ) -1) ≤ µ(exp(λ) -1) and E[exp(λX)] ≤ µ(exp(λ) -1) + 1</formula><p>Lemma E.6. Let (X a t ) t 1 with a ∈ R, be |R| &lt; ∞ independent sequences of independent random variables bounded in [0, 1] defined on a probability space (Ω, F, P) with common expectations µ a = E[X a t ] of minimal value µ = min a∈R µ a . Let F t be an increasing sequence of σ-fields of F such that for each t, σ((X a 1 ) a∈R , . . . , (X a t ) a∈R ) ⊂ F t and for s &gt; t and a a recommendation, X a s is independent from F t . Consider |R| previsible sequences ( a t ) t≥1 of Bernoulli variables (for all t &gt; 0, a t is F t-1 -mesurable) such that for all t &gt; 0, i a t ∈ {0, 1}. Let δ &gt; 0 and for every t let</p><formula xml:id="formula_70">S(t) = t s=1 i i s X i s , N (t) = t s=1 i i s , μ(t) = S(t) N (t) u(t) = max{q &gt; μ(t) : N (t)d(μ(t), q) ≤ δ} Then P(u(t) &lt; µ) ≤ e δ log(t) exp(-δ)</formula><p>Proof. For every λ &lt; 0, by Lemma E.5, it holds that log(E[exp(λX a 1 )]) ≤ log(1 -µ + µ exp(λ)) = φ µ (λ) for all a. Let W λ 0 = 1 and for t ≥ 1,</p><formula xml:id="formula_71">W λ t = exp(λS(t) -N (t)φ µ (λ)) (W λ t ) t≥ 0 is a super-martingale relative to (F t ) t≥0 . In fact, E[exp(λ{S(t + 1) -S(t)})|F t ] = E[exp(λ i i t+1 X i t+1 )|F t ]</formula><p>As (X i t ) t are independent sequences, we can rewrite :</p><formula xml:id="formula_72">E[exp(λ{S(t + 1) -S(t)})|F t ] = i E[exp(λ i t+1 X i t+1 )|F t ] = i exp( i t+1 log(E[exp(λX i t+1 )|F t ])) = exp( i i t+1 log(E[exp(λX i 1 )|F t ])) ≤ exp( i i t+1 φ µ (λ)) = exp({N (t + 1) -N (t)}φ µ (λ))</formula><p>which can be rewritten as</p><formula xml:id="formula_73">E[exp(λS(t + 1) -N (t + 1)φ µ (λ))|F t ] ≤ exp(λS(t) -N (t)φ µ (λ))</formula><p>The rest of the proof follows <ref type="bibr" target="#b11">(Garivier &amp; Cappé, 2011)</ref>. Using the "peeling trick": the interval {1, . . . , t} of possible values for N (t) is divided into slices {t k-1 + 1, . . . , t k } of geometrically increasing size. Each slice is treated independently. We assume that δ &gt; 1 and we construct the slicing as follow : t 0 = 0 and for k ∈ N * , t k = (1 + η) k , with η = 1/(δ -1).</p><p>Let D = log t log 1+η be the first interval such that t D ≥ t and A k the event {t k-1 ≤ N (t) ≤ t k } ∩ {u(t) &lt; µ} . We have : </p><formula xml:id="formula_74">P(u(t) &lt; µ) ≤ P( D k=1 A k ) ≤ D k=1 P(A k ) Note that</formula><formula xml:id="formula_75">(z, µ) = δ/(1 + η) k and x ∈]0, µ[ such that d(x, µ) = δ/N (t). We define λ(x) = log(x(1 -µ)) -log(µ(1 -x)) &lt; 0 so that we can rewrite d(x, µ) as d(x, µ) = λ(x)x -φ µ (λ(x)). • with N (t) &gt; tk-1 , we have d(z, µ) = δ (1+µ) k ≥ δ (1+µ)N (t) • with N (t) ≤ t k , we have d(μ(t), µ) &gt; δ N (t) &gt; δ (1+η) k = d(z, µ). As μ &lt; µ, we have μ(t) ≤ z Hence on the event { tk-1 &lt; N (t) ≤ t k } ∩ {μ(t) &lt; µ} ∩ {d(μ(t), µ)} it holds that λ(z)μ(t) -φ µ (λ(z)) ≥ λ(z)z - φ µ (λ(z)) = d(z, µ) ≥ δ (1+η)N (t)</formula><p>It leads to :</p><formula xml:id="formula_76">{ tk-1 &lt; N (t) ≤ t k } ∩ {u(t) &lt; µ} ⊂ {λ(z)μ(t) -φ µ (λ(z)) ≥ δ (1 + η)N (t) } ⊂ {λ(z)S(t) -N (t)φ µ (λ(z)) ≥ δ (1 + η) } ⊂ {W λ n (z) &gt; exp δ (1 + η) } As (W λ t ) t≥0 is a supermartingale, E[W λ(z) n ] ≤ E[W λ(z) n</formula><p>] = 1, and the Markov inequality yields :</p><formula xml:id="formula_77">P({ tk-1 &lt; N (t) ≤ t k } ∩ {u(t) &lt; µ}) ≤ P W λ n (z) &gt; exp δ (1 + η) ≤ exp - δ (1 + η)</formula><p>As η = 1/(δ -1), D = log n log 1+η and log(1 + 1/(δ -1)) ≥ 1/δ, we obtain :</p><formula xml:id="formula_78">P(u(t) &lt; µ) ≤     log n log 1 + 1 δ-1     exp(-δ + 1) ≤ e δ log(t) exp(-δ)</formula><p>F. Proof of Theorem 5.1 (Upper-Bound on the Regret of UniRank Assuming a Total Order on Items)</p><p>Before proving the regret upper-bound of UniRank, we prove Lemmas F.1 and F.2 which are respectively bounding the exploration when the leader is the optimal one, and the number of iterations at which the leader is sub-optimal. Finally, the regret upper-bound of UniRank is given in Appendix F.3. Proof. Let c ∈ {2, . . . , L} be a position, and denote i (respectively j) the item min(c -1, K) (resp. c). We aim at upperbounding the number of iterations such that the leader P P P (t) is the optimal partition P P P * , and either the subsets P P P * c-1 = {i} and P P P * c = {j} are merged in the chosen partition P P P (t), or j ∈ P P P * K+1 (t) is added to the subset P P P * K = {i} in the chosen partition P P P (t). Both situations require sj,i (t) to be positive. </p><formula xml:id="formula_79">∈ P c (s) 2 1{c i (s) = c j (s)}.</formula><p>Let bound the first term in the right-hand side.</p><p>Denote Λ = t : P P P (t) = P P P * , ∃c , P c (t) = {i, j} the set of iterations at which P P P (t) = P P P * and both items i and j are gathered in a subset of P P P (t). We decompose that set as Λ ⊆ s∈N Λ(s), with Λ(s) := {t ∈ Λ : t i,j (t) = s}. |Λ(s)| 1 as t i,j (t) increases for each t ∈ Λ. Note that for each s ∈ N and n ∈ Λ(s), t i,j (n) t i,j (n) = s.</p><p>Note also that with the current hypothesis on the order, i j, hence by Lemma E.4,</p><formula xml:id="formula_80">E   t≥1 1 t ∈ Λ, ŝj,i (t) &gt; ∆j,i 2   = O(1).</formula><p>The second term is bounded similarly with the same set Λ but with a different decomposition: Λ ⊆ s∈N Λ(s), with Λ(s) := {t ∈ Λ : t * j (t) = s}. |Λ(s)| 1 as t * j (t) increases for each t ∈ Λ. Note that for each s ∈ N and n ∈ Λ(s), t * j (n) t * j (n) = s. Therefore, the same proof as the one used in Lemma E.4 gives 1{ P P P (t) = P P P * } = O (log log T ) .</p><formula xml:id="formula_81">E   t≥1 1 t ∈ Λ, T * j (t) &lt; δ * j 2 t * j (t)   = O(1)</formula><p>Proof. Let P P P = P P P * be an ordered partition of items of size d, and let upper-bound the expected number of iterations at which P P P (t) = P P P by O (log log T ). As there is a finite number of partitions, this will conclude the proof.</p><p>In this proof, for any couple of items (i, j) we denote ti,j (t) := t-1 s=1 1 P P P (t) = P P P , ∃c, (i, j) ∈ P c (s) 2 the number of iterations at which both items have been gathered in the same subset of P P P (s) while the leader was P P P . For each partition P P P in the neighborhood N P P P , we also denote t P P P (t) := t-1 s=1 1 P P P (t) = P P P , P P P (t) = P P P the number of iterations at which P P P has been chosen while the leader was P P P .</p><p>The proof depends on the difference between P P P and P P P * . By Lemma 5.4,</p><p>• either ∃c ∈ [ d], such that |P c | &gt; 1 and i * argmax j∈Pc\{i * } g(j), where i * = argmax i∈Pc g(i);</p><p>• or ∃c ∈ [ d -1], ∃(i, j) ∈ Pc × Pc+1 , such that j i.</p><p>We first upper-bound the expected number of iterations at which P P P (t) = P P P under the first condition, and then prove a similar upper-bound under the second condition.</p><p>Assume that there exists c ∈ [ d], such that |P c | &gt; 1 and i argmax j∈Pc\{i * } g(j), where i = argmax i∈Pc g(i). Let t be an iteration such that P P P (t) = P P P . By Assumption 3.3 and by design of the algorithm, if for each item j ∈ Pc \ {i}, the sign of ŝi,j (t) would be the same as the sign of ∆i,j &gt; 0, then i would be alone in Pc (t). So ŝi,j (t) 0 for at least one item j ∈ Pc \ {i}. Let control the number of iteration at which this is true by considering the following decomposition: , ŝi,j (t) 0, .</p><formula xml:id="formula_82">t</formula><p>Let j be an item in Pc \ {i}, and let first upper-bound the expected size of A i,j and B i,j , and then the expected size of C i,j .</p><p>Note that at each iteration such that P P P (t) = P P P , i and j are in the same subset of the partition P P P (t), therefore ti,j (t) = t P P P (t).</p><p>Denote Λ = t : P P P (t) = P P P the set of iterations at which P P P (t) = P P P , and decompose that set as Λ ⊆ s∈N Λ(s), with Λ(s) := {t ∈ Λ : t P P P (t) = s}. |Λ(s)| 1 as t P P P (t) increases for each t ∈ Λ. Note that for each s ∈ N and n ∈ Λ(s), t i,j (n) ti,j (n) = t P P P (t) = s. Then by Lemma E.4</p><formula xml:id="formula_83">E [|A i,j |] = E   t≥1 1 t ∈ Λ, T i,j (t) &lt; δi,j 2 t i,j (t)   = O(1)</formula><p>and</p><formula xml:id="formula_84">E [|B i,j |] = E   t≥1 1 t ∈ Λ, ŝi,j (t) ∆i,j &lt; 1 2   = O(1).</formula><p>Let now upper-bound the expected size of C i,j .</p><p>As i j, ∆i,j &gt; 0.</p><p>Let t ∈ C i,j . As ŝi,j (t) 0, t T , and t P P P (t) = ti,j (t) t i,j (t) 2 δi,j Let P P P be such neighbor. In the first scenario we denote i(P P P ) := argmin i∈Pc g(i) and j(P P P ) := argmax j∈Pc+1 g(j). In the second scenario we denote i(P P P ) := argmin i∈P d-1 g(i), and j(P P P ) the item j. Finally, we denote N + the set of neighbors P P P of P P P such that j(P P P ) i(P P P ), and N -its complement { P P P } ∪ N ( P P P ) \ N + .</p><p>It is also worth noting that with current hypothesis on P P P ,</p><p>• |N + | + |N -| = N P P P + 1 L;</p><p>• N + is non-empty (due to current assumption on P P P );</p><p>• for each partition P P P ∈ N ( P P P ), t P P P (t) = ti(P P P ),j(P P P ) (t);</p><p>• by design of the algorithm, at each iteration t such that P P P (t) = P P P , ŝi(P P P ),j(P P P ) (t) &gt; 0 for each partition P P P ∈ N ( P P P ) as i(P P P ) is in a subset before j(P P P ) in P P P .</p><p>To bound E 1{ P P P (t) = P P P } , we use the decomposition {t ∈ [T ] : P P P (t) = P P P } = ∪ P P P + ∈N + A P P P + ∪ B where A P P P + = t : P P P (t) = P P P , t P P P + (t) ε t P P P (t) , B = t : P P P (t) = P P P , ∀P P P ∈ N + , t P P P + (t) &lt; ε t P P P (t) , and ε := 1</p><formula xml:id="formula_85">N P P P + 1 1 L .</formula><p>Hence, E 1{ P P P (t) = P P P } Bound on E [|A P P P + |] Let P P P ∈ N + be a permutation.</p><p>First, let's t be in A P P P + . Note that ∆i(P P P + ),j(P P P + ) &lt; 0, as j(P P P + ) i(P P P + ). Therefore, as ŝi(P P P + ),j(P P P + ) (t) &gt; 0, ŝi(P P P + ),j(P P P + ) (t) &gt; ∆i(P P P + ),j(P P P + )</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2</head><p>, and thus E [|A P P P + |] = E t≥1 1 t ∈ A P P P + , ŝi(P P P + ),j(P P P + ) (t) &gt; ∆i(P P P + ),j(P P P + )</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2</head><p>.</p><p>Secondly, let's decompose A P P P + as A P P P + ⊆ s∈N Λ(s), with Λ(s) := {t ∈ A P P P + : t P P P (t) = s}. |Λ(s)| 1 as t P P P (t) increases for each t ∈ A P P P + . Note that for each s ∈ N and n ∈ Λ(s), t i(P P P + ),j(P P P + ) (n) ti(P P P + ),j(P P P + ) (n) = t P P P + (n) ε t P P P (t) = εs. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2. Cumulative regret w.r.t. iterations. K = 5 and L = 10 for Yandex and Simul models (b,c,e,f); K = 3 and L ∈ {5, . . . , 11} for KDD model (a); K = and L = 6 for Yandex 8107157 (d) which corresponds to the parameters of the query 8107157 of Yandex. The plotted curves correspond to the average over 200, 160, or 20 independent sequences of recommendations (20 sequences per query). The (small) shaded areas depict the standard error of our regret estimates.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>T t=1 1</head><label>1</label><figDesc>t∈Λ,ŝi,j (t)&lt; ∆i,j 2 = O(1) + O(1) = O(1) which corresponds to Claim (5). Other claims are proved symmetrically. E.3. Upper-Bound on the Number of Lower-Estimations of an Optimistic Estimator</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>F. 1 .</head><label>1</label><figDesc>Upper-Bound on the Number of Sub-Optimal Merges of UniRank when the Leader is the Optimal Partition Lemma F.1 (Upper-bound on the number of sub-optimal merges of UniRank when the leader is the optimal partition). Under the hypotheses of Theorem 5.1, for any position c ∈ {2, . . . , L} UniRank fulfills E log T + O (log log T ) .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>which is absurd. Hence, C i,j = ∅, andE [|C i,j |] = 0. Overall, if there exists c ∈ [ d], such that |P c | &gt; 1 and i argmax j∈Pc\{i} g(j), where i = argmax i∈Pc g(i), i,j |] + E [|B i,j |] + E [|C i,j |] = O(1) + O(1) + 0 = O(1)Assume that there exists c ∈ [ d -1], and (i, j) ∈ Pc × Pc+1 , such that j i. By design of UniRank, each neighbor of P P P takes one of both forms:1. P1 , . . . , Pc-1 , Pc ∪ Pc+1 , Pc+2 , . . . P d , 2. P1 , . . . , P d-2 , P d-1 ∪ {j}, P d \ {j} .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>P</head><label></label><figDesc>P P ∈N + E [|A P P P + |] + E [|B|] .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>c (t) = {k -1, k} | P P P (t) = P P P * ∆ k c (t) = {min(k -1, K), k} | P P P (t) = P P P * ∆ k .Let finally upper-bound the overall regret. t) = P P P * µ * -E a a a(t) µ a a a(t) | P P P (t) = P P P * + T t=1 P P P P (t) = P P P * µ * -E a a a(t) µ a a a(t) | P P P (t) = P P P * c (t) = {min(k -1, K), k} | P P P (t) = P P P * ∆ k O (log log T ) t) = P P P * , P c(t) = {min(k -1, K), k, } ∆ k = O (log log T ) t) = P P P * , P c (t) = {min(k -1, K), k, } O (log log T )which concludes the proof.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 .</head><label>2</label><figDesc>Average computation time (in ms) per recommendation. For each top 10 query of Yandex dataset, 20 runs are performed assuming CM model and L = 10.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>TO BE DIFFERENT FROM c k , WHILE BOTH ITEMS ARE IN THE SAME SUBSET OF THE CHOSEN PARTITION P P P (t) AND P P P (t) IS IN THE NEIGHBORHOOD OF THE OPTIMAL PARTITION ∆i,j SMALLEST (RESPECTIVELY HIGHEST) EXPECTED DIFFERENCE OF CLICK BETWEEN ITEMS i AND j IF i Ti,j (t) NUMBER OF ITERATIONS AT WHICH ITEMS i AND j HAVE BEEN GATHERED IN THE SAME SUBSET OF ITEMS Pc(s) AND LEAD TO A DIFFERENT CLICK VALUE, Ti,j (t) =</figDesc><table><row><cell>SYMBOL</cell><cell>MEANING</cell><cell></cell></row><row><cell>T</cell><cell>TIME HORIZON</cell><cell></cell></row><row><cell>t</cell><cell>ITERATION</cell><cell></cell></row><row><cell>L</cell><cell>NUMBER OF ITEMS</cell><cell></cell></row><row><cell>i</cell><cell>INDEX OF AN ITEM</cell><cell></cell></row><row><cell>K</cell><cell>NUMBER OF POSITIONS IN A RECOMMENDATION</cell><cell></cell></row><row><cell>k</cell><cell>INDEX OF A POSITION</cell><cell></cell></row><row><cell>[n]</cell><cell>SET OF INTEGERS {1, . . . , n}</cell><cell></cell></row><row><cell>P L K</cell><cell cols="2">SET OF PERMUTATIONS OF K DISTINCT ITEMS AMONG L</cell></row><row><cell>θ θ θ</cell><cell>VECTORS OF PROBABILITIES OF CLICK</cell><cell></cell></row><row><cell>θi</cell><cell>PROBABILITY OF CLICK ON ITEM i</cell><cell></cell></row><row><cell>κ κ κ</cell><cell>VECTORS OF PROBABILITIES OF VIEW</cell><cell></cell></row><row><cell>κ k</cell><cell>PROBABILITY OF VIEW AT POSITION k</cell><cell></cell></row><row><cell>A</cell><cell>SET OF BANDIT ARMS</cell><cell></cell></row><row><cell>a a a</cell><cell>AN ARM IN A</cell><cell></cell></row><row><cell>a a a(t)</cell><cell>THE ARM CHOSEN AT ITERATION t</cell><cell></cell></row><row><cell>a k a a a  *</cell><cell cols="2">ITEM DISPLAYED AT POSITION K IN THE RECOMMENDATION a a a BEST ARM</cell></row><row><cell>ρ</cell><cell cols="3">FUNCTION FROM P L K × [K] TO [0, 1] GIVING THE PROBABILITY OF CLICK</cell></row><row><cell>ρ(a a a, k)</cell><cell cols="3">PROBABILITY OF CLICK ON THE ITEM DISPLAYED AT POSITION k WHEN RECOMMENDING a a a</cell></row><row><cell>c c c(t)</cell><cell>CLICKS VECTOR AT ITERATION t</cell><cell></cell></row><row><cell>ci(t)</cell><cell>CLICKS ON ITEM I AT ITERATION t</cell><cell></cell></row><row><cell>r(t) µa a a</cell><cell>REWARD COLLECTED AT ITERATION t, r(t) =</cell><cell>L i=1 ci(t)</cell></row><row><cell></cell><cell></cell><cell></cell><cell>j (RESP. j</cell><cell>i)</cell></row><row><cell></cell><cell cols="3">WHILE BOTH ITEMS ARE IN THE SAME SUBSET OF THE CHOSEN PARTITION P P P (t)</cell></row><row><cell>R(T )</cell><cell></cell><cell>T t=1 µ a a a(t)</cell></row><row><cell></cell><cell>STRICT WEAK ORDER</cell><cell></cell></row><row><cell>(i, j) • a a a</cell><cell cols="2">PERMUTATION SWAPPING ITEMS I AND J IN RECOMMENDATION a a a</cell></row><row><cell>P P P</cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="2">GRAPH CARRYING A PARTIAL ORDER ON THE PARTITIONS OF ITEMS</cell></row><row><cell>N ( P P P )</cell><cell cols="3">NEIGHBORHOOD t-1 s=1 1 ∃c, (i, j) ∈ Pc(s) 2 1{ci(s) = cj (s)}</cell></row><row><cell>t P P P (t)</cell><cell cols="2">NUMBER OF TIME A PERMUTATION P P P AS BEEN THE LEADER, t P P P (t) :=</cell><cell>t-1 s=1 1 P P P (s) = P P P</cell></row><row><cell>δi,j (a a a)</cell><cell></cell><cell></cell></row></table><note><p>EXPECTATION OF r(t) WHILE RECOMMENDING a a a, µa a a = E[r(t) | a a a(t) = a a a] µ * HIGHEST EXPECTED REWARD, µ * = max a a a∈P L K µa a a ∆ GENERIC REWARD GAP BETWEEN ONE OF THE SUB-OPTIMAL ARMS AND ONE OF THE BEST ARMS ∆c REWARD GAP WHILE EXCHANGING ITEMS min(c -1, K) AND c IN THE OPTIMAL RECOMMENDATION, δi,j SMALLEST PROBABILITY FOR ci(t) TO BE DIFFERENT FROM cj (t) WHILE BOTH ITEMS ARE IN THE SAME SUBSET OF THE CHOSEN PARTITION P P P (t) δ * k SMALLEST PROBABILITY FOR c min(k-1,K) (t) CUMULATIVE (PSEUDO-)REGRET, R(T ) = T µ * -E ORDERED PARTITION OF ITEMS REPRESENTING A SUBSET OF RECOMMENDATIONS, P P P = (P1, . . . , P d ) Pc c th PART OF P P P SUCH AS d c=1 Pc = [L], AND Pc ∩ P c IS EMPTY WHEN c = c A (P P P ) SET OF RECOMMENDATIONS a a a AGREEING WITH P P P P P P (t) BEST PARTITION AT ITERATION t GIVEN THE PREVIOUS CHOICES AND FEEDBACKS (CALLED LEADER) P P P * PARTITION SUCH THAT ANY PERMUTATION a a a IN A (P P P * ) IS COMPATIBLE WITH THE STRICT WEAK ORDER ON ITEMS. G IN G OF THE PARTITION P P P , N ( P P P ) := P1(t), . . . , Pc-1(t), Pc(t) ∪ Pc+1(t), Pc+2(t), . . . P d (t) : c ∈ [ d -2] ∪ P1(t), . . . , P d-1 (t) ∪ {j}, P d-1 (t) \ {j}, P d (t) : j ∈ P d (t) . ti,j (t) NUMBER OF ITERATIONS AT WHICH ITEMS i AND j HAVE BEEN GATHERED IN THE SAME SUBSET OF ITEMS Pc(s), ti,j (t) := t-1 s=1 1 ∃c, (i, j) ∈ Pc(s) 2</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 4 .</head><label>4</label><figDesc>Summary of the notations.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head></head><label></label><figDesc>, andE [Z t | 0 t , B t = 1] &gt; δi,j by Lemma E.1.Therefore by Lemma E.3</figDesc><table><row><cell>t s=1 B s Z s , t i,j (t + 1) =</cell><cell>t s=1 B s</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head></head><label></label><figDesc>by definition of u(t), we have u(t) &lt; µ if and only if μ(t) &lt; µ and N (t)d(μ(t), µ) &gt; δ. Let s be the smallest integer such that δ/(s + 1) ≤ d(0, µ). If N (t) ≤ s, then</figDesc><table><row><cell>sd(0, µ)</cell><cell>&lt;</cell><cell>δ.</cell></row><row><cell>as μ≤µ</cell><cell>by definition of s</cell><cell></cell></row></table><note><p>N (t)d(μ, µ) ≤ sd(μ, µ) ≤ Thus, we can't have μ &lt; µ and N (t)d(μ, µ) &gt; δ and P(u(t) &lt; µ) = 0 . We have for all k such that t k ≤ s, P(A k ) = 0 and we have u(t) &gt; µ when N (t) ∈ {t k-1 + 1, . . . , t k } and t k ≤ s. Now lets see how u(t) can be upper bounded by µ when N (t) &gt; s. For k such that t k ≥ s, we note tk-1 = max{t k-1 , s} and we take z &lt; µ such as d</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head></head><label></label><figDesc>It remains to upper-bound the third term.Let note C := t ∈ [T ] : P P P (t) = P P P * , ∃c , P c (t) = {i, j}, T * j (t) Bound on the Expected Number of Iterations at which the Leader is not the Optimal Partition Lemma F.2 (Upper-bound on the expected number of iterations at which the leader is not the optimal partition).</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>δ *  j 2 t  *  j (t), ŝj,i (t)</cell><cell>∆j,i 2 , sj,i (t) 0 .</cell></row><row><cell cols="2">Let t ∈ C.</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="7">By Pinsker's inequality and as sj,i (t) 0,</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>1</cell><cell>sj,i (t) + 1</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>2</cell><cell>2</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>ŝj,i (t) + 1 2</cell><cell>+</cell><cell>log( tP P P  *  (t)) + 3 log(log( tP P P  *  (t))) 2T i,j (t)</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>∆j,i 4</cell><cell>+</cell><cell>1 2</cell><cell>+</cell><cell>log( tP P P  *  (t))) + 3 log(log( tP P P  *  (t)))) 2T i,j (t)</cell><cell>.</cell></row><row><cell cols="2">Hence, T i,j (t) as (i) tP P P  *  (t)</cell><cell>t</cell><cell cols="4">8 log( tP P P  *  (t)))+24 log(log( tP P P  *  (t)))) ∆2 i,j T , (ii) T  *  j (t) T i,j (t), and (iii) δ *  as ∆i,j = -∆j,i &gt; 0 given Lemma E.1. Then, by definition of C and j δi,j &gt; 0 given Lemma E.1, t  *  2T  *  j (t) 2Ti,j (t) j (t) δ *  j δ *  j</cell></row><row><cell cols="4">16 log(T )+48 log(log(T ))</cell><cell></cell><cell></cell></row><row><cell>δ *  j</cell><cell>∆2 i,j</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>j (t) 16 log(T )+48 log(log(T )) δ *  j i,j ∆2</cell><cell>, and</cell></row><row><cell></cell><cell></cell><cell></cell><cell>T</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>E</cell><cell>1</cell><cell>T  *  j (t)</cell><cell>δ *  j 2 t  *  j (t), ŝj,i(t)</cell><cell>∆j,i 2 ,</cell><cell>= E [|C|]</cell></row><row><cell></cell><cell></cell><cell></cell><cell>t=1</cell><cell></cell><cell></cell><cell>sj,i(t) 0</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>E</cell><cell>t∈[T ]: P P P (t)=P P P  t  *  16 log(T )+48 log(log(T )) j (t) δ *  j ∆2 i,j</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>16 log(T ) + 48 log(log(T )) δ *  j i,j ∆2</cell><cell>,</cell></row><row><cell cols="5">which concludes the proof.</cell><cell></cell></row><row><cell cols="7">F.2. Upper-Under the</cell></row><row><cell cols="7">hypotheses of Theorem 5.1, UniRank fulfills</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>T</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>E</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>t=1</cell></row></table><note><p>. Therefore, C ⊆ t ∈ [T ] : P P P (t) = P P P * , ∃c , P c (t) = {i, j}, t * P P P (t)=P P P * , ∃c ,P c (t)={i,j}, * , ∃c ,P c (t)={i,j},</p></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>Usually, the unimodality is defined as the existence of a strictly increasing path from any sub-optimal arm to a a a * . Assumption</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_1"><p>2.1 is equivalent and we use it in this paper as it directly relates to the shape of the theoretical analysis.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_2"><p>This second bound is proven in<ref type="bibr" target="#b26">(Sentenac et al., 2021)</ref> for a matching problem handled with an algorithm similar to TopRank.Remark 5.2 (Exploration not at the top). With CM model, exploring at the top reduces the regret: it leads to less exploration, while the instantaneous regret remains unchanged. However, this results does not hold with PBM (see Theorem 6 in<ref type="bibr" target="#b19">(Lagrée et al., 2016)</ref> for details): while exploring at the top decreases the number of explorations, it also increases the regret per exploration; and the best trade-off depends on the values θ θ θ and κ κ κ.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p>We thank the reviewers for their valuable comments towards clarification of the paper. This research was partially supported by the <rs type="funder">Inria Project Lab</rs> "<rs type="projectName">Hybrid Approaches for Interpretable AI</rs>" (<rs type="projectName">HyAIAI</rs>) and the network on the foundations of trustworthy AI, integrating learning, optimisation, and reasoning (TAILOR) financed by the <rs type="funder">EU</rs>'s <rs type="programName">Horizon 2020 research and innovation program</rs> under agreement <rs type="grantNumber">952215</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funded-project" xml:id="_TJk7wcM">
					<orgName type="project" subtype="full">Hybrid Approaches for Interpretable AI</orgName>
				</org>
				<org type="funded-project" xml:id="_Fzeh7b4">
					<idno type="grant-number">952215</idno>
					<orgName type="project" subtype="full">HyAIAI</orgName>
					<orgName type="program" subtype="full">Horizon 2020 research and innovation program</orgName>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Thus, as j(P P P + ) i(P P P + ), by Lemma E.4 E   t≥1 1 t ∈ A P P P + , ŝi(P P P + ),j(P P P + ) (t) &gt; ∆i(P P P + ),j(P P P + ) 2   = O(1).</p><p>Overall, E [|A P P P + |] = E t≥1 1 t ∈ A P P P + , ŝi(P P P + ),j(P P P + ) (t) &gt; ∆i(P P P + ),j(P P P + )</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2</head><p>= O (1) .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Bound on E [|B|]</head><p>We first split B in two parts: B = B t0 ∪ B T t0 , where B t0 := {t ∈ B : t P P P (t) t 0 }, B T t0 := {t ∈ B : t P P P (t) &gt; t 0 }, and t 0 is chosen as small as possible to satisfy a constraint required later on in the proof. Namely, t 0 = max P P P -∈N ( P P P )\N + inf s : log(s)+3 log(log(s)) δj(P P P -),i(P P P -) (εs-1) &lt; ∆i(P P P -),j(P P P -)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>8</head><p>, with t 0 = 0 if N ( P P P ) \ N + is empty. Note that t 0 only depends on δj(P P P -),i(P P P -) and ∆i(P P P -),j(P P P -) for P P P -∈ N ( P P P ) \ N + .</p><p>We also define</p><p>• D P P P -:= t ∈ [T ] : P P P (t) = P P P , P P P (t) = P P P -, T j(P P P -),i(P P P -) (t) &lt; δj(P P P -),i(P P P -) 2 t j(P P P -),i(P P P -) (t) , for each P P P -∈ N ( P P P )\ N +</p><p>• E P P P -:= t ∈ [T ] : P P P (t) = P P P , P P P (t) = P P P -, ŝi(P P P -),j(P P P -) (t) &lt; ∆i(P P P -),j(P P P -)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2</head><p>, for each P P P -∈ N ( P P P ) \ N +</p><p>• F P P P + := t ∈ [T ] : P P P (t) = P P P , sj(P P P ),i(P P P ) (t)+1  . Let's elicit an iteration ψ(t) with specific properties. We denote s the first iteration such that t P P P -(s ) ε t P P P (t). At this iteration, t P P P -(s ) = ε t P P P (t) , and t P P P -(s ) = t P P P -(s -1) + 1, meaning that P P P (s -1) = P P P and P P P (s -1) = P P P -, and t P P P -(s -1) = ε t P P P (t) -1. Therefore, the set {s ∈ [t] : P P P (s) = P P P , P P P (s) = P P P -, t P P P -(s) = ε t P P P (t) -1} is non-empty. We define ψ(t) as the minimum on this set ψ(t) := min{s ∈ [t] : P P P (s) = P P P , P P P (s) = P P P -, t P P P -(s) = ε t P P P (t) -1}.</p><p>Let prove by contradiction that ψ(t) ∈ P P P -∈N -(D P P P -∪ E P P P -) ∪ P P P + ∈N + F P P P + . Assume that ψ(t) / ∈ P P P -∈N -(D P P P -∪ E P P P -) ∪ P P P + ∈N + F P P P + . The partition P P P -is in N -, so either P P P -= P P P or P P P -∈ N ( P P P ) \ N + .</p><p>The set N + is non-empty, so there exists a partition P P P + ∈ N + . As ψ(t) / ∈ P P P + ∈N + F P P P + , sj(P P P ),i(P P P ) (ψ(t))+1 2 &gt; ∆j(P P P ),i(P P P ) +1 2 , where ∆j(P P P ),i(P P P ) &gt; 0 as j(P P P ) i(P P P ). Thus sj(P P P ),i(P P P ) (ψ(t)) &gt; 0 and P P P (ψ(t)) = P P P -cannot be P P P by design of UniRank. Therefore P P P -∈ N ( P P P ) \ N + .</p><p>Thus, either N ( P P P ) \ N + is empty and we get a contradiction, or i(P P P -) and j(P P P -) are properly defined, and, by design of UniRank, sj(P P P -),i(P P P -) (ψ(t)) 0. Moreover, since P P P (ψ(t)) = P P P -and ψ(t) / ∈ D P P P -∪ E P P P -, T j(P P P -),i(P P P -) (ψ(t))</p><p>δj(P P P -),i(P P P -) 2 t j(P P P -),i(P P P -) (ψ(t)) and ŝi(P P P -),j(P P P -) (ψ(t))</p><p>∆i(P P P -),j(P P P -)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2</head><p>.</p><p>Therefore,</p><p>T j(P P P -),i(P P P -) (ψ(t)) δj(P P P -),i(P P P -) 2 t j(P P P -),i(P P P -) (ψ(t)) δj(P P P -),i(P P P -) 2 tj(P P P -),i(P P P -) (ψ(t))</p><p>= δj(P P P -),i(P P P -) 2 t P P P -(ψ(t)) = δj(P P P -),i(P P P -) 2 ( ε t P P P (t) -1) δj(P P P -),i(P P P -) 2 (ε t P P P (t) -1)</p><p>and by Pinsker's inequality and the fact that ψ(t) t and t P P P (s) is non-decreasing in s, and t P P P (t) &gt; t 0 , 1 2</p><p>sj(P P P -),i(P P P -) (ψ(t)) + 1 2 -ŝ j(P P P -),i(P P P -) (ψ(t)) + 1 2 -log( t P P P (ψ(t))) + 3 log(log( t P P P (ψ(t)))) 2T j(P P P -),i(P P P -) (ψ(t)) = ŝi(P P P -),j(P P P -) (ψ(t)) + 1 2 -log( t P P P (ψ(t))) + 3 log(log( t P P P (ψ(t)))) 2T j(P P P -),i(P P P -) (ψ(t)) 1 2 + ∆i(P P P -),j(P P P -) 4 -log( t P P P (t)) + 3 log(log( t P P P (t))) δj(P P P -),i(P P P -) (ε t P P P (t) -1) 1 2 + ∆i(P P P -),j(P P P -) 4 -∆i(P P P -),j(P P P -) 8 = 1 2 + ∆i(P P P -),j(P P P -) 8 which contradicts the fact that ∆i(P P P -),j(P P P -) &gt; 0.</p><p>Overall, we always get a contradiction, so, for any t ∈ B T t0 , ψ(t) ∈ P P P -∈N -(D P P P -∪ E P P P -) ∪ P P P + ∈N + F P P P + . Hence, B T t0 ⊆ n∈ P P P -∈N -(D P P P -∪E P P P -)∪ P P P + ∈N + F P P P + B T t0 ∩ {t ∈ [T ] : ψ(t) = n}. Let n be in  Λ(s) := {t ∈ Λ : t i(P P P -),j(P P P -) (t) = s}. |Λ(s)| 1 as t i(P P P -),j(P P P -) (t) increases for each t ∈ Λ. Note that for each s ∈ N and n ∈ Λ(s), t i(P P P -),j(P P P -) (n) t i(P P P -),j(P P P -) (n) = s. Then, by Lemma E.4, as i(P P P -) j(P P P -)</p><p>1{t ∈ Λ : T i(P P P -),j(P P P -) (t) &lt; δi(P P P -),j(P P P -) 2 t i(P P P -),j(P P P -) (t)} = O(1)</p><p>and</p><p>1{t ∈ Λ : ŝi(P P P -),j(P P P -) (t) &lt; ∆i(P P P -),j(P P P -)</p><p>Bound on E [|F P P P + |] By Lemma E.6, for each partition</p><p>.</p><p>Overall E 1{ P P P (t) = P</p><p>O (log log T ), which concludes the proof.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F.3. Final</head><p>Step of the Proof of Theorem 5.1 (Upper-Bound on the Regret of UniRank Assuming a Total Order on Items)</p><p>The proof of Theorem 5.1 from Lemmas F.1 and F.2 is mainly based on an appropriate decomposition of the regret.</p><p>Proof of Theorem 5.1. The upper-bound on the expected number of iterations at which UniRank explores while the leader is the optimal partition is given by Lemma F.1.</p><p>The upper-bound on the expected number of iterations at which the leader is not the optimal partition is given by Lemma F.2.</p><p>Let now consider the impact of these upper-bounds on the regret of UniRank.</p><p>Let remind that P * c = {c} for c ∈ [K], d * = K + 1, and</p><p>, where a a a * := (1, 2, . . . , K).</p><p>Let first upper-bound the regret suffered at iteration t while the the leader is the optimal partition: Let's focus on the first right hand-side term. As the probability of click at position k only depends on the set of items in positions 1 to k -1, and as under the condition a k (t) = k ∧ P P P (t) = P P P * , a a a(t) and a a a * have the same set of items in positions</p><p>= k, P P P (t) = P P P * . Hence that term is equal to 0.</p><p>Let now take a look at the second term. By design of UniRank, as a k-1 (t) = k ∧ P P P (t) = P P P * , there exists c such that P c (t) = {k -1, k}, and P a k-1 (t) = k | P P P (t) = P P P * = P a k-1 (t) = k, P c (t) = {k -1, k} | P P P (t) = P P P * = 1 2 P P c (t) = {k -1, k} | P P P (t) = P P P * .</p><p>Similarly, the third term corresponds to the existence of c such that P c (t) = {k -1, k}, and P a k (t) = k -1 | P P P (t) = P P P * = 1 2 P P c (t) = {k -1, k} | P P P (t) = P P P * .</p><p>By summing both terms, we have to handle</p><p>which is equal to 1 2 P P c (t) = {k -1, k} | P P P (t) = P P P * ∆ k , where</p><p>as the probability of click at any position k only depends on the set of items in positions 1 to k -1.</p><p>Finally, following the same argumentation, the last term is equal to 1 2 P P c (t) = {K, } | P P P (t) = P P P * ∆ , where ∆ := ρ(a a a * , K) -ρ((K, ) • a a a * , K).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>G. UniRank's Theoretical Results While Facing State-of-the-Art Click Models</head><p>Here, we prove Corollaries 5.2 and 5.3 and then discuss the relationship between our upper-bounds and the known lower bounds.</p><p>G.1. Proof of Corollary 5.2 (Upper-Bound on the Regret of UniRank when Facing CM * Click Model)</p><p>Corollary G.1 is a more precise version of Corollary 5.2. Its proof consists in identifying the gaps δ * k , ∆k , and ∆ k , where k is the index of an item.</p><p>Corollary G.1 (Facing CM * click model). Under the hypotheses of Theorem 5.1, if the user follows CM with probability θ i to click on item i when it is observed, then for any index k 2,</p><p>Hence, UniRank fulfills</p><p>Proof of Corollary G.1. Values δ * k and ∆ k derive from a straightforward computation given CM model. Let us prove the lower-bound on ∆k . Let i and j be two items such that i = j. Let a a a be a recommendation such that P(c i (t) = c j (t) | a a a(t) = a a a) &gt; 0.</p><p>Without loss of generality, assume i appears in a a a in position k, and if j appears in a a a, it is in a position</p><p>c=k+1 (1 -θ ac ) if j appears in a a a and 0 otherwise.</p><p>Hence the lower-bounding values for ∆k , by noting that the term A is lower-bounded by Corollary G.2 (Facing PBM * click model). Under the hypotheses of Theorem 5.1, if the user follows PBM with the probability θ i of clicking on item i when it is observed and the probability κ k of observing the position k, then for any index</p><p>Hence, UniRank fulfills</p><p>where ∆ := min{min k∈{2,...,K}</p><p>Proof of Corollary G.2. Values δ * k and ∆ k derive from a straightforward computation given PBM model. Let us prove the lower-bound on ∆k . Let i and j be two items such that i = j. Let a a a be a recommendation such that P(c i (t) = c j (t) | a a a(t) = a a a) &gt; 0.</p><p>If both i and j appear in a a a, denote k &lt; these positions. Then ∆i,j (a a a) = 1 2 (κ k + κ )(θ i -θ j ) 1 2 (κ k + κ )(θ i + θ j ) -2κ k κ θ i θ j θ i -θ j θ i + θ j .</p><p>If only one of both items i and j appears in a a a then ∆i,j (a a a) = θi-θj θi+θj .</p><p>Hence for any index k 2, ∆k θ min(K,k-1) -θ k θ min(K,k-1) +θ k .</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Top-k off-policy correction for a reinforce recommender system</title>
		<author>
			<persName><forename type="first">M</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Beutel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Covington</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Belletti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chi</forename></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">H</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 12th ACM Int. Conf. on Web Search and Data Mining, WSDM &apos;19</title>
		<meeting>of the 12th ACM Int. Conf. on Web Search and Data Mining, WSDM &apos;19</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="456" to="464" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Combinatorial multiarmed bandit: General framework and applications</title>
		<author>
			<persName><forename type="first">W</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yuan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">proc. of the 30th Int. Conf. on Machine Learning, ICML&apos;13</title>
		<meeting>of the 30th Int. Conf. on Machine Learning, ICML&apos;13</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A thompson sampling algorithm for cascading bandits</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">C</forename><surname>Cheung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">proc. of the 22nd Int. Conf. on Artificial Intelligence and Statistics, AISTATS&apos;19</title>
		<meeting>of the 22nd Int. Conf. on Artificial Intelligence and Statistics, AISTATS&apos;19</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Click Models for Web Search</title>
		<author>
			<persName><forename type="first">A</forename><surname>Chuklin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Markov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>De Rijke</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015">2015</date>
			<publisher>Morgan &amp; Claypool Publishers</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Unimodal bandits: Regret lower bounds and optimal algorithms</title>
		<author>
			<persName><forename type="first">R</forename><surname>Combes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Proutière</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">proc. of the 31st Int. Conf. on Machine Learning, ICML&apos;14</title>
		<meeting>of the 31st Int. Conf. on Machine Learning, ICML&apos;14</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Learning to rank: Regret lower bounds and efficient algorithms</title>
		<author>
			<persName><forename type="first">R</forename><surname>Combes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Magureanu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Proutière</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Laroche</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">proc. of the ACM SIGMETRICS Int. Conf. on Measurement and Modeling of Computer Systems</title>
		<meeting>of the ACM SIGMETRICS Int. Conf. on Measurement and Modeling of Computer Systems</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Unimodal bandits with continuous arms: Order-optimal regret without smoothness</title>
		<author>
			<persName><forename type="first">R</forename><surname>Combes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Proutière</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Fauquette</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. ACM Meas. Anal. Comput. Syst</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2020-05">May 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">An experimental comparison of click position-bias models</title>
		<author>
			<persName><forename type="first">N</forename><surname>Craswell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Zoeter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Ramsey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">proc. of the Int. Conf. on Web Search and Data Mining, WSDM &apos;08</title>
		<meeting>of the Int. Conf. on Web Search and Data Mining, WSDM &apos;08</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Learning to rank in the position based model with bandit feedback</title>
		<author>
			<persName><forename type="first">B</forename><surname>Ermis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Ernst</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Zappella</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 29th ACM Int. Conf. on Information &amp; Knowledge Management, CIKM&apos;20</title>
		<meeting>of the 29th ACM Int. Conf. on Information &amp; Knowledge Management, CIKM&apos;20</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="2405" to="2412" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Combinatorial network optimization with unknown variables: Multiarmed bandits with linear rewards and individual observations</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Gai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Krishnamachari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Jain</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE/ACM Trans. Netw</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1466" to="1478" />
			<date type="published" when="2012-10">October 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Learning to rank using contextual bandits</title>
		<author>
			<persName><forename type="first">P</forename><surname>Gampa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Fujita</surname></persName>
		</author>
		<author>
			<persName><surname>Banditrank</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Knowledge Discovery and Data Mining, PAKDD&apos;21</title>
		<editor>
			<persName><forename type="first">K</forename><surname>Karlapalem</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Cheng</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ramakrishnan</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><forename type="middle">K</forename><surname>Agrawal</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><forename type="middle">K</forename><surname>Reddy</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Srivastava</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename><surname>Chakraborty</surname></persName>
		</editor>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="259" to="271" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">The kl-ucb algorithm for bounded stochastic bandits and beyond</title>
		<author>
			<persName><forename type="first">A</forename><surname>Garivier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Cappé</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">proc. of the 24th Annual Conf. on Learning Theory, COLT&apos;11</title>
		<meeting>of the 24th Annual Conf. on Learning Theory, COLT&apos;11</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Bandit algorithm for both unknown best position and best item display on web pages</title>
		<author>
			<persName><forename type="first">C.-S</forename><surname>Gauthier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Gaudel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Fromont</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">19th International Symposium on Intelligent Data Analysis</title>
		<meeting><address><addrLine>Porto (virtual), Portugal</addrLine></address></meeting>
		<imprint>
			<publisher>IDA</publisher>
			<date type="published" when="2021-04">Apr 2021. 2021</date>
			<biblScope unit="page" from="1" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Parametric graph for unimodal ranking bandit</title>
		<author>
			<persName><forename type="first">C.-S</forename><surname>Gauthier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Gaudel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Fromont</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">A</forename><surname>Lompo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 38th Int. Conf. on Machine Learning, ICML&apos;21</title>
		<meeting>of the 38th Int. Conf. on Machine Learning, ICML&apos;21</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="3630" to="3639" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">DCM bandits: Learning to rank with multiple clicks</title>
		<author>
			<persName><forename type="first">S</forename><surname>Katariya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Kveton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Szepesvári</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">proc. of the 33rd Int. Conf. on Machine Learning, ICML&apos;16</title>
		<meeting>of the 33rd Int. Conf. on Machine Learning, ICML&apos;16</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Optimal regret analysis of thompson sampling in stochastic multi-armed bandit problem with multiple plays</title>
		<author>
			<persName><forename type="first">J</forename><surname>Komiyama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Honda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Nakagawa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">proc. of the 32nd Int. Conf. on Machine Learning, ICML&apos;15</title>
		<meeting>of the 32nd Int. Conf. on Machine Learning, ICML&apos;15</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Position-based multiple-play bandit problem with unknown position bias</title>
		<author>
			<persName><forename type="first">J</forename><surname>Komiyama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Honda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Takeda</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">proc. of the 31st conf. on Neural Information Processing Systems, NeurIPS&apos;17</title>
		<meeting>of the 31st conf. on Neural Information Processing Systems, NeurIPS&apos;17</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Cascading bandits: Learning to rank in the cascade model</title>
		<author>
			<persName><forename type="first">B</forename><surname>Kveton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Szepesvári</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ashkan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">proc. of the 32nd Int. Conf. on Machine Learning, ICML&apos;15</title>
		<meeting>of the 32nd Int. Conf. on Machine Learning, ICML&apos;15</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="767" to="776" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Combinatorial cascading bandits</title>
		<author>
			<persName><forename type="first">B</forename><surname>Kveton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ashkan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Szepesvári</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">proc. of the 29th conf. on Neural Information Processing Systems, NeurIPS&apos;15</title>
		<meeting>of the 29th conf. on Neural Information Processing Systems, NeurIPS&apos;15</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Multiple-play bandits in the position-based model</title>
		<author>
			<persName><forename type="first">P</forename><surname>Lagrée</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Vernade</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Cappé</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">proc. of the 30th conf. on Neural Information Processing Systems, NeurIPS&apos;16</title>
		<meeting>of the 30th conf. on Neural Information Processing Systems, NeurIPS&apos;16</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Toprank: A practical algorithm for online stochastic ranking</title>
		<author>
			<persName><forename type="first">T</forename><surname>Lattimore</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Kveton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Szepesvari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">proc. of the 32nd conf. on Neural Information Processing Systems, NeurIPS&apos;18</title>
		<meeting>of the 32nd conf. on Neural Information Processing Systems, NeurIPS&apos;18</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Safe online learning to re-rank via implicit click feedback</title>
		<author>
			<persName><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Kveton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Lattimore</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Markov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>De Rijke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Szepesvári</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zoghi</surname></persName>
		</author>
		<author>
			<persName><surname>Bubblerank</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">proc. of the 35th Uncertainty in Artificial Intelligence Conference, UAI&apos;19</title>
		<meeting>of the 35th Uncertainty in Artificial Intelligence Conference, UAI&apos;19</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Contextual combinatorial cascading bandits</title>
		<author>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">proc. of the 33rd Int. Conf. on Machine Learning, ICML&apos;16</title>
		<meeting>of the 33rd Int. Conf. on Machine Learning, ICML&apos;16</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Online learning to rank with features</title>
		<author>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Lattimore</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Szepesvári</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 36th Int. Conf. on Machine Learning, ICML&apos;19</title>
		<meeting>of the 36th Int. Conf. on Machine Learning, ICML&apos;19</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Learning diverse rankings with multi-armed bandits</title>
		<author>
			<persName><forename type="first">F</forename><surname>Radlinski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Kleinberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thorsten</forename></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">proc. of the 25th Int. Conf. on Machine Learning, ICML&apos;08</title>
		<meeting>of the 25th Int. Conf. on Machine Learning, ICML&apos;08</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Predicting clicks: Estimating the click-through rate for new ads</title>
		<author>
			<persName><forename type="first">M</forename><surname>Richardson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Dominowska</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ragno</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">proc. of the 16th International World Wide Web Conference, WWW &apos;07</title>
		<meeting>of the 16th International World Wide Web Conference, WWW &apos;07</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Pure exploration and regret minimization in matching bandits</title>
		<author>
			<persName><forename type="first">F</forename><surname>Sentenac</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Calauzenes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Perchet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Vojnovic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 38th Int. Conf. on Machine Learning, ICML&apos;21</title>
		<meeting>of the 38th Int. Conf. on Machine Learning, ICML&apos;21</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="9434" to="9442" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Yandex personalized web search challenge</title>
		<ptr target="https://www.kaggle.com/c/yandex-personalized-web-search-challenge" />
		<imprint>
			<date type="published" when="2013">2013</date>
			<publisher>Yandex</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Online learning to rank in stochastic click models</title>
		<author>
			<persName><forename type="first">M</forename><surname>Zoghi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Tunys</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ghavamzadeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Kveton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Szepesvari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">proc. of the 34th Int. Conf. on Machine Learning, ICML&apos;17</title>
		<meeting>of the 34th Int. Conf. on Machine Learning, ICML&apos;17</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Cascading bandits for large-scale recommendation problems</title>
		<author>
			<persName><forename type="first">S</forename><surname>Zong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Ni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Sung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">R</forename><surname>Ke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Kveton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">proc. of the 32nd Conference on Uncertainty in Artificial Intelligence, UAI &apos;16</title>
		<meeting>of the 32nd Conference on Uncertainty in Artificial Intelligence, UAI &apos;16</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
