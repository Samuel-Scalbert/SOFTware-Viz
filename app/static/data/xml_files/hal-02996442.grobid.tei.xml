<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Injection of Knowledge in a Sourcing Recommender System</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Molka</forename><forename type="middle">Tounsi</forename><surname>Dhouib</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Catherine</forename><surname>Faron</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Andrea</forename><forename type="middle">G B</forename><surname>Tettamanzi</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">Université Côte d&apos;Azur</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">I3S</orgName>
								<orgName type="institution" key="instit1">Inria</orgName>
								<orgName type="institution" key="instit2">CNRS</orgName>
								<orgName type="institution" key="instit3">Silex Sophia Antipolis</orgName>
								<address>
									<postCode>0000-0002-6670-7821</postCode>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="institution">Université Côte d&apos;Azur</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="institution" key="instit1">Inria</orgName>
								<orgName type="institution" key="instit2">CNRS</orgName>
								<orgName type="institution" key="instit3">I3S</orgName>
								<address>
									<postCode>0000-0001</postCode>
									<settlement>Sophia Antipolis</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff4">
								<orgName type="institution">Université Côte d&apos;Azur</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff5">
								<orgName type="institution" key="instit1">Inria</orgName>
								<orgName type="institution" key="instit2">CNRS</orgName>
								<address>
									<addrLine>I3S Sophia Antipolis</addrLine>
									<postCode>0000-0002-8877-4654</postCode>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Injection of Knowledge in a Sourcing Recommender System</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">61A1FC39A520C6B49A71E489A5D78B95</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-04-12T14:53+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Recommender systems provide suggestions to users for items that best meet their needs. In this work, we study the benefits of using knowledge and, more specifically, a 'bag of concepts' representation to enhance a recommender system in the sourcing domain. We tested our approach in a real-world case study provided by the Silex company. The experimental results show that injecting knowledge in the recommendation process outperforms word embedding approaches.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>Nowadays, Recommender systems (RS) are primarily used in commercial applications to provide a personalized experience and suggest relevant items to users such as music, movies, books, trips, products. In the context of the Silex company, our goal is to propose a RS that can predict relevant providers (items) that are likely to be of interest for a service request (user). Silex simplifies the sourcing process by allowing companies to provide a description of their professional activities, their offers and/or the services they are looking for in natural language, in French.</p><p>In this paper, we propose to combine a conceptual representation of texts to their representation based on word embedding to enhance the recommendation in the sourcing domain. Our main research question is: Can the integration of domain knowledge enhance the performance of a recommender system in our use case? We focus on the following sub-questions: (i) What is the best way to integrate domain knowledge into the representation of service requests and providers in order to enhance the quality of recommendations? (ii) To what extent does the injection of domain knowledge improve the performance of the system?</p><p>The remainder of this paper is organized as follows. Section II gives an overview of state of the art recommendation approaches. Section III presents the recommendation approach we propose. Section IV reports and discusses the results of our experiments in the sourcing domain. Section V concludes and provides an outline of future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. RELATED WORK</head><p>There are four main approaches to RS:</p><p>• Content-based recommendation <ref type="bibr" target="#b0">[1]</ref>: This approach consists in analyzing the content (i.e., set of attributes or metadata) of items liked by users in the past and suggests items with similar content <ref type="bibr" target="#b1">[2]</ref>. • Collaborative filtering <ref type="bibr" target="#b2">[3]</ref>: It is based on the feedback (rating) on items provided by similar users. • Knowledge-based recommendation <ref type="bibr" target="#b3">[4]</ref>: This approach consists in using ontologies to model knowledge about the user context, the item context and the domain. • Hybrid recommendation <ref type="bibr" target="#b4">[5]</ref>: This approach combines the three above ones, to take advantage of the benefits of each of them. Our method is at the intersection of the content-based and knowledge-based approaches. The idea behind our approach is to take advantage of the power of word embedding, which approximates a general semantic relation, and the power of domain knowledge, which models a more specific semantic relation, to provide high quality recommendations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. PROPOSED APPROACH</head><p>Our proposal relies on the use of domain knowledge that can be captured into a thesaurus or an ontology. In the following we will refer to vocabulary indistinctly as a thesaurus or an ontology. In the experiments reported in this paper and conducted to answer the Silex use case, we are using a sourcing domain vocabulary, as we exploit different types of relationship between concepts and their labels (and not intentional definitions).</p><p>Our approach comprises five steps: (i) construction of a vocabulary for the sourcing domain, (ii) entity recognition from the textual descriptions of service requests and providers, (iii) entity management, (iv) vector representation of service requests and providers, and (v) recommendation algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Vocabulary for the Sourcing Domain</head><p>The preliminary step of our approach is the construction of a vocabulary to capture the sourcing knowledge <ref type="bibr" target="#b5">[6]</ref> by identifying and combining several relevant standard metadata repositories such as ESCO,<ref type="foot" target="#foot_0">1</ref> ROME,<ref type="foot" target="#foot_1">2</ref> NAF, <ref type="foot" target="#foot_2">3</ref> UNSPSC, <ref type="foot" target="#foot_3">4</ref> and CPF, 5 . Our sourcing vocabulary gathers 124040 concepts. We proposed an alignment method and applied it to automatically align the above-mentioned vocabularies, which where partially overlapping <ref type="bibr" target="#b6">[7]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Sourcing Named Entity Recognizer</head><p>The second step of our approach consists in extracting the relevant entities (i.e., services, products, occupations, skills, and business sectors) from the textual descriptions (i.e. service requests and company descriptions), based on our sourcing vocabulary. To handle this type of textual data, our approach <ref type="bibr" target="#b7">[8]</ref> is based on a Bidirectional Long-term and Short-term Mermory (Bi-LSTM) encodes an input textual description and a Conditional Random Fields model (CRF) labels every word to detect entities. In addition to word embedding, we extract three other kinds of embedding for each word in the textual description: (i) a character-level embedding to represent rare words or words with spelling errors; (ii) a syntax embedding to locate the user's need in a description: and (iii) a position embedding to push the model to understand that it is highly likely that the words at the beginning of the text are relevant information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Entity Linking with the Sourcing Vocabulary</head><p>In order to link the named entities extracted from the descriptions of service requests and providers with the closest concepts in the sourcing vocabulary, we defined a similarity measure between an entity and a concept.</p><p>We first represent each extracted entity and each concept of the sourcing vocabulary by an embedding vector which is computed as the average of the word embedding vectors of all the words participating in the entity or label of concept and occurring in the dictionary. In the absence of a large corpus available to train a word embedding model for our use case, we use fastText pre-trained word vectors for French.</p><p>The embedding vector for an entity or a (label of) concept x is thus computed as</p><formula xml:id="formula_0">V (x) = 1 n n i=1 w i ,<label>(1)</label></formula><p>where n is the number of words of the dictionary occurring in x and w i ∈ R 300 denotes the word embedding vector of the ith word of x occurring in the dictionary. If a word of x does not belong to the dictionary, it is just ignored.</p><p>Then we define the similarity between an entity e extracted form a request or provider description and a concept c in the sourcing vocabulary as the cosine similarity between their embedding vectors V (e) and V (c):</p><formula xml:id="formula_1">sim(e, c) = V (e) • V (c) ||V (e)|| • ||V (c|| .<label>(2)</label></formula><p>Finally, we link each entity with the most similar concept in the vocabulary O: linked 0 (e, c) ⇐⇒ sim(e, c) = max ci∈O sim(e, c i ). (3) 5 https://www.insee.fr/fr/metadonnees/cpfr21/section/A?champRecherche= true</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Vector Representation of Service Requests and Providers</head><p>We aim to represent each service request or provider by a vector that summarizes the semantics of the entities extracted from its description. For each description of a service request or provider, we consider three alternative vector representations: (i) the average of the embedding vectors of the entities in the textual description, (ii) a bag of concepts representation, and (iii) a vector representation combining the two former ones.</p><p>1) Word Embedding of Entities: The base vector representation V Emb (x) of a service request or provider x is the average of the embedding vectors of all the entities e i , i = 1, ..., n extracted from its description:</p><formula xml:id="formula_2">V Emb (x) = 1 n n i=1 V (e i ),<label>(4)</label></formula><p>where V (e i ) is the vector representation of entity e i as defined in "(1)".</p><p>2) Bag of Concepts: Using the result of the above described entity linking process, we consider an alternative representation V BoC (x) of a service request or provider x based on the sourcing vocabulary S: the bag of the concepts (BoC) in S which the entities e i extracted from x are linked to according to "(3)":</p><formula xml:id="formula_3">V BoC (x) = BoC S (x) = (b 1 , ..., b m )<label>(5)</label></formula><p>where m is the size of the sourcing vocabulary S and b i = 1 if ∃e ∈ x, linked S (e, c i ), and b i = 0 otherwise. Additionally, we considered enriching the BoC representation of a service request or provider, by considering not only the concepts linked to the entities it contains but also some neighbors in the vocabulary to the linked concepts. More precisely, we considered the parents of the concepts linked to the entities (skos:narrower relation) or those semantically close (skos:closeMatch relation). Formally, we define three alternative BoC representations: </p><formula xml:id="formula_4">V</formula><p>where m is the size of the sourcing vocabulary S and b i = 1 if ∃e ∈ x, linked S (e, c i ) or linked S (e, c j ) with c j skos:narrower c i or c j skos:closeMatch c i ; and b i = 0 otherwise.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>BoC (x) = BoC S (x) = (b 1 , ..., b m ) (6)where m is the size of the sourcing vocabulary S and b i = 1 if ∃e ∈ x, linked S (e, c i ) or linked S (e, c j ) with c j skos:narrower c i ; and b i = 0 otherwise.V BoC (x) = BoC S (x) = (b 1 , ..., b m ) (7)where m is the size of the sourcing vocabulary S and b i = 1 if ∃e ∈ x, linked S (e, c i ) or linked S (e, c j ) with c j skos:closeMatch c i ; and b i = 0 otherwise.V BoC (x) = BoC S (x) = (b 1 , ..., b m )</figDesc></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>https://ec.europa.eu/esco/portal/home</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>http://www.pole-emploi.org/accueil/mot-cle.html?tagId= 94b2eaf6-d7bd-4244-bddc-01415605563b</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2"><p>https://www.insee.fr/fr/information/2406147</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3"><p>https://www.unspsc.org/</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>V. CONCLUSION</head><p>In this paper, we presented a sourcing recommender system based on domain knowledge. We focus especially on the vector representation of the descriptions by evaluating the performance of the system using word embedding or injecting domain knowledge into the representation. Our experiments show that recommendation accuracy can be greatly improved through the injection of domain knowledge in the recommendation process. As future work, we aim firstly to use BERT or Camembert for French texts as models to generate word embedding representations.</p></div>
			</div>			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>3) Combination of Vector Representations: We define a third type of vector representation of a description of service request or provider as the concatenation of the vector representations defined in "(4)" and one of the BoC representations defined in "(5)", "(6)", "(7)", and "(8)", respectively:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Recommendation Algorithm</head><p>We define two metrics to measure the similarity between a service provider p and a service request r. The first one is the cosine similarity between the vector representations of p and r:</p><p>sim</p><p>where V stands for one of the representations defined in "(4)" to "(12)". The second metrics is</p><p>where sim 1 is then computed with the base vector representation V 1 .</p><p>A service provider p is recommended for a service request r if sim 1 (p, r) or sim 2 (p, r) is greater than a given threshold, depending on the chosen similarity measure.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. EXPERIMENTS AND RESULTS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Dataset and Protocol</head><p>We evaluate the performance of our recommendation approach on a dataset provided by sales experts at Silex. This dataset comprises 109 descriptions of service requests and the 649 providers in various areas which were manually selected and recommended for these requests. We consider two sets of annotations of this dataset: A is the set of annotations automatically performed by our NER approach; A is the result of a manual cleaning of A that we performed.</p><p>To decide on the optimal vector representation and algorithm to recommend service providers, we conducted eleven experiments whose settings are depicted in Table <ref type="table">I</ref>, the baseline being experiment Emb.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>TABLE I: Experimental settings</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experiment</head><p>Vector representation Similarity measure</p><p>In order to evaluate the performance of the proposed settings, and therefore the interest of injecting domain knowledge into vector representations, we used the precision, recall, F1 score metrics and the precision score considering the N top ranking providers (up to the tenth) according to the usual formula for "precision at N ": .</p><p>We conducted the parameter learning (i.e threshold) through 5-fold cross validation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Results and Discussion</head><p>Table <ref type="table">II</ref> and III present the performance of our system for each tested setting in terms of precision, recall and F1 score with datasets A and A respectively.  In order to evaluate to what extent the performance of our proposed approach depends on the method adopted to automatically annotate the descriptions of the service requests and providers, we conducted some additional experiments in which we used DBpedia spotlight 6 for NER. Table <ref type="table">IV</ref> presents the results on dataset A when named entities are extracted with DBpedia spotlight <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b9">[10]</ref>.</p><p>Figures <ref type="figure">1a</ref> and<ref type="figure">1b</ref> present the performance of our system for each tested setting in terms of P@N on dataset A and dataset A respectively. 6    All methods, where a word embedding representation is enriched with domain knowledge, obtain a better precision measure than the baseline method using word embedding alone. Focusing on the precision@N results, with both datasets, we can conclude that injecting domain knowledge is highly beneficial to our RS. Although a BoC representation performs very well from the 2 top-ranking items on dataset A, we can observe that its performance keeps steady on both datasets up to the tenth item. Using this cleaned dataset, the performance of all methods are increased. This emphasizes the fact that all methods are very sensitive to the quality of entity linking.</p><p>All in all, it appears that injecting domain knowledge into the vector representations is all the more beneficial the greater the quality of the annotations. Also, enriching the conceptual representations by considering the subsumption relation and skos:closeMatch relation clearly gives a better results. Finally, the comparison with the experiments using DBpedia spotlight for NER confirms that the introduction of domain knowledge in the recommendation process is beneficial and helps enhance the performance of the system even when one cannot rely on a high-quality NER method.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Newsweeder: Learning to filter netnews</title>
		<author>
			<persName><forename type="first">K</forename><surname>Lang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning Proceedings 1995</title>
		<imprint>
			<publisher>Elsevier</publisher>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page" from="331" to="339" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Data mining and personalization technologies</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">S</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings. 6th International Conference on Advanced Systems for Advanced Applications</title>
		<meeting>6th International Conference on Advanced Systems for Advanced Applications</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="6" to="13" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Social information filtering: algorithms for automating &quot;word of mouth</title>
		<author>
			<persName><forename type="first">U</forename><surname>Shardanand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Maes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the SIGCHI conference on Human factors in computing systems</title>
		<meeting>the SIGCHI conference on Human factors in computing systems</meeting>
		<imprint>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page" from="210" to="217" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Knowledge based recommendation system in semantic web -a survey</title>
		<author>
			<persName><forename type="first">A</forename><surname>Ameen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Applications</title>
		<imprint>
			<biblScope unit="volume">182</biblScope>
			<biblScope unit="issue">43</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Toward the next generation of recommender systems: A survey of the state-of-the-art and possible extensions</title>
		<author>
			<persName><forename type="first">G</forename><surname>Adomavicius</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Tuzhilin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on knowledge and data engineering</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="734" to="749" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Construction d&apos;ontologie pour le domaine du sourcing</title>
		<author>
			<persName><forename type="first">M</forename><surname>Dhouib</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">F</forename><surname>Zucker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Tettamanzi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">29es Journées Francophones d&apos;Ingénierie des Connaissances</title>
		<imprint>
			<date type="published" when="2018">2018. 2018</date>
			<biblScope unit="page" from="137" to="144" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">An ontology alignment approach combining word embedding and the radius measure</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">T</forename><surname>Dhouib</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">F</forename><surname>Zucker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">G</forename><surname>Tettamanzi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Semantic Systems</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="191" to="197" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">A hybrid bi-lstm-crf model for sequence labeling applied tothe sourcing domain,&quot; 6ème conférence sur les Applications Pratiques de l&apos;Intelligence Artificielle APIA</title>
		<author>
			<persName><forename type="first">H</forename><surname>Daoud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">T</forename><surname>Dhouib</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Rancati</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">F</forename><surname>Zucker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">G</forename><surname>Tettamanzi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Dbpedia spotlight: Shedding light on the web of documents</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">N</forename><surname>Mendes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Jakob</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Garcia-Silva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Bizer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 7th International Conference on Semantic Systems (I-Semantics)</title>
		<meeting>the 7th International Conference on Semantic Systems (I-Semantics)</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Improving efficiency and accuracy in multilingual entity extraction</title>
		<author>
			<persName><forename type="first">J</forename><surname>Daiber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Jakob</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Hokamp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">N</forename><surname>Mendes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 9th International Conference on Semantic Systems (I-Semantics)</title>
		<meeting>the 9th International Conference on Semantic Systems (I-Semantics)</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
