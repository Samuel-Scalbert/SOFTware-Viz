<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">MDSC: Modelling Distributed Stream Processing across the Edge-to-Cloud Continuum</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Daniel</forename><surname>Balouek-Thomert</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Pedro</forename><surname>Silva</surname></persName>
							<email>pedro.silva@hpi.de</email>
						</author>
						<author>
							<persName><forename type="first">Kevin</forename><surname>Fauvel</surname></persName>
							<email>kevin.fauvel@inria.fr</email>
						</author>
						<author>
							<persName><forename type="first">Alexandru</forename><surname>Costan</surname></persName>
							<email>alexandru.costan@irisa.fr</email>
						</author>
						<author>
							<persName><forename type="first">Gabriel</forename><surname>Antoniu</surname></persName>
							<email>gabriel.antoniu@irisa.fr</email>
						</author>
						<author>
							<persName><forename type="first">Manish</forename><surname>Parashar</surname></persName>
							<email>manish.parashar@utah.edu</email>
						</author>
						<author>
							<persName><roleName>Fauvel, Costa, Antoniu</roleName><forename type="first">Balouek-Thomert</forename><surname>Silva</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">University of Utah</orgName>
								<orgName type="institution" key="instit2">SCI Institute</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">Hasso-Plattner Institut</orgName>
								<orgName type="institution">Uni. Potsdam</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="institution" key="instit1">Univ Rennes</orgName>
								<orgName type="institution" key="instit2">Inria</orgName>
								<orgName type="institution" key="instit3">CNRS</orgName>
								<orgName type="institution" key="instit4">IRISA</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="institution" key="instit1">Univ Rennes</orgName>
								<orgName type="institution" key="instit2">Inria</orgName>
								<orgName type="institution" key="instit3">CNRS</orgName>
								<orgName type="institution" key="instit4">IRISA</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff4">
								<orgName type="institution" key="instit1">Univ Rennes</orgName>
								<orgName type="institution" key="instit2">Inria</orgName>
								<orgName type="institution" key="instit3">CNRS</orgName>
								<orgName type="institution" key="instit4">IRISA</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff5">
								<orgName type="institution" key="instit1">University of Utah</orgName>
								<orgName type="institution" key="instit2">SCI Institute</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">MDSC: Modelling Distributed Stream Processing across the Edge-to-Cloud Continuum</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">100F1E797B4BC66565627C4581024BB7</idno>
					<idno type="DOI">10.1145/1122445.1122456</idno>
					<note type="submission">Submitted on 4 Jan 2022</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-04-12T14:46+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Computing Continuum</term>
					<term>Stream Processing</term>
					<term>Modelling Daniel Balouek-Thomert</term>
					<term>Pedro</term>
				</keywords>
			</textClass>
			<abstract xml:lang="fr">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>des établissements d'enseignement et de recherche français ou étrangers, des laboratoires publics ou privés.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>With the proliferation of the Internet of Things (IoT), we have witnessed the development and popularization of new Machine Learning (ML) applications aiming to leverage distributed and heterogeneous data sources to automate decision-making. These applications bring new data processing challenges, in particular related Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. Woodstock '18, June 03-05, 2018, Woodstock, NY © 2018 Association for Computing Machinery. ACM ISBN 978-1-4503-XXXX-X/18/06. . . $15.00 https://doi.org <ref type="bibr">/10.1145/1122445.1122456</ref> to the need to process large volumes of streamed data under highthroughput and low-latency constraints.</p><p>Moving away from traditional centralized Cloud models, the use of resources spanning at the Edge of the infrastructure and in the Fog (i.e., between the Edge and Cloud), allows to distribute analytics while preserving low latency, high availability, and privacy. This aggregation of heterogeneous resources along the data path from the Edge to the Cloud, also referred to as the Edge-to-Cloud Continuum, or the Computing Continuum <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b10">11]</ref>, can be harnessed to support distributed analytics.</p><p>As IoT and ML applications are powered by pipelines of multiple data processing frameworks <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b12">13]</ref>, the integration of the different software, libraries and platform components is a significant challenge on large and heterogeneous infrastructures. Understanding the dependencies between the application workflows to best leverage the underlying infrastructure is crucial for the end-to-end performance. However, we are currently missing models enabling this adequate mapping of distributed analytics pipelines on the Edge-to-Cloud Continuum.</p><p>To tap into the power of the Computing Continuum, we propose MDSC, an approach for modeling distributed stream-based applications running across the Edge-to-Cloud continuum. The objective of MDSC is to facilitate the definition and evaluation of alternative deployment options for such applications atop the Edge-to-Cloud Continuum, in a versatile way.</p><p>To enable this vision, MDSC leverages a set of simple but expressive architectural concepts (e.g., layers, processing units, buses), which aim to describe the essential components of the application and to make more explicit their inter-relations and functionalities. These abstractions further enable grouping for components of similar nature and allow to characterize the communication among those groups. Subsequently, this model facilitates the definition of alternative mappings onto the underlying edge/fog/cloud infrastructure.</p><p>The contributions of this paper are:</p><p>• a hierarchical approach for modeling distributed streambased applications on the Edge-to-Cloud Continuum -MDSC (Section 3); • an illustration of how this model can be applied to a complex ML-based real-life application for Earthquake Early Warning -MDSC EEW (Section 4); • a large-scale experimental validation of MDSC EEW through various experiments on an Edge-to-Cloud infrastructure emulated atop the Grid'5000 testbed (Sections 5 and 6); 1</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">BACKGROUND AND CHALLENGES</head><p>State-of-the-art stream-based analytics applications are mostly built on the premise that data ingestion, management, and processing are done in centralized locations by leveraging general purpose analytics frameworks such as Apache Flink <ref type="bibr" target="#b12">[13]</ref> or Apache Spark <ref type="bibr" target="#b33">[34]</ref>. At the same time, legacy single-machine ML libraries start to receive support for execution in distributed settings, based on dataflow models <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b22">23]</ref>. Efforts from major Cloud providers enable ML capabilities when consuming data from devices at large scale but do not offer the ability to orchestrate application components across hybrid Edge-Cloud infrastructures <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b6">7]</ref>. Edge Analytics systems take advantage of the processing power of machines located at and near the Edge of the network in order to accelerate and to scale up analytics applications with minimum resource usage. This decentralization of stream-based data analytics systems leads to multiple challenges:</p><p>Expressive and versatile models for both the application and the infrastructure. To effectively leverage the computing power near the network edges, powerful and expressive models are necessary to help describe the application by considering the possible configurations and limitations of the underlying infrastructure.</p><p>Sustained real-time processing Many Edge analytics systems (ML-enabled or not), such as home assistants and health care systems, require real-time or near real-time processing latency. Achieving it is non-trivial when processing huge volumes of data streamed from heterogeneous sources.</p><p>Effective processing distribution considering constrained resources Complex trade-offs needs to be considered when deploying stream-based analytics pipelines across the Continuum: which parts should be executed at the Edge and which in the Cloud?</p><p>Given their different scopes, addressing all these challenges within a single framework is a non-trivial endeavour. There is already work on processing distribution <ref type="bibr" target="#b16">[17]</ref> and ML on constrained resources <ref type="bibr" target="#b17">[18]</ref>. Therefore, in this paper, we focus on the first challenge: provide expressive and versatile models for the application and for the infrastructure, as an effective means to enable real-time processing in analytics applications deployed on the Edge-to-Cloud Continuum (the second challenge).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">MDSC: AN APPROACH FOR MODELLING DISTRIBUTED STREAM-BASED ANALYTICS</head><p>In this section, we introduce MDSC, a modelling approach which aims to help developers organize the different components of processing frameworks used by analytics applications (ML-based or not), separate their concerns and roles, and provide a set of good practice guidelines for distributing data processing on the Computing Continuum. MDSC can be summarized as a composition of layers, consisting of units, connected by buses.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Modeling Infrastructures as Layers</head><p>Processing Layers A layer is an abstract representation of a subset of computing resources of an infrastructure. The main objective of a layer is to describe data processing and characterize the data flow among resources. The strategy for grouping resources is mainly related to the location of the resources and their processing objective.</p><p>For example, in an infrastructure composed of Edge, Fog and Cloud, there could be 3 different layers, one for each part of the infrastructure. Each layer groups resources with different characteristics.</p><p>Processing units are responsible for data processing (e.g., data transformation, aggregation, or filtering) by means of user-defined logic. Key components of processing units are libraries, data connectors and user-defined logic, that can be extended by system designers. The objective of modeling processing units is to have a straightforward and compact view of the available processing resources of a layer, of their composition and interactions. For example, in a ML application, a processing pod could define the Python Standard Library and scikit-learn <ref type="bibr" target="#b21">[22]</ref> as libraries, a Docker image containing an off-the-shelf third party software as user-defined logic, and an implementation of a Kafka connector class as a data connector.</p><p>Helper Units provide an environment from which processing units can benefit in order to process data. helper units may be ingestion systems, key-value stores, load-balancing servers, or proxy servers. Notice that a unit does not necessarily map to an entire machine. It can represent management resources and can be encapsulated by a virtual machine, a container, or a process.</p><p>Buses They connect layers or units inside a layer. Units inside of the same layer share the same network, however this is not necessarily the case for units from different layers. Helper units have the responsibility of pulling or receiving data through the network and making it accessible for processing units.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Modeling Applications as UDL Components</head><p>The main role of UDL (user-defined logic) components of processing units is to expose their data processing logic, i.e., the procedures defined by the user to transform the data. Consequently, UDL components are responsible for mapping the application itself and its placement among the different processing units and layers. For example, UDL components can be encapsulated in a Java program, a standalone binary, a container, or in the processing operators of a workflow/dataflow or stream processing engine, such as Flink.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Features</head><p>MDSC has two main features which help the application and infrastructure modeling process.</p><p>Organization is crucial when designing complex systems because of the amount of different technologies that need to work together, and their consequent configurations and characteristics. With MDSC, the concepts of layers and buses and processing/helper units help the designers organize and arrange together the different frameworks and technologies at their hands. While conceptually simple, these abstractions are powerful in terms of expressiveness (as illustrated in Section 4).</p><p>Separation of concerns is enhanced by organization. MDSC aims at grouping similar roles and functionalities together so that the interactions as well as the interference of the frameworks and technologies become clearer. We argue that besides helping the modeling process, these features allow for a compact and easy to understand way of abstracting an application, especially in environments shared by designers with different backgrounds (as it is often the case of ML applications). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">MODELING AND DEPLOYING A REAL-LIFE ML APPLICATION ON THE EDGE-TO-CLOUD CONTINUUM</head><p>In this section we illustrate the use of MDSC to model an ML-based Earthquake Early Warning system.</p><p>4.1 DMSEEW: An Algorithm for Distributed ML-Based Earthquake Early Warning Earthquake Early Warning (EEW) systems provide earthquake alerts before the shaking damage of a seismic event reaches sensitive areas, giving governments and communities a time window of seconds to minutes to take protective actions. Traditionally, EEW is executed in a fully centralized fashion with data from sensors being sent to Clouds.</p><p>In a previous work <ref type="bibr" target="#b15">[16]</ref>, we proposed moving part of the sensor data processing towards the Edge to speed-up detection while further enhancing network usage reduction, fault tolerance, and idle machines usage. The Distributed Multi-Sensor Earthquake Early Warning (DMSEEW) takes sensor-level class predictions (normal activity, medium earthquake or large earthquake) based on the data gathered by each sensor, aggregates them using a bag-of-words representation, and use it to predict the final earthquake category. A high-level illustration of DMSEEW and its important processing steps are presented in Figure <ref type="figure" target="#fig_1">1</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Modeling the DMSEEW Hierarchical Processing</head><p>By-sensor classification To perform the by-sensor classification, it is necessary to gather measurements streamed by each sensor and apply the WEASEL+MUSE <ref type="bibr" target="#b26">[27]</ref> classifier on those data. To gather and process the data without interrupting the stream, we use sliding windows configured to hold and then process 30 seconds of data every 1 second. The processing performed at the moment that the window data is evaluated can be summarized as sorting the data points and running the WEASEL+MUSE classifier on the resulting time-series. Hence, each sensor produces a stream of seismic measurements which is processed and transformed into a stream of predictions. By-region prediction Sensors are organized into regions, with the objective of predicting the magnitude of eventual seismic events in each of those regions. As sensors generate streams of by-sensor predictions, it is necessary to filter those streams by region, then, for each stream containing only predictions of a given region, to predict the final event category. For doing that, we use 1-second tumbling windows (i.e., processing abstractions that store the last 1 second of data before processing it) to gather predictions from a given region and we calculate the final prediction using the 1NN classifier on a normalized frequency vector of predictions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Deploying DMSEEW on the Edge-to-Cloud Continuum</head><p>MDSC EEW is a model of DMSEEW mapped on the hybrid infrastructure, based on MDSC (Figure <ref type="figure" target="#fig_0">2</ref>). In summary, it uses 4 layers: (i) Edge, where the data are produced; (ii) Fog, where data are pre-processed (by-sensor classification); (iii) Cloud, where the partially processed data are gathered and finally processed (by-region prediction); and (iv) Bus, connecting the above layers.</p><p>The Edge layer holds seismic sensors which act as processing units, grouped by region. Their only processing capability is sending the data to a predefined gateway server, located in the Fog. Each group within the Edge layer has one bus which models the LAN that connects all sensors isolated from the outside world and forwards sensor data to other networks. Note that in this example we consider 50 sensing regions; for each region we define a separate group of 20 processing units inside the Edge layer.</p><p>The Fog layer is essentially composed of gateway machines. They aggregate data coming from a set of sensors in the Edge and process them. For each of the 50 sensing regions we consider one fog-level gateway with an MQTT server, which ingests data coming from the sensors, and a Java program, that pulls data from the MQTT server, processes them and sends the results to the Cloud. Hence, we model every MQTT server as a helper unit and every Java program as a processing unit. Furthermore, processing units have access to different libraries such as Java JDK, Eclipse Paho, and WEASEL+MUSE. They describe the by-sensor classification step as user-defined logic and use connectors to the MQTT servers and to the Kafka cluster.</p><p>The Cloud layer is mainly composed of an Apache Kafka cluster, an Apache Zookeeper server, modeled as helper units, and an Apache Flink cluster, whose Task Managers are modeled as processing units. Apache Kafka brokers ingest the data, Apache Zookeeper manages Kafka metadata, and Flink processes the data pulled from Kafka and pushes the results back to Kafka. processing units rely on many libraries to process the data, such as Java SDK, the Flink API, and the ML library LIBSVM <ref type="bibr" target="#b5">[6]</ref>. These libraries are used by the userdefined logic component implementing the by-region prediction step (cf. Section 4.2).</p><p>Buses model the intra-and inter-processing layers communication. Each Edge-level group of processing units has its own LAN and can communicate with the corresponding Fog-level helper unit through high speed region LANs. The Fog layer communicates with the Cloud layer using Internet or a dedicated network.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">EVALUATION METHODOLOGY</head><p>To illustrate the versatility of the MDSC modeling, we used it to enable a comparative performance analysis of the Edge-based implementation of DMSEEW with various cloud-only implementations. The goal of this evaluation is to show that: a) MDSC is able to gracefully scale up to thousands of sensors and tens of processing nodes; b) MDSC isolates performance bottlenecks at various levels, from application to infrastructure; c) MDSC is able to identify trade-offs between Edge-to-Cloud and Cloud-only deployments; </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Baselines</head><p>The default Edge-to-Cloud MDSC implementation of EEW, using the WEASEL+MUSE predictor, is further denoted as WME and will be compared to three different baselines: WEASEL+MUSE EEW Cloud-only (WME-CO), Random EEW (RE), and Random EEW Cloudonly (RE-CO). They are all based on MDSC but differ in the layer where the by-sensor data processing is performed and the prediction library used for that purpose, as shown in Figure <ref type="figure" target="#fig_2">3</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>WME-CO</head><p>The by-sensor data processing step is performed on the Cloud, i.e., the Fog machines only forward the data produced by the sensors to the Cloud. The prediction library used is the same as MDSC, i.e., WEASEL+MUSE.</p><p>RE The by-sensor data processing is performed on the Fog, as in MDSC, using an integer pseudo-random generator as predictor. This baseline acts as a lower bound for Edge computing scenarios, since, in practice, there is no processing done for calculating the predictions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>RE-CO</head><p>The by-sensor data processing is performed uniquely on the Cloud and the by-sensor and the by-region predictions are calculated using an integer pseudo-random generator. This baseline acts as a lower bound for Cloud-only scenarios.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Fog Cloud</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>RE-CO</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>WME-CO</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Edge</head><p>Data Source </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Cyber-Infrastructure</head><p>We implemented the architecture described in Section 3 and deployed it on the gros cluster from the Grid'5000 experimental test bed <ref type="bibr" target="#b14">[15]</ref>. We rely on the prototype of an experimental platform <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b28">29]</ref> able to set up the environment, execute the experiments and gather metrics and results. This platform was designed based on a methodology ensuring the repeatability of the experiments, so that the comparison of MDSC with the baselines remains fair. In absolute numbers, the resulting distributed EEW system has  <ref type="table">1</ref>: Fog-to-Cloud network configurations used for the evaluation of MDSC EEW 1,000 sensors emulated by virtual machines deployed on 25 host machines. Each set of 20 sensors composes an Edge layer and it is connected to one of the 50 implemented Fog layers. All Fog layers communicate and transfer their data to one Cloud layer containing a 5-machine Apache Kafka cluster, a 5-machine Apache Flink cluster and one Apache Zookeeper server. We describe in detail in Table <ref type="table">1</ref> the values of bandwidth, minimum latency and jitter for each type of network configuration.</p><p>The end-to-end latency measures in milliseconds the time elapsed between the production of an event by a sensor and the prediction of the corresponding seismic event on the Cloud. This metric contains the by-sensor window processing time (maximum of 30s plus the classifier execution time) and the by-region window processing time (maximum of 1s plus the processing time). It also contains Edge-to-Fog and Fog-to-Cloud transfer times.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Datasets</head><p>Initially, our objective was to use real seismic data<ref type="foot" target="#foot_0">1</ref> from the American Incorporated Research Institutions for Seismology (IRIS) <ref type="bibr" target="#b0">[1]</ref>, as in <ref type="bibr" target="#b15">[16]</ref>. Nevertheless, with its size of 58MB from 897,060 data points, it is not large enough for stressing the infrastructure of the scenarios proposed in this work. Hence, we artificially generate data using the IRIS format. We generate 12,000 messages for each of the 1,000 sensors distributed in 50 regions with a frequency of 100Hz. Hence, each sensor produces 100 messages per second for 2 minutes (resulting in a total of 12,000,000 messages to be processed).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">EVALUATION RESULTS</head><p>We first assess the performance of the lower bound RE and RE-CO baselines. Then, we compare the WME and WME-CO scenarios, highlighting issues related to network and library constraints.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Random EEW: Lower Bounds</head><p>We start by presenting the performance of RE and RE-CO, the lower bound scenarios that are used as a basis of comparison to the other scenarios throughout this section. The main characteristic of those scenarios is that predictions are calculated through the generation of pseudo-random integers whenever the processing windows are ready to be evaluated. Due to that, the main performance bottleneck of this scenario is the network, as observed in Figure <ref type="figure" target="#fig_4">4</ref>.</p><p>The behavior of RE experiments is very similar because, in Edge computing scenarios, messages are aggregated in the Fog and only the predictions are sent to the Cloud, generating less data load on the network. Consequently, even on network constrained scenarios, the latencies only vary between 30 and 45 seconds. The difference between the amount of data transferred from the Fog to the Cloud is illustrated in Table <ref type="table" target="#tab_2">2</ref>. There are more than 13 times less data being sent to the Cloud compared to RE-CO scenarios.</p><p>On RE-CO experiments, the impact of network constraints is shown by the translation of the latency curves as the network characteristic changes. Observe that the RE-CO 10Gb scenario has better latency than the Edge scenarios, showing that, when the network is not constrained, processing everything on the Cloud can be a better option in terms of latency. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">MDSC EEW: Performance Overview</head><p>We can now discuss the performance of WME (the vanilla MDSC implementation of EEW on Edge-to-Cloud) using WME-CO, RE and RE-CO as baselines. We show that despite the amount of computing resources available, the latency of WME is directly affected by the choice of the classification library used in DMSEEW. The extent of the performance degradation caused by that library is further discussed using the results of WME-CO.</p><p>We illustrate the WME and WME-CO scenarios in Figure <ref type="figure" target="#fig_5">5</ref>. The main observation from this chart is the gap between the latencies of the WME and WME-CO experiments. While WME's latencies vary between 40 and 50 seconds, 90% of WME-CO latencies are above 100 seconds.</p><p>Starting with WME-CO, we observe very high latencies even for 10Gb scenarios. While the lower bound performance (cf. Figure <ref type="figure" target="#fig_4">4</ref>) indicated that 10Gb scenarios provide better latencies than Edge computing ones, in Figure <ref type="figure" target="#fig_5">5</ref> that scenario has latencies close to 400 seconds. We identify, however, a similar behavior of IE compared to the lower bound RE, but with slightly higher latencies, varying between 32s and 50s.</p><p>The behavior of WME-CO observed in Figure <ref type="figure" target="#fig_5">5</ref> can be explained by the existence of two bottlenecks: the network, in 2G and 3G scenarios, as discussed in Section 6.1, and the interaction between WEASEL+MUSE, the ML library used for predicting the sensorwise magnitudes of events, and Apache Flink. The implementation of WEASEL+MUSE <ref type="bibr" target="#b27">[28]</ref> is a prototype, hence, it is not optimized in terms of execution time complexity, and it is not thread-safe. Because of the latter, it is not possible to share the same instance of the model among processing window instances running in the same Flink Task Manager. Since there will be one new open window per sensor every 1 second and for 30 seconds, that procedure demands more memory than the available one on each Task Manager, slowing down the data processing due to garbage collection and swapping.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">RELATED WORK</head><p>A rich set of tools, libraries and frameworks are currently proposed at the intersection of Edge computing and ML. In this section, we provide an overview of the state of the art of the efforts from the converging communities of Big Data and Artificial Intelligence at the network edge.</p><p>Stream processing with ML libraries. In the Big Data community, the baseline approach for ML tasks like prediction and classification is to periodically transfer all the raw data from the Edge to the Cloud. Back-end stream processing frameworks like Apache Spark <ref type="bibr" target="#b33">[34]</ref> and Apache Flink <ref type="bibr" target="#b12">[13]</ref> perform advanced analytics once the data is collected. They are supported by rich dedicated libraries like MLlib <ref type="bibr" target="#b19">[20]</ref> and FlinkML <ref type="bibr" target="#b2">[3]</ref> respectively. These frameworks are greedy in terms of resources and cannot be executed on Edge nodes per se. Instead, some dedicated systems such as Azure IoT Edge <ref type="bibr" target="#b3">[4]</ref>, and the AWS IoT Greengrass <ref type="bibr" target="#b4">[5]</ref> can be used to offload the ML computations on the Edge nodes.</p><p>ML at the Edge. Several studies <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b20">21]</ref> identified the main vectors driving a shift towards using resources at the Edge of the network, near the data sources, building what is called the Edge intelligence <ref type="bibr" target="#b31">[32]</ref>: ML training and ML inference at the Edge.</p><p>Fast inference was initially achieved on single Edge devices. Instead of transmitting raw contextual data in the network, <ref type="bibr" target="#b23">[24]</ref> only transmits the inferred knowledge using incremental ML on the Edge nodes. DeepDecision <ref type="bibr" target="#b24">[25]</ref> and MCDNN <ref type="bibr" target="#b18">[19]</ref> take the offloading decision based on constraints such as the size of input data, the model to be executed, the tradeoffs between the inference accuracy, network latency and bandwidth. Most of these approaches are application specific. When applied to different contexts, the overhead of the adaptation increases the inference latency particularly on high-dimensional input data and on mobile devices <ref type="bibr" target="#b20">[21]</ref>.</p><p>Edge-enhanced architectures Distributed deep learning has motivated the use of computing hierarchies by splitting neural network <ref type="bibr" target="#b30">[31]</ref> or using sparse updates <ref type="bibr" target="#b29">[30]</ref> to aggressively reduce communication costs. However, these works are either not resilient/sensitive to topology changes <ref type="bibr" target="#b32">[33]</ref> or rely on unsuitable resource management for service delivery <ref type="bibr" target="#b11">[12]</ref>. Previous work from authors have explored Edge-enhanced infrastructures for Urgent Science and large-scale application <ref type="bibr" target="#b9">[10]</ref>.</p><p>Conclusion Different from these works, our architecture for ML executions on the Continuum: (i) is general enough to be adapted to any application, in any context, without loss of efficiency, and (ii) holistically considers the deployment issues of ML on Edge/Cloud nodes (i.e., communication and computation constraints).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">CONCLUSION AND FUTURE WORK</head><p>In this paper we present MDSC, an approach for modeling distributed stream-based applications on Edge-to-Cloud continuum infrastructures. It uses interconnected layers and units to model the core components of an application, such as libraries, data processing and management tools. We illustrate the versatility of MDSC by modeling of a complex real-life ML application, that was deployed on an Edge-to-Cloud infrastructure emulated atop Grid'5000.</p><p>As future work, we are looking into developing the description of the helper units to reflect their internal configuration and libraries, which can have an impact on the application performance. Another interesting research direction is the design of scheduling algorithms that help designers decide where to deploy processing units on the different available layers of a hybrid infrastructure.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>2</head><label>2</label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Earthquake Early Warning use-case (DMSEEW).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>REFigure 3 :</head><label>3</label><figDesc>Figure 3: Baselines summary according to the layers used for by-sensor and by-region processing.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>Distributed Stream Processing across the Edge-to-Cloud Continuum Woodstock '18, June 03-05, 2018, Woodstock, NY 2G (0.3Mb/s), Edge 2G (0.3Mb/s), Cloud-only 3G (2Mb/s), Edge 3G (2Mb/s), Cloud-only 10Gb (10Gb/s), Edge 10Gb (10Gb/s),</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Latency resulting from processing one seismic event on lower bound scenarios RE and RE-CO.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Latency resulting from processing one seismic event on WME and WME-CO scenarios.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>Amount of messages transferred between Fog and Cloud on different network configurations for WME and WME-CO experiments. The same behavior is observed on RE and RE-CO experiments.</figDesc><table><row><cell cols="4">WME-2G/3G/10Gb WME-CO-3G WME-CO-2G WME-CO-10GB</cell></row><row><cell>9,100</cell><cell>1,647,126</cell><cell>11,695,871</cell><cell>12,000,000</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>https://figshare.com/articles/EarthquakeEarlyWarningDataset/9758555</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Incorporated Research Institutions for Seismology</title>
		<ptr target="https://www.iris.edu/" />
		<imprint>
			<date type="published" when="2020-05-25">25-May-2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<ptr target="https://cloud.google.com/iot-edge/" />
		<title level="m">Google Cloud IoT Edge</title>
		<imprint>
			<date type="published" when="2015">2015. 15-April-2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<ptr target="https://ci.apache.org/projects/flink/flink-docs-release-1.4/dev/libs/ml/" />
		<title level="m">Apache FlinkML</title>
		<imprint>
			<date type="published" when="2019">2019. 15-April-2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<ptr target="https://github.com/Azure/ai-toolkit-iot-edge" />
		<title level="m">AI Toolkit for Azure IoT Edge</title>
		<imprint>
			<date type="published" when="2020-04">2020. 15-April-2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<ptr target="https://aws.amazon.com/greengrass/" />
		<title level="m">AWS IoT Greengrass</title>
		<imprint>
			<date type="published" when="2020-04">2020. 15-April-2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<ptr target="https://www.csie.ntu.edu.tw/~cjlin/libsvm/" />
		<title level="m">LIBSVM -A Library for Support Vector Machines</title>
		<imprint>
			<date type="published" when="2020-05-25">2020. 25-May-2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<ptr target="https://azure.microsoft.com/en-us/services/iot-edge/" />
		<title level="m">Microsoft Azure IoT Edge</title>
		<imprint>
			<date type="published" when="2020-04">2020. 15-April-2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">TensorFlow: A system for large-scale machine learning</title>
		<author>
			<persName><forename type="first">M</forename><surname>Abadi</surname></persName>
		</author>
		<ptr target="https://www.usenix.org/system/files/conference/osdi16/osdi16-abadi.pdf" />
	</analytic>
	<monogr>
		<title level="m">12th USENIX Symposium on Operating Systems Design and Implementation (OSDI 16)</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="265" to="283" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Towards a computing continuum: Enabling edge-to-cloud integration for data-driven workflows</title>
		<author>
			<persName><surname>Balouek-Thomert</surname></persName>
		</author>
		<idno type="DOI">10.1177/1094342019877383</idno>
		<ptr target="https://doi.org/10.1177/1094342019877383" />
	</analytic>
	<monogr>
		<title level="j">The International Journal of High Performance Computing Applications</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1159" to="1174" />
			<date type="published" when="2019-11">2019. Nov. 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Harnessing the Computing Continuum for Urgent Science</title>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Balouek-Thomert</surname></persName>
		</author>
		<idno type="DOI">10.1145/3439602.3439618</idno>
		<ptr target="https://doi.org/10.1145/3439602.3439618" />
	</analytic>
	<monogr>
		<title level="j">SIGMETRICS Perform. Eval. Rev</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="41" to="46" />
			<date type="published" when="2020-11">2020. Nov. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Harnessing the computing continuum for programming our world</title>
		<author>
			<persName><surname>Beckman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Fog Computing: Theory and Practice</title>
		<imprint>
			<biblScope unit="page" from="215" to="230" />
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Bringing the cloud to the edge</title>
		<author>
			<persName><forename type="first">C</forename><surname>Hyunseok</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Communications Workshops (INFOCOM WKSHPS)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2014">2014. 2014</date>
			<biblScope unit="page" from="346" to="351" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Apache Flink: Stream and Batch Processing in a Single Engine</title>
		<author>
			<persName><forename type="first">P</forename><surname>Carbone</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Data Engineering Bulletin</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">01</biblScope>
			<date type="published" when="2015">2015. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Deep Learning With Edge Computing: A Review</title>
		<author>
			<persName><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Ran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. IEEE</title>
		<imprint>
			<biblScope unit="volume">107</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1655" to="1674" />
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Adding Virtualization Capabilities to the Grid&apos;5000 Testbed</title>
		<author>
			<persName><forename type="first">F</forename><surname>Desprez</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-319-04519-1_1</idno>
		<ptr target="https://doi.org/10.1007/978-3-319-04519-1_1" />
	</analytic>
	<monogr>
		<title level="s">Cloud Computing and Services Science. Communications in Computer and Information Science</title>
		<imprint>
			<biblScope unit="volume">367</biblScope>
			<biblScope unit="page" from="3" to="20" />
			<date type="published" when="2013">2013</date>
			<publisher>Springer International Publishing</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A Distributed Multi-Sensor Machine Learning Approach to Earthquake Early Warning</title>
		<author>
			<persName><forename type="first">K</forename><surname>Fauvel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Thirty-Fourth AAAI Conference on Artificial Intelligence</title>
		<meeting>the Thirty-Fourth AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Distributed Operator Placement for IoT Data Analytics Across Edge and Cloud Resources</title>
		<author>
			<persName><forename type="first">E</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Gibert</forename><surname>Renart</surname></persName>
		</author>
		<idno type="DOI">10.1109/CCGRID.2019.00060</idno>
		<ptr target="https://doi.org/10.1109/CCGRID.2019.00060" />
	</analytic>
	<monogr>
		<title level="m">CCGrid 2019 -19th Annual IEEE/ACM International Symposium in Cluster, Cloud, and Grid Computing</title>
		<meeting><address><addrLine>Larnaca, Cyprus</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1" to="10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Protonn: Compressed and accurate knn for resourcescarce devices</title>
		<author>
			<persName><forename type="first">C</forename><surname>Gupta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 34th International Conference on Machine Learning</title>
		<meeting>the 34th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="page" from="1331" to="1340" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">MCDNN: An Approximation-Based Execution Framework for Deep Stream Processing Under Resource Constraints</title>
		<author>
			<persName><forename type="first">S</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">14th Annual International Conference on Mobile Systems, Applications, and Services</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="123" to="136" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">MLlib: Machine Learning in Apache Spark</title>
		<author>
			<persName><forename type="first">X</forename><surname>Meng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1235" to="1241" />
			<date type="published" when="2016">2016. 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Machine Learning at the Network Edge: A Survey</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">G</forename><surname>Sarwar Murshed</surname></persName>
		</author>
		<idno>arXiv (07</idno>
		<imprint>
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Scikit-learn: Machine learning in Python</title>
		<author>
			<persName><forename type="first">F</forename><surname>Pedregosa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of machine learning research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2825" to="2830" />
			<date type="published" when="2011-10">2011. Oct (2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Scikit-Learn: Machine Learning in Python</title>
		<author>
			<persName><forename type="first">F</forename><surname>Pedregosa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Varoquaux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gramfort</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Michel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Thirion</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Grisel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Blondel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Prettenhofer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Dubourg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Vanderplas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Passos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Cournapeau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Brucher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Perrot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Duchesnay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2825" to="2830" />
			<date type="published" when="2011">2011. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Leveraging Edge Computing through Collaborative Machine Learning</title>
		<author>
			<persName><forename type="first">K</forename><surname>Portelli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Anagnostopoulos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 5th International Conference on Future Internet of Things and Cloud Workshops</title>
		<imprint>
			<biblScope unit="page" from="164" to="169" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">DeepDecision: A Mobile Deep Learning Framework for Edge Video Analytics</title>
		<author>
			<persName><forename type="first">X</forename><surname>Ran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE INFOCOM 2018 -Conference on Computer Communications</title>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="1421" to="1429" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">E2Clab: Exploring the Computing Continuum through Repeatable, Replicable and Reproducible Edge-to-Cloud Experiments</title>
		<author>
			<persName><forename type="first">Rosendo</forename><surname>Daniel</surname></persName>
		</author>
		<idno type="DOI">10.1109/CLUSTER49012.2020.00028</idno>
		<ptr target="https://doi.org/10.1109/CLUSTER49012.2020.00028" />
	</analytic>
	<monogr>
		<title level="m">Cluster 2020 -IEEE International Conference on Cluster Computing</title>
		<meeting><address><addrLine>Kobe, Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="1" to="11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Multivariate Time Series Classification with WEASEL+MUSE</title>
		<author>
			<persName><forename type="first">P</forename><surname>Schäfer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Leser</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017. 2017</date>
		</imprint>
	</monogr>
	<note type="report_type">ArXiv</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Last accessed on</title>
		<author>
			<persName><forename type="first">P</forename><surname>Schäfer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Leser</surname></persName>
		</author>
		<ptr target="https://github.com/patrickzib/SFA" />
	</analytic>
	<monogr>
		<title level="m">WEASEL MUSE Artifact</title>
		<imprint>
			<date type="published" when="2020-05">May 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Towards a Methodology for Benchmarking Edge Processing Frameworks</title>
		<author>
			<persName><forename type="first">P</forename><surname>Silva</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Parallel and Distributed Processing Symposium Workshops (IPDPSW)</title>
		<imprint>
			<date type="published" when="2019">2019. 2019</date>
			<biblScope unit="page" from="904" to="907" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">eSGD: Communication Efficient Distributed Deep Learning on the Edge</title>
		<author>
			<persName><forename type="first">Zeyi</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">HotEdge</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Distributed DNN over the Cloud, the Edge and End Devices</title>
		<author>
			<persName><forename type="first">S</forename><surname>Teerapittayanon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Mcdanel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">T</forename><surname>Kung</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1709.01921</idno>
		<imprint>
			<date type="published" when="2017">2017. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Convergence of Edge Computing and Deep Learning: A Comprehensive Survey</title>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Communications Surveys Tutorials</title>
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">ApproxIoT: Approximate Analytics for Edge Computing</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Wen</surname></persName>
		</author>
		<idno type="DOI">10.1109/ICDCS.2018.00048</idno>
		<ptr target="https://doi.org/10.1109/ICDCS.2018.00048" />
	</analytic>
	<monogr>
		<title level="m">IEEE 38th International Conference on Distributed Computing Systems (ICDCS)</title>
		<imprint>
			<date type="published" when="2018">2018. 2018</date>
			<biblScope unit="page" from="411" to="421" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Apache Spark: A Unified Engine for Big Data Processing</title>
		<author>
			<persName><forename type="first">M</forename><surname>Zaharia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Commun. ACM</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="56" to="65" />
			<date type="published" when="2016-10">2016. oct 2016</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
