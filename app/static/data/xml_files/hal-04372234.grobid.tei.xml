<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A Framework to Assess Knowledge Graphs Accountability</title>
				<funder ref="#_k7M3sdh #_jAMUFKN #_nyUwpwD">
					<orgName type="full">unknown</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Jennie</forename><surname>Andersen</surname></persName>
							<email>jennie.andersen@insa-lyon.fr</email>
						</author>
						<author>
							<persName><forename type="first">Sylvie</forename><surname>Cazalens</surname></persName>
							<email>sylvie.cazalens@insa-lyon.fr</email>
						</author>
						<author>
							<persName><forename type="first">Philippe</forename><surname>Lamarre</surname></persName>
							<email>philippe.lamarre@insa-lyon.fr</email>
						</author>
						<author>
							<persName><forename type="first">Pierre</forename><surname>Maillot</surname></persName>
							<email>pierre.maillot@inria.fr</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Univ. Lyon</orgName>
								<orgName type="institution" key="instit2">INSA Lyon</orgName>
								<orgName type="institution" key="instit3">CNRS</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution" key="instit1">UCBL</orgName>
								<orgName type="institution" key="instit2">LIRIS</orgName>
								<address>
									<postCode>UMR5205</postCode>
									<settlement>Villeurbanne</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="institution" key="instit1">Univ. Lyon</orgName>
								<orgName type="institution" key="instit2">INSA Lyon</orgName>
								<orgName type="institution" key="instit3">CNRS</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="institution" key="instit1">UCBL</orgName>
								<orgName type="institution" key="instit2">LIRIS</orgName>
								<address>
									<postCode>UMR5205</postCode>
									<settlement>Villeurbanne</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff4">
								<orgName type="institution" key="instit1">Univ. Lyon</orgName>
								<orgName type="institution" key="instit2">INSA Lyon</orgName>
								<orgName type="institution" key="instit3">CNRS</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff5">
								<orgName type="institution" key="instit1">UCBL</orgName>
								<orgName type="institution" key="instit2">LIRIS</orgName>
								<address>
									<postCode>UMR5205</postCode>
									<settlement>Villeurbanne</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff6">
								<orgName type="institution">Univ. Cote d&apos;Azur</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff7">
								<orgName type="institution" key="instit1">Inria</orgName>
								<orgName type="institution" key="instit2">CNRS</orgName>
								<orgName type="institution" key="instit3">I3S Sophia Antpolis</orgName>
								<address>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">A Framework to Assess Knowledge Graphs Accountability</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">7503A323417D29CDC1840C20346D0B1E</idno>
					<idno type="DOI">10.1109/WI-</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-04-12T14:49+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Dataset accountability</term>
					<term>RDF graphs</term>
					<term>Evaluation Framework</term>
					<term>Data Quality I. INTRODUCTION</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Knowledge Graphs (KGs), and Linked Open Data in particular, enable the generation and exchange of more and more information on the Web. In order to use and reuse these data properly, the presence of accountability information is essential. Accountability requires specific and accurate information about people's responsibilities and actions. In this article, we define KGAcc, a framework dedicated to the assessment of RDF graphs accountability. It consists of accountability requirements and a measure of accountability for KGs. Then, we evaluate KGs from the LOD cloud and describe the results obtained. Finally, we compare our approach with data quality and FAIR assessment frameworks to highlight the differences.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Therefore, every KG holding personal information, such as Wikidata, should provide contact information of this controller, i.e. a person responsible for the data, and ideally allow users to access it directly via its SPARQL endpoint. As another example, to avoid misinterpretation and to improve the (re)use of the data, it is often necessary to know for what purpose they were created, and for whom the data are intended. For instance, in some database mainly dedicated to teaching purposes, such as the MONDIAL Database<ref type="foot" target="#foot_0">2</ref> , some inaccuracies can be tolerated (or even desired). However, it cannot be reused without precaution for other purposes. Therefore, it should indicate its intended audience or its expected usage. However, when querying its SPARQL endpoint, this information is not available. Accountability ensures that this kind of information of major interest is effectively available. Several studies are already looking for meta-information, either as some particular aspects of data quality <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr" target="#b5">[6]</ref>, or as some requirements of the FAIR principles (Findability, Accessibility, Interoperability, Reproducibility) <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b9">[10]</ref>. Yet, they neither take into account the information used in the two previous examples nor several other accountability information. This highlights the importance of accountability as a specific and distinct characteristic of RDF datasets and the importance of their evaluation w.r.t. this aspect.</p><p>Hence, in this paper, we propose a new framework, KGAcc, dedicated to the assessment of RDF graphs accountability. It consists of organized accountability requirements and a measure of accountability. We experiment it on many KGs offering a publicly available SPARQL endpoint. Our accountability measure gives an indication of the accountability of KGs to dataset users and providers. It aims to guide users in their choice of one KG rather than another and to help providers to identify ways to improve their datasets.</p><p>To define such a measure, several questions arise, such as what meta-information is required? How to evaluate heterogeneous KGs? First, to define requirements, we rely on the LiQuID metadata model which focuses on dataset accountability <ref type="bibr" target="#b0">[1]</ref> in general. It provides an explicit list of accountability requirements expressed in natural language. The problem, then, is to adapt this model to the specificities of knowledge graphs and to define the requirements in terms of SPARQL queries. To evaluate the KGs, we use the SPARQL-based test suite of the IndeGx framework <ref type="bibr" target="#b10">[11]</ref>. We observe that most of them do not provide any easily accessible accountability information. However, as some KGs do answer some questions, it shows that our demand is reasonable and that KGs have a lot of room for improvement. In addition, to illustrate the specificities of this measure, we compare it with several assessment frameworks for data quality and FAIRness.</p><p>The rest of the article is organized as follows. Section II describes the state of the art. We define the KGAcc framework in Section III. Then, Section IV is devoted to the description of the methodology for evaluating RDF graphs and the results obtained. We then compare our accountability measure with the existing assessments of knowledge graphs in Section V. Finally, we conclude in the last section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. RELATED WORK</head><p>Generally speaking, accountability requires that there is sufficient information to describe the data <ref type="bibr" target="#b0">[1]</ref>, the actions on the data, from its creation <ref type="bibr" target="#b11">[12]</ref> to its use <ref type="bibr" target="#b1">[2]</ref>, and the people responsible for these data as well as these actions <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b1">[2]</ref>. It may concern different levels of the information system, such as information accountability <ref type="bibr" target="#b1">[2]</ref>, <ref type="bibr" target="#b11">[12]</ref>, systems <ref type="bibr" target="#b12">[13]</ref>, and dataset accountability <ref type="bibr" target="#b0">[1]</ref>. To evaluate the accountability of knowledge graphs, we focus on this latter point. The accountability of knowledge graphs may be considered as part of their data quality, in the broad sense. These last years, several studies have highlighted the many facets of the notion <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr" target="#b5">[6]</ref>. In addition, general monitoring tools such as SPARQLES <ref type="bibr" target="#b13">[14]</ref> and YummyData <ref type="bibr" target="#b14">[15]</ref> have been proposed, enabling to assess and draw profiles of SPARQL endpoints.</p><p>As a matter of fact, measuring the accountability of KGs is a special case of assessing metadata completeness, which is defined as "the degree to which metadata properties and values are not missing in a dataset for a given task" <ref type="bibr" target="#b15">[16]</ref>. Many works consider the presence of meta-information to evaluate knowledge graphs. Studies about the data quality of KGs <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr" target="#b5">[6]</ref> include many different metrics, among which a few focus on meta-information. For instance, provenance information is required by a metric on trustworthiness. The FAIR principles <ref type="bibr" target="#b9">[10]</ref> are also interested in meta-information. One of the principles of findability states that "data [must be] described with rich metadata", and reusability requires that "meta(data) are richly described with a plurality of accurate and relevant attributes", including a license, and provenance information. Therefore, the required meta-information may overlap between accountability, data quality and FAIRness while having their own specificities. Because of the high variability of the actual implementations of these metrics and principles, we confront them with our own requirements at the scale of the RDF properties in section V.</p><p>In order to define the KGAcc framework to measure the accountability of KG, we base our work on the LiQuID metadata model <ref type="bibr" target="#b0">[1]</ref> which considers datasets in general. It offers a way for datasets to represent accountability meta-information throughout their life cycle. The model has been validated based on a real-world workload that relies on existing regulations (such as the GDPR) and an expert survey. To our knowledge, it is the only one to provide such a precise and explicit list of accountability requirements, presented in the form of questions that describe the model. Our framework adapts the hierarchy and the associated questions of LiQuID, taking into account the expressiveness of the most common vocabularies. It provides the requirements as a set of SPARQL queries corresponding to the questions. Our very first experiments are shortly reported in <ref type="bibr" target="#b16">[17]</ref>. The work described in this paper relies on (i) new experiments that enable to distinguish between each dataset of a SPARQL endpoint, and ii) improved queries, taking into account more vocabularies. In addition, we provide a thorough comparison with other evaluation frameworks <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr" target="#b5">[6]</ref>, <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b8">[9]</ref>.</p><p>Finally, in order to conduct our experiments and to query KGs with our own set of queries, several frameworks can be used. Luzzu <ref type="bibr" target="#b4">[5]</ref> and Sieve <ref type="bibr" target="#b17">[18]</ref> enable users to choose metrics among those defined and to declare new ones. Monitoring tools, such as SPARQLES <ref type="bibr" target="#b13">[14]</ref>, also enable assessing some quality aspects. Instead of these, we choose the IndeGx framework <ref type="bibr" target="#b10">[11]</ref> because it relies entirely on SPARQL queries, unlike Sieve and Luzzu, and is easily extendable. The IndeGx framework enables querying many KGs, with multiple queries, and storing the results in RDF. Its primary use case is to build an index of KGs and thus to extract and compute various information about them using a SPARQL-based test suite. To evaluate KG accountability, we use it as an engine to submit our own queries to KGs and to store the evaluation results in RDF.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. ACCOUNTABILITY REQUIREMENTS AND METRIC</head><p>In this section, we define the KGAcc framework. We define the requirements of knowledge graphs accountability, i.e. the precise information that KGs must contain. To be as unambiguous as possible, we go one step further in expressing these requirements using SPARQL queries. Finally, we formally define the metric of accountability. Our proposal is based on the LiQuID metadata model <ref type="bibr" target="#b0">[1]</ref> that enables the representation of information related to the accountability of datasets. To illustrate the use of their model, they provide precise questions that a dataset must answer to be considered accountable. LiQuID is not specific to any type of dataset, so it is necessary to adapt it.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. The LiQuID Metadata Model of Accountability</head><p>The LiQuID metadata model relies on a hierarchical structure. First, it covers all steps of a dataset's life cycle: data collection, processing, maintenance and usage. Then, each life cycle step is structured according to different question types: why, who, when, where, how and what. Finally, each question type is divided into different fields of information level: description, explanation, legal and ethical considerations and limitations. The authors provide an exhaustive list of questions to describe each aspect of this hierarchy. For instance, for "data  In what physical location can the KG be used? 1</p><p>processing", question type "when", the question associated with the field "description" is "On what date(s) or time frame(s) has the data been processed?". The LiQuID approach proceeds in a very systematic way and requires a large amount of very detailed information, representing what data sources should expose to be as accountable as possible.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Adaptation of LiQuID for Knowledge Graphs</head><p>Ideally, to assess the accountability of a KG, we should consider all LiQuID questions. However, it is not possible for all questions to be adapted for KGs and translated into SPARQL queries.</p><p>Indeed, as shown by Oppold and Herschel <ref type="bibr" target="#b0">[1]</ref>, the two general metadata models Dublin Core 3 and PROV <ref type="bibr" target="#b18">[19]</ref>, cannot cover all the fields proposed by LiQuID. According to them, both models "contain few fields, some of them too general to be mapped to specific LiQuID fields". We make the same observation with other general metadata models used in KGs, especially if the task is not to provide the information required by the model, but to query it. As a consequence of this lack of expressiveness, some questions cannot be translated into queries. As an example, some fields of the information level require too specific information, such as "Why is it lawful to collect this kind of data?", which, to our knowledge, cannot be expressed in a KG using existing vocabularies. As another example, two questions result in the same query for different steps of the life cycle, this is in particular the case for the collection and processing steps.</p><p>Faced with these difficulties, we opt for a soft strategy in which the maximum score of accountability seems attainable to us. It consists in keeping only questions compatible with the 3 https://dublincore.org/specifications/dublin-core/dcmi-terms/ most common vocabularies of the semantic web. Therefore, we make the following adaptations: (i) only the field "description" of the information level is considered, (ii) the data processing step of the life cycle level is merged into the data collection step, (iii) the question types "why", "what" in "data collection" and "what" in "data maintenance" are not considered, and (iv) two questions concerning the exact methods and tools used for creation and maintenance are not considered in favor of more flexible questions concerning the methodology or procedure only. The resulting hierarchy is shown in Figure <ref type="figure" target="#fig_0">1</ref>. As for the rest of the paper, we omit the last level, as it only contains the "description" element.</p><p>This definition of the accountability requirements, guided by the desire to ask reasonable questions, leads to a core set of 23 LiQuID questions (out of 207). We then define the KGAcc requirements by adapting these questions to the context of KGs. We make them more precise, and divide them into smaller parts, so they focus on only one element each. This precision is made as faithfully as possible, with the aforementioned limitations. Table <ref type="table" target="#tab_0">I</ref> illustrates this adaptation. Therefore, the KGAcc framework results in 30 questions: 5 for Data Collection, 5 for Data Maintenance, and 20 for Data Usage. The totality of the questions is available on GitHub<ref type="foot" target="#foot_1">4</ref> .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. SPARQL Implementation of the Questions</head><p>Once the questions have been defined, each of them is translated into a SPARQL query or a succession of SPARQL queries. We use more than ten vocabularies of reference, chosen regarding their relevance to describe datasets and concepts around: VoID <ref type="bibr" target="#b19">[20]</ref> is used to express metadata about RDF datasets. DCAT <ref type="foot" target="#foot_2">5</ref> and DataID<ref type="foot" target="#foot_3">6</ref> allow the description of datasets and catalogs of datasets. SPARQL-SD <ref type="bibr" target="#b20">[21]</ref> enables to describe SPARQL endpoints. These vocabularies rely on other general vocabularies, the Dublin Core, FOAF <ref type="foot" target="#foot_4">7</ref> and SKOS <ref type="foot" target="#foot_5">8</ref> . We also use PROV-O and PAV <ref type="bibr" target="#b21">[22]</ref> for provenance issues. DQV <ref type="foot" target="#foot_6">9</ref> is used to describe the quality of datasets. Finally, we use schema.org a very general and widely used vocabulary, and some specific vocabularies for licenses, such as Creative Commons <ref type="foot" target="#foot_7">10</ref> . Each query uses all coherent properties and classes of these vocabularies to be as complete as possible. Listing 1 shows an example of a question translated into a query, where ?kg must be replaced by the IRI of the knowledge graph at hand. As queries are associated with questions requiring answers, they are "ASK" queries. The answer TRUE is considered a success, as it means that the KG contains the desired information. On the opposite, the answer FALSE or an error (e.g., timeout exception) is a failure, as it means the KG is unable to provide the wanted information.</p><p>Finally, notice that to express our precise requirements, we can either use the queries in their extended version, including all possible ways of expressing the required information, as in Listing 1. Alternatively, we can express the requirements in the form of a compact query, as in Listing 2, completed with a set of equivalences between properties (and between more complex graph patterns if necessary).</p><p>Listing 2. Compact query associated with "Who publishes this dataset?" PREFIX dct: &lt;http://purl.org/dc/terms/&gt; ASK { ?kg dct:publisher ?publisher . }</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Definition of the Metric</head><p>First, we define the score obtained for each question. Then it is possible to determine the score of each node of the KGAcc hierarchy defined in Figure <ref type="figure" target="#fig_0">1</ref>, from the bottom to the top. The score at the top of the hierarchy is the overall accountability score.</p><p>A successful query gives a score of 1 to its associated question, while a failure gives 0. The score of a question associated with a succession of queries is the average of the score given by each query. The accountability score of a leaf of the KGAcc hierarchy (e.g. "data usage -who") is the weighted average of the scores obtained for its associated questions. Notice that LiQuID does not weight its questions, which suggests they are of equal importance. To stay close to this, we use to the following rule. When m (m ≥ 1) KGAcc questions come from a same LiQuID question, a weight of 1/m is associated to each of them. Table I illustrates these weights. For instance, "data usage -who" has three questions, coming from two LiQuID questions. The first leads to one question, so its weight is 1, and the second leads to two questions, therefore their weight is 1/2 each. The accountability score of "data usage -who" is the weighted average of these three questions, with the weights of 1, 1/2, and 1/2. For the other elements of the hierarchy, we determine their score by computing the (nonweighted) average of the scores of the elements underneath.</p><p>Formally, let g be a knowledge graph, ℓ a leaf node of the KGAcc hierarchy (e.g. "data usage -who"), and let Q(ℓ) denote all questions associated with ℓ. With score a function giving the score of g for a given question q, w q the weight of question q, the accountability score of g w.r.t. ℓ is:</p><formula xml:id="formula_0">accountability(g, ℓ) = q∈Q(ℓ) w q • score(g, q) q∈Q(ℓ) w q (1)</formula><p>and the score of a given node n of the KGAcc hierarchy which is not a leaf is:</p><formula xml:id="formula_1">accountability(g, n) = n ′ child of n accountability(g, n ′ ) number of children of n<label>(2)</label></formula><p>In particular, the global accountability score is the score for the upper node in the hierarchy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. EXPERIMENTATION AND RESULTS</head><p>In this section, we describe our experiments. First, we detail the method employed to conduct an evaluation campaign of several KGs. Then, we discuss two aspects of the results. First, we examine the capabilities of knowledge graphs with regard to accountability. Second, we discuss the measure itself and the relevance of the KGAcc questions. All our queries and results are publicly available on our GitHub repository <ref type="foot" target="#foot_8">11</ref> .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Processing and Tool</head><p>To evaluate a knowledge graph, we first need to identify its IRI within its own data. Then, we proceed in several stages to evaluate how the KG answers the queries defined in the previous section.</p><p>An important prerequisite of all our queries is to identify the IRI that the studied KG uses to refer to itself, or more precisely, the IRIs of the datasets it contains. Indeed, this IRI is the subject of at least one triple in all our queries, as illustrated in Listing 1. Therefore, a query looking for the IRI is defined and presented in Listing 3, where $rawEndpointUrl is replaced by the URL of the endpoint during evaluation. If the KG does not provide an answer to this query, it will not answer any of our queries. In order to reduce the complexity of the queries sent to KGs, we focus on the accountability requirements in their compact form (cf. Listing 2). So, we proceed according to the following steps. For each KG, we first extract the triples corresponding to its metadata. As explained before, we use queries that begin with the lines described in Listing 3 to identify them. Then, we saturate this description of the KG by adding equivalent properties and classes, as defined by the requirements. Finally, we evaluate a KG according to this saturated metadata, using compact queries.</p><p>To carry out all these steps, we use the framework IndeGx 12 . It relies on a SPARQL-based test suite and can pre-process some steps for a better scalability. To it, we provide SPARQL queries and configure the actions to be taken based on their results, i.e. which triples to write or update in the resulting RDF graph. So, we embed a set of queries into the framework, following the steps previously detailed, and declare how to store the result (True or False) for each evaluation query and for each KG using the DQV Vocabulary.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Querying of the SPARQL Endpoints</head><p>Our experiments query the 336 SPARQL endpoints already identified by IndeGx, extracted from LOD Cloud, Wikidata, SPARQLES, Yummy Data, and Linked Wiki in February 2023. These endpoints were queried at three different time points in June 2023. For each endpoint, only the results of an experiment for which it was available are kept. In this way, KGs are not penalized if they were unavailable at a given time. All endpoints not succeeding the query of Listing 3 are assigned an accountability score of 0, as no triple concerning its KG could be extracted.</p><p>Finally, given the results obtained for each query and thus each question, the accountability score can be computed. As defined in subsection III-D, an average is used to calculate the score for each aspect of the KGAcc hierarchy of Figure <ref type="figure" target="#fig_0">1</ref>, until the overall accountability score is obtained.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Analysis of the Results</head><p>Among the 336 endpoints tested, only 26 successfully provide accountability information (Listing 3). The others were unavailable or did not provide easily accessible 12 https://github.com/Wimmics/dekalog meta-information within their data. Among the 26 endpoints, 166 different datasets were identified (in the sense of dcat:Dataset or void:Dataset. . . ), with accountability scores varying between 3.1% and 59%, with an average score of 26%. Even though most of the KGs do not provide any accountability information, the distribution of the values shows that this measure allows to discriminate between the datasets and the 26 endpoints left. On average, KGs are more accountable concerning "data usage" (41%) than "data collection" (25%), and twice better on "data collection" than on "data maintenance" (12%).</p><p>URLs start with http(s):// and, except for *, end with /sparql. Figure <ref type="figure" target="#fig_2">2</ref> shows the accountability score of the best dataset of each endpoint. This score is divided according to the three life cycle steps "data collection", "data maintenance" and "data usage". It is possible to compare two datasets in more detail. As an example, Figure <ref type="figure" target="#fig_1">3</ref> shows the strengths and weaknesses of the main dataset of http://caligraph.org/sparql and of http: //wasabi.inria.fr/sparql according to the life cycle steps (3a) and more precisely on the question types of the "data usage" step (3b).  The small number of KGs having a non-zero accountability score is not surprising. This observation is in line with other results <ref type="bibr" target="#b22">[23]</ref> showing that less than 10% of KGs provide selfdescriptions within their data. However, for some KGs, it is possible that some meta-information may be present outside of the KG itself, for instance on their web page, or inside the KG but not findable in the way shown in Listing 3. While not taking them into account may penalize some KGs, it points out the fact that they are less transparent because the information is less accessible.</p><p>Several reasons may explain the scores obtained on the different life cycle steps. The "data usage" step covers general description elements that are widely used such as a description, a publisher, or a license, that more than half of the 26 endpoints provide. Furthermore, it encompasses all questions involving VoID vocabulary, which are each answered at least once by more than 50% of the endpoints on average. "Data usage" also requires a link to the endpoint or a dump, so having an answer to this question is expected considering how we identify the IRI of the KG. "Data maintenance" usually has bad scores. This may be due to the fact that half of the questions have only one possible property, with no alternative. For instance, the modification frequency can only be obtained with the property accrualPeriodicity from the Dublin Core vocabulary. This lack of alternative solutions to express this concept makes it more difficult to answer the query and highlights the fact that the question is more unusual. "Data has various results with very common requirements, such as the creator and the creation date, and more difficult questions to answer such as the creation method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Discussion about the KGAcc Framework</head><p>As far as the framework is concerned, at least two questions can be asked: are the requirements relevant? Are they too demanding? Figure <ref type="figure">4</ref> provides some answers. It represents the distribution of the values of accountability of the best dataset of each endpoint w.r.t. each aspect of the KGAcc hierarchy. Each box represents the first quartile (Q1), the median, and the third quartile (Q3) of the values obtained on the different aspects and the whiskers indicate the minimum and the maximum values obtained. It shows that the question types of "data usage" usually have good values in the different KGs. It also shows that half of the aspects can be fully covered, including "data collection -who", "data collection -when" and "data collection -how" for instance.</p><p>On the one hand, as many of the aspects sometimes get the maximum score, it shows that these queries are relevant and that KGs have a good margin to improve themselves. On the other hand, some of the low scores observed on that figure may be explained by too demanding queries. Indeed, it is important to notice that 6 out of 30 queries never succeed. For instance, in "data usage -when" the end date of availability of the dataset may be difficult for providers to specify, as they may consider that their KGs will be available indefinitely. Other questions concerning locations may not be in line with the current practices. Indeed, they are especially important for KGs that hold private information, which is generally not the case for public SPARQL endpoints. As other frameworks, on the context, KGAcc may be discussed and improved with experts and KG providers.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. COMPARISON WITH SOME EVALUATION FRAMEWORKS</head><p>To take the analysis of our framework a step further, we compare it in detail with several data quality and FAIRness assessment frameworks. The comparison is made at the level of the required properties: we aim to verify to what extent other studies require the properties demanded by the KGAcc framework. To do so, we focus on studies that consider RDF properties and RDF datasets, and that either provide an open access implementation or that describe the metrics in sufficient detail to allow comparison. This is why works such as F-UJI <ref type="bibr" target="#b7">[8]</ref> or Sieve <ref type="bibr" target="#b17">[18]</ref> are not considered.</p><p>Concerning data quality, Zaveri et al. <ref type="bibr" target="#b5">[6]</ref> provide an organized list of metrics obtained by a systematic literature review. This work is theoretical and does not implement these metrics, therefore, we do not take it into account. However, we focus on two major studies of data quality inspired by Zaveri et al. First, Färber et al. <ref type="bibr" target="#b3">[4]</ref> evaluate the data quality of five crossdomain KGs, namely DBpedia, Freebase, OpenCyc, Wikidata, and YAGO. While the implementation of their metrics is not available, each metric is richly described. Secondly, Debattista et al. <ref type="bibr" target="#b4">[5]</ref> provide a more generic set of data quality metrics enabling the evaluation of any KG. Their implementation is available online but the article <ref type="bibr" target="#b4">[5]</ref> describing them is more detailed and understandable. Therefore, for all these studies, we base our comparison solely on the referenced article.</p><p>For FAIRness, FAIR-checker <ref type="bibr" target="#b8">[9]</ref> is interested in RDF triples as embedded metadata in web pages. For comparison, we rely on the specifications provided by the online tool <ref type="foot" target="#foot_9">13</ref> when evaluating a resource. We also consider O'FAIRe <ref type="bibr" target="#b6">[7]</ref> which focuses on RDF ontologies. It provides an online tool <ref type="foot" target="#foot_10">14</ref> to see the results obtained by a list of ontologies. To compare with them, we consider the complete list of questions and their required properties <ref type="foot" target="#foot_11">15</ref> . In total, this leads us to consider two data quality studies and two FAIRness ones.</p><p>Table <ref type="table" target="#tab_0">II</ref> summarizes our comparative study. For each KGAcc query, if one of its required properties is also required in a data quality or FAIR metric, a mark is indicated in the table. If this property must not necessarily concern the KG (e.g. the creator of a resource instead of the creator of the dataset), then the mark is ≈, showing that the FAIR or data quality metric is not really related to dataset accountability. Otherwise, if this property is mandatory to obtain a maximum score on the data quality or FAIR metric, the mark is ✓. If the property is listed among other properties and only one or two or n of these properties are necessary for success, then the mark is ⊂. For instance, in O'FAIRe the third question for principle F2 states that to obtain the maximum score, six properties should be used from a list of 37 properties, whatever those six properties may be. Therefore, unlike the ✓ mark, a ⊂ mark does not guarantee that passing the FAIR metric ensures passing the accountability query. This table highlights several elements concerning data quality metrics. First, as part of the measure of accessibility, all these evaluations require a license to be present using properties such as dcterms:licence <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b4">[5]</ref>. They also demand some particular provenance information: the creators or the publishers of the KG <ref type="bibr" target="#b4">[5]</ref>, or other information not specifically related to the KG such as the source of some data to enhance trustworthiness <ref type="bibr" target="#b3">[4]</ref>, their modification dates <ref type="bibr" target="#b3">[4]</ref>, or traceability of the data <ref type="bibr" target="#b4">[5]</ref>. Some other meta-information is expected to be provided, such as the serialization formats <ref type="bibr" target="#b4">[5]</ref>. Finally, Färber et al. <ref type="bibr" target="#b3">[4]</ref> request the provision of KG metadata citing as an example the URI of the SPARQL endpoint or the RDF export URL to indicate where to access the data.</p><p>Concerning FAIR metrics, only two metrics are related to accountability in FAIR-checker. The first one measures the 'R1.1' principle that requires a license. The second one measures the provisioning of provenance information (R1.2) by checking that at least one of the 23 listed properties is found (such as prov:wasDerivedFrom, pav:createdBy, etc.). O'FAIRe offers more similarities with our work. There are mainly two different kinds of metrics of interest compared to our queries. First, the metrics concerning the reusability principles focus on one information each and are mostly also required by accountability (creator, contributor, source, method, periodicity, license and rights). Secondly, some metrics of findability require that the ontology uses some well-known properties. Indeed, two questions of the principle 'F2' cover properties required by at least 11 accountability queries (such as dct:created, void:dataDump...).</p><p>As a result, both data quality and FAIRness share common interests with accountability. Therefore, improving them may have a positive impact on the assessment of accountability and vice versa. However, neither data quality nor FAIRness focuses specifically on accountability as a whole and does not take into account all the elements it requires. The general studies on data quality only slightly overlap with accountability. FAIRness has more similarities, particularly with regard to the steps of data collection and maintenance as it is mainly interested in questions of provenance. In particular, O'FAIRe seems to have many similarities. However, most of them result solely from the two findability metrics, which are not very informative about the type of metadata present, since they cover no more than 11 of our queries. Therefore, the measure of accountability is much more detailed, precise, and focused than O'FAIRe on our point of interest. And as the result of each query is available, the former provides a much more relevant view of accountability.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. CONCLUSION</head><p>In order to evaluate the accountability of RDF graphs, we proposed : (i) the KGAcc framework defining requirements concerning the metadata that the KGs should expose and an associated metric, (ii) the evaluation of a large set of endpoints, (iii) a comparison of our approach with other frameworks that assess data quality or compliance to the FAIR principles.</p><p>The KGAcc requirements are expressed as SPARQL queries. They are obtained through a meticulous adaptation of an existing hierarchy of natural language questions, proposed for datasets in general <ref type="bibr" target="#b0">[1]</ref>, to the specific context of KGs. Indeed, the dedicated vocabularies make easy stating some requirements. But their lack of expressiveness makes some questions collapse into a same query or prevents from considering demanding and precise questions about ethical and legal questions. This is why we end up with a relatively small set of queries.</p><p>The evaluation of many RDF graphs reveals that most of them do not provide any of the required information within their data, even though some of the required information is very commonly requested. However, there are RDF graphs that provide some of the expected information, showing our demands are reasonable. Our comparative study shows in particular that O'FAIRe is the framework considering the most properties common to accountability. However, it is not so demanding in terms of accountability and cannot be considered as a framework dedicated to this aspect.</p><p>In future works, to improve our measure, we will introduce some weights to aggregate the results differently, and we will propose an online visualization of the results. Finally, it could be interesting to automate some tasks, such as defining the equivalences.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig.1. The KGAcc Hierarchy of Requirements of Accountability, adapted from LiQuID<ref type="bibr" target="#b0">[1]</ref> to Fit the Context of Knowledge Graphs</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Listing 3 .</head><label>3</label><figDesc>Query to identify the IRI of the studied KG SELECT ?kg WHERE { ?kg ?endpointLink $rawEndpointUrl . { ?kg a dcat:Dataset } UNION { ?kg a void:Dataset } UNION { ?kg a dcmitype:Dataset } UNION { ?kg a schema:Dataset } UNION { ?kg a sd:Dataset } UNION { ?kg a dataid:Dataset } }</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Accountability Score Obtained by the Best Dataset of Each Evaluated Endpoint, Detailed to the Three Life Cycle Steps.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Accountability of Two KGs w.r.t. Different Elements of the Hierarchy</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>W</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>TABLE I ACCOUNTABILITY</head><label>I</label><figDesc>REQUIREMENTS CONCERNING DATA USAGE: ORIGINAL QUESTIONS FROM LIQUID AND THE ADAPTED ONES IN THE KGACC FRAMEWORK</figDesc><table><row><cell></cell><cell>Questions from LiQuID</cell><cell>KGAcc Questions</cell><cell>Weight</cell></row><row><cell></cell><cell>Who publishes this data set?</cell><cell>Who publishes this KG?</cell><cell>1</cell></row><row><cell>Usage. Who</cell><cell>Who has used/ can use the published data set?</cell><cell>Who has the right to use the published KG? Who is intended to use the published KG?</cell><cell>1/2 1/2</cell></row><row><cell></cell><cell cols="2">When can/ was the published data set be used? Since when was the KG available?</cell><cell>1</cell></row><row><cell>Usage. When</cell><cell>When is it available?</cell><cell>Until when is the KG available?</cell><cell>1</cell></row><row><cell></cell><cell>Until what point in time is it valid?</cell><cell>Until when is the KG valid?</cell><cell>1</cell></row><row><cell>Usage. Where</cell><cell>Where is the data set published/ available?</cell><cell>allowing to gain access to it? What is the webpage presenting the KG and/or</cell><cell>1/2</cell></row><row><cell></cell><cell></cell><cell>Where to access the KG (either through a dump</cell><cell>1/2</cell></row><row><cell></cell><cell></cell><cell>or a SPARQL endpoint)?</cell><cell></cell></row></table><note><p>Where (place, geographically) can the published data set be used?</p></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_0"><p>https://www.semwebtech.org/mondial/10/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_1"><p>https://github.com/Jendersen/KG accountability/tree/v2.0/docs</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_2"><p>https://www.w3.org/ns/dcat</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_3"><p>http://dataid.dbpedia.org/ns/core</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_4"><p>http://xmlns.com/foaf/spec/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8" xml:id="foot_5"><p>https://www.w3.org/TR/skos-reference/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="9" xml:id="foot_6"><p>https://www.w3.org/TR/vocab-dqv/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="10" xml:id="foot_7"><p>http://creativecommons.org/ns</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="11" xml:id="foot_8"><p>https://github.com/Jendersen/KG accountability/tree/v2.0</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="13" xml:id="foot_9"><p>fair-checker.france-bioinformatique.fr/check Accessed: 10 April 2023</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="14" xml:id="foot_10"><p>agroportal.lirmm.fr/landscape#fairness assessment</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="15" xml:id="foot_11"><p>https://github.com/agroportal/fairness/blob/master/doc/results/ FAIR-questions.md Accessed: 10 April 2023</p></note>
		</body>
		<back>

			<div type="funding">
<div><p>This work is supported by the <rs type="projectName">ANR DeKaloG (Decentralized Knowledge Graphs)</rs> project, <rs type="grantNumber">ANR-19-CE23-0014</rs>, <rs type="projectName">CE23 -Intelligence artificielle</rs>.</p><p>1 https://eur-lex.europa.eu/eli/reg/2016/679<rs type="grantNumber">/2016-05-04</rs></p></div>
			</div>
			<listOrg type="funding">
				<org type="funded-project" xml:id="_k7M3sdh">
					<idno type="grant-number">ANR-19-CE23-0014</idno>
					<orgName type="project" subtype="full">ANR DeKaloG (Decentralized Knowledge Graphs)</orgName>
				</org>
				<org type="funded-project" xml:id="_jAMUFKN">
					<orgName type="project" subtype="full">CE23 -Intelligence artificielle</orgName>
				</org>
				<org type="funding" xml:id="_nyUwpwD">
					<idno type="grant-number">/2016-05-04</idno>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Accountable data analytics start with accountable data: The LiQuID metadata model</title>
		<author>
			<persName><forename type="first">S</forename><surname>Oppold</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Herschel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ER Forum/Posters/Demos</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="59" to="72" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Information accountability</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Weitzner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Abelson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Berners-Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Feigenbaum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hendler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">J</forename><surname>Sussman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="82" to="87" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">The many dimensions of transparency: A literature review</title>
		<author>
			<persName><forename type="first">D</forename><surname>Wyatt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Helsinki Legal Studies Research Paper</title>
		<imprint>
			<biblScope unit="issue">53</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Linked data quality of dbpedia, freebase, opencyc, wikidata, and yago</title>
		<author>
			<persName><forename type="first">M</forename><surname>Färber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Bartscherer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Menne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rettinger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Semantic Web</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="77" to="129" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Evaluating the quality of the lod cloud: An empirical investigation</title>
		<author>
			<persName><forename type="first">J</forename><surname>Debattista</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Lange</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Auer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Cortis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Semantic Web</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="859" to="901" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Quality assessment for linked data: A survey</title>
		<author>
			<persName><forename type="first">A</forename><surname>Zaveri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rula</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Maurino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Pietrobon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lehmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Auer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Semantic Web</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="63" to="93" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">O&apos;FAIRe: Ontology FAIRness evaluator in the agroportal semantic resource repository</title>
		<author>
			<persName><forename type="first">E</forename><surname>Amdouni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bouazzouni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Jonquet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ESWC 2022-19th Extended Semantic Web Conference, Poster and demonstration</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">An automated solution for measuring the progress toward fair research data</title>
		<author>
			<persName><forename type="first">A</forename><surname>Devaraju</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Huber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Patterns</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">11</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">FAIR-checker -supporting the findability and reusability of digital life science resources</title>
		<author>
			<persName><forename type="first">T</forename><surname>Rosnet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>De Lamotte</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M.-D</forename><surname>Devignes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Lefort</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gaignard</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">The FAIR guiding principles for scientific data management and stewardship</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Wilkinson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Dumontier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">J</forename><surname>Aalbersberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Appleton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Axton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Baak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Blomberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-W</forename><surname>Boiten</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">B</forename><surname>Da</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Silva</forename><surname>Santos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Scientific data</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="9" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">IndeGx: A model and a framework for indexing RDF knowledge graphs with SPARQL-based test suits</title>
		<author>
			<persName><forename type="first">P</forename><surname>Maillot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Corby</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Faron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Gandon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Michel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Web Semantics</title>
		<imprint>
			<biblScope unit="page">100775</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Assessing trust: Contextual accountability</title>
		<author>
			<persName><forename type="first">M</forename><surname>Rowe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Butters</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SPOT@ ESWC</title>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A semantic framework to support ai system accountability and audit</title>
		<author>
			<persName><forename type="first">I</forename><surname>Naja</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Markovic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Edwards</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Cottrill</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Semantic Web: 18th International Conference, ESWC 2021, Virtual Event</title>
		<title level="s">Proceedings</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2021">June 6-10, 2021. 2021</date>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="160" to="176" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Sparqles: Monitoring public sparql endpoints</title>
		<author>
			<persName><forename type="first">P.-Y</forename><surname>Vandenbussche</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Umbrich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Matteis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Hogan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Buil-Aranda</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Semantic web</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1049" to="1065" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Yummydata: providing high-quality open life science data</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Yamamoto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Yamaguchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Splendiani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Database</title>
		<imprint>
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Knowledge graph completeness: A systematic literature review</title>
		<author>
			<persName><forename type="first">S</forename><surname>Issa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Adekunle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Hamdi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>-S. Cherfi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Dumontier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zaveri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="31" to="322" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Assessing knowledge graphs accountability</title>
		<author>
			<persName><forename type="first">J</forename><surname>Andersen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Cazalens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Lamarre</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Semantic Web: ESWC 2023 Satellite Events</title>
		<meeting><address><addrLine>Hersonissos, Greece</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Sieve: linked data quality assessment and fusion</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">N</forename><surname>Mendes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Mühleisen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Bizer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2012 joint EDBT/ICDT workshops</title>
		<meeting>the 2012 joint EDBT/ICDT workshops</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="116" to="123" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">PROV-O: The PROV Ontology</title>
		<author>
			<persName><forename type="first">T</forename><surname>Lebo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sahoo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Mcguinness</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Belhajjame</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Corsar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Cheney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Garijo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Soiland-Reyes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zednik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhao</surname></persName>
		</author>
		<ptr target="https://www.w3.org/TR/prov-o/" />
	</analytic>
	<monogr>
		<title level="m">W3C Recommendation. W3C</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Describing linked datasets with the VoID vocabulary</title>
		<author>
			<persName><forename type="first">K</forename><surname>Alexander</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Cyganiak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hausenblas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhao</surname></persName>
		</author>
		<ptr target="https://www.w3.org/TR/void/" />
	</analytic>
	<monogr>
		<title level="m">W3C Note. W3C</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Sparql 1.1 service description</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">T</forename><surname>Williams</surname></persName>
		</author>
		<ptr target="https://www.w3.org/TR/sparql11-service-description/" />
	</analytic>
	<monogr>
		<title level="m">W3C Recommendation. W3C</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Pav ontology: provenance, authoring and versioning</title>
		<author>
			<persName><forename type="first">P</forename><surname>Ciccarese</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Soiland-Reyes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Belhajjame</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Gray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Goble</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Clark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of biomedical semantics</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="22" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">KartoGraphI: Drawing a Map of Linked Data</title>
		<author>
			<persName><forename type="first">P</forename><surname>Maillot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Corby</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Faron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Gandon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Michel</surname></persName>
		</author>
		<ptr target="https://hal.archives-ouvertes.fr/hal-03652865" />
	</analytic>
	<monogr>
		<title level="m">ESWC 2022 -19th European Semantic Web Conferences</title>
		<meeting><address><addrLine>Hersonissos, Greece</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2022-05">May 2022</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
