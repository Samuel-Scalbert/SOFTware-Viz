<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Overview of LifeCLEF Plant Identification task 2020</title>
				<funder ref="#_4SDsCFJ">
					<orgName type="full">Agence Nationale de la Recherche</orgName>
					<orgName type="abbreviated">ANR</orgName>
				</funder>
				<funder ref="#_Dgn8XrR">
					<orgName type="full">European Union</orgName>
				</funder>
				<funder ref="#_A6zHXDe">
					<orgName type="full">unknown</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Hervé</forename><surname>Goëau</surname></persName>
							<email>herve.goeau@cirad.fr</email>
							<affiliation key="aff0">
								<orgName type="laboratory">CIRAD</orgName>
								<orgName type="institution">UMR AMAP</orgName>
								<address>
									<country key="FR">France</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="laboratory" key="lab1">AMAP</orgName>
								<orgName type="laboratory" key="lab2">CIRAD</orgName>
								<orgName type="institution" key="instit1">Univ Montpellier</orgName>
								<orgName type="institution" key="instit2">CNRS</orgName>
								<orgName type="institution" key="instit3">INRAE</orgName>
								<orgName type="institution" key="instit4">IRD</orgName>
								<address>
									<settlement>Montpellier</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Pierre</forename><surname>Bonnet</surname></persName>
							<email>pierre.bonnet@cirad.fr</email>
							<affiliation key="aff0">
								<orgName type="laboratory">CIRAD</orgName>
								<orgName type="institution">UMR AMAP</orgName>
								<address>
									<country key="FR">France</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="laboratory" key="lab1">AMAP</orgName>
								<orgName type="laboratory" key="lab2">CIRAD</orgName>
								<orgName type="institution" key="instit1">Univ Montpellier</orgName>
								<orgName type="institution" key="instit2">CNRS</orgName>
								<orgName type="institution" key="instit3">INRAE</orgName>
								<orgName type="institution" key="instit4">IRD</orgName>
								<address>
									<settlement>Montpellier</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Alexis</forename><surname>Joly</surname></persName>
							<email>alexis.joly@inria.fr</email>
							<affiliation key="aff2">
								<orgName type="institution">Inria ZENITH team</orgName>
								<address>
									<country key="FR">France</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="institution">LIRMM</orgName>
								<address>
									<settlement>Montpellier</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Overview of LifeCLEF Plant Identification task 2020</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">6B698C0E0FEF410FF35AEBECCCD3C844</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-04-12T14:54+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>LifeCLEF</term>
					<term>PlantCLEF</term>
					<term>plant</term>
					<term>domain adaptation</term>
					<term>cross-domain classification</term>
					<term>tropical flora</term>
					<term>Amazon rainforest</term>
					<term>Guiana Shield</term>
					<term>species identification</term>
					<term>fine-grained classification</term>
					<term>evaluation</term>
					<term>benchmark</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Automated identification of plants has improved considerably thanks to the recent progress in deep learning and the availability of training data with more and more photos in the field. However, this profusion of data only concerns a few tens of thousands of species, mostly located in North America and Western Europe, much less in the richest regions in terms of biodiversity such as tropical countries. On the other hand, for several centuries, botanists have collected, catalogued and systematically stored plant specimens in herbaria, particularly in tropical regions, and the recent efforts by the biodiversity informatics community made it possible to put millions of digitized sheets online. The LifeCLEF 2020 Plant Identification challenge (or "PlantCLEF 2020") was designed to evaluate to what extent automated identification on the flora of data deficient regions can be improved by the use of herbarium collections. It is based on a dataset of about 1,000 species mainly focused on the South America's Guiana Shield, an area known to have one of the greatest diversity of plants in the world. The challenge was evaluated as a cross-domain classification task where the training set consist of several hundred thousand herbarium sheets and few thousand of photos to enable learning a mapping between the two domains. The test set was exclusively composed of photos in the field. This paper presents the resources and assessments of the conducted evaluation, summarizes the approaches and systems employed by the participating research groups, and provides an analysis of the main outcomes.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Automated identification of plants and animals has improved considerably in the last few years. In the scope of the LifeCLEF 2017 Plant Identification chal-lenge <ref type="bibr" target="#b13">[14]</ref> in particular, impressive identification performance were measured thanks to recent deep learning models (e.g. up to 90 % classification accuracy over 10K species), and it was shown in <ref type="bibr" target="#b12">[13]</ref> that automated systems are nowadays not so far from the human expertise. However, these conclusions are valid for species that are mostly living in Europe and North America. Therefore, the LifeCLEF 2019 Plant identification challenge was focused on tropical countries, where there are typically much less of collected observations and images and where the flora is much more difficult to identify for human experts <ref type="bibr" target="#b6">[7]</ref>. In the meantime, biodiversity informatics initiatives such as iDigBio <ref type="foot" target="#foot_0">5</ref> or e-ReColNat<ref type="foot" target="#foot_1">6</ref> made available online millions of digitized herbarium sheets collected over several centuries and conserved in many natural history museums over the world. During centuries, botanists have collected, catalogued and systematically stored plant specimens in herbaria. These physical specimens are used to study the variability of species, their phylogenetic relationship, their evolution, or phenological trends. One of the key step in the workflow of botanists and taxonomists is to find the herbarium sheets that correspond to a new specimen observed in the field. This task requires a high level of expertise and can be very tedious. Developing automated tools to facilitate this work is thus of crucial importance. In the continuity of the PlantCLEF challenges organized in previous years <ref type="bibr" target="#b3">[4]</ref><ref type="bibr" target="#b4">[5]</ref><ref type="bibr" target="#b5">[6]</ref><ref type="bibr" target="#b6">[7]</ref><ref type="bibr" target="#b7">[8]</ref><ref type="bibr" target="#b8">[9]</ref><ref type="bibr" target="#b9">[10]</ref><ref type="bibr" target="#b10">[11]</ref><ref type="bibr" target="#b11">[12]</ref>, the LifeCLEF 2020 Plant identification challenge presented in this paper was designed to evaluate to what extend automated identification on the flora of data deficient regions can be improved by the use of natural history collections of herbarium sheets. Many species in tropical countries are not easily accessible, resulting in a very limited number of photos collected in the field, while several hundred or even several thousand of herbarium sheets have been collected over the centuries. Herbaria collections represent potentially a large pool of data to train species prediction models, but they also induces a much more difficult problem usually referred as a cross domain classification task. Indeed, a plant photographed in the field may have a very different visual appearance than its dried version placed on a herbarium sheet (as illustrated in Figure <ref type="figure" target="#fig_0">1</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Datasets and task description</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Training set</head><p>The conducted study was based on a newly created dataset of 997 species mainly focused on the Guiana shield and the Northern Amazon rainforest (see Figure <ref type="figure">2</ref>), an area known to have one of the greatest diversity of plants and animals in the world. The dataset contains 321,270 herbarium sheets (see Table1 for detailed information). About 12% were collected in French Guyana and hosted in the "Herbier IRD de Guyane" (IRD Herbarium of French Guyana). These herbarium sheets were digitized in the context of the e-ReColNat 6 project. The In order to enable learning a mapping between the two domains (i.e. between the "source" domain of herbarium sheets and the "target" domain of field photos), a relatively smaller set of 6,316 photos in the field was provided additionally to the large herbarium sheets dataset. About 62 % of them also come from he iDigBio portal and were acquired by various photographers related to numerous institutes and national museums that share their data in iDigBio. Besides, two highly trusted experts of the French Guyana flora, Marie-Françoise Prévost "Fanchon" <ref type="bibr" target="#b2">[3]</ref> and Jean-François Molino<ref type="foot" target="#foot_2">7</ref> provided the remaining field photos that were divided between the training set and the test set.</p><p>A valuable asset of the training set is that a set of 354 plant observations are provided with both herbarium sheets and field photos for the same individual plant. This potentially allows a more precise mapping between the two domains (see previous Figure <ref type="figure" target="#fig_0">1</ref> as an example). It should also be noted that about half of the species in the training set (495 to be precise) is only represented by herbarium sheets and therefore it is not possible to learn to recognize them directly from field photos.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Test set</head><p>The test set was composed of 3,186 photos in the field related to 638 plant observations (about 5 pictures per plants on average). To avoid bias related to similar pictures coming from neighboring plants in the same observation site, we ensured that all observations of a given species by a given collector were either in the training set or in the test set but never spread over the two sets. For instance, for the observations of J.F. Molino, the 166 species in the test set are different from the 125 species in the training set.</p><p>Most importantly, plant species in the test set were selected according to the number of field photos illustrating them in the training set. As it can be Fig. <ref type="figure">2</ref>. Density grid maps by number of species of geolocated plant specimens in the PlantCLEF2020 dataset. Many species have also been collected in other regions outside French Guiana, over a large part of the Americas, but also in Africa for some of them. observed in Figure <ref type="figure" target="#fig_1">3</ref> (a), the priority was given to species with few or no field pictures at all. Such a choice may seem drastic, making the task extremely difficult, but the underlying idea was to encourage and promote methods that are as generic as possible, capable of transferring knowledge between the two domains, even without any examples in the target domain for some classes. The second motivation of this choice, was to impose a mapping between herbarium and field photos and avoid that classical methods based on CNNs perform well because of an abundance of field photos in the training set rather than the use of herbarium sheets above all.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">External training sets</head><p>Participants to the evaluation were allowed to use complementary training data (e.g. for pre-training purposes) but on the condition that (i) the experiment is entirely reproducible, i.e. that the used external resource is clearly referenced and accessible to any other research group, (ii) the use of external training data or not is clearly mentioned for each evaluated method, and (iii) the additional resource does not contain any of the test observations. External training data was thus allowed but participants had to provide at least one submission that used only the training data provided this year.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Task Description</head><p>The goal of the task was to identify the correct species of the 638 plant of the test set. For every plant, the evaluated systems had to return a list of species, ranked without ex-aequo. Each participating group was allowed to submit up to 10 run files built from different methods or systems (a run file is a formatted text file containing the species predictions for all test items).</p><p>The main evaluation measure for the challenge was the Mean Reciprocal Rank (MRR), which is defined as the mean of the multiplicative inverse of the rank of the correct answer:</p><p>1</p><formula xml:id="formula_0">Q Q q=1 1 rank q</formula><p>where Q is the number of plant observations and rank q is the predicted rank of the true label for the qth plant observation.</p><p>A second evaluation measure was again the MRR but computed on a subset of observations of difficult species that are rarely photographed in the field. The species were chosen based on the most comprehensive estimates possible from different data sources (iDigBio, GBIF, Encyclopedia of Life, Bing and Google Image search engines, that were actually provided by the organizers or some participants of previous editions of PlantCLEF and ExpertCLEF challenges). It is therefore a more challenging metric because it focuses on the species which impose a mapping between herbarium and field photos. Figure <ref type="figure" target="#fig_1">3</ref> (b) revises the previous Figure <ref type="figure" target="#fig_1">3</ref> (a) according to the considered external data sources and shows that many plant observations in the difficult test subset are related to species estimated to have less than 10 field photos.</p><p>Course of the challenge: The training data was publicly shared in early February 2020 through the AICrowd platform <ref type="foot" target="#foot_3">8</ref> . Any research team wishing to participate in the evaluation could register on the platform and download the data. The test data was shared in mid-April but without the species labels, which were kept secret. Each team could then submit up to 10 submissions corresponding to different methods or different settings of the same method. A submission (also called a run) takes the form of a csv file containing the predictions of the method being evaluated for all observations in the test set. For each submission, the calculation of the evaluation metrics is then done automatically and visible to the participant. Once, the submission phase was closed (mid-June), the participants could also see the evaluation metric values of the other participants. As a last important step, each participant was asked to provide a working note, i.e. a detailed technical report containing all technical information required to reproduce the results of all submissions. All LifeCLEF working notes are reviewed by at least two members of LifeCLEF organizing committee to ensure a sufficient level of quality and reproducibility.</p><p>3 Participants and methods 68 participants registered for the PlantCLEF challenge 2020 and downloaded the data set, and 7 research groups succeeded in submitting a total of 49 runs, i.e. files containing the predictions of the system(s) they ran. Details of the methods are developed in the individual working notes of most of the participants (LU <ref type="bibr" target="#b20">[21]</ref>, ITCR PlantNet <ref type="bibr" target="#b19">[20]</ref>, Neuon AI <ref type="bibr" target="#b1">[2]</ref> and SSN <ref type="bibr" target="#b15">[16]</ref>). The other teams did not provide a detailed description of their systems, but some informal descriptions were sometimes provided in the metadata associated with the submissions and partially contributed to the comments below.</p><p>LU, Lehigh University, USA, 10 runs <ref type="bibr" target="#b20">[21]</ref>: this team used a Partial Domain Adaptation (PDA) approach corresponding to the scenario where target categories are only a subset of source categories to promote positive transfer. They first extracted deep features from a pre-trained NASNetLarge model <ref type="bibr" target="#b21">[22]</ref> and find the shared categories between the two domains. They then develop an novel Adversarial Consistent Learning (ACL) approach through an unified deep architecture which combine a source domain classification loss, an adversarial loss and a feature consistent loss. The adversarial loss helps to learn domain-invariant features while the feature consistent loss aims to preserve the fine-grained feature transition between the two domains.</p><p>Neuon AI, Malaysia, 7 runs <ref type="bibr" target="#b1">[2]</ref>: this team developed a triplet loss network <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b17">18]</ref> between herbarium sheets and field images, trained to maximize the embedding distances of different species while minimizing the embedding distances of same species. First, two InceptionV4 CNNs <ref type="bibr" target="#b18">[19]</ref> were fine-tuned, one exclusively with the herbarium sheets related to the 997 classes, and an other one with more than 1 million pictures related to 10k classes from the PlantCLEF 2017 dataset <ref type="bibr" target="#b4">[5]</ref>. The networks are then fused in a final embedding layer trained to optimize the distances between two embeddings based on triplet loss, but only on the subset of 435 classes that contain both herbarium sheets and field photos in the PlantCLEF 2020 training set. Then, each class is associated to a single embedding computed as the average of embeddings from random herbarium sheets of the class. For inference, a plant observation is then associated to a single embedding computed as the average of the embeddings from all field photos of the observation. The Cosine similarity is used as a distance metric between the embeddings of all the herbarium classes and the embedding of the tested field observation. It is then transformed with Inverse Distance Weighting into probabilities for ranking the classes. The best results was reached with an ensemble of 3 triplet loss networks, without any frozen layers and many data augmentations techniques on both sides (training and test pictures).</p><p>ITCR -PlantNet, Costa Rica &amp; France, 10 runs, <ref type="bibr" target="#b19">[20]</ref>: this team based most of its runs on a Few Shot Adversarial Domain Adaptation approach <ref type="bibr" target="#b14">[15]</ref> (FSADA) where the purpose is to learn a domain agnostic feature space while preserving the discriminative ability of the features for performing the species classification task. First, a ResNet50 is finetuned in the herbarium sheets only. Then, the encoder part of the ResNet50, without the classifier last layers, is frozen and used to extract features on herbarium sheets or field photos. Then, given random pairs of extracted features, a discriminator is trained to distinguish 4 categories: (1) different domains and different classes, (2) different domains and same class, (3) same domain and different classes, (4) same domain and same classes. Finally, during a last stage, the encoder, the discriminator and the classifier are trained together. Domain adaptation is achieved once the discriminator is not able to distinguish samples from categories (1) and (2) and categories (3) and ( <ref type="formula">4</ref>), when the discriminator is not able to tell which was the original domain. This participant attempted several improvements based on a jigsaw self-supervision technique or/and the use of the taxonomic information provided in the metadata (with multi-task classifiers and multiple discriminators). The best result was obtained with an ensemble of several variations of FSADA models, while the best single model was using 3 taxonomic levels (species, genus, family) and external datasets (PlantCLEF 2019 <ref type="bibr" target="#b6">[7]</ref> and GBIF <ref type="bibr" target="#b16">[17]</ref>). SSN College of Engineering, India, 2 runs, <ref type="bibr" target="#b15">[16]</ref>: this team used a classical CNN approach based on a ResNet50 which didn't give very good results given the limited number of field photos in the training set. It seems they didn't use any external data.</p><p>The 3 other teams did not provide an extended description of their system. According to the description provided in the submission system, the UWB team (3 runs) used a classical CNN approach based on ResNet18 with various combinations of external data <ref type="bibr" target="#b16">[17]</ref>. Unfortunately, at the time of writing, there is not enough information about the submissions from the "To Be" (10 runs) and the "Domain" teams (7 runs).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Results</head><p>We report in Figure <ref type="figure" target="#fig_2">4</ref> and Table <ref type="table">4</ref> the performances achieved by the 49 evaluated runs. Figure <ref type="figure" target="#fig_3">5</ref> reorganizes the results according to the second MRR metric focusing on the most difficult species. The main outcomes we can derive from that results are the following ones:</p><p>A very difficult task even with the most advanced deep learning techniques. The best MRR value obtained across all evaluated methods was equal to   0.18. This is quite low compared to the MRR value measured within more classical plant identification benchmarks, e.g. MRR=0.92 in LifeCLEF 2017 Plant Identification challenge <ref type="bibr" target="#b13">[14]</ref> and MRR=0.36 LifeCLEF 2019 Plant Identification challenge focused on tropical flora <ref type="bibr" target="#b6">[7]</ref>. As already noticed, tropical flora is inherently more difficult than generalist flora (even for experts), which partially explains the low performance achieved. The asymmetry between training data based on herbarium sheets and test data based on field photos adds a considerable difficulty. It is important to note that the low scores achieved do not mean that the use of herbarium sheets does not improve the identification. The species in the test set were actually selected as the ones having very few field pictures in the training set. The performance that would have been obtained on that species without using any herbarium sheet would have been considerably weaker.</p><p>Traditional CNNs performed poorly. Figure <ref type="figure" target="#fig_2">4</ref> shows a great disparity between the performances obtained by the different evaluated methods. To explain that we have first to distinguish between approaches based on classical CNNs alone (typically pre-trained on ImageNet and fine-tuned with the provided training data) and approaches that additionally incorporate an explicit and formal domain adaptation technique between the herbarium and field domains. As expected regarding the low number of field photos in the training set for numerous species, directly fine-tuned CNNs with the PlantCLEF 2020 training set obtained the lowest scores (ITCR PlantNet Run 1, SSN Run 1&amp;2, UWB Run 1).</p><p>Moreover, the use of external training data with classical CNNs did not greatly improve performances. It provides some improvements on the main evaluation metric as demonstrated with the UWB runs 2 &amp; 3 and ITCR PlantNet Run 2. All these runs extended the training data with the PlantCLEF 2019 training data <ref type="bibr" target="#b6">[7]</ref> and the GBIF training data provided by <ref type="bibr" target="#b16">[17]</ref>). ITCR PlantNet Run 2 made a greater improvement on the main MRR metric probably because they used a two stage training strategy: they first fine-tuned a pre-trained ResNet50 with all the herbarium sheets from PlantCLEF 2020, and then finetuned it again with all the field photos PlantCLEF 2020 and the external training data (Plant-CLEF 2019 and GBIF). This two stages strategy can be seen eventually as a first naive domain adaptation technique because the second stage shifts the learned features in an initial herbarium feature space to a field feature space. However, regarding the second MRR metric focusing on the most difficult species with few field photos in the training set, performances for all the aforementioned runs is still quite low. This means that the performances of a classical CNN approach, without a formal domain adaptation technique, is too dependent from the number of field photos available in the training data, and is not able to efficiently transfer visual knowledge from the herbarium domain to the field photos domain.</p><p>An adversarial domain adaptation technique performed the best. Among other submissions, two participants stood out from the crowd with two different domain adaptation techniques. ITCR PlantNet team based all its remaining runs on a Few Shot Adversarial Domain Adaptation approach <ref type="bibr" target="#b14">[15]</ref> (FSADA), directly applied in the ITCR PlantNet Run 3. FSADA approach uses a discriminator that helps the initial encoder trained on herbarium sheets to shift the learned feature representations to a domain agnostic feature space where the discriminator is no longer able to distinguish if a picture comes from the herbarium or the field domain, while maintaining the discriminative power regarding the final species classification task. The basic FSADA approach (ITCR Plant-Net Run 3) clearly outperformed the traditional CNN approach (ITCR PlantNet Run 1), while both approaches are based on the same initial finetuned ResNet50 model on the herbarium training data. It should be noted that the LU team also used an adversarial approach but with less success.</p><p>A mapping domain adaptation techniques reached an impressive genericity on difficult species. While the adversarial domain adaptation technique used by the ITCR PlantNet team obtained the best results on the overall MRR metric, the Neuon AI team obtained the best results on the second MRR metric focusing on the most difficult species in the test set. Contrary to the approach used by ITCR which tries to learn a common and agnostic feature space to both domains, the Neuon team tries on its side to finetune two networks dedicated each to one of the domain and to optimize a distance that maps the two domains for the purpose of classifying species. The Neuon AI Run 5, which is an ensemble of 3 instances of their approach, gave particularly impressive results with fairly high and, more importantly, equivalent values for both MRR measures. It means that Neuon AI's approach is very robust to the lack of training field photos and able to generalize on rare difficult species in the test set. In other words, their approach is able to transfer knowledge to rare species which was the underlying objective of the challenge.</p><p>External data improved domain adaptation approaches. ITCR Plant-Net Run 4 shows a significant impact on the main MRR metric from using external training data compared to the same adversarial domain adaptation approach (ITCR PlantNet Run 3), while maintaining the same level of genericity on rare species with similar MRRs value on the second metric. Unfortunately it is not possible to measure this impact on the Neuon AI method because they did not provide a run using only this year's training data.</p><p>Multi-task approaches have a positive impact on performance. Some teams implemented multi-task approaches, i.e. they added additional tasks than the main species identification task in the global optimization problem. Such approaches are known to potentially improve the performance of the main task by providing additional knowledge to the model and help the extraction of potentially useful common features. The use of upper taxon level information, in particular, was successful in ITCR PlantNet Run 6 (using a multi-classification task integrated to the FSADA approach) compared to ITCR PlantNet Run 4 using only the species classification task. Noticeably, yhis is the first time over all LifeCLEF plant identification challenges that we clearly observe an important gain of the use of genus and family information to improve the species identification. Many species with few training data have apparently been able to benefit indirectly from a "sibling" species with many data related to a same genus or family. The impact is probably enhanced this year because of the lack of visual data on many species. To a lesser extent, self supervision auxiliary task such as jigsaw solving prediction task (ITCR PlantNet Run 5) improved a little the baseline of this team (ITCR PlantNet Run 4), and the best submission over all this year challenge is an ensemble of all FSADA approaches, combining self supervision or not, upper taxons or not.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>This paper presented the overview and the results of the LifeCLEF 2020 plant identification challenge following the 9 previous editions conducted within CLEF evaluation forum. This year's task was particularly challenging, focusing on species rarely photographed in the field in the northern tropical Amazon. The results revealed that the last advances in domain adaptation enable the use of herbarium data to facilitate the identification of rare tropical species for which no or very few other training photos are available. A mapping domain adaptation technique based on a two-streamed Herbarium-Field triplet loss network reached an impressive genericity by obtaining quite high similar results regardless of whether the species have many or very few field photos in the training set. On the other hand, a Few Shot Adversarial Domain Adaptation technique outperformed all the other approaches according to the main metric but not with the same genericity according to the second metric, even if the use of taxonomic information can improve the genericity. The results are thus contrasted and allow us to hope for improvements in the near future on both aspects: raw performances and genericity. We believe that the proposed task may be in the future a new baseline dataset in the field of domain adaptation, and motivate new contributions through a realistic and crucial usage for the plant biology research community.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Photos in the field and herbarium sheets of the same individual plant (Tapirira guianensis Aubl.). Despite the very different visual appearances between the two types of images, similar structure and shapes of flowers, fruits and leaves can be observed.</figDesc><graphic coords="4,219.80,141.76,103.74,77.82" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Species according to the estimated number of images for each domain in the training set (in blue). Each species is surrounded by an additional orange circle if it is used in the test set, and a red circle if used in the test subset of difficult species (with few field photos according to the PlantCLEF 2020 the training set). The bottom graph revises the positions of the species by including additional training pictures from external datasets that could be used by the participants. It is estimated that most of the species related to the difficult test subset have less than 10 field photos.</figDesc><graphic coords="6,134.77,123.15,345.84,433.07" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. PlantCLEF 2020 evaluation results based on the primary evaluation metric, i.e. the Mean Reciprocal Rank over the entire test set.</figDesc><graphic coords="11,134.77,140.60,345.82,170.27" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. PlantCLEF 2020 evaluation results based on the secondary metric, i.e. the Mean Reciprocal Rank over the subset of difficult species with few or no field photos in the training set.</figDesc><graphic coords="11,134.77,412.95,345.82,169.67" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Details of the PlantCLEF 2020 dataset according to the origin of the pictures and their domain (herbarium sheets or field photos).</figDesc><table><row><cell>Origin</cell><cell>Domain</cell><cell cols="3">Used as #Pictures #Species</cell></row><row><cell cols="3">Herbier IRD de Guyane Herbarium sheets Train</cell><cell>38,552</cell><cell>631</cell></row><row><cell>iDigBio</cell><cell cols="2">Herbarium sheets Train</cell><cell>282,718</cell><cell>991</cell></row><row><cell>iDigBio</cell><cell>Field photos</cell><cell>Train</cell><cell>3,935</cell><cell>426</cell></row><row><cell>Fanchon</cell><cell>Field photos</cell><cell>Train</cell><cell>1,130</cell><cell>183</cell></row><row><cell>Molino</cell><cell>Field photos</cell><cell>Train</cell><cell>1,251</cell><cell>125</cell></row><row><cell>Fanchon</cell><cell>Field photos</cell><cell>Test</cell><cell>1,830</cell><cell>271</cell></row><row><cell>Molino</cell><cell>Field photos</cell><cell>Test</cell><cell>1,356</cell><cell>166</cell></row><row><cell>Train (all)</cell><cell cols="2">Herbarium sheets Train</cell><cell>321,270</cell><cell>997</cell></row><row><cell>Train (all)</cell><cell>Field photos</cell><cell>Train</cell><cell>6,316</cell><cell>502</cell></row><row><cell>Test (all)</cell><cell>Field photos</cell><cell>Test</cell><cell>3,186</cell><cell>408</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Results of the LifeCLEF 2020 Plant Identification Task</figDesc><table><row><cell>Team run</cell><cell>MRR (whole test set)</cell><cell>MRR (difficult species)</cell></row><row><cell>ITCR PlantNet Run 10</cell><cell>0.180</cell><cell>0.052</cell></row><row><cell>ITCR PlantNet Run 9</cell><cell>0.170</cell><cell>0.039</cell></row><row><cell>ITCR PlantNet Run 8</cell><cell>0.167</cell><cell>0.060</cell></row><row><cell>ITCR PlantNet Run 6</cell><cell>0.161</cell><cell>0.037</cell></row><row><cell>ITCR PlantNet Run 4</cell><cell>0.148</cell><cell>0.039</cell></row><row><cell>ITCR PlantNet Run 7</cell><cell>0.143</cell><cell>0.036</cell></row><row><cell>ITCR PlantNet Run 5</cell><cell>0.134</cell><cell>0.062</cell></row><row><cell>Neuon AI Run 7</cell><cell>0.121</cell><cell>0.107</cell></row><row><cell>ITCR PlantNet Run 2</cell><cell>0.112</cell><cell>0.013</cell></row><row><cell>Neuon AI Run 5</cell><cell>0.111</cell><cell>0.108</cell></row><row><cell>Neuon AI Run 3</cell><cell>0.103</cell><cell>0.094</cell></row><row><cell>Neuon AI Run 2</cell><cell>0.099</cell><cell>0.076</cell></row><row><cell>Neuon AI Run 6</cell><cell>0.093</cell><cell>0.066</cell></row><row><cell>Neuon AI Run 4</cell><cell>0.088</cell><cell>0.073</cell></row><row><cell>Neuon AI Run 1</cell><cell>0.081</cell><cell>0.061</cell></row><row><cell>ITCR PlantNet Run 3</cell><cell>0.054</cell><cell>0.039</cell></row><row><cell>UWB Run 2</cell><cell>0.039</cell><cell>0.007</cell></row><row><cell>UWB Run 3</cell><cell>0.039</cell><cell>0.007</cell></row><row><cell>LU Run 8</cell><cell>0.032</cell><cell>0.016</cell></row><row><cell>LU Run 10</cell><cell>0.032</cell><cell>0.016</cell></row><row><cell>LU Run 9</cell><cell>0.032</cell><cell>0.016</cell></row><row><cell>Domain Run 2</cell><cell>0.031</cell><cell>0.015</cell></row><row><cell>Domain Run 6</cell><cell>0.029</cell><cell>0.015</cell></row><row><cell>Domain Run 4</cell><cell>0.028</cell><cell>0.015</cell></row><row><cell>To Be Run 10</cell><cell>0.028</cell><cell>0.016</cell></row><row><cell>To Be Run 9</cell><cell>0.028</cell><cell>0.014</cell></row><row><cell>Domain Run 1</cell><cell>0.028</cell><cell>0.007</cell></row><row><cell>LU Run 5</cell><cell>0.027</cell><cell>0.008</cell></row><row><cell>Domain Run 5</cell><cell>0.026</cell><cell>0.014</cell></row><row><cell>LU Run 7</cell><cell>0.025</cell><cell>0.007</cell></row><row><cell>LU Run 6</cell><cell>0.025</cell><cell>0.008</cell></row><row><cell>Domain Run 3</cell><cell>0.024</cell><cell>0.015</cell></row><row><cell>UWB Run 1</cell><cell>0.024</cell><cell>0.011</cell></row><row><cell>To Be Run 7</cell><cell>0.019</cell><cell>0.007</cell></row><row><cell>Domain Run 7</cell><cell>0.019</cell><cell>0.012</cell></row><row><cell>To Be Run 2</cell><cell>0.016</cell><cell>0.007</cell></row><row><cell>To Be Run 8</cell><cell>0.015</cell><cell>0.005</cell></row><row><cell>To Be Run 6</cell><cell>0.014</cell><cell>0.009</cell></row><row><cell>LU Run 2</cell><cell>0.011</cell><cell>0.004</cell></row><row><cell>LU Run 3</cell><cell>0.011</cell><cell>0.004</cell></row><row><cell>To Be Run 5</cell><cell>0.011</cell><cell>0.009</cell></row><row><cell>LU Run 4</cell><cell>0.009</cell><cell>0.007</cell></row><row><cell>LU Run 1</cell><cell>0.009</cell><cell>0.006</cell></row><row><cell>SSN Run 2</cell><cell>0.008</cell><cell>0.003</cell></row><row><cell>SSN Run 1</cell><cell>0.008</cell><cell>0.003</cell></row><row><cell>To Be Run 1</cell><cell>0.006</cell><cell>0.005</cell></row><row><cell>To Be Run 3</cell><cell>0.006</cell><cell>0.005</cell></row><row><cell>To Be Run 4</cell><cell>0.006</cell><cell>0.005</cell></row><row><cell>ITCR PlantNet Run 1</cell><cell>0.002</cell><cell>0.002</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_0"><p>http://portal.idigbio.org/portal/search</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_1"><p>https://explore.recolnat.org/search/botanique/type=index</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_2"><p>https://scholar.google.fr/citations?user=xZXYc4kAAAAJ&amp;hl=fr</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8" xml:id="foot_3"><p>https://www.aicrowd.com/challenges/lifeclef-2020-plant</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><p>Acknowledgements This project has received funding from the <rs type="funder">French National Research Agency</rs> under the <rs type="programName">Investments for the Future Program</rs>, referred as <rs type="grantNumber">ANR-16-CONV-0004</rs> and from the <rs type="funder">European Union</rs>'s <rs type="programName">Horizon 2020 research and innovation program</rs> under grant agreement No <rs type="grantNumber">863463</rs> (<rs type="projectName">Cos4Cloud</rs> project). This work was supported in part by the <rs type="programName">Microsoft AI for Earth program</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_4SDsCFJ">
					<idno type="grant-number">ANR-16-CONV-0004</idno>
					<orgName type="program" subtype="full">Investments for the Future Program</orgName>
				</org>
				<org type="funded-project" xml:id="_Dgn8XrR">
					<idno type="grant-number">863463</idno>
					<orgName type="project" subtype="full">Cos4Cloud</orgName>
					<orgName type="program" subtype="full">Horizon 2020 research and innovation program</orgName>
				</org>
				<org type="funding" xml:id="_A6zHXDe">
					<orgName type="program" subtype="full">Microsoft AI for Earth program</orgName>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Few-shot learning approach for plant disease classification using images taken in the field</title>
		<author>
			<persName><forename type="first">D</forename><surname>Argüeso</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Picon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Irusta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Medela</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">G</forename><surname>San-Emeterio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bereciartua</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Alvarez-Gila</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.compag.2020.105542</idno>
		<ptr target="http://www.sciencedirect.com/science/article/pii/S0168169920302544" />
	</analytic>
	<monogr>
		<title level="j">Computers and Electronics in Agriculture</title>
		<imprint>
			<biblScope unit="volume">175</biblScope>
			<biblScope unit="page">105542</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Herbarium-field triplets network for cross-domain plant identification -neuon submission to lifeclef 2020 plant</title>
		<author>
			<persName><forename type="first">S</forename><surname>Chulif</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">L</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CLEF: Conference and Labs of the Evaluation Forum</title>
		<meeting><address><addrLine>Thessaloniki, Greece</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020-09">Sep. 2020. 2020</date>
		</imprint>
	</monogr>
	<note>CLEF working notes 2020</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Marie-françoise prévost &quot;fanchon&quot;(1941-2013)</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">G</forename><surname>Delprete</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Feuillet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Taxon</title>
		<imprint>
			<biblScope unit="volume">62</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="419" to="419" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Plant identification in an open-world (lifeclef 2016)</title>
		<author>
			<persName><forename type="first">H</forename><surname>Goëau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Bonnet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Joly</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CLEF: Conference and Labs of the Evaluation Forum</title>
		<meeting><address><addrLine>Évora, Portugal</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016-09">Sep. 2016. 2016</date>
		</imprint>
	</monogr>
	<note>CLEF task overview 2016</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Plant identification based on noisy web data: the amazing performance of deep learning (lifeclef 2017)</title>
		<author>
			<persName><forename type="first">H</forename><surname>Goëau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Bonnet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Joly</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CLEF: Conference and Labs of the Evaluation Forum</title>
		<meeting><address><addrLine>Dublin, Ireland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017-09">Sep. 2017. 2017</date>
		</imprint>
	</monogr>
	<note>CLEF task overview 2017</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Overview of expertlifeclef 2018: how far automated identification systems are from the best experts ?</title>
		<author>
			<persName><forename type="first">H</forename><surname>Goëau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Bonnet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Joly</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CLEF: Conference and Labs of the Evaluation Forum</title>
		<meeting><address><addrLine>Avignon, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018-09">Sep. 2018. 2018</date>
		</imprint>
	</monogr>
	<note>CLEF task overview 2018</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Overview of lifeclef plant identification task 2019: diving into data deficient tropical countries</title>
		<author>
			<persName><forename type="first">H</forename><surname>Goëau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Bonnet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Joly</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CLEF: Conference and Labs of the Evaluation Forum</title>
		<meeting><address><addrLine>Lugano, Switzerland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019-09">Sep. 2019. 2019</date>
		</imprint>
	</monogr>
	<note>CLEF task overview 2019</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">The imageclef 2013 plant identification task</title>
		<author>
			<persName><forename type="first">H</forename><surname>Goëau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Bonnet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Joly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Bakic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Barthélémy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Boujemaa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">F</forename><surname>Molino</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CLEF: Conference and Labs of the Evaluation Forum</title>
		<meeting><address><addrLine>Valencia, Spain. Valencia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013-09">Sep. 2013. 2013</date>
		</imprint>
	</monogr>
	<note>CLEF task overview 2013</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">The imageclef 2011 plant images classification task</title>
		<author>
			<persName><forename type="first">H</forename><surname>Goëau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Bonnet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Joly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Boujemaa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Barthélémy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">F</forename><surname>Molino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Birnbaum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Mouysset</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Picard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CLEF: Conference and Labs of the Evaluation Forum</title>
		<meeting><address><addrLine>Amsterdam, Netherlands</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011-09">Sep. 2011. 2011</date>
		</imprint>
	</monogr>
	<note>CLEF task overview 2011</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Imageclef2012 plant images identification task</title>
		<author>
			<persName><forename type="first">H</forename><surname>Goëau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Bonnet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Joly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Yahiaoui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Barthélémy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Boujemaa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">F</forename><surname>Molino</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CLEF: Conference and Labs of the Evaluation Forum</title>
		<meeting><address><addrLine>Rome, Italy; Rome</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012-09">Sep. 2012. 2012</date>
		</imprint>
	</monogr>
	<note>CLEF task overview 2012</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Lifeclef plant identification task</title>
		<author>
			<persName><forename type="first">H</forename><surname>Goëau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Joly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Bonnet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CLEF: Conference and Labs of the Evaluation Forum</title>
		<meeting><address><addrLine>Toulouse, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015-09">2015. Sep. 2015. 2015</date>
		</imprint>
	</monogr>
	<note>CLEF task overview 2015</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">The lifeclef 2014 plant images identification task</title>
		<author>
			<persName><forename type="first">H</forename><surname>Goëau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Joly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Bonnet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Selmi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">F</forename><surname>Molino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Barthélémy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Boujemaa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CLEF: Conference and Labs of the Evaluation Forum</title>
		<meeting><address><addrLine>Sheffield, United Kingdom. Sheffield, UK</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014-09">Sep. 2014. 2014</date>
		</imprint>
	</monogr>
	<note>CLEF task overview 2014</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Overview of lifeclef 2018: a large-scale evaluation of species identification and recommendation algorithms in the era of ai</title>
		<author>
			<persName><forename type="first">A</forename><surname>Joly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Goëau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Botella</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Glotin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Bonnet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">P</forename><surname>Vellinga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Müller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CLEF: Cross-Language Evaluation Forum for European Languages. Experimental IR Meets Multilinguality, Multimodality, and Interaction</title>
		<editor>
			<persName><forename type="first">G</forename><forename type="middle">J</forename><surname>Jones</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Lawless</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Gonzalo</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Kelly</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Goeuriot</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename><surname>Mandl</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Cappellato</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<meeting><address><addrLine>Avigon, France</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2018-09">Sep 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Lifeclef 2017 lab overview: multimedia species identification challenges</title>
		<author>
			<persName><forename type="first">A</forename><surname>Joly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Goëau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Glotin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Spampinato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Bonnet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">P</forename><surname>Vellinga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Lombardo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Planque</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Palazzo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Müller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference of the Cross-Language Evaluation Forum for European Languages</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="255" to="274" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Few-shot adversarial domain adaptation</title>
		<author>
			<persName><forename type="first">S</forename><surname>Motiian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Iranmanesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Doretto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="6670" to="6680" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Plant species identification using transfer learning -plantclef 2020</title>
		<author>
			<persName><forename type="first">Ram</forename><surname>Nanda H Krishna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Kaushik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CLEF: CLEF: Conference and Labs of the Evaluation Forum</title>
		<meeting><address><addrLine>Thessaloniki, Greece</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020-09">Sep. 2020. 2020</date>
		</imprint>
	</monogr>
	<note>CLEF working notes 2020</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Recognition of the amazonian flora by inception networks with test-time class prior estimation</title>
		<author>
			<persName><forename type="first">L</forename><surname>Picek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sulc</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Matas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CLEF: Conference and Labs of the Evaluation Forum</title>
		<meeting><address><addrLine>Lugano, Switzerland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019-09">Sep. 2019. 2019</date>
		</imprint>
	</monogr>
	<note>CLEF working notes 2019</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Facenet: A unified embedding for face recognition and clustering</title>
		<author>
			<persName><forename type="first">F</forename><surname>Schroff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Kalenichenko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Philbin</surname></persName>
		</author>
		<idno type="DOI">10.1109/CVPR.2015.7298682</idno>
		<ptr target="http://dx.doi.org/10.1109/CVPR.2015.7298682" />
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2015-06">2015. Jun 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<author>
			<persName><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Alemi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1602.07261</idno>
		<title level="m">Inception-v4, inception-resnet and the impact of residual connections on learning</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Domain adaptation in the context of herbarium collections: a submission to plantclef 2020</title>
		<author>
			<persName><forename type="first">J</forename><surname>Villacis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Goëau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Bonnet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Mata-Montero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Joly</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CLEF: Conference and Labs of the Evaluation Forum</title>
		<meeting><address><addrLine>Thessaloniki, Greece</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020-09">Sep. 2020. 2020</date>
		</imprint>
	</monogr>
	<note>CLEF working notes 2020</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Adversarial consistent learning on partial domain adaptation of plantclef 2020 challenge</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">D</forename><surname>Davison</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CLEF: Conference and Labs of the Evaluation Forum</title>
		<meeting><address><addrLine>Thessaloniki, Greece</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020-09">Sep. 2020. 2020</date>
		</imprint>
	</monogr>
	<note>CLEF working notes 2020</note>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Learning transferable architectures for scalable image recognition</title>
		<author>
			<persName><forename type="first">B</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Vasudevan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
