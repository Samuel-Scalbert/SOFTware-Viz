<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Probing neural language models for understanding of words of estimative probability</title>
				<funder ref="#_7AbRk5c">
					<orgName type="full">ERC Advanced</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Damien</forename><surname>Sileo</surname></persName>
							<email>damien.sileo@inria.fr</email>
							<affiliation key="aff0">
								<orgName type="laboratory">UMR 9189</orgName>
								<orgName type="institution" key="instit1">Univ. Lille</orgName>
								<orgName type="institution" key="instit2">Inria</orgName>
								<orgName type="institution" key="instit3">CNRS</orgName>
								<orgName type="institution" key="instit4">Centrale Lille</orgName>
								<address>
									<addrLine>-CRIStAL</addrLine>
									<postCode>F-59000</postCode>
									<settlement>Lille</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Marie-Francine</forename><surname>Moens</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">KU Leuven</orgName>
								<address>
									<country key="BE">Belgium</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Probing neural language models for understanding of words of estimative probability</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">D188F717C3E9EF35536A76A74AECF042</idno>
					<idno type="DOI">10.18653/v1/2023.starsem-1.41</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-04-12T14:49+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Words of Estimative Probability (WEP) are phrases used to express the plausibility of a statement. Examples include terms like probably, maybe, likely, doubt, unlikely, and impossible. Surveys have shown that human evaluators tend to agree when assigning numerical probability levels to these WEPs. For instance, the term highly likely equates to a median probability of 0.90±0.08 according to a survey by <ref type="bibr" target="#b7">Fagen-Ulmschneider (2015)</ref>. In this study, our focus is to gauge the competency of neural language processing models in accurately capturing the consensual probability level associated with each WEP. Our first approach is utilizing the UNLI dataset (Chen et al., 2020), which links premises and hypotheses with their perceived joint probability p. From this, we craft prompts in the form: "[PREMISE]. [WEP], [HYPOTHESIS]." This allows us to evaluate whether language models can predict if the consensual probability level of a WEP aligns closely with p. In our second approach, we develop a dataset based on WEP-focused probabilistic reasoning to assess if language models can logically process WEP compositions. For example, given the prompt "[EVENTA] is likely. [EVENTB] is impossible.", a wellfunctioning language model should not conclude that [EVENTA&amp;B] is likely. Through our study, we observe that both tasks present challenges to out-of-the-box English language models. However, we also demonstrate that fine-tuning these models can lead to significant and transferable improvements.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Expression of uncertainty is an important part of communication. Formal statistics are the rigorous way to quantify uncertainty but do not fit all communication styles. Words of estimative probability (WEP) such as maybe and believe are adverbs or verbs that are informal alternatives. <ref type="bibr" target="#b8">Kent (1964)</ref> noted the importance of clarifying WEP meaning for intelligence analysis in the Central Intelligence Agency, and provided guidelines for mapping WEP to numerical probabilities. Several studies then measured the human perceptions of probability words and discovered some agreement with <ref type="bibr" target="#b8">Kent (1964)</ref>'s guidelines. In this work, we use the scale derived from a survey <ref type="bibr" target="#b7">(Fagen-Ulmschneider, 2015)</ref>, which is the largest and most recent WEP perception survey available. 123 participants were asked to label WEP with numerical probabilities. We use the median of the participant answers to assign a consensual value to each WEP. Associated probabilities for the 19 WEP we use are available in Appendix A, table <ref type="table" target="#tab_2">2</ref>.</p><p>Here, we assess whether neural language models learn the consensual probability judgment of WEP from language modeling pretraining. We develop datasets and a methodology to probe neural language model understanding of WEP. The first dataset leverages previously annotated probability scores between a premise and a hypothesis, in order to measure a language model's ability to capture the agreement between numerical probabilities and WEP-expressed probabilities. The second dataset is based on compositions of facts with WEP-expressed probabilities, and measures verbal probabilistic reasoning in language models. Our contributions are as follows: (i) two datasets and methods to measure understanding of WEP; and (ii) evaluation of the ability of neural language models (GPT2, RoBERTa-trained on MNLI) to tackle WEP-related problems, showing that offthe-shelf models are very little influenced by them, even though fine-tuning on our constructed datasets quickly leads to high accuracies. The code and generated datasets are publicly available<ref type="foot" target="#foot_0">1</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related work</head><p>Our work probes a particular aspect of language understanding. We do not analyze the inside of the models <ref type="bibr" target="#b17">(Rogers et al., 2020)</ref>. We focus on the models' ability to perform controlled tasks <ref type="bibr" target="#b12">(Naik et al., 2018;</ref><ref type="bibr">Richardson et al., 2020)</ref> involving WEP. WEP were studied in the context of intelligence analysis and linguistics, our work is the first to look at them through natural language processing (NLP) models. Our study also pertains to NLP analyses of logical reasoning and probability problems, and to uncertainty in natural language inference tasks.</p><p>Linguistics study of <ref type="bibr">WEP Kent (1964)</ref>'s seminal work was the first to link WEP and numerical probability estimates, with intelligence analysis motivations (Dhami and Mandel, 2021) and a prescriptivist approach. This inspired further quantifications of human perceptions of WEP, in the context of medical reports (O <ref type="bibr">'Brien, 1989;</ref><ref type="bibr" target="#b14">Ott, 2021)</ref> and weather reports <ref type="bibr" target="#b9">(Lenhardt et al., 2020)</ref>. <ref type="bibr" target="#b7">Fagen-Ulmschneider (2015)</ref> proposed the largest survey up to date with 123 participants about generaldomain WEP perception.</p><p>Logical and probabilistic reasoning Another strand of work probes NLP text encoders capabilities, notably reasoning abilities. <ref type="bibr" target="#b24">Weston et al. (2015)</ref> probed understanding of specific problems like negation, spatial and temporal reasoning with the bAbI dataset. <ref type="bibr">Richardson et al. (2020)</ref> probe understanding of first-order logic reasoning, <ref type="bibr" target="#b20">Sileo and Lernould (2023)</ref> probe epistemic logic reasoning. Our work is the first to address probabilistic logic, alongside <ref type="bibr" target="#b6">Dries et al. (2017)</ref>; <ref type="bibr" target="#b23">Suster et al. (2021)</ref> who construct a dataset of natural language probability problems, e.g., "A bag has 4 white and 8 blue marbles. You pull out one marble and it is blue. You pull out another marble, what is the probability of it being white?". They also rely on the ProbLog solver <ref type="bibr" target="#b4">(De Raedt et al., 2007)</ref>, but focus on numeric probability problems. By contrast, our work targets WEP, and textual probabilistic logical reasoning.</p><p>Natural language inference, uncertainty, modality, evidentiality Uncertainty was also studied in the context of natural language inference tasks. <ref type="bibr" target="#b29">Zhou et al. (2022)</ref> study the disagreement across annotators when labeling entailment relationships. <ref type="bibr" target="#b26">Zhang et al. (2017)</ref> annotate graded entailment with 5 probability levels, and the UNLI dataset <ref type="bibr" target="#b2">(Chen et al., 2020</ref>) go further by annotating numerical probabilities. Our work also pertains to the study of modality <ref type="bibr" target="#b15">(Palmer, 1992;</ref><ref type="bibr" target="#b18">Saurí et al., 2006)</ref> and more particularly evidentiality <ref type="bibr" target="#b22">(Su et al., 2010)</ref>, but where previous work focused on WEP.</p><p>3 Probing WEP understanding</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Verbalization and distractor generation</head><p>Our goal is to measure the understanding of WEP. One requirement of WEP understanding is capturing the consensual probability level. To test that, we use contexts (PREMISE) paired with a conclusions (HYPOTHESIS). The likelihood of a conclusion, p, depends on the associated context. One example from UNLI <ref type="bibr" target="#b2">(Chen et al., 2020)</ref>, which annotates that, is (A man in a white shirt taking a picture , A man takes a picture , 1.0).</p><p>We convert a triplet (PREMISE, HYPOTHESIS, p) to the following verbalization:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>PREMISE. T p (HYPOTHESIS).</head><p>(</p><formula xml:id="formula_0">)<label>1</label></formula><p>where T p is a text template assigned to the probability p. To select a template, we find the WEP whose associated median probability (see table <ref type="table" target="#tab_2">2</ref>) is the closest to p. We then use handcrafted templates to construct a modal sentence from the selected WEP and the hypothesis, e.g., "It is certain that a man takes a picture". Table <ref type="table" target="#tab_3">3</ref> in appendix B displays the templates that we associate with each WEP.</p><p>We also generate an invalid verbalization by randomly selecting an incorrect WEP (a WEP whose consensual probability differs from p by at least 40%)<ref type="foot" target="#foot_1">2</ref> , e.g., It is unlikely that a man takes a picture. We hypothesize that language models and entailment recognition models should give a higher score (respectively likelihood and entailment probability) to the correct valid verbalization than to the invalid verbalization of p.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">WEP-UNLI: probability/WEP matching</head><p>The UNLI dataset annotates (PREMISE, HYPOTH-ESIS) pairs from the SNLI dataset <ref type="bibr" target="#b0">(Bowman et al., 2015)</ref> with joint probability scores p, totaling 55k training examples, 3k/3k validation/test examples. We use these examples to generate WEPunderstanding dataset with verbalization validity prediction as shown in the previous subsection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>% Round 1 template</head><p>Sampled round 1 (premise) p1::factA.</p><p>There is a very good chance that Bernhard is a swan. p2::factB.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>It is almost certain that Greg is gray.</head><p>p3::factC.</p><p>There is a better than even chance that Sandra left the apple.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>% Round 2 template</head><p>Sampled round 2 (premise, continued) p4::factX:-op1(fact1, fact2).</p><p>Chances are slight that if Bernhard is a swan, or Sandra left the apple, then sheep are afraid of mice.</p><p>p5::factY:-op2(fact3, fact4).</p><p>It is improbable that if Greg is gray, and Bernhard is a swan, then Lily is a rhino. p6::factZ:-op3(fact5, fact6).</p><p>There is a very good chance that if Greg is gray, and Sandra left the apple, then Sumit is thirsty.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>% Round 3 template</head><p>Sampled hypothesis hypothesis:-op4(fact7, fact8). Figure <ref type="figure">1</ref>: WEP-reasoning task constructions, with 2 hops. We sample randomly concrete facts f act i and probabilities p i then build modal sentences with verbalization templates. We randomly sample logical operators to compose the modal sentences from the previous rounds to construct a premise, then a hypothesis, and we use a probabilistic soft logic solver to compute the hypothesis probability. We then correctly and incorrectly verbalize this probability. This process generates data for the task of probability verbalization validity. 1 hop reasoning skips the second round: fact7 and fact8 are sampled from {factA,factB,factC}</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">WEP-Reasoning: WEP compositions</head><p>Here, our goal is to assess models' ability to reason over combinations of probabilistic statements. We construct synthetic (PREMISE, HYPOTHESIS, p) examples from random factoids extracted from the bAbI dataset <ref type="bibr" target="#b24">(Weston et al., 2015)</ref>. Figure <ref type="figure">1</ref> illustrates the construction of WEP-reasoning examples:</p><p>We randomly sample initial facts and associated probability levels, and we verbalize them with the previously mentioned templates from Table <ref type="table" target="#tab_3">3</ref> (Round 1). We further compose them with randomly sampled logical operators <ref type="bibr">(and, or, xor)</ref>. We then generate a hypothesis with logical combinations of the previous round. Finally, we feed the constructed premise and hypothesis to a probabilistic soft reasoning engine in order to derive the likelihood of the hypothesis given the premise. We rely on the ProbLog <ref type="bibr" target="#b4">(De Raedt et al., 2007)</ref> reasoner which implements <ref type="bibr" target="#b3">Dantsin (1992)</ref> semantics.</p><p>To evaluate different complexities of reasoning, we propose two variants: 2-hop reasoning, where facts in Round 2 combine facts from Round 1, and the final hypothesis combines facts from Round 2. and 1-hop reasoning where facts from the hypothesis combine Round 1 facts (Round 2 is skipped).</p><p>Since we want to sample more than two facts and we cannot a priori use text from the UNLI dataset, because UNLI only provides entailment likelihood for specific pairs. Combining several sentences could cause unaccounted interference. Therefore, we sample subject/verb/object factoids from the bAbI <ref type="bibr" target="#b24">(Weston et al., 2015)</ref> datasets instead, which is built with handwritten arbitrary factoids such as John went to the kitchen. To sample multiple factoids, we prevent any overlap of concepts <ref type="bibr">(verb, subject, object)</ref> between any pair of facts to make the facts independent of one another.</p><p>We sample probability levels from the list of medians of all WEP to prevent sampling the levels that too distant from a known WEP. When we assign a WEP to a probability level, we assume that the correct semantics is the consensual one, but humans differs slightly from this consensus. Still, when adding random perturbations of 20% to sampled p 1...6 , the hypothesis probability is perturbed by less than 40% for 98% of examples.</p><p>We generate 5k examples using the template depicted in Figure <ref type="figure">1</ref>, and use 10%/10% of the data for the validation/test splits. Appendix C shows the distribution of correct WEP for each dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>We conduct verbalization validity prediction (binary classification task of WEP correctness detection between two candidates) under two settings. Table <ref type="table">1</ref>: Test accuracy percentage of different models over the 3 WEP-understanding tasks. The last three rows display the accuracy when fine-tuning on each task, and transferability of the fine-tuned model outside the diagonal.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Zero-shot models</head><p>We use off-the-shelf language models to assign likelihood scores to a context and its conclusion. We evaluate the rate at which valid verbalization is scored higher than invalid verbalization. We refine the scores by also considering the average likelihood per token <ref type="bibr" target="#b1">(Brown et al., 2020;</ref><ref type="bibr" target="#b19">Schick and Schütze, 2021)</ref> and calibrated scores <ref type="bibr" target="#b1">(Brown et al., 2020;</ref><ref type="bibr" target="#b27">Zhao et al., 2021)</ref> where we divide the score of a PREMISE. T p (HYPOTHESIS). by the score of T p (HYPOTHESIS). We evaluate the normalized, length-normalized, and calibrated likelihood on the validation sets of each dataset and select the most accurate method for each dataset and model. We also consider a pretrained natural language inference model, which is trained to predict entailment scores between a context and a conclusion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>GPT2</head><p>We use the pretrained GPT2 base version with 127M parameters <ref type="bibr" target="#b16">(Radford et al., 2019)</ref>, which is a causal language model trained to estimate text likelihood. We concatenate the premise and hypothesis and compute their likelihood as a plausibility score.</p><p>RoBERTa We also use the pretrained RoBERTa base model with 123M parameters <ref type="bibr" target="#b10">(Liu et al., 2019)</ref> to score the masked language modeling likelihood of the premise/hypothesis pair.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>RoBERTa-MNLI</head><p>We fine-tune RoBERTa on the MNLI entailment detection dataset <ref type="bibr" target="#b25">(Williams et al., 2018)</ref> with standard hyperparameters (see the following subsection).</p><p>Human baseline To establish human baseline performance on the constructed dataset, we had two NLP researchers annotate 100 examples randomly sampled from the test set of each dataset, with a multiple-choice question answering setting.</p><p>Overall inter-annotator agreement is relatively high, with a Fleiss's κ of 0.70/0.68/0.71 for WEP Reasoning 1 hop, 2 hops and WEP-UNLI respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Fine-tuning and transfer across probes</head><p>We fine-tune RoBERTa-base models on our datasets, using standard <ref type="bibr" target="#b11">(Mosbach et al., 2021)</ref> hyperparameters<ref type="foot" target="#foot_2">3</ref> (3 epochs, sequence length of 256, learning rate of 2.10 -5 batch size of 16. We use length-normalization with GPT2 likelihood and calibration with RoBERTa likelihood as they worked best on the validation sets.). We use a multiplechoice-question answering setup (we predict logit scores for the valid and invalid verbalization, combine their score with a softmax, then optimize the likelihood of the valid verbalization). The same format is applied to all tasks, so we can also study the transfer of capacities acquired during fine-tuning of each probe, for instance, between probability matching and compositional reasoning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Results and discussion</head><p>Table <ref type="table">1</ref> shows the results of our experiments. The very low accuracy of causal and masked language models (first two rows) demonstrates how challenging the WEP-understanding tasks are.</p><p>RoBERTa fine-tuned on MNLI dataset performs better than chance for WEP-UNLI. MNLI contains 814 instances of probably in the MNLI dataset, but we found little to no evidence of WEP compositions among them, which can explain the results.</p><p>Finally, fine-tuning on the dataset of a particular probe leads to high test accuracy on the associated test set. More surprisingly, fine-tuning on one dataset also causes substantial accuracy gain on other probes. This suggests that our datasets can be incorporated in text encoder training in order to improve WEP handling.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>We investigated WEP understanding in neural language models with new datasets and experiments, showing that WEP processing is challenging but helped by supervision which leads to transferable improvement. Future work could extract WEP probability scales from the UNLI dataset as an alternative to human perception surveys, but our work suggests that this requires language modeling progress.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Associated probabilities</head></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>Either Bernhard is a swan or sheep are afraid of mice. It is likely that either Bernhard is a swan or sheep are afraid of mice. It is unlikely that either Bernhard is a swan or sheep are afraid of mice. 0</figDesc><table><row><cell>query(hypothesis). ProbLog Reasoner template Sample bAbI facts A,B,C,X,Y,Z p=0.7235 Sample chances p1…p6 T p1 hypothesis Sample facts 1...8 from facts T p' (hyp.): 1 premise hyp. p A,B,C,X,Y,Z in previous rounds Sample op 1…4 from {and, or, xor} distractor Compute hypothesis likelihood, relevant WEP factA Probability verbalization premise T p' (hyp.) y p' ≈ p likelihood T p' (hyp.): Reasoning Generated label y: p verbalization validity Generated input: premise, T p' (hyp.)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>Median probability percentage associated to words of estimative probability according to<ref type="bibr" target="#b7">(Fagen- Ulmschneider, 2015)</ref>. First and last words ( †) are taken from<ref type="bibr" target="#b8">(Kent, 1964)</ref>.</figDesc><table><row><cell>WEP</cell><cell>Median probability judgment</cell></row><row><cell cols="2">certain almost certain highly likely very good chance 80.0 ± 10.8 100  † 95.0 ± 10.9 90.0 ± 8.4 we believe 75.0 ± 15.0 likely 70.0 ± 11.3 probably 70.0 ± 12.9 probable 70.0 ± 14.7 better than even 60.0 ± 9.1 about even 50.0 ± 4.9 probably not 25.0 ± 14.4 we doubt 20.0 ± 16.9 unlikely 20.0 ± 15.0 little chance 10.0 ± 12.2 chances are slight 10.0 ± 10.9 improbable 10.0 ± 17.5 highly unlikely 5.0 ± 17.3 almost no chance 2.0 ± 17.0 impossible 0  †</cell></row><row><cell>B WEP verbalization template</cell><cell></cell></row><row><cell>WEP</cell><cell>Verbalization template</cell></row><row><cell>about even</cell><cell>chances are about even that [FACT]</cell></row><row><cell>almost certain</cell><cell>it is almost certain that [FACT]</cell></row><row><cell cols="2">almost no chance there is almost no chance that [FACT]</cell></row><row><cell>better than even</cell><cell>there is a better than even chance that [FACT]</cell></row><row><cell>certain</cell><cell>it is certain that [FACT]</cell></row><row><cell cols="2">chances are slight chances are slight that [FACT]</cell></row><row><cell>highly likely</cell><cell>it is highly likely that [FACT]</cell></row><row><cell>highly unlikely</cell><cell>it is highly unlikely that [FACT]</cell></row><row><cell>impossible</cell><cell>it is impossible that [FACT]</cell></row><row><cell>improbable</cell><cell>it is improbable that [FACT]</cell></row><row><cell>likely</cell><cell>it is likely that [FACT]</cell></row><row><cell>little chance</cell><cell>there is little chance that [FACT]</cell></row><row><cell>probable</cell><cell>it is probable that [FACT]</cell></row><row><cell>probably</cell><cell>it is probably the case that [FACT]</cell></row><row><cell>probably not</cell><cell>it is probably not the case that [FACT]</cell></row><row><cell>unlikely</cell><cell>it is unlikely that [FACT]</cell></row><row><cell cols="2">very good chance there is a very good chance that [FACT]</cell></row><row><cell>we believe</cell><cell>we believe that [FACT]</cell></row><row><cell>we doubt</cell><cell>we doubt that [FACT]</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 :</head><label>3</label><figDesc>Templates used to convert a fact and a WEP expressed uncertainty into a modal sentence.</figDesc><table><row><cell cols="2">C WEP frequencies on the generated datasets</cell><cell></cell><cell></cell></row><row><cell>WEP-reasoning</cell><cell>(1 hop) WEP-Reasoning</cell><cell>(2 hops) WEP-USNLI</cell><cell></cell></row><row><cell>WEP</cell><cell>frequency WEP</cell><cell>frequency WEP</cell><cell>frequency</cell></row><row><cell>about even probably not better than even we believe highly likely certain highly unlikely almost no chance impossible almost certain very good chance chances are slight little chance probable unlikely likely probably we doubt improbable</cell><cell>11.1 impossible 9.7 about even 7.7 probably not 7.1 highly unlikely 6.4 almost no chance 6.0 better than even 5.9 we believe 5.8 highly likely 5.3 very good chance 5.1 we doubt 4.7 improbable 3.6 chances are slight 3.5 unlikely 3.2 little chance 3.1 almost certain 3.1 certain 3.0 likely 2.9 probable 2.9 probably</cell><cell>13.2 impossible 10.8 better than even 9.0 certain 8.2 about even 8.0 almost certain 6.6 highly likely 4.3 very good chance 4.0 almost no chance 4.0 we believe 4.0 highly unlikely 3.9 probably not 3.9 likely 3.6 probable 3.5 probably 2.9 unlikely 2.7 little chance 2.5 chances are slight 2.4 improbable 2.2 we doubt</cell><cell>25.6 10.7 7.2 6.9 6.7 6.0 5.9 5.0 4.1 4.1 3.4 2.5 2.4 2.4 1.5 1.5 1.5 1.4 1.4</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4 :</head><label>4</label><figDesc>Validation set frequency of WEP in the correct answer of each dataset (percentages).</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>/hf.co/.../probability_words_nli</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>This threshold ensures sufficient distance, while also ensuring that each WEP has at least one possible distractor.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2"><p>Deviation from these hyperparameters did not yield significant improvement on the validation sets.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_3"><p>Kyle Richardson, Hai Hu, Lawrence Moss, and Ashish Sabharwal. 2020. Probing natural language inference models through semantic fragments. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 34, pages 8713-8721.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head n="6">Acknowledgements</head><p>This work is part of the <rs type="projectName">CALCULUS</rs> project, which is funded by the <rs type="funder">ERC Advanced</rs> Grant <rs type="grantNumber">H2020-ERC-2017 ADG 788506 4</rs> .</p></div>
			</div>
			<listOrg type="funding">
				<org type="funded-project" xml:id="_7AbRk5c">
					<idno type="grant-number">H2020-ERC-2017 ADG 788506 4</idno>
					<orgName type="project" subtype="full">CALCULUS</orgName>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A large annotated corpus for learning natural language inference</title>
		<author>
			<persName><forename type="first">R</forename><surname>Samuel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gabor</forename><surname>Bowman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Angeli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Potts</surname></persName>
		</author>
		<author>
			<persName><surname>Manning</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D15-1075</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Lisbon, Portugal</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="632" to="642" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Language models are few-shot learners</title>
		<author>
			<persName><forename type="first">Tom</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Mann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nick</forename><surname>Ryder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Melanie</forename><surname>Subbiah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jared</forename><forename type="middle">D</forename><surname>Kaplan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Prafulla</forename><surname>Dhariwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arvind</forename><surname>Neelakantan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pranav</forename><surname>Shyam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Girish</forename><surname>Sastry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amanda</forename><surname>Askell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in neural information processing systems</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="1877" to="1901" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Uncertain natural language inference</title>
		<author>
			<persName><forename type="first">Tongfei</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhengping</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Poliak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Keisuke</forename><surname>Sakaguchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Van Durme</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.acl-main.774</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="8772" to="8779" />
		</imprint>
	</monogr>
	<note>Online</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Probabilistic logic programs and their semantics</title>
		<author>
			<persName><forename type="first">Eugene</forename><surname>Dantsin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Logic Programming</title>
		<meeting><address><addrLine>Berlin, Heidelberg; Berlin Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1992">1992</date>
			<biblScope unit="page" from="152" to="164" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Problog: A probabilistic prolog and its application in link discovery</title>
		<author>
			<persName><forename type="first">Luc</forename><surname>De Raedt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Angelika</forename><surname>Kimmig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hannu</forename><surname>Toivonen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
		<meeting><address><addrLine>Hyderabad</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="2462" to="2467" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Words or numbers? communicating probability in intelligence analysis</title>
		<author>
			<persName><forename type="first">K</forename><surname>Mandeep</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">R</forename><surname>Dhami</surname></persName>
		</author>
		<author>
			<persName><surname>Mandel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">American Psychologist</title>
		<imprint>
			<biblScope unit="volume">76</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">549</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Solving probability problems in natural language</title>
		<author>
			<persName><forename type="first">Anton</forename><surname>Dries</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Angelika</forename><surname>Kimmig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jesse</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vaishak</forename><surname>Belle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luc</forename><surname>De</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Raedt</forename></persName>
		</author>
		<idno type="DOI">10.24963/ijcai.2017/556</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Sixth International Joint Conference on Artificial Intelligence, IJCAI-17</title>
		<meeting>the Twenty-Sixth International Joint Conference on Artificial Intelligence, IJCAI-17</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="3981" to="3987" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Perception of probability words</title>
		<author>
			<persName><forename type="first">Wade</forename><surname>Fagen-Ulmschneider</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Words of estimative probability</title>
		<author>
			<persName><forename type="first">Sherman</forename><surname>Kent</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Studies in intelligence</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="49" to="65" />
			<date type="published" when="1964">1964</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">How likely is that chance of thunderstorms? a study of how national weather service forecast offices use words of estimative probability and what they mean to the public</title>
		<author>
			<persName><forename type="first">Rachael</forename><forename type="middle">N</forename><surname>Emily D Lenhardt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Makenzie</forename><forename type="middle">J</forename><surname>Cross</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joseph</forename><forename type="middle">T</forename><surname>Krocak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sean</forename><forename type="middle">R</forename><surname>Ripberger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carol</forename><forename type="middle">L</forename><surname>Ernst</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hank</forename><forename type="middle">C</forename><surname>Silva</surname></persName>
		</author>
		<author>
			<persName><surname>Jenkins-Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Operational Meteorology</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">5</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<author>
			<persName><forename type="first">Yinhan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Myle</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Naman</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jingfei</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mandar</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Omer</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mike</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Veselin</forename><surname>Stoyanov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1907.11692</idno>
		<title level="m">Roberta: A robustly optimized bert pretraining approach</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">On the stability of fine-tuning bert: Misconceptions, explanations, and strong baselines</title>
		<author>
			<persName><forename type="first">Marius</forename><surname>Mosbach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maksym</forename><surname>Andriushchenko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dietrich</forename><surname>Klakow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Stress test evaluation for natural language inference</title>
		<author>
			<persName><forename type="first">Aakanksha</forename><surname>Naik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abhilasha</forename><surname>Ravichander</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Norman</forename><surname>Sadeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carolyn</forename><surname>Rose</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Graham</forename><surname>Neubig</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th International Conference on Computational Linguistics</title>
		<meeting>the 27th International Conference on Computational Linguistics<address><addrLine>Santa Fe, New Mexico, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="2340" to="2353" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Words or numbers? the evaluation of probability expressions in general practice</title>
		<author>
			<persName><forename type="first">B J O'</forename><surname>Brien</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of the Royal College of General Practitioners</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="98" to="100" />
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Words representing numeric probabilities in medical writing are ambiguous and misinterpreted</title>
		<author>
			<persName><forename type="first">E</forename><surname>Douglas</surname></persName>
		</author>
		<author>
			<persName><surname>Ott</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JSLS: Journal of the Society of Laparoscopic &amp; Robotic Surgeons</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Words and worlds; on the linguistic analysis of modality</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">R</forename><surname>Palmer</surname></persName>
		</author>
		<idno type="DOI">10.1016/0024-3841(92)90007-6</idno>
		<ptr target=".310" />
	</analytic>
	<monogr>
		<title level="j">Lingua</title>
		<editor>
			<persName><forename type="first">Richard</forename><surname>Matthews</surname></persName>
		</editor>
		<imprint>
			<biblScope unit="volume">191</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="87" to="90" />
			<date type="published" when="1991">1992. 1991</date>
			<pubPlace>frankfurt am main/bern/ new</pubPlace>
		</imprint>
	</monogr>
	<note>series xiv. pp. sfr 76.00 (pb</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Language models are unsupervised multitask learners</title>
		<author>
			<persName><forename type="first">Alec</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeffrey</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rewon</forename><surname>Child</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dario</forename><surname>Amodei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">OpenAI blog</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page">9</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">A primer in BERTology: What we know about how BERT works</title>
		<author>
			<persName><forename type="first">Anna</forename><surname>Rogers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Olga</forename><surname>Kovaleva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anna</forename><surname>Rumshisky</surname></persName>
		</author>
		<idno type="DOI">10.1162/tacl_a_00349</idno>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="842" to="866" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Annotating and recognizing event modality in text</title>
		<author>
			<persName><forename type="first">Roser</forename><surname>Saurí</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marc</forename><surname>Verhagen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Pustejovsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Nineteenth International Florida Artificial Intelligence Research Society Conference</title>
		<meeting>the Nineteenth International Florida Artificial Intelligence Research Society Conference<address><addrLine>Melbourne Beach, Florida, USA</addrLine></address></meeting>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2006-05-11">2006. May 11-13, 2006</date>
			<biblScope unit="page" from="333" to="339" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Exploiting cloze-questions for few-shot text classification and natural language inference</title>
		<author>
			<persName><forename type="first">Timo</forename><surname>Schick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hinrich</forename><surname>Schütze</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.eacl-main.20</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume</title>
		<meeting>the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="255" to="269" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Mindgames: Targeting theory of mind in large language models with dynamic epistemic modal logic</title>
		<author>
			<persName><forename type="first">Damien</forename><surname>Sileo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Antoine</forename><surname>Lernould</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.03353</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Beyond the imitation game: Quantifying and extrapolating the capabilities of language models</title>
		<author>
			<persName><forename type="first">Aarohi</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abhinav</forename><surname>Rastogi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abhishek</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abu</forename><surname>Awal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Md</forename><surname>Shoeb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abubakar</forename><surname>Abid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Fisch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Adam R Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aditya</forename><surname>Santoro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adrià</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><surname>Garriga-Alonso</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2206.04615</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Evidentiality for text trustworthiness detection</title>
		<author>
			<persName><forename type="first">Qi</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chu-Ren</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kai-Yun</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2010 Workshop on NLP and Linguistics: Finding the Common Ground</title>
		<meeting>the 2010 Workshop on NLP and Linguistics: Finding the Common Ground<address><addrLine>Uppsala, Sweden</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="10" to="17" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Mapping probability word problems to executable representations</title>
		<author>
			<persName><forename type="first">Simon</forename><surname>Suster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pieter</forename><surname>Fivez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pietro</forename><surname>Totis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Angelika</forename><surname>Kimmig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jesse</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luc</forename><surname>De Raedt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Walter</forename><surname>Daelemans</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.emnlp-main.294</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2021 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Punta Cana, Dominican Republic</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="3627" to="3640" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<author>
			<persName><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Antoine</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sumit</forename><surname>Chopra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><forename type="middle">M</forename><surname>Rush</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bart</forename><surname>Van Merriënboer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Armand</forename><surname>Joulin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1502.05698</idno>
		<title level="m">Towards ai-complete question answering: A set of prerequisite toy tasks</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">A broad-coverage challenge corpus for sentence understanding through inference</title>
		<author>
			<persName><forename type="first">Adina</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nikita</forename><surname>Nangia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Samuel</forename><surname>Bowman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1112" to="1122" />
		</imprint>
	</monogr>
	<note>Long Papers</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Ordinal common-sense inference</title>
		<author>
			<persName><forename type="first">Sheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rachel</forename><surname>Rudinger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Duh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Van Durme</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="379" to="395" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Calibrate before use: Improving few-shot performance of language models</title>
		<author>
			<persName><forename type="first">Zihao</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><surname>Wallace</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shi</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sameer</forename><surname>Singh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 38th International Conference on Machine Learning</title>
		<meeting>the 38th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">139</biblScope>
			<biblScope unit="page" from="12697" to="12706" />
		</imprint>
	</monogr>
	<note>Proceedings of Machine Learning Research</note>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title/>
		<author>
			<persName><surname>Pmlr</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Distributed nli: Learning to predict human opinion distributions for language reasoning</title>
		<author>
			<persName><forename type="first">Xiang</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yixin</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohit</forename><surname>Bansal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: ACL 2022</title>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
