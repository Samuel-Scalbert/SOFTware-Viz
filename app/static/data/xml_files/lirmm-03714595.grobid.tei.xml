<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Rewriting the Infinite Chase</title>
				<funder ref="#_QJ8duq6 #_wtb2T2a">
					<orgName type="full">EPSRC</orgName>
				</funder>
				<funder ref="#_WuMf5KZ #_Rn8xYqp">
					<orgName type="full">Concur</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Michael</forename><surname>Benedikt</surname></persName>
							<email>michael.benedikt@cs.ox.ac.uk</email>
							<affiliation key="aff0">
								<orgName type="institution">Oxford University</orgName>
								<address>
									<settlement>Oxford</settlement>
									<country key="GB">United Kingdom</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Maxime</forename><surname>Buron</surname></persName>
							<email>maxime.buron@inria.fr</email>
							<affiliation key="aff1">
								<orgName type="laboratory">LIRMM</orgName>
								<orgName type="institution" key="instit1">Inria</orgName>
								<orgName type="institution" key="instit2">Univ. of Montpellier Montpellier</orgName>
								<address>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Stefano</forename><surname>Germano</surname></persName>
							<email>stefano.germano@cs.ox.ac.uk</email>
							<affiliation key="aff2">
								<orgName type="institution">Oxford University</orgName>
								<address>
									<settlement>Oxford</settlement>
									<country key="GB">United Kingdom</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Kevin</forename><surname>Kappelmann</surname></persName>
							<email>kevin.kappelmann@tum.de</email>
							<affiliation key="aff3">
								<orgName type="institution">Technical University of Munich</orgName>
								<address>
									<settlement>Munich</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Boris</forename><surname>Motik</surname></persName>
							<email>boris.motik@cs.ox.ac.uk</email>
							<affiliation key="aff4">
								<orgName type="institution">Oxford University</orgName>
								<address>
									<settlement>Oxford</settlement>
									<country key="GB">United Kingdom</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Rewriting the Infinite Chase</title>
					</analytic>
					<monogr>
						<idno type="ISSN">2150-8097</idno>
					</monogr>
					<idno type="MD5">EBBFC9FB5E63429CCFF9EA596F58F8A9</idno>
					<idno type="DOI">10.14778/3551793.3551851</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-04-12T14:46+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Guarded tuple-generating dependencies (GTGDs) are a natural extension of description logics and referential constraints. It has long been known that queries over GTGDs can be answered by a variant of the chase-a quintessential technique for reasoning with dependencies. However, there has been little work on concrete algorithms and even less on implementation. To address this gap, we revisit Datalog rewriting approaches to query answering, where GTGDs are transformed to a Datalog program that entails the same base facts on each base instance. We show that the rewriting can be seen as containing "shortcut" rules that circumvent certain chase steps, we present several algorithms that compute the rewriting by simulating specific types of chase steps, and we discuss important implementation issues. Finally, we show empirically that our techniques can process complex GTGDs derived from synthetic and real benchmarks and are thus suitable for practical use.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Tuple-generating dependencies (TGDs) are a natural extension of description logics and referential constraints, and they are extensively used in databases. For example, they are used in data integration to capture semantic restrictions on data sources, mapping rules between data sources and the mediated schema, and constraints on the mediated schema. A fundamental computational problem in such applications is query answering under TGDs: given a query 𝑄, a collection of facts 𝐼 , and a set of TGDs Σ, find all the answers to 𝑄 that logically follow from 𝐼 and Σ. This problem has long been seen as a key component of a declarative data integration systems <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b32">33]</ref>, and it also arises in answering querying using views and accessing data sources with restrictions <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b36">37]</ref>.</p><p>The chase is a quintessential technique for reasoning with TGDs. It essentially performs "forward reasoning" by extending a set of given facts 𝐼 to a set 𝐼 ′ of all facts implied by 𝐼 and a set of TGDs Σ.</p><p>To answer a query, one can compute 𝐼 ′ using the chase and then evaluate the query in 𝐼 ′ . Unfortunately, the chase does not necessarily terminate, and in fact query answering for general TGDs is undecidable. Considerable effort was devoted to identifying classes of TGDs for which query answering is decidable. One line of work has focused on TGDs where the chase terminates; weakly-acyclic TGDs <ref type="bibr" target="#b20">[21]</ref> are perhaps the best-known such class. Another line of work focused on guarded TGDs (GTGDs). GTGDs are interesting since they can capture common constraints used in data integration, and ontologies expressed in variants of description logic (DL) <ref type="bibr" target="#b5">[6]</ref> can be translated directly into GTGDs. Example 1.1 illustrates the use of GTGDs used in a practical data integration scenario.</p><p>Example 1.1. The IEC Common Information Model (CIM) is an open model for describing power generation and distribution networks. It is frequently used as a semantic layer in applications that integrate data about power systems <ref type="bibr" target="#b21">[22]</ref>. CIM is defined in UML, but its formal semantics has been provided by a translation into an OWL ontology. The domain of CIM is described using classes and properties, which correspond to unary and binary relations, respectively. Moreover, semantic relationships between classes and properties are represented as OWL axioms, many of which can be translated into GTGDs. A significant portion of CIM describes power distribution equipment using GTGDs such as (1)- <ref type="bibr" target="#b3">(4)</ref>.</p><p>ACEquipment(𝑥) → ∃𝑦 hasTerminal(𝑥, 𝑦) ∧ ACTerminal(𝑦) <ref type="bibr" target="#b0">(1)</ref> ACTerminal(𝑥) → Terminal(𝑥) <ref type="bibr" target="#b1">(2)</ref> hasTerminal(𝑥, 𝑧) ∧ Terminal(𝑧) → Equipment(𝑥) <ref type="bibr" target="#b2">(3)</ref> ACTerminal(𝑥) → ∃𝑦 partOf(𝑥, 𝑦) ∧ ACEquipment(𝑦) <ref type="bibr" target="#b3">(4)</ref> Data integration is then achieved by populating the vocabulary using mappings, which can be seen queries over the data sources that produce a set of facts called a base instance. A key issue in data integration is dealing with incompleteness of data sources. For example, it is not uncommon that one data source mentions two switches sw 1 and sw 2 , while another data source provides information about connected terminals only for switch sw 1 .</p><p>ACEquipment(sw 1 ) ACEquipment(sw 2 )</p><p>(5)</p><p>hasTerminal(sw 1 , trm 1 ) ACTerminal(trm 1 )</p><p>GTGDs can be used to complete the data. For example, if a user asks to list all pieces of equipment known to the system, both sw 1 and sw 2 will be returned, even though the base instance does not explicitly classify either switch as a piece of equipment. ⊳ Even though the chase for GTGDs does not necessarily terminate, query answering for GTGDs is decidable <ref type="bibr" target="#b33">[34]</ref>. To prove decidability, one can argue that the result of a chase is tree-like-that is, the facts derived by the chase can be arranged into a particular kind of tree. Next, one can develop a finite representation of potentially infinite trees. One possibility is to describe the trees using a finite tree automaton, so query answering can be reduced to checking automaton emptiness. While theoretically elegant, this method is not amenable to practical use: building the automaton and the emptiness test are both complex and expensive, and such algorithms always exhibit worst-case complexity. Alternatively, one can use blocking to identify a tree prefix sufficient for query evaluation. Blocking is commonly used in description logic reasoning <ref type="bibr" target="#b5">[6]</ref>, and it was later lifted to guarded logic <ref type="bibr" target="#b26">[27]</ref>. However, blocking was shown to be impractical for query answering: the required tree prefix can be much larger than the base instance 𝐼 so, as 𝐼 grows in size, the size of the tree prefix becomes unmanageable.</p><p>More promising query answering techniques for GTGDs are based on Datalog rewriting <ref type="bibr" target="#b34">[35]</ref>. The idea was initially proposed by Marnette <ref type="bibr" target="#b34">[35]</ref>, and it was later extended to broader classes of TGDs <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b23">24]</ref> and settings <ref type="bibr" target="#b10">[11]</ref>. The main idea is to transform an input set of GTGDs Σ into a set rew(Σ) of Datalog rules such that Σ and rew(Σ) entail the same base facts on each base instance. Thus, given a base instance 𝐼 , instead of computing the chase of 𝐼 and Σ (which may not terminate), we compute the chase 𝐼 ′ of 𝐼 and rew(Σ). Since Datalog rules essentially correspond to existential-free TGDs, 𝐼 ′ is always finite and it can be computed using optimized Datalog engines. Moreover, Σ and rew(Σ) entail the same base facts on 𝐼 , so we can answer any existential-free conjunctive query (i.e., queries where all variables are answer variables) by evaluating in 𝐼 ′ . The restriction to existential-free queries is technical: existentially quantified variables in a query can be matched to objects introduced by existential quantification, and these are not preserved in a Datalog rewriting. However, practical queries are typically existential-free since all query variables are usually answer variables.</p><p>Example 1.2. A Datalog program consisting of rules (2)-( <ref type="formula">3</ref>) and ( <ref type="formula" target="#formula_1">7</ref>) is a rewriting of GTGDs (1)- <ref type="bibr" target="#b3">(4)</ref>.</p><formula xml:id="formula_1">ACEquipment(𝑥) → Equipment(𝑥)<label>(7)</label></formula><p>Rule ( <ref type="formula" target="#formula_1">7</ref>) is a logical consequence of GTGDs ( <ref type="formula">1</ref>)- <ref type="bibr" target="#b2">(3)</ref>, and it provides a "shortcut" for the inferences of the other GTGDs. ⊳ The advantage of rewriting-based approaches is scalability in the size of the base instance 𝐼 . Such techniques have been implemented and practically validated in the context of description logics <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b28">29]</ref>, but practical algorithms have not yet been proposed for GTGDs. This raises several theoretical and practical questions.</p><p>How to compute the Datalog rules needed for completeness? Existing Datalog rewriting algorithms often prove their correctness indirectly. For example, completeness of a rewriting algorithm for description logics <ref type="bibr" target="#b28">[29]</ref> uses a proof-theoretic argument, which does not provide an intuition about why the algorithm actually works.</p><p>Our first contribution is to relate Datalog rewriting approaches to the chase. Towards this goal, we introduce the one-pass variant of the chase, which we use to develop a general completeness criterion for Datalog rewriting algorithms. This, in turn, provides us with a better understanding of how rewriting algorithms work, and it allows us to discover new algorithms in a systematic way.</p><p>What does the space of rewriting algorithms look like? Computing the rewriting rew(Σ) usually requires extending Σ with certain logical consequences of Σ. We show that we can select the relevant consequences using different criteria. Some methods require deriving TGDs with existential quantifiers in the head, others generate Datalog rules directly, and yet other methods derive logical implications with function symbols. We relate all of these methods to the one-pass chase mentioned earlier, and we provide theoretical worst-case guarantees about their performance.</p><p>How do we ensure scalability of rewriting algorithms? Implementations of Datalog rewriting algorithms have thus far been mainly considered in the setting of description logics <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b37">38]</ref>. To the best of our knowledge, we provide the first look at optimization and implementation of Datalog rewriting algorithms for GTGDs. We achieve scalability by developing and combining various indexing and redundancy elimination techniques.</p><p>How do we evaluate rewriting algorithms? We provide a benchmark for GTGD query answering algorithms, and we use it to evaluate our methods. To the best of our knowledge, this is the first attempt to evaluate query answering techniques for GTGDs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Summary of contributions.</head><p>We give an extensive account of Datalog rewriting for GTGDs. In particular, we develop a theoretical framework that allows us to understand, motivate, and show completeness of rewriting algorithms. Moreover, we present several concrete algorithms, establish worst-case complexity bounds, and discuss their relationships. We complement this theoretical analysis with a discussion of how to adapt techniques from first-order theorem proving to the setting of GTGDs. Finally, we empirically evaluate our techniques using an extensive benchmark. All proofs and the details of one algorithm are given in the appendix of this paper. Our implementation and a more detailed account of our experimental results can be found online <ref type="bibr" target="#b12">[13]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head><p>Answering queries via rewriting has been extensively considered in description logics. For example, queries over ontologies in the DL-Lite family of languages can be rewritten into first-order queries <ref type="bibr" target="#b17">[18]</ref>, and fact entailment for SH IQ ontologies can be rewritten to disjunctive Datalog <ref type="bibr" target="#b28">[29]</ref>. These techniques provide the foundation for the Ontop <ref type="bibr" target="#b16">[17]</ref> and KAON2 <ref type="bibr" target="#b37">[38]</ref> systems, respectively.</p><p>In the context of TGDs, first-order rewritings were considered in data integration systems with inclusion and key dependencies <ref type="bibr" target="#b15">[16]</ref>. Datalog rewritings have been considered for GTGDs <ref type="bibr" target="#b34">[35]</ref> and their extensions such as frontier-guarded TGDs <ref type="bibr" target="#b10">[11]</ref>, and nearly frontierguarded and nearly guarded TGDs <ref type="bibr" target="#b23">[24]</ref>. The focus in these studies was to identify complexity bounds and characterize expressivity of TGD classes rather than provide practical algorithms. Existing implements of query answering for TGDs use first-order rewriting for linear TGDs <ref type="bibr" target="#b47">[48]</ref>, chase variants for TGDs with terminating chase <ref type="bibr" target="#b13">[14]</ref>, chase with blocking for warded TGDs <ref type="bibr" target="#b11">[12]</ref>, chase with the magic sets transformation for shy TGDs <ref type="bibr" target="#b2">[3]</ref>, and Datalog rewriting for separable and weakly separable TGDs <ref type="bibr" target="#b48">[49]</ref>. These TGD classes are all different from GTGDs, and we are unaware of any attempts to implement and evaluate GTGD rewriting algorithms.</p><p>Our algorithms are related to resolution-based decision procedures for variants of guarded logics <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b49">50]</ref>. Moreover, our characterization of Datalog rewritings is related to a chase variant used to answer queries over data sources with access patterns <ref type="bibr" target="#b3">[4]</ref>. Finally, a variant of the one-pass chase from Section 4 was generalized to the broader context of disjunctive GTGDs <ref type="bibr" target="#b30">[31]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">PRELIMINARIES</head><p>In this section, we recapitulate the well-known definitions and notation that we use to formalize our technical results.</p><p>TGDs. Let consts, vars, and nulls be pairwise disjoint, infinite sets of constants, variables, and labeled nulls, respectively. A term is a constant, a variable, or a labeled null; moreover, a term is ground if it does not contain a variable. For 𝛼 a formula or a set thereof, consts(𝛼), vars(𝛼), nulls(𝛼), and terms(𝛼) are the sets of constants, free variables, labeled nulls, and terms, respectively, in 𝛼.</p><p>A schema is a set of relations, each of which is associated with a nonnegative integer arity. A fact is an expression of the form 𝑅( ì 𝑡), where 𝑅 is an 𝑛-ary relation and ì</p><p>𝑡 is a vector of 𝑛 ground terms; moreover, 𝑅( ì 𝑡) is a base fact if ì 𝑡 contains only constants. An instance 𝐼 is a finite set of facts, and 𝐼 is a base instance if it contains only base facts. An atom is an expression of the form 𝑅( ì 𝑡), where 𝑅 is an 𝑛-ary relation and ì</p><p>𝑡 is a vector of 𝑛 terms not containing labeled nulls. Thus, each base fact is an atom. We often treat conjunctions as sets of conjuncts; for example, for 𝛾 a conjunction of facts and 𝐼 an instance, 𝛾 ⊆ 𝐼 means that each conjunct of 𝛾 is contained 𝐼 .</p><p>A tuple generating dependency (TGD) is a first-order formula of the form ∀ì 𝑥 [𝛽 → ∃ì 𝑦 𝜂], where 𝛽 and 𝜂 are conjunctions of atoms, 𝜂 is not empty, the free variables of 𝛽 are ì 𝑥, and the free variables of 𝜂 are contained in ì 𝑥 ∪ ì 𝑦. Conjunction 𝛽 is the body and formula ∃ì 𝑦 𝜂 is the head of the TGD. We often omit ∀ì 𝑥 when writing a TGD. A TGD is full if ì 𝑦 is empty; otherwise, the TGD is non-full. A TGD is in head-normal form if it is full and its head contains exactly one atom, or it is non-full and each head atom contains at least one existentially quantified variable. Each TGD can be easily transformed to an equivalent set of TGDs in head-normal form. A full TGD in head-normal form is a Datalog rule, and a Datalog program is a finite set of Datalog rules. The head-width (hwidth) and the body-width (bwidth) of a TGD are the numbers of variables in the head and body, respectively; these are extended to sets of TGDs by taking the maxima over all TGDs. The notion of an instance satisfying a TGD is inherited from first-order logic. A base fact 𝐹 is entailed by an instance 𝐼 and a finite set of TGDs Σ, written 𝐼, Σ |= 𝐹 , if 𝐹 ∈ 𝐼 ′ holds for each instance 𝐼 ′ ⊇ 𝐼 that satisfies Σ.</p><p>A substitution 𝜎 is a function that maps finitely many variables to terms. The domain and the range of 𝜎 are dom(𝜎) and rng(𝜎), respectively. For 𝛾 a term, a vector of terms, or a formula, 𝜎 (𝛾) is obtained by replacing each free occurrence of a variable 𝑥 in 𝛾 such that 𝑥 ∈ dom(𝜎) with 𝜎 (𝑥).</p><p>Fact Entailment for Guarded TGDs. Fact entailment for general TGDs is semidecidable, and many variants of the chase can be used to define a (possibly infinite) set of facts that is homomorphically contained in each modef of a base instance and a set of TGDs.</p><p>Fact entailment is decidable for guarded TGDs (GTGDs): a TGD ∀ì 𝑥 [𝛽 → ∃ì 𝑦 𝜂] is guarded if 𝛽 contains an atom (called a guard) that contains all variables of ì 𝑥. Note that a guard need not be unique in 𝛽. Let Σ be a finite set of GTGDs. We say that a set of ground terms 𝐺 is Σ-guarded by a fact 𝑅( ì 𝑡) if 𝐺 ⊆ ì 𝑡 ∪ consts(Σ). Moreover, 𝐺 is Σ-guarded by a set of facts 𝐼 if 𝐺 is Σ-guarded by some fact in 𝐼 . Finally, a fact 𝑆 ( ì 𝑢) is Σ-guarded by a fact 𝑅( ì 𝑡) (respectively a set of facts 𝐼 ) if ì 𝑢 is Σ-guarded by 𝑅( ì 𝑡) (respectively 𝐼 ). By adapting the reasoning techniques for guarded logics <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b46">47]</ref> and referential database constraints <ref type="bibr" target="#b29">[30]</ref>, fact entailment for GTGDs can be decided by a chase variant that works on tree-like structures. A chase tree 𝑇 consists of a directed tree, one tree vertex that is said to be recently updated, and a function mapping each vertex 𝑣 in the tree to a finite set of facts 𝑇 (𝑣). A chase tree 𝑇 can be transformed to another chase tree 𝑇 ′ in the following two ways.</p><p>• One can apply a chase step with a GTGD 𝜏 = ∀ì 𝑥 [𝛽 → ∃ì 𝑦 𝜂] in head-normal form. The precondition is that there exist a vertex 𝑣 in 𝑇 and a substitution 𝜎 with domain ì 𝑥 such that 𝜎 (𝛽) ⊆ 𝑇 (𝑣). The result of the chase step is obtained as follows.</p><p>-If 𝜏 is full (and thus 𝜂 is a single atom), then chase tree 𝑇 ′ is obtained from 𝑇 by making 𝑣 recently updated in 𝑇 ′ and setting 𝑇 ′ (𝑣) = 𝑇 (𝑣) ∪ {𝜎 (𝜂)}.</p><p>-If 𝜏 is not full, then 𝜎 is extended to a substitution 𝜎 ′ that maps each variable in ì 𝑦 to a labeled null not occurring in 𝑇 , and chase tree 𝑇 ′ is obtained from 𝑇 by introducing a fresh child 𝑣 ′ of 𝑣, making 𝑣 ′ recently updated in 𝑇 ′ , and setting 𝑇 (𝑣 ′ ) = 𝜎 ′ (𝜂) ∪ {𝐹 ∈ 𝑇 (𝑣) | 𝐹 is Σ-guarded by 𝜎 ′ (𝜂)}.</p><p>• One can apply a propagation step from a vertex 𝑣 to a vertex 𝑣 ′ in 𝑇 . Chase tree 𝑇 ′ is obtained from 𝑇 by making 𝑣 ′ recently updated in 𝑇 ′ and setting 𝑇 ′ (𝑣 ′ ) = 𝑇 (𝑣 ′ ) ∪ 𝑆 for some nonempty set 𝑆 satisfying 𝑆 ⊆ {𝐹 ∈ 𝑇 (𝑣) | 𝐹 is Σ-guarded by 𝑇 (𝑣 ′ )}.</p><p>A tree-like chase sequence for a base instance 𝐼 and a finite set of GTGDs Σ in head-normal form is a finite sequence of chase trees 𝑇 0 , . . . ,𝑇 𝑛 such that 𝑇 0 contains exactly one root vertex 𝑟 that is recently updated in 𝑇 0 and 𝑇 0 (𝑟 ) = 𝐼 , and each 𝑇 𝑖 with 0 &lt; 𝑖 ≤ 𝑛 is obtained from 𝑇 𝑖 -1 by a chase step with some 𝜏 ∈ Σ or a propagation step. For each vertex 𝑣 in 𝑇 𝑛 and each fact 𝐹 ∈ 𝑇 𝑛 (𝑣), this sequence is a tree-like chase proof of 𝐹 from 𝐼 and Σ. It is well known that 𝐼, Σ |= 𝐹 if and only if there exists a tree-like chase proof of 𝐹 from 𝐼 and Σ (e.g., <ref type="bibr" target="#b33">[34]</ref>). Example 4.3 in Section 4 illustrates these definitions. One can decide 𝐼, Σ |= 𝐹 by imposing an upper bound on the size of chase trees that need to be considered <ref type="bibr" target="#b33">[34]</ref>.</p><p>Rewriting. A Datalog rewriting of a finite set of TGDs Σ is a Datalog program rew(Σ) such that 𝐼, Σ |= 𝐹 if and only if 𝐼, rew(Σ) |= 𝐹 for each base instance 𝐼 and each base fact 𝐹 . If Σ contains GTGDs only, then a Datalog rewriting rew(Σ) is guaranteed to exist (which is not the case for general TGDs). Thus, we can reduce fact entailment for GTGDs to Datalog reasoning, which can be solved using highly optimized Datalog techniques <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b37">38]</ref>. For example, given a base instance 𝐼 , we can compute the materialization of rew(Σ) on 𝐼 by applying the rules of rew(Σ) to 𝐼 up to a fixpoint. This will compute precisely all base facts entailed by rew(Σ) (and thus also by Σ) on 𝐼 , and it can be done in time polynomial in the size of 𝐼 .</p><p>Encoding Existentials by Function Symbols. It is sometimes convenient to represent existentially quantified values using functional terms. In such cases, we use a slightly modified notions of terms, atoms, and rules. It will be clear from the context which definitions we use in different parts of the paper.</p><p>We adjust the notion of a term as either a constant, a variable, or an expression of the form 𝑓 ( ì 𝑡) where 𝑓 is an 𝑛-ary function symbol and ì 𝑡 is a vector of 𝑛 terms. The notions of ground terms, (base) facts, and (base) instances, and atoms are the same as before, but they use the modified notion of terms. A rule is a first-order implication of the form ∀ì 𝑥 [𝛽 → 𝐻 ] where 𝛽 is a conjunction of atoms whose free variables are ì 𝑥, and 𝐻 is an atom whose free variables are contained in ì 𝑥; as for TGDs, we often omit ∀ì 𝑥. A rule thus contains no existential quantifiers, but its head contains exactly one atom that can contain function symbols. Also, a Datalog rule, a function-free rule, and a full TGD in head-normal form are all synonyms. Finally, a base fact still contains only constants.  <ref type="bibr" target="#b40">[41,</ref><ref type="bibr" target="#b41">42]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">CHASE-BASED DATALOG REWRITING</head><p>Our objective is to develop rewriting algorithms that can handle complex GTGDs. Each algorithm will derive Datalog rules that provide "shortcuts" in tree-like chase proofs: instead of introducing a child vertex 𝑣 ′ using a chase step with a non-full GTGD at vertex 𝑣, performing some inferences in 𝑣 ′ , and then propagating a derived fact 𝐹 back from 𝑣 ′ to 𝑣, these "shortcuts" will derive 𝐹 in one step without having to introduce 𝑣 ′ . The main question is how to derive all "shortcuts" necessary for completeness while keeping the number of derivations low. In this section we lay the technical foundations that will allow us to study different strategies for deriving "shortcuts" in Section 5. We show that, instead of considering arbitrary chase proofs, we can restrict our attention to chase proofs that are one-pass according to Definition 4.1. Then, we identify the parts of such proofs that we need to be able to circumvent using "shortcuts". Finally, we present sufficient conditions that guarantee completeness of rewriting algorithms. We start by describing formally the structure of tree-like chase proofs. Definition 4.1. A tree-like chase sequence 𝑇 0 , . . . ,𝑇 𝑛 for a base instance 𝐼 and a finite set of GTGDs Σ in head-normal form is onepass if, for each 0 &lt; 𝑖 ≤ 𝑛, chase tree 𝑇 𝑖 is obtained by applying one of the following two steps to the recently updated vertex 𝑣 of 𝑇 𝑖 -1 : • a propagation step copying exactly one fact from 𝑣 to its parent, or</p><p>• a chase step with a GTGD from Σ provided that no propagation step from 𝑣 to the parent of 𝑣 is applicable.</p><p>Thus, each step in a tree-like chase sequence is applied to a "focused" vertex; steps with non-full TGDs move the "focus" from a parent to a child, and propagation steps move the "focus" in the opposite direction. Moreover, once a child-to-parent propagation takes place, the child cannot be revisited in further steps. Theorem 4.2 states a key property about chase proofs for GTGDs: whenever a proof exists, there exists a one-pass proof too. Example 4.3 illustrates important aspects of Definition 4.1 and Theorem 4.2. Theorem 4.2. For each base instance 𝐼 , each finite set of GTGDs Σ in head-normal form, and each base fact 𝐹 such that 𝐼, Σ |= 𝐹 , there exists a one-pass tree-like chase proof of 𝐹 from 𝐼 and Σ.</p><p>Example 4.3. Let 𝐼 = {𝐴(𝑎, 𝑏)} and let Σ contain GTGDs (8)- <ref type="bibr" target="#b12">(13)</ref>.</p><formula xml:id="formula_2">𝐴(𝑥 1 , 𝑥 2 ) → ∃𝑦 𝐵(𝑥 1 , 𝑦) ∧ 𝐶 (𝑥 1 , 𝑦)<label>(8)</label></formula><formula xml:id="formula_3">𝐶 (𝑥 1 , 𝑥 2 ) → 𝐷 (𝑥 1 , 𝑥 2 ) (9) 𝐵(𝑥 1 , 𝑥 2 ) ∧ 𝐷 (𝑥 1 , 𝑥 2 ) → 𝐸 (𝑥 1 )<label>(10)</label></formula><formula xml:id="formula_4">𝐴(𝑥 1 , 𝑥 2 ) ∧ 𝐸 (𝑥 1 ) → ∃𝑦 1 , 𝑦 2 𝐹 (𝑥 1 , 𝑦 1 ) ∧ 𝐹 (𝑦 1 , 𝑦 2 ) (11) 𝐸 (𝑥 1 ) ∧ 𝐹 (𝑥 1 , 𝑥 2 ) → 𝐺 (𝑥 1 )<label>(12)</label></formula><formula xml:id="formula_5">𝐵(𝑥 1 , 𝑥 2 ) ∧ 𝐺 (𝑥 1 ) → 𝐻 (𝑥 1 )<label>(13)</label></formula><p>A tree-like chase sequence for 𝐼 and Σ is shown in Figure <ref type="figure" target="#fig_4">1</ref>, and it provides a proof of the base fact 𝐻 (𝑎) from 𝐼 and Σ. The recently updated vertex of each chase tree is shown in red. We denote the root vertex by 𝑟 , and its left and right children by 𝑣 1 and 𝑣 2 , respectively. The step producing 𝑇 7 from 𝑇 6 does not satisfy the requirements of one-pass chase: it propagates the fact 𝐺 (𝑎) from 𝑣 2 to 𝑣 1 , where the latter is a "sibling" of the former.</p><p>To obtain a one-pass chase sequence, we could try to "slow down" the propagation of 𝐺 (𝑎): we first propagate 𝐺 (𝑎) from 𝑣 2 to 𝑟 , and then from 𝑟 to 𝑣 1 . The former step is allowed in one-pass chase, but the latter step is not: once we leave the subtree rooted at 𝑣 1 , we are not allowed to revisit it later. Note, however, that 𝐵(𝑎, 𝑛 1 ) and 𝐺 (𝑎) must occur jointly in a vertex of a chase tree in order to derive 𝐻 (𝑎). Moreover, note that no reordering of chase steps will The solution, which is used in the proof of Theorem 4.2, is to replace propagation to the child by "regrowing" the entire subtree.</p><p>In our example, we replace the steps producing 𝑇 7 and 𝑇 8 with the steps shown in Figure <ref type="figure">2</ref>. Chase tree 𝑇 1  7 is obtained from 𝑇 6 by propagating 𝐺 (𝑎) from 𝑣 2 to 𝑟 . Then, instead of propagating 𝐺 (𝑎) from 𝑟 to 𝑣 1 , a new vertex 𝑣 3 is created in 𝑇 2  7 by reapplying (8) and fact 𝐺 (𝑎) is pushed to 𝑣 3 as part of the chase step with a non-full GTGD. This allows 𝐻 (𝑎) to be derived in vertex 𝑣 3 of 𝑇 1  8 . Fact 𝐷 (𝑛 3 ) can be derived in vertex 𝑣 3 , but this is not needed to prove 𝐻 (𝑎). Moreover, our chase is oblivious <ref type="bibr" target="#b33">[34]</ref>: a non-full TGD can be applied to the same facts several times, each time introducing a fresh vertex and fresh labeled nulls. The number of children of a vertex is thus not naturally bounded, and our objective is not to apply all chase steps exhaustively to obtain a universal model of Σ. Instead, we are interested only in chase proofs, which must only contain steps needed to demonstrate entailment of a specific fact. ⊳ One-pass chase proofs are interesting because they can be decomposed into loops as described in Definition 4.4. Definition 4.4. For 𝑇 0 , . . . ,𝑇 𝑛 a one-pass tree-like chase sequence for some 𝐼 and Σ, a loop at vertex 𝑣 with output fact 𝐹 is a subsequence 𝑇 𝑖 , . . . ,𝑇 𝑗 with 0 ≤ 𝑖 &lt; 𝑗 ≤ 𝑛 such that • 𝑇 𝑖+1 is obtained by a chase step with a non-full GTGD,</p><p>• 𝑇 𝑗 is obtained by a propagation step that copies 𝐹 , and</p><p>• 𝑣 is the recently updated vertex of both 𝑇 𝑖 and 𝑇 𝑗 .</p><p>The length of the loop is defined as 𝑗 -𝑖.</p><p>Example 4.5. Subsequence 𝑇 0 ,𝑇 1 ,𝑇 2 ,𝑇 3 ,𝑇 4 of the chase trees from Example 4.3 is a loop at the root vertex 𝑟 with output fact 𝐸 (𝑎): chase tree 𝑇 1 is obtained by applying a non-full GTGD to 𝑟 , and chase tree 𝑇 4 is obtained by propagating 𝐸 (𝑎) back to 𝑟 . Analogously, 𝑇 4 ,𝑇 5 ,𝑇 6 ,𝑇 1  7 is another loop at 𝑟 with output fact 𝐺 (𝑎). Finally, 𝑇 1  7 ,𝑇 2  7 ,𝑇 1 8 ,𝑇 9 is a loop at 𝑟 with output fact 𝐻 (𝑎). ⊳ Thus, a loop is a subsequence of chase steps that move the "focus" from a parent to a child vertex, perform a series of inferences in the child and its descendants, and finally propagate one fact back to the parent. If non-full TGDs are applied to the child, then the loop can be recursively decomposed into further loops at the child. The properties of the one-pass chase ensure that each loop is finished as soon as a fact is derived in the child that can be propagated to the parent, and that the vertices introduced in the loop are not revisited at any later point in the proof. In this way, each loop at vertex 𝑣 can be seen as taking the set 𝑇 𝑖 (𝑣) as input and producing the output fact 𝐹 that is added to 𝑇 𝑗 (𝑣). This leads us to the following idea: for each loop with the input set of facts 𝑇 𝑖 (𝑣), a rewriting should contain a "shortcut" Datalog rule that derives the loop's output.</p><p>Example 4.6. One can readily check that rules ( <ref type="formula" target="#formula_6">14</ref>)-( <ref type="formula" target="#formula_8">16</ref>) provide "shortcuts" for the three loops identified in Example 4.5.</p><formula xml:id="formula_6">𝐴(𝑥 1 , 𝑥 2 ) → 𝐸 (𝑥 1 )<label>(14)</label></formula><formula xml:id="formula_7">𝐴(𝑥 1 , 𝑥 2 ) ∧ 𝐸 (𝑥 1 ) → 𝐺 (𝑥 1 )<label>(15)</label></formula><formula xml:id="formula_8">𝐴(𝑥 1 , 𝑥 2 ) ∧ 𝐺 (𝑥 1 ) → 𝐻 (𝑥 1 )<label>(16)</label></formula><p>Moreover, these are all relevant "shortcuts": the union of rules ( <ref type="formula" target="#formula_6">14</ref>)-( <ref type="formula" target="#formula_8">16</ref>) and the Datalog rules from Example 4.3-that is, rules ( <ref type="formula">9</ref>), ( <ref type="formula" target="#formula_3">10</ref>), <ref type="bibr" target="#b11">(12)</ref>, and (13)-is a rewriting of the set Σ from Example 4.1. ⊳ These ideas are formalized in Proposition 4.7, which will provide us with a correctness criterion for our algorithms. Proposition 4.7. A Datalog program Σ ′ is a rewriting of a finite set of GTGDs Σ in head-normal form if</p><formula xml:id="formula_9">• Σ ′ is a logical consequence of Σ,</formula><p>• each Datalog rule of Σ is a logical consequence of Σ ′ , and</p><p>• for each base instance 𝐼 , each one-pass tree-like chase sequence 𝑇 0 , . . . ,𝑇 𝑛 for 𝐼 and Σ, and each loop 𝑇 𝑖 , . . . ,𝑇 𝑗 at the root vertex 𝑟 with output fact 𝐹 , there exist a Datalog rule 𝛽 → 𝐻 ∈ Σ ′ and a substitution 𝜎 such that 𝜎 (𝛽) ⊆ 𝑇 𝑖 (𝑟 ) and 𝜎 (𝐻 ) = 𝐹 .</p><p>Intuitively, the first condition ensures soundness: rewriting Σ ′ should not derive more facts than Σ. The second condition ensures that Σ ′ can mimic direct applications of Datalog rules from Σ at the root vertex 𝑟 . The third condition ensures that Σ ′ can reproduce the output of each loop at vertex 𝑟 using a "shortcut" Datalog rule.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">REWRITING ALGORITHMS</head><p>We now consider ways to produce "shortcut" Datalog rules satisfying Proposition 4.7. In Subsection 5.1 we present the ExbDR algorithm that manipulates GTGDs directly, and in Subsections 5.2 and 5.3 we present the SkDR and HypDR algorithms, respectively, that manipulate rules obtained by Skolemizing the input GTGDs. All of these algorithms can produce intermediate GTGDs/rules that are not necessarily Datalog rules. In Appendix E we present the FullDR algorithm that manipulates GTGDs, but derives only Datalog rules. However, the performance of FullDR proved to not be competitive, so we do not discuss it any further here.</p><p>Each algorithm is defined by an inference rule Inf that can be applied to several TGDs/rules to derive additional TGDs/rules. For simplicity, we use the same name for the rule and the resulting algorithm. Given a set of GTGDs Σ, the algorithm applies Inf to (the Skolemization of) Σ as long as possible and then returns all produced Datalog rules. This process, however, can derive a large number of TGDs/rules, so it is vital to eliminate TGDs/rules whenever possible. We next define notions of redundancy that can be used to discard certain TGDs/rules produced by Inf.</p><formula xml:id="formula_10">Definition 5.1. A TGD 𝜏 1 = ∀ì 𝑥 1 [𝛽 1 → ∃ì 𝑦 1 𝜂 1 ] is a syntactic tau- tology if it is in head-normal form and 𝛽 1 ∩ 𝜂 1 ≠ ∅. TGD 𝜏 1 subsumes a TGD 𝜏 2 = ∀ì 𝑥 2 [𝛽 2 → ∃ì 𝑦 2 𝜂 2 ] if there exists a substitution 𝜇 such that dom(𝜇) = ì 𝑥 1 ∪ ì 𝑦 1 , 𝜇 ( ì 𝑥 1 ) ⊆ ì 𝑥 2 , 𝜇 ( ì 𝑦 1 ) ⊆ ì 𝑦 1 ∪ ì 𝑦 2 , 𝜇 (𝑦) ≠ 𝜇 (𝑦 ′ ) for distinct 𝑦 and 𝑦 ′ in ì 𝑦 1 , 𝜇 (𝛽 1 ) ⊆ 𝛽 2 , and 𝜇 (𝜂 1 ) ⊇ 𝜂 2 . A rule 𝜏 1 = ∀ì 𝑥 1 [𝛽 1 → 𝐻 1 ] is a syntactic tautology if 𝐻 1 ∈ 𝛽 1 . Rule 𝜏 1 subsumes a rule 𝜏 2 = ∀ì 𝑥 2 [𝛽 2 → 𝐻 2 ] if there exists a substi- tution 𝜇 such that 𝜇 (𝛽 1 ) ⊆ 𝛽 2 and 𝜇 (𝐻 1 ) = 𝐻 2 .</formula><p>A TGD/rule 𝜏 is contained in a set of TGDs/rules 𝑆 up to redundancy if 𝜏 is a syntactic tautology or some 𝜏 ′ ∈ 𝑆 subsumes 𝜏.</p><p>The following example illustrates Definition 5.1.</p><p>Example 5.2. Rule 𝐴(𝑥) ∧ 𝐵(𝑥) → 𝐴(𝑥) is a syntactic tautology: applying a chase step with it cannot produce a new fact. A non-full TGD in head-normal form cannot be a syntactic tautology since each head atom of such a TGD contains an existentially quantified variable that does not occur in the TGD body.</p><p>Rule</p><formula xml:id="formula_11">𝜏 1 = 𝐴(𝑓 (𝑥 1 ), 𝑓 (𝑥 1 )) ∧ 𝐵(𝑥 1 ) → 𝐵(𝑓 (𝑥 1 )</formula><p>) is subsumed by rule 𝜏 2 = 𝐴(𝑥 2 , 𝑥 3 ) → 𝐵(𝑥 2 ) using substitution 𝜇 1 that maps both 𝑥 2 and 𝑥 3 to 𝑓 (𝑥 1 ). If 𝜏 1 derives 𝐵(𝑓 (𝑡)) in one step from a set of facts 𝐼 by a substitution 𝜎 where 𝜎 (𝑥 1 ) = 𝑡, then 𝜏 2 also derives 𝐵(𝑓 (𝑡)) from 𝐼 in one step by substitution 𝜎 • 𝜇 1 . Thus, rule 𝜏 1 is not needed when rule 𝜏 2 is present, so 𝜏 1 can be discarded.</p><p>While syntactic tautologies and rule subsumption are standard in first-order theorem proving <ref type="bibr" target="#b7">[8]</ref>, subsumption of TGDs is more involved. TGD</p><formula xml:id="formula_12">𝜏 3 = 𝐴(𝑥 1 , 𝑥 1 ) ∧ 𝐵(𝑥 1 ) → ∃𝑦 1 𝐶 (𝑥 1 , 𝑦 1 ) is subsumed by TGD 𝜏 4 = 𝐴(𝑥 2 , 𝑥 3 ) → ∃𝑦 2 , 𝑦 3 𝐶 (𝑥 2 , 𝑦 2 ) ∧ 𝐷 (𝑥 3 , 𝑦 3 ) by substitu- tion 𝜇 2 where 𝜇 2 (𝑥 2 ) = 𝜇 2 (𝑥 3 ) = 𝑥 1 , 𝜇 2 (𝑦 2 ) = 𝑦 1 , and 𝜇 2 (𝑦 3 ) = 𝑦 3 .</formula><p>The conditions on substitution 𝜇 2 in Definition 5.1 ensure that 𝑦 2 and 𝑦 3 are not mapped to each other or to 𝑥 1 . Thus, as in the previous paragraph, the result of each chase step with 𝜏 3 and substitutions 𝜎 and 𝜎 ′ can always be obtained (up to isomorphism) by a chase step with 𝜏 4 and substitutions 𝜎 • 𝜇 2 and 𝜎 ′ • 𝜇 2 .</p><p>⊳ In Definition 5.3 we formalize the notion of applying Inf exhaustively up to redundancy. The definition, however, does not say how to actually do it: we discuss this and other issues in Section 6.</p><p>Definition 5.3. For Inf an inference rule and Σ a finite set of GTGDs, Inf(Σ) is the subset of all Skolem-free Datalog rules of Σ ′ , where Σ ′ is the smallest set that contains up to redundancy each TGD/rule obtained by • transforming Σ into head-normal form if Inf manipulates TGDs or Skolemizing Σ if Inf manipulates rules, and • selecting an adequate number of premises in Σ ′ , renaming any variables shared by distinct premises, applying Inf to the renamed premises, and transforming the result into head-normal form.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">The Existential-Based Rewriting</head><p>As we discussed in Section 4, each loop 𝑇 𝑖 , . . . ,𝑇 𝑗 at vertex 𝑣 in a one-pass chase sequence can be seen as taking 𝑇 𝑖 (𝑣) as input and producing one fact included in 𝑇 𝑗 (𝑣) as output. Let 𝑣 ′ be child of 𝑣 introduced in𝑇 𝑖+1 . The idea behind the ExbDR algorithm is to derive all GTGDs such that, for each 𝑘 with 𝑖 &lt; 𝑘 ≤ 𝑗, all facts of 𝑇 𝑘 (𝑣 ′ ) 𝐴(𝑎, 𝑏) 𝐵(𝑎, 𝑛 1 ), 𝐶 (𝑎, 𝑛 1 )</p><formula xml:id="formula_13">𝐷 (𝑎, 𝑛 1 ) 𝐸 (𝑎)<label>(8) (9)</label></formula><p>(17) = ( <ref type="formula" target="#formula_2">8</ref>) + (9) (10) (18) = ( <ref type="formula" target="#formula_15">17</ref>) + (10)</p><p>Figure <ref type="figure">3</ref>: Deriving "shortcuts" for the loop 𝑇 0 -𝑇 4 in ExbDR can be derived from the input 𝑇 𝑖 (𝑣) in one step. The output of the loop can then also be derived from 𝑇 𝑖 (𝑣) in one step by full GTGD, so this GTGD provides us with the desired loop "shortcut". Before formalizing this idea, we slightly adapt the notion of unification.</p><p>Definition 5.4. For 𝑋 a set of variables, an 𝑋 -unifier and an 𝑋 -MGU 𝜃 of atoms 𝐴 1 , . . . , 𝐴 𝑛 and 𝐵 1 , . . . , 𝐵 𝑛 are defined as in Section 3, but with the additional requirement that 𝜃 (𝑥) = 𝑥 for each 𝑥 ∈ 𝑋 .</p><p>It is straightforward to see that an 𝑋 -MGU is unique up to the renaming of variables not contained in 𝑋 , and that it can be computed as usual while treating variables in 𝑋 as if they were constants. We are now ready to formalize the ExbDR algorithm. </p><formula xml:id="formula_14">𝜏 = ∀ì 𝑥 [𝛽 → ∃ì 𝑦 𝜂 ∧ 𝐴 1 ∧ • • • ∧ 𝐴 𝑛 ] with 𝑛 ≥ 1 and 𝜏 ′ = ∀ì 𝑧 [𝐴 ′ 1 ∧ • • • ∧ 𝐴 ′ 𝑛 ∧ 𝛽 ′ → 𝐻 ′ ] and, for 𝜃 a ì 𝑦-MGU of 𝐴 1 , . . . , 𝐴 𝑛 and 𝐴 ′ 1 , . . . , 𝐴 ′ 𝑛 , , if 𝜃 ( ì 𝑥) ∩ ì 𝑦 = ∅ and vars(𝜃 (𝛽 ′ )) ∩ ì 𝑦 = ∅, it derives 𝜃 (𝛽) ∧ 𝜃 (𝛽 ′ ) → ∃ì 𝑦 𝜃 (𝜂) ∧ 𝜃 (𝐴 1 ) ∧ • • • ∧ 𝜃 (𝐴 𝑛 ) ∧ 𝜃 (𝐻 ′ ).</formula><p>Example 5.6. Consider again the set Σ from Example 4.3. The idea behind the ExbDR algorithm is illustrated in Figure <ref type="figure">3</ref>, which summarizes the steps of the loop 𝑇 0 ,𝑇 1 ,𝑇 2 ,𝑇 3 ,𝑇 4 from Figure <ref type="figure" target="#fig_4">1</ref>. We denote the vertices by 𝑟 and 𝑣 1 as in Example 4.3.</p><p>Fact 𝐴(𝑎, 𝑏) is the input to the loop, and the first step of the loop derives 𝐵(𝑎, 𝑛 1 ) and 𝐶 (𝑎, 𝑛 1 ) using GTGD <ref type="bibr" target="#b7">(8)</ref>. Next, GTGD (9) evolves vertex 𝑣 1 by deriving 𝐷 (𝑎, 𝑛 1 ). To capture this, the ExbDR inference rule combines <ref type="bibr" target="#b7">(8)</ref>, the GTGD that creates 𝑣 1 , with (9), the GTGD that evolves 𝑣 1 . This produces GTGD <ref type="bibr" target="#b16">(17)</ref>, which derives all facts of 𝑣 1 from the input fact in one step. Vertex 𝑣 1 is evolved further using GTGD <ref type="bibr" target="#b9">(10)</ref> to derive 𝐸 (𝑎). To reflect this, the ExbDR inference rule combines ( <ref type="formula" target="#formula_15">17</ref>) and <ref type="bibr" target="#b9">(10)</ref> to produce <ref type="bibr" target="#b17">(18)</ref>, which again derives all facts of 𝑣 1 from the loop's input in one step.</p><formula xml:id="formula_15">𝐴(𝑥 1 , 𝑥 2 ) → ∃𝑦 𝐵(𝑥 1 , 𝑦) ∧ 𝐶 (𝑥 1 , 𝑦) ∧ 𝐷 (𝑥 1 , 𝑦)<label>(17)</label></formula><formula xml:id="formula_16">𝐴(𝑥 1 , 𝑥 2 ) → ∃𝑦 𝐵(𝑥 1 , 𝑦) ∧ 𝐶 (𝑥 1 , 𝑦) ∧ 𝐷 (𝑥 1 , 𝑦) ∧ 𝐸 (𝑥 1 )<label>(18)</label></formula><p>Fact 𝐸 (𝑎) does not contain the labeled null 𝑛 1 that is introduced when creating 𝑣 1 , so it can be propagated to the root vertex 𝑟 as the output of the loop. This is reflected in <ref type="bibr" target="#b17">(18)</ref>: atom 𝐸 (𝑥 1 ) does not contain any existential variables. Definition 5.3 requires each derived GTGD to be brought into head-normal, so ( <ref type="formula" target="#formula_16">18</ref>) is broken up into ( <ref type="formula" target="#formula_15">17</ref>) and ( <ref type="formula" target="#formula_6">14</ref>). The latter GTGD is full, and it provides us with the desired shortcut for the loop.</p><p>Next, <ref type="bibr" target="#b11">(12)</ref> and atom 𝐹 (𝑥 1 , 𝑦 1 ) of ( <ref type="formula">11</ref>) produce <ref type="bibr" target="#b18">(19)</ref>, and transformation into head-normal form produces <ref type="bibr" target="#b10">(11)</ref> and <ref type="bibr" target="#b14">(15)</ref>. Moreover, ( <ref type="formula" target="#formula_2">8</ref>) and ( <ref type="formula" target="#formula_5">13</ref>) produce <ref type="bibr" target="#b19">(20)</ref>, and transformation (20) into head-normal form produces ( <ref type="formula" target="#formula_8">16</ref>) and <ref type="bibr" target="#b20">(21)</ref>.</p><formula xml:id="formula_17">𝐴(𝑥 1 , 𝑥 2 ) ∧ 𝐸 (𝑥 1 ) → ∃𝑦 1 , 𝑦 2 𝐹 (𝑥 1 , 𝑦 1 ) ∧ 𝐹 (𝑦 1 , 𝑦 2 ) ∧ 𝐺 (𝑥 1 ) (19) 𝐴(𝑥 1 , 𝑥 2 ) ∧ 𝐺 (𝑥 1 ) → ∃𝑦 𝐵(𝑥 1 , 𝑦) ∧ 𝐶 (𝑥 1 , 𝑦) ∧ 𝐻 (𝑥 1 )<label>(20)</label></formula><formula xml:id="formula_18">𝐴(𝑥 1 , 𝑥 2 ) ∧ 𝐺 (𝑥 1 ) → ∃𝑦 𝐵(𝑥 1 , 𝑦) ∧ 𝐶 (𝑥 1 , 𝑦)<label>(21)</label></formula><p>GTGD ( <ref type="formula" target="#formula_18">21</ref>) is subsumed by ( <ref type="formula" target="#formula_2">8</ref>) so it can be dropped. No further inferences are possible after this, so all derived full GTGDs are returned as the rewriting of Σ. ⊳ Before proceeding, we present an auxiliary result showing certain key properties of the ExbDR inference rule. Proposition 5.7. Each application of the ExbDR inference rule to 𝜏, 𝜏 ′ , and 𝜃 as in Definition 5.5 satisfies the following properties. 1. Some atom</p><formula xml:id="formula_19">𝐴 ′ 𝑖 with 1 ≤ 𝑖 ≤ 𝑛 is a guard in 𝜏 ′ . 2. For each 1 ≤ 𝑖 ≤ 𝑛 such that 𝐴 ′</formula><p>𝑖 is a guard of 𝜏 ′ , and for 𝜎 the ì 𝑦-MGU of 𝐴 ′ 𝑖 and the corresponding atom</p><formula xml:id="formula_20">𝐴 𝑖 such that 𝜎 ( ì 𝑥) ∩ ì 𝑦 = ∅, it is the case that vars 𝜎 (𝐴 ′ 𝑗 ) ∩ ì 𝑦 ≠ ∅ for each 1 ≤ 𝑗 ≤ 𝑛. 3.</formula><p>The result is a GTGD whose body and head width are at most bwidth(Σ) and hwidth(Σ), respectively.</p><p>In the second claim of Proposition 5.7, 𝜎 unifies only 𝐴 𝑖 and 𝐴 ′ 𝑖 , whereas 𝜃 unifies all 𝐴 1 , . . . , 𝐴 𝑛 and 𝐴 ′ 1 , . . . , 𝐴 ′ 𝑛 ; thus, 𝜎 and 𝜃 are not necessarily the same. The third claim is needed to prove termination of ExbDR.</p><p>Proposition 5.7 can be used to guide the application of the ExbDR inference rule. Consider an attempt to apply the ExbDR inference rule to two candidate GTGDs 𝜏 = 𝛽 → ∃ì 𝑦 𝜂 and 𝜏 ′ = 𝛽 ′ → 𝐻 ′ . The first claim of Proposition 5.7 tells us that a guard of 𝜏 ′ will definitely participate in the inference. Thus, we can choose one such guard 𝐺 ′ ∈ 𝛽 ′ of 𝜏 ′ and try to find a ì 𝑦-MGU 𝜎 of 𝐺 ′ and a counterpart atom 𝐺 ∈ 𝜂 from the head of 𝜏. Next, we need to check whether 𝜎 ( ì 𝑥) ∩ ì 𝑦 = ∅; if not, there is no way for 𝜃 ( ì 𝑥) ∩ ì 𝑦 = ∅ to hold so the inference is not possible. By the second claim of Proposition 5.7, all candidates for the atoms participating in the inference will contain a variable that is mapped by 𝜎 to a member of ì 𝑦; thus,</p><formula xml:id="formula_21">𝑆 ′ = 𝜎 (𝐴 ′ ) | 𝐴 ′ ∈ 𝛽 ′ ∧ vars(𝜎 (𝐴 ′ )) ∩ ì</formula><p>𝑦 ≠ ∅ is the set of all relevant side atoms. Note that we apply 𝜎 to the atoms in 𝑆 ′ to simplify further matching. The next step is to identify the corresponding head atoms of 𝜏. To achieve this, for each atom 𝐴 ′ ∈ 𝑆 ′ of the form 𝑅(𝑡 1 , . . . , 𝑡 𝑛 ), we identify the set 𝐶 [𝐴 ′ ] of candidate counterpart atoms as the set of atoms of the form 𝑅(𝑠 1 , . . . , 𝑠 𝑛 ) ∈ 𝜎 (𝜂) such that, for each argument position 𝑖 with 1</p><formula xml:id="formula_22">≤ 𝑖 ≤ 𝑛, if either 𝑡 𝑖 ∈ ì 𝑦 or 𝑠 𝑖 ∈ ì</formula><p>𝑦, then 𝑡 𝑖 = 𝑠 𝑖 . Finally, we consider each possible combination 𝑆 of such candidates, and we try to find an MGU 𝜃 of sets 𝑆 and 𝑆 ′ . If unification succeeds, we derive the corresponding GTGD. Program ExbDR(Σ) can thus be large in the worst case. In Section 7 we show empirically that rewritings are suitable for practical use. From a theoretical point of view, checking fact entailment via ExbDR(Σ) is worst-case optimal. To see why, let 𝑟 , 𝑎, and 𝑐 be as in Theorem 5.8, and consider a base instance 𝐼 with 𝑐 ′ constants. The fixpoint of ExbDR(Σ) on 𝐼 contains at most 𝑟 (𝑐 + 𝑐 ′ ) 𝑎 facts, and it can be computed in time 𝑂 (𝑟 (𝑐 + 𝑐 ′ ) 𝑎 • |ExbDR(Σ)|): each rule 𝜏 ∈ ExbDR(Σ) is guarded so we can apply a chase step with 𝜏 by matching a guard and then checking the remaining body atoms. Hence, we can compute ExbDR(Σ) and find its fixpoint in 2Exp-Time, in ExpTime if the relation arity is fixed, and in PTime if Σ is fixed (i.e., if we consider data complexity). These results match the lower bounds for checking fact entailment for GTGDs <ref type="bibr" target="#b33">[34]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Using Skolemization</head><p>The ExbDR algorithm exhibits two drawbacks. First, each application of the ExbDR inference rule potentially introduces a head atom, so the rule heads can get very long. Second, each inference requires matching a subset of body atoms of 𝜏 ′ to a subset of the head atoms of 𝜏; despite the optimizations outlined after Proposition 5.7, this can be costly, particularly when rule heads are long.</p><p>We would ideally derive GTGDs with a single head atom and unify just one body atom of 𝜏 ′ with the head atom of 𝜏, but this does not seem possible if we stick to manipulating GTGDs. For example, atoms 𝐶 (𝑦) and 𝐷 (𝑦) of GTGD <ref type="bibr" target="#b16">(17)</ref> refer to the same labeled null (represented by variable 𝑦), and this information would be lost if we split <ref type="bibr" target="#b16">(17)</ref> into two GTGDs. We thus need a way to refer to the same existentially quantified object in different logical formulas. This can be achieved by replacing existentially quantified variables by Skolem terms, which in turns gives rise to the SkDR algorithm from Definition 5.10. Before presenting the algorithm, in Definition 5.9 we generalize the notion of guardedness to rules. </p><formula xml:id="formula_23">𝜏 = 𝛽 → 𝐻 and 𝜏 ′ = 𝐴 ′ ∧ 𝛽 ′ → 𝐻 ′ such that</formula><p>• 𝛽 is Skolem-free and 𝐻 contains a Skolem symbol, and</p><p>• 𝐴 ′ contains a Skolem symbol, or 𝜏 ′ is Skolem-free and 𝐴 ′ contains all variables of 𝜏 ′ , and, for 𝜃 an MGU of 𝐻 and 𝐴 ′ , it derives</p><formula xml:id="formula_24">𝜃 (𝛽) ∧ 𝜃 (𝛽 ′ ) → 𝜃 (𝐻 ′ ).</formula><p>Example 5.11. Skolemizing GTGDs <ref type="bibr" target="#b7">(8)</ref> and <ref type="bibr" target="#b10">(11)</ref> produces rules ( <ref type="formula">22</ref>)- <ref type="bibr" target="#b22">(23)</ref>, and ( <ref type="formula" target="#formula_26">24</ref>)- <ref type="bibr" target="#b24">(25)</ref>, respectively.</p><formula xml:id="formula_25">𝐴(𝑥 1 , 𝑥 2 ) → 𝐵(𝑥 1 , 𝑓 (𝑥 1 , 𝑥 2 )) (22) 𝐴(𝑥 1 , 𝑥 2 ) → 𝐶 (𝑥 1 , 𝑓 (𝑥 1 , 𝑥 2 ))<label>(23)</label></formula><formula xml:id="formula_26">𝐴(𝑥 1 , 𝑥 2 ) ∧ 𝐸 (𝑥 1 ) → 𝐹 (𝑥 1 , 𝑔(𝑥 1 , 𝑥 2 ))<label>(24)</label></formula><formula xml:id="formula_27">𝐴(𝑥 1 , 𝑥 2 ) ∧ 𝐸 (𝑥 1 ) → 𝐹 (𝑔(𝑥 1 , 𝑥 2 ), ℎ(𝑥 1 , 𝑥 2 ))<label>(25)</label></formula><p>Intuitively, rules ( <ref type="formula">22</ref>) and ( <ref type="formula" target="#formula_25">23</ref>) jointly represent the facts introduced by the non-full GTGD (8): functional term 𝑓 (𝑥 1 , 𝑥 2 ) allows both rules to "talk" about the same labeled nulls. This allows the SkDR inference rule to simulate the ExbDR inference rule while unifying just pairs of atoms. In particular, SkDR combines ( <ref type="formula">22</ref>) and ( <ref type="formula" target="#formula_3">10</ref>) to obtain <ref type="bibr" target="#b25">(26)</ref>; it combines ( <ref type="formula" target="#formula_25">23</ref>) and ( <ref type="formula">9</ref>) to obtain <ref type="bibr" target="#b26">(27)</ref>; and it combines ( <ref type="formula" target="#formula_28">26</ref>) and ( <ref type="formula" target="#formula_29">27</ref>) to obtain the "shortcut" rule <ref type="bibr" target="#b13">(14)</ref>.</p><formula xml:id="formula_28">𝐴(𝑥 1 , 𝑥 2 ) ∧ 𝐷 (𝑥 1 , 𝑓 (𝑥 1 , 𝑥 2 )) → 𝐸 (𝑥 1 )<label>(26)</label></formula><formula xml:id="formula_29">𝐴(𝑥 1 , 𝑥 2 ) → 𝐷 (𝑥 1 , 𝑓 (𝑥 1 , 𝑥 2 ))<label>(27)</label></formula><p>The rules with Skolem-free bodies derived in this way allow us to reconstruct derivations in one step analogously to Example 5.6, and the rules with Skolem symbols in body atoms capture the intermediate derivation steps. For example, rules ( <ref type="formula" target="#formula_28">26</ref>) and ( <ref type="formula" target="#formula_30">28</ref>) capture the result of matching the first and the second body atom, respectively, of rule <ref type="bibr" target="#b9">(10)</ref> to facts produced by rules ( <ref type="formula">22</ref>) and ( <ref type="formula" target="#formula_29">27</ref>), respectively.</p><p>To complete the rewriting, SkDR combines ( <ref type="formula" target="#formula_26">24</ref>) with ( <ref type="formula" target="#formula_4">12</ref>) to obtain <ref type="bibr" target="#b14">(15)</ref>, and it combines ( <ref type="formula">22</ref>) with ( <ref type="formula" target="#formula_5">13</ref>) to derive <ref type="bibr" target="#b15">(16)</ref>. However, SkDR also combines ( <ref type="formula" target="#formula_3">10</ref>) and ( <ref type="formula" target="#formula_29">27</ref>) into ( <ref type="formula" target="#formula_30">28</ref>), which with ( <ref type="formula">22</ref>) derives ( <ref type="formula" target="#formula_6">14</ref>) the second time. These inferences are superfluous: they just process the two body atoms of (10) in a different order. Also, SkDR combines ( <ref type="formula" target="#formula_4">12</ref>) and ( <ref type="formula" target="#formula_27">25</ref>) into rule <ref type="bibr" target="#b28">(29)</ref>, which is a "deadend" in that it does not further contribute to a Datalog rule.</p><formula xml:id="formula_30">𝐴(𝑥 1 , 𝑥 2 ) ∧ 𝐵(𝑥 1 , 𝑓 (𝑥 1 , 𝑥 2 )) → 𝐸 (𝑥 1 )<label>(28)</label></formula><formula xml:id="formula_31">𝐴(𝑥 1 , 𝑥 2 ) ∧ 𝐸 (𝑥 1 ) ∧ 𝐸 (𝑔(𝑥 1 , 𝑥 2 )) → 𝐺 (𝑔(𝑥 1 , 𝑥 2 ))<label>(29)</label></formula><p>Our HypDR algorithm in Subsection 5.3 can avoid these overheads, but at the expense of using more than two rules at a time. ⊳ Proposition 5.12 and Theorem 5.13 capture the relevant properties of the SkDR algorithm. Proposition 5.12. Each application of the SkDR inference rule to rules 𝜏 and 𝜏 ′ as in Definition 5.10 produces a guarded rule. Theorem 5.13. Program SkDR(Σ) is a Datalog rewriting of a finite set of GTGDs Σ. Moreover, the rewriting can be computed in time 𝑂 (𝑏 𝑟 𝑑 • (𝑒+𝑤 𝑏 +𝑐 ) 𝑑𝑎 ) for 𝑟 the number of relations in Σ, 𝑎 the maximum relation arity in Σ, 𝑒 the number of existential quantifiers in Σ, 𝑤 𝑏 = bwidth(Σ), 𝑐 = |consts(Σ)|, and some 𝑏 and 𝑑.</p><p>It is natural to wonder whether SkDR is guaranteed to be more efficient than ExbDR. We next show that neither algorithm is generally better: there exist families of inputs on which SkDR performs exponentially more inferences than ExbDR, and vice versa. Proposition 5.14. There exists a family {Σ 𝑛 } 𝑛∈N of finite sets of GTGDs such that the number of GTGDs derived by ExbDR is 𝑂 (2 𝑛 ) times larger than the number of rules derived by SkDR on each Σ 𝑛 .</p><p>Proof. For each 𝑛 ∈ N, let Σ 𝑛 contain the following GTGDs.</p><formula xml:id="formula_32">𝐴(𝑥) → ∃ì 𝑦 𝐵 1 (𝑥, 𝑦 1 ) ∧ • • • ∧ 𝐵 𝑛 (𝑥, 𝑦 𝑛 ) (<label>30</label></formula><formula xml:id="formula_33">)</formula><formula xml:id="formula_34">𝐵 𝑖 (𝑥 1 , 𝑥 2 ) ∧ 𝐶 𝑖 (𝑥 1 ) → 𝐷 𝑖 (𝑥 1 , 𝑥 2 ) for 1 ≤ 𝑖 ≤ 𝑛<label>(31)</label></formula><p>On such Σ 𝑛 , ExbDR derives a GTGD of the form <ref type="bibr" target="#b31">(32)</ref> for each subset {𝑘 1 , . . . , 𝑘 𝑚 } ⊆ {1, . . . , 𝑛}, and there are 2 𝑛 such TGDs. In contrast, the Skolemization of (30) consists of 𝑛 rules shown in equation <ref type="bibr" target="#b32">(33)</ref>, so SkDR derives just 𝑛 rules shown in equation <ref type="bibr" target="#b33">(34)</ref>.</p><formula xml:id="formula_35">𝐴(𝑥) ∧ 𝑚 𝑖=1 𝐶 𝑘 𝑖 (𝑥) → ∃ì 𝑦 𝑛 𝑖=1 𝐵 𝑖 (𝑥, 𝑦 𝑖 ) ∧ 𝑚 𝑖=1 𝐷 𝑘 𝑖 (𝑥, 𝑦 𝑘 𝑖 ) (32) 𝐴(𝑥) → 𝐵 𝑖 (𝑥, 𝑓 𝑖 (𝑥)) for 1 ≤ 𝑖 ≤ 𝑛 (33) 𝐴(𝑥) ∧ 𝐶 𝑖 (𝑥) → 𝐷 𝑖 (𝑥, 𝑓 𝑖 (𝑥)) for 1 ≤ 𝑖 ≤ 𝑛 □(34)</formula><p>Proposition 5.15. There exists a family {Σ 𝑛 } 𝑛∈N of finite sets of GTGDs such that the number of rules derived by SkDR is 𝑂 (2 𝑛 ) times larger than the number of TGDs derived by ExbDR on each Σ 𝑛 .</p><p>Proof. For each 𝑛 ∈ N, let Σ 𝑛 contain the following GTGDs.</p><formula xml:id="formula_36">𝐴(𝑥) → ∃𝑦 𝐵 1 (𝑥, 𝑦) ∧ • • • ∧ 𝐵 𝑛 (𝑥, 𝑦)<label>(35)</label></formula><formula xml:id="formula_37">𝐵 1 (𝑥 1 , 𝑥 2 ) ∧ • • • ∧ 𝐵 𝑛 (𝑥 1 , 𝑥 2 ) → 𝐶 (𝑥 1 )<label>(36)</label></formula><p>On such Σ 𝑛 , ExbDR derives just GTGD (37) in one step. In contrast, the Skolemization of ( <ref type="formula" target="#formula_36">35</ref>) consists of 𝑛 rules of the form <ref type="bibr" target="#b37">(38)</ref> for each 1 ≤ 𝑖 ≤ 𝑛. Thus, SkDR combines these with (36) to derive 2 𝑛 -1 rules of the form <ref type="bibr" target="#b38">(39)</ref>, one for each subset {𝑘 1 , . . . , 𝑘 𝑚 } ⊊ {1, . . . , 𝑛}.</p><formula xml:id="formula_38">𝐴(𝑥) → 𝐶 (𝑥)<label>(37)</label></formula><formula xml:id="formula_39">𝐴(𝑥) → 𝐵 𝑖 (𝑥, 𝑓 (𝑥))<label>(38)</label></formula><formula xml:id="formula_40">𝐴(𝑥) ∧ 𝐵 𝑘 1 (𝑥, 𝑓 (𝑥)) ∧ • • • ∧ 𝐵 𝑘 𝑚 (𝑥, 𝑓 (𝑥)) → 𝐶 (𝑥) □ (39)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Combining Several SkDR Steps into One</head><p>The SkDR algorithm can produce many rules with Skolem symbols in the body, which is the main reason for Proposition 5.15. We next present the HypDR algorithm, which uses the hyperresolution inference rule as a kind of "macro" to combine several SkDR steps into one. We show that this can be beneficial for several reasons.</p><p>Definition 5.16. The Hyperresolution Rewriting inference rule HypDR takes guarded rules </p><formula xml:id="formula_41">𝜏 1 = 𝛽 1 → 𝐻 1 . . . 𝜏 𝑛 = 𝛽 𝑛 → 𝐻 𝑛 and 𝜏 ′ = 𝐴 ′ 1 ∧ • • • ∧ 𝐴 ′ 𝑛 ∧ 𝛽 ′ → 𝐻 ′ such that • for each 𝑖 with 1 ≤ 𝑖 ≤ 𝑛,</formula><formula xml:id="formula_42">𝜃 (𝛽 1 ) ∧ • • • ∧ 𝜃 (𝛽 𝑛 ) ∧ 𝜃 (𝛽 ′ ) → 𝜃 (𝐻 ′ ).</formula><p>Example 5.17. The HypDR inference rule simulates chase steps in the child vertex of a loop analogously to ExbDR: all body atoms matching a fact introduced in the child vertex are resolved in one step. We can see two benefits of this on our running example.</p><p>First, HypDR derives ( <ref type="formula" target="#formula_29">27</ref>) from ( <ref type="formula" target="#formula_25">23</ref>) and ( <ref type="formula">9</ref>), and it derives ( <ref type="formula" target="#formula_6">14</ref>) from ( <ref type="formula" target="#formula_3">10</ref>), <ref type="bibr" target="#b21">(22)</ref>, and <ref type="bibr" target="#b26">(27)</ref>. Rule ( <ref type="formula" target="#formula_6">14</ref>) is derived just once, and without intermediate rules ( <ref type="formula" target="#formula_28">26</ref>) and <ref type="bibr" target="#b27">(28)</ref>. In other words, the HypDR inference rule does not resolve the body atoms of a rule in every possible order. As Proposition 5.20 below shows, this can reduce the number of derived rules by an exponential factor.</p><p>Second, HypDR derives only rules with Skolem-free bodies, and thus does not derive the "dead-end" rule <ref type="bibr" target="#b28">(29)</ref>. In other words, all consequences of HypDR derive in one step one fact in the child vertex of a loop from the loop's input 𝑇 𝑖 (𝑣).</p><p>The downside of HypDR is that more than two rules can participate in an inference. This requires more complex unification and selection of candidates that can participate in an inference. ⊳ Proof. For each 𝑛 ∈ N, let Σ 𝑛 contain the following GTGDs.</p><formula xml:id="formula_43">𝐴(𝑥) → ∃𝑦 𝐵(𝑥, 𝑦)<label>(40)</label></formula><formula xml:id="formula_44">𝐵(𝑥 1 , 𝑥 2 ) ∧ 𝐶 𝑖 (𝑥 1 ) → 𝐷 𝑖 (𝑥 1 , 𝑥 2 ) for 1 ≤ 𝑖 ≤ 𝑛 (41) 𝐷 1 (𝑥 1 , 𝑥 2 ) ∧ • • • ∧ 𝐷 𝑛 (𝑥 1 , 𝑥 2 ) → 𝐸 (𝑥 1 )<label>(42)</label></formula><p>Skolemizing ( <ref type="formula" target="#formula_43">40</ref>) produces <ref type="bibr" target="#b42">(43)</ref>. Thus, SkDR combines <ref type="bibr" target="#b42">(43)</ref> with each (41) to derive each <ref type="bibr" target="#b43">(44)</ref>, and it uses ( <ref type="formula" target="#formula_46">44</ref>) and ( <ref type="formula" target="#formula_44">42</ref>) to derive 2 𝑛 -1 rules of the form <ref type="bibr" target="#b44">(45)</ref> for each set of indexes 𝐼 satisfying ∅ ⊊ 𝐼 ⊆ {1, . . . , 𝑛}; note that none of these rules are redundant.</p><formula xml:id="formula_45">𝐴(𝑥) → 𝐵(𝑥, 𝑓 (𝑥))<label>(43)</label></formula><formula xml:id="formula_46">𝐴(𝑥) ∧ 𝐶 𝑖 (𝑥) → 𝐷 𝑖 (𝑥, 𝑓 (𝑥)) for 1 ≤ 𝑖 ≤ 𝑛<label>(44)</label></formula><formula xml:id="formula_47">𝐴(𝑥) ∧ 𝑖 ∈𝐼 𝐶 𝑖 (𝑥) ∧ 𝑗 ∈ {1,...,𝑛}\𝐼 𝐷 𝑗 (𝑥, 𝑓 (𝑥)) → 𝐸 (𝑥)<label>(45)</label></formula><p>In contrast, HypDR derives each (44) just like SkDR, and it combines in one step <ref type="bibr" target="#b41">(42)</ref> and all <ref type="bibr" target="#b43">(44)</ref> to derive <ref type="bibr" target="#b44">(45)</ref> for 𝐼 = {1, . . . , 𝑛}. □</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">IMPLEMENTATION AND OPTIMIZATIONS</head><p>In this section, we discuss numerous issues that have to be addressed to make the computation of a rewriting practical.</p><p>Computing Inf(Σ) in Practice. Definition 5.3 does not specify how to compute the set Σ ′ , and redundancy elimination makes this question nontrivial. When Inf derives a TGD/rule 𝜏, we can apply subsumption in two ways. First, we can discard 𝜏 if 𝜏 is subsumed by a previously derived TGD/rule; this is known as forward subsumption. Second, if 𝜏 is not discarded, we can discard each previously derived TGD/rule that is subsumed by 𝜏; this is known as backward subsumption. The set of derived TGD/rules can thus grow and shrink, so the application of Inf has to be carefully structured to ensure that all inferences are performed eventually.</p><p>We address this problem by a variant of the Otter loop <ref type="bibr" target="#b35">[36]</ref> used in first-order theorem provers. The pseudo-code is shown in Algorithm 1. The algorithm maintains two sets of TGDs/rules: the worked-off set W contain TGDs/rules that have been processed by Inf, and the unprocessed set U contains TGDs/rules that are still to be processed. Set W is initially empty (line 1), and set U is initialized to the head-normal form of Σ if Inf manipulates TGDs, or to the Skolemization of Σ if Inf manipulates rules. The algorithm then processes each 𝜏 ∈ U until U becomes empty (lines 3-10). It is generally beneficial to process shorter TGDs/rules first as that improves chances of redundancy elimination. After moving 𝜏 to W (line 5), Choose some 𝜏 ∈ U and remove it from U 5:</p><formula xml:id="formula_48">W = W ∪ {𝜏 } 6:</formula><p>Let E be the result of applying Inf to 𝜏 and a subset of W and transforming the result into head-normal form 7:</p><p>for each 𝜏 ′ ∈ E do 8:</p><p>if 𝜏 ′ is not contained in W ∪ U up to redundancy then 9:</p><p>Remove from W and U each 𝜏 ′′ subsumed by 𝜏 ′ 10:</p><formula xml:id="formula_49">U = U ∪ {𝜏 ′ } 11: return {𝜏 ∈ W | 𝜏 is a Skolem-free Datalog rule}</formula><p>the algorithm applies Inf to 𝜏 and W and transforms the results into head-normal form (line 6). The algorithm discards each resulting 𝜏 ′ ∈ E that is a syntactic tautology or is forward-subsumed by an element of W ∪ U (line 8). If 𝜏 ′ is not discarded, the algorithm applies backward subsumption to 𝜏 ′ , W, and U (line 9) and adds 𝜏 ′ to U (line 10). When all TGDs/rules are processed, the algorithm returns all Skolem-free Datalog rules from W (line 11). The result of applying Inf to TGDs/rules in W is thus contained in W ∪ U up to redundancy at all times so, upon algorithm's termination, set W satisfies the condition on Σ ′ from Definition 5.3.</p><p>Checking Subsumption. Checking whether TGD/rule 𝜏 1 subsumes 𝜏 2 is NP-complete <ref type="bibr" target="#b31">[32]</ref>, and the main difficulty is in matching the variables of 𝜏 1 to the variables of 𝜏 2 . Thus, we use an approximate check in our implementation. First, we normalize each TGD to use fixed variables 𝑥 1 , 𝑥 2 , . . . and 𝑦 1 , 𝑦 2 , . . .: we sort the body and head atoms by their relations using an arbitrary, but fixed ordering and breaking ties arbitrarily, and then we rename all variables so that the 𝑖 𝑡ℎ distinct occurrence of a universally (respectively existentially) quantified variable from left to right is 𝑥 𝑖 (respectively 𝑦 𝑖 ). To see whether</p><formula xml:id="formula_50">𝜏 1 = 𝛽 1 → ∃ì 𝑦 𝜂 1 subsumes 𝜏 2 = 𝛽 2 → ∃ì 𝑦 𝜂 2 ,</formula><p>we determine whether 𝛽 1 ⊆ 𝛽 2 and 𝜂 1 ⊇ 𝜂 2 holds, which requires only polynomial time. We use a similar approximation for rules. Variable normalization ensures termination, and using a modified subsumption check does not affect the correctness of the rewriting: set W may contain more TGDs/rules than strictly necessary, but these are all logical consequences of (the Skolemization of) Σ.</p><p>Subsumption Indexing. Sets W and U can be large, so we use a variant of feature vector indexing <ref type="bibr" target="#b43">[44]</ref> to retrieve subsumption candidates in W ∪ U. For simplicity, we consider only TGDs in the following discussion, but rules can be handled analogously. Note that a TGD 𝜏 1 can subsume TGD 𝜏 2 only if the set of relations occurring in the body of 𝜏 1 (respectively the head of 𝜏 2 ) is a subset of the set of relations occurring in the body of 𝜏 2 (respectively the head of 𝜏 1 ). Thus, we can reduce the problem of retrieving subsumption candidates to the problem of, given a domain set 𝐷, a set 𝑁 of subsets of 𝐷, a subset 𝑆 ⊆ 𝐷, and ⊲⊳ ∈ {⊆, ⊇}, retrieving each 𝑆 ′ ∈ 𝑁 satisfying 𝑆 ′ ⊲⊳ 𝑆. The set-trie data structure <ref type="bibr" target="#b42">[43]</ref> can address this problem. The idea is to order 𝐷 in an arbitrary, yet fixed way, so that we can treat each subset of 𝑁 as a word over 𝐷. We then index 𝑁 by constructing a trie over the words representing the elements of 𝑁 . Finally, we retrieve all 𝑆 ′ ∈ 𝑁 satisfying 𝑆 ′ ⊲⊳ 𝑆 by traversing the trie, where the ordering on 𝐷 allows us to considerably reduce the number of vertices we visit during the traversal. A minor issue is that retrieving TGDs that subsume a given TGD requires both subset and superset testing for body and head relations, respectively, and vice versa for retrieval of subsumed TGDs. To address this, we introduce a distinct symbol 𝑅 𝑏 and 𝑅 ℎ for each relation 𝑅 occurring in Σ, and we represent each TGD 𝜏 as a feature vector 𝐹 𝜏 of these symbols corresponding to the body and head of 𝜏. Moreover, we combine in the obvious way the subset and superset retrieval algorithms. For example, when searching for a TGD 𝜏 ′ ∈ W ∪ U that subsumes a given TGD 𝜏, we use the subset retrieval for the symbols 𝑅 𝑏 and the superset retrieval for symbols 𝑅 ℎ . Finally, we order these symbols by the decreasing frequency of the order of the symbols' occurrence in the set Σ of input TGDs, and moreover we order each 𝑅 𝑏 before all 𝑅 ℎ . Relation Clustering. We observed that the subsumption indexes can easily get very large, so index traversal can become a considerable source of overhead. To reduce the index size, we group the symbols 𝑅 𝑏 and 𝑅 ℎ into clusters 𝐶 𝑏 and 𝐶 ℎ , respectively. Then, the feature vector 𝐹 𝜏 associated with each TGD 𝜏 consists of all clusters 𝐶 𝑏 and 𝐶 ℎ that contain a relation occurring in the body and head, respectively, of 𝜏. We adapt the trie traversal algorithms in the obvious way to take into account this change. The number of clusters is computed using the average numbers of symbols and atoms in the input TGDs, and clusters are computed with the aim of balancing the number of TGDs stored in each leaf vertex.</p><p>Unification Indexing. We construct indexes over W that allow us to quickly identify TGDs/rules that can participate in an inference with some 𝜏. For TGDs, we maintain a hash table that maps each relation 𝑅 to a set of TGDs containing 𝑅 in the body, and another hash table that does the same but for TGD heads. To index rules, we use a variant of a path indexing <ref type="bibr" target="#b44">[45]</ref>: each atom in a rule is represented as a sequence of relations and function symbols occurring in the atom, and such sequences are entered into two tries (one for body and one for head atoms). Then, given rule 𝜏, we consider each body and head atom 𝐴 of 𝜏, we convert 𝐴 into the corresponding sequence, and we use the sequence to query the relevant trie for all candidates participating in an inference with 𝜏 on 𝐴.</p><p>Cheap Lookahead Optimization. Consider an application of the ExbDR inference rule to GTGDs 𝜏 and 𝜏 ′ as in Definition 5.5, producing a GTGD 𝜏 ′′ where vars(𝜃 (𝐻 ′ )) ∩ ì 𝑦 ≠ ∅ and the relation of 𝐻 ′ does not occur in the body of a GTGD in Σ. In each one-pass chase sequence for some base instance and Σ, no GTGD of Σ can be applied to a fact obtained by instantiating 𝜃 (𝐻 ′ ), so deriving this fact is redundant. Consequently, we can drop such 𝜏 ′′ as soon as we derive it in line 6. Analogously, when the SkDR inference rule is applied to rules 𝜏 and 𝜏 ′ as in Definition 5.10, we can drop the resulting rule if 𝜃 (𝐻 ′ ) is not full and it contains a relation not occurring in the body of a GTGD in Σ.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">EXPERIMENTAL EVALUATION</head><p>We implemented a system that can produce a Datalog rewriting of a set of GTGDs using our algorithms, and we conducted an empirical evaluation using a comprehensive collection of 428 synthetic and </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1">Input GTGDs, Competitors, &amp; Test Setting</head><p>Before discussing our results, we next describe our test setting.</p><p>Input GTGDs. We are unaware of any publicly available sets of GTGDs that we could readily use in our evaluation, so we derived the input GTGDs for our evaluation from the ontologies in the Oxford Ontology Library <ref type="bibr" target="#b39">[40]</ref>. At the time of writing, this library contained 787 ontologies, each assigned a unique five-digit identifier.</p><p>After removing closely-related ontology variants, we were left with 428 core ontologies. We loaded each ontology using the parser from the Graal system <ref type="bibr" target="#b8">[9]</ref>, discarded axioms that cannot be translated into GTGDs, and converted the remaining axioms into GTGDs. We used the standard translation of description logics into first-order logic <ref type="bibr" target="#b5">[6]</ref>, where each class corresponds to a unary relation, and each property corresponds to a binary relation. We thus obtained 428 sets of input GTGDs with properties shown in Table <ref type="table" target="#tab_4">1</ref>.</p><p>To evaluate our algorithms on TGDs containing relations of arity higher than two, we devised a way to "blow up" relation arity. Given a set of GTGDs and a blowup factor 𝑏, our method proceeds as follows. First, in each atom of each GTGD, it replaces each variable argument with 𝑏 fresh variables uniquely associated with the variable; for example, for 𝑏 = 2, atom 𝐴(𝑥, 𝑦) is transformed into atom 𝐴(𝑥 1 , 𝑥 2 , 𝑦 1 , 𝑦 2 ). Next, the method randomly introduces fresh head and body atoms over the newly introduced variables; in doing so, it ensures that the new atoms do not introduce patterns that would prevent application of the ExbDR inference rule.</p><p>Competitors. We compared the ExbDR, SkDR, and HypDR algorithms, implemented as described in Section 6. As noted in Section 2, no existing system we are aware of implements a Datalog rewriting algorithm for GTGDs. However, the KAON2 system <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b38">39]</ref> can rewrite GTGDs obtained from OWL ontologies, so we used KAON2 as a baseline in our experiments with OWL-based GTGDs. We made sure that all inputs to KAON2 and our algorithms include only GTGDs that all methods can process.</p><p>Test Setting. We conducted all experiments on a laptop with an Intel Core i5-6500 CPU @ 3. <ref type="bibr" target="#b19">20</ref>   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2">Experiments with GTGDs from Ontologies</head><p>We computed the Datalog rewriting of GTGDs obtained from OWL ontologies using our three algorithms and KAON2. Figure <ref type="figure" target="#fig_5">4</ref> shows the number of inputs that each algorithm processed in a given time, provides information about the inputs and outputs of each system, and compares the performance among systems. The input size for ExbDR is the number of GTGDs after transforming the input into head-normal form, and for SkDR and HypDR it is the number of rules after Skolemization. Input size is not available for KAON2 since this system reads an OWL ontology and transforms it into GTGDs internally. The output size is the number of Datalog rules in the rewriting. Finally, the blowup is the ratio of the output and the input sizes. Each input GTGD contained at most seven body atoms. Out of 428 inputs, 349 were processed within the ten minute limit by our three systems, and 334 inputs were processed by all four systems. Moreover, 32 inputs, each containing between 20,270 and 221,648 GTGD, were not processed by any system.</p><p>Discussion. As one can see in Figure <ref type="figure" target="#fig_5">4</ref>, all algorithms were able to compute the rewriting of large inputs containing 100k+ GTGDs. Moreover, for the vast majority of inputs that were successfully processed, the size of the rewriting and the number of body atoms in the rewriting are typically of the same order of magnitude as the input. Hence, the worst-case exponential blowup from Theorems 5.8, 5.13, and 5.19 does not appear in practice: the size of the rewriting seems to be determined primarily by the input size.</p><p>Relative Performance. No system can be identified as the best in general, but HypDR seems to offer the best performance on average. The algorithm was able to process most inputs; it was at least 35% faster than the other systems on the slowest input; it was never slower by an order of magnitude; there were only 14 inputs that could be processed by some other algorithm but not HypDR; and the output of HypDR does not differ significantly from the output of SkDR. This is in line with our motivation for HypDR outlined in Example 5.17. Specifically, HypDR derives rules with just one head atom, but it does not derive intermediate rules with functional body atoms. The main source of overhead in HypDR seems to be more complex selection of rules participating in an inference.</p><p>Impact of Subsumption. All algorithms spend a considerable portion of their running time checking TGD/rule subsumption, so it is natural to wonder whether this overhead is justified. To answer this question, we ran our three approaches using a modification of Algorithm 1: we replaced the check for containment up to redundancy in line 8 with just checking 𝜏 ′ ∉ W ∪ U, and we removed line 9. Note that our normalization of variables described in Section 6 still guarantees termination. This change significantly increased the number of derivations: the numbers of derived TGDs/rules increased on average by a factor of 104, 185, and 103 on ExbDR, SkDR, and HypDR, respectively. Interestingly, this increase did not affect the performance uniformly. While SkDR was able to process 12 inputs an order of magnitude faster, ExbDR and HypDR timed out on 72 and 17 additional inputs, respectively. This, we believe, is due to how different inference rules select inference candidates. The SkDR rule is applied to just pairs of rules, and candidate pairs can be efficiently retrieved using unification indexes. In contrast, ExbDR requires matching several head atoms with as many body atoms, which makes developing a precise index for candidate pair retrieval difficult; thus, as the number of derived TGDs increases, the number of false candidates retrieved from the index increases as well. Finally, HypDR can be applied to an arbitrary number of rules, so selecting inference candidates clearly becomes more difficult as the number of derived rules increases.</p><p>Impact of Structural Transformation. KAON2 uses structural transformation <ref type="bibr" target="#b6">[7]</ref> to simplify ontology axioms before translating them into GTGDs. For example, axiom 𝐴 ⊑ ∃𝐵.∃𝐶.𝐷 is transformed into 𝐴 ⊑ ∃𝐵.𝑋 and 𝑋 ⊑ ∃𝐶.𝐷 for 𝑋 a fresh class. The resulting axioms have simpler structure, which is often beneficial to performance. To see how this transformation affects our algorithms, we reran our experiments while transforming the input axioms in the same way as in KAON2. This indeed improved the performance of SkDR by one order of magnitude on 22 ontologies, and it did not hurt the performance of HypDR. The main challenge is to generalize this transformation to arbitrary GTGDs: whereas description logic axioms exhibit syntactic nesting that lends itself naturally to this transformation, it is less clear how to systematically apply this transformation to TGDs, where heads and bodies consist of "flat" conjunctions. We leave this question for future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.3">End-to-End Experiments</head><p>To validate our approach end-to-end, we selected ten inputs where ExbDR produced the largest rewritings. For each of these, we generated a large base instance using WatDiv <ref type="bibr" target="#b1">[2]</ref>, and we computed the fixpoint of the rewriting and the instance using the RDFox <ref type="bibr" target="#b45">[46]</ref> Datalog system v5.4. Table <ref type="table" target="#tab_6">2</ref> summarizes our results. All programs used in this experiment are at least several orders of magnitude larger than what is usually encountered in practical applications of Datalog, but RDFox nevertheless computed the fixpoint of all rewritings in a few minutes. Moreover, although the fixpoints seem to be an order of magnitude larger than the base instance, this is not a problem for highly optimized systems such as RDFox. Hence, checking fact entailment via rewritings produced by our algorithms is feasible in practice.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.4">GTGDs With Relations of Higher Arity</head><p>Finally, we computed the rewriting of GTGDs obtained by blowing up relation arity as described in Subsection 7.1 using a blowup factor of five. We did not use KAON2 since this system supports relations of arity at most two. Figure <ref type="figure" target="#fig_3">5</ref> summarizes our results. Out of 428 inputs, 187 were processed within the ten minute limit by our three systems, and 128 inputs were not processed by any system.</p><p>While HypDR performed best on GTGDs derived from ontologies, Figure <ref type="figure" target="#fig_3">5</ref> shows it to be worst-performing on higher-arity GTGDs: it successfully processed only 199 inputs within the ten minute timeout, whereas SkDR and ExbDR processed 238 and 274 inputs, respectively. This is mainly due to additional body atoms introduced by our "blowup" method: these increase the number of rules participating in an application of the HypDR inference rule, which makes selecting the participating rules harder.</p><p>This experiment proved to be more challenging, as most problems discussed in Section 6 became harder. For example, in ExbDR, higher arity of atoms increases the likelihood that an atom retrieved through a unification index does not unify with a given atom, and that the atoms of the selected GTGDs cannot be successfully matched. Subsumption indexing is also more difficult for similar reasons. However, the inputs used in this experiment consist of a large numbers of GTGDs with relations of arity ten, so they can be seen as a kind of a "stress test". Our algorithms were able to  process more than half of such inputs, which leads us to believe that they can also handle more well-behaved GTGDs used in practice.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">CONCLUSION</head><p>We presented several algorithms for rewriting a finite set of guarded TGDs into a Datalog program that entails the same base facts on each base instance. Our algorithms are based on a new framework that establishes a close connection between Datalog rewritings and a particular style of the chase. In future, we plan to generalize our framework to wider classes of TGDs, such as frontier-guarded TGDs, as well as provide rewritings for conjunctive queries under certain answer semantics. Moreover, we shall investigate whether the extension of our framework to disjunctive guarded TGDs <ref type="bibr" target="#b30">[31]</ref> can be used to obtain practical algorithms for rewriting disjunctive guarded TGDs into disjunctive Datalog programs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A PROOFS FOR SECTION 4: ONE-PASS CHASE PROOFS</head><p>In Section 4 we introduced the notion of a one-pass chase proof, which allows us to establish a completeness criterion for saturations that is tied to the chase. We provide details of the proofs in this appendix.</p><p>A.1 Proof of Theorem 4.2: Existence of One-Pass Chase Proofs Theorem 4.2. For each base instance 𝐼 , each finite set of GTGDs Σ in head-normal form, and each base fact 𝐹 such that 𝐼, Σ |= 𝐹 , there exists a one-pass tree-like chase proof of 𝐹 from 𝐼 and Σ.</p><p>Throughout this section, we fix an arbitrary base instance 𝐼 and a finite set of GTGDs Σ. It is known that 𝐼, Σ |= 𝐹 if and only if there exists a tree-like chase proof of 𝐹 from 𝐼 and Σ. We next prove Theorem 4.2 by showing that each such proof can be transformed to a one-pass chase proof of 𝐹 from 𝐼 and Σ. This argument was developed jointly with Antoine Amarilli, and it is related to proofs by Amarilli and Benedikt <ref type="bibr" target="#b3">[4]</ref> and Kappelmann <ref type="bibr" target="#b30">[31]</ref>; however, note that Definition 4.1 imposes slightly stronger conditions on one-pass chase sequences than related definitions in those works.</p><p>Towards our goal, we first state two basic properties of tree-like chase sequences. The first claim is a variation of the well-known fact that any chase tree produced for GTGDs represents a tree decomposition <ref type="bibr" target="#b14">[15]</ref>. The second claim captures the idea that, as the chase progresses, facts may be added within a vertex, but this will not produced new guarded sets of terms.</p><p>Lemma A.1. Let 𝑇 0 , . . . ,𝑇 𝑛 be an arbitrary tree-like chase sequence for 𝐼 and Σ. 1. For each 0 ≤ 𝑖 ≤ 𝑛, all vertices 𝑣 1 and 𝑣 2 in 𝑇 𝑖 , each set 𝐺 of ground terms that is Σ-guarded by 𝑇 𝑖 (𝑣 1 ) and by 𝑇 𝑖 (𝑣 2 ), and each vertex 𝑣 3 on the unique path in 𝑇 𝑖 between 𝑣 1 and 𝑣 2 , set 𝐺 is Σ-guarded by 𝑇 𝑖 (𝑣 3 ).</p><p>2. For each 0 ≤ 𝑖 ≤ 𝑛, each vertex 𝑣 in 𝑇 𝑖 , each set 𝐺 of ground terms that is Σ-guarded by 𝑇 𝑖 (𝑣), and each 0 ≤ 𝑗 ≤ 𝑖 such that 𝑇 𝑗 contains 𝑣, set 𝐺 is Σ-guarded by 𝑇 𝑗 (𝑣).</p><p>Proof of Claim 1. The proof is by induction on 𝑖 with 0 ≤ 𝑖 ≤ 𝑛. For 𝑖 = 0, chase tree 𝑇 0 contains just one vertex so the claim holds trivially. Now assume that the property holds for some 0 ≤ 𝑖 &lt; 𝑛 and consider ways in which 𝑇 𝑖+1 can be derived from 𝑇 𝑖 . First, 𝑇 𝑖+1 can be obtained by applying a chase step to 𝑇 𝑖 at vertex 𝑣 with some GTGD 𝜏 ∈ Σ. Let 𝑣 1 be the recently updated vertex of 𝑇 𝑖+1 . Thus, 𝑣 1 is either 𝑣 or a fresh child of 𝑣. Moreover, consider each fact 𝑅( ì 𝑡) derived by the step, each set of ground terms 𝐺 ⊆ ì 𝑡, each vertex 𝑣 2 such that 𝐺 is Σ-guarded by 𝑇 𝑖+1 (𝑣 2 ), and each vertex 𝑣 3 on the unique path in 𝑇 𝑖+1 between 𝑣 1 and 𝑣 2 . If 𝐺 contains a labeled null that is freshly introduced in 𝑇 𝑖+1 , the claim holds trivially because 𝑣 2 and 𝑣 3 are necessarily the same as 𝑣 1 . Otherwise, 𝜏 is guarded, so 𝑇 𝑖 (𝑣) contains a fact 𝑆 ( ì 𝑢) such that 𝐺 ⊆ ì 𝑢. But then, 𝐺 is Σ-guarded by 𝑇 𝑖 (𝑣 3 ) by the induction assumption. Moreover, 𝑇 𝑖 (𝑣 3 ) ⊆ 𝑇 𝑖+1 (𝑣 3 ) ensures that 𝐺 is Σ-guarded by 𝑇 𝑖+1 (𝑣 3 ), as required. Second, 𝑇 𝑖+1 can be obtained by applying a propagation step to 𝑇 𝑖 , but then the property clearly holds. □</p><p>Proof of Claim 2. The proof is by induction on 𝑖 with 0 ≤ 𝑖 ≤ 𝑛. The base case for 𝑖 = 0 is trivial. For the induction step, assume that the property holds for some 𝑖. If 𝑇 𝑖+1 is obtained from 𝑇 𝑖 by a chase step with a non-full GTGD, then the claim clearly holds for 𝑇 𝑖+1 because the step introduces a fresh vertex that does not occur in any 𝑇 𝑗 with 0 ≤ 𝑗 ≤ 𝑖. Otherwise, 𝑇 𝑖+1 is obtained by extending some 𝑇 𝑖 (𝑣), so consider an arbitrary fact 𝐹 ∈ 𝑇 𝑖+1 (𝑣) \ 𝑇 𝑖 (𝑣). Clearly, 𝐹 is Σ-guarded by 𝑇 𝑖 (𝑣): if the step involves a full GTGD, then a body atom of the GTGD is matched to a fact 𝐹 ′ ∈ 𝑇 𝑖 (𝑣) such that 𝐹 is Σ-guarded by 𝐹 ′ ; moreover, if the step involves propagation, then by definition there exists a fact 𝐹 ′ ∈ 𝑇 𝑖 (𝑣) such that 𝐹 is Σ-guarded by 𝐹 ′ . Thus, each set of ground terms 𝐺 that is Σ-guarded by 𝑇 𝑖+1 (𝑣) is also Σ-guarded by 𝐹 ′ ∈ 𝑇 𝑖 (𝑣), so the claim holds. □</p><p>In the rest of the proof, we show how to convert an arbitrary tree-like chase proof into a one-pass one through a series of transformations. Before proceeding, we next describe formally the types of chase sequence that we consider in our transformations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Definition A.2.</head><p>• A chase sequence is local if each propagation step in the sequence copies just one fact to either the parent or a child vertex.</p><p>• A chase sequence is rootward if each propagation step in the sequence copies just one fact from a child to its parent.</p><p>• A chase sequence is almost one-pass if it is rootward and each chase or propagation step is applied to the recently updated vertex or an ancestor thereof, and a chase step is applied only if a propagation step is not applicable to the recently updated vertex or an ancestor thereof.</p><p>Note that facts can still be copied from a parent to a child in a rootward chase sequence, but this can be done only in chase steps with non-full GTGDs that introduce a child. Furthermore, the use of "almost" in the "almost one-pass" reflects the caveat that, in an almost one-pass chase sequence, a step can be applied to an ancestor of the recently updated vertex, thus "jumping rootward" in the tree, whereas such steps are forbidden in a one-pass chase sequence.</p><p>We capture formally the relationship between the chase sequences produced by our transformations using the notion introduced in Definition A.3.</p><p>Definition A.3. A chase tree 𝑇 is a subset of a chase tree 𝑇 ′ , written 𝑇 ⊆ 𝑇 ′ , if the tree of 𝑇 is a subtree of 𝑇 ′ (i.e., the root of 𝑇 is the root of 𝑇 ′ , and whenever vertex 𝑣 is a parent of vertex 𝑣 ′ in 𝑇 , then 𝑣 is a parent of 𝑣 ′ in 𝑇 ′ ), and 𝑇 (𝑣) ⊆ 𝑇 ′ (𝑣) holds for each vertex 𝑣 of 𝑇 .</p><p>We are now ready to present our transformations, which we capture in a series of lemmas. We next summarize the main intuitions.</p><p>• In Lemma A.4, we show that an arbitrary chase sequence can be transformed into a local chase sequence by "slowing down" propagation steps so that facts are copied only between vertices that are adjacent in a chase tree. • In Lemma A.5, we show that each local chase sequence can be transformed into a rootward chase sequence. Intuitively, instead of propagating a fact from a parent to a child, we "regrow" a clone of the relevant child and the entire subtree underneath. The relevant fact is then copied as part of the chase step with the non-full GTGD that "regrows" the child's clone. • In Lemma A.6, we show that each rootward chase sequence can be transformed to an almost one-pass chase sequence. The main difficulty arises due to the fact that steps in a rootward chase sequence can be applied to arbitrary vertices. We address this problem by shuffling and regrowing parts of the chase trees. • Finally, in Lemma A.7, we show that each almost one-pass chase proof can be transformed to a one-pass chase proof by pruning irrelevant parts of the chase sequence.</p><p>Lemma A.4. For each tree-like chase sequence 𝑇 0 , . . . ,𝑇 𝑛 for 𝐼 and Σ, there exists a local tree-like chase sequence 𝑇 0 , . . . ,𝑇 𝑚 for 𝐼 and Σ such that 𝑇 𝑛 ⊆ 𝑇 𝑚 .</p><p>Proof. Each propagation step in 𝑇 0 , . . . ,𝑇 𝑛 that copies more than one fact can clearly be "expanded" into several steps, each copying just one fact. Moreover, due to Claim 1 of Lemma A.1, each propagation step that copies a fact 𝐹 between vertices 𝑣 and 𝑣 ′ that are further apart can be "expanded" into several steps that propagate 𝐹 to all vertices on the unique path between 𝑣 and 𝑣 ′ . □ Lemma A.5. For each local tree-like chase sequence 𝑇 0 , . . . ,𝑇 𝑛 for 𝐼 and Σ, there exists a rootward tree-like chase sequence 𝑇 0 , . . . ,𝑇 𝑚 for 𝐼 and Σ such that (S1) 𝑇 𝑛 ⊆ 𝑇 𝑚 , and (S2) for each vertex 𝑣 in 𝑇 𝑛 that is introduced by a chase step with a non-full GTGD 𝜏 ∈ Σ and substitutions 𝜎 and 𝜎 ′ , vertex 𝑣 is introduced into some 𝑇 𝑘 with 0 ≤ 𝑘 ≤ 𝑚 by a chase step with the same 𝜏, 𝜎, and 𝜎 ′ .</p><p>Proof. Let 𝑇 0 , . . . ,𝑇 𝑛 be an arbitrary local tree-like chase sequence for 𝐼 and Σ. We prove the claim by induction on 0 ≤ 𝑖 ≤ 𝑛. The induction base 𝑖 = 0 holds trivially. For the induction step, we assume that the claim holds for some 𝑖 with 0 ≤ 𝑖 &lt; 𝑛. By the inductive assumption, there exists a rootward chase sequence 𝑇 0 , . . . ,𝑇 𝑗 for 𝐼 such that 𝑇 𝑖 ⊆ 𝑇 𝑗 and property (S2) holds. Let 𝑣 be the vertex of 𝑇 𝑖 to which a chase or propagation step is applied to derive 𝑇 𝑖+1 . By Definition A.3, chase tree 𝑇 𝑗 contains vertex 𝑣 and 𝑇 𝑖 (𝑣) ⊆ 𝑇 𝑗 (𝑣) holds. We now consider ways in which 𝑇 𝑖+1 can be derived from 𝑇 𝑖 .</p><p>Assume that 𝑇 𝑖+1 is obtained from 𝑇 𝑖 by a chase step with non-full TGD 𝜏 ∈ Σ, and let 𝑣 ′ be the child of 𝑣 introduced by the step. Without loss of generality, we can choose 𝑣 ′ and the fresh labeled nulls such that they do not occur in 𝑇 𝑗 . Now let 𝑇 𝑗+1 be obtained from 𝑇 𝑗 by adding 𝑣 ′ as a child of 𝑣 and setting 𝑇 𝑗+1 (𝑣 ′ ) = 𝑇 𝑖+1 (𝑣 ′ ). Clearly, 𝑇 0 , . . . ,𝑇 𝑗 ,𝑇 𝑗+1 is a rootward chase sequence such that 𝑇 𝑖+1 ⊆ 𝑇 𝑗+1 and property (S2) hold, as required.</p><p>Assume that 𝑇 𝑖+1 is obtained from 𝑇 𝑖 by a chase step with a full TGD 𝜏 ∈ Σ deriving a fact 𝐹 , or by a rootward propagation step that copies a fact 𝐹 from 𝑇 𝑖 (𝑣) to the parent of 𝑣. Let 𝑣 ′ be the recently updated vertex of 𝑇 𝑖+1 . Chase tree 𝑇 𝑗 clearly contains 𝑣 ′ . If 𝐹 ∈ 𝑇 𝑗 (𝑣 ′ ), then sequence 𝑇 0 , . . . ,𝑇 𝑗 satisfies the inductive property. If 𝑇 𝑖+1 is obtained from 𝑇 𝑖 by a propagation step, then 𝐹 is Σ-guarded by 𝑇 𝑖 (𝑣 ′ ). But then, 𝑇 𝑖 (𝑣 ′ ) ⊆ 𝑇 𝑗 (𝑣 ′ ) ensures that 𝐹 is also Σ-guarded by 𝑇 𝑗 (𝑣 ′ ) and thus the propagation step is applicable to vertices 𝑣 and 𝑣 ′ in 𝑇 𝑗 . Now let 𝑇 𝑗+1 to be the same as 𝑇 𝑗 but with 𝑇 𝑗+1 (𝑣 ′ ) = 𝑇 𝑗 (𝑣 ′ ) ∪ {𝐹 } and with 𝑣 ′ being the recently updated vertex. Clearly, 𝑇 0 , . . . ,𝑇 𝑗 ,𝑇 𝑗+1 is a rootward chase sequence satisfying 𝑇 𝑖+1 ⊆ 𝑇 𝑗+1 , as required. Moreover, property (S2) holds by the induction hypothesis.</p><p>The only remaining case is when 𝑇 𝑖+1 is obtained from 𝑇 𝑖 by applying a propagation step that copies one fact 𝐹 to a child 𝑣 ′ of 𝑣. By Definition A.3, chase tree 𝑇 𝑗 contains vertex 𝑣 ′ and 𝑇 𝑖 (𝑣 ′ ) ⊆ 𝑇 𝑗 (𝑣 ′ ) holds. Sequence 𝑇 0 , . . . ,𝑇 𝑗 satisfies the inductive property if 𝐹 ∈ 𝑇 𝑗 (𝑣 ′ ) holds, so we next assume 𝐹 ∉ 𝑇 𝑗 (𝑣 ′ ). We next show that we can simulate propagation by "replaying" the chase steps that generate 𝑣 ′ and all of its descendants. Towards this goal, let 𝑇 𝑘 be the chase tree in the original sequence where 𝑣 ′ is first introduced by applying a chase step with the non-full GTGD 𝜏 = 𝛽 → ∃ì 𝑦 𝜂 ∈ Σ, and let 𝜎 and 𝜎 ′ be substitutions used in the step. By the inductive property (S2), there exists ℓ 0 with 0 &lt; ℓ 0 ≤ 𝑗 such that 𝑣 ′ is introduced in 𝑇 ℓ 0 as the result of applying a chase step with the same non-full TGD 𝜏 and substitutions 𝜎 and 𝜎 ′ . Finally, let 𝑇 ℓ 0 , . . . ,𝑇 ℓ 𝑚 be the subsequence of 𝑇 0 , . . . ,𝑇 𝑗 consisting of precisely those chase trees that were obtained by applying a chase or a propagation step to 𝑣 ′ or a descendant of 𝑣 ′ . In other words, the chase steps producing 𝑇 ℓ 0 , . . . ,𝑇 ℓ 𝑚 are exactly the steps that we need to "replay" to simulate the propagation of 𝐹 from 𝑣 to 𝑣 ′ .</p><p>Our objective is to "replay" the steps producing 𝑇 ℓ 0 , . . . ,𝑇 ℓ 𝑚 so that they introduce exactly the same vertices and labeled nulls, which is needed because property (S1) talks about exact containment of the final chase trees of the two sequences (rather than containment up to isomorphism). A technical issue is that these vertices and labeled nulls already occur in the sequence 𝑇 0 , . . . ,𝑇 𝑗 ; thus, if we extended this sequence directly, we could not "reapply" the chase steps with non-full GTGDs, which by definition introduce fresh vertices and labeled nulls. To get around this, we first perform the following renaming step. Let 𝑁 be the set of labeled nulls introduced by the chase steps with non-full TGDs in subsequence 𝑇 ℓ 0 , . . . ,𝑇 ℓ 𝑚 , and let 𝑊 be the set of introduced vertices (thus, 𝑊 contains 𝑣 ′ and all of its descendants). Moreover, let 𝑈 0 , . . . , 𝑈 𝑗 be the chase sequence obtained by uniformly replacing in 𝑇 0 , . . . ,𝑇 𝑗 each labeled null in 𝑁 with a distinct, fresh labeled null, and by uniformly replacing each vertex 𝑤 ∈ 𝑊 by a fresh vertex.</p><p>We next describe the chase trees that will be produced by "replaying" the steps producing the subsequence 𝑇 ℓ 0 , . . . ,𝑇 ℓ 𝑚 . Intuitively, we must "graft" the results of these steps onto 𝑈 𝑗 : for 𝑣 ′ or a descendant of 𝑣 ′ we take the results of the chase steps in the subsequence, and for each other vertex we copy the content from 𝑈 𝑗 . Formally, let 𝑉 0 , . . . , 𝑉 𝑚 be the sequence obtained from the subsequence 𝑇 ℓ 0 , . . . ,𝑇 ℓ 𝑚 using the following steps.</p><p>(R1) For each 0 ≤ 𝑝 ≤ 𝑚 and each vertex 𝑤 in 𝑈 𝑗 such that 𝑤 is neither 𝑣 ′ nor a descendant of 𝑣 ′ in 𝑈 𝑗 , we set 𝑉 𝑝 (𝑤) = 𝑈 𝑗 (𝑤).</p><p>(R2) For each 0 ≤ 𝑝 ≤ 𝑚 and each vertex 𝑤 that occurs in 𝑇 ℓ 𝑝 such that 𝑤 is 𝑣 ′ or a descendant of 𝑣 ′ in 𝑇 ℓ 𝑝 , we set 𝑉 𝑝 (𝑤) = 𝑇 ℓ 𝑝 (𝑤).</p><p>(R3) We add to 𝑉 0 (𝑣 ′ ) each fact 𝐺 ∈ 𝑈 𝑗 (𝑣) that is Σ-guarded by 𝜎 ′ (𝜂).</p><p>(R4) We analogously extend each 𝑉 𝑝 with 1 ≤ 𝑝 ≤ 𝑚 to ensure that each chase step with a non-full GTGD correctly propagates all relevant facts to a child.</p><p>We now argue that 𝑈 0 , . . . , 𝑈 𝑗 , 𝑉 0 , . . . , 𝑉 𝑚 is a rootward chase sequence that satisfies properties (S1) and (S2). Towards this goal, we make the following observations.</p><p>• Sequence 𝑈 0 , . . . , 𝑈 𝑗 is a rootward chase sequence produced by the same steps as 𝑇 0 , . . . ,𝑇 𝑗 , but with the vertices in 𝑊 and labeled nulls in 𝑁 uniformly renamed. Also, due to step (R4), 𝑉 0 , . . . , 𝑉 𝑚 is a rootward chase sequence produced by the same steps as 𝑇 ℓ 0 , . . . ,𝑇 ℓ 𝑚 .</p><p>• Chase tree 𝑉 0 coincides with 𝑈 𝑗 on each vertex that is not 𝑣 ′ or a descendant of 𝑣 ′ . Moreover, 𝑈 𝑗 does not contain a labeled null in 𝑁 , and it does not contain 𝑣 ′ or a descendant of 𝑣 ′ ; thus, 𝑉 0 can be seen as the result of applying to 𝑈 𝑗 a chase step with the non-full GTGD 𝜏 and substitutions 𝜎 and 𝜎 ′ that introduces vertex 𝑣 ′ as a child of 𝑣.</p><p>• We now show that property (S2) is satisfied-that is, that 𝑇 𝑖+1 ⊆ 𝑉 𝑚 holds. Towards this goal, consider an arbitrary vertex 𝑤 occurring in 𝑇 𝑖+1 ; by the induction assumption, we have 𝑇 𝑖 (𝑤) ⊆ 𝑇 𝑗 (𝑤). If 𝑤 is neither 𝑣 ′ nor a descendant thereof, then neither 𝑤 nor a labeled null occurring in 𝑇 𝑖 (𝑤) was renamed in 𝑈 𝑗 , so we have 𝑇 𝑗 (𝑤) = 𝑈 𝑗 (𝑤) = 𝑉 𝑚 (𝑤), where the last equality is ensured by step (R1); thus, 𝑇 𝑖+1 (𝑤) = 𝑇 𝑖 (𝑤) ⊆ 𝑉 𝑚 (𝑤) holds, as required. Now assume that 𝑤 is 𝑣 ′ or a descendant thereof. Then, 𝑇 𝑗 (𝑤) = 𝑇 ℓ 𝑚 (𝑤) holds by the fact that 𝑇 ℓ 𝑚 is the last place in 𝑇 0 , . . . ,𝑇 𝑗 where 𝑣 ′ or a descendant of 𝑣 ′ was modified, and 𝑇 ℓ 𝑚 (𝑤) = 𝑉 𝑚 (𝑤) holds by step (R2); putting it all together, we have 𝑇 𝑖 (𝑤) ⊆ 𝑉 𝑚 (𝑤). Now if 𝑤 is not 𝑣 ′ (i.e., 𝑤 is a descendant of 𝑣 ′ ), then 𝑇 𝑖+𝑖 (𝑤) = 𝑇 𝑖 (𝑤) ⊆ 𝑉 𝑚 (𝑤) holds, as required.</p><p>We finally consider the case when 𝑤 is 𝑣 ′ , so 𝑇 𝑖+1 (𝑣 ′ ) = 𝑇 𝑖 (𝑣 ′ ) ∪ {𝐹 }. Since the propagation step is applicable to 𝑇 𝑖 , fact 𝐹 is Σ-guarded by 𝑇 𝑖 (𝑣 ′ ). By Claim 2 of Lemma A.1, fact 𝐹 is also Σ-guarded by 𝑇 𝑘 (𝑣 ′ ). Finally, by the definition of a chase step with a non-full TGD, fact 𝐹 is Σ-guarded by 𝜎 ′ (𝜂). But then, step (R3) ensures 𝐹 ∈ 𝑉 0 (𝑣 ′ ) ⊆ 𝑉 𝑚 (𝑣 ′ ). Consequently, 𝑇 𝑖+𝑖 (𝑣 ′ ) ⊆ 𝑉 𝑚 (𝑣 ′ ) holds, as required.</p><p>• We now show that property (S2) is satisfied. To this end, consider an arbitrary vertex 𝑤 in 𝑇 𝑖+1 introduced by a chase step with a non-full GTGD 𝜏 and substitutions 𝜎 and 𝜎 ′ . If 𝑤 is not 𝑣 ′ or a descendant thereof, then the labeled nulls introduced by the chase step are not renamed in 𝑈 0 , . . . , 𝑈 𝑗 , so the claim holds by the induction assumption. Otherwise, the chase steps producing 𝑉 0 , . . . , 𝑉 𝑚 are exactly the same as the chase steps producing 𝑇 ℓ 0 , . . . ,𝑇 ℓ 𝑚 , so the claim holds by the induction assumption too. □ Lemma A.6. For each rootward tree-like chase sequence 𝑇 0 , . . . ,𝑇 𝑛 for 𝐼 and Σ, there exists an almost one-pass chase sequence 𝑇 0 , . . . ,𝑇 𝑚 for 𝐼 and Σ such that 𝑇 𝑛 ⊆ 𝑇 𝑚 .</p><p>Proof. Let 𝑇 0 , . . . ,𝑇 𝑛 be an arbitrary rootward tree-like chase sequence for 𝐼 and Σ. The induction base 𝑖 = 0 holds trivially. For the induction step, we assume that the claim holds for some 𝑖 with 0 ≤ 𝑖 &lt; 𝑛. By the inductive assumption, there exists an almost one-pass chase sequence 𝑇 0 , . . . ,𝑇 𝑗 for 𝐼 and Σ such that 𝑇 𝑖 ⊆ 𝑇 𝑗 holds. Now assume that 𝑇 𝑖+1 is obtained by applying a chase or a propagation step to some vertex 𝑣 of 𝑇 𝑖 , and let 𝑘 be the maximal number such that 0 ≤ 𝑘 ≤ 𝑗 and 𝑣 is recently updated in 𝑇 𝑘 . Such 𝑘 clearly exists since 𝑣 occurs in 𝑇 𝑗 , and 𝑇 𝑖 (𝑣) ⊆ 𝑇 𝑘 (𝑣) holds because 𝑘 is maximal. We now consider ways in which 𝑇 𝑖+1 can be derived from 𝑇 𝑖 .</p><p>Assume that 𝑇 𝑖+1 is obtained from 𝑇 𝑖 by a chase step with non-full GTGD 𝜏 ∈ Σ and substitutions 𝜎 and 𝜎 ′ , and let 𝑣 ′ be the child of 𝑣 introduced by the step. Without loss of generality, we can choose 𝑣 ′ and the fresh labeled nulls such that they do not occur in 𝑇 𝑗 . We shall now "move" this chase step so that it is performed immediately after 𝑇 𝑘 . Towards this goal, we describe the chase trees that are obtained by this move. For each 𝑝 with 𝑘 ≤ 𝑝 ≤ 𝑗, let 𝑈 𝑝 be the chase tree obtained from 𝑇 𝑝 by adding vertex 𝑣 ′ and letting 𝑈 𝑝 (𝑣 ′ ) = 𝑇 𝑖+1 (𝑣 ′ ). We now argue that 𝑇 0 , . . . ,𝑇 𝑘 , 𝑈 𝑘 , . . . , 𝑈 𝑗 is an almost one-pass chase sequence satisfying the conditions of the lemma.</p><p>• Chase tree 𝑈 𝑘 can be seen as obtained from 𝑇 𝑘 by a chase step with 𝜏 and substitutions 𝜎 and 𝜎 ′ . Moreover, for each 𝑝 with 𝑘 ≤ 𝑝 &lt; 𝑗, chase tree 𝑈 𝑝+1 is obtained from 𝑈 𝑝 in the same way as 𝑇 𝑝+1 is obtained from 𝑇 𝑝 . Thus, all preconditions of all chase steps are satisfied.</p><p>• Chase tree 𝑈 𝑘 is obtained from 𝑇 𝑘 by applying the chase step to the recently updated vertex 𝑣 of 𝑇 𝑘 . Moreover, if 𝑘 &lt; 𝑗, then 𝑇 𝑘+1 is obtained from 𝑇 𝑘 by applying a step to 𝑣 or an ancestor of 𝑣, and so 𝑈 𝑘+1 is obtained from 𝑈 𝑘 by applying a step to an ancestor of the recently updated vertex of 𝑈 𝑘 . Thus, the sequence is almost one-pass.</p><p>• The construction clearly satisfies 𝑇 𝑖+1 ⊆ 𝑈 𝑗 .</p><p>In the rest of this proof we consider the case when 𝑇 𝑖+1 is obtained from 𝑇 𝑖 by a chase step with a full GTGD 𝜏 ∈ Σ deriving a fact 𝐹 , or by a propagation step that copies a fact 𝐹 from 𝑇 𝑖 (𝑣) to the parent of 𝑣. Let 𝑣 ′ be the recently updated vertex of 𝑇 𝑖+1 . Chase tree 𝑇 𝑗 clearly contains 𝑣 ′ . If 𝐹 ∈ 𝑇 𝑘 (𝑣 ′ ), then sequence 𝑇 0 , . . . ,𝑇 𝑗 satisfies the inductive property, so we next assume that 𝐹 ∉ 𝑇 𝑘 (𝑣 ′ ) holds. We shall now transform 𝑇 0 , . . . ,𝑇 𝑗 so that this step is applied immediately after 𝑇 𝑘 , and fact 𝐹 is propagated towards the root as far as possible. Since this will move the recently updated vertex towards the root, we will then "reapply" all relevant steps from 𝑇 0 , . . . ,𝑇 𝑗 to "regrow" the relevant part of the sequence. In each case, we specify the structure of the chase trees and discuss the steps that produce these trees.</p><p>Let 𝑈 0 be obtained from 𝑇 𝑘 by adding 𝐹 to 𝑇 𝑘 (𝑣). We argue that 𝑈 0 can be seen as being obtained from 𝑇 𝑘 by the same step that produces 𝑇 𝑖+1 from 𝑇 𝑖 .</p><p>• If 𝑇 𝑖+1 is obtained from 𝑇 𝑖 by a chase step with a full GTGD, then 𝐹 ∉ 𝑇 𝑘 (𝑣 ′ ) holds ensures that the same step is applicable to 𝑇 𝑘 (𝑣 ′ ) (where 𝑣 ′ = 𝑣).</p><p>• If 𝑇 𝑖+1 is obtained from 𝑇 𝑖 by a propagation step, then 𝐹 is Σ-guarded by 𝑇 𝑖 (𝑣 ′ ). But then, 𝑇 𝑖 (𝑣 ′ ) ⊆ 𝑇 𝑗 (𝑣 ′ ) ensures that 𝐹 is also Σ-guarded by 𝑇 𝑗 (𝑣 ′ ), and Claim 2 of Lemma A.1 ensures that 𝐹 is Σ-guarded by 𝑇 𝑘 (𝑣 ′ ). Thus, the propagation step is applicable to vertices 𝑣 and 𝑣 ′ in 𝑇 𝑘 .</p><p>Moreover, let 𝑈 1 , . . . , 𝑈 𝑠 be the chase trees obtained by propagating 𝐹 starting from 𝑈 0 towards the root using local steps as long as possible.</p><p>Clearly, 𝑇 0 , . . . ,𝑇 𝑘 , 𝑈 0 , 𝑈 1 , . . . , 𝑈 𝑠 is a correctly formed almost one-pass chase sequence. Let 𝑣 ′′ be the recently updated vertex of 𝑈 𝑠 , We cannot simply append the step producing 𝑇 𝑘+1 after 𝑈 𝑠 because this step might not be applicable to 𝑣 ′′ or an ancestor thereof. Thus, to obtain the chase sequence satisfying the claim of the lemma, we shall find a place in sequence 𝑇 0 , . . . ,𝑇 𝑗 where vertex 𝑣 ′′ is introduced, and we shall "replay" all steps from that point onwards. In doing so, we shall use chase steps that introduce the same vertices and labeled nulls, so we will first need to rename these in the sequence 𝑇 0 , . . . ,𝑇 𝑘 , 𝑈 0 , 𝑈 1 , . . . , 𝑈 𝑠 .</p><p>Let ℓ be the smallest integer such that 𝑇 ℓ contains 𝑣 ′′ . Clearly, ℓ ≤ 𝑘 holds. Now let 𝑁 be the set of labeled nulls introduced by applying a chase step to 𝑣 ′′ or a descendant thereof, and let 𝑊 the the set of descendants of 𝑣 ′′ in the sequence 𝑇 0 , . . . ,𝑇 𝑗 . Moreover, let</p><formula xml:id="formula_51">𝑇 ′ 0 , . . . ,𝑇 ′ 𝑘 , 𝑈 ′ 0 , 𝑈 ′ 1 , . . .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>, 𝑈</head><p>′ 𝑠 be the chase sequence obtained by uniformly replacing in 𝑇 0 , . . . ,𝑇 𝑘 , 𝑈 0 , 𝑈 1 , . . . , 𝑈 𝑠 each labeled null in 𝑁 with a distinct, fresh labeled null, and by uniformly replacing each vertex 𝑤 ∈ 𝑊 by a fresh vertex.</p><p>We now transform chase trees 𝑇 ℓ+1 , . . . ,𝑇 𝑗 into chase tress 𝑉 ℓ+1 , . . . , 𝑉 𝑗 that reflect the result of "replaying" after 𝑈 ′ 𝑠 the steps producing the former sequence. Intuitively, each 𝑉 𝑝 is a "union" of 𝑈 𝑠 and 𝑇 𝑝 . Formally, for each 𝑝 with ℓ &lt; 𝑝 ≤ 𝑗, we define 𝑉 𝑝 as follows. • For ℓ ≤ 𝑝 &lt; 𝑗, either 𝑉 𝑝+1 is obtained from 𝑉 𝑝 (or 𝑈 ′ 𝑠 in case 𝑝 = ℓ) by the same step that produces 𝑇 𝑝+1 from 𝑇 𝑝 , or the step is not applicable. In the latter case, we can simply drop such 𝑉 𝑝+1 from the sequence. By dropping all such 𝑉 𝑝+1 , we clearly obtain a valid almost one-pass chase sequence.</p><p>• We have 𝑇 𝑖 ⊆ 𝑇 𝑗 by the induction assumption, and steps (S1)-(S3) clearly ensure 𝑇 𝑖 ⊆ 𝑉 𝑗 . Moreover, 𝑇 𝑖+1 differs from 𝑇 𝑖 only in vertex 𝑣 ′ , where 𝑇 𝑖+1 (𝑣 ′ ) = 𝑇 (𝑣 ′ ) ∪ {𝐹 } holds. Our construction, however, clearly ensures 𝐹 ∈ 𝑈 ′ 𝑠 (𝑣 ′′ ), and step (S4) ensures that 𝐹 is propagated in each chase step with a non-full GTGD introducing a vertex on the unique path from 𝑣 ′′ to 𝑣 ′ . Thus, 𝑇 𝑖+1 ⊆ 𝑉 𝑗 holds. □ Lemma A.7. For each base fact 𝐹 and each almost one-pass tree-like chase proof of 𝐹 from 𝐼 and Σ, there exists a one-pass tree-like chase proof of 𝐹 from 𝐼 and Σ.</p><p>Proof. Consider an arbitrary base fact 𝐹 and an arbitrary almost one-pass tree-like chase proof 𝑇 0 , . . . ,𝑇 𝑛 of 𝐹 from 𝐼 and Σ. Since 𝐹 is a base fact, without loss of generality we can assume that 𝐹 occurs in the facts of the root vertex. Now let 𝑇 𝑖 be the first chase tree that contains 𝐹 in the root, and let 𝑊 be the set containing each non-root vertex 𝑣 occurring in any of the chase trees such that no propagation step is applied to 𝑣. We transform this proof to a one-pass proof as follows. First, we delete each 𝑇 𝑗 with 𝑖 &lt; 𝑗 ≤ 𝑛. Next, we delete in each remaining 𝑇 𝑗 each vertex 𝑣 ∈ 𝑊 and each descendant of 𝑣. Finally, we delete each remaining 𝑇 𝑗 that is equal to 𝑇 𝑗+1 . After this transformation, every vertex has a propagation step applied to it. It is straightforward to see that the result is a one-pass tree-like chase sequence. Moreover, since 𝐹 occurs in the root, the sequence is a tree-like chase proof of 𝐹 from 𝐼 and Σ. □</p><p>A. • each Datalog rule of Σ is a logical consequence of Σ ′ , and</p><p>• for each base instance 𝐼 , each one-pass tree-like chase sequence 𝑇 0 , . . . ,𝑇 𝑛 for 𝐼 and Σ, and each loop 𝑇 𝑖 , . . . ,𝑇 𝑗 at the root vertex 𝑟 with output fact 𝐹 , there exist a Datalog rule 𝛽 → 𝐻 ∈ Σ ′ and a substitution 𝜎 such that 𝜎 (𝛽) ⊆ 𝑇 𝑖 (𝑟 ) and 𝜎 (𝐻 ) = 𝐹 .</p><p>Proof. Let Σ and Σ ′ be as specified in the proposition, let 𝐼 be an arbitrary base instance, and let 𝐹 be an arbitrary base fact. Since Σ ′ is a logical consequence of Σ, it is clear that 𝐼, Σ ′ |= 𝐹 implies 𝐼, Σ |= 𝐹 . Thus, we assume that 𝐼, Σ |= 𝐹 holds, and we prove that 𝐼, Σ ′ |= 𝐹 holds as well. By Theorem 4.2, there exists a one-pass tree-like chase proof 𝑇 0 , . . . ,𝑇 𝑛 of 𝐹 from 𝐼 and Σ. Without loss of generality, we can assume that 𝐹 is produced in the last step of the proof, and so the recently updated vertex of 𝑇 𝑛 is root vertex 𝑟 . Let 𝑖 0 &lt; • • • &lt; 𝑖 𝑚 be exactly the indexes between 0 and 𝑛 such that the recently updated vertex of 𝑇 𝑖 𝑗 is 𝑟 . We next construct a tree-like chase sequence 𝑇 0 , . . . ,𝑇 𝑘 for 𝐼 and Σ ′ such that 𝑇 𝑛 (𝑟 ) ⊆ 𝑇 𝑘 (𝑟 ). To formalize our inductive construction of this chase sequence, we shall also construct a sequence of indexes ℓ 0 , . . . , ℓ 𝑚 such that ℓ 𝑚 = 𝑘 and, for each 𝑗 with 0 ≤ 𝑗 ≤ 𝑚, we have 𝑇 𝑖 𝑗 (𝑟 ) ⊆ 𝑇 ℓ 𝑗 (𝑟 ); in other words, each index ℓ 𝑗 helps us establish the inductive property by relating 𝑇 𝑖 𝑗 and 𝑇 ℓ 𝑗 . For the base case, 𝑖 0 = 0 holds by the definition of a tree-like chase proof; thus, we set 𝑇 0 = 𝑇 0 and ℓ 0 = 0, and the required property clearly holds. For the inductive step, we consider arbitrary 0 &lt; 𝑗 ≤ 𝑚 such that the claim holds for 𝑗 -1, and assume that the sequence constructed thus far is 𝑇 ℓ 0 , . . . ,𝑇 ℓ 𝑗 -1 . We have the following two cases.</p><p>• The recently updated vertex of 𝑇 𝑖 𝑗 -1 is 𝑟 . Thus, 𝑖 𝑗 -1 = 𝑖 𝑗 -1 , and 𝑇 𝑖 𝑗 is obtained from 𝑇 𝑖 𝑗 by with a full GTGD 𝛽 → 𝐻 ∈ Σ producing a fact 𝐺 ∈ 𝑇 𝑖 𝑗 (𝑟 ). The second condition of the proposition ensures that 𝛽 → 𝐻 is a logical consequence of Σ ′ , so 𝐺 can be derived from 𝑇 ℓ 1 (𝑟 ) and the Datalog rules of Σ ′ using ℘ steps. We then define ℓ 𝑗 = ℓ 𝑗 -1 + ℘, and we append the corresponding steps to obtain the sequence 𝑇 0 , . . . ,𝑇 We finally prove a property that will be needed in the proofs in Appendices B-E. This property intuitively ensures that, as soon as a fact 𝐹 is derived in the child vertex of a loop such that 𝐹 does not contain any null values introduced by the child, the loop is completed and 𝐹 is propagated to the parent vertex.</p><p>Proposition A.8. For each loop 𝑇 𝑖 , . . . ,𝑇 𝑗 at a vertex 𝑣 in a one-pass tree-like chase proof for some 𝐼 and Σ, for 𝑖 &lt; 𝑘 ≤ 𝑗, and for 𝑣 ′ the vertex introduced in 𝑇 𝑖+1 , set terms 𝑇 𝑘 (𝑣 ′ ) \ nulls 𝑇 𝑖+1 (𝑣 ′ ) is Σ-guarded by 𝑇 𝑖 (𝑣).</p><p>Proof. Consider an arbitrary loop 𝑇 𝑖 , . . . ,𝑇 𝑗 at a vertex 𝑣 in a one-pass tree-like chase proof for some 𝐼 and Σ, and let 𝑣 ′ be the child of 𝑣 introduced by the chase step producing 𝑇 𝑖+1 . We prove the claim by induction on 𝑘 with 𝑖 &lt; 𝑘 ≤ 𝑗. For the induction base 𝑘 = 𝑖 + 1, the definition of a chase step with a non-full GTGD clearly ensures this claim for 𝑇 𝑖+1 (𝑣 ′ ). For the induction step, consider an arbitrary 𝑘 such that the claim holds. Our claim holds trivially if 𝑇 𝑘+1 (𝑣 ′ ) = 𝑇 𝑘 (𝑣 ′ ), so we assume that 𝑇 𝑘+1 (𝑣 ′ ) \ 𝑇 𝑘 (𝑣 ′ ) contains exactly one fact 𝐹 , which can be derived in one of the following two ways.</p><p>• Assume 𝐹 is obtained by a propagation step to vertex 𝑣 ′ . Then, 𝐹 is Σ-guarded by 𝑇 𝑘 (𝑣 ′ ), so terms(𝐹 ) ⊆ terms 𝑇 𝑘 (𝑣 ′ ) ∪ consts(Σ) holds.</p><p>• Assume 𝐹 is obtained by applying a full GTGD 𝜏 ∈ Σ to 𝑇 𝑘 (𝑣 ′ ) using a substitution 𝜎. Then, 𝜏 contains a guard atom 𝐴 in the body such that 𝜎 (𝐴) ⊆ 𝑇 𝑘 (𝑣 ′ ); moreover, the head 𝜏 contains all variables of 𝐴, and so we have terms(𝐹 ) ⊆ terms 𝑇 𝑘 (𝑣 ′ ) ∪ consts(Σ).</p><p>Either Proof of Correctness. Let Σ ′ be the set Σ closed under the ExbDR inferences rule as specified in Definition 5.3. It is straightforward to see that Σ ′ is a logical consequence of Σ, so ExbDR(Σ) is also a logical consequence of Σ. Moreover, ExbDR(Σ) contains each full GTGD of Σ up to redundancy, so each full GTGD of Σ is logically entailed by ExbDR(Σ). We next consider an arbitrary base instance 𝐼 and a one-pass tree-like chase sequence for 𝐼 and Σ, and we show the following property:</p><p>(♦) for each loop 𝑇 𝑖 , . . . ,𝑇 𝑗 in the sequence at some vertex 𝑣 with output fact 𝐹 , there exist a full GTGD 𝛽 → 𝐻 ∈ Σ ′ and a substitution 𝜎 such that 𝜎 (𝛽) ⊆ 𝑇 𝑖 (𝑣) and 𝐹 = 𝜎 (𝐻 ). Since ExbDR(Σ) contains all full TGDs of Σ ′ and this property holds for the root vertex 𝑟 , Proposition 4.7 ensures that ExbDR(Σ) is a rewriting of Σ.</p><p>Our proof is by induction on the length of the loop. The base case and the inductive step have the same structure, so we consider them jointly. Thus, consider an arbitrary loop 𝑇 𝑖 ,𝑇 𝑖+1 , . . . ,𝑇 𝑗 -1 ,𝑇 𝑗 at vertex 𝑣 in the sequence, and assume that the claim holds for all shorter loops in the sequence. By the definition of the loop, chase tree 𝑇 𝑖+1 is obtained from 𝑇 𝑖 by applying a chase step to some non-full TGD ∀ì 𝑥 [𝛽 0 → ∃ì 𝑦 𝜂 0 ] ∈ Σ. Let 𝜎 0 and 𝜎 ′ 0 be the substitutions used in this chase step, let 𝑁 = nulls(rng(𝜎 ′ 0 )) \ nulls(rng(𝜎 0 )), let 𝑣 ′ be the child of 𝑣 introduced in 𝑇 𝑖+1 , and let 𝑆 ⊆ 𝑇 𝑖 (𝑣) be the facts that are copied to 𝑇 𝑖+1 (𝑣 ′ ) because they are Σ-guarded by 𝜎 ′ 0 (𝜂 0 ). Thus, we have 𝑇 𝑖+1 (𝑣 ′ ) = 𝑆 ∪ 𝜎 ′ 0 (𝜂 0 ). By Proposition A.8 and the fact that a chase step is applied only if propagation to the parent is not applicable, the output fact of the loop is added to 𝑇 𝑗 -1 (𝑣 ′ ) in step 𝑗 -1, and in 𝑇 𝑗 this fact is propagated back to 𝑇 𝑗 (𝑣). In other words, for each 𝑘 with 𝑖 &lt; 𝑘 &lt; 𝑗 -1, each fact in 𝑇 𝑘 (𝑣 ′ ) \ 𝑆 contains at least one labeled null from 𝑁 , or the fact would be Σ-guarded by 𝑇 𝑖 (𝑣) and thus propagated back to vertex 𝑣. We show that, in the loop 𝑇 𝑖 ,𝑇 𝑖+1 , . . . ,𝑇 𝑗 -1 ,𝑇 𝑗 fixed above, the following property holds for each 𝑘 with 𝑖 &lt; 𝑘 &lt; 𝑗 -1:</p><p>(♢) there exist a GTGD ∀ì 𝑥 [𝛽 → ∃ì 𝑦 𝜂] ∈ Σ ′ , a substitution 𝜎 such that 𝜎 (𝛽) ⊆ 𝑇 𝑖 (𝑣), and a substitution 𝜎 ′ that extends 𝜎 by mapping ì 𝑦 to fresh labeled nulls such that 𝑇 𝑘 (𝑣 ′ ) ⊆ 𝑆 ∪ 𝜎 ′ (𝜂). We prove (♢) by induction on 𝑘. We have already proved the base case 𝑘 = 𝑖 + 1 above. For the inductive step, assume that (♢) holds for some 𝑘, so there exists a GTGD ∀ì 𝑥 [𝛽 → ∃ì 𝑦 𝜂] ∈ Σ ′ and substitutions 𝜎 and 𝜎 ′ satisfying (♢) for 𝑘. Now consider 𝑇 𝑘+1 . Property (♢) holds by the inductive hypothesis if 𝑇 𝑘+1 (𝑣 ′ ) = 𝑇 𝑘 (𝑣 ′ )-that is, if the step involves a descendant of 𝑣 ′ . Otherwise, 𝑇 𝑘+1 (𝑣 ′ ) = 𝑇 𝑘 (𝑣 ′ ) ∪ {𝐺 } where fact 𝐺 is obtained in one of the following two ways.</p><p>• A full GTGD in Σ derives 𝐺 from 𝑇 𝑘 (𝑣 ′ ). Set Σ ′ contains this GTGD up to redundancy, so by Definition 5.1 there exist a full GTGD 𝛽 ′′ → 𝐻 ′ ∈ Σ ′ and a substitution 𝜌 such that 𝜌 (𝛽 ′′ ) ⊆ 𝑇 𝑘 (𝑣 ′ ) and 𝜌 (𝐻 ′ ) = 𝐺. • Fact 𝐺 is the output of a loop at vertex 𝑣 ′ . But then, this loop is shorter than 𝑇 𝑖 , . . . ,𝑇 𝑗 so, by property (♦), there exists a full GTGD 𝛽 ′′ → 𝐻 ′ ∈ Σ ′ and a substitution 𝜌 such that 𝜌 (𝛽 ′′ ) ⊆ 𝑇 𝑘 (𝑣 ′ ) and 𝜌 (𝐻 ′ ) = 𝐺. Since 𝜂 is in head-normal form, each atom in 𝜎 ′ (𝜂) contains at least one labeled null of 𝑁 . Now let 𝐴 ′ 1 , . . . , 𝐴 ′ 𝑛 be the atoms of 𝛽 ′′ that are matched to the atoms in 𝜎 ′ (𝜂). Atom 𝜌 (𝐻 ′ ) contains at least one labeled null of 𝑁 , so 𝑛 ≥ 1. Thus, we can assume that 𝛽 ′′ → 𝐻 ′ is of the form 𝐴 Moreover, some 𝐴 ′ 𝑖 is a guard so all variables of 𝐴 ′ 1 ∧ • • • ∧ 𝐴 ′ 𝑛 ∧ 𝛽 ′ → 𝐻 ′ participate in unification, and thus we can extend 𝜎 and 𝜎 ′ to substitutions 𝜁 and 𝜁 ′ , respectively, covering these variables such that 𝜁 (𝜃 (𝛽)) ∪ 𝜁 (𝜃 (𝛽 ′ )) ⊆ 𝑇 𝑖 (𝑣) and 𝑇 𝑘+1 (𝑣 ′ ) ⊆ 𝑆 ∪ 𝜁 ′ (𝜃 (𝜂)) ∪ 𝜁 ′ (𝜃 (𝐻 ′ )). Set Σ ′ contains 𝜏 up to redundancy. Since 𝐺 ∉ 𝑇 𝑘 (𝑣 ′ ), GTGD 𝜏 is not a syntactic tautology, so there exists a GTGD ∀ì 𝑥 1 [𝛽 1 → ∃ì 𝑦 1 𝜂 1 ] ∈ Σ ′ and substitution 𝜇 such that dom(𝜇) = ì 𝑥 1 ∪ ì 𝑦 1 , 𝜇 ( ì 𝑥 1 ) ⊆ ì 𝑥 2 , 𝜇 ( ì 𝑦 1 ) ⊆ ì 𝑦 1 ∪ ì 𝑦 2 and 𝜇 (𝑦) ≠ 𝜇 (𝑦 ′ ) for distinct 𝑦 and 𝑦 ′ in ì 𝑦 1 , and 𝜇 (𝛽 1 ) ⊆ 𝜃 (𝛽) ∧ 𝜃 (𝛽 ′ ) and 𝜇 (𝜂 1 ) ⊇ 𝜃 (𝜂) ∧ 𝜃 (𝐻 ′ ). Now let 𝜎 1 be the substitution defined as 𝜎 1 (𝑥) = 𝜁 (𝜇 (𝑥)) on each 𝑥 ∈ ì 𝑥, and let 𝜎 ′ 1 be the extension of 𝜎 1 to ì 𝑦 1 such that 𝜎 ′ 1 (𝑦) = 𝜁 ′ (𝜇 (𝑦)) for each 𝑦 ∈ ì 𝑦. Clearly, 𝜎 1 (𝛽 1 ) ⊆ 𝑇 𝑘 (𝑣 ′ ) and 𝑇 𝑘+1 (𝑣 ) ⊆ 𝑆 ∪ 𝜎 ′ 1 (𝜂 1 ) hold, so property (♢) is satisfied. To complete the proof, consider now the derivation of 𝑇 𝑗 -1 . By property (♢), there exists a GTGD ∀ì 𝑥 [𝛽 → ∃ì 𝑦 𝜂] ∈ Σ ′ and substitutions 𝜎 and 𝜎 ′ such that 𝜎 (𝛽) ⊆ 𝑇 𝑖 (𝑣) and 𝑇 𝑗 -2 (𝑣 ′ ) = 𝑆 ∪ 𝜎 ′ (𝜂). Then, as above, Σ ′ contains a full TGD of the form 𝐴 ′ 1 ∧ • • • ∧ 𝐴 ′ 𝑛 ∧ 𝛽 ′ → 𝐻 ′ that satisfies 𝜌 (𝐴 ′ 1 ) ∪ • • • ∪ 𝜌 (𝐴 ′ 𝑛 ) ⊆ 𝜎 ′ (𝜂) and 𝜌 (𝛽 ′ ) ⊆ 𝑆 for some substitution 𝜌. A minor difference is that 𝜌 (𝐻 ′ ) does not contain a labeled null introduced by 𝜎 ′ (𝜂 0 ), so 𝑛 = 0 is possible; however, in such a case, this TGD immediately satisfies property (♦). Moreover, if 𝑛 &gt; 0, then 𝛽 → ∃ì 𝑦 𝜂 can again be resolved with 𝐴 ′ 1 ∧ • • • ∧ 𝐴 ′ 𝑛 ∧ 𝛽 ′ → 𝐻 ′ to produce 𝜃 (𝛽) ∧ 𝜃 (𝛽 ′ ) → ∃ì 𝑦 𝜃 (𝜂) ∧ 𝜃 (𝐻 ′ ) ∈ Σ ′ satisfying vars(𝜃 (𝐻 ′ )) ∩ ì 𝑦 = ∅. This TGD is transformed into head-normal form by Definition 5.3, so ∀ì 𝑥 [𝜃 (𝛽) ∧ 𝜃 (𝛽 ′ ) → 𝜃 (𝐻 ′ )] is contained in Σ ′ up to redundancy. But then, Σ ′ contains a full GTGD that satisfies property (♦) by the same argument as above. □</p><p>Proof of Complexity. Fix Σ, 𝑟 , 𝑤 𝑏 , 𝑤 ℎ , 𝑐, and 𝑎 as stated in the theorem. The number of different body atoms of arity 𝑎 constructed using 𝑟 relations, 𝑤 𝑏 variables, and 𝑐 constants is clearly bounded by ℓ 𝑏 = 𝑟 • (𝑤 𝑏 + 𝑐) 𝑎 . Moreover, by the third claim of Proposition 5.7, the number of variables in the head of each TGD is bounded by 𝑤 ℎ , so the number of head atoms is bounded by ℓ ℎ = 𝑟 • (𝑤 ℎ + 𝑐) 𝑎 . The body (resp. head) of each GTGD corresponds to a subset of these atoms, so number of different GTGDs up to variable renaming is bounded by ℘ = 2 ℓ 𝑏 • 2 ℓ ℎ . Thus, the ExbDR inference rule needs to be applied to at most ℘ 2 = 2 2(ℓ 𝑏 +ℓ ℎ ) pairs of GTGDs. For each such pair, one might need to consider each possible way to match the ℓ 𝑏 body atoms of 𝜏 ′ to ℓ ℎ head atoms of 𝜏, and there are at most (ℓ ℎ ) ℓ 𝑏 ≤ 2 ℓ 𝑏 •ℓ ℎ of these. Consequently, unifier 𝜃 may need to be computed at most 2 2(ℓ 𝑏 +ℓ ℎ ) • 2 ℓ 𝑏 •ℓ ℎ ≤ 2 5•ℓ 𝑏 •ℓ ℎ = 32 ℓ 𝑏 •ℓ ℎ times. To check whether TGD 𝜏</p><formula xml:id="formula_52">1 = ∀ì 𝑥 1 [𝛽 1 → ì 𝑦 1 𝜂 1 ] is subsumed by 𝜏 2 = ∀ì 𝑥 2 [𝛽 2 → ì 𝑦 2 𝜂 2 ]</formula><p>, we can proceed as follows. First, we consider all possible ways to match an atom of 𝛽 1 to an atom of 𝛽 2 ; since both conjunctions contain at most ℓ 𝑏 atoms, there are at most ℓ 𝑏 ℓ 𝑏 ≤ 2 ℓ 𝑏 2 such matchings. Second, we analogously consider each of at most 2 (ℓ ℎ ) 2 ways to match an atom of 𝜂 2 to an atom of 𝜂 1 . Once all atoms have been matched, we try to find a substitution 𝜇 satisfying Definition 5.1 in linear time. Thus, a subsumption check for pairs of TGDs takes at most 2 ℓ 𝑏 2 • 2 ℓ ℎ 2 steps. Finally, unification of atoms requires time that is linear in 𝑎, and all other steps require linear time too. □ C PROOFS FOR SkDR C.1 Proof of Proposition 5.12: Properties of SkDR</p><p>We reuse results by de Nivelle <ref type="bibr" target="#b18">[19]</ref> about unification of atoms in guarded rules. The variable depth [19, Definition 3] of an atom is defined as -1 if the atom is ground, or as the maximum number of nested function symbols that contain a variable of the atom. Moreover, an atom is weakly covering <ref type="bibr" target="#b18">[19,</ref><ref type="bibr">Definition 6]</ref> if each nonground functional subterm of the atom contains all variables of the atom. Finally, de Nivelle [19, Theorem 1] says that, for 𝜃 an MGU of weakly covering atoms 𝐴 and 𝐵, atom 𝐶 = 𝜃 (𝐴) = 𝜃 (𝐵) is also weakly covering, the variable depth of 𝐶 is bounded by the variable depth of 𝐴 and 𝐵, and the number of variables of 𝐶 is bounded by the number of variables of 𝐴 and 𝐵 too.</p><p>Proposition 5.12. Each application of the SkDR inference rule to rules 𝜏 and 𝜏 ′ as in Definition 5.10 produces a guarded rule.</p><p>Proof. Consider arbitrary rules 𝜏 = 𝛽 → 𝐻 and 𝜏 ′ = 𝐴 ′ ∧ 𝛽 ′ → 𝐻 ′ and an MGU 𝜃 of 𝐻 and 𝐴 ′ satisfying the preconditions of the SkDR inference rule. Atom 𝐻 thus contains a Skolem symbol, and rule 𝜏 is guarded; consequently, atom 𝐻 is weakly covering, it contains a term of the form 𝑓 ( ì 𝑡) where ì 𝑡 consists of constants and all variables of the rule, and the variable depth of 𝐻 is at most one. The corresponding atom 𝐴 ′ can be of the following two forms.</p><p>• Atom 𝐴 ′ is Skolem-free. But then, 𝐴 ′ contains all variables of 𝜏 ′ , and it is clearly weakly covering. By de Nivelle <ref type="bibr">[19,</ref>   </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Definition 5 . 5 .</head><label>55</label><figDesc>The Existential-Based Datalog Rewriting inference rule ExbDR takes two guarded TGDs</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Theorem 5 . 8 .</head><label>58</label><figDesc>Program ExbDR(Σ) is a Datalog rewriting of a finite set of GTGDs Σ. Moreover, the rewriting can be computed in time 𝑂 (𝑏 𝑟 𝑑 • (𝑤 𝑏 +𝑐 ) 𝑑𝑎 •𝑟 𝑑 • (𝑤 ℎ +𝑐 ) 𝑑𝑎 ) for 𝑟 the number of relations in Σ, 𝑎 the maximum relation arity in Σ, 𝑤 𝑏 = bwidth(Σ), 𝑤 ℎ = hwidth(Σ), 𝑐 = |consts(Σ)|, and some 𝑏 and 𝑑.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Definition 5 . 9 .</head><label>59</label><figDesc>Rule ∀ì 𝑥 [𝛽 → 𝐻 ] is guarded if each function symbol in the rule is a Skolem symbol, the body 𝛽 contains a Skolem-free atom 𝐴 ∈ 𝛽 such that vars(𝐴) = ì 𝑥, and each Skolem term in the rule is of the form 𝑓 ( ì 𝑡) where vars 𝑓 ( ì 𝑡) = ì 𝑥 and ì 𝑡 is function-free. Definition 5.10. The Skolem Datalog Rewriting inference rule SkDR takes two guarded rules</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Proposition 5 .</head><label>5</label><figDesc>18 and Theorem 5.19 capture the properties of HypDR, and Proposition 5.20 compares it to SkDR. Proposition 5.18. Each application of the HypDR inference rule to rules 𝜏 1 , . . . , 𝜏 𝑛 and 𝜏 ′ as in Definition 5.16 produces a guarded rule. Theorem 5.19. Program HypDR(Σ) is a Datalog rewriting of a finite set of GTGDs Σ. Moreover, the rewriting can be computed in time time 𝑂 (𝑏 𝑟 𝑑 • (𝑒+𝑤 𝑏 +𝑐 ) 𝑑𝑎 ) for 𝑟 the number of relations in Σ, 𝑎 the maximum relation arity in Σ, 𝑒 the number of existential quantifiers in Σ, 𝑤 𝑏 = bwidth(Σ), 𝑐 = |consts(Σ)|, and some 𝑏 and 𝑑. Proposition 5.20. There exists a family {Σ 𝑛 } 𝑛∈N of finite sets of GTGDs such that SkDR derives 𝑂 (2 𝑛 ) more rules than HypDR on each Σ 𝑛 .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Algorithm 1</head><label>1</label><figDesc>Computing Inf(Σ) for Σ a finite set of GTGDs 1: W = ∅ 2: U = the head-normal form or the Skolemization of Σ 3: while U ≠ ∅ do 4:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Results for TGDs Derived from Ontologies</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Results for TGDs with Higher-Arity Relations</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>(</head><label></label><figDesc>S1) The chase tree 𝑉 𝑝 contains the union of the vertices of 𝑈 ′ 𝑠 and 𝑇 𝑝 . (S2) For each vertex 𝑤 occurring only in 𝑈 ′ 𝑠 (resp. 𝑇 𝑝 ), we define 𝑉 𝑝 (𝑤) = 𝑈 ′ 𝑠 (𝑤) (resp. 𝑉 𝑝 (𝑤) = 𝑇 𝑝 (𝑤)). (S3) For each vertex 𝑤 occurring in both 𝑈 ′ 𝑠 and 𝑇 𝑝 , we define 𝑉 𝑝 (𝑤) = 𝑈 ′ 𝑠 (𝑤) ∪ 𝑇 𝑝 (𝑤). (S4) If 𝑇 𝑝 is obtained by applying to a vertex 𝑤 of 𝑇 𝑝 -1 a chase step with a non-full GTGD 𝜏 = ∀ì 𝑥 [𝛽 → ∃ì 𝑦 𝜂] and substitutions 𝜎 and 𝜎 ′ , then, for 𝑤 ′ the child of 𝑤 introduced by the step, we extend 𝑉 𝑝 (𝑤 ′ ) with each fact 𝐺 ∈ 𝑉 𝑝 -1 (𝑤) that is Σ-guarded by 𝜎 ′ (𝜂). We now argue that 𝑇 ′ ℓ+1 , . . . , 𝑉 𝑗 contains an almost one-pass chase sequence for Σ and 𝐼 that satisfies the conditions of this lemma. • Sequence 𝑇 ′ 0 , . . . ,𝑇 ′ 𝑘 , 𝑈 ′ 0 , 𝑈 ′ 1 , . . . , 𝑈 ′ 𝑠 is clearly a valid almost one-pass chase sequence.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>′ 1 ∧</head><label>1</label><figDesc>• • • ∧ 𝐴 ′ 𝑛 ∧ 𝛽 ′ → 𝐻 ′ where {𝜌 (𝐴 ′ 1 ), . . . , 𝜌 (𝐴 ′ 𝑛 )} ⊆ 𝜎 ′ (𝜂) and 𝜌 (𝛽 ′ ) ⊆ 𝑆. Also, since 𝛽 ′′ → 𝐻 ′ is guarded, at least one of 𝐴 ′ 𝑖 is a guard for 𝛽 ′′ → 𝐻 ′ . Let 𝐴 1 , . . . , 𝐴 𝑛 be the atoms of 𝜂 such that 𝜎 ′ (𝐴 𝑖 ) = 𝜌 (𝐴 ′ 𝑖 ) for 1 ≤ 𝑖 ≤ 𝑛. Since 𝜎 ′ maps each 𝑦 ∈ ì 𝑦 to a distinct labeled null that does not occur in 𝑇 𝑖 , we have 𝜎 ′ ( ì 𝑥) ∩ 𝜎 ′ ( ì 𝑦) = ∅. Thus, there exists a ì 𝑦-MGU 𝜃 of 𝐴 1 , . . . , 𝐴 𝑛 and 𝐴 ′ 1 , . . . , 𝐴 ′ 𝑛 satisfying 𝜃 ( ì 𝑥) ∩ ì 𝑦 = ∅. Conjunction 𝜌 (𝛽 ′ ) does not contain a labeled null of 𝑁 , so vars(𝜃 (𝛽 ′ )) ∩ ì 𝑦 = ∅ holds. Thus, the preconditions of the ExbDR inference rule are satisfied for ∀ì 𝑥 [𝛽 → ∃ì 𝑦 𝜂] and 𝐴 ′ 1 ∧ • • • ∧ 𝐴 ′ 𝑛 ∧ 𝛽 ′ → 𝐻 ′ , so the ExbDR rule derives 𝜏 = 𝜃 (𝛽) ∧ 𝜃 (𝛽 ′ ) → ∃ì 𝑦 𝜃 (𝜂) ∧ 𝜃 (𝐻 ′ ).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Theorem 5 . 13 .</head><label>513</label><figDesc>Program SkDR(Σ) is a Datalog rewriting of a finite set of GTGDs Σ. Moreover, the rewriting can be computed in time 𝑂 (𝑏 𝑟 𝑑 • (𝑒+𝑤 𝑏 +𝑐 ) 𝑑𝑎 ) for 𝑟 the number of relations in Σ, 𝑎 the maximum relation arity in Σ, 𝑒 the number of existential quantifiers in Σ, 𝑤 𝑏 = bwidth(Σ), 𝑐 = |consts(Σ)|, and some 𝑏 and 𝑑.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>Skolemization allow us to replace existential quantifiers in TGDs by functional terms. Specifically, let 𝜏 = ∀ì 𝑥 [𝛽 → ∃ì 𝑦 𝜂], and let 𝜎 be a substitution defined on each 𝑦 ∈ ì 𝑦 as 𝜎 (𝑦) = 𝑓 𝜏,𝑦 ( ì 𝑥) where 𝑓 𝜏,𝑦 is a fresh | ì 𝑥 |-ary Skolem symbol uniquely associated with 𝜏 and 𝑦. Then, the Skolemization of 𝜏 produces rules ∀ì 𝑥 [𝛽 → 𝜎 (𝐻 )] for each atom 𝐻 ∈ 𝜂. Moreover, the Skolemization Σ ′ of a finite set of TGDs Σ is the union of the rules obtained by Skolemizing each 𝜏 ∈ Σ. It is well known that 𝐼, Σ |= 𝐹 if and only if 𝐼, Σ ′ |= 𝐹 for each base instance 𝐼 and each base fact 𝐹 . Unification. A unifier of atoms 𝐴 1 , . . . , 𝐴 𝑛 and 𝐵 1 , . . . , 𝐵 𝑛 is a substitution 𝜃 such that 𝜃 (𝐴 𝑖 ) = 𝜃 (𝐵 𝑖 ) for 1 ≤ 𝑖 ≤ 𝑛. Such 𝜃 is a most general unifier (MGU) if, for each unifier 𝜎 of 𝐴 1 , . . . , 𝐴 𝑛 and 𝐵 1 , . . . , 𝐵 𝑛 , there exists a substitution 𝜌 such that 𝜎 = 𝜌 • 𝜃 (where • is function composition). An MGU is unique up to variable renaming if it exists, and it can be computed in time 𝑂 ( 𝑛 𝑖=1 |𝐴 𝑖 | + |𝐵 𝑖 |) where |𝐴 𝑖 | and |𝐵 𝑖 | are the encoding sizes of 𝐴 𝑖 and 𝐵 𝑖</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>derive 𝐻 (𝑎): we must first produce 𝑣 1 to be able to derive 𝑣 2 , and we must combine 𝐺 (𝑎) from 𝑣 2 and 𝐵(𝑎, 𝑛 1 ) from 𝑣 1 .</figDesc><table><row><cell></cell><cell cols="2">𝐴(𝑎, 𝑏)</cell><cell></cell><cell></cell><cell></cell><cell>𝐴(𝑎, 𝑏)</cell></row><row><cell>𝑇 1 7</cell><cell cols="2">𝐸 (𝑎) 𝐺 (𝑎)</cell><cell></cell><cell cols="2">𝑇 2 7</cell><cell>𝐸 (𝑎) 𝐺 (𝑎)</cell></row><row><cell cols="2">𝐵(𝑎, 𝑛1)</cell><cell>𝐸 (𝑎)</cell><cell></cell><cell cols="2">𝐵(𝑎, 𝑛1)</cell><cell>𝐸 (𝑎)</cell><cell>𝐵(𝑎, 𝑛3)</cell></row><row><cell cols="2">𝐶 (𝑎, 𝑛1)</cell><cell cols="2">𝐹 (𝑎, 𝑛2)</cell><cell cols="2">𝐶 (𝑎, 𝑛1)</cell><cell>𝐹 (𝑎, 𝑛2)</cell><cell>𝐶 (𝑎, 𝑛3)</cell></row><row><cell cols="2">𝐷 (𝑎, 𝑛1)</cell><cell cols="2">𝐹 (𝑛2, 𝑛3)</cell><cell cols="2">𝐷 (𝑎, 𝑛1)</cell><cell>𝐹 (𝑛2, 𝑛3)</cell><cell>𝐸 (𝑎)</cell></row><row><cell cols="2">𝐸 (𝑎)</cell><cell>𝐺 (𝑎)</cell><cell></cell><cell>𝐸 (𝑎)</cell><cell></cell><cell>𝐺 (𝑎)</cell><cell>𝐺 (𝑎)</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>𝐴(𝑎, 𝑏)</cell></row><row><cell>𝑇 1 8</cell><cell cols="2">𝐴(𝑎, 𝑏) 𝐸 (𝑎) 𝐺 (𝑎)</cell><cell></cell><cell></cell><cell></cell><cell>𝑇9</cell><cell>𝐻 (𝑎) 𝐸 (𝑎) 𝐺 (𝑎)</cell></row><row><cell>𝐵(𝑎, 𝑛1) 𝐶 (𝑎, 𝑛1) 𝐷 (𝑎, 𝑛1) 𝐸 (𝑎)</cell><cell cols="2">𝐸 (𝑎) 𝐹 (𝑎, 𝑛2) 𝐹 (𝑛2, 𝑛3) 𝐺 (𝑎)</cell><cell cols="2">𝐵(𝑎, 𝑛3) 𝐶 (𝑎, 𝑛3) 𝐸 (𝑎) 𝐺 (𝑎) 𝐻 (𝑎)</cell><cell cols="2">𝐵(𝑎, 𝑛1) 𝐶 (𝑎, 𝑛1) 𝐷 (𝑎, 𝑛1) 𝐸 (𝑎)</cell><cell>𝐸 (𝑎) 𝐹 (𝑎, 𝑛2) 𝐹 (𝑛2, 𝑛3) 𝐺 (𝑎)</cell><cell>𝐵(𝑎, 𝑛3) 𝐶 (𝑎, 𝑛3) 𝐸 (𝑎) 𝐺 (𝑎) 𝐻 (𝑎)</cell></row><row><cell cols="7">Figure 2: One-Pass Chase Sequence Obtained from Figure 1</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>conjunction 𝛽 𝑖 is Skolem-free and atom 𝐻 𝑖 contains a Skolem symbol, and • rule 𝜏 ′ is Skolem-free, and, for 𝜃 an MGU of 𝐻 1 , . . . , 𝐻 𝑛 and 𝐴 ′</figDesc><table /><note><p>1 , . . . , 𝐴 ′ 𝑛 , if conjunction 𝜃 (𝛽 ′ ) is Skolem-free, it derives</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 1 :</head><label>1</label><figDesc>Input GTGDs at a Glance</figDesc><table><row><cell>Inputs</cell><cell></cell><cell># Full TGDs</cell><cell># Non-Full TGDs</cell></row><row><cell></cell><cell>Min</cell><cell cols="2">Max Avg Med Min</cell><cell>Max Avg Med</cell></row><row><cell>428</cell><cell cols="2">1 171,905 11,030 789</cell><cell>2 156,743 5,255 283</cell></row><row><cell cols="4">realistic inputs. Our objectives were to show that our algorithms</cell></row><row><cell cols="4">can indeed rewrite complex GTGDs, and that the rewriting can</cell></row><row><cell cols="4">be successfully processed by modern Datalog systems. In Subsec-</cell></row><row><cell cols="4">tion 7.1 we describe the test setting. Then, in Subsection 7.2 we</cell></row><row><cell cols="4">discuss the rewriting experiments with GTGDs obtained from on-</cell></row><row><cell cols="4">tologies, and in Subsection 7.3 we validate the usefulness of the</cell></row><row><cell cols="4">rewriting approach end-to-end. Finally, in Subsection 7.4 we discuss</cell></row><row><cell cols="4">rewriting GTGDs of higher arity. Due to the very large number of</cell></row><row><cell cols="4">inputs, we can only summarize our results in this paper; however,</cell></row><row><cell cols="4">our complete evaluation results are available online [13].</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head></head><label></label><figDesc>GHz and 16 GB of RAM, running Ubuntu 20.04.4 LTS and Java 11.0.15. In each test run, we loaded a set of TGDs, measured the wall-clock time required to compute</figDesc><table><row><cell></cell><cell></cell><cell cols="2">Time (s)</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="2">585</cell><cell cols="2">ExbDR</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="2">100</cell><cell>SkDR</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="2">HypDR</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="2">10</cell><cell cols="2">KAON2</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>1</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="2">0.1</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="5">Nr. of Processed Sets of TGDs</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>ExbDR</cell><cell cols="3">SkDR HypDR KAON2</cell></row><row><cell cols="4"># of Processed Inputs</cell><cell></cell><cell>367</cell><cell>377</cell><cell cols="2">382</cell><cell>362</cell></row><row><cell cols="4">Max. Processed Input Size</cell><cell></cell><cell cols="4">185,515 324,092 324,092</cell><cell>N/A</cell></row><row><cell cols="3">Max. Output Size</cell><cell></cell><cell></cell><cell cols="4">196,594 124,846 124,846</cell><cell>61,964</cell></row><row><cell cols="3">Max. Size Blowup</cell><cell></cell><cell></cell><cell>8.95</cell><cell>8.85</cell><cell cols="2">8.85</cell><cell>N/A</cell></row><row><cell cols="5">Max. Body Atoms in Output</cell><cell>7</cell><cell>6</cell><cell></cell><cell>6</cell><cell>4</cell></row><row><cell cols="3"># Blowup ≥ 1.5</cell><cell></cell><cell></cell><cell>26</cell><cell>14</cell><cell></cell><cell>16</cell><cell>N/A</cell></row><row><cell>Time (s)</cell><cell>Min. Max. Avg. Med.</cell><cell></cell><cell></cell><cell></cell><cell>0.05 582.18 23.23 0.82</cell><cell>0.05 584.79 14.34 0.52</cell><cell cols="2">0.04 404.34 6.38 0.55</cell><cell>0.21 547.53 18.66 0.49</cell></row><row><cell></cell><cell></cell><cell cols="4">time (𝑌 )/time (𝑋 ) ≥ 10</cell><cell cols="3">𝑋 and 𝑌 both fail</cell></row><row><cell>𝑋</cell><cell>𝑌</cell><cell cols="4">ExbDR SkDR HypDR KAON2</cell><cell cols="3">ExbDR SkDR HypDR KAON2</cell></row><row><cell cols="2">ExbDR</cell><cell></cell><cell>19</cell><cell>0</cell><cell>19</cell><cell>61</cell><cell></cell></row><row><cell cols="2">SkDR</cell><cell>37</cell><cell></cell><cell>0</cell><cell>26</cell><cell>33</cell><cell>51</cell></row><row><cell cols="2">HypDR</cell><cell>37</cell><cell>12</cell><cell></cell><cell>31</cell><cell>35</cell><cell>43</cell><cell>46</cell></row><row><cell cols="2">KAON2</cell><cell>35</cell><cell>15</cell><cell>0</cell><cell></cell><cell>37</cell><cell>47</cell><cell>46</cell><cell>66</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 2 :</head><label>2</label><figDesc>Computing the Fixpoint of the Rewriting</figDesc><table><row><cell cols="5">Ont. ID # Rules # Input Facts # Output Facts Time (s)</cell></row><row><cell>00387</cell><cell>63,422</cell><cell>4,403,105</cell><cell>51,439,424</cell><cell>53</cell></row><row><cell>00448</cell><cell>67,986</cell><cell>5,510,444</cell><cell>107,235,697</cell><cell>110</cell></row><row><cell>00470</cell><cell>75,146</cell><cell>10,532,943</cell><cell>141,396,446</cell><cell>242</cell></row><row><cell>00471</cell><cell>78,977</cell><cell>11,077,423</cell><cell>128,954,126</cell><cell>253</cell></row><row><cell>00472</cell><cell>75,146</cell><cell>10,533,008</cell><cell>141,396,576</cell><cell>279</cell></row><row><cell>00473</cell><cell>78,977</cell><cell>11,077,459</cell><cell>128,954,198</cell><cell>291</cell></row><row><cell>00573</cell><cell>113,959</cell><cell>9,197,254</cell><cell>155,118,592</cell><cell>206</cell></row><row><cell>00682</cell><cell>68,461</cell><cell>5,183,460</cell><cell>105,431,952</cell><cell>101</cell></row><row><cell>00684</cell><cell>81,553</cell><cell>6,057,017</cell><cell>66,981,628</cell><cell>109</cell></row><row><cell>00686</cell><cell>124,846</cell><cell>10,402,324</cell><cell>166,366,039</cell><cell>238</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head></head><label></label><figDesc>2 Proof of Proposition 4.7: Rewriting Criterion Using One-pass Chase Proofs Proposition 4.7. A Datalog program Σ ′ is a rewriting of a finite set of GTGDs Σ in head-normal form if • Σ ′ is a logical consequence of Σ,</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head></head><label></label><figDesc>ℓ 𝑗 -1 , . . . ,𝑇 ℓ 𝑗 . • Otherwise, 𝑇 𝑖 𝑗 -1 , . . . ,𝑇 𝑖 𝑗 is a loop at the root vertex 𝑟 with some output fact 𝐺 ∈ 𝑇 𝑖 𝑗 (𝑟 ). The third condition of the proposition ensures that there exists a Datalog rule 𝛽 → 𝐻 ∈ Σ ′ and a substitution 𝜎 such that 𝜎 (𝛽) ⊆ 𝑇 𝑖 (𝑟 ) and 𝜎 (𝐻 ) = 𝐺. We define ℓ 𝑗 = ℓ 𝑗 -1 + 1, and we define 𝑇 ℓ 𝑗 as the the chase tree containing just the root vertex 𝑟 such that 𝑇 ℓ 𝑗 (𝑟 ) = 𝑇 ℓ 𝑗 -1 (𝑟 ) ∪ {𝐺 }; thus, 𝑇 ℓ 𝑗 is obtained from 𝑇 ℓ 𝑗 -1 by applying the Datalog rule 𝛽 → 𝐻 ∈ Σ ′ to the root vertex 𝑟 . Moreover, 𝑇 𝑖 𝑗 (𝑟 ) ⊆ 𝑇 ℓ 𝑗 (𝑟 ) clearly holds, as required.</figDesc><table /><note><p>□ A.3 Proof of Proposition A.8: Properties of One-Pass Chase Proofs</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head></head><label></label><figDesc>way, we have terms 𝑇 𝑘+1 (𝑣 ′ ) ⊆ terms 𝑇 𝑘 (𝑣 ′ ) ∪ consts(Σ). By the induction assumption, set terms 𝑇 𝑘 (𝑣 ′ ) \ nulls(𝑇 𝑖+1 (𝑣 ′ )) is Σ-guarded by 𝑇 𝑖 (𝑣), and so set terms 𝑇 𝑘 1 (𝑣 ′ ) \ nulls(𝑇 𝑖+1 (𝑣 ′ )) is also Σ-guarded by 𝑇 𝑖 (𝑣), as required.□ B PROOFS FOR ExbDR B.1 Proof of Proposition 5.7: Properties of ExbDR Proposition 5.7. Each application of the ExbDR inference rule to 𝜏, 𝜏 ′ , and 𝜃 as in Definition 5.5 satisfies the following properties. 1. Some atom 𝐴 ′ 𝑖 with 1 ≤ 𝑖 ≤ 𝑛 is a guard in 𝜏 ′ . 2. For each 1 ≤ 𝑖 ≤ 𝑛 such that 𝐴 ′ 𝑖 is a guard of 𝜏 ′ , and for 𝜎 the ì 𝑦-MGU of 𝐴 ′ 𝑖 and the corresponding atom 𝐴 𝑖 such that 𝜎 ( ì 𝑥) ∩ ì 𝑦 = ∅, it is the case that vars 𝜎 (𝐴 ′ 𝑗 ) ∩ ì 𝑦 ≠ ∅ for each 1 ≤ 𝑗 ≤ 𝑛. 3. The result is a GTGD whose body and head width are at most bwidth(Σ) and hwidth(Σ), respectively. Proof of Claim 1. Let 𝐺 be a guard for 𝜏 ′ . For the sake of a contradiction, assume that 𝐺 is not one of the atoms 𝐴 ′ 𝐴 1 , atom 𝐴 ′ 1 contains at some position a variable 𝑧 such that 𝜃 (𝑧) = 𝑦. Since 𝐺 is a guard for 𝜏 ′ , variable 𝑧 occurs in 𝐺. Therefore, we have vars(𝜃 (𝐺)) ∩ ì 𝑦 ≠ ∅, which contradicts the requirement vars(𝜃 (𝛽 ′ )) ∩ ì 𝑦 = ∅ of the ExbDR inference rule. □ Proof of Claim 2. Consider arbitrary 𝑖 such that 1 ≤ 𝑖 ≤ 𝑛 and 𝐴 ′ 𝑖 is a guard of 𝜏 ′ , and let 𝜎 be an MGU of 𝐴 ′ 𝑖 and the corresponding atom 𝐴 𝑖 of 𝜏. Since 𝜃 is a unifier of 𝐴 ′ 𝑖 and 𝐴 𝑖 as well as of other pairs of atoms, there clearly exists a substitution 𝜌 such that 𝜃 = 𝜌 • 𝜎. Now consider an arbitrary 𝐴 ′ 𝑗 with 1 ≤ 𝑗 ≤ 𝑛 in 𝜏 ′ . Substitution 𝜃 matches 𝐴 ′ 𝑗 to the corresponding atom 𝐴 𝑗 in the head of 𝜏. Since TGD 𝜏 is in head-normal form, atom 𝐴 𝑗 contains at least one variable 𝑦 ∈ ì 𝑦. Since 𝜃 (𝑦) = 𝑦, we necessarily have 𝑦 ∈ vars(𝜃 (𝐴 ′ 𝑗 )). Consequently, atom 𝐴 ′ 𝑗 contains some variable 𝑧 such that 𝜃 (𝑧) = 𝑦. Since 𝐴 ′ 𝑖 is a guard for 𝜏 ′ , variable 𝑧 occurs in 𝐴 ′ 𝑖 . Now assume for the sake of a contradiction that 𝜎 (𝑧) ≠ 𝑦.Then 𝜎 (𝑧) = 𝜎 (𝑥) for some 𝑥 ∈ vars(𝐴 𝑖 ) and 𝑦 = 𝜃 (𝑧) = 𝜌 (𝜎 (𝑧)) = 𝜌 (𝜎 (𝑥)) 𝜃 (𝑥). However, this contradicts the requirement 𝜃 ( ì 𝑥) ∩ ì 𝑦 = ∅ of the ExbDR inference rule. □ Proof of Claim 3. By Claim 1, there exists 𝑖 with 1 ≤ 𝑖 ≤ 𝑛 such that atom 𝐴 ′ 𝑖 is a guard for 𝜏 ′ . Thus, vars(𝛽 ′ ) ∪ vars(𝐻 ′ ) ⊆ vars(𝐴 ′ 𝑖 ). The ExbDR inference rule ensures vars(𝜃 (𝛽 ′ )) ∩ ì 𝑦 = ∅, which in turn ensures vars(𝜃 (𝛽 ′ )) ⊆ vars(𝜃 (𝐴 ′ 𝑖 )) \ ì 𝑦. Now let 𝐺 be a guard for 𝜏. We clearly have vars(𝜃 (𝛽)) ⊆ vars(𝜃 (𝐺)). Moreover, 𝜃 (𝑦 𝑖 ) = 𝑦 𝑖 and 𝜃 (𝑥) ∩ ì 𝑦 = ∅ ensure vars(𝜃 (𝜂)) ∪ vars(𝜃 (𝐴 𝑖 )) ⊆ vars(𝜃 (𝐺)) ∪ ì 𝑦. Thus, 𝜃 (𝐺) is a guard for the TGD produced by the ExbDR inference rule. Finally, since 𝐺 contains all variables of 𝜏, the widths of the resulting TGD and 𝜏 are equal. □ B.2 Proof of Theorem 5.8: Correctness and Complexity of ExbDR Theorem 5.8. Program ExbDR(Σ) is a Datalog rewriting of a finite set of GTGDs Σ. Moreover, the rewriting can be computed in time 𝑂 (𝑏 𝑟 𝑑 • (𝑤 𝑏 +𝑐 ) 𝑑𝑎 •𝑟 𝑑 • (𝑤 ℎ +𝑐 ) 𝑑𝑎 ) for 𝑟 the number of relations in Σ, 𝑎 the maximum relation arity in Σ, 𝑤 𝑏 = bwidth(Σ), 𝑤</figDesc><table /><note><p>1 , . . . , 𝐴 ′ 𝑛 -that is, 𝐺 ∈ 𝛽 ′ . Since 𝑛 ≥ 1, atom 𝐴 ′ 1 in the body of 𝜏 ′ is matched to 𝐴 1 in the head of 𝜏. Since 𝜏 is in head-normal form, 𝐴 1 contains at least one variable 𝑦 ∈ ì 𝑦. Moreover, the conditions of the ExbDR inference rule ensure 𝜃 (𝑦) = 𝑦. Since 𝑦 does not occur in 𝐴 ′ 1 and 𝜃 unifies 𝐴 ′ 1 and ℎ = hwidth(Σ), 𝑐 = |consts(Σ)|, and some 𝑏 and 𝑑.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head></head><label></label><figDesc>Theorem 1], atom 𝜃 (𝐴 ′ ) is weakly covering and has variable depth at most one; consequently, each atom in rule 𝜃 (𝐴 ′ ) ∧ 𝜃 (𝛽 ′ ) → 𝜃 (𝐻 ′ ) is weakly covering and has variable depth at most one. Moreover, the variable depth of 𝜃 (𝐻 ) is also at most one, which can be only if 𝜃 maps each variable in 𝐻 to another variable or a constant. Thus, each atom in rule 𝜃 (𝛽) → 𝜃 (𝐻 ) is weakly covering and has variable depth at most one; moreover, 𝜃 (𝛽) contains an atom that contains all variables of the rule. But then, rule 𝜃 (𝛽) ∧ 𝜃 (𝛽 ′ ) → 𝜃 (𝐻 ′ ) is guarded, as required.• Atom 𝐴 ′ contains a Skolem symbol. But then, 𝐴 ′ is weakly covering by the definition of guarded rules, and its variable depth is at most one. By de Nivelle [19, Theorem 1], atom 𝜃 (𝐻 ) = 𝜃 (𝐴 ′ ) is weakly covering and has variable depth at most one, which can be the case only if 𝜃 maps all variables to other variables or constants. Consequently, rules 𝜃 (𝛽) → 𝜃 (𝐻 ) and 𝜃 (𝐴 ′ ) ∧ 𝜃 (𝛽 ′ ) → 𝜃 (𝐻 ′ ) are both guarded. But then, rule 𝜃 (𝛽) ∧ 𝜃 (𝛽 ′ ) → 𝜃 (𝐻 ′ ) is guarded, as required.</figDesc><table /><note><p>□ C.2 Proof of Theorem 5.13: Correctness and Complexity of SkDR</p></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>ACKNOWLEDGMENTS</head><p>This work was funded by the <rs type="funder">EPSRC</rs> <rs type="grantName">grants OASIS</rs> (<rs type="grantNumber">EP/S032347/1</rs>), <rs type="projectName">AnaLOG</rs> (<rs type="grantNumber">EP/P025943/1</rs>), <rs type="funder">Concur</rs> (<rs type="grantNumber">EP/V050869/1</rs>), and <rs type="projectName">QUINTON</rs> (<rs type="grantNumber">EP/T022124/1</rs>). For the purpose of Open Access, the author has applied a CC BY public copyright licence to any Author Accepted Manuscript (AAM) version arising from this submission.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funded-project" xml:id="_QJ8duq6">
					<idno type="grant-number">EP/S032347/1</idno>
					<orgName type="grant-name">grants OASIS</orgName>
					<orgName type="project" subtype="full">AnaLOG</orgName>
				</org>
				<org type="funding" xml:id="_wtb2T2a">
					<idno type="grant-number">EP/P025943/1</idno>
				</org>
				<org type="funded-project" xml:id="_WuMf5KZ">
					<idno type="grant-number">EP/V050869/1</idno>
					<orgName type="project" subtype="full">QUINTON</orgName>
				</org>
				<org type="funding" xml:id="_Rn8xYqp">
					<idno type="grant-number">EP/T022124/1</idno>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Proof of Correctness. Let Σ be an arbitrary finite set of GTGDs, and let Σ ′ be the set of rules obtained from Σ as specified in Definition 5.3. It is straightforward to see that Σ ′ is a logical consequence of the Skolemization of Σ, so SkDR(Σ) is also a logical consequence of Σ. Moreover, SkDR(Σ) contains each full TGD of Σ up to redundancy, so each full TGD of Σ is logically entailed by SkDR(Σ). We next consider an arbitrary base instance 𝐼 and a one-pass tree-like chase sequence for 𝐼 and Σ, and we show the following property:</p><p>(♦) for each loop 𝑇 𝑖 , . . . ,𝑇 𝑗 in the sequence at some vertex 𝑣 with output fact 𝐹 , there exist a Skolem-free rule 𝛽 → 𝐻 ∈ Σ ′ and a substitution 𝜎 such that 𝜎 (𝛽) ⊆ 𝑇 𝑖 (𝑣) and 𝐹 = 𝜎 (𝐻 ).</p><p>Since SkDR(Σ) contains all Skolem-free rules of Σ ′ and this property holds for the root vertex 𝑟 , Proposition 4.7 ensures that SkDR(Σ) is a rewriting of Σ.</p><p>Our proof is by induction in the length of the loop. The base case and the inductive step have the same structure, so we consider them jointly. Thus, consider an arbitrary loop 𝑇 𝑖 ,𝑇 𝑖+1 , . . . ,𝑇 𝑗 -1 ,𝑇 𝑗 at vertex 𝑣 in the sequence, and assume that the claim holds for all shorter loops in the sequence. By the definition of a loop, chase tree 𝑇 𝑖+1 is obtained from 𝑇 𝑖 by applying a chase step to some non-full GTGD 𝜏 ∈ Σ and substitution 𝛾. Let 𝑣 ′ be the child of 𝑣 introduced in 𝑇 𝑖+1 , let 𝑆 ⊆ 𝑇 𝑖 (𝑣) be the facts that are copied to 𝑇 𝑖+1 (𝑣 ′ ) because they are Σ-guarded by the instantiated head of 𝜏, let 𝑁 = {𝑛 1 , . . . , 𝑛 𝑚 } be the set of labeled nulls introduced in the chase step for the existentially quantified variables 𝑦 1 , . . . , 𝑦 𝑚 of 𝜏, let 𝜈 be a function that maps each labeled null 𝑛 𝑖 to the ground term 𝑓 𝑖 (𝛾 ( ì 𝑥)) where 𝑓 𝑖 is the symbol used in the Skolemization of 𝑦 𝑖 . For 𝑈 a set of facts, let 𝜈 (𝑈 ) be the result of replacing each occurrence of a labeled null 𝑛 ∈ dom(𝜈) in 𝑈 with 𝜈 (𝑛) and eliminating any duplicate facts in the result. Clearly, the inverse function 𝜈 -is well-defined, and we define 𝜈 -(𝑈 ) for 𝑈 a set of facts in the obvious way. By Proposition A.8 and the fact that propagation is applied eagerly, the output fact of the loop is added to 𝑇 𝑗 -1 (𝑣 ′ ) in step 𝑗 -1, and in 𝑇 𝑗 this fact is propagated back to 𝑇 𝑗 (𝑣). In other words, for each 𝑘 with 𝑖 &lt; 𝑘 &lt; 𝑗 -1, each fact in 𝑇 𝑘 (𝑣 ′ ) \ 𝑆 contains at least one labeled null from 𝑁 , or the fact would be Σ-guarded by 𝑇 𝑖 (𝑣) and would thus be propagated back to vertex 𝑣. We now show that the following property holds for each 𝑘 with 𝑖 &lt; 𝑘 ≤ 𝑗 -1:</p><p>(♢) for each fact 𝐺 ∈ 𝑇 𝑘 (𝑣 ′ ) \ 𝑆, there exist a rule 𝛽 → 𝐻 ∈ Σ ′ and a substitution 𝜎 such that 𝛽 is Skolem-free, 𝜎 (𝛽) ⊆ 𝜈 (𝑇 𝑖 (𝑣)), and 𝜎 (𝐻 ) = 𝜈 (𝐺).</p><p>Property (♢) implies (♦): fact 𝐹 does not contain a labeled null from 𝑁 , so the rule 𝛽 → 𝐻 ∈ Σ ′ whose existence is implied by (♢) for 𝑘 = 𝑗 -1 is actually a Skolem-free rule that satisfies (♦).</p><p>We next prove property (♢) by a nested induction on 𝑘. For the base case 𝑘 = 𝑖 + 1, property (♢) holds due to the fact that Σ ′ contains the rules obtained by Skolemizing GTGD 𝜏. For the inductive step, assume that (♢) holds for some 𝑘 and consider the possible ways to obtain 𝑇 𝑘+1 from 𝑇 𝑘 . Property (♢) holds by the inductive hypothesis if 𝑇 𝑘+1 (𝑣 ′ ) = 𝑇 𝑘 (𝑣 ′ )-that is, if the step involves a descendant of 𝑣 ′ . Otherwise, 𝑇 𝑘+1 (𝑣 ′ ) = 𝑇 𝑘 (𝑣 ′ ) ∪ {𝐺 } where fact 𝐺 is obtained in one of the following two ways.</p><p>• A full TGD in Σ derives 𝐺 from 𝑇 𝑘 (𝑣 ′ ). Set Σ ′ contains this TGD up to redundancy, so by Definition 5.1 there exist a Skolem-free rule 𝛽 ′′ → 𝐻 ′ ∈ Σ ′ and a substitution 𝜎 ′ such that 𝜎 ′ (𝛽 ′′ ) ⊆ 𝜈 (𝑇 𝑘 (𝑣 ′ )) and 𝜎 ′ (𝐻 ′ ) = 𝜈 (𝐺). • Fact 𝐺 is the output of a loop at vertex 𝑣 ′ . But then, this loop is shorter than 𝑇 𝑖 , . . . ,𝑇 𝑗 so, by property (♦), there exist a Skolem-free rule 𝛽 ′′ → 𝐻 ′ ∈ Σ ′ and a substitution 𝜎 ′ such that 𝜎 ′ (𝛽 ′′ ) ⊆ 𝜈 (𝑇 𝑘 (𝑣 ′ )) and 𝜎 ′ (𝐻 ′ ) = 𝜈 (𝐺). Now let 𝑊 = {𝐵 ′ ∈ 𝛽 ′′ | 𝜎 ′ (𝐵 ′ ) ∉ 𝑆 }. We next show that set Σ ′ contains up to redundancy the result of "resolving away" each atom 𝐵 ′ ∈ 𝑊 . A slight complication arises due to the fact that the SkDR inference rule considers only two rules at a time, and that the result of each inference is contained in Σ ′ up to redundancy. Thus, we will achieve our goal by showing that the SkDR inference rule can be applied up to 𝑛 = |𝑊 | times. Our proof is by induction on 1 ≤ ℓ ≤ 𝑛. Towards this goal, we shall define 𝑛 rules 𝛽 ′′ ℓ → 𝐻 ′ ℓ , substitutions 𝜎 ′ ℓ , and sets of atoms 𝑊 = 𝑊 0 ⊋ • • • ⊋ 𝑊 𝑛 for ℓ with 0 ≤ ℓ ≤ 𝑛 satisfying the following invariant:</p><p>). For ℓ = 𝑛, we have 𝑊 𝑛 = ∅, and so property ( * ) implies property (♢), as required. Our construction proceeds as follows.</p><p>For the base case ℓ = 0, property ( * ) clearly holds for 𝛽 ′′ 0 = 𝛽 ′′ , 𝜎 ′ 0 = 𝜎 ′ , and let 𝑊 0 = 𝑊 . For the induction step, assume that ( * ) holds for some 0 ≤ ℓ &lt; 𝑛, so 𝛽 ′′ ℓ → 𝐻 ′ ℓ , 𝜎 ′ ℓ , and 𝑊 ℓ satisfying ( * ) have been defined. First, assume that there exists</p><p>Otherwise, we consider the following possibilities.</p><p>where atom 𝐴 ′ ℓ contains a Skolem symbol, in which case this atom contains all variables of the rule.</p><p>Either way, there exists 𝐵 ′ ∈ 𝑊 ℓ such that 𝜎 ′ ℓ (𝐴 ′ ℓ ) = 𝜎 ′ (𝐵 ′ ) where 𝜎 ′ (𝐵 ′ ) ∈ 𝑇 𝑘 (𝑣 ′ ) \ 𝑆. Thus, by property (♢), these exist a rule 𝛽 ℓ → 𝐻 ℓ ∈ Σ ′ and a substitution 𝜎 ℓ such that 𝛽 ℓ is Skolem-free, 𝜎 ℓ (𝛽 ℓ ) ⊆ 𝜈 (𝑇 𝑖 (𝑣)), and 𝜎 ℓ (𝐻 ℓ ) = 𝜎 ′ (𝐵 ′ ); the last observation ensures that 𝐻 ℓ contains a Skolem symbol. Moreover, there exists an MGU 𝜃 ℓ of 𝐻 ℓ and 𝐴 ′ ℓ , so the SkDR inference rule is applicable to</p><p>is not a syntactic tautology. Thus, by Definition 5.1, there exist a rule</p><p>Then, property ( * ) clearly holds for 𝛽 ′′ ℓ+1 → 𝐻 ′ ℓ+1 , 𝜎 ′ ℓ+1 , and 𝑊 ℓ+1 , as required. □ Proof of Complexity. Fix Σ, 𝑟 , 𝑤 𝑏 , 𝑒, 𝑐, and 𝑎 as stated in the theorem. Skolemizing a GTGD ∀ì 𝑥 [𝛽 → ∃ì 𝑦 𝜂] produces guarded rules in which each atom is of the form 𝑅(𝑡 1 , . . . , 𝑡 𝑛 ) such that each 𝑡 𝑖 is a constant, a variable from ì 𝑥, or a term of the form 𝑓 ( ì 𝑥) where 𝑓 is a Skolem symbol. Moreover, each atom obtained from 𝑅(𝑡 1 , . . . , 𝑡 𝑛 ) by the SkDR inference rule is obtained by replacing a variable in ì 𝑥 with another variable or a constant. Thus, atom 𝑅(𝑡 1 , . . . , 𝑡 𝑛 ) cannot contain more than | ì 𝑥 | variables. Since the number of different symbols obtained by Skolemization is clearly bounded by 𝑒, the number of different atoms of such form is bounded by ℓ = 𝑟 • (𝑤 𝑏 + 𝑒 + 𝑐) 𝑎 . The body of each guarded rule corresponds to a subset of these atoms, so the number of different rules up to variable remaining is bounded by 2 ℓ • ℓ ≤ 2 ℓ • 2 ℓ = 2 2ℓ = ℘. By Definition 5.3, the result of applying the SkDR inference rule is retained in set Σ ′ only if the set does not contain a variable renaming of the result. Thus, the SkDR inference rule needs to be applied to at most ℘ 2 = 2 4ℓ pairs of rules. For each pair, one might need to unify at most ℓ body atoms of one rule with the head atom of the other rule, so the unifier 𝜃 may need to be computed at most ℘ 2 • ℓ ≤ ℘ 2 • 2 ℓ = 2 5ℓ = 32 ℓ times. We can check subsumption between a pair of rules analogously to Theorem 5.8: for each of at most 2 ℓ 2 ways to match the body atoms of one rule to the body atoms of another rule, we try to find a substitution 𝜇 satisfying Definition 5.   Proof of Correctness. The correctness proof for HypDR is almost identical to the correctness proof in Theorem 5.13, so we outline just the difference. In particular, we wish to prove properties (♦) and (♢) exactly as stated in Theorem 5.13 using the same proof structure. In the proof of property (♢), we establish existence of a Skolem-free rule 𝛽 ′′ → 𝐻 ′ ∈ Σ ′ and a substitution 𝜎 ′ such that 𝜎 ′ (𝛽 ′′ ) ⊆ 𝜈 (𝑇 𝑘 (𝑣 ′ )) and 𝜎 ′ (𝐻 ′ ) = 𝜈 (𝐺) in exactly the same way. The difference to the proof of Theorem 5.13 is that we "resolve away" all relevant body atoms of 𝛽 ′′ in one step. To this end, let 𝐴 ′ 1 , . . . , 𝐴 ′ 𝑛 be precisely the atoms of 𝛽 ′′ such that 𝜎 ′ (𝐴 ′ 𝑖 ) ∉ 𝑆 for each 1 ≤ 𝑖 ≤ 𝑛. Thus, we can assume that the rule is of the form</p><p>, and 𝜎 ′ (𝛽 ′ ) ⊆ 𝑆 clearly holds. By property (♢), for each 1 ≤ ℓ ≤ 𝑛, there exist a rule 𝛽 ℓ → 𝐻 ℓ ∈ Σ ′ and substitution 𝜎 ℓ such that 𝛽 ℓ is Skolem-free and 𝜎 ℓ (𝐻 ℓ ) = 𝜎 ′ (𝐴 ′ ℓ ); the last observation ensures that 𝐻 ℓ contains a Skolem symbol. Finally, there exists an MGU 𝜃 of 𝐻 1 , . . . , 𝐻 𝑛 and 𝐴 ′ 1 , . . . , 𝐴 ′ 𝑛 . Since 𝜎 ′ (𝛽 ′ ) ⊆ 𝑆, conjunction 𝜃 (𝛽 ′ ) is Skolem-free. Thus, the HypDR inference rule is applicable to</p><p>) is not a syntactic tautology so, by Definition 5.1, there exist a rule 𝛽 → 𝐻 ∈ Σ ′ and substitution 𝜇 such that 𝜇 (𝛽) ⊆ 𝜃 (𝛽 1 ) ∪ • • • ∪ 𝜃 (𝛽 𝑛 ) ∪ 𝜃 (𝛽 ′ ) and 𝜇 (𝐻 ) = 𝜃 (𝐻 ′ ). Let 𝜎 be the substitution defined on each variable 𝑥 in 𝛽 → 𝐻 such that 𝜎 (𝑥) = 𝜁 (𝜇 (𝑥)). Then, 𝜎 (𝛽) ⊆ 𝑆 and 𝜎 (𝐻 ) = 𝜎 ′ (𝐻 ′ ) = 𝜈 (𝐺), as required for property (♢). □ Proof of Complexity. Fix Σ, 𝑟 , 𝑤 𝑏 , 𝑒, 𝑐, and 𝑎 as stated in the theorem. In the same way as in the complexity proof of Theorem 5.13, the number of different atoms can be bounded by ℓ = 𝑟 • (𝑤 𝑏 + 𝑒 + 𝑐) 𝑎 , and the number of different rules can be bounded by ℘ = 2 2ℓ . Now we can apply the HypDR inference rule as follows: we choose one of the ℘ rules that plays the role of 𝜏 ′ and then, for each of the at most ℓ body atoms in 𝜏 ′ , we select one of the ℘ rules that play the role of rules 𝜏 𝑖 . Hence, there are at most ℘ • ℘ ℓ = ℘ ℓ+1 different applications of the HypDR inference rule. Thus, we may need to compute the unifier 𝜃 at most (2 2ℓ ) ℓ+1 = 2 2ℓ 2 +2ℓ ≤ 2 3ℓ 2 times. Finally, the times needed for subsumption checking, unification, and all other steps can be bounded analogously as in the complexity proof of Theorem 5. <ref type="bibr" target="#b12">13</ref>. □</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E THE FullDR ALGORITHM: CREATING DATALOG RULES DIRECTLY</head><p>The algorithms presented in the body of the paper all create the Datalog rules needed for the final rewriting as well as intermediate non-full TGDs or rules that are discarded after all inferences are performed. We now present an algorithm that produces only Datalog rules. Similar algorithms have appeared in the prior literature <ref type="bibr" target="#b3">[4]</ref>. After presenting such an algorithm, we explain the shortcomings of this approach.</p><p>Definition E.1. The Full Datalog Rewriting inference rule FullDR can be applied in two ways, depending on the types of TGDs it takes.</p><p>• The (COMPOSE) variant of the FullDR inference rule takes full TGDs</p><p>and a substitution 𝜃 such that </p><p>• The (PROPAGATE) variant of the FullDR inference rule takes TGDs</p><p>and Proof of Correctness. The proof follows the same structure as the correctness proof of Theorem 5.8: we show that property (♦) holds for each loop on a one-pass tree-like chase sequence for 𝐼 and Σ; a minor difference is that the TGD whose existence is implied by (♦) is not necessarily guarded, but has width bounded by hwidth(𝜎). To this end, we consider an arbitrary loop 𝑇 𝑖 ,𝑇 𝑖+1 , . . . ,𝑇 𝑗 -1 ,𝑇 𝑗 at vertex 𝑣 in the sequence, and assume that the claim holds for all shorter loops in the sequence. By the definition of the loop, chase tree 𝑇 𝑖+1 is obtained from 𝑇 𝑖 by applying a chase step to some non-full TGD ∀ì 𝑥 [𝛽 0 → ∃ì 𝑦 𝜂 0 ] ∈ Σ. Let 𝜎 0 and 𝜎 ′ 0 be the substitutions used in this chase step, and let 𝑣 ′ be the child of 𝑣 introduced in 𝑇 𝑖+1 . Note that 𝑇 𝑖+1 (𝑣 ′ ) contains at most hwidth(Σ) + |consts(Σ)| distinct terms. We show by another induction on 𝑘 that the following property holds for each 𝑘 with 𝑖 &lt; 𝑘 ≤ 𝑗 -1:</p><p>(♢) for each fact 𝐺 ∈ 𝑇 𝑘 (𝑣 ′ ) \ 𝑇 𝑖+1 (𝑣 ′ ), there exist a full TGD ∀ì 𝑥 [𝛽 → 𝐻 ] ∈ Σ ′ of width at most width(Σ) and a substitution 𝜎 such that 𝜎 (𝛽) ⊆ 𝑇 𝑖+1 (𝑣 ′ ) and 𝜎 (𝐻 ) = 𝐺. For the base case 𝑘 = 𝑖 + 1, property (♢) holds vacuously because 𝑇 𝑘 (𝑣 ′ ) \ 𝑇 𝑖+1 (𝑣 ′ ) = ∅. For the inductive step, assume that (♢) holds for some 𝑘 and consider the possible ways to obtain 𝑇 𝑘+1 from 𝑇 𝑘 . Property (♢) holds by the inductive hypothesis if 𝑇 𝑘+1 (𝑣 ′ ) = 𝑇 𝑘 (𝑣 ′ )-that is, if the step involves a descendant of 𝑣 ′ . Otherwise, 𝑇 𝑘+1 (𝑣 ′ ) = 𝑇 𝑘 (𝑣 ′ ) ∪ {𝐺 } where fact 𝐺 is obtained in one of the following two ways.</p><p>• A full TGD in Σ derives 𝐺 from 𝑇 𝑘 (𝑣 ′ ). Set Σ ′ contains this TGD up to redundancy, so by Definition 5.1 there exist a full TGD 𝛽 ′′ → 𝐻 ′ ∈ Σ ′ and a substitution 𝜎 such that 𝜎 (𝛽 ′′ ) ⊆ 𝑇 𝑘 (𝑣 ′ ) and 𝜎 (𝐻 ′ ) = 𝐺. • Fact 𝐺 is the output of a loop at vertex 𝑣 ′ . But then, this loop is shorter than 𝑇 𝑖 , . . . ,𝑇 𝑗 so, by property (♦), there exists a full TGD 𝛽 ′′ → 𝐻 ′ ∈ Σ ′ and a substitution 𝜎 such that 𝜎 (𝛽 ′′ ) ⊆ 𝑇 𝑘 (𝑣 ′ ) and 𝜎 (𝐻 ′ ) = 𝐺. Either way, the width of rule 𝛽 ′′ → 𝐻 ′ is bounded by width(Σ), and we can assume that</p><p>for each 1 ≤ ℓ ≤ 𝑛, and 𝜎 (𝛽 ′ ) ⊆ 𝑇 𝑖+1 (𝑣 ′ ). By property (♢), for each 1 ≤ ℓ ≤ 𝑛 there exist a full TGD 𝛽 ℓ → 𝐻 ℓ ∈ Σ ′ and a substitution 𝜎 ℓ such that 𝜎 ℓ (𝛽 ℓ ) ⊆ 𝑇 𝑖+1 (𝑣 ′ ) and 𝜎 ℓ (𝐻 ℓ ) = 𝛾 (𝐴 ′ ℓ ). Moreover, set rng(𝜎 ℓ ) clearly contains at most hwidth(Σ) + |consts(Σ)| distinct terms. But then, there exist substitutions 𝜃 1 , . . . , 𝜃 𝑛 that allow us to iteratively compose each 𝛽 ℓ → 𝐻 ℓ with</p><p>to obtain a full TGD subsumed by some 𝜏 ∈ Σ ′ and substitution 𝜎 1 such that 𝜏 and 𝜎 1 satisfy property (♢). To complete the proof, consider an arbitrary fact 𝐹 ∈ 𝑇 𝑗 -1 (𝑣 ′ ) \ 𝑇 𝑖+1 (𝑣 ′ ) that is propagated from 𝑣 ′ to 𝑣 in 𝑇 𝑗 , and let 𝛽 ′′ → 𝐻 ′ ∈ Σ ′ and 𝜎 be the TGD and substitution whose existence is guaranteed by property (♢). Now if 𝜎 (𝛽 ′′ ) ⊆ 𝑇 𝑖+1 (𝑣 ′ ) \ 𝜎 ′ 0 (𝜂 0 ), then TGD 𝛽 ′′ → 𝐻 ′ satisfies property (♦). Otherwise, we can assume that the rule is of the form</p><p>where 𝜎 (𝐴 ′ 𝑖 ) ∈ 𝜎 ′ 0 (𝜂 0 ) for each 1 ≤ 𝑖 ≤ 𝑛, and 𝜎 (𝛽 ′ ) ⊆ 𝑇 𝑖+1 (𝑣 ′ ) \ 𝜎 ′ 0 (𝜂 0 ). Moreover, rng(𝜎) clearly contains at most hwidth(Σ) + |consts(Σ)| distinct terms. But then, there exists a substitution 𝜃 that allows us to apply the (PROPAGATE) variant of the FullDR inference rule to 𝛽 0 → ∃ì 𝑦 𝜂 0 and 𝐴 ′ 1 ∧ • • • ∧ 𝐴 ′ 𝑛 ∧ 𝛽 ′ → 𝐻 ′ to obtain a full TGD subsumed by some TGD 𝜏 ∈ Σ ′ and substitution 𝜎 1 such that 𝜏 and 𝜎 1 satisfy property (♦). □ Proof of Complexity. The proof is analogous to the proof of complexity of Theorem 5.8. In particular, the (PROPAGATE) variant of the FullDR inference rule is analogous to the ExbDR inference rule, so we can bound in the same way the number of candidate rule pairs and possible ways to match body atoms of 𝜏 ′ to head atoms of 𝜏 by 32 ℓ 2</p><p>, where ℓ = 𝑟 • (𝑤 + 𝑐) 𝑎 . Once a candidate pair of 𝜏 and 𝜏 ′ has been selected, we need to consider all possible substitutions 𝜃 . Each such 𝜃 is defined on at most 2𝑤 variables ì 𝑥 ∪ ì 𝑧. Moreover, each variable is mapped to one of the 𝑤 + 𝑐 variables or to one of the 𝑐 constants in consts(Σ). Hence, there are at most (𝑤 + 2𝑐) 2𝑤 ≤ 4 (𝑤+2𝑐 ) •𝑤 ≤ 4 (𝑤+𝑐 ) 2 different substitutions 𝜃 . Consequently, the (PROPAGATE) variant of the FullDR inference rule can be applied at most 32 ℓ 2 • 4 (𝑤+𝑐 ) 2 &lt; 32 𝑛• (𝑤+𝑐 ) 2𝑎+1 times. Applications of the (COMPOSE) variant can be bounded analogously. Finally, the times needed for subsumption checking, unification, and all other steps can be bounded analogously as in the complexity proof of Theorem 5.8, with a minor difference that only body atoms need to be matched in the subsumption checks. □</p><p>The FullDR algorithm has several obvious weak points. First, it considers all possible ways to compose Datalog rules as long as this produces a rule with at most hwidth(Σ) + |consts(Σ)| variables. This may seem unnecessary, but the (COMPOSE) variant of the FullDR inference rule cannot be simply dropped while retaining completeness. To understand why, consider an arbitrary loop 𝑇 𝑖 , . . . ,𝑇 𝑗 at vertex 𝑣 with output fact 𝐹 in a one-pass chase proof: the (PROPAGATE) variant of the FullDR inference reflects only the chase step that derives the loop's output 𝐹 , so the (COMPOSE) variant is needed to reflects the chase steps that produce facts derived in the child of 𝑣 that are not propagated back to 𝑣. Second, it is not clear how one efficiently obtains the atoms 𝐴 1 , . </p><p>The (COMPOSE) variant of the FullDR inference rule should be applied to GTGDs ( <ref type="formula">47</ref>) and ( <ref type="formula">48</ref>), but it is not clear which unifier 𝜃 , identifying variables 𝑧 𝑖 in the latter with variables 𝑥 𝑖 in the former, one should use. The standard resolution inference rule from first-order theorem proving would consider only the MGU 𝜃 that maps 𝑧 3 to 𝑥 4 ; however, this would produce the resolvent 𝑆 (𝑥 1 , 𝑥 2 , 𝑥 3 , 𝑥 4 ) ∧ 𝑇 (𝑧 1 , 𝑧 2 , 𝑥 4 ) → 𝑃 (𝑧 1 ) containing more than hwidth(Σ) = 4 variables, so this rule is not derived by the (COMPOSE) variant. Eliminating the upper bound on the number of variables is not a solution: doing so would allow the derivation of full TGDs with an unbounded number of variables, which would prevent termination. Instead, the (COMPOSE) variant requires us to consider every possible substitution 𝜃 that maps variables 𝑥 1 , . . . , 𝑥 </p><p>need to be considered, which is clearly infeasible in practice. ⊳ Nevertheless, we implemented FullDR using the subsumption and indexing techniques described in Section 6. Unsurprisingly, we did not find FullDR competitive in our experiments. In fact, FullDR timed out on 173 ontologies, and there are only three ontologies where another algorithm reached the timeout but FullDR did not. For this reason, we do not discuss the results with FullDR in Section 7.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Rewriting Guarded Existential Rules into Small Datalog Programs</title>
		<author>
			<persName><forename type="first">Shqiponja</forename><surname>Ahmetaj</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Magdalena</forename><surname>Ortiz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mantas</forename><surname>Simkus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICDT. Schloss Dagstuhl-Leibniz-Zentrum fuer Informatik</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">1-4</biblScope>
			<biblScope unit="page">24</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Diversified Stress Testing of RDF Data Management Systems</title>
		<author>
			<persName><forename type="first">Günes</forename><surname>Aluç</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Olaf</forename><surname>Hartig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Tamer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Khuzaima</forename><surname>Özsu</surname></persName>
		</author>
		<author>
			<persName><surname>Daudjee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ISWC. Springer</title>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="197" to="212" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Magic-Sets for Datalog with Existential Quantifiers</title>
		<author>
			<persName><forename type="first">Mario</forename><surname>Alviano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicola</forename><surname>Leone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marco</forename><surname>Manna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Giorgio</forename><surname>Terracina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pierfrancesco</forename><surname>Veltri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Datalog</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">0</biblScope>
			<biblScope unit="page" from="31" to="43" />
			<date type="published" when="2012">2012</date>
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">When Can We Answer Queries Using Result-Bounded Data Interfaces? Log</title>
		<author>
			<persName><forename type="first">Antoine</forename><surname>Amarilli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Benedikt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Methods Comput. Sci</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1" to="14" />
			<date type="published" when="2022">2022. 2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Modal languages and bounded fragments of predicate logic</title>
		<author>
			<persName><forename type="first">Hajnal</forename><surname>Andréka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Johan</forename><surname>Van Benthem</surname></persName>
		</author>
		<author>
			<persName><forename type="first">István</forename><surname>Németi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Philosophical Logic</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="217" to="274" />
			<date type="published" when="1998">1998. 1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">The Description Logic Handbook: Theory, Implementation and Applications</title>
		<editor>F. Baader, D. Calvanese, D. McGuinness, D. Nardi, and P. F. Patel-Schneider</editor>
		<imprint>
			<date type="published" when="2007">2007</date>
			<publisher>Cambridge University Press</publisher>
			<pubPlace>Cambridge, UK</pubPlace>
		</imprint>
	</monogr>
	<note>2nd ed.</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Normal Form Transformations</title>
		<author>
			<persName><forename type="first">M</forename><surname>Baaz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Egly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Leitsch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Handbook of Automated Reasoning</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Robinson</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Voronkov</surname></persName>
		</editor>
		<meeting><address><addrLine>Amsterdam, The Netherlands</addrLine></address></meeting>
		<imprint>
			<publisher>Elsevier Science</publisher>
			<date type="published" when="2001">2001</date>
			<biblScope unit="volume">I</biblScope>
			<biblScope unit="page" from="273" to="333" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Resolution Theorem Proving</title>
		<author>
			<persName><forename type="first">Leo</forename><surname>Bachmair</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Harald</forename><surname>Ganzinger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Handbook of automated reasoning</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="19" to="99" />
			<date type="published" when="2001">2001. 2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Graal: A Toolkit for Query Answering with Existential Rules</title>
		<author>
			<persName><forename type="first">J.-F</forename><surname>Baget</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Leclère</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M.-L</forename><surname>Mugnier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Rocher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Sipieter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">RuleML</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="328" to="344" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Walking the complexity lines for generalized guarded existential rules</title>
		<author>
			<persName><forename type="first">Jean-François</forename><surname>Baget</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marie-Laure</forename><surname>Mugnier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Rudolph</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michaël</forename><surname>Thomazo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI. AAAI Press</title>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="712" to="717" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Rewriting Guarded Negation Queries</title>
		<author>
			<persName><forename type="first">Vince</forename><surname>Bárány</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Benedikt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Balder</forename><surname>Ten</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cate</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">MFCS. Springer</title>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="98" to="110" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">The Vadalog System: Datalog-based Reasoning for Knowledge Graphs</title>
		<author>
			<persName><forename type="first">Luigi</forename><surname>Bellomarini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Emanuel</forename><surname>Sallinger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Georg</forename><surname>Gottlob</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. VLDB Endow</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="975" to="987" />
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Guarded Saturation</title>
		<author>
			<persName><forename type="first">Michael</forename><surname>Benedikt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maxime</forename><surname>Buron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefano</forename><surname>Germano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Kappelmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Boris</forename><surname>Motik</surname></persName>
		</author>
		<ptr target="https://krr-oxford.github.io/Guarded-saturation/" />
		<imprint>
			<date type="published" when="2021-07-04">2021. July 4, 2022</date>
			<publisher>GitHub</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Benchmarking the Chase</title>
		<author>
			<persName><forename type="first">Michael</forename><surname>Benedikt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">George</forename><surname>Konstantinidis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Giansalvatore</forename><surname>Mecca</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Boris</forename><surname>Motik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paolo</forename><surname>Papotti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Donatello</forename><surname>Santoro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Efthymia</forename><surname>Tsamoura</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">PODS. ACM</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="37" to="52" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Taming the Infinite Chase: Query Answering under Expressive Relational Constraints</title>
		<author>
			<persName><forename type="first">Andrea</forename><surname>Calì</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Georg</forename><surname>Gottlob</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Kifer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Artificial Intelligence Research</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="page" from="115" to="174" />
			<date type="published" when="2013">2013. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Query rewriting and answering under constraints in data integration systems</title>
		<author>
			<persName><forename type="first">Andrea</forename><surname>Calì</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Domenico</forename><surname>Lembo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Riccardo</forename><surname>Rosati</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI. Morgan Kaufmann</title>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="16" to="21" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Ontop: Answering SPARQL queries over relational databases</title>
		<author>
			<persName><forename type="first">Diego</forename><surname>Calvanese</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Cogrel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sarah</forename><surname>Komla-Ebri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roman</forename><surname>Kontchakov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Davide</forename><surname>Lanti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Martin</forename><surname>Rezk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mariano</forename><surname>Rodriguez-Muro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guohui</forename><surname>Xiao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Semantic Web</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="471" to="487" />
			<date type="published" when="2017">2017. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Tractable Reasoning and Efficient Query Answering in Description Logics: The DL-Lite Family</title>
		<author>
			<persName><forename type="first">Diego</forename><surname>Calvanese</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Giuseppe</forename><forename type="middle">De</forename><surname>Giacomo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Domenico</forename><surname>Lembo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maurizio</forename><surname>Lenzerini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Riccardo</forename><surname>Rosati</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Autom. Reason</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="385" to="429" />
			<date type="published" when="2007">2007. 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">A Resolution Decision Procedure for the Guarded Fragment</title>
		<author>
			<persName><forename type="first">Hans</forename><surname>De</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nivelle</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CADE. Springer</title>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="191" to="204" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Query reformulation with constraints</title>
		<author>
			<persName><forename type="first">A</forename><surname>Deutsch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Popa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Tannen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIGMOD Record</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="65" to="73" />
			<date type="published" when="2006">2006. 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Data exchange: semantics and query answering</title>
		<author>
			<persName><forename type="first">R</forename><surname>Fagin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">G</forename><surname>Kolaitis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Popa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Theoretical Computer Science</title>
		<imprint>
			<biblScope unit="volume">336</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="89" to="124" />
			<date type="published" when="2005">2005. 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">An Ontology-Based Reasoning Approach for Electric Power Utilities</title>
		<author>
			<persName><forename type="first">Mohamed</forename><surname>Gaha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arnaud</forename><surname>Zinflou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christian</forename><surname>Langheit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexandre</forename><surname>Bouffard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mathieu</forename><surname>Viau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luc</forename><surname>Vouligny</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">RR. Springer</title>
		<imprint>
			<biblScope unit="page" from="95" to="108" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">A Superposition Decision Procedure for the Guarded Fragment with Equality</title>
		<author>
			<persName><forename type="first">H</forename><surname>Ganzinger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>De Nivelle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 14th IEEE Symposium on Logic in Computer Science (LICS &apos;99)</title>
		<meeting>of the 14th IEEE Symposium on Logic in Computer Science (LICS &apos;99)</meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="295" to="305" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Expressiveness of Guarded Existential Rule Languages</title>
		<author>
			<persName><forename type="first">Georg</forename><surname>Gottlob</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Rudolph</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mantas</forename><surname>Simkus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">PODS. ACM</title>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="27" to="38" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Data Integration: The Teenage Years</title>
		<author>
			<persName><forename type="first">Alon</forename><surname>Halevy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anand</forename><surname>Rajaraman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joann</forename><surname>Ordille</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">VLDB. ACM</title>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="9" to="16" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Answering queries using views: A survey</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Alon</surname></persName>
		</author>
		<author>
			<persName><surname>Halevy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">VLDB Journal</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="270" to="294" />
			<date type="published" when="2001">2001. 2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Guarded Logics: Algorithms and Bisimulation</title>
		<author>
			<persName><forename type="first">Colin</forename><surname>Hirsch</surname></persName>
		</author>
		<ptr target="http://www.umbrialogic.com/hirsch-thesis.pdf" />
		<imprint>
			<date type="published" when="2002-07-04">2002. July 4, 2022</date>
			<pubPlace>Aachen, Germany</pubPlace>
		</imprint>
		<respStmt>
			<orgName>RWTH Aachen</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D. Dissertation</note>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Reducing S H I Q -Description Logic to Disjunctive Datalog Programs</title>
		<author>
			<persName><forename type="first">Ullrich</forename><surname>Hustadt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Boris</forename><surname>Motik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ulrike</forename><surname>Sattler</surname></persName>
		</author>
		<editor>KR.</editor>
		<imprint>
			<date type="published" when="2004">2004</date>
			<publisher>AAAI Press</publisher>
			<biblScope unit="page" from="152" to="162" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Reasoning in description logics by a reduction to disjunctive datalog</title>
		<author>
			<persName><forename type="first">Ullrich</forename><surname>Hustadt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Boris</forename><surname>Motik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ulrike</forename><surname>Sattler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Automated Reasoning</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="351" to="384" />
			<date type="published" when="2007">2007. 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Testing Containment of Conjunctive Queries under Functional and Inclusion Dependencies</title>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">S</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anthony</forename><forename type="middle">C</forename><surname>Klug</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JCSS</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="167" to="189" />
			<date type="published" when="1984">1984. 1984</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Decision Procedures for Guarded Logics</title>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Kappelmann</surname></persName>
		</author>
		<idno>CoRR abs/1911.03679</idno>
		<ptr target="http://arxiv.org/abs/1911.03679" />
		<imprint>
			<date type="published" when="2019-07-04">2019. 2019. July 4, 2022</date>
			<biblScope unit="page">92</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">NP-Completeness of the Set Unification and Matching Problems</title>
		<author>
			<persName><forename type="first">Deepak</forename><surname>Kapur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paliath</forename><surname>Narendran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CADE. Springer</title>
		<imprint>
			<date type="published" when="1986">1986</date>
			<biblScope unit="page" from="489" to="495" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Logic-Based Techniques in Data Integration</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Alon</surname></persName>
		</author>
		<author>
			<persName><surname>Levy</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000">2000</date>
			<publisher>Kluwer Academic Publishers</publisher>
			<biblScope unit="page" from="575" to="595" />
			<pubPlace>Norwell, MA, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">A General Datalog-Based Framework for Tractable Query Answering over Ontologies</title>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Lukasiewicz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrea</forename><surname>Calì</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Georg</forename><surname>Gottlob</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Web Semantics</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">0</biblScope>
			<biblScope unit="page" from="57" to="83" />
			<date type="published" when="2012">2012. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Resolution and Datalog Rewriting Under Value Invention and Equality Constraints</title>
		<author>
			<persName><forename type="first">Bruno</forename><surname>Marnette</surname></persName>
		</author>
		<idno>CoRR abs/1212.0254</idno>
		<imprint>
			<date type="published" when="2012">2012. 2012</date>
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Otter-The CADE-13 Competition Incarnations</title>
		<author>
			<persName><forename type="first">William</forename><surname>Mccune</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Larry</forename><surname>Wos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Automated Reasoning</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="211" to="220" />
			<date type="published" when="1997">1997. 1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">The backchase revisited</title>
		<author>
			<persName><forename type="first">M</forename><surname>Meier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">VLDB J</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="495" to="516" />
			<date type="published" when="2014">2014. 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Reasoning in description logics using resolution and deductive databases</title>
		<author>
			<persName><forename type="first">Boris</forename><surname>Motik</surname></persName>
		</author>
		<ptr target="http://digbib.ubka.uni-karlsruhe.de/volltexte/1000003797" />
		<imprint>
			<date type="published" when="2006-07-04">2006. July 4, 2022</date>
			<pubPlace>Karlsruhe, Germany</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Karlsruhe Institute of Technology</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D. Dissertation</note>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">The KAON2 System</title>
		<author>
			<persName><forename type="first">Boris</forename><surname>Motik</surname></persName>
		</author>
		<ptr target="http://kaon2.semanticweb.org/" />
		<imprint>
			<date type="published" when="2022-07-04">2022. July 4, 2022</date>
		</imprint>
		<respStmt>
			<orgName>Karslruhe Institute of Technology</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Oxford Ontology Library</title>
		<ptr target="http://krr-nas.cs.ox.ac.uk/ontologies/" />
		<imprint>
			<date type="published" when="2021-07-04">2021. July 4, 2022</date>
			<publisher>Oxford KR group</publisher>
		</imprint>
		<respStmt>
			<orgName>Oxford University</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Linear Unification</title>
		<author>
			<persName><forename type="first">Mike</forename><surname>Paterson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><forename type="middle">N</forename><surname>Wegman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Comput. Syst. Sci</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="158" to="167" />
			<date type="published" when="1978">1978. 1978</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">A machine-oriented logic based on the resolution principle</title>
		<author>
			<persName><forename type="first">John</forename><surname>Alan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robinson</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JACM</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="23" to="41" />
			<date type="published" when="1965">1965. 1965</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Index Data Structure for Fast Subset and Superset Queries</title>
		<author>
			<persName><forename type="first">Iztok</forename><surname>Savnik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CD-ARES</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="134" to="148" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Simple and Efficient Clause Subsumption with Feature Vector Indexing</title>
		<author>
			<persName><forename type="first">Stephan</forename><surname>Schulz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Automated Reasoning and Mathematics</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="45" to="67" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">The Path-Indexing Method for Indexing Terms</title>
		<author>
			<persName><forename type="first">Mark</forename><forename type="middle">E</forename><surname>Stickel</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1989">1989</date>
		</imprint>
		<respStmt>
			<orgName>SRI</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">The RDFox System. Oxford Semantic Technologies</title>
		<ptr target="https://www.oxfordsemantic.tech/" />
		<imprint>
			<date type="published" when="2022-07-04">2022. July 4, 2022</date>
			<publisher>Oxford Semantic Technologies</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Why Is Modal Logic so Robustly Decidable?</title>
		<author>
			<persName><forename type="first">Moshe</forename><forename type="middle">Y</forename><surname>Vardi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">DIMACS Series in Discrete Mathematics and Theoretical Computer Science</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="149" to="184" />
			<date type="published" when="1997">1997</date>
			<publisher>American Mathematical Society</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">NYAYA: A System Supporting the Uniform Management of Large Sets of Semantic Data</title>
		<author>
			<persName><forename type="first">Roberto</forename><surname>De</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Virgilio</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Giorgio</forename><surname>Orsi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Letizia</forename><surname>Tanca</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Riccardo</forename><surname>Torlone</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICDE. IEEE Computer Society</title>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="1309" to="1312" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Query Answering for Existential Rules via Efficient Datalog Rewriting</title>
		<author>
			<persName><forename type="first">Zhe</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peng</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kewen</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhiqiang</forename><surname>Zhuang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hai</forename><surname>Wan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI. ijcai.org</title>
		<imprint>
			<date type="published" when="1933">2021. 1933-1939</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Deciding the Loosely Guarded Fragment and Querying Its Horn Fragment Using Resolution</title>
		<author>
			<persName><forename type="first">Sen</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Renate</forename><forename type="middle">A</forename><surname>Schmidt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="3080" to="3087" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
