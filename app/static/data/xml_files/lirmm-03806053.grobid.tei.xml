<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Variable Size Segmentation for Efficient Representation and Querying of Non-Uniform Time Series Datasets</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Lamia</forename><surname>Djebour</surname></persName>
							<email>lamia.djebour@inria.fr</email>
							<affiliation key="aff0">
								<orgName type="laboratory">INRIA &amp; LIRMM</orgName>
								<orgName type="institution">Univ Montpellier</orgName>
								<address>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Reza</forename><surname>Akbarinia</surname></persName>
							<email>reza.akbarinia@inria.fr</email>
							<affiliation key="aff1">
								<orgName type="laboratory">INRIA &amp; LIRMM</orgName>
								<orgName type="institution">Univ Montpellier</orgName>
								<address>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Florent</forename><surname>Masseglia</surname></persName>
							<email>florent.masseglia@inria.fr</email>
							<affiliation key="aff2">
								<orgName type="laboratory">INRIA &amp; LIRMM</orgName>
								<orgName type="institution">Univ Montpellier</orgName>
								<address>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Variable Size Segmentation for Efficient Representation and Querying of Non-Uniform Time Series Datasets</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">CEEF022EEE7ABC68CFDD83B0768468E5</idno>
					<idno type="DOI">10.1145/3477314.3507000</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-04-12T14:52+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Information systems → Data mining</term>
					<term>Spatial-temporal systems</term>
					<term>Nearest-neighbor search Time Series, Representations, Information Retrieval Masseglia. 2022. Variable Size Segmentation</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Existing approaches for time series similarity computing are the core of many data analytics tasks. Given the considered data volumes, or simply the need for fast response times, they often rely on shorter representations, usually with information loss. This incurs approximate comparisons where precision is a major issue. We present and experimentally evaluate ASAX, a new approach for segmenting time series before their transformation into symbolic representations. ASAX reduces significantly the information loss incurred by possible splittings at different steps of the representation calculation, particularly for datasets with unbalanced (nonuniform) distributions. We provide theoretical guarantees on the lower bound of similarity measures, and our experiments illustrate that our method outperforms the state of the art, with significant gain in precision for datasets with unbalanced distributions.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Many applications in different domains generate time series data at an increasing rate. That continuous flow of emitted data may concern personal activities (e.g., through smart-meters or smartplugs for electricity or water consumption) or professional activities (e.g., for monitoring heart activity or through the sensors installed on plants by farmers). This results in the production of large and complex data, usually in the form of time series <ref type="bibr">[8, 9, 13, 15-19, 21, 22]</ref> that challenge knowledge discovery. Data mining techniques on such massive sets of time series have drawn a lot of interest since their application may lead to improvements in a large number of these activities, relying on fast and accurate similarity search in time series for performing tasks like , e.g., Classification, Clustering, and Motifs Discovery <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b22">23]</ref>.</p><p>Because of the considered data volumes in such applications, these tasks can be slow on raw data. This is why approximation SAC'22, April 25 -April 29, 2022, Brno, Czech Republic . over time series is often regarded as a means to allow fast computation of similarity search. SAX <ref type="bibr" target="#b10">[11]</ref> is one of the most popular representations of time series, allowing dimensionality reduction on the classic data mining tasks. SAX is efficient because it constructs symbolic representations by splitting the time domain into segments of equal size. This approximation model is effective for time series having a uniform and balanced distribution over the time domain. However, we observe that, in the case of time series having high variation over some time intervals, this "one size fits all" division into segments of fixed length is not advantageous.</p><p>To illustrate the impact of a fixed length division of the series into segments, let us consider Figure <ref type="figure" target="#fig_0">1</ref>. It shows a set D of time series, taken from ECGFiveDays dataset of UCR Archive <ref type="bibr" target="#b4">[5]</ref>, where the time series length is 132. In this dataset, the distribution of values over time domain is not uniform. We can notice that there is almost no variation from time point 1 to 44 and from 95 to 132. On the other hand, the remaining part, from time point 44 to 95, shows an important variation in the data values. Figure <ref type="figure" target="#fig_1">1a</ref> shows the SAX division on D, with a fixed-size segmentation on the time series. In this example the segment size is 22, leading to 6 segments in total. If we take any time series X from D and we convert it into its SAX representation, the first two segments are always represented by the same symbol, all the values of these two segments being close to each other. Actually, there is no need to consider these two distinct segments. And the same applies to the last two segments. Meanwhile, for segments 3 and 4, all the values of each segment are represented by a single symbol while the data values present great variations, causing a significant loss of information on these segments.</p><p>As one can observe, it is not necessary to split the parts that are constant or where the variation is low since they don't carry any relevant information and would therefore better form a single segment. It is more efficient to divide into several small segments the parts where variation is important in order to preserve potentially relevant information as shown in Figure <ref type="figure" target="#fig_1">1b</ref>. The splitting of Figure <ref type="figure" target="#fig_1">1b</ref> is the actual splitting obtained by our approach with a segment budget limited to 6. The first two and last two segments better correspond to the information carried by the series. It would be rather counter-intuitive to merge segments 1 and 2, while it is the opposite for Figure <ref type="figure" target="#fig_1">1a</ref>. The time intervals where data values show important differences are split like, e.g., between times point 66 and 88. By proposing such a customized splitting, we aim at improving the performance of information retrieval algorithms that will rely on our data representation. In order to improve the quality of similarity search, and to achieve adaptive splitting as illustrated above, we propose a new approximation method for time series that considers the time series shape and does the splitting by means of segments of variable size on the time domain. By measuring the entropy of symbolic representations, our algorithm chooses between different possible splittings at each step of the representation computation. This approach allows reducing information loss, and thus increasing the accuracy of time series representations leading to better precision during retrieval phases, particularly from non-uniform datasets. In this paper, we make the following contributions:</p><p>• We propose a new representation technique, called ASAX (Adaptive SAX), that allows obtaining a variable-size segmentation of time series with better precision in retrieval tasks thanks to its lower information loss. Our representation is based on entropy measurement for detecting what time intervals should be split. • We propose a lower bounding method that allows approximating the distance between the original time series based on their representations in ASAX. • We implemented our approach and conducted empirical experiments using more than 10 real world datasets. The results suggest that ASAX can obtain significant performance gains in terms of precision for similarity search compared to SAX. They illustrate that the more the data distribution in the time domain is unbalanced, the greater is the precision gain of ASAX. For example, for the EGCFiveDays dataset that has a non-uniform distribution in the time domain, the precision of ASAX is 82% compared to 55% for SAX.</p><p>The rest of the paper is organized as follows, we review the related works in Section 2. In Section 3, we describe the details of ASAX representation. In Section 4, we present the experimental evaluation of our approach. We discuss the related work in Section 5, and finally conclude in Section 6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">PROBLEM DEFINITION AND BACKGROUND</head><p>In this section, we first present the background about SAX representation, and then define the problem we address. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">SAX Representation</head><p>Given two time series 𝑋 = {𝑥 1 , ..., 𝑥 𝑛 } and 𝑌 = {𝑦 1 , ..., 𝑦 𝑛 }, the Euclidean distance between 𝑋 and 𝑌 is defined as <ref type="bibr" target="#b5">[6]</ref>:</p><formula xml:id="formula_0">𝐸𝐷 (𝑋, 𝑌 ) = 𝑛 𝑖=1 (𝑥 𝑖 -𝑦 𝑖 ) 2</formula><p>The Euclidean distance is one of the most straightforward similarity measurement methods used in time series analysis.</p><p>The SAX representation is based on the Piecewise Aggregate Approximation (PAA) representation <ref type="bibr" target="#b10">[11]</ref> which allows for dimensionality reduction while providing the important lower bounding property as we will show later. The idea of PAA is to have a fixed segment size, and minimize dimensionality by using the mean values on each segment. Example 1 gives an illustration of PAA. By transforming the original time series 𝑋 and 𝑌 into PAA representations, 𝑋 = {𝑥 1 , ..., 𝑥 𝑤 } and 𝑌 = {𝑦 1 , ..., 𝑦 𝑤 }, the lower bounding approximation of the Euclidean distance for these two representations can be obtained by : 𝐷𝑅 𝑓 (𝑋, 𝑌 ) = 𝑛 𝑤 𝑤 𝑖=1 (𝑥 𝑖 -𝑦 𝑖 ) 2  The SAX representation takes as input the reduced time series obtained using PAA. It discretizes this representation into a predefined set of symbols, with a given cardinality, where a symbol is a binary number. The size of the symbols set is called the cardinality. Example 2 gives an illustration of the SAX representation.  where the function 𝑑𝑖𝑠𝑡 ( x𝑖 , ŷ𝑖 ) is the distance between two SAX symbols x𝑖 and x𝑖 . The lower bounding condition is formulated as: 𝑀𝐼 𝑁 𝐷𝐼𝑆𝑇 𝑓 ( X, Ŷ ) ≤ 𝐸𝐷 (𝑋, 𝑌 )</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Similarity Queries</head><p>The problem of similarity queries is one of the main problems in time series analysis and mining. In information retrieval, finding the 𝑘 nearest neighbors (k-NN) of a query is a fundamental problem. Let us define exact and approximate 𝑘 nearest neighbors. Definition 1. (Exact 𝑘 nearest neighbors) Given a query time series 𝑄 and a set of time series 𝐷, let 𝑅 = 𝐸𝑥𝑎𝑐𝑡𝑘𝑁 𝑁 (𝑄, 𝐷) be the set of 𝑘 nearest neighbors of 𝑄 from 𝐷. Let 𝐸𝐷 (𝑋, 𝑌 ) be the Euclidean distance between two time series 𝑋 and 𝑌 , then the set 𝑅 is defined as follows:</p><formula xml:id="formula_1">(𝑅 ⊆ 𝐷) ∧ (|𝑅| = 𝑘) ∧ (∀𝑎 ∈ 𝑅, ∀𝑏 ∈ (𝐷 -𝑅), 𝐸𝐷 (𝑎, 𝑄) ≤ 𝐸𝐷 (𝑏, 𝑄))</formula><p>Definition 2. (Approximate 𝑘 nearest neighbors) Given a set of time series 𝐷, a query time series 𝑄, and 𝜖 &gt; 0. We say that 𝑅 = 𝐴𝑝𝑝𝑘𝑁 𝑁 (𝑄, 𝐷) is the approximate 𝑘 nearest neighbors of 𝑄 from 𝐷, if 𝐸𝐷 (𝑎, 𝑄) ≤ (1 + 𝜖)𝐸𝐷 (𝑏, 𝑄), where 𝑎 is the 𝑘 𝑡ℎ nearest neighbor from 𝑅 and 𝑏 is the true 𝑘 𝑡ℎ nearest neighbor.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Time Series Approximation</head><p>The SAX representation proceeds to an approximation by minimizing the dimensionality: the original time series are divided into segments of equal size.</p><p>This representation does not depend on the time series values, but on their length. It allows SAX to perform the segmentation in 𝑂 (𝑛) where 𝑛 is the time series of length. However, for a given reduction in dimensionality, the modeling error may not be minimal since the model does not adapt to the information carried by the series. Our claim is that, by taking into account the information carried by time series for choosing the segments, we may obtain significant increase in the precision of kNN queries. This issue motivated us for proposing an adaptive representation aiming at minimizing the information loss.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Problem Statement</head><p>Our goal is to propose a variable-size segmentation of the time domain that minimizes the loss of information in the time series representation.</p><p>The problem we address is stated as follows. Given a database of time series 𝐷 and a number 𝑤, divide the time domain into 𝑤 segments of variable size such that the representation of the times series based on that segmentation lowers the error of kNN queries.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">ADAPTIVE SAX (ASAX)</head><p>In this section, we propose ASAX, a variable-size segmentation technique for the time series representation. To create a segmentation with minimum information loss, ASAX divides the time domain based on the representation entropy.</p><p>In the rest of this section, we first describe the notion of entropy for the time series representation. Then, we describe our algorithm for creating the variable-size segments. Finally, we present our method for measuring the lower bound distance between time series in the proposed representation. This lower bounding is useful for efficient evaluation of kNN queries.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Entropy</head><p>Entropy is a mathematical function which intuitively corresponds to the amount of information contained or delivered by a source of information. This source of information can be of various types. The more the source emits different information the higher is the entropy. If the source always sends the same information, the entropy is minimal. Formally, entropy is defined as follows.</p><p>Definition 3. Given a set 𝑋 of elements, and each element 𝑥 ∈ 𝑋 having a probability 𝑃 𝑥 of occurrence, the entropy 𝐻 of the set 𝑋 is defined as: 𝐻 (𝑋 ) = -𝑥 ∈𝑋 𝑃 𝑥 × log 𝑃 𝑥 In our context, we calculate the entropy on a set containing the different symbolic representations obtained from the transformation of the original time series of a dataset according to a given segmentation. The entropy computed on this set allows to measure the quantity of information contained in the time series representations. Let us illustrate this using an example. Example 3. Consider the database D={x,y,z} in Figure <ref type="figure" target="#fig_4">3</ref> where x, y and z are time series with l=8. Let us create a representation having two segments (e.g., 0-4, and 4-8), and then compute the entropy of the representation of the set D. To generate the representation of the time series x, y and z, they are discretized by obtaining their PAA representation and then using predetermined break-points to map the PAA coefficients into the corresponding symbols like the SAX representation proceeds. We have converted the 3 time series into symbolic representations with size 2, and cardinality 4. Thus, the symbolic representations of x, y and z are x = [00, 10], ŷ = [00, 10] and ẑ = [00, 10], respectively. We notice that the 3 time series have the same symbolic representation, thus, the set X consists of only this unique symbolic representation with an occurrence equal to 3., i.e., 𝑋 = {[00, 10]}. The entropy H(X) of X is computed as follows:</p><formula xml:id="formula_2">𝐻 (𝑋 ) = -(𝑃 (𝑥 = [00, 10]) × log 2 𝑃 (𝑥 = [00, 10]))</formula><p>where the probability for the word x is 𝑃 (𝑥 = [00, 10]) = 3 3 = 1. Therefore, we have 𝐻 (𝑋 ) = -(1 log 1) = 0 meaning that in the representation 𝑋 there is no information allowing to distinguish the three original time series from each other. This is explained by the fact that they have the same representation with a fixed-size segmentation. In the next subsection, we describe our algorithm to create variable-size segments based on entropy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Variable-Size Segmentation Based on Entropy Measurement</head><p>Given a database of time series 𝐷, and a number 𝑤, our goal is to find the 𝑘 variable size segments that minimize the loss of information in time series representations. Intuitively, our algorithm works as follows. First it splits the time domain into two segments of equal size. Then, it performs 𝑤 -2 iterations, and in each iteration it finds the segment 𝑠 whose split makes the minimum loss in entropy, and it splits that segment. By doing this, in each iteration a new segment is added to the set of segments. This continues until having 𝑤 segments.</p><p>Let us now describe ASAX in more details. The pseudo-code is shown in Algorithm 1. It first splits the time domain into two equal parts and creates two segments that are included to the set 𝑠𝑒𝑔𝑚𝑒𝑛𝑡𝑠 (Line 1). Then, it sets the current number of segments, denoted as 𝑘, to 2 (Line 2).</p><p>Afterwards, in a loop, until the number of segments is less than 𝑤 the algorithm proceeds as follows. For each segment 𝑖 (from 1 to 𝑘), 𝑖 is divided into two equal parts, if its size is greater than 𝑚𝑖𝑛𝑆𝑖𝑧𝑒, which is the minimum possible size of a segment, and it's default value is 1. Then, a temporary set of segments 𝑡𝑒𝑚𝑝𝑆𝑒𝑔𝑚𝑒𝑛𝑡𝑠 is created including the two new segments and all previously created segments except 𝑖 (i.e., expect the one that has been divided). Then, for each time series 𝑡𝑠 in the database 𝐷, the algorithm generates the symbolic representation of 𝑡𝑠 (denoted as 𝑤𝑜𝑟𝑑) using the segments included in 𝑡𝑒𝑚𝑝𝑆𝑒𝑔𝑚𝑒𝑛𝑡𝑠 with the given cardinality 𝑎 (Line 12), and inserts it to a hash table (Line 13). Note that for all time series, ASAX uses the same cardinality to map the PAA coefficients into the corresponding symbols. After having inserted all the representations of the time series contained in 𝐷 to the hash table, the entropy of the representations is calculated (Line 14). If the entropy is higher than the maximum entropy obtained until now, the algorithm sets 𝑖 as the segment to be split, and keeps the entropy of the representation. This procedure continues by splitting one of the segments at each time, and computing the entropy. The algorithm selects the one whose entropy is the highest, and updates the set of the segments by removing the selected segment, and inserting its splits to the set 𝑠𝑒𝑔𝑚𝑒𝑛𝑡𝑠 (Lines 18-20). Then, the variable 𝑘, which shows the number of current segments, is incremented by one. The algorithm ends if the number of segments is equal to the required number, i.e., 𝑤.</p><p>Example 4. Let us consider the dataset D in Figure <ref type="figure" target="#fig_4">3</ref> which represents the initialization of the algorithm, i.e., the time domain is divided into two segments of the same size. The next step is to create the 3rd segment by splitting one of the two existing segments. Two different scenarios are possible. Scenario 1 : The first scenario is shown in Figure <ref type="figure" target="#fig_7">4a</ref> where the left segment is divided into two equal parts. We generate the symbolic representation of the time series 𝑥, 𝑦, and 𝑧 by using the 3 segments. Let's assume the cardinality is 4. Then, x = [00, 00, 10], ŷ = [00, 00, 10] and ẑ = [00, 00, 10] are the symbolic representation of x, y and z, respectively. Thus, the set 𝑋 1 consists of only one representation [00,00,10] with an occurrence of 3, i.e., 𝑋 After having calculated the entropy for the two scenarios, we see that 𝐻 (𝑋 1 ) &lt; 𝐻 (𝑋 2 ). We aim to maximize the entropy, therefore we choose the segmentation generated in Scenario 2 for this iteration of our algorithm. We continue the next iterations, until the number of segment reaches w.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Lower Bounding of the Similarity Measure</head><p>SAX <ref type="bibr" target="#b11">[12]</ref> defines a distance measure on the representation of time series as described in Section 2.1. Given the representation of two time series, the 𝑀𝐼 𝑁 𝐷𝐼𝑆𝑇 𝑓 function allows obtaining a lower bounding approximation of the Euclidean distance between the original time series. By the following theorem, we propose a lower bounding approximation formula for the case of variable size segmentation in ASAX. Theorem 1. Let 𝑋 and 𝑌 be two time series. Suppose that by using ASAX we create a variable size segmentation with 𝑤 segments, such that the size of the 𝑖 𝑡ℎ segment is 𝑙 𝑖 . Let 𝑋 and 𝑌 be the PAA representation of variable size of 𝑋 and 𝑌 in ASAX, 𝐷𝑅 𝑣 (𝑋, 𝑌 ) gives a lower bounding approximation of the Euclidean distance between 𝑋 and 𝑌 :</p><formula xml:id="formula_3">𝐷𝑅 𝑣 (𝑋, 𝑌 ) = 𝑤 𝑖=1 ((𝑥 𝑖 -𝑦 𝑖 ) 2 × 𝑙 𝑖 )</formula><p>Let X and Ŷ be the representations of 𝑋 and 𝑌 in ASAX obtained by converting 𝑋 and 𝑌 into symbolic representation. Then, 𝑀𝐼 𝑁 𝐷𝐼𝑆𝑇 𝑣 ( X, Ŷ ) gives a lower bounding approximation of the Euclidean distance between 𝑋 and 𝑌 : 𝑀𝐼 𝑁 𝐷𝐼𝑆𝑇 𝑣 ( X, Ŷ )</p><formula xml:id="formula_4">= 𝑤 𝑖=1 (𝑑𝑖𝑠𝑡 ( x𝑖 , ŷ𝑖 ) 2 × 𝑙 𝑖 )</formula><p>Proof. The proof has been removed due to lack of space.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Uniform Distribution of Symbols</head><p>SAX breakpoints divide the value domain into regions of different size where small regions are concentrated on the middle of the value domain and regions at extreme values are larger. This is illustrated by Figure <ref type="figure" target="#fig_8">5</ref>, with three time series from our motivating example in Figure <ref type="figure" target="#fig_0">1</ref>. The breakpoints of SAX with 10 symbols are represented by horizontal lines, and, logically, they appear close to the center of the distribution. If we keep such distribution of symbols, then we would have two issues. First, the extreme values of the series like those above 2 or below -4 would be assigned the same symbol (their PAA value on the segment would fall in the same symbol). Second, the adaptive segmentation would consider that the slight variations around zero are more important than the ones at extreme values, ending in irrelevant splits that favor minor information gain. For this reason, we propose to calculate the breakpoints differently. In ASAX, the discretization is done based on breakpoints that produce uniform distributions of symbols. These breakpoints divide the value domain into regions of equal size. In the case of Figure <ref type="figure" target="#fig_8">5</ref> the 10 symbol regions will be evenly distributed in the range of data values. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">EXPERIMENTS</head><p>In this section, we report the results of experimental studies on the proposed ASAX segmentation approach that illustrate its performance in improving the accuracy of time series representations in to get better precision during information search operations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Datasets and Experimental Settings</head><p>We compared the ASAX representation with the existing SAX representation on datasets selected for their particular (lack of) uniformity. Notice that SAX and its extensions in the literature use a fixed-size segmentation of the time domain. But, ASAX proposes a variable-size segmentation based on information theory techniques. The approaches are implemented in Python programming language and Numba JIT compiler is used to optimize machine code at runtime 1 . The experimental evaluation was conducted on a machine using Fedora 31 operating system with 16 Gigabytes of main memory, an Intel Core i7 1,90 GHz-4,80 GHz processor with 4 cores. 1 Our code is available for download here: https://github.com/lamiad/ASAX We carried out our experiments on several real world datasets from the UCR Time Series Classification Archive <ref type="bibr" target="#b4">[5]</ref>. Table <ref type="table" target="#tab_1">2</ref> gives basic information about the datasets: name, type, length of the time series (number of values). Notice that almost all selected datasets have non-uniform distributions over time domain (see Figure <ref type="figure">6</ref>), else SyntheticControl that has a quasi uniform distribution.</p><p>For each approach, we set the default cardinality value to 32 and the length w of the approximate representations is reduced to 10% of the original time series length. In the experiments, we measure the ASAX and SAX precision in similarity search by applying a k-Nearest Neighbor (k-NN) search, as detailed in Subsection 4.2. For ASAX, we measure the time cost of the variable-size segmentation in Subsection 4.3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Precision of k-Nearest Neighbor Search</head><p>In this part of experiments, we compare the quality of ASAX and SAX representation on the different datasets described in Table <ref type="table" target="#tab_1">2</ref> by measuring the precision of the approximate k-NN search for both of the two approaches. The precision reported for each dataset represents the average precision for a set of arbitrary random queries taken from this dataset. The search precision for each query Q from a dataset D is calculated as follows :</p><formula xml:id="formula_5">𝑝 = |𝐴𝑝𝑝𝑘𝑁 𝑁 (𝑄, 𝐷) ∩ 𝐸𝑥𝑎𝑐𝑡𝑘𝑁 𝑁 (𝑄, 𝐷)| 𝑘</formula><p>where AppkNN(Q,D) and ExactkNN(Q,D) are the sets of approximate k nearest neighbors and exact k nearest neighbors of Q from D, respectively. AppkNN(Q,D) is obtained using 𝐷𝑅 𝑓 distance measure for SAX and 𝐷𝑅 𝑣 for the ASAX representation and the set Exac-tkNN(Q,D) contains the k-NN of Q using the euclidean distance ED. AppkNN(Q,D) and ExactkNN(Q,D) use a linear search that consists in computing the distance from the query point Q to every other point in D, keeping track of the "best so far" result. The precision results are reported in Figure <ref type="figure">6</ref> where each dataset is plotted with the precision obtained (as percentage) for both approaches and the datasets are sorted in descending order of precision gain. The plots show the shape of the different time series of each dataset and we can notice that the distribution of time series over the time domain varies from one dataset to another. Let us take for example the ECGFiveDays dataset presented in Figure <ref type="figure">6a</ref> and SyntheticControl shown in Figure <ref type="figure">6i</ref>. On the first one, we were able to achieve a precision of 82% for ASAX while it is 55% for SAX, which is a significant gain in precision. This higher precision for ASAX is due to the variable-size segmentation which created segments in the parts that undergo a significant variation (from time point 44 to 95) as discussed in our motivating example, except that, here, we have 13 segments (allowing ASAX to perform a better distribution of the segments according to information gain). For SyntheticControl we can see that the precision of the approximate k-NN search is the same for both ASAX and SAX approaches which is 32%. In this dataset, the shape of the time series is balanced over the time, and the segmentations obtained by ASAX and SAX are the same, resulting in equivalent precision. These results suggest the advantage of our approach over the state-of-the-art when applied to time series with unbalanced distribution. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Time cost of ASAX segmentation algorithm</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">RELATED WORK</head><p>Several techniques have been yet proposed to reduce the dimensionality of time series. Examples of such techniques that can significantly decrease the time and space required for similarity search are: singular value decomposition (SVD) <ref type="bibr" target="#b6">[7]</ref>, the discrete Fourier transformation (DFT) <ref type="bibr" target="#b0">[1]</ref>, discrete wavelets transformation (DWT) <ref type="bibr" target="#b2">[3]</ref>, piecewise aggregate approximation (PAA) <ref type="bibr" target="#b9">[10]</ref>, random sketches <ref type="bibr" target="#b3">[4]</ref>, and symbolic aggregate approXimation (SAX) <ref type="bibr" target="#b11">[12]</ref>.</p><p>SAX <ref type="bibr" target="#b11">[12]</ref> is one of the most popular techniques for time series representation. It uses a symbolic representation that segments all time series into equi-length segments and symbolizes the mean value of each segment. The symbolic representation allows to lower bound the corresponding distance measures defined on the original time series. Several extensions of SAX have been yet proposed, mainly for improving the similarity search performance via indexing. For example, iSAX <ref type="bibr" target="#b19">[20]</ref> is an indexable version of SAX designed for indexing large collections of time series. iSAX 2.0 <ref type="bibr" target="#b1">[2]</ref> proposes a new mechanism and also algorithms for efficient bulk loading and node splitting policy, wich is not supported by iSAX index. In <ref type="bibr" target="#b1">[2]</ref>, two extensions of iSAX 2.0, namely iSAX 2.0 Clustered and iSAX2+, have been proposed. These extensions focus on the efficient handling of the raw time series data during the bulk loading process, by using a technique that uses main memory buffers to group and route similar time series together down the tree, performing the insertion in a lazy manner.</p><p>However, the segmentation in SAX and its extensions is not adaptive to the data since their division principle of the time domain is based on fixed-size segments which is not always effective for unbalanced data distributions. To increase the quality of the approximation for this type of time series we propose our approach ASAX based on SAX representation and a variable-length segmentation algorithm. Our approach is complementary to the SAX extensions, such as iSAX and iSAX 2.0 which have been proposed for improving the kNN queries response time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">CONCLUSION</head><p>In this paper, we proposed a new approximation technique, called ASAX, that considers the time series distribution on the time domain and performs variable-size segmentation, by using the entropy of symbolic representations. Our technique allows reducing information loss and thus increasing the accuracy of time series representations. We implemented our technique and evaluated its performance using several real world datasets. The experimental results suggest that ASAX can obtain significant performance gains in terms of precision for similarity search compared to SAX. The results show that the more the data distribution in the time domain is unbalanced (non-uniform), the greater is the precision gain of ASAX, e.g., for the EGCFiveDays dataset that has a non-uniform distribution in the time domain, the precision of ASAX is 82% compared to 55% for SAX.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: SAX segmentation Vs. ASAX segmentation</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Example 1 .</head><label>1</label><figDesc>Figure 2b shows the PAA representation of 𝑋 , the time series of Figure 2a. The representation is composed of 𝑤 = |𝑋 |/𝑙 values, where 𝑙 is the segment size. With PAA, for each segment, the set of values is replaced with their mean. The length of the final representation 𝑤 is the number of segments (and, usually, 𝑤 &lt;&lt; |𝑋 |).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Example 2 .</head><label>2</label><figDesc>In Figure2c, we have converted the time series 𝑋 to SAX representation with 4 segments, and cardinality 4 using the PAA A SAX representation of X, with 4 segments and cardinality 4, [00, 00, 01, 11].</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: A time series 𝑋 is discretized by obtaining a PAA representation and then using predetermined break-points to map the PAA coefficients into SAX symbols. Here, the symbols are given in binary notation, where 00 is the first symbol, 01 is the second symbol, etc. The time series of Figure 2a in the representation of Figure 2c is [first, first, second, fourth] (which becomes [00, 00, 01, 11] in binary).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: ASAX segmentation with 2 segments</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>3 = 1 : 4 𝑠𝑒𝑔𝑚𝑒𝑛𝑡𝑇𝑜𝑆𝑝𝑙𝑖𝑡 = 1 5𝑒𝑛𝑡𝑟𝑜𝑝𝑦 = 0 6 for 𝑖=1 to 𝑘 do 7 𝑡𝑒𝑚𝑝𝑆𝑒𝑔𝑚𝑒𝑛𝑡𝑠 = 𝑠𝑒𝑔𝑚𝑒𝑛𝑡𝑠 8 if 14 𝑒 = entropy(ℎ𝑎𝑠ℎ𝑇 𝑎𝑏𝑙𝑒) 15 if 𝑒 &gt; 𝑒𝑛𝑡𝑟𝑜𝑝𝑦 then 16 𝑠𝑒𝑔𝑚𝑒𝑛𝑡𝑇𝑜𝑆𝑝𝑙𝑖𝑡 = 𝑖 17 𝑒𝑛𝑡𝑟𝑜𝑝𝑦 = 𝑒 18 split 2 19𝑠𝑒𝑔𝑚𝑒𝑛𝑡𝑠 = 𝑠𝑒𝑔𝑚𝑒𝑛𝑡𝑠 -{𝑠𝑒𝑔𝑚𝑒𝑛𝑡𝑇𝑜𝑆𝑝𝑙𝑖𝑡 } 20 𝑠𝑒𝑔𝑚𝑒𝑛𝑡𝑠 = 𝑠𝑒𝑔𝑚𝑒𝑛𝑡𝑠 {𝑠 1 , 𝑠 2 } 21 𝑘 = 𝑘+1 22 return 𝑠𝑒𝑔𝑚𝑒𝑛𝑡𝑠 1 1 3</head><label>3141678141516171822012111</label><figDesc>1 = [00, 00, 10]. The entropy is then calculated as: 𝐻 (𝑋 1 ) = -(𝑃 (𝑥 = [00, 00, 10]) log 𝑃 (𝑥 = [00, 00, 10])) where 𝑃 (𝑥 = [00, 00, 10]) = 3Algorithm ASAX variable-size segmentation Input: 𝐷: time series database; 𝑛: the length of time series; 𝑚𝑖𝑛𝑆𝑖𝑧𝑒: the minimum possible size of a segment; 𝑎: cardinality of symbols; 𝑤: the required number of segments Output: 𝑤 variable-size segments 1 𝑠𝑒𝑔𝑚𝑒𝑛𝑡𝑠 = {[0, 𝑛 2 ], [ 𝑛 2 , 𝑛]}; // split time domain into two equal size segments 2 𝑘 = 2 3 while 𝑘 ≠ 𝑤 do 𝑙𝑒𝑛𝑔𝑡ℎ(tempSegments[𝑖]) &gt; 𝑚𝑖𝑛𝑆𝑖𝑧𝑒 then 9 split segment 𝑖 into two equal parts, and replace the segment 𝑖 by its corresponding parts in 𝑡𝑒𝑚𝑝𝑆𝑒𝑔𝑚𝑒𝑛𝑡𝑠 10 ℎ𝑎𝑠ℎ𝑡𝑎𝑏𝑙𝑒 = new HashTable11 foreach 𝑡𝑠 ∈ 𝐷 do 12 𝑤𝑜𝑟𝑑 = ASAX(𝑡𝑠, 𝑡𝑒𝑚𝑝𝑆𝑒𝑔𝑚𝑒𝑛𝑡𝑠, 𝑎) 13 ℎ𝑎𝑠ℎ𝑇 𝑎𝑏𝑙𝑒.put(𝑤𝑜𝑟𝑑) 𝑠𝑒𝑔𝑚𝑒𝑛𝑡𝑇𝑜𝑆𝑝𝑙𝑖𝑡 into two equal size segments 𝑠 1 and 𝑠 and we have 𝐻 (𝑋 1 ) = -(1 log 1) = 0. Scenario 2 : This scenario is shown in Figure 4b in which the right segment is split. As for Scenario 1 we generate the symbolic representation of time series x, y and z using the 3 segments, and cardinality of 4. x = [00, 01, 10], ŷ = [00, 01, 11] and ẑ = [00, 01, 11] are the symbolic representation of x, y and z, respectively. In this scenario the representation set 𝑋 2 consists of [00,01,10] with an occurrence of 1 and [00,01,11] with an occurrence of 2, i.e., 𝑋 = [00, 01, 10], [00, 01, 10]. The entropy is calculated as: 𝐻 (𝑋 2 ) = -(𝑃 (𝑥 = [00, 01, 10]) log 𝑃 (𝑥 = [00, 01, 10]) + 𝑃 (𝑥 = [00, 01, 11]) log 𝑃 (𝑥 = [00, 01, 11])) where 𝑃 (𝑥 = [00, 01, 10]) = and 𝑃 (𝑥 = [00, 01, 11]) = 2 3 . Then, 𝐻 (𝑋 2 ) = -(</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>Scenario 2 of ASAX segmentation with 3 segments</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: The two different scenarios of ASAX segmentation with 3 segments. Scenario 4b is the one chosen because it optimizes the entropy.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: The Gaussian based distribution of symbols in SAX are not suitable for ASAX since they would favor minor information gain.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 6 :Figure 7 :</head><label>67</label><figDesc>Figure6: The data distribution of the tested datasets, and the precision results for each dataset. p(SAX) and p(ASAX) show the precision of SAX and ASAX respectively. The datasets are sorted in descending order of precision gain.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 7</head><label>7</label><figDesc>Figure 7 reports the time cost of our proposed approach. It gives the segmentation time of ASAX on the datasets of our experiments. It does not concern SAX since SAX divides the time domain into segments of fixed size which does not require any computation</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Some frequently used symbols 𝑋 is a sequence of values 𝑋 = {𝑥 1 , ..., 𝑥 𝑛 }. We assume that every time series has a value at every timestamp 𝑡 = 1, 2, ..., 𝑛. The length of 𝑋 is denoted by |𝑋 |.SAX allows a time series 𝑇 of length 𝑛 to be reduced to a string of arbitrary length 𝑤. Table1lists the notations used in this paper.</figDesc><table><row><cell>𝐷</cell><cell>Time series database</cell></row><row><cell cols="2">𝑋 , 𝑌 , 𝑄 Time series</cell></row><row><cell cols="2">𝑛 = |𝑋 | The length of time series 𝑋</cell></row><row><cell>𝑙</cell><cell>The segment size</cell></row><row><cell>𝑤</cell><cell>The number of PAA segments</cell></row><row><cell>𝑎</cell><cell>The cardinality (the alphabet size)</cell></row><row><cell>X</cell><cell>The SAX representation of time series 𝑋</cell></row><row><cell>𝑘</cell><cell>the 𝑘 nearest neighbors</cell></row><row><cell>A time series</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Datasets basic information</figDesc><table><row><cell>Name</cell><cell>Type</cell><cell>time series Length</cell></row><row><cell>AllGestureWiimoteZ</cell><cell>Sensor</cell><cell>500</cell></row><row><cell>ECG200</cell><cell>ECG</cell><cell>90</cell></row><row><cell>ECG5000</cell><cell>ECG</cell><cell>140</cell></row><row><cell>ECGFiveDays</cell><cell>ECG</cell><cell>130</cell></row><row><cell>Fungi</cell><cell>HRM</cell><cell>200</cell></row><row><cell>GesturePebbleZ1</cell><cell>Sensor</cell><cell>450</cell></row><row><cell>MedicalImages</cell><cell>Image</cell><cell>90</cell></row><row><cell cols="2">SonyAIBORobotSurface1 Sensor</cell><cell>70</cell></row><row><cell>SyntheticControl</cell><cell cols="2">Simulated 60</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>SAC'22, April 25 -April 29, 2022, Brno, Czech Republic Lamia Djebour, Reza Akbarinia, and Florent Masseglia</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Efficient Similarity Search In Sequence Databases</title>
		<author>
			<persName><forename type="first">Rakesh</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christos</forename><surname>Faloutsos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arun</forename><forename type="middle">N</forename><surname>Swami</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 4th Int. Conf. on FODO</title>
		<meeting>of the 4th Int. Conf. on FODO</meeting>
		<imprint>
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Beyond one billion time series: indexing and mining very large time series collections with i SAX2+</title>
		<author>
			<persName><forename type="first">A</forename><surname>Camerra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Shieh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Palpanas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Rakthanmanon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">J</forename><surname>Keogh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Knowl. Inf. Syst</title>
		<imprint>
			<date type="published" when="2014">2014. 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Efficient Time Series Matching by Wavelets</title>
		<author>
			<persName><forename type="first">Kin-Pong</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ada</forename><surname>Wai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">-Chee</forename><surname>Fu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the ICDE</title>
		<meeting>of the ICDE</meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Fast Window Correlations over Uncooperative Time Series</title>
		<author>
			<persName><forename type="first">Richard</forename><surname>Cole</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dennis</forename><surname>Shasha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaojian</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD Conf</title>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="743" to="749" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">The UCR Time Series Classification Archive</title>
		<author>
			<persName><forename type="first">Anh</forename><surname>Hoang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eamonn</forename><surname>Dau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kaveh</forename><surname>Keogh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chin-Chia</forename><surname>Kamgar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yan</forename><surname>Michael Yeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shaghayegh</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><surname>Gharghabi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ann</forename><surname>Chotirat</surname></persName>
		</author>
		<author>
			<persName><surname>Ratanamahatana</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bing</forename><surname>Yanping</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nurjahan</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anthony</forename><surname>Begum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abdullah</forename><surname>Bagnall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gustavo</forename><surname>Mueen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hexagon-Ml</forename><surname>Batista</surname></persName>
		</author>
		<ptr target="https://www.cs.ucr.edu/~eamonn/time_series_data_2018/" />
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Fast Subsequence Matching in Time-series Databases</title>
		<author>
			<persName><forename type="first">C</forename><surname>Faloutsos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ranganathan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Manolopoulos</surname></persName>
		</author>
		<idno type="DOI">10.1145/191843.191925</idno>
		<ptr target="https://doi.org/10.1145/191843.191925" />
	</analytic>
	<monogr>
		<title level="j">SigRec</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="419" to="429" />
			<date type="published" when="1994">1994. 1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Fast Subsequence Matching in Time-series Databases</title>
		<author>
			<persName><forename type="first">Christos</forename><surname>Faloutsos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ranganathan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yannis</forename><surname>Manolopoulos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the SIGMOD</title>
		<meeting>of the SIGMOD</meeting>
		<imprint>
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Computational Intelligence Challenges and Applications on Large-Scale Astronomical Time Series Databases</title>
		<author>
			<persName><forename type="first">Pablo</forename><surname>Huijse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pablo</forename><forename type="middle">A</forename><surname>Estévez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pavlos</forename><surname>Protopapas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jose</forename><forename type="middle">C</forename><surname>Principe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pablo</forename><surname>Zegers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Comp. Int. Mag</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="27" to="39" />
			<date type="published" when="2014">2014. 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Time-series active search for quick retrieval of audio and video</title>
		<author>
			<persName><forename type="first">Kunio</forename><surname>Kashino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gavin</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hiroshi</forename><surname>Murase</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICASSP</title>
		<imprint>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Dimensionality Reduction for Fast Similarity Search in Large Time Series Databases</title>
		<author>
			<persName><forename type="first">J</forename><surname>Eamonn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kaushik</forename><surname>Keogh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><forename type="middle">J</forename><surname>Chakrabarti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sharad</forename><surname>Pazzani</surname></persName>
		</author>
		<author>
			<persName><surname>Mehrotra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Knowl. Inf. Syst</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="263" to="286" />
			<date type="published" when="2001">2001. 2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">A Symbolic Representation of Time Series, with Implications for Streaming Algorithms</title>
		<author>
			<persName><forename type="first">J</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Keogh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lonardi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Chiu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003">2003</date>
			<publisher>SIGMOD</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Experiencing SAX: A Novel Symbolic Representation of Time Series</title>
		<author>
			<persName><forename type="first">J</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Keogh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lonardi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Data Min. Knowl. Discov</title>
		<imprint>
			<date type="published" when="2007">2007. 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">ULISSE: ULtra Compact Index for Variable-Length Similarity Search in Data Series</title>
		<author>
			<persName><forename type="first">Michele</forename><surname>Linardi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Themis</forename><surname>Palpanas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICDE</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Matrix Profile X: VALMOD -Scalable Discovery of Variable-Length Motifs in Data Series</title>
		<author>
			<persName><forename type="first">Michele</forename><surname>Linardi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yan</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Themis</forename><surname>Palpanas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eamonn</forename><forename type="middle">J</forename><surname>Keogh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGMOD</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">VALMOD: A Suite for Easy and Exact Detection of Variable Length Motifs in Data Series</title>
		<author>
			<persName><forename type="first">Michele</forename><surname>Linardi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yan</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Themis</forename><surname>Palpanas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eamonn</forename><forename type="middle">J</forename><surname>Keogh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGMOD</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Data Series Management: The Road to Big Sequence Analytics</title>
		<author>
			<persName><forename type="first">Themis</forename><surname>Palpanas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIGMOD Record</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="47" to="52" />
			<date type="published" when="2015">2015. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Searching and Mining Trillions of Time Series Subsequences Under Dynamic Time Warping</title>
		<author>
			<persName><forename type="first">T</forename><surname>Rakthanmanon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Campana</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mueen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Batista</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Westover</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zakaria</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Keogh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD</title>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Practical Data Prediction for Real-World Wireless Sensor Networks</title>
		<author>
			<persName><forename type="first">Usman</forename><surname>Raza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alessandro</forename><surname>Camerra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amy</forename><forename type="middle">L</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Themis</forename><surname>Palpanas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gian</forename><forename type="middle">Pietro</forename><surname>Picco</surname></persName>
		</author>
		<idno type="DOI">10.1109/TKDE.2015.2411594</idno>
		<ptr target="https://doi.org/10.1109/TKDE.2015.2411594" />
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Knowl. Data Eng</title>
		<imprint>
			<date type="published" when="2015">2015. 2015</date>
		</imprint>
	</monogr>
	<note>accepted for publication. accepted for publication</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Tuning Time Series Queries in Finance: Case Studies and Recommendations</title>
		<author>
			<persName><forename type="first">Dennis</forename><surname>Shasha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Data Eng. Bull</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="40" to="46" />
			<date type="published" when="1999">1999. 1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">iSAX: Indexing and Mining Terabyte Sized Time Series</title>
		<author>
			<persName><forename type="first">J</forename><surname>Shieh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Keogh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD Conf</title>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="623" to="631" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Long-term variability of AGN at hard X-rays</title>
		<author>
			<persName><forename type="first">S</forename><surname>Soldi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wayne</forename><forename type="middle">H</forename><surname>Volker Beckmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gabriele</forename><surname>Baumgartner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><forename type="middle">R</forename><surname>Ponti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Shrader</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Lubinski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Krimm</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jack</forename><surname>Mattana</surname></persName>
		</author>
		<author>
			<persName><surname>Tueller</surname></persName>
		</author>
		<idno type="DOI">10.1051/0004-6361/201322653</idno>
		<ptr target="https://doi.org/10.1051/0004-6361/201322653" />
	</analytic>
	<monogr>
		<title level="j">Astronomy and Astrophysics -A&amp;A</title>
		<imprint>
			<biblScope unit="volume">563</biblScope>
			<biblScope unit="page">16</biblScope>
			<date type="published" when="2014-03">2014. March 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Time series shapelets: a new primitive for data mining</title>
		<author>
			<persName><forename type="first">Lexiang</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eamonn</forename><forename type="middle">J</forename><surname>Keogh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD</title>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Data Series Management: Fulfilling the Need for Big Sequence Analytics</title>
		<author>
			<persName><forename type="first">Kostas</forename><surname>Zoumpatianos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Themis</forename><surname>Palpanas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICDE</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
