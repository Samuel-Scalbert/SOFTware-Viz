<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">An In-depth Analysis of Implicit and Subtle Hate Speech Messages</title>
				<funder>
					<orgName type="full">3IA Côte d&apos;Azur Investments</orgName>
				</funder>
				<funder ref="#_zxmGz5x">
					<orgName type="full">Agence Nationale de la Recherche</orgName>
					<orgName type="abbreviated">ANR</orgName>
				</funder>
				<funder>
					<orgName type="full">French government</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Nicolas</forename><surname>Ocampo</surname></persName>
							<email>nicolas-benjamin.ocampo@etu.univ-cotedazur.fr</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Universite Côte d&apos;Azur</orgName>
								<orgName type="institution" key="instit2">CNRS</orgName>
								<orgName type="institution" key="instit3">Inria</orgName>
								<address>
									<region>I3S</region>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Ekaterina</forename><surname>Sviridova</surname></persName>
							<email>ekaterina.sviridova@inria.fr</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Universite Côte d&apos;Azur</orgName>
								<orgName type="institution" key="instit2">CNRS</orgName>
								<orgName type="institution" key="instit3">Inria</orgName>
								<address>
									<region>I3S</region>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Elena</forename><surname>Cabrio</surname></persName>
							<email>elena.cabrio@univ-cotedazur.fr</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Universite Côte d&apos;Azur</orgName>
								<orgName type="institution" key="instit2">CNRS</orgName>
								<orgName type="institution" key="instit3">Inria</orgName>
								<address>
									<region>I3S</region>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Serena</forename><surname>Villata</surname></persName>
							<email>villata@i3s.unice.fr</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Universite Côte d&apos;Azur</orgName>
								<orgName type="institution" key="instit2">CNRS</orgName>
								<orgName type="institution" key="instit3">Inria</orgName>
								<address>
									<region>I3S</region>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">An In-depth Analysis of Implicit and Subtle Hate Speech Messages</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">5D080325E18D84C94BB42D4C1021BB91</idno>
					<idno type="DOI">10.18653/v1/2023.eacl-main.147</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-04-12T14:48+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The research carried out so far in detecting abusive content in social media has primarily focused on overt forms of hate speech. While explicit hate speech (HS) is more easily identifiable by recognizing hateful words, messages containing linguistically subtle and implicit forms of HS (as circumlocution, metaphors and sarcasm) constitute a real challenge for automatic systems. While the sneaky and tricky nature of subtle messages might be perceived as less hurtful with respect to the same content expressed clearly, such abuse is at least as harmful as overt abuse. In this paper, we first provide an in-depth and systematic analysis of 7 standard benchmarks for HS detection, relying on a fine-grained and linguistically-grounded definition of implicit and subtle messages. Then, we experiment with state-of-the-art neural network architectures on two supervised tasks, namely implicit HS and subtle HS message classification. We show that while such models perform satisfactory on explicit messages, they fail to detect implicit and subtle content, highlighting the fact that HS detection is not a solved problem and deserves further investigation.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The rising mass of communication through social media further exacerbates harmful consequences of online hate speech. As a result, social media have faced mounting pressure from civil rights groups demanding to ramp up their enforcement of antihate speech policies, so that to monitor and limit this kind of content. In the latest years, numerous methods have been developed to automatically identify this type of utterances expressing hateful or abusive content on social media using Natural Language Processing methods. A variety of datasets have also been built, exemplifying various manifestations of this harmful content <ref type="bibr" target="#b41">(Poletto et al., 2021)</ref>. However, most of the research carried out so far on this topic has focused on overt forms of hate speech. Explicit hate speech is more easily identifiable by recognizing a clearly hateful word or phrase. Only recently, a few works <ref type="bibr" target="#b31">(Hartvigsen et al., 2022;</ref><ref type="bibr" target="#b52">Wiegand et al., 2022</ref><ref type="bibr">Wiegand et al., , 2021a;;</ref><ref type="bibr" target="#b22">ElSherief et al., 2021;</ref><ref type="bibr" target="#b35">Jurgens et al., 2019;</ref><ref type="bibr" target="#b49">Waseem et al., 2017)</ref> have started to focus on implicitness, where circumlocution, metaphor, or stereotypes are used to intentionally convey hatred towards a particular group. In those messages, hatefulness can be captured only by understanding their global meaning, as well as contextual information.</p><p>In this paper, we carry out an in-depth analysis of implicit HS in standard benchmarks for HS detection. Additionally, we define the notion of Subtle HS that puts forward hateful meanings elusively relying on human perception and through the use of complex syntactic structures. In our study, we collect messages from 7 available datasets for HS detection that cover different topics and are extracted from different social media platforms, and we enrich them with the following three-layer annotation: HS/non HS, Explicit/Implicit and Subtle/Non Subtle. We also provide a fine-grained annotation for implicit HS messages with 18 implicit properties such as irony, exaggeration, metaphor, and rhetorical question, among others. The newly created resource named ISHate (Implicit and Subtle Hate speech) provides a rich and variegate benchmark for pushing forward research on implicit and subtle hateful messages, and constitutes a challenging test-bed to evaluate computational approaches. <ref type="foot" target="#foot_0">1</ref>Additionally, we evaluate SOTA and competitive baseline classifiers to detect both implicit and subtle HS in ISHate, showing that current methods fail to effectively detect implicit and subtle HS messages due to their peculiar nature. NOTE: This paper contains examples of language which may be offensive to some readers. They do not represent the views of the authors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>In the latest years, there has been significant research on abusive language and hate speech detection using Natural Language Processing (NLP) methods (e.g., <ref type="bibr" target="#b56">Xu et al. (2012)</ref>; <ref type="bibr" target="#b18">Dadvar et al. (2013)</ref>; <ref type="bibr" target="#b41">Poletto et al. (2021)</ref>; <ref type="bibr" target="#b7">Bohra et al. (2018)</ref>; <ref type="bibr" target="#b17">Corazza et al. (2020)</ref>; <ref type="bibr">Zampieri et al. (2019a)</ref>; <ref type="bibr" target="#b12">Caselli et al. (2020</ref><ref type="bibr" target="#b11">Caselli et al. ( , 2021))</ref>). A few works focus on subtypes of HS, such as <ref type="bibr" target="#b48">Warner and Hirschberg (2012)</ref> that tackles the recognition of antisemitism, or <ref type="bibr" target="#b50">Waseem and Hovy (2016)</ref>; <ref type="bibr" target="#b2">Badjatiya et al. (2017)</ref>; Gambäck and Sikdar (2017) that investigate predictive features to identify HS in the form of racism and sexism. In this context, several challenges and shared tasks have also been organized over the years, that made datasets and resources for multiple languages available (for a survey, see <ref type="bibr" target="#b41">Poletto et al. (2021)</ref>). Research studies carried out so far have mostly focused on overt forms of hate speech, while very few works address the issue of implicit and subtle HS <ref type="bibr" target="#b22">(ElSherief et al., 2021)</ref>. However, several works show awareness of the problem. For instance, <ref type="bibr" target="#b48">Warner and Hirschberg (2012)</ref> and <ref type="bibr" target="#b56">Xu et al. (2012)</ref> discuss systems' limitations in identifying HS messages which are ambiguous, have patterns of emotional speech or lack context. <ref type="bibr" target="#b59">Zhang and Luo (2018)</ref> and <ref type="bibr" target="#b17">Corazza et al. (2020)</ref> highlight the complexity of recognizing hateful messages when the meaning is conveyed through sarcasm, stereotypes, complex syntactic structure, or non-explicit lexical patterns.</p><p>Among the few studies that attempted to address the issues of implicit and subtle detection, <ref type="bibr" target="#b12">Caselli et al. (2020)</ref> defines a shared task to detect implicit and explicit abusive messages from AbusEval, a reannotated dataset based on OLID/OffensEval <ref type="bibr">(Zampieri et al., 2019a)</ref>. <ref type="bibr" target="#b4">Benikova et al. (2018)</ref> paraphrases German HS tweets obtaining implicit and explicit messages to study classification methods. <ref type="bibr" target="#b18">Dadvar et al. (2013)</ref> shows how taking user context improves cyberbullying detection with neither explicit profanities nor apparent neutral emotions. <ref type="bibr" target="#b35">Jurgens et al. (2019)</ref> and <ref type="bibr" target="#b49">Waseem et al. (2017)</ref> explain why explicitness, implicitness, and subtlety are typologies of abusiveness and encourage researchers to develop proactive technologies in this area. <ref type="bibr" target="#b22">ElSherief et al. (2021)</ref> introduces a taxonomy of implicit hate speech and a benchmark corpus with fine-grained labels for each message. <ref type="bibr" target="#b31">Hartvigsen et al. (2022)</ref> proposes a large-scale approach to automatically generate benign and implicit HS statements through the language model GPT3. <ref type="bibr">Wiegand et al. (2021a</ref><ref type="bibr" target="#b52">Wiegand et al. ( , 2022) )</ref> proposes resources to tackle implicitly abusive comparisons and abusive remarks, which are two subtypes of implicitness. <ref type="bibr">Wiegand et al. (2021b)</ref> explains the key issues in the implicit abuse detection, as well as possible future directions to explore. Even though these studies set the basis to explore and model the issue of implicit HS, there is still large room for improvement, both in terms of creating adequate resources to investigate these aspects and in terms of computational approaches to address them.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">HS, Implicitness and Subtlety</head><p>Hate Speech is defined as a direct attack against people -rather than concepts or institutionsbased on protected characteristics (PC): race, ethnicity, national origin, disability, religious affiliation, caste, sexual orientation, sex, gender identity, and severe disease <ref type="bibr">(Meta, 2022)</ref>. We encompass in the concept refugees, migrants, immigrants, asylum seekers from the most severe attacks, and occupations when they are referenced along with PC, though commentary and criticism of immigration policies are excluded from HS. Following this definition, HS differs from related concepts mainly since it is specifically oriented to groups of people with PC as the main target <ref type="bibr" target="#b41">(Poletto et al., 2021)</ref>. In the following, we provide clear and operational definitions of explicit, implicit and subtle HS. Reported examples are extracted from the White Supremacy Forum (WSF) <ref type="bibr" target="#b19">(de Gibert et al., 2018)</ref> and the CONAN <ref type="bibr" target="#b15">(Chung et al., 2019)</ref> datasets, described in Section 4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Explicit Hate Speech</head><p>Explicit HS is unambiguous in its potential to be abusive/hateful, such as language containing racial or homophobic slurs. Explicit HS uses words whose literal definition (taken from the dictionary) is hateful <ref type="bibr" target="#b22">(ElSherief et al., 2021;</ref><ref type="bibr" target="#b49">Waseem et al., 2017;</ref><ref type="bibr" target="#b12">Caselli et al., 2020)</ref>, as in Example 1.</p><p>1. Negros are so dumb . (WSF)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Implicit Hate Speech</head><p>According to the definitions of <ref type="bibr" target="#b22">ElSherief et al. (2021)</ref>, implicit HS does not immediately denote abuse/hate. Implicitness goes beyond word-related meaning, implying figurative language use such as <ref type="bibr">irony, sarcasm, etc. (ElSherief et al., 2021;</ref><ref type="bibr" target="#b4">Benikova et al., 2018)</ref>, generally hiding the real meaning, making it more difficult to grasp and undermining the collection of hateful messages <ref type="bibr" target="#b31">(Hartvigsen et al., 2022;</ref><ref type="bibr" target="#b49">Waseem et al., 2017)</ref>. Therefore, we deal with figurative meaning intended by the author rather than literal meaning of words that may be extracted from dictionaries.</p><p>In our extensive study on hate speech datasets, we identified 18 typical properties of implicitness relying on linguistics features (listed in Table <ref type="table" target="#tab_1">2</ref>). Among the most significant ones we have irony <ref type="bibr" target="#b25">(Frenda et al., 2022)</ref>, sarcasm <ref type="bibr" target="#b42">(Potamias et al., 2020)</ref>, black humor, metaphor <ref type="bibr" target="#b14">(Choi et al., 2021;</ref><ref type="bibr" target="#b27">Gao et al., 2018)</ref>, exaggeration <ref type="bibr" target="#b45">(Troiano et al., 2018)</ref>, rhetorical question, sentiment <ref type="bibr" target="#b37">(Li et al., 2021)</ref>, inference, lack of context <ref type="bibr" target="#b18">(Dadvar et al., 2013)</ref>, and lack of extralinguistic knowledge. Most of the implicit HS messages contain combinations of several properties, as in: 2. Global Jewry did not want Brexit and are doing everything they can to sabotage it. (CO-NAN)</p><p>Example 2 illustrates an interlacement of irony and exaggeration. Global Jewry represents a wordplay mixing Global Jury and Jews adding humorous content to the perception of Jewish people as a nation, while doing everything is hyperbolic pointing out that Jewish are extremely occupied by Brexit.</p><p>The whole message is ironical as it emphasizes that Israel has its own interest in other country's affairs.</p><p>3. I also , unfortuantely , spent 7-8th grade in a 95 % monkey house (WSF)</p><p>In Example 3 there is an overlap of irony, exaggeration, and metaphor (underlined). 95 % looks more like an exaggeration than a fact, while monkey house refers to the group of students and in the metaphor due to their skin color they are compared with monkeys.</p><p>4. Are you sure that Islam is a peaceful religion? (CONAN)</p><p>Example 4 interlaces rhetorical question, inference, and sentiment. The rhetorical question doubts about the peacefulness of Islam, expressing at the same time the author's take on it. As well as that, we may read negative inference between the lines.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Subtle Hate Speech</head><p>Subtle Hate Speech concerns hateful messages that are so delicate or elusive as to be difficult to analyze or describe, and that depend on an indirect method to deliver the meaning (Merriam-Webster, 2022). However, literal meanings <ref type="bibr" target="#b44">(Roland et al., 1968;</ref><ref type="bibr" target="#b5">Bertrand, 1905)</ref> are of prime importance in subtle messages by contrast to implicit messages where we go beyond literal meanings <ref type="bibr" target="#b49">(Waseem et al., 2017)</ref>. Although implicitness and subtlety differ a lot at this point, we still rely on language users' perception <ref type="bibr" target="#b28">(Grice, 1967</ref><ref type="bibr" target="#b29">(Grice, , 1989;;</ref><ref type="bibr" target="#b36">Korta and Perry, 2020)</ref> to understand implicit and subtle messages <ref type="bibr" target="#b4">(Benikova et al., 2018)</ref>. Despite the challenges in characterizing human perception schematically, in our study, the use of elements such as negations with positive clauses, conditionals, connectors, unrelated constructions, word order, and circumlocution can greatly affect the subtlety of a message. Cases of HS that convey the meaning directly and straightforwardly are non-subtle. As subtlety is even less studied than implicitness in the domain of HS <ref type="bibr" target="#b9">(Breitfeller et al., 2019)</ref>, and only considered as a related concept of implicitness in previous works <ref type="bibr" target="#b35">(Jurgens et al., 2019;</ref><ref type="bibr" target="#b22">ElSherief et al., 2021;</ref><ref type="bibr" target="#b31">Hartvigsen et al., 2022)</ref>, we analyze their interrelation, particularly whether one of these concepts is an umbrella term for the other.</p><p>First, we study whether explicit HS can convey the meaning in a subtle way, to accept or reject the idea that implicitness is a general term for subtlety. As can be seen from the example below, a message can be explicit and subtle at the same time: 5. As a brit my knowledge of american law is somewhat lacking but even i know that this holder groid has committed treason (WSF)</p><p>Example 5 is explicit as it literally conveys hateful meanings with the expression holder groid, but it is subtle as the intended hateful meaning is disguised by the first and second underlined constructions, pushing out the attention from the explicit hateful expression.</p><p>On the other side, we investigate whether subtlety is an umbrella concept for implicitness (whether all implicit messages are subtle by default). The following example shows an implicit non-subtle HS message: 6. I 'm either in North Florida or Nigeria sometimes i can't tell the difference. (WSF)</p><p>According to the definitions of explicitness and implicitness, this message is not explicit since it does not contain any hateful words, thus, it does not directly convey hateful meaning. However, it is hateful despite being more elaborated, as it includes certain figures of speech that trigger hateful meaning. The underlined expression in Example 6 represents antithesis, while the message itself is ironical. This message also lacks contextual information and extralinguistic knowledge. Although being implicit, this message is not subtle as the meaning is delivered plainly without any delusion or delicacy. Based on these considerations, we consider implicitness and subtlety as two separate concepts. To illustrate the difference between implicit non-subtle messages presented above and implicit subtle cases, consider the following example:</p><p>7. I think it is a bit late to think to look after the saety and the future of white people in Southfrica . (WSF)</p><p>We label it as implicit HS as it does not express hateful meaning explicitly via offensive words and it is ironic. It is also subtle as it starts with an introductory construction that makes the message more sophisticated and adds extra weight to it.</p><p>As can be expected, it is also possible to find non-hateful subtle or implicit sentences (such as ironic or sentimental texts). However, our work focuses on exploring implicitness and subtlety in the context of hate speech only, therefore those more general cases are not investigated.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">The ISHate Dataset</head><p>Relying on the fine-grained definitions of HS provided in the previous section (explicit, implicit and subtle HS), we collect and enrich 7 available standard datasets for HS detection. As a result, we create the first benchmark for implicit and subtle HS detection on social media messages extracted from different sources.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Data Collection</head><p>Nearly all available resources of user-generated HS content are retrieved with a keyword-based approach, and mainly relying on a list of words with negative polarity <ref type="bibr" target="#b41">(Poletto et al., 2021)</ref>. However, with this strategy it is possible to extract mainly explicit HS expressions (as in the AbusEval dataset, <ref type="bibr" target="#b12">Caselli et al. (2020)</ref>). Given that our study focuses on implicit and subtle HS, we prefer to explore resources collected from communities of users that are potentially prone to hate speech, or resources manually created using a systematic approach. In the following, we list the considered resources: White Supremacy Forum Dataset (WSF) (de <ref type="bibr" target="#b19">Gibert et al., 2018)</ref>, that contains HS messages from Stormfront, scraped from the most influential white supremacist forum on the Web. The database is arranged in sub-forums and conversation threads. <ref type="bibr">HatEval (Basile et al., 2019)</ref>, which is among the most well-known benchmark for HS detection. A combined approach is applied to collect hateful and misogynous tweets by monitoring potential victims of hate accounts, downloading the history of identified haters, and filtering Twitter streams with both neutral and derogatory keywords. Implicit Hate Corpus (IHC) <ref type="bibr" target="#b22">(ElSherief et al., 2021)</ref>, annotated with explicit HS, implicit HS, and non-HS labels obtained from online hate groups on Twitter. The authors focused on eight ideological clusters of U.S., as Black Separatists, White Nationalist and Neo-Nazi. From this dataset we only extracted messages labeled as implicit HS, as it is one of our target categories. ToxiGen <ref type="bibr" target="#b31">(Hartvigsen et al., 2022)</ref>, a dataset with benign and implicit toxic messages against minority groups. ToxiGen is machine-generated through the GPT3 language model and prompt programming. Similarly to IHC, we only extracted messages which were automatically labeled as implicit HS and human-validated as toxic by the authors. We did not consider unfinished generated sentences which make a part of implicit messages. YouTube Video Comments Dataset (YouTube) <ref type="bibr" target="#b30">(Hammer, 2017)</ref>, that consists of YouTube comments posted under videos related to religion and politics. Differently from the other resources, the messages are annotated as "violent" or "clean". CONAN <ref type="bibr" target="#b15">(Chung et al., 2019)</ref>, a dataset of HS messages and counter-narratives (CN) pairs for CN generation. Two native English speakers were asked to write 50 prototypical short texts, which NGO could later use to write their hate texts and counternarratives. We believe that messages for which a CN can be provided might be richer in implicit content since a slur-based explicit HS message might produce very poor argumentative CN. Multi-Target CONAN (MCONAN) <ref type="bibr" target="#b23">(Fanton et al., 2021)</ref>, a dataset of English HS/CN pairs comprising several hate targets. It is collected using a Human-in-the-Loop approach. A generative lan-guage model is refined iteratively by using data from the previous loops to generate new samples that NGOs experts review.</p><p>Before starting the annotation process with the fine-grained annotations (Explicit, Implicit and Subtle HS), we had to make sure that the definition of HS originally used to annotate such resources is consistent with ours. In the first annotation round, we checked the messages originally annotated as HS, and discarded the few ones that did not correspond to the definition of HS reported in Section 3. For the YouTube dataset, we also added the HS labels. While all the messages annotated as HS are directed to PC, it should be noted that the topics distribution and the writing quality might be different, given the heterogeneity of the selected resources. HS messages mostly target Islamism, Judaism, misogyny, multi-culturalism, racism, immigration, and refugees. Regarding time creation, WSF is made from threads posted between 2002 and 2017, ToxiGen's LM was trained with messages from 2016 to 2019, Hateval consists of messages of 2018, the YouTube comments were collected in 2017, while the IHC contains tweets from U.S. ideological clusters from 2015 to 2017.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Annotation Procedure</head><p>Following the annotation scheme described in Section 3, four graduate-level annotators with linguistics and computational linguistics competences carried out a pilot annotation study on a sample of 100 messages extracted from each of the above mentioned resources to converge to non-ambiguous annotation strategies. We calculate the Inter Annotator Agreement (IAA) on this sample, resulting in Cohen's κ=0.793 <ref type="bibr" target="#b16">(Cohen, 1960)</ref> for the implicit layer (binary annotation Explicit/Implicit) and 0.730 for the subtlety layer (binary annotation Subtle/Non-Subtle). We also compute the IAA considering both layers simultaneously, that is, considering one layer of 4 classes (Implicit, Explicit, Subtle, Non-Subtle), obtaining a Cohen's κ of 0.734. In the reconciliation phase, we notice that most of the disagreements are due to the interlacement of subtlety and implicitness. For that reason, we also calculate an ordered weighted disagreement using Krippendorff's α to penalize less when the annotators agree at least on one of the layers <ref type="bibr" target="#b1">(Artstein and Poesio, 2008)</ref>. The Krippendorff's α is 0.757. Despite the complexity of the annotation task, obtained results are considered as strong agreement in a two-annotators setting. The rest of the annotations has then been carried out by two of the annotators mentioned above, which were provided with the final version of the annotation guidelines (containing the definitions of the target classes, i.e., subtlety and implicitness, and a discussion about borderline cases), together with a set of labeled examples.</p><p>Finally, the implicit properties annotations are added on top of the messages labeled as implicit as an additional annotation layer to highlight 18 linguistic features that implicitly convey hateful meaning. For this layer, annotations are carried out by one expert linguist.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Data Statistics</head><p>Table <ref type="table" target="#tab_0">1</ref> shows statistics of the final dataset, reporting on the number of annotated HS messages for each resource and for the three annotation layers.</p><p>The ISHate collection consists of a total of 29116 messages, where 11247 are HS (further annotated with the Explicit/Implicit and Subtle/Non-subtle labels). For computational purposes, we provide a dataset split in three subsets, i.e., train (70%), validation (15%), and test (15%) sets. Each of the partition respects the distribution of all the annotation layers using stratified splitting. As can be seen, classes are unbalanced, each resource providing only a reduced number of implicit and subtle messages -as expected. Note that CONAN and MCONAN do not contain Non-HS messages, because their main objective is CN generation. As for IHC and ToxiGen, we only look through previously annotated implicit HS messages disregarding non hateful ones. Note also that ToxiGen claimed to contain only implicit adversarial messages, but according to our definitions and annotation guidelines many messages are considered as explicit and non-subtle by our annotators.</p><p>Table <ref type="table" target="#tab_1">2</ref> shows the full distribution of the implicit properties relative to the implicit messages in ISHate. As it can be seen, Inference (58%), Context (48%), Sentiment (45%), Exaggeration (28%) and Irony (22%), are the most frequent properties of implicit HS messages, whereas Euphemism (4%), Circumlocution (3%), Metonymy (0.4%) and Synecdoche (0.08%) are the least recurrent. Note that one implicit message can be labeled with more than one property. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Data Augmentation</head><p>To overcome the problem of the unbalanced dataset, we propose oversampling and data augmentation (DA) methods for the minority classes using adversarial methods and generative models following <ref type="bibr" target="#b38">(Mayer et al., 2020;</ref><ref type="bibr" target="#b51">Wei and Zou, 2019)</ref>, and the GPT2 language model <ref type="bibr" target="#b43">(Radford et al., 2019)</ref>.</p><p>Replace Named Entities (RNE). It replaces a named entity (PER, LOC, ORG, and MISC) in the input sentence. A candidate NE in a sentence is replaced by another one according to a previously collected list of NEs <ref type="bibr" target="#b38">(Mayer et al., 2020)</ref>. Then, the most similar NE is selected by using pre-trained FastText embeddings <ref type="bibr" target="#b8">(Bojanowski et al., 2016)</ref>. In our use case, we notice that the number of NEs PER, LOC, and ORG are very few compared to MISC. This might be due to the fact that HS messages in our collection mostly target groups and not individuals. However, expressions like muslims, jews, or blacks are present in the MISC category and replaced, as in Example 8. As it can be noticed, the expression preserves its meaning, that is, the use of the rhetorical question to convey that Muslims are not considered as a part of society.</p><p>8. Original: Have Muslims ever made a contri-bution to our society? (CONAN) Augmented: Have Moslem Arabs ever made a contribution to our society?</p><p>Replace Scalar Adverbs (RSA). It replaces emphasising adverbs like considerably or largely, with another scalar adverb that might increase or decrease the emphasis of an adjective/verb. 9. Original: I do like the outfit they dressed the simian in ; he looks so regal (WSF) Augmented: I do like the outfit they dressed the simian in ; he looks incredibly regal</p><p>Example 9 is another implicit racist HS message that uses irony by combining simian, dressed, and regal. RSA replaces the scalar adverb, slightly increasing the emphasis of regal in the sentence. Add Adverbs to Verbs (AAV). It adds modifiers to verbs to accentuate them. In this case, we use speculative adverbs like certainly, likely, clearly.</p><p>10. Original: I wish we lived in a world in which only men could be doctors, lawyers, firemen, and teachers. (MCONAN) Augmented: I wish we lived in a world in which only men could plausibly be doctors, lawyers, firemen, and teachers.</p><p>In Example 10, the meaning is made elusive by the use of the expression I wish we lived, the addition of plausibly alters the possibility of the verb "to be", but keeps the misogyny meaning.</p><p>Replace Adjectives (RA). Easy Data Augmentation (EDA). Given an input sentence, EDA randomly: i) replaces a non-stop word expression with a synonym using Wordnet; ii) inserts a synonym of a non-stop word in a random position; iii) chooses two words of the sentence and swaps their positions; iv) removes each word in the sentence with a certain probability. Only one of the four operations at a time is applied to a sentence.</p><p>13. Original: A lot of white women are trying to create danger by drawing these other people into our countries . (WSF) Augmented: A lot of our women are trying to create danger by drawing these other people into white countries .</p><p>A parameter α expressing the percent of the words to be changed in a sentence is specified (in our setting, α = 0.1 as in <ref type="bibr" target="#b51">Wei and Zou (2019)</ref>). Back Translation. It translates an input message into a different language to translate it back into the original language. We use the translation from English to Russian following (ElSherief et al., 2021).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="14.">Original:</head><p>As a nation , we are in desperate need for an immigration time out and a zero tolerance policy for those here illegally . (WSF) Augmented:</p><p>As a nation, we desperately need an immigration timeout and a zero-tolerance policy for those here illegally.</p><p>Generative Models (GM). We fine-tune autoregressive generative language models with instances from our minority classes, i.e., explicit subtle, implicit non-subtle, and implicit subtle messages. To do so, we prefix this label on the text as a prompt.</p><p>Then, language models are asked to generate messages starting with one of our fine-tuned prompts, as in Example 15. We use GPT2 <ref type="bibr" target="#b43">(Radford et al., 2019)</ref> as a language model, fine-tuned for 4 epochs using learning rate of 3e-5, and batch size of 32. Additionally, we implement a human-in-the-loop approach revising the generated examples and reannotating them in case the original label is nomore appropriate for the message.</p><p>15. Input: Explicit Subtle HS:</p><p>Augmented: Explicit Subtle HS: In the end, it comes down to what women want from a man... If they want to play with whores, they can stay at home and have babies...</p><p>Except for GM and BT, the same strategy is applied to augmentation methods to produce new messages. Preprocessing (e.g., Parts-of-Speech tagging and Named Entities Recognition) is carried out using Flair <ref type="bibr" target="#b0">(Akbik et al., 2019)</ref> and NLTK <ref type="bibr" target="#b6">(Bird and Loper, 2004</ref>) models, and allows to recognize possible candidate phrases to perform a replacement/addition. Then, a candidate phrase is perturbed by another one according to a list of adverbs, NEs, or adjectives based on domain data. We rely on FastText and WordNet Synsets to maintain the semantics of the augmented sentences with respect to the original one. The number of candidates to perform a replacement/addition and the number of replacement/additions per candidate are provided as parameters to these methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Evaluation</head><p>To show that implicit and subtle HS detection is still a very challenging task, we evaluate a set of state-of-the-art models for HS detection on the ISHate dataset. We propose two 3-label classification tasks:</p><p>• Task A (Non-HS/Explicit HS/Implicit HS)</p><p>• Task B (Non-HS/Non-Subtle HS/Subtle HS)</p><p>To this goal, we consider the following models: Universal Sentence Encoder (USE) + SVM <ref type="bibr" target="#b34">(Indurthi et al., 2019)</ref>. First-ranked model on the <ref type="bibr">HatEval benchmark (Basile et al., 2019)</ref>. The USE <ref type="bibr" target="#b13">(Cer et al., 2018)</ref> is a sentence embedding that encodes text into high dimensional vectors of 512 dimensions, trained on large data sources to provide an encoding method that works for various NLP tasks. An SVM classifier with RBF kernel and default parameters is then used for classification.</p><p>DeBERTa V3 (hate_speech18). SOTA model on the WSF dataset <ref type="bibr" target="#b19">(de Gibert et al., 2018)</ref>. For classification, a default HuggingFace implementation of a one-layer Feed Forward network is used on top of DeBERTa <ref type="bibr">(He et al., 2021a,b)</ref>, a transformer-based model. The model is later fine-tuned for 4 epochs (learning rate of 2e-5, batch size of 32). BERT <ref type="bibr" target="#b20">(Devlin et al., 2018)</ref>. We use this language model to encode text sequences and classify them by adding a Feed-forward neural network on top.</p><p>HateBERT. A re-trained BERT model using over 1 million posts from banned communities on Reddit <ref type="bibr" target="#b11">(Caselli et al., 2021)</ref> and then fine-tuned on our dataset. HateBERT obtained very promising results in the benchmarks HatEval, OffensEval <ref type="bibr">(Zampieri et al., 2019b)</ref>, and AbusEval <ref type="bibr" target="#b12">(Caselli et al., 2020)</ref>.</p><p>As for preprocessing, we replace long non-space character chains for only one occurrence, and delete digits, special symbols, and URLs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Results</head><p>Table <ref type="table" target="#tab_4">3</ref> reports on the results of the different models on the two tasks. On both tasks, all models show satisfactory performances when detecting overt forms of HS (Explicit HS and Non-Subtle HS classes), with DeBERTa outperforming the other models. The results obtained by all models for the Implicit HS and Subtle HS classes are much lower, and comparable to those obtained by ElSherief et al. (2021) (F1-score=.586) on the implicit class.</p><p>As a follow-up experiment, we apply the oversampling techniques (Section 4) on the minority classes of tasks A and B until balancing them with respect to the Explicit HS and Non-Subtle HS categories. The oversampling is performed on the training set only. The test set is the one of the original dataset, and is therefore unbalanced in order to evaluate the system on real class distribution and to avoid information leakage from train to test through augmentation methods. Tables <ref type="table" target="#tab_5">4a</ref> and<ref type="table" target="#tab_5">4b</ref> show the number of additional generated implicit/subtle messages and the resultant training set distribution per augmentation method, respectively. Among all tested models, only HateBERT significantly improves its performance for detecting implicit messages combining all augmented data (ALL) (see Table <ref type="table" target="#tab_4">3</ref>). We also highlight that back translation (BT) better contributes to the performance on the implicit hate class for BERT, DeBERTa, and USE+SVM 2 . Performances 2 The table reporting the obtained results by all models on surprisingly increase for the subtle class with USE+SVM+BT showing that back-translated messages provide diversity by rephrasing subtle examples without altering their meaning. Data generated with simpler augmentation methods as BERT+RNE and DeBERTa+RI also show slight improvements for subtlety. However, performances decrease on the implicit class when applying data augmentation strategies GM and GM+Revised, and only slightly improve on the subtle class.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Error Analysis</head><p>To gain insights into the models' behaviours, we manually analyse the classification errors of the best performing approaches, i.e., HateBERT+ALL and USE+SVM+BT for both tasks A and B. For the Non-HS/Explicit/Implicit classification, it is harder for HateBERT+ALL to differentiate implicit messages rather than explicit ones. Figure <ref type="figure" target="#fig_1">1</ref> in Appendix A shows the resultant embedding through t-SNE (van der Maaten and Hinton, 2008) approximation of all implicit messages of the test set, and two samples of the other two classes, showing how HateBERT+ALL is capable of separating the space in three different blobs for classification (Figure <ref type="figure" target="#fig_1">1a</ref>), embedding well the human-annotated Explicit HS and Non-HS classes (Figure <ref type="figure" target="#fig_1">1b</ref>), but badly encoding implicit annotated messages (instances spread over the explicit and non-hateful blobs). We also considered the F1-scores of the (Non-HS vs Implicit HS) and (Non-HS vs Explicit HS) classes, as if we had binary labels, obtaining an (F1-score=0.670) and (F1-score=0.850) on the target categories respectively, showing that implicit cases are harder to detect than explicit ones.</p><p>Among misclassified examples, we can find messages where the PC are not explicitly named (Example 16). Contextual knowledge is needed there to grasp that the target of the message is black people.</p><p>16. I can picture him as that baby monkey on the ' save the rainforest comercial or whatever Additionally, from the misclassified messages we extract the most frequent implicit properties not captured by the classifier 3 . They concern Inference (53%), Context (41%), Sentiment (40%), Exaggeration (24%), Extralinguistic knowledge (24%).</p><p>For Subtle/Non Subtle message classification, we also plotted the USE embedding for the best different types of augmented data is in the Appendix. 3 The full table can be found in the Appendix.  <ref type="bibr">.888 .866 .877 .766 .803 .784 .399 .382 .390 .891 .868 .879 .783 .832 .807 .667 .103 .178 BERT .903 .893 .898 .81 .833 .821 .394 .371 .382 .902 .891 .897 .819 .846 .832 .250 .103 .145 HateBERT .904 .89 .897 .811 .849 .829 .447 .382 .412 .903 .890 .897 .814 .850 .831 .143 .026 .043 DeBERTa .927 .899 .913 .825 .880 .851 .467 .419 .442 .920 .893 .906 .823 .877 .849 .375 .077 .128 HateBERT+ALL .903 .896 .899 .827 .827 .827 .502 .559 .529 .903 .881 .892 .816 .844 .830 .391 .462 .424 BERT+BT .909 .887 .898 .824 .826 .825 .459 .608 .523 .898 .900 .899 .839 .832 .835 .304 .359 .329 DeBERTa+BT .919 .885 .902 .830 .857 .844 .428 .543 .479 .920 .897 .908 .835 .876 .855 .385 .256 .308 USE+SVM+BT .897 .856 .876 .782 .787 .785 .403 .645 .496 .892 .868 .880 .789 .831 .809 .739 .436 .548 BERT+RNE .897 .897 .897 .807 .829 .818 .455 .349 .395 .899 .895 .897 .826 .839 .833 .400 .256 .312 DeBERTa+RI .922 .894 .908 .821 .878 .849 .460 .398 .427 .910 .894 .902 .828 .860 .843 .364 .205 .262 HateBERT+GM .901 .898 .899 .824 .827 .825 .414 .425 .419 .899 .898 .899 .831 .834 .832 .250 .231 .240 HateBERT+GM+R. .905 .891 .898 .816 .835 .826 .408 .419 .414 .894 .898 .896 .826 .826 .826 .192 .128 .154</ref>   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusions</head><p>In this paper, we have presented ISHate, the first benchmark dataset annotated with both implicit and subtle HS labels, which represents a challenging test-bed to evaluate computational approaches. We also provide a fine-grained annotation for implicit HS messages with 18 implicit properties which represent the relevant features that HS classifiers should possess to improve implicit HS detection. It has been created enriching 7 existing datasets for HS detection over different topics and from different social media. We have shown that current SOTA models fail to properly detect implicit and subtle HS messages as peculiar features connected to Sentiment, Inference, Context and Irony, as well as complex syntactic structure, cannot be properly understood. We also investigated data augmentation strategies to increase the number of instances for the minority classes. We show that -while they cannot be the ultimate solution to the lack of implicit and subtle examples -they still play a role in improving the systems' performances, in line with <ref type="bibr" target="#b22">ElSherief et al. (2021)</ref>. As for future work, we plan to propose alternative large-scale methods to collect implicit and subtle messages by targeting "hateful" users, manual creation <ref type="bibr">(Wiegand et al., 2021a</ref><ref type="bibr" target="#b52">(Wiegand et al., , 2022) )</ref> or refining human-in-the-loop generative methods as in <ref type="bibr" target="#b31">(Hartvigsen et al., 2022)</ref>. Also, we will investigate features modeling implicit properties <ref type="bibr" target="#b47">(Wallace et al., 2014;</ref><ref type="bibr" target="#b45">Troiano et al., 2018;</ref><ref type="bibr" target="#b26">Frenda and Patti, 2019)</ref> and new model architectures for HS detection <ref type="bibr" target="#b40">(Nejadgholi et al., 2022)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Limitations</head><p>The main limitation of this paper lies in the intrinsic difficulty to provide a clear definition of the notions of Implicit HS and Subtle HS (given the limited number of definitions available in the literature for these notions), and, as a consequence, to build annotated resources. Enhancing the ISHate dataset with new instances requires future annotators to be experts in computational linguistics trained on our annotation guidelines through pilot annotations to keep the same level of agreement. This restricts crowdsourcing-like options, making the resource building process more expensive. Moreover, the complexity of the messages and of the considered categories makes the process time-consuming (i.e., a trained annotator requires 30sec. for explicit messages and 1.30min. for implicit/subtle messages on average). Even opting for generative and synthetic data augmentation approaches, they still require human-in-the-loop intervention and high computational resources to generate Implicit/Subtle HS messages on a big scale.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Performance Details in Data Augmentation</head><p>Inspired by the ranked one augmentation strategy in ElSherief et al. ( <ref type="formula">2021</ref>), i.e., a back-translation approach, we also test SOTA models on our dataset, ISHate, with the augmentation techniques described in Section 4.4. Each model is trained with the originally collected data described in Section 4.3 and additional data obtained from one augmentation strategy. At the end, we also evaluate each model using only non-augmented test data. Tables <ref type="table">6a</ref> and<ref type="table">6b</ref> show the experiments' results on tasks A and B.</p><p>We further analyse the errors committed by the best performing model on task A. We took from Table <ref type="table">6a</ref> HateBERT+ALL and the third annotation layer described in Sections 3 and 4 to identify which are the most frequent implicit properties on task A miss-classified messages.  We also analysed the embeddings of our bestperforming models in tasks A and B (Hate-BERT+ALL and USE+SVM+BT, respectively) through t-SNE (van der <ref type="bibr" target="#b46">Maaten and Hinton, 2008)</ref>. Figures <ref type="figure" target="#fig_1">1</ref> and<ref type="figure" target="#fig_2">2</ref> show the text embeddings for sentences of the test set, labeled by both classifiers and annotators, for the implicit and subtle tasks.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B Implicit Properties</head><p>In the following part, we provide a list of implicit properties with their definitions. All the examples illustrating implicit properties are used in implicit hateful messages and their descriptions are presented in the annotation guidelines.</p><p>Antithesisthe rhetorical contrast of ideas through parallel arrangements of words, clauses, or sentences (as in "action, not words" or "they promised freedom and provided slavery") (Merriam-Webster, 2022)</p><p>Black humorhumor marked by the use of usually morbid, ironic, grotesquely comic episodes; humor treating sinister subjects like death, disease, deformity, handicap or warfare with bitter amusement <ref type="bibr" target="#b55">(Willinger et al., 2017)</ref> Circumlocutionthe use of an unnecessarily large number of words to express an idea <ref type="bibr">(Merriam-Webster, 2022)</ref> Contextthe parts of a discourse that surround a word or passage and can throw light on its meaning <ref type="bibr" target="#b18">(Dadvar et al., 2013)</ref> Euphemismthe substitution of an agreeable or inoffensive expression for one that may suggest something unpleasant <ref type="bibr" target="#b10">(Casas Gómez, 2009)</ref> Exaggeration (hyperbole)an act or instance of exaggerating something: overstatement of the truth <ref type="bibr" target="#b45">(Troiano et al., 2018)</ref> Extralinguistic knowledgeany knowledge that exists outside knowledge of the language. In other words, it refers to knowledge that an author or a recipient of a message may possess about the message itself or about the world, but which is not expressed by any linguistic means.</p><p>Fallacya false or mistaken idea; an often plausible argument using false or invalid inference <ref type="bibr">(Merriam-Webster, 2022)</ref> Humiliationthe embarrassment and shame a person feels when someone makes them appear stupid or when they make a mistake in public <ref type="bibr">(Dictionary, 2022)</ref> Inferencesomething that is inferred. The premises and conclusion of a process of inferring <ref type="bibr">(Merriam-Webster, 2022)</ref> Ironythe use of words to express something other than and especially the opposite of the literal meaning; incongruity between the actual result of a sequence of events and the normal or expected result <ref type="bibr" target="#b42">(Potamias et al., 2020)</ref> Metaphora figure of speech in which a word or phrase literally denoting one kind of object or idea is used in place of another to suggest a likeness or analogy between them <ref type="bibr" target="#b14">(Choi et al., 2021;</ref><ref type="bibr" target="#b27">Gao et al., 2018)</ref> Metonymya figure of speech consisting of the use of the name of one thing for that of another of which it is an attribute or with which it is associated (such as "crown" in "lands belonging to the crown") <ref type="bibr">(Merriam-Webster, 2022)</ref> Rhetorical questiona question not intended to require an answer, used mainly for dramatic effect <ref type="bibr" target="#b24">(Frank, 1990)</ref> Sarcasma mode of satirical wit depending on its effect on bitter, caustic, and often ironic language usually directed against an individual. Sarcasm differs from irony with one distinct characteristic: negativity. Sarcasm is mostly witty mockery having a negative connotation whereas irony does not represent negativity <ref type="bibr" target="#b42">(Potamias et al., 2020)</ref> Sentimentan attitude, thought, or judgment prompted by feeling; the emotional significance of a passage or expression as distinguished from its verbal context <ref type="bibr" target="#b37">(Li et al., 2021)</ref> Synecdochea figure of speech by which a part is put for the whole, the whole for a part, the species for the genus, the genus for the species, or the name of the material for the thing made <ref type="bibr">(Merriam-Webster, 2022)</ref> Visual signspunctuation marks, quotes, and use of uppercase that play a role of support in hate messages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C Annotation Tool Interface</head><p>Figure <ref type="figure">3a</ref> demonstrates a screenshot of the annotation interface of the Label Studio tool used for the labeling process. According to the annotation scheme represented by three annotation layers (discussed in Section 3 and Subsection 4.2) Label Studio has three consecutive annotation steps. The first step consists in implicitness with three choices: Implicit HS, Explicit HS, Undecided, keeping in mind that the tool allows to filter Non-Hate out before starting the labeling process. The first choice of Implicit HS or Explicit HS brings in the appearance of the second step of subtlety with three choices: Subtle, Non-Subtle, Undecided. This step does not appear with an Undecided choice at the previous step. As well as that, the choice of Implicit HS triggers the appearance of the third step which consists of implicit properties being characteristic of only implicit messages. Figure <ref type="figure">3b</ref> shows the shape of the resultant dataset after annotation.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>(a) Embedding using predicted annotations.(b) Embedding using manual annotations.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Embedding of HateBERT + ALL in the test set of task A</figDesc><graphic coords="15,324.57,428.54,181.43,136.07" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Embedding of USE+SVM+BT in the test set of task B</figDesc><graphic coords="15,324.57,581.54,181.43,136.07" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="18,116.21,227.62,362.85,191.38" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Statistics on the annotated dataset (resources and label distributions for the two tasks)</figDesc><table><row><cell>Label Non-HS Explicit HS Implicit HS Non-HS Non-Subtle Subtle</cell><cell>Train # 12508 .614 2680 .614 2681 .614 Dev Test % # % # % 7007 .344 1501 .344 1501 .344 866 .042 186 .043 186 .043 12508 .614 2680 .614 2681 .614 7691 .377 1648 .377 1648 .377 182 .009 39 .009 39 .009</cell><cell>CONAN HatEval IHC MCONAN ToxiGen WSF Youtube 0 7421 0 0 0 9342 1106 324 3107 317 3344 183 987 1747 81 110 300 295 170 173 109 0 7421 0 0 0 9342 1106 393 3191 614 3595 348 1018 1828 12 26 3 44 5 142 28</cell></row><row><cell cols="2">Implicit HS # 729 58.885 % 602 48.627 569 45.961 359 28.998 275 22.213 Extralinguistic knowledge 193 15.590 Implicit Properties Inference Context Sentiment Exaggeration Irony Black humor 144 11.632 Rhetorical question 134 10.824 Visual signs 122 9.855 Humiliation 115 9.289 Antithesis 97 7.835 Metaphor 93 7.512 Sarcasm 85 6.866 Fallacy 74 5.977 Euphemism 56 4.523 Circumlocution 41 3.312 Metonymy 6 0.485 Synecdoche 1 0.081</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Statistics on implicit properties distribution.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 :</head><label>3</label><figDesc>Obtained results on tasks A and B.</figDesc><table><row><cell cols="2">Aug. method RSA AAV RNE Label Implicit HS 6848 7032 828 817 467 6935 748 200 RI RA EDA BT GM GM+Revised 82 23957 ALL Subtle HS 3192 3136 480 210 172 2912 179 200 204 10685</cell></row><row><cell cols="2">(a) Number of additional implicit/subtle messages generated by each augmentation method.</cell></row><row><cell>Aug. method Label Non-HS Explicit HS Implicit HS Non-HS Non-Subtle HS Subtle HS</cell><cell>ORIG RSA AAV RNE .614 .459 .456 .59 .590 .600 RI RA EDA .458 .592 .608 BT GM GM+Revised ALL .611 .282 .344 .257 .256 .33 .331 .336 .257 .332 .340 .342 .158 .042 .283 .288 .08 .079 .064 .286 .076 .052 .046 .560 .614 .531 .532 .600 .607 .609 .537 .608 .608 .608 .403 .377 .326 .327 .369 .374 .374 .330 .374 .374 .374 .248 .009 .143 .141 .032 .019 .017 .133 .018 .019 .019 .350</cell></row><row><cell cols="2">(b) Train set distribution (%) per augmentation method (ORIG corresponds to the original train distribution).</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 4 :</head><label>4</label><figDesc>Statistics on the train set with data augmentation.</figDesc><table><row><cell>model on this task (Figure 2 in Appendix A). How-</cell></row><row><cell>ever, it can be seen that USE+SVM+BT could not</cell></row><row><cell>differentiate correctly on the subtle notion despite</cell></row><row><cell>of the results reported in Table 6b. Example 17</cell></row><row><cell>is not predicted as subtle. It shows how the word</cell></row><row><cell>order may influence our understanding. At a first</cell></row><row><cell>glance, the part how stupid the Jews seems to have</cell></row><row><cell>a different meaning from what the phrase actually</cell></row><row><cell>conveys if we read it entirely. We may also notice</cell></row><row><cell>a circumlocution in the second part of the message.</cell></row><row><cell>17. I am insulted by how stupid the jews think we</cell></row><row><cell>are until i see what they see by reading the</cell></row><row><cell>posts amongst our so called , ' ' awakened</cell></row><row><cell>brethren .</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head></head><label></label><figDesc>Table 5 shows how Inference, Context, Sentiment, Exaggeration, and Extralinguistic knowledge are the most recurrent not captured devices.</figDesc><table><row><cell>Implicit HS # % 44 53.659 34 41.463 33 40.244 23 28.049 Extralinguistic knowledge 20 24.390 Implicit Property Inference Context Sentiment Exaggeration Irony 17 20.732 Black humor 12 14.634 Visual signs 11 13.415 Metaphor 9 10.976 Rhetorical question 8 9.756 Antithesis 6 7.317 Humiliation 5 6.098 Sarcasm 5 6.098 Circumlocution 4 4.878 Fallacy 4 4.878 Euphemism 3 3.659</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 5 :</head><label>5</label><figDesc>Implicit properties of the messages that are not captured by HateBERT+ALL .</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>The annotated corpora, and the accompanying annotation guidelines and software can be found at https://github. com/benjaminocampo/ISHate</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p>This work has been supported by the <rs type="funder">French government</rs>, through the <rs type="funder">3IA Côte d'Azur Investments</rs> in the Future project managed by the <rs type="funder">National Research Agency (ANR)</rs> with the reference number <rs type="grantNumber">ANR-19-P3IA-0002</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_zxmGz5x">
					<idno type="grant-number">ANR-19-P3IA-0002</idno>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Ethics Statement</head><p>This paper contains examples of HS from existing linguistic resources for HS detection and which do not reflect the authors' opinions.</p><p>While our purpose is to prevent and curate social media resources from HS, the release of this dataset might still pose a potential misuse case. However, we still consider that effective classifiers for this task are necessary to tackle implicit and subtle online hate on scale and prevent the spreading of this harmful content online. Our work aims at making a step towards that objective and encourages the scientific community to investigate these aspects.    </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">FLAIR: An easy-to-use framework for state-of-theart NLP</title>
		<author>
			<persName><forename type="first">Alan</forename><surname>Akbik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tanja</forename><surname>Bergmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Duncan</forename><surname>Blythe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kashif</forename><surname>Rasul</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefan</forename><surname>Schweter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roland</forename><surname>Vollgraf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Annual Conference of the North American Chapter of the Association for Computational Linguistics (Demonstrations)</title>
		<imprint>
			<date type="published" when="2019">2019. 2019</date>
			<biblScope unit="page" from="54" to="59" />
		</imprint>
	</monogr>
	<note>NAACL 2019</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Survey article: Inter-coder agreement for computational linguistics</title>
		<author>
			<persName><forename type="first">Ron</forename><surname>Artstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Massimo</forename><surname>Poesio</surname></persName>
		</author>
		<idno type="DOI">10.1162/coli.07-034-R2</idno>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="555" to="596" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Deep learning for hate speech detection in tweets</title>
		<author>
			<persName><forename type="first">Pinkesh</forename><surname>Badjatiya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shashank</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Manish</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vasudeva</forename><surname>Varma</surname></persName>
		</author>
		<idno>CoRR, abs/1706.00188</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">SemEval-2019 Task 5: Multilingual Detection of Hate Speech Against Immigrants and Women in Twitter</title>
		<author>
			<persName><forename type="first">Cristina</forename><surname>Valerio Basile</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elisabetta</forename><surname>Bosco</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Debora</forename><surname>Fersini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Viviana</forename><surname>Nozza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Francisco</forename><surname>Patti</surname></persName>
		</author>
		<author>
			<persName><surname>Manuel Rangel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paolo</forename><surname>Pardo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Manuela</forename><surname>Rosso</surname></persName>
		</author>
		<author>
			<persName><surname>Sanguinetti</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/S19-2007</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th International Workshop on Semantic Evaluation</title>
		<meeting>the 13th International Workshop on Semantic Evaluation<address><addrLine>Minneapolis, Minnesota, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="54" to="63" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">What Does This Imply? Examining the Impact of Implicitness on the Perception of Hate Speech</title>
		<author>
			<persName><forename type="first">Darina</forename><surname>Benikova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Wojatzki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Torsten</forename><surname>Zesch</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-319-73706-5_14</idno>
	</analytic>
	<monogr>
		<title level="m">Language Technologies for the Challenges of the Digital Age</title>
		<imprint>
			<publisher>Cham. Springer International Publishing</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="171" to="179" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">On denoting</title>
		<author>
			<persName><forename type="first">Russell</forename><surname>Bertrand</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mind</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="issue">14</biblScope>
			<biblScope unit="page" from="479" to="493" />
			<date type="published" when="1905">1905</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">NLTK: The natural language toolkit</title>
		<author>
			<persName><forename type="first">Steven</forename><surname>Bird</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Edward</forename><surname>Loper</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACL Interactive Poster and Demonstration Sessions</title>
		<meeting>the ACL Interactive Poster and Demonstration Sessions<address><addrLine>Barcelona, Spain</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="214" to="217" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A dataset of Hindi-English code-mixed social media text for hate speech detection</title>
		<author>
			<persName><forename type="first">Aditya</forename><surname>Bohra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Deepanshu</forename><surname>Vijay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vinay</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Syed</forename><surname>Sarfaraz Akhtar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Manish</forename><surname>Shrivastava</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/W18-1105</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Second Workshop on Computational Modeling of People&apos;s Opinions, Personality, and Emotions in Social Media</title>
		<meeting>the Second Workshop on Computational Modeling of People&apos;s Opinions, Personality, and Emotions in Social Media<address><addrLine>New Orleans, Louisiana, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="36" to="41" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Enriching word vectors with subword information</title>
		<author>
			<persName><forename type="first">Piotr</forename><surname>Bojanowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Edouard</forename><surname>Grave</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Armand</forename><surname>Joulin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tomás</forename><surname>Mikolov</surname></persName>
		</author>
		<idno>CoRR, abs/1607.04606</idno>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Finding Microaggressions in the Wild: A Case for Locating Elusive Phenomena in Social Media Posts</title>
		<author>
			<persName><forename type="first">Luke</forename><surname>Breitfeller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Emily</forename><surname>Ahn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Jurgens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yulia</forename><surname>Tsvetkov</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D19-1176</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1664" to="1674" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Towards a new approach to the linguistic definition of euphemism</title>
		<author>
			<persName><forename type="first">Miguel</forename><surname>Casas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gómez</forename></persName>
		</author>
		<idno type="DOI">10.1016/j.langsci.2009.05.001</idno>
	</analytic>
	<monogr>
		<title level="j">Language Sciences</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="725" to="739" />
			<date type="published" when="2006">2009. 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">HateBERT: Retraining BERT for abusive language detection in English</title>
		<author>
			<persName><forename type="first">Tommaso</forename><surname>Caselli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Valerio</forename><surname>Basile</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jelena</forename><surname>Mitrović</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Granitzer</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.woah-1.3</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 5th Workshop on Online Abuse and Harms (WOAH 2021)</title>
		<meeting>the 5th Workshop on Online Abuse and Harms (WOAH 2021)</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="17" to="25" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">I Feel Offended, Don&apos;t Be Abusive! Implicit/Explicit Messages in Offensive and Abusive Language</title>
		<author>
			<persName><forename type="first">Tommaso</forename><surname>Caselli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Valerio</forename><surname>Basile</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jelena</forename><surname>Mitrović</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Inga</forename><surname>Kartoziya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Granitzer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12th Language Resources and Evaluation Conference</title>
		<meeting>the 12th Language Resources and Evaluation Conference<address><addrLine>Marseille, France</addrLine></address></meeting>
		<imprint>
			<publisher>European Language Resources Association</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="6193" to="6202" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Universal sentence encoder</title>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Cer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yinfei</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sheng-Yi</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nan</forename><surname>Hua</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicole</forename><surname>Limtiaco</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rhomni</forename><surname>St</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noah</forename><surname>John</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mario</forename><surname>Constant</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Steve</forename><surname>Guajardo-Cespedes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yun-Hsuan</forename><surname>Tar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brian</forename><surname>Sung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ray</forename><surname>Strope</surname></persName>
		</author>
		<author>
			<persName><surname>Kurzweil</surname></persName>
		</author>
		<idno>CoRR, abs/1803.11175</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">MelBERT: Metaphor Detection via Contextualized Late Interaction using Metaphorical Identification Theories</title>
		<author>
			<persName><forename type="first">Minjin</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sunkyung</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eunseong</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Heesoo</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junhyuk</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dongwon</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jongwuk</forename><surname>Lee</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2104.13615</idno>
		<idno type="arXiv">arXiv:2104.13615arXiv:2104.13615</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">CONAN -COunter NArratives through nichesourcing: a multilingual dataset of responses to fight online hate speech</title>
		<author>
			<persName><forename type="first">Yi-Ling</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elizaveta</forename><surname>Kuzmenko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Serra</forename><surname>Sinem Tekiroglu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marco</forename><surname>Guerini</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P19-1271</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 57th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="2819" to="2829" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A coefficient of agreement for nominal scales</title>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Cohen</surname></persName>
		</author>
		<idno type="DOI">10.1177/001316446002000104</idno>
	</analytic>
	<monogr>
		<title level="j">Educational and Psychological Measurement</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="37" to="46" />
			<date type="published" when="1960">1960</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">A multilingual evaluation for online hate speech detection</title>
		<author>
			<persName><forename type="first">Michele</forename><surname>Corazza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefano</forename><surname>Menini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elena</forename><surname>Cabrio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sara</forename><surname>Tonelli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Serena</forename><surname>Villata</surname></persName>
		</author>
		<idno type="DOI">10.1145/3377323</idno>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Internet Technol</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Improving cyberbullying detection with user context</title>
		<author>
			<persName><forename type="first">Maral</forename><surname>Dadvar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dolf</forename><surname>Trieschnigg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roeland</forename><surname>Ordelman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Franciska</forename><surname>De</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jong</forename></persName>
		</author>
		<idno type="DOI">10.1007/978-3-642-36973-5_62</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 35th European Conference on Advances in Information Retrieval, ECIR&apos;13</title>
		<meeting>the 35th European Conference on Advances in Information Retrieval, ECIR&apos;13<address><addrLine>Berlin, Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="693" to="696" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Hate Speech Dataset from a White Supremacy Forum</title>
		<author>
			<persName><forename type="first">Ona</forename><surname>De Gibert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Naiara</forename><surname>Perez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aitor</forename><surname>García-Pablos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Montse</forename><surname>Cuadros</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1809.04444</idno>
		<idno>ArXiv: 1809.04444</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">BERT: pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<idno>CoRR, abs/1810.04805</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Collins dictionary</title>
		<imprint>
			<date type="published" when="2022">2022</date>
			<publisher>Collins Dictionary</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Latent hatred: A benchmark for understanding implicit hate speech</title>
		<author>
			<persName><forename type="first">Mai</forename><surname>Elsherief</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Caleb</forename><surname>Ziems</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Muchlinski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vaishnavi</forename><surname>Anupindi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jordyn</forename><surname>Seybolt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Munmun</forename><forename type="middle">De</forename><surname>Choudhury</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Diyi</forename><surname>Yang</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.emnlp-main.29</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2021 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Punta Cana, Dominican Republic</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="345" to="363" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Human-in-the-Loop for Data Collection: a Multi-Target Counter Narrative Dataset to Fight Online Hate Speech</title>
		<author>
			<persName><forename type="first">Margherita</forename><surname>Fanton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Helena</forename><surname>Bonaldi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Serra</forename><surname>Sinem Tekiroglu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marco</forename><surname>Guerini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics</title>
		<title level="s">Association for Computational Linguistics</title>
		<meeting>the 59th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">You call that a rhetorical question?: Forms and functions of rhetorical questions in conversation</title>
		<author>
			<persName><forename type="first">Jane</forename><surname>Frank</surname></persName>
		</author>
		<idno type="DOI">10.1016/0378-2166(90)90003-V</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Pragmatics</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="723" to="738" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">The unbearable hurtfulness of sarcasm</title>
		<author>
			<persName><forename type="first">Simona</forename><surname>Frenda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alessandra</forename><forename type="middle">Teresa</forename><surname>Cignarella</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Valerio</forename><surname>Basile</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cristina</forename><surname>Bosco</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Viviana</forename><surname>Patti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paolo</forename><surname>Rosso</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.eswa.2021.116398</idno>
	</analytic>
	<monogr>
		<title level="j">Expert Syst. Appl</title>
		<imprint>
			<biblScope unit="volume">193</biblScope>
			<biblScope unit="issue">C</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Computational Models for Irony Detection in Three Spanish Variants</title>
		<author>
			<persName><forename type="first">Simona</forename><surname>Frenda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Viviana</forename><surname>Patti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Björn</forename><surname>Gambäck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Utpal</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sikdar</forename></persName>
		</author>
		<idno type="DOI">10.18653/v1/W17-3013</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First Workshop on Abusive Language Online</title>
		<meeting>the First Workshop on Abusive Language Online<address><addrLine>Vancouver, BC, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017">2019. 2017</date>
			<biblScope unit="page" from="85" to="90" />
		</imprint>
	</monogr>
	<note>Using convolutional neural networks to classify hate-speech</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Neural Metaphor Detection in Context</title>
		<author>
			<persName><forename type="first">Ge</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eunsol</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yejin</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D18-1060</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Brussels, Belgium</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="607" to="613" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Logic and conversation</title>
		<author>
			<persName><forename type="first">Herbert</forename><surname>Paul</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Grice</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Studies in the Way of Words</title>
		<editor>
			<persName><forename type="first">Paul</forename><surname>Grice</surname></persName>
		</editor>
		<imprint>
			<publisher>Harvard University Press</publisher>
			<date type="published" when="1967">1967</date>
			<biblScope unit="page" from="41" to="58" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<author>
			<persName><forename type="first">Herbert</forename><surname>Paul</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Grice</forename></persName>
		</author>
		<title level="m">Studies in the Way of Words</title>
		<meeting><address><addrLine>Cambridge</addrLine></address></meeting>
		<imprint>
			<publisher>Harvard University Press</publisher>
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Automatic Detection of Hateful Comments in Online Discussion</title>
		<author>
			<persName><forename type="first">Lewi</forename><surname>Hugo</surname></persName>
		</author>
		<author>
			<persName><surname>Hammer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Industrial Networks and Intelligent Systems</title>
		<imprint>
			<publisher>Cham. Springer International Publishing</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="164" to="173" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">ToxiGen: A Large-Scale Machine-Generated Dataset for Adversarial and Implicit Hate Speech Detection</title>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Hartvigsen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Saadia</forename><surname>Gabriel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hamid</forename><surname>Palangi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maarten</forename><surname>Sap</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dipankar</forename><surname>Ray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ece</forename><surname>Kamar</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2203.09509</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">a. Debertav3: Improving deberta using electra-style pretraining with gradient-disentangled embedding sharing</title>
		<author>
			<persName><forename type="first">Pengcheng</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weizhu</forename><surname>Chen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007">2021. 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Deberta: Decoding-enhanced bert with disentangled attention</title>
		<author>
			<persName><forename type="first">Pengcheng</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaodong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weizhu</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">FERMI at SemEval-2019 task 5: Using sentence embeddings to identify hate speech against immigrants and women in Twitter</title>
		<author>
			<persName><forename type="first">Vijayasaradhi</forename><surname>Indurthi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bakhtiyar</forename><surname>Syed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Manish</forename><surname>Shrivastava</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nikhil</forename><surname>Chakravartula</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Manish</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vasudeva</forename><surname>Varma</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/S19-2009</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th International Workshop on Semantic Evaluation</title>
		<meeting>the 13th International Workshop on Semantic Evaluation<address><addrLine>Minneapolis, Minnesota, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="70" to="74" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">A just and comprehensive strategy for using NLP to address online abuse</title>
		<author>
			<persName><forename type="first">David</forename><surname>Jurgens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Libby</forename><surname>Hemphill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eshwar</forename><surname>Chandrasekharan</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P19-1357</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 57th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="3658" to="3666" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Pragmatics</title>
		<author>
			<persName><forename type="first">Kepa</forename><surname>Korta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Perry</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Stanford Encyclopedia of Philosophy</title>
		<editor>
			<persName><forename type="first">Edward</forename><forename type="middle">N</forename><surname>Zalta</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2020">2020. Spring 2020</date>
		</imprint>
		<respStmt>
			<orgName>Stanford University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Metaphysics Research Lab</note>
	<note>edition</note>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Learning implicit sentiment in aspect-based sentiment analysis with supervised contrastive pre-training</title>
		<author>
			<persName><forename type="first">Zhengyan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yicheng</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chong</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhongyu</forename><surname>Wei</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.emnlp-main.22</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2021 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Online and Punta Cana, Dominican Republic</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="246" to="256" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Generating adversarial examples for topic-dependent argument classification</title>
		<author>
			<persName><forename type="first">Tobias</forename><surname>Mayer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Santiago</forename><surname>Marro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elena</forename><surname>Cabrio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Serena</forename><surname>Villata</surname></persName>
		</author>
		<idno type="DOI">10.3233/FAIA200489</idno>
	</analytic>
	<monogr>
		<title level="m">Computational Models of Argument -Proceedings of COMMA 2020</title>
		<meeting><address><addrLine>Perugia, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>IOS Press</publisher>
			<date type="published" when="2020-09-04">2020. September 4-11, 2020</date>
			<biblScope unit="volume">326</biblScope>
			<biblScope unit="page" from="33" to="44" />
		</imprint>
	</monogr>
	<note>Frontiers in Artificial Intelligence and Applications</note>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m">Facebook: Hate speech policies</title>
		<imprint>
			<publisher>Dictionary. Meta</publisher>
			<date type="published" when="2022">2022. 2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Improving generalizability in implicitly abusive language detection with concept activation vectors</title>
		<author>
			<persName><forename type="first">Isar</forename><surname>Nejadgholi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kathleen</forename><surname>Fraser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Svetlana</forename><surname>Kiritchenko</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2022.acl-long.378</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 60th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Dublin, Ireland</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="5517" to="5529" />
		</imprint>
	</monogr>
	<note>: Long Papers)</note>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Resources and benchmark corpora for hate speech detection: a systematic review</title>
		<author>
			<persName><forename type="first">Fabio</forename><surname>Poletto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Valerio</forename><surname>Basile</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Manuela</forename><surname>Sanguinetti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cristina</forename><surname>Bosco</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Viviana</forename><surname>Patti</surname></persName>
		</author>
		<idno type="DOI">10.1007/s10579-020-09502-8</idno>
	</analytic>
	<monogr>
		<title level="j">Language Resources and Evaluation</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="477" to="523" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">A transformerbased approach to irony and sarcasm detection</title>
		<author>
			<persName><forename type="first">Rolandos Alexandros</forename><surname>Potamias</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Georgios</forename><surname>Siolas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andreas</forename><forename type="middle">Georgios</forename><surname>Stafylopatis</surname></persName>
		</author>
		<idno type="DOI">10.1007/s00521-020-05102-3</idno>
	</analytic>
	<monogr>
		<title level="j">Neural Computing and Applications</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">23</biblScope>
			<biblScope unit="page" from="17309" to="17320" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">Language models are unsupervised multitask learners</title>
		<author>
			<persName><forename type="first">Alec</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeff</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rewon</forename><surname>Child</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dario</forename><surname>Amodei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Elements of semiology / Roland Barthes</title>
		<author>
			<persName><forename type="first">Barthes</forename><surname>Roland</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Annette</forename><surname>Lavers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Smith</forename><surname>Colin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">translated from the French by Annette Lavers and Colin Smith</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Hill and Wang</publisher>
			<date type="published" when="1968">1968</date>
		</imprint>
	</monogr>
	<note>1st american ed. edition</note>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">A computational exploration of exaggeration</title>
		<author>
			<persName><forename type="first">Enrica</forename><surname>Troiano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carlo</forename><surname>Strapparava</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gözde</forename><surname>Özbal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Serra</forename><surname>Sinem</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tekiroglu</forename></persName>
		</author>
		<idno type="DOI">10.18653/v1/D18-1367</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Brussels, Belgium</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="3296" to="3304" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Visualizing data using t-sne</title>
		<author>
			<persName><forename type="first">Laurens</forename><surname>Van Der Maaten</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">86</biblScope>
			<biblScope unit="page" from="2579" to="2605" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Humans require context to infer ironic intent (so computers probably do, too)</title>
		<author>
			<persName><forename type="first">Byron</forename><forename type="middle">C</forename><surname>Wallace</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Do</forename><surname>Kook Choe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Laura</forename><surname>Kertz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eugene</forename><surname>Charniak</surname></persName>
		</author>
		<idno type="DOI">10.3115/v1/P14-2084</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 52nd Annual Meeting of the Association for Computational Linguistics<address><addrLine>Baltimore, Maryland</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="512" to="516" />
		</imprint>
	</monogr>
	<note>: Short Papers)</note>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Detecting hate speech on the world wide web</title>
		<author>
			<persName><forename type="first">William</forename><surname>Warner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julia</forename><surname>Hirschberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Second Workshop on Language in Social Media</title>
		<meeting>the Second Workshop on Language in Social Media<address><addrLine>Montréal, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="19" to="26" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Understanding abuse: A typology of abusive language detection subtasks</title>
		<author>
			<persName><forename type="first">Zeerak</forename><surname>Waseem</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Davidson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dana</forename><surname>Warmsley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ingmar</forename><surname>Weber</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/W17-3012</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First Workshop on Abusive Language Online</title>
		<meeting>the First Workshop on Abusive Language Online<address><addrLine>Vancouver, BC, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="78" to="84" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Hateful symbols or hateful people? predictive features for hate speech detection on Twitter</title>
		<author>
			<persName><forename type="first">Zeerak</forename><surname>Waseem</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dirk</forename><surname>Hovy</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N16-2013</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the NAACL Student Research Workshop</title>
		<meeting>the NAACL Student Research Workshop<address><addrLine>San Diego, California</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="88" to="93" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<title level="m" type="main">EDA: Easy Data Augmentation Techniques for Boosting Performance on Text Classification Tasks</title>
		<author>
			<persName><forename type="first">Jason</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kai</forename><surname>Zou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1901.11196</idno>
		<idno>ArXiv:1901.11196</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">Technical Report</note>
	<note>type: article</note>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Identifying Implicitly Abusive Remarks about Identity Groups using a Linguistically Informed Approach</title>
		<author>
			<persName><forename type="first">Michael</forename><surname>Wiegand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elisabeth</forename><surname>Eder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Josef</forename><surname>Ruppenhofer</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2022.naacl-main.410</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Seattle, United States</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="5600" to="5612" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">a. Implicitly abusive comparisons -a new dataset and linguistic analysis</title>
		<author>
			<persName><forename type="first">Michael</forename><surname>Wiegand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maja</forename><surname>Geulig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Josef</forename><surname>Ruppenhofer</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.eacl-main.27</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume</title>
		<meeting>the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="358" to="368" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Implicitly abusive language -what does it actually look like and why are we not getting there</title>
		<author>
			<persName><forename type="first">Michael</forename><surname>Wiegand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Josef</forename><surname>Ruppenhofer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elisabeth</forename><surname>Eder</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.naacl-main.48</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="576" to="587" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Cognitive and emotional demands of black humour processing: the role of intelligence, aggressiveness and mood</title>
		<author>
			<persName><forename type="first">Ulrike</forename><surname>Willinger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andreas</forename><surname>Hergovich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michaela</forename><surname>Schmoeger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthias</forename><surname>Deckert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Susanne</forename><surname>Stoettner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Iris</forename><surname>Bunda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrea</forename><surname>Witting</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Melanie</forename><surname>Seidler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Reinhilde</forename><surname>Moser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefanie</forename><surname>Kacena</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Jaeckle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Loader</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christian</forename><surname>Mueller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eduard</forename><surname>Auff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cogn. Process</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="159" to="167" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Learning from bullying traces in social media</title>
		<author>
			<persName><forename type="first">Jun-Ming</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kwang-Sung</forename><surname>Jun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaojin</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amy</forename><surname>Bellmore</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<title level="s">Association for Computational Linguistics</title>
		<meeting>the 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Montréal, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="656" to="666" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Predicting the type and target of offensive posts in social media</title>
		<author>
			<persName><forename type="first">Marcos</forename><surname>Zampieri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shervin</forename><surname>Malmasi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Preslav</forename><surname>Nakov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sara</forename><surname>Rosenthal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noura</forename><surname>Farra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ritesh</forename><surname>Kumar</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N19-1144</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Minneapolis, Minnesota</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1415" to="1420" />
		</imprint>
	</monogr>
	<note>Long and Short Papers</note>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Semeval-2019 task 6: Identifying and categorizing offensive language in social media (offenseval)</title>
		<author>
			<persName><forename type="first">Marcos</forename><surname>Zampieri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shervin</forename><surname>Malmasi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Preslav</forename><surname>Nakov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sara</forename><surname>Rosenthal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noura</forename><surname>Farra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ritesh</forename><surname>Kumar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th International Workshop on Semantic Evaluation</title>
		<meeting>the 13th International Workshop on Semantic Evaluation</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="75" to="86" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<monogr>
		<title level="m" type="main">Hate speech detection: A solved problem? the challenging case of long tail on twitter</title>
		<author>
			<persName><forename type="first">Ziqi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lei</forename><surname>Luo</surname></persName>
		</author>
		<idno>CoRR, abs/1803.03662</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
