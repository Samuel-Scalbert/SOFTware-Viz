{"application": "software-mentions", "version": "0.8.0", "date": "2024-10-07T11:54+0000", "md5": "AC30687EA2BEE3A57652414B0F10964D", "mentions": [{"type": "software", "software-type": "software", "software-name": {"rawForm": "Bing", "normalizedForm": "Bing", "offsetStart": 41, "offsetEnd": 45}, "context": "Two complementary datasets named IPM and Bing, which were initially introduced in (Mohanty et al., 2016), are used in this work to evaluate the robustness of a model for predicting plant diseases on exterior images. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.00012350082397460938}, "created": {"value": true, "score": 0.7844283580780029}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999920129776001}, "created": {"value": true, "score": 0.7844283580780029}, "shared": {"value": false, "score": 5.960464477539062e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Bing", "normalizedForm": "Bing", "offsetStart": 42, "offsetEnd": 46}, "context": "Next, by analyzing the performance of the Bing images (Supplementary Table 7-12), we observed that with the exception of the VGG16 model pre-trained on PlantCLEF2015 (Supplementary Table 10), which has the correct prediction for all the images of Potato Late blight, the rest of the model configurations show major classification errors, confusing these images with Tomato Late blight, which is actually related to the same common name of disease but on different crops.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999798536300659}, "created": {"value": false, "score": 1.7881393432617188e-06}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999920129776001}, "created": {"value": true, "score": 0.7844283580780029}, "shared": {"value": false, "score": 5.960464477539062e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Bing", "normalizedForm": "Bing", "offsetStart": 51, "offsetEnd": 55}, "context": "Tables 3 and4 show the distribution of the IPM and Bing images. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.986035943031311}, "created": {"value": false, "score": 2.4199485778808594e-05}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999920129776001}, "created": {"value": true, "score": 0.7844283580780029}, "shared": {"value": false, "score": 5.960464477539062e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Bing", "normalizedForm": "Bing", "offsetStart": 54, "offsetEnd": 58}, "context": "If not, it might suggest that the size of the IPM and Bing is too small to generalize the results.", "mentionContextAttributes": {"used": {"value": true, "score": 0.5213826894760132}, "created": {"value": false, "score": 9.965896606445312e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999920129776001}, "created": {"value": true, "score": 0.7844283580780029}, "shared": {"value": false, "score": 5.960464477539062e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "PlantCLEF", "normalizedForm": "PlantCLEF", "offsetStart": 65, "offsetEnd": 74}, "version": {"rawForm": "2015", "normalizedForm": "2015"}, "context": "As for the GoogLeNetBN and InceptionV3, the model pre-trained on PlantCLEF2015 leads to better performance than the one pre-trained on the ImageNet dataset, unlike the VGG16. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.006634891033172607}, "created": {"value": false, "score": 5.2928924560546875e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999798536300659}, "created": {"value": false, "score": 0.011286377906799316}, "shared": {"value": false, "score": 3.5762786865234375e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LifeCLEF", "normalizedForm": "LifeCLEF", "offsetStart": 65, "offsetEnd": 93}, "context": "This dataset is related to the plant identification challenge in LifeCLEF (Joly et al., 2015) and addresses the problem of species identification based on multi-organ and multi-image observations of specimens. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0350918173789978}, "created": {"value": false, "score": 0.00014793872833251953}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.0350918173789978}, "created": {"value": false, "score": 0.00014793872833251953}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Bing", "normalizedForm": "Bing", "offsetStart": 69, "offsetEnd": 73}, "context": "A qualitative assessment of the data, as shown in Fig. 1, shows that Bing images contain background noise (i.e. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9794414043426514}, "created": {"value": false, "score": 7.510185241699219e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999920129776001}, "created": {"value": true, "score": 0.7844283580780029}, "shared": {"value": false, "score": 5.960464477539062e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Bing", "normalizedForm": "Bing", "offsetStart": 73, "offsetEnd": 77}, "context": "However, by comparing the overall top-1 accuracy of the combined IPM and Bing images, the  VGG16 pre-trained with the ImageNet dataset shows a better result than the one pre-trained with PlantCLEF2015, which are 44.54% and 36.13%", "mentionContextAttributes": {"used": {"value": true, "score": 0.9959630370140076}, "created": {"value": false, "score": 3.814697265625e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999920129776001}, "created": {"value": true, "score": 0.7844283580780029}, "shared": {"value": false, "score": 5.960464477539062e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "PlantCLEF", "normalizedForm": "PlantCLEF", "offsetStart": 78, "offsetEnd": 87}, "version": {"rawForm": "2015", "normalizedForm": "2015"}, "context": "For example, in Fig. 5b, the GoogLeNetBN models pre-trained with ImageNet and PlantCLEF2015 concentrate mainly on the center of the leaf, while the VGG16 models mostly focus on infected secondary veins. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.34945976734161377}, "created": {"value": false, "score": 1.2278556823730469e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999798536300659}, "created": {"value": false, "score": 0.011286377906799316}, "shared": {"value": false, "score": 3.5762786865234375e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Bing", "normalizedForm": "Bing", "offsetStart": 79, "offsetEnd": 83}, "context": "Next, we analyzed the performance of deep models to identify new data (IPM and Bing) from other domains, typically pictures in the field.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999904632568359}, "created": {"value": false, "score": 0.012801110744476318}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999920129776001}, "created": {"value": true, "score": 0.7844283580780029}, "shared": {"value": false, "score": 5.960464477539062e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "PlantCLEF", "normalizedForm": "PlantCLEF", "offsetStart": 83, "offsetEnd": 92}, "version": {"rawForm": "2015", "normalizedForm": "2015", "offsetStart": 92, "offsetEnd": 96}, "context": "For example, in Fig. 5a, both the GoogLeNetBN models pre-trained with ImageNet and PlantCLEF2015 are activated by areas of yellowish venation, while the VGG16 models are activated by areas infected with large brown spots with yellow tissues around. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.37773406505584717}, "created": {"value": false, "score": 7.62939453125e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999798536300659}, "created": {"value": false, "score": 0.011286377906799316}, "shared": {"value": false, "score": 3.5762786865234375e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Bing", "normalizedForm": "Bing", "offsetStart": 85, "offsetEnd": 89}, "context": "Note that there are only two pepper crop images in IPM, and one pepper crop image in Bing, of which the number of samples is insufficient to infer the performance of deep models in recognizing the disease of an unseen crop.", "mentionContextAttributes": {"used": {"value": false, "score": 0.022726833820343018}, "created": {"value": false, "score": 1.4066696166992188e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999920129776001}, "created": {"value": true, "score": 0.7844283580780029}, "shared": {"value": false, "score": 5.960464477539062e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Bing", "normalizedForm": "Bing", "offsetStart": 88, "offsetEnd": 92}, "context": "It is difficult to conclude which pre-training task works best for the external IPM and Bing test data mainly because the size of these two set of images is quite small.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0032744407653808594}, "created": {"value": false, "score": 5.364418029785156e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999920129776001}, "created": {"value": true, "score": 0.7844283580780029}, "shared": {"value": false, "score": 5.960464477539062e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Bing", "normalizedForm": "Bing", "offsetStart": 89, "offsetEnd": 93}, "context": "From Table 6, we can see that S co approach in general works better than S cd on IPM and Bing.", "mentionContextAttributes": {"used": {"value": false, "score": 0.003580927848815918}, "created": {"value": false, "score": 0.0010251998901367188}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999920129776001}, "created": {"value": true, "score": 0.7844283580780029}, "shared": {"value": false, "score": 5.960464477539062e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Bing", "normalizedForm": "Bing", "offsetStart": 90, "offsetEnd": 94}, "context": "Among the 38 crop-disease pairs in PV, the IPM test set allows to evaluate 19 pairs while Bing test set allows to evaluate 26 pairs. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.004904747009277344}, "created": {"value": false, "score": 2.6226043701171875e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999920129776001}, "created": {"value": true, "score": 0.7844283580780029}, "shared": {"value": false, "score": 5.960464477539062e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Bing", "normalizedForm": "Bing", "offsetStart": 93, "offsetEnd": 97}, "context": "cluttered backgrounds) more often than IPM image, suggesting a more difficult recognition on Bing than on IPM.", "mentionContextAttributes": {"used": {"value": false, "score": 0.3769534230232239}, "created": {"value": false, "score": 9.5367431640625e-06}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999920129776001}, "created": {"value": true, "score": 0.7844283580780029}, "shared": {"value": false, "score": 5.960464477539062e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "PlantCLEF", "normalizedForm": "PlantCLEF", "offsetStart": 94, "offsetEnd": 103}, "version": {"rawForm": "2015", "normalizedForm": "2015"}, "context": "For the FTPC configuration, a model is first pre-trained with ImageNet, then finetuned on the PlantCLEF2015 dataset before being fine-tuned on the PV dataset.", "mentionContextAttributes": {"used": {"value": false, "score": 0.37572407722473145}, "created": {"value": false, "score": 2.5033950805664062e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999798536300659}, "created": {"value": false, "score": 0.011286377906799316}, "shared": {"value": false, "score": 3.5762786865234375e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Bing", "normalizedForm": "Bing", "offsetStart": 99, "offsetEnd": 103}, "context": "However, in our experiments, the generalization performances of the models were studied on IPM and Bing, which is currently the only field test set available online with verified field truth. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999802112579346}, "created": {"value": false, "score": 0.004959523677825928}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999920129776001}, "created": {"value": true, "score": 0.7844283580780029}, "shared": {"value": false, "score": 5.960464477539062e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Bing", "normalizedForm": "Bing", "offsetStart": 112, "offsetEnd": 116}, "context": "Unlike what is generally observed in many other areas, the VGG16 model achieves the best performance on IPM and Bing test sets, 44.54% and 28.13% respectively, surpassing deeper architectures.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0009912848472595215}, "created": {"value": false, "score": 0.00020676851272583008}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999920129776001}, "created": {"value": true, "score": 0.7844283580780029}, "shared": {"value": false, "score": 5.960464477539062e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "PlantCLEF", "normalizedForm": "PlantCLEF", "offsetStart": 117, "offsetEnd": 126}, "version": {"rawForm": "2015", "normalizedForm": "2015", "offsetStart": 126, "offsetEnd": 130}, "context": "However, the class of pepper leaves with bacteria spots shows a contrary result where the model pre-trained with the PlantCLEF2015 (65.75%) is better than the one pre-trained with the ImageNet (43.06%).", "mentionContextAttributes": {"used": {"value": true, "score": 0.716288149356842}, "created": {"value": false, "score": 1.1682510375976562e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999798536300659}, "created": {"value": false, "score": 0.011286377906799316}, "shared": {"value": false, "score": 3.5762786865234375e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "PlantCLEF", "normalizedForm": "PlantCLEF", "offsetStart": 137, "offsetEnd": 146}, "version": {"rawForm": "2015", "normalizedForm": "2015", "offsetStart": 146, "offsetEnd": 150}, "context": "Therefore, in this study, we compare two finetuning strategies, one directly using a model pre-trained on ImageNet and another one using PlantCLEF2015, a dataset dedicated to plant identification (H. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9793939590454102}, "created": {"value": false, "score": 0.011286377906799316}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999798536300659}, "created": {"value": false, "score": 0.011286377906799316}, "shared": {"value": false, "score": 3.5762786865234375e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Bing", "normalizedForm": "Bing", "offsetStart": 152, "offsetEnd": 156}, "context": "We were able to retrieve all the 119 images from IPM6 mentioned in (Mohanty et al., 2016), but we could only retrieve 64 of the 121 images expected for Bing 6 (missing images are no longer available online). ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9995896220207214}, "created": {"value": false, "score": 9.799003601074219e-05}, "shared": {"value": false, "score": 5.960464477539062e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999920129776001}, "created": {"value": true, "score": 0.7844283580780029}, "shared": {"value": false, "score": 5.960464477539062e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "PlantCLEF", "normalizedForm": "PlantCLEF", "offsetStart": 152, "offsetEnd": 161}, "version": {"rawForm": "2015", "normalizedForm": "2015", "offsetStart": 161, "offsetEnd": 165}, "context": "Next, by analyzing the performance of the Bing images (Supplementary Table 7-12), we observed that with the exception of the VGG16 model pre-trained on PlantCLEF2015 (Supplementary Table 10), which has the correct prediction for all the images of Potato Late blight, the rest of the model configurations show major classification errors, confusing these images with Tomato Late blight, which is actually related to the same common name of disease but on different crops. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999798536300659}, "created": {"value": false, "score": 1.7881393432617188e-06}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999798536300659}, "created": {"value": false, "score": 0.011286377906799316}, "shared": {"value": false, "score": 3.5762786865234375e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Bing", "normalizedForm": "Bing", "offsetStart": 155, "offsetEnd": 159}, "context": "Next, using the S co approach, in order to determine which pre-training task is the most effective, we compared the top-1 accuracy of the combined IPM and Bing images, and found", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999920129776001}, "created": {"value": false, "score": 2.3603439331054688e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999920129776001}, "created": {"value": true, "score": 0.7844283580780029}, "shared": {"value": false, "score": 5.960464477539062e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Bing", "normalizedForm": "Bing", "offsetStart": 159, "offsetEnd": 163}, "context": "We believe that the lack of diversity in the PV data set, which could make the learned model sometimes misleading when used in real field data such as IPM and Bing.", "mentionContextAttributes": {"used": {"value": false, "score": 0.005636692047119141}, "created": {"value": false, "score": 0.003379344940185547}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999920129776001}, "created": {"value": true, "score": 0.7844283580780029}, "shared": {"value": false, "score": 5.960464477539062e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "PlantCLEF", "normalizedForm": "PlantCLEF", "offsetStart": 167, "offsetEnd": 176}, "version": {"rawForm": "2015", "normalizedForm": "2015"}, "context": "From Table 6, we can see that, despite the fact that S cd can achieve a better result in the PV (seen) set, S co generalizes better to PV (unseen) set, especially the PlantCLEF2015 model which reaches 65.11%, the highest top-1 accuracy. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.007342875003814697}, "created": {"value": false, "score": 2.7179718017578125e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999798536300659}, "created": {"value": false, "score": 0.011286377906799316}, "shared": {"value": false, "score": 3.5762786865234375e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Bing Image Search", "normalizedForm": "Bing Image Search", "offsetStart": 167, "offsetEnd": 184}, "context": "Unlike in PV, these test images are not limited to a controlled environment (see Fig. 1) and are extracted from a reliable online sources for IPM5 and downloaded from Bing Image Search. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.02341163158416748}, "created": {"value": false, "score": 4.1365623474121094e-05}, "shared": {"value": false, "score": 3.933906555175781e-06}}, "documentContextAttributes": {"used": {"value": false, "score": 0.02341163158416748}, "created": {"value": false, "score": 4.1365623474121094e-05}, "shared": {"value": false, "score": 3.933906555175781e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "PlantCLEF", "normalizedForm": "PlantCLEF", "offsetStart": 187, "offsetEnd": 196}, "version": {"rawForm": "2015", "normalizedForm": "2015", "offsetStart": 196, "offsetEnd": 200}, "context": "However, by comparing the overall top-1 accuracy of the combined IPM and Bing images, the  VGG16 pre-trained with the ImageNet dataset shows a better result than the one pre-trained with PlantCLEF2015, which are 44.54% and 36.13% ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9959630370140076}, "created": {"value": false, "score": 3.814697265625e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999798536300659}, "created": {"value": false, "score": 0.011286377906799316}, "shared": {"value": false, "score": 3.5762786865234375e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "PlantCLEF", "normalizedForm": "PlantCLEF", "offsetStart": 197, "offsetEnd": 206}, "version": {"rawForm": "2015", "normalizedForm": "2015", "offsetStart": 206, "offsetEnd": 210}, "context": "Specifically, it can be seen that, for the S co , the ImageNet pre-trained model (83.89%) can distinguish better between healthy and unhealthy pepper leaf samples compared to that pre-trained with PlantCLEF2015 (65.40%). ", "mentionContextAttributes": {"used": {"value": false, "score": 0.16975635290145874}, "created": {"value": false, "score": 1.0132789611816406e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999798536300659}, "created": {"value": false, "score": 0.011286377906799316}, "shared": {"value": false, "score": 3.5762786865234375e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Bing", "normalizedForm": "Bing", "offsetStart": 211, "offsetEnd": 215}, "context": "It can be seen that, although models trained with FS configuration, especially the deeper architectures, achieve relatively high performance in PV test set, they have lower classification performance in IPM and Bing than fine-tuned models.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0012158751487731934}, "created": {"value": false, "score": 6.270408630371094e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999920129776001}, "created": {"value": true, "score": 0.7844283580780029}, "shared": {"value": false, "score": 5.960464477539062e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "PlantCLEF", "normalizedForm": "PlantCLEF", "offsetStart": 239, "offsetEnd": 248}, "version": {"rawForm": "2015", "normalizedForm": "2015"}, "context": "Next, based on failure analysis of the PV (unseen), we observed that, with the ImageNet pre-trained models, a majority of Pepper bell Bacterial spot are confused with target spot, Huanglongbing (Citrus greening) and early blight; with the PlantCLEF2015 pre-trained models, most of the Pepper bell Bacterial spot images are confused with Haunglongbing (Citrus greening), Tomato Yellow Leaf Curl Virus and early blight.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999752044677734}, "created": {"value": false, "score": 2.6226043701171875e-06}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999798536300659}, "created": {"value": false, "score": 0.011286377906799316}, "shared": {"value": false, "score": 3.5762786865234375e-07}}}], "references": [], "runtime": 10538, "id": "d537a9a3cc4da83852400d5fa90995158383abfd", "metadata": {"id": "d537a9a3cc4da83852400d5fa90995158383abfd"}, "original_file_path": "../../datalake/Samuel/SOFTware-Sync/downloads/xml/hal-02470280.grobid.tei.xml", "file_name": "hal-02470280.grobid.tei.xml"}