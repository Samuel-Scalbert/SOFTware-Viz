{"application": "software-mentions", "version": "0.8.0", "date": "2024-10-07T11:47+0000", "md5": "0FE0E034A3790121A1F9F17288E5916E", "mentions": [{"type": "software", "software-type": "software", "software-name": {"rawForm": "AudioSet", "normalizedForm": "AudioSet", "offsetStart": 0, "offsetEnd": 8}, "context": "AudioSet consists of an ontology of 587 sound event classes and a collection of 2 million human-labeled 10-second sound clips drawn from YouTube videos.", "mentionContextAttributes": {"used": {"value": false, "score": 0.014788031578063965}, "created": {"value": false, "score": 0.0003706216812133789}, "shared": {"value": false, "score": 7.152557373046875e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999868869781494}, "created": {"value": false, "score": 0.06008964776992798}, "shared": {"value": false, "score": 7.152557373046875e-07}}, "references": [{"label": "[23]", "normalizedForm": "[23]", "refKey": 23}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "AudioSet", "normalizedForm": "AudioSet", "offsetStart": 10, "offsetEnd": 18}, "context": "Note that AudioSet does not come with precise time boundaries for each sound class within the 10-second clips and thus annotations are considered weak labels.", "mentionContextAttributes": {"used": {"value": false, "score": 0.02495485544204712}, "created": {"value": false, "score": 1.1682510375976562e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999868869781494}, "created": {"value": false, "score": 0.06008964776992798}, "shared": {"value": false, "score": 7.152557373046875e-07}}, "references": [{"label": "[23]", "normalizedForm": "[23]", "refKey": 23}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Skateboard", "normalizedForm": "Skateboard", "offsetStart": 27, "offsetEnd": 37}, "context": "\u2022 Vehicle sounds: Bicycle, Skateboard, Car, Car passing by, Bus, Truck, Motorcycle, Train.", "mentionContextAttributes": {"used": {"value": false, "score": 0.015311896800994873}, "created": {"value": false, "score": 4.279613494873047e-05}, "shared": {"value": false, "score": 1.3113021850585938e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997624754905701}, "created": {"value": false, "score": 4.279613494873047e-05}, "shared": {"value": false, "score": 1.3113021850585938e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Skateboard", "normalizedForm": "Skateboard", "offsetStart": 33, "offsetEnd": 43}, "context": "This explanation also applied to Skateboard.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9997624754905701}, "created": {"value": false, "score": 1.4901161193847656e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997624754905701}, "created": {"value": false, "score": 4.279613494873047e-05}, "shared": {"value": false, "score": 1.3113021850585938e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "AudioSet", "normalizedForm": "AudioSet", "offsetStart": 42, "offsetEnd": 50}, "context": "1) Dataset: The task employed a subset of AudioSet [23].", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999868869781494}, "created": {"value": false, "score": 3.4570693969726562e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999868869781494}, "created": {"value": false, "score": 0.06008964776992798}, "shared": {"value": false, "score": 7.152557373046875e-07}}, "references": [{"label": "[23]", "normalizedForm": "[23]", "refKey": 23, "offsetStart": 22678, "offsetEnd": 22682}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "AudioSet", "normalizedForm": "AudioSet", "offsetStart": 66, "offsetEnd": 74}, "context": "The labels are derived from an ontology defined by the authors of AudioSet. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9951291084289551}, "created": {"value": false, "score": 0.06008964776992798}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999868869781494}, "created": {"value": false, "score": 0.06008964776992798}, "shared": {"value": false, "score": 7.152557373046875e-07}}, "references": [{"label": "[23]", "normalizedForm": "[23]", "refKey": 23}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "AudioSet", "normalizedForm": "AudioSet", "offsetStart": 129, "offsetEnd": 137}, "context": "DCASE 2018 Challenge had five tasks: acoustic scene classification [51], general-purpose audio tagging of Freesound content with AudioSet labels [52], bird audio detection [53], large-scale weakly labeled semisupervised sound event detection in domestic environments [46], and monitoring of domestic activities based on multi-channel acoustics [54].", "mentionContextAttributes": {"used": {"value": true, "score": 0.8372024893760681}, "created": {"value": false, "score": 6.198883056640625e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999868869781494}, "created": {"value": false, "score": 0.06008964776992798}, "shared": {"value": false, "score": 7.152557373046875e-07}}, "references": [{"label": "[52]", "normalizedForm": "[52]", "refKey": 52, "offsetStart": 62878, "offsetEnd": 62882}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "scripts", "normalizedForm": "scripts", "offsetStart": 189, "offsetEnd": 196}, "context": "1) Dataset: The dataset consists of the source material for creating mixtures: background scene and target sound event recordings, as well as a set of pre-created mixtures and the software scripts (so-called recipes), according to which they were created. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.36525511741638184}, "created": {"value": false, "score": 6.592273712158203e-05}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.36525511741638184}, "created": {"value": false, "score": 6.592273712158203e-05}, "shared": {"value": false, "score": 3.5762786865234375e-07}}}], "references": [{"refKey": 23, "tei": "<biblStruct xml:id=\"b23\">\n\t<analytic>\n\t\t<title level=\"a\" type=\"main\">Audio Set: An ontology and human-labeled dataset for audio events</title>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Jort</forename><forename type=\"middle\">F</forename><surname>Gemmeke</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Daniel</forename><forename type=\"middle\">P W</forename><surname>Ellis</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Dylan</forename><surname>Freedman</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Aren</forename><surname>Jansen</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Wade</forename><surname>Lawrence</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">R</forename><forename type=\"middle\">Channing</forename><surname>Moore</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Manoj</forename><surname>Plakal</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Marvin</forename><surname>Ritter</surname></persName>\n\t\t</author>\n\t\t<idno type=\"DOI\">10.1109/icassp.2017.7952261</idno>\n\t</analytic>\n\t<monogr>\n\t\t<title level=\"m\">2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</title>\n\t\t<imprint>\n\t\t\t<publisher>IEEE</publisher>\n\t\t\t<date type=\"published\" when=\"2017-03\">2017</date>\n\t\t</imprint>\n\t</monogr>\n</biblStruct>\n"}, {"refKey": 52, "tei": "<biblStruct xml:id=\"b52\">\n\t<analytic>\n\t\t<title level=\"a\" type=\"main\">Audio Tagging with Noisy Labels and Minimal Supervision</title>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Eduardo</forename><surname>Fonseca</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Manoj</forename><surname>Plakal</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Frederic</forename><surname>Font</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Daniel</forename><forename type=\"middle\">P W</forename><surname>Ellis</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Xavier</forename><surname>Serra</surname></persName>\n\t\t</author>\n\t\t<idno type=\"DOI\">10.33682/w13e-5v06</idno>\n\t</analytic>\n\t<monogr>\n\t\t<title level=\"m\">Proceedings of the Detection and Classification of Acoustic Scenes and Events 2019 Workshop (DCASE2019)</title>\n\t\t<meeting>the Detection and Classification of Acoustic Scenes and Events 2019 Workshop (DCASE2019)</meeting>\n\t\t<imprint>\n\t\t\t<publisher>New York University</publisher>\n\t\t\t<date type=\"published\" when=\"2019\">2018. November 2018</date>\n\t\t\t<biblScope unit=\"page\" from=\"69\" to=\"73\" />\n\t\t</imprint>\n\t</monogr>\n</biblStruct>\n"}], "runtime": 10235, "id": "3fb0642c352aad07712d22cb8f0f3f85a886ca06", "metadata": {"id": "3fb0642c352aad07712d22cb8f0f3f85a886ca06"}, "original_file_path": "../../datalake/Samuel/SOFTware-Sync/downloads/xml/hal-02067935.grobid.tei.xml", "file_name": "hal-02067935.grobid.tei.xml"}