{"application": "software-mentions", "version": "0.8.0", "date": "2024-10-07T11:38+0000", "md5": "812774076CC71F3DFB75C6E2BFC2205F", "mentions": [{"type": "software", "software-type": "software", "software-name": {"rawForm": "CycleGAN", "normalizedForm": "CycleGAN", "offsetStart": 0, "offsetEnd": 8}, "context": "CycleGAN has been chosen for this task because it ensures cycle consistency: when we translate from one domain to the other and back again, we should arrive where we started.", "mentionContextAttributes": {"used": {"value": false, "score": 0.004302978515625}, "created": {"value": false, "score": 0.03702282905578613}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9940292835235596}, "created": {"value": false, "score": 0.03702282905578613}, "shared": {"value": false, "score": 1.1920928955078125e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CycleGAN", "normalizedForm": "CycleGAN", "offsetStart": 0, "offsetEnd": 8}, "context": "CycleGAN generates the most differing images compared to all the others, because it takes elements from all photos in the dataset.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0002257227897644043}, "created": {"value": false, "score": 1.049041748046875e-05}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9940292835235596}, "created": {"value": false, "score": 0.03702282905578613}, "shared": {"value": false, "score": 1.1920928955078125e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CycleGAN", "normalizedForm": "CycleGAN", "offsetStart": 3, "offsetEnd": 15}, "context": "In CycleGAN [6] the network not only translates the input image from the source domain to the target domain but also translates the resulting image back to the source domain, enforcing the visual consistency between the two images in the source domain: the initial image and the image resulting from two consecutive translation steps. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0007814168930053711}, "created": {"value": false, "score": 1.3709068298339844e-05}, "shared": {"value": false, "score": 1.1920928955078125e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9940292835235596}, "created": {"value": false, "score": 0.03702282905578613}, "shared": {"value": false, "score": 1.1920928955078125e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CycleGAN", "normalizedForm": "CycleGAN", "offsetStart": 13, "offsetEnd": 21}, "context": "By doing so, CycleGAN will be aware of how to pre-process those kinds of images, and the results may be refined. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0002707839012145996}, "created": {"value": false, "score": 0.0023336410522460938}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9940292835235596}, "created": {"value": false, "score": 0.03702282905578613}, "shared": {"value": false, "score": 1.1920928955078125e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CycleGAN", "normalizedForm": "CycleGAN", "offsetStart": 20, "offsetEnd": 28}, "context": "For this purpose, a CycleGAN has been trained on two sets: the set of Van Gogh's paintings, consisting of 400 samples (set A), and the set of photographs (set B), containing 6853 images.", "mentionContextAttributes": {"used": {"value": false, "score": 0.2452787160873413}, "created": {"value": false, "score": 0.0080718994140625}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9940292835235596}, "created": {"value": false, "score": 0.03702282905578613}, "shared": {"value": false, "score": 1.1920928955078125e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "GANilla", "normalizedForm": "GANilla", "offsetStart": 20, "offsetEnd": 30}, "context": "This is the case of GANilla [5], an architecture consisting of a CNN based on Resnet18 used in an autoencoder structure to learn a latent space and skip connections allowing to translate the input image from the source domain to the target domain. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0001518726348876953}, "created": {"value": false, "score": 0.00025159120559692383}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.0001518726348876953}, "created": {"value": false, "score": 0.00025159120559692383}, "shared": {"value": false, "score": 4.76837158203125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Cy-cleGAN", "normalizedForm": "Cy-cleGAN", "offsetStart": 69, "offsetEnd": 81}, "context": "The starting point was hence the dataset used by Zhu et al. to train Cy-cleGAN [6], where Van Gogh's paintings have been retrieved from WikiArt, while real photos have been downloaded from Flickr by using landscapes-related hashtags. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9988422989845276}, "created": {"value": false, "score": 1.1086463928222656e-05}, "shared": {"value": false, "score": 1.9073486328125e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9988422989845276}, "created": {"value": false, "score": 1.1086463928222656e-05}, "shared": {"value": false, "score": 1.9073486328125e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Flickr", "normalizedForm": "Flickr", "offsetStart": 189, "offsetEnd": 195}, "context": "The starting point was hence the dataset used by Zhu et al. to train Cy-cleGAN [6], where Van Gogh's paintings have been retrieved from WikiArt, while real photos have been downloaded from Flickr by using landscapes-related hashtags. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9988422989845276}, "created": {"value": false, "score": 1.1086463928222656e-05}, "shared": {"value": false, "score": 1.9073486328125e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9988422989845276}, "created": {"value": false, "score": 1.1086463928222656e-05}, "shared": {"value": false, "score": 1.9073486328125e-06}}}, {"type": "software", "software-type": "implicit", "software-name": {"rawForm": "library", "normalizedForm": "library", "offsetStart": 272, "offsetEnd": 279}, "context": "Then, all the selected images have been segmented using the approach of Penhou\u00ebt et al. [10], which is composed of two parts: first, a pre-trained CNN called Pyramid Scene Parsing Network (PSPNet) creates a segmentation image; secondarily, a Knowledge Graph from a Python library, called Sematch, measures the similarity between two class words (e.g.: sky and ground). ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9934380650520325}, "created": {"value": false, "score": 4.184246063232422e-05}, "shared": {"value": false, "score": 5.960464477539062e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9934380650520325}, "created": {"value": false, "score": 4.184246063232422e-05}, "shared": {"value": false, "score": 5.960464477539062e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CycleGAN", "normalizedForm": "CycleGAN", "offsetStart": 279, "offsetEnd": 290}, "context": "Three baselines were chosen to compare the outcomes of the architecture presented in this paper with the state-of-the-art: (i) the classical NST model [3], (ii) CNNMRF architecture [4] due to it being similar to NST, but rather focusing on different patches of images, and (iii) CycleGAN [6], which involves the usage of an unpaired dataset. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9940292835235596}, "created": {"value": false, "score": 2.0265579223632812e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9940292835235596}, "created": {"value": false, "score": 0.03702282905578613}, "shared": {"value": false, "score": 1.1920928955078125e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Sematch", "normalizedForm": "Sematch", "offsetStart": 288, "offsetEnd": 295}, "context": "Then, all the selected images have been segmented using the approach of Penhou\u00ebt et al. [10], which is composed of two parts: first, a pre-trained CNN called Pyramid Scene Parsing Network (PSPNet) creates a segmentation image; secondarily, a Knowledge Graph from a Python library, called Sematch, measures the similarity between two class words (e.g.: sky and ground). ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9934380650520325}, "created": {"value": false, "score": 4.184246063232422e-05}, "shared": {"value": false, "score": 5.960464477539062e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9934380650520325}, "created": {"value": false, "score": 4.184246063232422e-05}, "shared": {"value": false, "score": 5.960464477539062e-07}}}], "references": [], "runtime": 14704, "id": "02c7c348f9e3126878039ab1510165eb653f2261", "metadata": {"id": "02c7c348f9e3126878039ab1510165eb653f2261"}, "original_file_path": "../../datalake/Samuel/SOFTware-Sync/downloads/xml/hal-03921565.grobid.tei.xml", "file_name": "hal-03921565.grobid.tei.xml"}