{"application": "software-mentions", "version": "0.8.0", "date": "2024-10-07T12:00+0000", "md5": "402420D40B2EBEF8B2404786CE97F323", "mentions": [{"type": "software", "software-type": "software", "software-name": {"rawForm": "XCM", "normalizedForm": "XCM", "offsetStart": 0, "offsetEnd": 3}, "context": "XCM-seq is the same as XCM except that the 2D and 1D convolution blocks are in sequence.", "mentionContextAttributes": {"used": {"value": false, "score": 0.006722509860992432}, "created": {"value": false, "score": 8.463859558105469e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999932050704956}, "created": {"value": true, "score": 0.9999338388442993}, "shared": {"value": false, "score": 5.4836273193359375e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "XCM", "normalizedForm": "XCM", "offsetStart": 0, "offsetEnd": 3}, "context": "XCM outperforms both XCM-Seq and MTEX-CNN on average on the UEA datasets (rank: 2.3, XCM-Seq: 5.0, MTEX-CNN: 7.2).", "mentionContextAttributes": {"used": {"value": false, "score": 0.06691527366638184}, "created": {"value": false, "score": 3.0517578125e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999932050704956}, "created": {"value": true, "score": 0.9999338388442993}, "shared": {"value": false, "score": 5.4836273193359375e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "XCM", "normalizedForm": "XCM", "offsetStart": 0, "offsetEnd": 3}, "context": "XCM exhibits a better average rank than the state-of-the-art classifiers on both the large and small public UEA datasets.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0028405189514160156}, "created": {"value": false, "score": 1.7762184143066406e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999932050704956}, "created": {"value": true, "score": 0.9999338388442993}, "shared": {"value": false, "score": 5.4836273193359375e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "WEASEL+ MUSE", "normalizedForm": "WEASEL+ MUSE", "offsetStart": 0, "offsetEnd": 12}, "context": "WEASEL+ MUSE shows better results compared to gRSF, LPS, mv-ARF, SMTS and UFS on average (20 MTS datasets).", "mentionContextAttributes": {"used": {"value": false, "score": 0.12179362773895264}, "created": {"value": false, "score": 8.58306884765625e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.12179362773895264}, "created": {"value": true, "score": 0.9970675110816956}, "shared": {"value": false, "score": 1.1920928955078125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "WEASEL+MUSE", "normalizedForm": "WEASEL+MUSE", "offsetStart": 2, "offsetEnd": 13}, "context": " with the following hyperparameter: batch size {1, 8, 32};\u2022 WEASEL+MUSE: we used the", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999837875366211}, "created": {"value": false, "score": 3.0994415283203125e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999837875366211}, "created": {"value": false, "score": 3.218650817871094e-05}, "shared": {"value": false, "score": 1.6689300537109375e-06}}, "references": [{"label": "[6]", "normalizedForm": "[6]", "refKey": 6}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MTEX", "normalizedForm": "MTEX", "offsetStart": 3, "offsetEnd": 7}, "context": "As MTEX-CNN attribution maps exhibit a red color gradient, the precision of identification of the regions of the input data on MTEX-CNN attribution maps could be enhanced by setting a higher threshold than 0.6 for the attribution values.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9993818998336792}, "created": {"value": false, "score": 2.086162567138672e-05}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997316002845764}, "created": {"value": true, "score": 0.9856033325195312}, "shared": {"value": false, "score": 1.430511474609375e-06}}, "references": [{"label": "[12]", "normalizedForm": "[12]", "refKey": 12}, {"label": "[12]", "normalizedForm": "[12]", "refKey": 12}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MTEX", "normalizedForm": "MTEX", "offsetStart": 5, "offsetEnd": 9}, "context": "Both MTEX-CNN and XCM have periodically high attribution values on dimension 2 of the observed variables attribution maps.", "mentionContextAttributes": {"used": {"value": false, "score": 0.1159161925315857}, "created": {"value": false, "score": 3.933906555175781e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997316002845764}, "created": {"value": true, "score": 0.9856033325195312}, "shared": {"value": false, "score": 1.430511474609375e-06}}, "references": [{"label": "[12]", "normalizedForm": "[12]", "refKey": 12}, {"label": "[12]", "normalizedForm": "[12]", "refKey": 12}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MUSE", "normalizedForm": "MUSE", "offsetStart": 7, "offsetEnd": 11}, "context": "WEASEL+MUSE generates a BoW representation by applying various sliding windows with different sizes on each discretized dimension (Symbolic Fourier Approximation) to capture features (unigrams, bigrams and dimension identification). ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0006835460662841797}, "created": {"value": false, "score": 1.2755393981933594e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.0006835460662841797}, "created": {"value": false, "score": 1.2755393981933594e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MTEX", "normalizedForm": "MTEX", "offsetStart": 7, "offsetEnd": 11}, "context": "First, MTEX-CNN and XCM (Batch Size: 1, Window Size: 20%) correctly predict the 10 MTS of the test set (accuracy 100%).", "mentionContextAttributes": {"used": {"value": true, "score": 0.9993665814399719}, "created": {"value": false, "score": 4.0531158447265625e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997316002845764}, "created": {"value": true, "score": 0.9856033325195312}, "shared": {"value": false, "score": 1.430511474609375e-06}}, "references": [{"label": "[12]", "normalizedForm": "[12]", "refKey": 12}, {"label": "[12]", "normalizedForm": "[12]", "refKey": 12}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CNN", "normalizedForm": "CNN", "offsetStart": 8, "offsetEnd": 11}, "context": "Then, a CNN architecture using fully connected layers to perform classification, especially with the size of the first layer depending on the time series length as in MTEX-CNN, is prone to overfitting and can lead to the explosion of the number of trainable parameters.", "mentionContextAttributes": {"used": {"value": false, "score": 6.0439109802246094e-05}, "created": {"value": false, "score": 0.000517725944519043}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997316002845764}, "created": {"value": true, "score": 0.9998825788497925}, "shared": {"value": false, "score": 1.430511474609375e-06}}, "references": [{"label": "[12]", "normalizedForm": "[12]", "refKey": 12}, {"label": "[12]", "normalizedForm": "[12]", "refKey": 12}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CNN", "normalizedForm": "CNN", "offsetStart": 8, "offsetEnd": 11}, "context": "The new CNN architecture of XCM has been designed to enable the precise identification of the observed variables and timestamps that are important for predictions based on Gradient-weighted Class Activation Mapping (Grad-CAM) [10].", "mentionContextAttributes": {"used": {"value": false, "score": 8.213520050048828e-05}, "created": {"value": true, "score": 0.9723411798477173}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997316002845764}, "created": {"value": true, "score": 0.9998825788497925}, "shared": {"value": false, "score": 1.430511474609375e-06}}, "references": [{"label": "[12]", "normalizedForm": "[12]", "refKey": 12}, {"label": "[12]", "normalizedForm": "[12]", "refKey": 12}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CNN", "normalizedForm": "CNN", "offsetStart": 8, "offsetEnd": 11}, "context": "As MTEX-CNN attribution maps exhibit a red color gradient, the precision of identification of the regions of the input data on MTEX-CNN attribution maps could be enhanced by setting a higher threshold than 0.6 for the attribution values.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9993818998336792}, "created": {"value": false, "score": 2.086162567138672e-05}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997316002845764}, "created": {"value": true, "score": 0.9998825788497925}, "shared": {"value": false, "score": 1.430511474609375e-06}}, "references": [{"label": "[12]", "normalizedForm": "[12]", "refKey": 12}, {"label": "[12]", "normalizedForm": "[12]", "refKey": 12}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CNN", "normalizedForm": "CNN", "offsetStart": 9, "offsetEnd": 12}, "context": "A recent CNN, MTEX-CNN [12] proposes using 2D and 1D convolution filters in sequence to extract key MTS information, i.e., information relative to the observed variables and time, respectively.", "mentionContextAttributes": {"used": {"value": false, "score": 9.894371032714844e-05}, "created": {"value": false, "score": 0.0001068115234375}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997316002845764}, "created": {"value": true, "score": 0.9998825788497925}, "shared": {"value": false, "score": 1.430511474609375e-06}}, "references": [{"label": "[12]", "normalizedForm": "[12]", "refKey": 12}, {"label": "[12]", "normalizedForm": "[12]", "refKey": 12}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CNN", "normalizedForm": "CNN", "offsetStart": 9, "offsetEnd": 12}, "context": "However, CNN architectures such as MTEX-CNN have significant limitations.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00012302398681640625}, "created": {"value": false, "score": 3.159046173095703e-05}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997316002845764}, "created": {"value": true, "score": 0.9998825788497925}, "shared": {"value": false, "score": 1.430511474609375e-06}}, "references": [{"label": "[12]", "normalizedForm": "[12]", "refKey": 12}, {"label": "[12]", "normalizedForm": "[12]", "refKey": 12}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "XCM", "normalizedForm": "XCM", "offsetStart": 9, "offsetEnd": 12}, "context": "Firstly, XCM extracts information relative to the observed variables with 2D convolution filters (upper green part in Figure 2).", "mentionContextAttributes": {"used": {"value": false, "score": 0.0656888484954834}, "created": {"value": false, "score": 2.9802322387695312e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999932050704956}, "created": {"value": true, "score": 0.9999338388442993}, "shared": {"value": false, "score": 5.4836273193359375e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MTEX", "normalizedForm": "MTEX", "offsetStart": 9, "offsetEnd": 13}, "context": "Finally, MTEX-CNN requires upsampling processes on feature maps when applying Grad-CAM, which can lead to an imprecise identification of the regions of the input data that are important for predictions.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00012636184692382812}, "created": {"value": false, "score": 3.266334533691406e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997316002845764}, "created": {"value": true, "score": 0.9856033325195312}, "shared": {"value": false, "score": 1.430511474609375e-06}}, "references": [{"label": "[12]", "normalizedForm": "[12]", "refKey": 12}, {"label": "[12]", "normalizedForm": "[12]", "refKey": 12}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CNN", "normalizedForm": "CNN", "offsetStart": 10, "offsetEnd": 13}, "context": "Both MTEX-CNN and XCM have periodically high attribution values on dimension 2 of the observed variables attribution maps.", "mentionContextAttributes": {"used": {"value": false, "score": 0.1159161925315857}, "created": {"value": false, "score": 3.933906555175781e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997316002845764}, "created": {"value": true, "score": 0.9998825788497925}, "shared": {"value": false, "score": 1.430511474609375e-06}}, "references": [{"label": "[12]", "normalizedForm": "[12]", "refKey": 12}, {"label": "[12]", "normalizedForm": "[12]", "refKey": 12}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MTEX", "normalizedForm": "MTEX", "offsetStart": 10, "offsetEnd": 14}, "context": "Moreover, MTEX-CNN and XCM with Grad-CAM all correctly identify the discriminative time window. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9979332685470581}, "created": {"value": false, "score": 3.814697265625e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997316002845764}, "created": {"value": true, "score": 0.9856033325195312}, "shared": {"value": false, "score": 1.430511474609375e-06}}, "references": [{"label": "[12]", "normalizedForm": "[12]", "refKey": 12}, {"label": "[12]", "normalizedForm": "[12]", "refKey": 12}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "XCM", "normalizedForm": "XCM", "offsetStart": 11, "offsetEnd": 14}, "context": "We present XCM, an end-to-end new compact and explainable convolutional neural network for MTS classification which supports its predictions with faithful explanations;", "mentionContextAttributes": {"used": {"value": false, "score": 0.00012600421905517578}, "created": {"value": true, "score": 0.9999338388442993}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999932050704956}, "created": {"value": true, "score": 0.9999338388442993}, "shared": {"value": false, "score": 5.4836273193359375e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "XCM", "normalizedForm": "XCM", "offsetStart": 11, "offsetEnd": 14}, "context": "We compare XCM with Grad-CAM to a reference commercial solution (HeatPhone [53]) and the most accurate state-of-the-art MTS classifier of our benchmark (see Section 4.2) on this real-world application-MLSTM-FCN-with SHAP [32].", "mentionContextAttributes": {"used": {"value": true, "score": 0.9186117053031921}, "created": {"value": false, "score": 2.0623207092285156e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999932050704956}, "created": {"value": true, "score": 0.9999338388442993}, "shared": {"value": false, "score": 5.4836273193359375e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "XCM", "normalizedForm": "XCM", "offsetStart": 11, "offsetEnd": 14}, "context": "Therefore, XCM outperforms the current state-of-the-art algorithm on the real-world application (Performance: Best), while enhancing explainability by providing faithful and more informative explanations.", "mentionContextAttributes": {"used": {"value": false, "score": 5.7697296142578125e-05}, "created": {"value": false, "score": 0.0006033182144165039}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999932050704956}, "created": {"value": true, "score": 0.9999338388442993}, "shared": {"value": false, "score": 5.4836273193359375e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CNN", "normalizedForm": "CNN", "offsetStart": 12, "offsetEnd": 15}, "context": "First, MTEX-CNN and XCM (Batch Size: 1, Window Size: 20%) correctly predict the 10 MTS of the test set (accuracy 100%).", "mentionContextAttributes": {"used": {"value": true, "score": 0.9993665814399719}, "created": {"value": false, "score": 4.0531158447265625e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997316002845764}, "created": {"value": true, "score": 0.9998825788497925}, "shared": {"value": false, "score": 1.430511474609375e-06}}, "references": [{"label": "[12]", "normalizedForm": "[12]", "refKey": 12}, {"label": "[12]", "normalizedForm": "[12]", "refKey": 12}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "-CAM", "normalizedForm": "-CAM", "offsetStart": 12, "offsetEnd": 16}, "context": "Indeed, Grad-CAM can also offer global explainability by averaging the attribution maps values per class. ", "mentionContextAttributes": {"used": {"value": false, "score": 2.372264862060547e-05}, "created": {"value": false, "score": 2.8014183044433594e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997251629829407}, "created": {"value": false, "score": 0.002720654010772705}, "shared": {"value": false, "score": 0.25355058908462524}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "XCM", "normalizedForm": "XCM", "offsetStart": 13, "offsetEnd": 16}, "context": "We show that XCM outperforms the state-of-the-art MTS classifiers on both the large and small UEA datasets [7]; \u2022 We illustrate on a synthetic dataset that XCM enables a more precise identification of the regions of the input data that are important for predictions compared to the current faithfully explainable deep learning MTS classifier MTEX-CNN; \u2022", "mentionContextAttributes": {"used": {"value": false, "score": 0.03140699863433838}, "created": {"value": false, "score": 0.0006378293037414551}, "shared": {"value": false, "score": 5.960464477539062e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999932050704956}, "created": {"value": true, "score": 0.9999338388442993}, "shared": {"value": false, "score": 5.4836273193359375e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "XCM", "normalizedForm": "XCM", "offsetStart": 13, "offsetEnd": 16}, "context": "We show that XCM outperforms the current most accurate state-of-the-art algorithm on a real-world application while enhancing explainability by providing faithful and more informative explanations.", "mentionContextAttributes": {"used": {"value": false, "score": 0.012761175632476807}, "created": {"value": false, "score": 0.002617061138153076}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999932050704956}, "created": {"value": true, "score": 0.9999338388442993}, "shared": {"value": false, "score": 5.4836273193359375e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "XCM", "normalizedForm": "XCM", "offsetStart": 13, "offsetEnd": 16}, "context": "In parallel, XCM extracts information relative to time with 1D convolution filters (lower red part in Figure 2).", "mentionContextAttributes": {"used": {"value": false, "score": 0.0002993345260620117}, "created": {"value": false, "score": 1.7881393432617188e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999932050704956}, "created": {"value": true, "score": 0.9999338388442993}, "shared": {"value": false, "score": 5.4836273193359375e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CNN", "normalizedForm": "CNN", "offsetStart": 14, "offsetEnd": 17}, "context": "Finally, MTEX-CNN requires upsampling processes on feature maps when applying Grad-CAM, which can lead to an imprecise identification of the regions of the input data that are important for predictions.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00012636184692382812}, "created": {"value": false, "score": 3.266334533691406e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997316002845764}, "created": {"value": true, "score": 0.9998825788497925}, "shared": {"value": false, "score": 1.430511474609375e-06}}, "references": [{"label": "[12]", "normalizedForm": "[12]", "refKey": 12}, {"label": "[12]", "normalizedForm": "[12]", "refKey": 12}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MTEX", "normalizedForm": "MTEX", "offsetStart": 14, "offsetEnd": 18}, "context": "A recent CNN, MTEX-CNN [12] proposes using 2D and 1D convolution filters in sequence to extract key MTS information, i.e., information relative to the observed variables and time, respectively. ", "mentionContextAttributes": {"used": {"value": false, "score": 9.894371032714844e-05}, "created": {"value": false, "score": 0.0001068115234375}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997316002845764}, "created": {"value": true, "score": 0.9856033325195312}, "shared": {"value": false, "score": 1.430511474609375e-06}}, "references": [{"label": "[12]", "normalizedForm": "[12]", "refKey": 12, "offsetStart": 3015, "offsetEnd": 3019}, {"label": "[12]", "normalizedForm": "[12]", "refKey": 12, "offsetStart": 3015, "offsetEnd": 3019}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "XCM", "normalizedForm": "XCM", "offsetStart": 15, "offsetEnd": 18}, "context": "We benchmarked XCM on the 30 currently available public UEA MTS datasets [7].", "mentionContextAttributes": {"used": {"value": true, "score": 0.9998323917388916}, "created": {"value": false, "score": 0.0002345442771911621}, "shared": {"value": false, "score": 1.3113021850585938e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999932050704956}, "created": {"value": true, "score": 0.9999338388442993}, "shared": {"value": false, "score": 5.4836273193359375e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "XCM", "normalizedForm": "XCM", "offsetStart": 15, "offsetEnd": 18}, "context": "We notice that XCM is the only classifier with a significant performance difference compared to DTW D .", "mentionContextAttributes": {"used": {"value": false, "score": 0.14759457111358643}, "created": {"value": false, "score": 1.9073486328125e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999932050704956}, "created": {"value": true, "score": 0.9999338388442993}, "shared": {"value": false, "score": 5.4836273193359375e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CNN", "normalizedForm": "CNN", "offsetStart": 15, "offsetEnd": 18}, "context": "Moreover, MTEX-CNN and XCM with Grad-CAM all correctly identify the discriminative time window.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9979332685470581}, "created": {"value": false, "score": 3.814697265625e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997316002845764}, "created": {"value": true, "score": 0.9998825788497925}, "shared": {"value": false, "score": 1.430511474609375e-06}}, "references": [{"label": "[12]", "normalizedForm": "[12]", "refKey": 12}, {"label": "[12]", "normalizedForm": "[12]", "refKey": 12}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "-CAM", "normalizedForm": "-CAM", "offsetStart": 15, "offsetEnd": 19}, "context": "Concerning Grad-CAM, we used the implementation available for Keras (https://github.com/jacobgil/keras-grad-cam ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9997251629829407}, "created": {"value": false, "score": 0.002720654010772705}, "shared": {"value": false, "score": 0.25355058908462524}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997251629829407}, "created": {"value": false, "score": 0.002720654010772705}, "shared": {"value": false, "score": 0.25355058908462524}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "XCM", "normalizedForm": "XCM", "offsetStart": 16, "offsetEnd": 19}, "context": "We observe that XCM and MTEX-CNN obtain the same performance whereas XCM has around 10 times fewer parameters than MTEX-CNN (trainable parameters: XCM 17k, MTEX-CNN 232k).", "mentionContextAttributes": {"used": {"value": true, "score": 0.6832642555236816}, "created": {"value": false, "score": 3.5762786865234375e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999932050704956}, "created": {"value": true, "score": 0.9999338388442993}, "shared": {"value": false, "score": 5.4836273193359375e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MTEX", "normalizedForm": "MTEX", "offsetStart": 16, "offsetEnd": 20}, "context": "We also include MTEX-CNN in the benchmark to demonstrate the superiority of our approach as MTEX-CNN has not been evaluated on the public UEA datasets.", "mentionContextAttributes": {"used": {"value": false, "score": 0.2156417965888977}, "created": {"value": false, "score": 0.031333208084106445}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997316002845764}, "created": {"value": true, "score": 0.9856033325195312}, "shared": {"value": false, "score": 1.430511474609375e-06}}, "references": [{"label": "[12]", "normalizedForm": "[12]", "refKey": 12}, {"label": "[12]", "normalizedForm": "[12]", "refKey": 12}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "XCM", "normalizedForm": "XCM", "offsetStart": 18, "offsetEnd": 21}, "context": "Both MTEX-CNN and XCM have periodically high attribution values on dimension 2 of the observed variables attribution maps.", "mentionContextAttributes": {"used": {"value": false, "score": 0.1159161925315857}, "created": {"value": false, "score": 3.933906555175781e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999932050704956}, "created": {"value": true, "score": 0.9999338388442993}, "shared": {"value": false, "score": 5.4836273193359375e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "XCM", "normalizedForm": "XCM", "offsetStart": 18, "offsetEnd": 21}, "context": "We have presented XCM, a new compact and explainable convolutional neural network for MTS classification, which extracts information relative to the observed variables and time directly from the input data.", "mentionContextAttributes": {"used": {"value": false, "score": 8.118152618408203e-05}, "created": {"value": true, "score": 0.9999217987060547}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999932050704956}, "created": {"value": true, "score": 0.9999338388442993}, "shared": {"value": false, "score": 5.4836273193359375e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CNN", "normalizedForm": "CNN", "offsetStart": 19, "offsetEnd": 22}, "context": "A recent CNN, MTEX-CNN [12] proposes using 2D and 1D convolution filters in sequence to extract key MTS information, i.e., information relative to the observed variables and time, respectively.", "mentionContextAttributes": {"used": {"value": false, "score": 9.894371032714844e-05}, "created": {"value": false, "score": 0.0001068115234375}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997316002845764}, "created": {"value": true, "score": 0.9998825788497925}, "shared": {"value": false, "score": 1.430511474609375e-06}}, "references": [{"label": "[12]", "normalizedForm": "[12]", "refKey": 12, "offsetStart": 3015, "offsetEnd": 3019}, {"label": "[12]", "normalizedForm": "[12]", "refKey": 12, "offsetStart": 3015, "offsetEnd": 3019}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "XCM", "normalizedForm": "XCM", "offsetStart": 19, "offsetEnd": 22}, "context": "More specifically, XCM exhibits better performance than MLSTM-FCN and WEASEL +MUSE on both the large (rank: 1.9, MLSTM-FCN rank: 2.1, WEASEL+MUSE rank: 4.6-train size \u2265 500, 23% of the datasets) and small datasets (rank: 2.4, MLSTM-FCN rank: 4.0, WEASEL+MUSE rank: 3.9-train size < 500, 77% of the datasets).", "mentionContextAttributes": {"used": {"value": true, "score": 0.6560125350952148}, "created": {"value": false, "score": 2.1457672119140625e-06}, "shared": {"value": false, "score": 7.152557373046875e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999932050704956}, "created": {"value": true, "score": 0.9999338388442993}, "shared": {"value": false, "score": 5.4836273193359375e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "XCM", "normalizedForm": "XCM", "offsetStart": 20, "offsetEnd": 23}, "context": "First, MTEX-CNN and XCM (Batch Size: 1, Window Size: 20%) correctly predict the 10 MTS of the test set (accuracy 100%).", "mentionContextAttributes": {"used": {"value": true, "score": 0.9993665814399719}, "created": {"value": false, "score": 4.0531158447265625e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999932050704956}, "created": {"value": true, "score": 0.9999338388442993}, "shared": {"value": false, "score": 5.4836273193359375e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Grad-CAM", "normalizedForm": "Grad-CAM", "offsetStart": 20, "offsetEnd": 28}, "context": "We compare XCM with Grad-CAM to a reference commercial solution (HeatPhone [53]) and the most accurate state-of-the-art MTS classifier of our benchmark (see Section 4.2) on this real-world application-MLSTM-FCN-with SHAP [32]. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9186117053031921}, "created": {"value": false, "score": 2.0623207092285156e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9186117053031921}, "created": {"value": false, "score": 3.612041473388672e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CNN", "normalizedForm": "CNN", "offsetStart": 21, "offsetEnd": 24}, "context": "We also include MTEX-CNN in the benchmark to demonstrate the superiority of our approach as MTEX-CNN has not been evaluated on the public UEA datasets.", "mentionContextAttributes": {"used": {"value": false, "score": 0.2156417965888977}, "created": {"value": false, "score": 0.031333208084106445}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997316002845764}, "created": {"value": true, "score": 0.9998825788497925}, "shared": {"value": false, "score": 1.430511474609375e-06}}, "references": [{"label": "[12]", "normalizedForm": "[12]", "refKey": 12}, {"label": "[12]", "normalizedForm": "[12]", "refKey": 12}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "XCM", "normalizedForm": "XCM", "offsetStart": 21, "offsetEnd": 24}, "context": "Figure 2 illustrates XCM, and the following paragraphs detail the architecture.", "mentionContextAttributes": {"used": {"value": false, "score": 0.28680962324142456}, "created": {"value": false, "score": 5.5670738220214844e-05}, "shared": {"value": false, "score": 5.960464477539062e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999932050704956}, "created": {"value": true, "score": 0.9999338388442993}, "shared": {"value": false, "score": 5.4836273193359375e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "XCM", "normalizedForm": "XCM", "offsetStart": 21, "offsetEnd": 24}, "context": "XCM outperforms both XCM-Seq and MTEX-CNN on average on the UEA datasets (rank: 2.3, XCM-Seq: 5.0, MTEX-CNN: 7.2).", "mentionContextAttributes": {"used": {"value": false, "score": 0.06691527366638184}, "created": {"value": false, "score": 3.0517578125e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999932050704956}, "created": {"value": true, "score": 0.9999338388442993}, "shared": {"value": false, "score": 5.4836273193359375e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "XCM", "normalizedForm": "XCM", "offsetStart": 23, "offsetEnd": 26}, "context": "Thus, (i) our approach XCM extracts both features related to observed variables (2D convolution filters) and time (1D convolution filters) directly from the input data, which leads to more discriminative features by incorporating all the relevant information and ultimately to a better classification performance on average than the 2D/1D sequential approach (see results in Section 5.1).", "mentionContextAttributes": {"used": {"value": false, "score": 0.00571364164352417}, "created": {"value": false, "score": 1.0967254638671875e-05}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999932050704956}, "created": {"value": true, "score": 0.9999338388442993}, "shared": {"value": false, "score": 5.4836273193359375e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "XCM", "normalizedForm": "XCM", "offsetStart": 23, "offsetEnd": 26}, "context": "XCM-seq is the same as XCM except that the 2D and 1D convolution blocks are in sequence.", "mentionContextAttributes": {"used": {"value": false, "score": 0.006722509860992432}, "created": {"value": false, "score": 8.463859558105469e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999932050704956}, "created": {"value": true, "score": 0.9999338388442993}, "shared": {"value": false, "score": 5.4836273193359375e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "XCM", "normalizedForm": "XCM", "offsetStart": 23, "offsetEnd": 26}, "context": "Moreover, MTEX-CNN and XCM with Grad-CAM all correctly identify the discriminative time window.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9979332685470581}, "created": {"value": false, "score": 3.814697265625e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999932050704956}, "created": {"value": true, "score": 0.9999338388442993}, "shared": {"value": false, "score": 5.4836273193359375e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "XCM", "normalizedForm": "XCM", "offsetStart": 24, "offsetEnd": 27}, "context": "Then, we illustrate how XCM can reconcile performance and explainability on a synthetic dataset.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0017754435539245605}, "created": {"value": false, "score": 0.011010944843292236}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999932050704956}, "created": {"value": true, "score": 0.9999338388442993}, "shared": {"value": false, "score": 5.4836273193359375e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "XCM", "normalizedForm": "XCM", "offsetStart": 24, "offsetEnd": 27}, "context": "In addition, concerning XCM explainability, Figure 6 shows an example of the observed variables and time attribution maps supporting the correct prediction of an MTS sample belonging to the class Estrus.", "mentionContextAttributes": {"used": {"value": true, "score": 0.7908734679222107}, "created": {"value": false, "score": 1.2278556823730469e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999932050704956}, "created": {"value": true, "score": 0.9999338388442993}, "shared": {"value": false, "score": 5.4836273193359375e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MTEX", "normalizedForm": "MTEX", "offsetStart": 24, "offsetEnd": 28}, "context": "We observe that XCM and MTEX-CNN obtain the same performance whereas XCM has around 10 times fewer parameters than MTEX-CNN (trainable parameters: XCM 17k, MTEX-CNN 232k).", "mentionContextAttributes": {"used": {"value": true, "score": 0.6832642555236816}, "created": {"value": false, "score": 3.5762786865234375e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997316002845764}, "created": {"value": true, "score": 0.9856033325195312}, "shared": {"value": false, "score": 1.430511474609375e-06}}, "references": [{"label": "[12]", "normalizedForm": "[12]", "refKey": 12}, {"label": "[12]", "normalizedForm": "[12]", "refKey": 12}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "XCM", "normalizedForm": "XCM", "offsetStart": 25, "offsetEnd": 28}, "context": "Firstly, we observe that XCM obtains the best average rank and the lowest rank variability across the datasets (rank: 2.3, standard error: 0.4), followed by MLSTM-FCN in second position (rank: 3.5, standard error: 0.5) and WEASEL+MUSE in third position (rank: 4.0, standard error: 0.5).", "mentionContextAttributes": {"used": {"value": true, "score": 0.6182390451431274}, "created": {"value": false, "score": 2.0265579223632812e-06}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999932050704956}, "created": {"value": true, "score": 0.9999338388442993}, "shared": {"value": false, "score": 5.4836273193359375e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "XCM", "normalizedForm": "XCM", "offsetStart": 26, "offsetEnd": 29}, "context": "The next section presents XCM in details.", "mentionContextAttributes": {"used": {"value": false, "score": 0.010179281234741211}, "created": {"value": false, "score": 0.0018728375434875488}, "shared": {"value": false, "score": 5.4836273193359375e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999932050704956}, "created": {"value": true, "score": 0.9999338388442993}, "shared": {"value": false, "score": 5.4836273193359375e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "XCM", "normalizedForm": "XCM", "offsetStart": 28, "offsetEnd": 31}, "context": "The new CNN architecture of XCM has been designed to enable the precise identification of the observed variables and timestamps that are important for predictions based on Gradient-weighted Class Activation Mapping (Grad-CAM) [10].", "mentionContextAttributes": {"used": {"value": false, "score": 8.213520050048828e-05}, "created": {"value": true, "score": 0.9723411798477173}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999932050704956}, "created": {"value": true, "score": 0.9999338388442993}, "shared": {"value": false, "score": 5.4836273193359375e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "XCM", "normalizedForm": "XCM", "offsetStart": 28, "offsetEnd": 31}, "context": "We used the same setting as XCM.", "mentionContextAttributes": {"used": {"value": true, "score": 0.999953031539917}, "created": {"value": false, "score": 5.602836608886719e-06}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999932050704956}, "created": {"value": true, "score": 0.9999338388442993}, "shared": {"value": false, "score": 5.4836273193359375e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "XCM", "normalizedForm": "XCM", "offsetStart": 28, "offsetEnd": 31}, "context": "Therefore, considering that XCM-Seq attributions maps are the same as XCM ones, we can assume that the use of half padding on the different convolution layers to reduce the number of parameters in MTEX-CNN, i.e., the use of upsampling to retrieve the input data dimensions on the attribution maps, can lead to a less precise identification of the regions of the input data that are important for predictions.", "mentionContextAttributes": {"used": {"value": true, "score": 0.715061366558075}, "created": {"value": false, "score": 1.990795135498047e-05}, "shared": {"value": false, "score": 1.430511474609375e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999932050704956}, "created": {"value": true, "score": 0.9999338388442993}, "shared": {"value": false, "score": 5.4836273193359375e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MTEX", "normalizedForm": "MTEX", "offsetStart": 28, "offsetEnd": 32}, "context": "As illustrated in Figure 1, MTEX-CNN is a two-stage CNN network which first extracts information relative to each feature with 2D convolution filters and then extracts information relative to time with 1D convolution filters.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0010300874710083008}, "created": {"value": false, "score": 0.0003025531768798828}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997316002845764}, "created": {"value": true, "score": 0.9856033325195312}, "shared": {"value": false, "score": 1.430511474609375e-06}}, "references": [{"label": "[12]", "normalizedForm": "[12]", "refKey": 12}, {"label": "[12]", "normalizedForm": "[12]", "refKey": 12}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CNN", "normalizedForm": "CNN", "offsetStart": 29, "offsetEnd": 32}, "context": "We observe that XCM and MTEX-CNN obtain the same performance whereas XCM has around 10 times fewer parameters than MTEX-CNN (trainable parameters: XCM 17k, MTEX-CNN 232k).", "mentionContextAttributes": {"used": {"value": true, "score": 0.6832642555236816}, "created": {"value": false, "score": 3.5762786865234375e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997316002845764}, "created": {"value": true, "score": 0.9998825788497925}, "shared": {"value": false, "score": 1.430511474609375e-06}}, "references": [{"label": "[12]", "normalizedForm": "[12]", "refKey": 12}, {"label": "[12]", "normalizedForm": "[12]", "refKey": 12}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CNN", "normalizedForm": "CNN", "offsetStart": 33, "offsetEnd": 36}, "context": "As illustrated in Figure 1, MTEX-CNN is a two-stage CNN network which first extracts information relative to each feature with 2D convolution filters and then extracts information relative to time with 1D convolution filters.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0010300874710083008}, "created": {"value": false, "score": 0.0003025531768798828}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997316002845764}, "created": {"value": true, "score": 0.9998825788497925}, "shared": {"value": false, "score": 1.430511474609375e-06}}, "references": [{"label": "[12]", "normalizedForm": "[12]", "refKey": 12}, {"label": "[12]", "normalizedForm": "[12]", "refKey": 12}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MTEX", "normalizedForm": "MTEX", "offsetStart": 33, "offsetEnd": 37}, "context": "XCM outperforms both XCM-Seq and MTEX-CNN on average on the UEA datasets (rank: 2.3, XCM-Seq: 5.0, MTEX-CNN: 7.2).", "mentionContextAttributes": {"used": {"value": false, "score": 0.06691527366638184}, "created": {"value": false, "score": 3.0517578125e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997316002845764}, "created": {"value": true, "score": 0.9856033325195312}, "shared": {"value": false, "score": 1.430511474609375e-06}}, "references": [{"label": "[12]", "normalizedForm": "[12]", "refKey": 12}, {"label": "[12]", "normalizedForm": "[12]", "refKey": 12}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CNN", "normalizedForm": "CNN", "offsetStart": 34, "offsetEnd": 37}, "context": "Following the good performance of CNN architectures in image recognition [14] and natural language processing [15,16], CNNs have started to be adopted for time series analysis [17].", "mentionContextAttributes": {"used": {"value": false, "score": 0.0013282299041748047}, "created": {"value": false, "score": 5.137920379638672e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997316002845764}, "created": {"value": true, "score": 0.9998825788497925}, "shared": {"value": false, "score": 1.430511474609375e-06}}, "references": [{"label": "[12]", "normalizedForm": "[12]", "refKey": 12}, {"label": "[12]", "normalizedForm": "[12]", "refKey": 12}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MTEX-CNN", "normalizedForm": "MTEX-CNN", "offsetStart": 35, "offsetEnd": 43}, "context": "However, CNN architectures such as MTEX-CNN have significant limitations. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.00012302398681640625}, "created": {"value": false, "score": 3.159046173095703e-05}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.03140699863433838}, "created": {"value": false, "score": 0.0006378293037414551}, "shared": {"value": false, "score": 5.960464477539062e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "XCM", "normalizedForm": "XCM", "offsetStart": 38, "offsetEnd": 41}, "context": "Thus, (ii) the output feature maps of XCM are processed with a 1D global average pooling before being input to a softmax layer for classification.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9997320771217346}, "created": {"value": false, "score": 7.748603820800781e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999932050704956}, "created": {"value": true, "score": 0.9999338388442993}, "shared": {"value": false, "score": 5.4836273193359375e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "XCM", "normalizedForm": "XCM", "offsetStart": 38, "offsetEnd": 41}, "context": "All the networks that we implemented (XCM, XCM-Seq and MTEX-CNN) were trained with 100 epochs, the categorical crossentropy loss and the Adam optimization (computing infrastructure: Debian 8 operating system, GPU NVIDIA GeForce RTX 2080 Ti with 11Gb GRAM and 96Gb of RAM).", "mentionContextAttributes": {"used": {"value": true, "score": 0.9997316002845764}, "created": {"value": false, "score": 1.2278556823730469e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999932050704956}, "created": {"value": true, "score": 0.9999338388442993}, "shared": {"value": false, "score": 5.4836273193359375e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CNN", "normalizedForm": "CNN", "offsetStart": 38, "offsetEnd": 41}, "context": "XCM outperforms both XCM-Seq and MTEX-CNN on average on the UEA datasets (rank: 2.3, XCM-Seq: 5.0, MTEX-CNN: 7.2).", "mentionContextAttributes": {"used": {"value": false, "score": 0.06691527366638184}, "created": {"value": false, "score": 3.0517578125e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997316002845764}, "created": {"value": true, "score": 0.9998825788497925}, "shared": {"value": false, "score": 1.430511474609375e-06}}, "references": [{"label": "[12]", "normalizedForm": "[12]", "refKey": 12}, {"label": "[12]", "normalizedForm": "[12]", "refKey": 12}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "XCM", "normalizedForm": "XCM", "offsetStart": 41, "offsetEnd": 44}, "context": "As presented in Table 4, we observe that XCM outperforms the current state-ofthe-art deep learning approach (MLSTM-FCN) and the reference commercial solution by increasing the average F1-score (69.7% versus 63.1 % and 55.3%) and obtaining the lowest variability across folds (1.5% versus 1.5% and 5.1%).", "mentionContextAttributes": {"used": {"value": false, "score": 0.003934919834136963}, "created": {"value": false, "score": 5.221366882324219e-05}, "shared": {"value": false, "score": 5.960464477539062e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999932050704956}, "created": {"value": true, "score": 0.9999338388442993}, "shared": {"value": false, "score": 5.4836273193359375e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "XCM", "normalizedForm": "XCM", "offsetStart": 43, "offsetEnd": 46}, "context": "All the networks that we implemented (XCM, XCM-Seq and MTEX-CNN) were trained with 100 epochs, the categorical crossentropy loss and the Adam optimization (computing infrastructure: Debian 8 operating system, GPU NVIDIA GeForce RTX 2080 Ti with 11Gb GRAM and 96Gb of RAM).", "mentionContextAttributes": {"used": {"value": true, "score": 0.9997316002845764}, "created": {"value": false, "score": 1.2278556823730469e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999932050704956}, "created": {"value": true, "score": 0.9999338388442993}, "shared": {"value": false, "score": 5.4836273193359375e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "XCM", "normalizedForm": "XCM", "offsetStart": 45, "offsetEnd": 48}, "context": "Finally, we end this section by showing that XCM outperforms the current most accurate state-of-the-art algorithm in a real-world application while providing faithful and more informative explanations.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0009684562683105469}, "created": {"value": false, "score": 0.2713872194290161}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999932050704956}, "created": {"value": true, "score": 0.9999338388442993}, "shared": {"value": false, "score": 5.4836273193359375e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "XCM", "normalizedForm": "XCM", "offsetStart": 46, "offsetEnd": 49}, "context": "We evaluate the classification performance of XCM and its explainability in Section 5.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9957459568977356}, "created": {"value": false, "score": 2.0384788513183594e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999932050704956}, "created": {"value": true, "score": 0.9999338388442993}, "shared": {"value": false, "score": 5.4836273193359375e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "XCM", "normalizedForm": "XCM", "offsetStart": 46, "offsetEnd": 49}, "context": "In our future work, we would like to automate XCM hyperparameter setting (Window Size) and evaluate the impact of different fusion methods of the 2D and 1D feature maps (e.g., weighting scheme) on XCM performance.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0007912516593933105}, "created": {"value": true, "score": 0.9997808337211609}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999932050704956}, "created": {"value": true, "score": 0.9999338388442993}, "shared": {"value": false, "score": 5.4836273193359375e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "XCM", "normalizedForm": "XCM", "offsetStart": 48, "offsetEnd": 51}, "context": "Therefore, in this work, we choose to benchmark XCM to the best-in-class for each similarity-based, feature-based and deep learning category (DTW D /DTW I , WEASEL+ MUSE and MLSTM-FCN classifiers).", "mentionContextAttributes": {"used": {"value": false, "score": 0.03093045949935913}, "created": {"value": true, "score": 0.9970675110816956}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999932050704956}, "created": {"value": true, "score": 0.9999338388442993}, "shared": {"value": false, "score": 5.4836273193359375e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "XCM", "normalizedForm": "XCM", "offsetStart": 48, "offsetEnd": 51}, "context": "In this section, we illustrate how our approach XCM reconciles performance and explainability and show that XCM enables a more precise identification of the regions of the input data that are important for predictions compared to the current deep learning MTS classifier also providing faithful explainability-MTEX-CNN.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0005757808685302734}, "created": {"value": false, "score": 0.4970887303352356}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999932050704956}, "created": {"value": true, "score": 0.9999338388442993}, "shared": {"value": false, "score": 5.4836273193359375e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "XCM", "normalizedForm": "XCM", "offsetStart": 48, "offsetEnd": 51}, "context": "We observe that the attribution maps drawn from XCM are more precise than the ones from MTEX-CNN, i.e., the intersection-over-union of the explanations is higher for XCM than for MTEX-CNN (intersection-over-union: XCM 0.65 versus MTEX-CNN 0.4).", "mentionContextAttributes": {"used": {"value": true, "score": 0.9954714775085449}, "created": {"value": false, "score": 1.6689300537109375e-06}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999932050704956}, "created": {"value": true, "score": 0.9999338388442993}, "shared": {"value": false, "score": 5.4836273193359375e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CNN", "normalizedForm": "CNN", "offsetStart": 49, "offsetEnd": 52}, "context": "Therefore, we support the predictions of our new CNN model XCM with Grad-CAM, a post hoc model-specific explainability method which provides faithful explanations at local level.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0001327991485595703}, "created": {"value": true, "score": 0.9947815537452698}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997316002845764}, "created": {"value": true, "score": 0.9998825788497925}, "shared": {"value": false, "score": 1.430511474609375e-06}}, "references": [{"label": "[12]", "normalizedForm": "[12]", "refKey": 12}, {"label": "[12]", "normalizedForm": "[12]", "refKey": 12}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CNN", "normalizedForm": "CNN", "offsetStart": 49, "offsetEnd": 52}, "context": "As illustrated in Figure 1, a recent explainable CNN, MTEX-CNN [12], proposes to use 2D and 1D convolution filters in sequence to extract key MTS information, i.e., information relative to the observed variables and time, respectively.", "mentionContextAttributes": {"used": {"value": false, "score": 6.604194641113281e-05}, "created": {"value": false, "score": 0.00017327070236206055}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997316002845764}, "created": {"value": true, "score": 0.9998825788497925}, "shared": {"value": false, "score": 1.430511474609375e-06}}, "references": [{"label": "[12]", "normalizedForm": "[12]", "refKey": 12}, {"label": "[12]", "normalizedForm": "[12]", "refKey": 12}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "XCM", "normalizedForm": "XCM", "offsetStart": 49, "offsetEnd": 52}, "context": "With regard to the hyperparameter Window Size of XCM, Figure 3 shows the average relative drop in performance across the datasets when using the other time window sizes than the one used in the best configuration given in Table 3.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9943354725837708}, "created": {"value": false, "score": 5.125999450683594e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999932050704956}, "created": {"value": true, "score": 0.9999338388442993}, "shared": {"value": false, "score": 5.4836273193359375e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "XCM", "normalizedForm": "XCM", "offsetStart": 50, "offsetEnd": 53}, "context": "The next section presents how the architecture of XCM allows the communication of explanations supporting the model predictions with Grad-CAM.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0001125335693359375}, "created": {"value": false, "score": 0.20616501569747925}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999932050704956}, "created": {"value": true, "score": 0.9999338388442993}, "shared": {"value": false, "score": 5.4836273193359375e-06}}}, {"type": "software", "software-type": "component", "software-name": {"rawForm": "scmamp", "normalizedForm": "scmamp", "offsetStart": 50, "offsetEnd": 56}, "context": "We used the implementation available in R package scmamp (https://www.rdocumentation.org/packages/scmamp/ ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9998045563697815}, "created": {"value": false, "score": 0.0005257725715637207}, "shared": {"value": false, "score": 0.3549800515174866}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9998045563697815}, "created": {"value": false, "score": 0.0005257725715637207}, "shared": {"value": false, "score": 0.3549800515174866}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CNN", "normalizedForm": "CNN", "offsetStart": 51, "offsetEnd": 54}, "context": "Therefore, we propose a new faithfully eXplainable CNN method for MTS classification (XCM) which improves MTEX-CNN in three substantial ways: (i) it generates features by extracting information relative to the observed variables and timestamps in parallel and directly from the input data; (ii) it enhances the generalization ability by adopting a compact architecture (in terms of the number of parameters); and (iii) it allows precise identification of the observed variables and timestamps of the input data that are important for predictions by avoiding upsampling processes.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0003489255905151367}, "created": {"value": false, "score": 0.18037843704223633}, "shared": {"value": false, "score": 1.1920928955078125e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997316002845764}, "created": {"value": true, "score": 0.9998825788497925}, "shared": {"value": false, "score": 1.430511474609375e-06}}, "references": [{"label": "[12]", "normalizedForm": "[12]", "refKey": 12}, {"label": "[12]", "normalizedForm": "[12]", "refKey": 12}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MTEX", "normalizedForm": "MTEX", "offsetStart": 51, "offsetEnd": 55}, "context": "There is no basis of comparison for MLSTM-FCN with MTEX-CNN [12] as MTEX-CNN has not been evaluated on public datasets.", "mentionContextAttributes": {"used": {"value": false, "score": 0.18324244022369385}, "created": {"value": false, "score": 4.649162292480469e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997316002845764}, "created": {"value": true, "score": 0.9856033325195312}, "shared": {"value": false, "score": 1.430511474609375e-06}}, "references": [{"label": "[12]", "normalizedForm": "[12]", "refKey": 12, "offsetStart": 10978, "offsetEnd": 10982}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CNN", "normalizedForm": "CNN", "offsetStart": 52, "offsetEnd": 55}, "context": "As illustrated in Figure 1, MTEX-CNN is a two-stage CNN network which first extracts information relative to each feature with 2D convolution filters and then extracts information relative to time with 1D convolution filters.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0010300874710083008}, "created": {"value": false, "score": 0.0003025531768798828}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997316002845764}, "created": {"value": true, "score": 0.9998825788497925}, "shared": {"value": false, "score": 1.430511474609375e-06}}, "references": [{"label": "[12]", "normalizedForm": "[12]", "refKey": 12}, {"label": "[12]", "normalizedForm": "[12]", "refKey": 12}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "XCM", "normalizedForm": "XCM", "offsetStart": 52, "offsetEnd": 55}, "context": "The accuracy results on the public UEA test sets of XCM and the other MTS classifiers are presented in Table 3.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9983400106430054}, "created": {"value": false, "score": 6.4373016357421875e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999932050704956}, "created": {"value": true, "score": 0.9999338388442993}, "shared": {"value": false, "score": 5.4836273193359375e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "XCM", "normalizedForm": "XCM", "offsetStart": 52, "offsetEnd": 55}, "context": "We can assume that the more compact architecture of XCM compared to the other deep learning classifiers provides a better generalization ability on the UEA datasets (average rank on the number of trainable parameters: XCM 1.7, MLSTM-FCN: 1.9, MTEX-CNN: 2.0).", "mentionContextAttributes": {"used": {"value": false, "score": 0.00446319580078125}, "created": {"value": false, "score": 3.2186508178710938e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999932050704956}, "created": {"value": true, "score": 0.9999338388442993}, "shared": {"value": false, "score": 5.4836273193359375e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "XCM", "normalizedForm": "XCM", "offsetStart": 53, "offsetEnd": 56}, "context": "Thus, based on the same attribution threshold (0.6), XCM allows a more precise identification of the regions of the input data that are important for predictions than MTEX-CNN.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0002937912940979004}, "created": {"value": false, "score": 3.933906555175781e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999932050704956}, "created": {"value": true, "score": 0.9999338388442993}, "shared": {"value": false, "score": 5.4836273193359375e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "XCM", "normalizedForm": "XCM", "offsetStart": 54, "offsetEnd": 57}, "context": "Therefore, (iii) the 2D and 1D convolution filters of XCM are fully padded.", "mentionContextAttributes": {"used": {"value": false, "score": 0.10378187894821167}, "created": {"value": false, "score": 3.933906555175781e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999932050704956}, "created": {"value": true, "score": 0.9999338388442993}, "shared": {"value": false, "score": 5.4836273193359375e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MTEX-CNN", "normalizedForm": "MTEX-CNN", "offsetStart": 54, "offsetEnd": 66}, "context": "As illustrated in Figure 1, a recent explainable CNN, MTEX-CNN [12], proposes to use 2D and 1D convolution filters in sequence to extract key MTS information, i.e., information relative to the observed variables and time, respectively. ", "mentionContextAttributes": {"used": {"value": false, "score": 6.604194641113281e-05}, "created": {"value": false, "score": 0.00017327070236206055}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.03140699863433838}, "created": {"value": false, "score": 0.0006378293037414551}, "shared": {"value": false, "score": 5.960464477539062e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MTEX", "normalizedForm": "MTEX", "offsetStart": 55, "offsetEnd": 59}, "context": "All the networks that we implemented (XCM, XCM-Seq and MTEX-CNN) were trained with 100 epochs, the categorical crossentropy loss and the Adam optimization (computing infrastructure: Debian 8 operating system, GPU NVIDIA GeForce RTX 2080 Ti with 11Gb GRAM and 96Gb of RAM). ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9997316002845764}, "created": {"value": false, "score": 1.2278556823730469e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997316002845764}, "created": {"value": true, "score": 0.9856033325195312}, "shared": {"value": false, "score": 1.430511474609375e-06}}, "references": [{"label": "[12]", "normalizedForm": "[12]", "refKey": 12}, {"label": "[12]", "normalizedForm": "[12]", "refKey": 12}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MTEX", "normalizedForm": "MTEX", "offsetStart": 55, "offsetEnd": 59}, "context": "However, as shown in Figure 5, the attribution maps of MTEX-CNN and XCM with the same explainability method (Grad-CAM) are different.", "mentionContextAttributes": {"used": {"value": false, "score": 0.2994080185890198}, "created": {"value": false, "score": 3.337860107421875e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997316002845764}, "created": {"value": true, "score": 0.9856033325195312}, "shared": {"value": false, "score": 1.430511474609375e-06}}, "references": [{"label": "[12]", "normalizedForm": "[12]", "refKey": 12}, {"label": "[12]", "normalizedForm": "[12]", "refKey": 12}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MTEX", "normalizedForm": "MTEX", "offsetStart": 55, "offsetEnd": 59}, "context": "Nonetheless, the observed variables attribution map of MTEX-CNN shows high attribution values on a window larger than the discriminative one (timestamps range [34,83], intersection-over-union: 0.41).", "mentionContextAttributes": {"used": {"value": false, "score": 0.4745708703994751}, "created": {"value": false, "score": 8.463859558105469e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997316002845764}, "created": {"value": true, "score": 0.9856033325195312}, "shared": {"value": false, "score": 1.430511474609375e-06}}, "references": [{"label": "[12]", "normalizedForm": "[12]", "refKey": 12}, {"label": "[12]", "normalizedForm": "[12]", "refKey": 12}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CNN", "normalizedForm": "CNN", "offsetStart": 56, "offsetEnd": 59}, "context": "There is no basis of comparison for MLSTM-FCN with MTEX-CNN [12] as MTEX-CNN has not been evaluated on public datasets.", "mentionContextAttributes": {"used": {"value": false, "score": 0.18324244022369385}, "created": {"value": false, "score": 4.649162292480469e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997316002845764}, "created": {"value": true, "score": 0.9998825788497925}, "shared": {"value": false, "score": 1.430511474609375e-06}}, "references": [{"label": "[12]", "normalizedForm": "[12]", "refKey": 12, "offsetStart": 10978, "offsetEnd": 10982}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "XCM", "normalizedForm": "XCM", "offsetStart": 56, "offsetEnd": 59}, "context": "Furthermore, the results confirm the superiority of the XCM approach based on the extraction in parallel and directly from the input data of features relative to the observed variables and time compared to the sequential approaches.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999595880508423}, "created": {"value": false, "score": 3.123283386230469e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999932050704956}, "created": {"value": true, "score": 0.9999338388442993}, "shared": {"value": false, "score": 5.4836273193359375e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "XCM", "normalizedForm": "XCM", "offsetStart": 56, "offsetEnd": 59}, "context": "This drop is below 15% on average on the category where XCM has the lowest level of accuracy (13.1% \u00b1 3.2%) and below 10% on average across all the datasets (7.0% \u00b1 1.3%).", "mentionContextAttributes": {"used": {"value": false, "score": 0.2952196002006531}, "created": {"value": false, "score": 3.707408905029297e-05}, "shared": {"value": false, "score": 5.960464477539062e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999932050704956}, "created": {"value": true, "score": 0.9999338388442993}, "shared": {"value": false, "score": 5.4836273193359375e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MTEX", "normalizedForm": "MTEX", "offsetStart": 57, "offsetEnd": 61}, "context": "Finally, deep learning methods (FCN [26], MLSTM-FCN [5], MTEX-CNN [12], ResNet [27], TapNet [28] and TST [29]) use Long-Short Term Memory (LSTM), Convolutional Neural Networks (CNN) or Transformers.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0006260275840759277}, "created": {"value": false, "score": 2.5033950805664062e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997316002845764}, "created": {"value": true, "score": 0.9856033325195312}, "shared": {"value": false, "score": 1.430511474609375e-06}}, "references": [{"label": "[12]", "normalizedForm": "[12]", "refKey": 12}, {"label": "[12]", "normalizedForm": "[12]", "refKey": 12}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CNN", "normalizedForm": "CNN", "offsetStart": 58, "offsetEnd": 61}, "context": "Our approach aims to design a new compact and explainable CNN architecture that performs well on both the large and small UEA datasets.", "mentionContextAttributes": {"used": {"value": false, "score": 6.210803985595703e-05}, "created": {"value": true, "score": 0.9998825788497925}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997316002845764}, "created": {"value": true, "score": 0.9998825788497925}, "shared": {"value": false, "score": 1.430511474609375e-06}}, "references": [{"label": "[12]", "normalizedForm": "[12]", "refKey": 12}, {"label": "[12]", "normalizedForm": "[12]", "refKey": 12}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "XCM", "normalizedForm": "XCM", "offsetStart": 59, "offsetEnd": 62}, "context": "Therefore, we support the predictions of our new CNN model XCM with Grad-CAM, a post hoc model-specific explainability method which provides faithful explanations at local level.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0001327991485595703}, "created": {"value": true, "score": 0.9947815537452698}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999932050704956}, "created": {"value": true, "score": 0.9999338388442993}, "shared": {"value": false, "score": 5.4836273193359375e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "XCM", "normalizedForm": "XCM", "offsetStart": 59, "offsetEnd": 62}, "context": "The following paragraphs explain how we adapt Grad-CAM for XCM.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00023216009140014648}, "created": {"value": true, "score": 0.5990254878997803}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999932050704956}, "created": {"value": true, "score": 0.9999338388442993}, "shared": {"value": false, "score": 5.4836273193359375e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "XCM", "normalizedForm": "XCM", "offsetStart": 59, "offsetEnd": 62}, "context": "The current state-of-the-art MTS classifiers MLSTM-FCN and XCM have different explainability methods (SHAP-post hoc model-agnostic, Grad-CAM-post hoc modelspecific) which come with their own form of explanations.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0005210041999816895}, "created": {"value": false, "score": 2.372264862060547e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999932050704956}, "created": {"value": true, "score": 0.9999338388442993}, "shared": {"value": false, "score": 5.4836273193359375e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CNN", "normalizedForm": "CNN", "offsetStart": 60, "offsetEnd": 63}, "context": "All the networks that we implemented (XCM, XCM-Seq and MTEX-CNN) were trained with 100 epochs, the categorical crossentropy loss and the Adam optimization (computing infrastructure: Debian 8 operating system, GPU NVIDIA GeForce RTX 2080 Ti with 11Gb GRAM and 96Gb of RAM).", "mentionContextAttributes": {"used": {"value": true, "score": 0.9997316002845764}, "created": {"value": false, "score": 1.2278556823730469e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997316002845764}, "created": {"value": true, "score": 0.9998825788497925}, "shared": {"value": false, "score": 1.430511474609375e-06}}, "references": [{"label": "[12]", "normalizedForm": "[12]", "refKey": 12}, {"label": "[12]", "normalizedForm": "[12]", "refKey": 12}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CNN", "normalizedForm": "CNN", "offsetStart": 60, "offsetEnd": 63}, "context": "However, as shown in Figure 5, the attribution maps of MTEX-CNN and XCM with the same explainability method (Grad-CAM) are different.", "mentionContextAttributes": {"used": {"value": false, "score": 0.2994080185890198}, "created": {"value": false, "score": 3.337860107421875e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997316002845764}, "created": {"value": true, "score": 0.9998825788497925}, "shared": {"value": false, "score": 1.430511474609375e-06}}, "references": [{"label": "[12]", "normalizedForm": "[12]", "refKey": 12}, {"label": "[12]", "normalizedForm": "[12]", "refKey": 12}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CNN", "normalizedForm": "CNN", "offsetStart": 60, "offsetEnd": 63}, "context": "Nonetheless, the observed variables attribution map of MTEX-CNN shows high attribution values on a window larger than the discriminative one (timestamps range [34,83], intersection-over-union: 0.41).", "mentionContextAttributes": {"used": {"value": false, "score": 0.4745708703994751}, "created": {"value": false, "score": 8.463859558105469e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997316002845764}, "created": {"value": true, "score": 0.9998825788497925}, "shared": {"value": false, "score": 1.430511474609375e-06}}, "references": [{"label": "[12]", "normalizedForm": "[12]", "refKey": 12}, {"label": "[12]", "normalizedForm": "[12]", "refKey": 12}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "XCM", "normalizedForm": "XCM", "offsetStart": 61, "offsetEnd": 64}, "context": "In this section, we first present the performance results of XCM on the public UEA datasets.", "mentionContextAttributes": {"used": {"value": true, "score": 0.7495940327644348}, "created": {"value": true, "score": 0.9986962676048279}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999932050704956}, "created": {"value": true, "score": 0.9999338388442993}, "shared": {"value": false, "score": 5.4836273193359375e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "XCM", "normalizedForm": "XCM", "offsetStart": 61, "offsetEnd": 64}, "context": "The plot confirms the top three ranking as presented before (XCM: 1, MLSTM-FCN: 2, and WEASEL+MUSE: 3), without showing a statistically significant difference between each other.", "mentionContextAttributes": {"used": {"value": true, "score": 0.8915347456932068}, "created": {"value": false, "score": 2.110004425048828e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999932050704956}, "created": {"value": true, "score": 0.9999338388442993}, "shared": {"value": false, "score": 5.4836273193359375e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CNN", "normalizedForm": "CNN", "offsetStart": 62, "offsetEnd": 65}, "context": "Finally, deep learning methods (FCN [26], MLSTM-FCN [5], MTEX-CNN [12], ResNet [27], TapNet [28] and TST [29]) use Long-Short Term Memory (LSTM), Convolutional Neural Networks (CNN) or Transformers.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0006260275840759277}, "created": {"value": false, "score": 2.5033950805664062e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997316002845764}, "created": {"value": true, "score": 0.9998825788497925}, "shared": {"value": false, "score": 1.430511474609375e-06}}, "references": [{"label": "[12]", "normalizedForm": "[12]", "refKey": 12}, {"label": "[12]", "normalizedForm": "[12]", "refKey": 12}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CNN", "normalizedForm": "CNN", "offsetStart": 63, "offsetEnd": 66}, "context": "As previously introduced with the example of the GDPR, our new CNN approach needs to be able to support each individual prediction.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00011551380157470703}, "created": {"value": true, "score": 0.9981032609939575}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997316002845764}, "created": {"value": true, "score": 0.9998825788497925}, "shared": {"value": false, "score": 1.430511474609375e-06}}, "references": [{"label": "[12]", "normalizedForm": "[12]", "refKey": 12}, {"label": "[12]", "normalizedForm": "[12]", "refKey": 12}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "XCM", "normalizedForm": "XCM", "offsetStart": 63, "offsetEnd": 66}, "context": "Therefore, aside from automating the hyperparameter setting of XCM (Window Size), it would be interesting to work on synthesizing the attribution maps to improve the level of information.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00037598609924316406}, "created": {"value": false, "score": 0.047014713287353516}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999932050704956}, "created": {"value": true, "score": 0.9999338388442993}, "shared": {"value": false, "score": 5.4836273193359375e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MTEX", "normalizedForm": "MTEX", "offsetStart": 63, "offsetEnd": 67}, "context": "In addition, the significant number of trainable parameters of MTEX-CNN affects its generalization ability on small datasets. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.00031626224517822266}, "created": {"value": false, "score": 5.996227264404297e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997316002845764}, "created": {"value": true, "score": 0.9856033325195312}, "shared": {"value": false, "score": 1.430511474609375e-06}}, "references": [{"label": "[12]", "normalizedForm": "[12]", "refKey": 12}, {"label": "[12]", "normalizedForm": "[12]", "refKey": 12}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MTEX-CNN", "normalizedForm": "MTEX-CNN", "offsetStart": 63, "offsetEnd": 71}, "context": "Finally, the use of non fully padded convolution filters as in MTEX-CNN can lead to an imprecise identification of the regions of the input data that are important for predictions as Grad-CAM is sensitive to upsampling processes. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.00019294023513793945}, "created": {"value": false, "score": 3.612041473388672e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.03140699863433838}, "created": {"value": false, "score": 0.0006378293037414551}, "shared": {"value": false, "score": 5.960464477539062e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "XCM", "normalizedForm": "XCM", "offsetStart": 64, "offsetEnd": 67}, "context": "Before discussing the performance and explainability results of XCM, we present in the next section the evaluation setting.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9435749650001526}, "created": {"value": true, "score": 0.513619601726532}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999932050704956}, "created": {"value": true, "score": 0.9999338388442993}, "shared": {"value": false, "score": 5.4836273193359375e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CNN", "normalizedForm": "CNN", "offsetStart": 68, "offsetEnd": 71}, "context": "In addition, the significant number of trainable parameters of MTEX-CNN affects its generalization ability on small datasets.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00031626224517822266}, "created": {"value": false, "score": 5.996227264404297e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997316002845764}, "created": {"value": true, "score": 0.9998825788497925}, "shared": {"value": false, "score": 1.430511474609375e-06}}, "references": [{"label": "[12]", "normalizedForm": "[12]", "refKey": 12}, {"label": "[12]", "normalizedForm": "[12]", "refKey": 12}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "XCM", "normalizedForm": "XCM", "offsetStart": 68, "offsetEnd": 71}, "context": "However, as shown in Figure 5, the attribution maps of MTEX-CNN and XCM with the same explainability method (Grad-CAM) are different.", "mentionContextAttributes": {"used": {"value": false, "score": 0.2994080185890198}, "created": {"value": false, "score": 3.337860107421875e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999932050704956}, "created": {"value": true, "score": 0.9999338388442993}, "shared": {"value": false, "score": 5.4836273193359375e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "XCM", "normalizedForm": "XCM", "offsetStart": 68, "offsetEnd": 71}, "context": "Following the illustration of the performance and explainability of XCM on a synthetic dataset, we showed how XCM can outperform the current most accurate state-of-the-art algorithm MLSTM-FCN on a real-world application while enhancing explainability by providing faithful and more informative explanations.", "mentionContextAttributes": {"used": {"value": true, "score": 0.8783320784568787}, "created": {"value": false, "score": 0.1116795539855957}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999932050704956}, "created": {"value": true, "score": 0.9999338388442993}, "shared": {"value": false, "score": 5.4836273193359375e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MTEX", "normalizedForm": "MTEX", "offsetStart": 68, "offsetEnd": 72}, "context": "There is no basis of comparison for MLSTM-FCN with MTEX-CNN [12] as MTEX-CNN has not been evaluated on public datasets.", "mentionContextAttributes": {"used": {"value": false, "score": 0.18324244022369385}, "created": {"value": false, "score": 4.649162292480469e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997316002845764}, "created": {"value": true, "score": 0.9856033325195312}, "shared": {"value": false, "score": 1.430511474609375e-06}}, "references": [{"label": "[12]", "normalizedForm": "[12]", "refKey": 12}, {"label": "[12]", "normalizedForm": "[12]", "refKey": 12}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "WEASEL+MUSE", "normalizedForm": "WEASEL+MUSE", "offsetStart": 68, "offsetEnd": 79}, "context": "On the other hand, BoW models (LPS [23], mv-ARF [24], SMTS [25] and WEASEL+MUSE [6]) convert time series into a bag of discrete words and use a histogram of words representation to perform the classification.", "mentionContextAttributes": {"used": {"value": false, "score": 0.000988602638244629}, "created": {"value": false, "score": 1.3709068298339844e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999837875366211}, "created": {"value": false, "score": 3.218650817871094e-05}, "shared": {"value": false, "score": 1.6689300537109375e-06}}, "references": [{"label": "[6]", "normalizedForm": "[6]", "refKey": 6, "offsetStart": 9491, "offsetEnd": 9494}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "XCM", "normalizedForm": "XCM", "offsetStart": 69, "offsetEnd": 72}, "context": "We observe that XCM and MTEX-CNN obtain the same performance whereas XCM has around 10 times fewer parameters than MTEX-CNN (trainable parameters: XCM 17k, MTEX-CNN 232k).", "mentionContextAttributes": {"used": {"value": true, "score": 0.6832642555236816}, "created": {"value": false, "score": 3.5762786865234375e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999932050704956}, "created": {"value": true, "score": 0.9999338388442993}, "shared": {"value": false, "score": 5.4836273193359375e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "XCM", "normalizedForm": "XCM", "offsetStart": 69, "offsetEnd": 72}, "context": "On the time attribution map, high attribution values (above 0.6) for XCM begin on timestamp 63 and end on timestamp 76 (expected: [60, 80], intersection-over-union: 0.65), whereas for MTEX-CNN they begin later (timestamp 68, intersection-over-union: 0.4).", "mentionContextAttributes": {"used": {"value": true, "score": 0.5550888180732727}, "created": {"value": false, "score": 1.5497207641601562e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999932050704956}, "created": {"value": true, "score": 0.9999338388442993}, "shared": {"value": false, "score": 5.4836273193359375e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "XCM", "normalizedForm": "XCM", "offsetStart": 70, "offsetEnd": 73}, "context": "Therefore, considering that XCM-Seq attributions maps are the same as XCM ones, we can assume that the use of half padding on the different convolution layers to reduce the number of parameters in MTEX-CNN, i.e., the use of upsampling to retrieve the input data dimensions on the attribution maps, can lead to a less precise identification of the regions of the input data that are important for predictions.", "mentionContextAttributes": {"used": {"value": true, "score": 0.715061366558075}, "created": {"value": false, "score": 1.990795135498047e-05}, "shared": {"value": false, "score": 1.430511474609375e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999932050704956}, "created": {"value": true, "score": 0.9999338388442993}, "shared": {"value": false, "score": 5.4836273193359375e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "WEASEL +MUSE", "normalizedForm": "WEASEL +MUSE", "offsetStart": 70, "offsetEnd": 82}, "context": "More specifically, XCM exhibits better performance than MLSTM-FCN and WEASEL +MUSE on both the large (rank: 1.9, MLSTM-FCN rank: 2.1, WEASEL+MUSE rank: 4.6-train size \u2265 500, 23% of the datasets) and small datasets (rank: 2.4, MLSTM-FCN rank: 4.0, WEASEL+MUSE rank: 3.9-train size < 500, 77% of the datasets).", "mentionContextAttributes": {"used": {"value": true, "score": 0.6560125350952148}, "created": {"value": false, "score": 2.1457672119140625e-06}, "shared": {"value": false, "score": 7.152557373046875e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.6560125350952148}, "created": {"value": false, "score": 2.1457672119140625e-06}, "shared": {"value": false, "score": 7.152557373046875e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "XCM", "normalizedForm": "XCM", "offsetStart": 71, "offsetEnd": 74}, "context": "These attribution maps constitute the explanations provided to support XCM model predictions and are available at the sample level.", "mentionContextAttributes": {"used": {"value": false, "score": 0.48940807580947876}, "created": {"value": false, "score": 0.00047588348388671875}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999932050704956}, "created": {"value": true, "score": 0.9999338388442993}, "shared": {"value": false, "score": 5.4836273193359375e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "XCM", "normalizedForm": "XCM", "offsetStart": 72, "offsetEnd": 75}, "context": "Finally, we performed a statistical test to evaluate the performance of XCM compared to the other MTS classifiers.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999932050704956}, "created": {"value": false, "score": 0.0001887679100036621}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999932050704956}, "created": {"value": true, "score": 0.9999338388442993}, "shared": {"value": false, "score": 5.4836273193359375e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CNN", "normalizedForm": "CNN", "offsetStart": 73, "offsetEnd": 76}, "context": "There is no basis of comparison for MLSTM-FCN with MTEX-CNN [12] as MTEX-CNN has not been evaluated on public datasets.", "mentionContextAttributes": {"used": {"value": false, "score": 0.18324244022369385}, "created": {"value": false, "score": 4.649162292480469e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997316002845764}, "created": {"value": true, "score": 0.9998825788497925}, "shared": {"value": false, "score": 1.430511474609375e-06}}, "references": [{"label": "[12]", "normalizedForm": "[12]", "refKey": 12}, {"label": "[12]", "normalizedForm": "[12]", "refKey": 12}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "XCM", "normalizedForm": "XCM", "offsetStart": 73, "offsetEnd": 76}, "context": "Furthermore, unlike MLSTM-FCN with SHAP and as discussed in Section 2.3, XCM with Grad-CAM approach provides faithful explanations, which is a prerequisite to reduce solution mistrust from the farmers (Faithfulness: MLSTM-FCN with SHAP-Imperfect and XCM with Grad-CAM-Perfect).", "mentionContextAttributes": {"used": {"value": false, "score": 0.0018808245658874512}, "created": {"value": false, "score": 3.4570693969726562e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999932050704956}, "created": {"value": true, "score": 0.9999338388442993}, "shared": {"value": false, "score": 5.4836273193359375e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "XCM", "normalizedForm": "XCM", "offsetStart": 74, "offsetEnd": 77}, "context": "More specifically, Grad-CAM can output two types of attribution maps from XCM architecture: one related to observed variables and another one related to time.", "mentionContextAttributes": {"used": {"value": false, "score": 4.947185516357422e-05}, "created": {"value": false, "score": 2.5987625122070312e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999932050704956}, "created": {"value": true, "score": 0.9999338388442993}, "shared": {"value": false, "score": 5.4836273193359375e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CNN", "normalizedForm": "CNN", "offsetStart": 75, "offsetEnd": 78}, "context": "A recent network, TapNet [28], also consists of a LSTM layer and a stacked CNN layer, followed by an attentional prototype network.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00011909008026123047}, "created": {"value": false, "score": 0.0006535649299621582}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997316002845764}, "created": {"value": true, "score": 0.9998825788497925}, "shared": {"value": false, "score": 1.430511474609375e-06}}, "references": [{"label": "[12]", "normalizedForm": "[12]", "refKey": 12}, {"label": "[12]", "normalizedForm": "[12]", "refKey": 12}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CNN", "normalizedForm": "CNN", "offsetStart": 76, "offsetEnd": 79}, "context": "As far as we have seen, an architecture concatenating a LSTM network with a CNN such as MLSTM-FCN, or a classifier based on unigrams/bigrams extraction following a Symbolic Fourier Approximation [8] such as WEASEL+MUSE, cannot provide perfectly faithful explanations as they rely solely on post hoc model-agnostic explainability methods [9], which could prevent their use in numerous applications.", "mentionContextAttributes": {"used": {"value": false, "score": 0.03177952766418457}, "created": {"value": false, "score": 3.218650817871094e-05}, "shared": {"value": false, "score": 7.152557373046875e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997316002845764}, "created": {"value": true, "score": 0.9998825788497925}, "shared": {"value": false, "score": 1.430511474609375e-06}}, "references": [{"label": "[12]", "normalizedForm": "[12]", "refKey": 12}, {"label": "[12]", "normalizedForm": "[12]", "refKey": 12}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CNN", "normalizedForm": "CNN", "offsetStart": 76, "offsetEnd": 79}, "context": "As far as we have seen, an architecture concatenating a LSTM network with a CNN such as MLSTM-FCN can only rely on post hoc model-agnostic explainability methods to support its predictions.", "mentionContextAttributes": {"used": {"value": false, "score": 7.796287536621094e-05}, "created": {"value": false, "score": 0.07061278820037842}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997316002845764}, "created": {"value": true, "score": 0.9998825788497925}, "shared": {"value": false, "score": 1.430511474609375e-06}}, "references": [{"label": "[12]", "normalizedForm": "[12]", "refKey": 12}, {"label": "[12]", "normalizedForm": "[12]", "refKey": 12}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "XCM", "normalizedForm": "XCM", "offsetStart": 80, "offsetEnd": 83}, "context": "We see in Figure 7 that the level of information of the explanation provided by XCM with Grad-CAM (Features+Time+Values) could be enhanced.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9995397329330444}, "created": {"value": false, "score": 3.886222839355469e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999932050704956}, "created": {"value": true, "score": 0.9999338388442993}, "shared": {"value": false, "score": 5.4836273193359375e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "WEASEL+MUSE", "normalizedForm": "WEASEL+MUSE", "offsetStart": 83, "offsetEnd": 94}, "context": "However, MLSTM-FCN outperforms the second-best MTS classifier (Bag-of-Words method WEASEL+MUSE [6]) only on the large datasets (relatively to the public UEA archive [7]training set size \u2265 500).", "mentionContextAttributes": {"used": {"value": false, "score": 0.006712496280670166}, "created": {"value": false, "score": 9.059906005859375e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999837875366211}, "created": {"value": false, "score": 3.218650817871094e-05}, "shared": {"value": false, "score": 1.6689300537109375e-06}}, "references": [{"label": "[6]", "normalizedForm": "[6]", "refKey": 6, "offsetStart": 1107, "offsetEnd": 1110}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "XCM", "normalizedForm": "XCM", "offsetStart": 85, "offsetEnd": 88}, "context": "XCM outperforms both XCM-Seq and MTEX-CNN on average on the UEA datasets (rank: 2.3, XCM-Seq: 5.0, MTEX-CNN: 7.2).", "mentionContextAttributes": {"used": {"value": false, "score": 0.06691527366638184}, "created": {"value": false, "score": 3.0517578125e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999932050704956}, "created": {"value": true, "score": 0.9999338388442993}, "shared": {"value": false, "score": 5.4836273193359375e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "XCM", "normalizedForm": "XCM", "offsetStart": 86, "offsetEnd": 89}, "context": "Therefore, we propose a new faithfully eXplainable CNN method for MTS classification (XCM) which improves MTEX-CNN in three substantial ways: (i) it generates features by extracting information relative to the observed variables and timestamps in parallel and directly from the input data; (ii) it enhances the generalization ability by adopting a compact architecture (in terms of the number of parameters); and (iii) it allows precise identification of the observed variables and timestamps of the input data that are important for predictions by avoiding upsampling processes.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0003489255905151367}, "created": {"value": false, "score": 0.18037843704223633}, "shared": {"value": false, "score": 1.1920928955078125e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999932050704956}, "created": {"value": true, "score": 0.9999338388442993}, "shared": {"value": false, "score": 5.4836273193359375e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "WEASEL+MUSE", "normalizedForm": "WEASEL+MUSE", "offsetStart": 87, "offsetEnd": 98}, "context": "The plot confirms the top three ranking as presented before (XCM: 1, MLSTM-FCN: 2, and WEASEL+MUSE: 3), without showing a statistically significant difference between each other.", "mentionContextAttributes": {"used": {"value": true, "score": 0.8915347456932068}, "created": {"value": false, "score": 2.110004425048828e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999837875366211}, "created": {"value": false, "score": 3.218650817871094e-05}, "shared": {"value": false, "score": 1.6689300537109375e-06}}, "references": [{"label": "[6]", "normalizedForm": "[6]", "refKey": 6}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MTEX", "normalizedForm": "MTEX", "offsetStart": 88, "offsetEnd": 92}, "context": "We observe that the attribution maps drawn from XCM are more precise than the ones from MTEX-CNN, i.e., the intersection-over-union of the explanations is higher for XCM than for MTEX-CNN (intersection-over-union: XCM 0.65 versus MTEX-CNN 0.4).", "mentionContextAttributes": {"used": {"value": true, "score": 0.9954714775085449}, "created": {"value": false, "score": 1.6689300537109375e-06}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997316002845764}, "created": {"value": true, "score": 0.9856033325195312}, "shared": {"value": false, "score": 1.430511474609375e-06}}, "references": [{"label": "[12]", "normalizedForm": "[12]", "refKey": 12}, {"label": "[12]", "normalizedForm": "[12]", "refKey": 12}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "XCM", "normalizedForm": "XCM", "offsetStart": 89, "offsetEnd": 92}, "context": "The first part details the architecture of the network, and the second part explains how XCM can provide explanations by identifying the observed variables and timestamps of the input data that are important for predictions.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0015954375267028809}, "created": {"value": false, "score": 0.0007464289665222168}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999932050704956}, "created": {"value": true, "score": 0.9999338388442993}, "shared": {"value": false, "score": 5.4836273193359375e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MTEX", "normalizedForm": "MTEX", "offsetStart": 92, "offsetEnd": 96}, "context": "We also include MTEX-CNN in the benchmark to demonstrate the superiority of our approach as MTEX-CNN has not been evaluated on the public UEA datasets.", "mentionContextAttributes": {"used": {"value": false, "score": 0.2156417965888977}, "created": {"value": false, "score": 0.031333208084106445}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997316002845764}, "created": {"value": true, "score": 0.9856033325195312}, "shared": {"value": false, "score": 1.430511474609375e-06}}, "references": [{"label": "[12]", "normalizedForm": "[12]", "refKey": 12}, {"label": "[12]", "normalizedForm": "[12]", "refKey": 12}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CNN", "normalizedForm": "CNN", "offsetStart": 93, "offsetEnd": 96}, "context": "We observe that the attribution maps drawn from XCM are more precise than the ones from MTEX-CNN, i.e., the intersection-over-union of the explanations is higher for XCM than for MTEX-CNN (intersection-over-union: XCM 0.65 versus MTEX-CNN 0.4).", "mentionContextAttributes": {"used": {"value": true, "score": 0.9954714775085449}, "created": {"value": false, "score": 1.6689300537109375e-06}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997316002845764}, "created": {"value": true, "score": 0.9998825788497925}, "shared": {"value": false, "score": 1.430511474609375e-06}}, "references": [{"label": "[12]", "normalizedForm": "[12]", "refKey": 12}, {"label": "[12]", "normalizedForm": "[12]", "refKey": 12}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "XCM", "normalizedForm": "XCM", "offsetStart": 94, "offsetEnd": 97}, "context": "3. The performance drop is presented across four categories of datasets, defined according to XCM levels of accuracy shown in Table 3. Abbreviation: Acc-Accuracy.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9598994255065918}, "created": {"value": false, "score": 3.719329833984375e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999932050704956}, "created": {"value": true, "score": 0.9999338388442993}, "shared": {"value": false, "score": 5.4836273193359375e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "XCM", "normalizedForm": "XCM", "offsetStart": 94, "offsetEnd": 97}, "context": "With regard to explainability, it would be interesting to further enhance the explanations of XCM with Grad-CAM by synthesizing the attribution maps with multidimensional sequential patterns to improve the level of information.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0013917088508605957}, "created": {"value": false, "score": 0.0004196763038635254}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999932050704956}, "created": {"value": true, "score": 0.9999338388442993}, "shared": {"value": false, "score": 5.4836273193359375e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CNN", "normalizedForm": "CNN", "offsetStart": 97, "offsetEnd": 100}, "context": "We also include MTEX-CNN in the benchmark to demonstrate the superiority of our approach as MTEX-CNN has not been evaluated on the public UEA datasets.", "mentionContextAttributes": {"used": {"value": false, "score": 0.2156417965888977}, "created": {"value": false, "score": 0.031333208084106445}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997316002845764}, "created": {"value": true, "score": 0.9998825788497925}, "shared": {"value": false, "score": 1.430511474609375e-06}}, "references": [{"label": "[12]", "normalizedForm": "[12]", "refKey": 12}, {"label": "[12]", "normalizedForm": "[12]", "refKey": 12}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "scmamp", "normalizedForm": "scmamp", "offsetStart": 98, "offsetEnd": 104}, "context": "We used the implementation available in R package scmamp (https://www.rdocumentation.org/packages/scmamp/", "mentionContextAttributes": {"used": {"value": true, "score": 0.9998045563697815}, "created": {"value": false, "score": 0.0005257725715637207}, "shared": {"value": false, "score": 0.3549800515174866}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9998045563697815}, "created": {"value": false, "score": 0.0005257725715637207}, "shared": {"value": false, "score": 0.3549800515174866}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MTEX", "normalizedForm": "MTEX", "offsetStart": 99, "offsetEnd": 103}, "context": "XCM outperforms both XCM-Seq and MTEX-CNN on average on the UEA datasets (rank: 2.3, XCM-Seq: 5.0, MTEX-CNN: 7.2).", "mentionContextAttributes": {"used": {"value": false, "score": 0.06691527366638184}, "created": {"value": false, "score": 3.0517578125e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997316002845764}, "created": {"value": true, "score": 0.9856033325195312}, "shared": {"value": false, "score": 1.430511474609375e-06}}, "references": [{"label": "[12]", "normalizedForm": "[12]", "refKey": 12}, {"label": "[12]", "normalizedForm": "[12]", "refKey": 12}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CNN", "normalizedForm": "CNN", "offsetStart": 104, "offsetEnd": 107}, "context": "XCM outperforms both XCM-Seq and MTEX-CNN on average on the UEA datasets (rank: 2.3, XCM-Seq: 5.0, MTEX-CNN: 7.2).", "mentionContextAttributes": {"used": {"value": false, "score": 0.06691527366638184}, "created": {"value": false, "score": 3.0517578125e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997316002845764}, "created": {"value": true, "score": 0.9998825788497925}, "shared": {"value": false, "score": 1.430511474609375e-06}}, "references": [{"label": "[12]", "normalizedForm": "[12]", "refKey": 12}, {"label": "[12]", "normalizedForm": "[12]", "refKey": 12}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MTEX", "normalizedForm": "MTEX", "offsetStart": 106, "offsetEnd": 110}, "context": "Therefore, we propose a new faithfully eXplainable CNN method for MTS classification (XCM) which improves MTEX-CNN in three substantial ways: (i) it generates features by extracting information relative to the observed variables and timestamps in parallel and directly from the input data; (ii) it enhances the generalization ability by adopting a compact architecture (in terms of the number of parameters); and (iii) it allows precise identification of the observed variables and timestamps of the input data that are important for predictions by avoiding upsampling processes.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0003489255905151367}, "created": {"value": false, "score": 0.18037843704223633}, "shared": {"value": false, "score": 1.1920928955078125e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997316002845764}, "created": {"value": true, "score": 0.9856033325195312}, "shared": {"value": false, "score": 1.430511474609375e-06}}, "references": [{"label": "[12]", "normalizedForm": "[12]", "refKey": 12}, {"label": "[12]", "normalizedForm": "[12]", "refKey": 12}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "XCM", "normalizedForm": "XCM", "offsetStart": 108, "offsetEnd": 111}, "context": "In this section, we illustrate how our approach XCM reconciles performance and explainability and show that XCM enables a more precise identification of the regions of the input data that are important for predictions compared to the current deep learning MTS classifier also providing faithful explainability-MTEX-CNN.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0005757808685302734}, "created": {"value": false, "score": 0.4970887303352356}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999932050704956}, "created": {"value": true, "score": 0.9999338388442993}, "shared": {"value": false, "score": 5.4836273193359375e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "XCM", "normalizedForm": "XCM", "offsetStart": 110, "offsetEnd": 113}, "context": "However, in addition to giving the relative importance of observed variables and time as MLSTM-FCN with SHAP, XCM with Grad-CAM provides more informative explanations by supplying the corresponding sample values (Information: MLSTM-FCN with SHAP-Features+Time and XCM with Grad-CAM-Features+Time+Values).", "mentionContextAttributes": {"used": {"value": false, "score": 0.02050602436065674}, "created": {"value": false, "score": 1.5497207641601562e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999932050704956}, "created": {"value": true, "score": 0.9999338388442993}, "shared": {"value": false, "score": 5.4836273193359375e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "XCM", "normalizedForm": "XCM", "offsetStart": 110, "offsetEnd": 113}, "context": "Following the illustration of the performance and explainability of XCM on a synthetic dataset, we showed how XCM can outperform the current most accurate state-of-the-art algorithm MLSTM-FCN on a real-world application while enhancing explainability by providing faithful and more informative explanations.", "mentionContextAttributes": {"used": {"value": true, "score": 0.8783320784568787}, "created": {"value": false, "score": 0.1116795539855957}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999932050704956}, "created": {"value": true, "score": 0.9999338388442993}, "shared": {"value": false, "score": 5.4836273193359375e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CNN", "normalizedForm": "CNN", "offsetStart": 111, "offsetEnd": 114}, "context": "Therefore, we propose a new faithfully eXplainable CNN method for MTS classification (XCM) which improves MTEX-CNN in three substantial ways: (i) it generates features by extracting information relative to the observed variables and timestamps in parallel and directly from the input data; (ii) it enhances the generalization ability by adopting a compact architecture (in terms of the number of parameters); and (iii) it allows precise identification of the observed variables and timestamps of the input data that are important for predictions by avoiding upsampling processes.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0003489255905151367}, "created": {"value": false, "score": 0.18037843704223633}, "shared": {"value": false, "score": 1.1920928955078125e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997316002845764}, "created": {"value": true, "score": 0.9998825788497925}, "shared": {"value": false, "score": 1.430511474609375e-06}}, "references": [{"label": "[12]", "normalizedForm": "[12]", "refKey": 12}, {"label": "[12]", "normalizedForm": "[12]", "refKey": 12}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "-CAM", "normalizedForm": "-CAM", "offsetStart": 112, "offsetEnd": 116}, "context": "We chose the state-of-the-art explainability method SHAP as its granularity of explanation is comparable to Grad-CAM (both global and local). ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9987965822219849}, "created": {"value": false, "score": 0.0009434819221496582}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997251629829407}, "created": {"value": false, "score": 0.002720654010772705}, "shared": {"value": false, "score": 0.25355058908462524}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MTEX", "normalizedForm": "MTEX", "offsetStart": 115, "offsetEnd": 119}, "context": "We observe that XCM and MTEX-CNN obtain the same performance whereas XCM has around 10 times fewer parameters than MTEX-CNN (trainable parameters: XCM 17k, MTEX-CNN 232k).", "mentionContextAttributes": {"used": {"value": true, "score": 0.6832642555236816}, "created": {"value": false, "score": 3.5762786865234375e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997316002845764}, "created": {"value": true, "score": 0.9856033325195312}, "shared": {"value": false, "score": 1.430511474609375e-06}}, "references": [{"label": "[12]", "normalizedForm": "[12]", "refKey": 12}, {"label": "[12]", "normalizedForm": "[12]", "refKey": 12}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "XCM", "normalizedForm": "XCM", "offsetStart": 117, "offsetEnd": 120}, "context": "First, as expected, we observe that the average relative impact of using suboptimal time window sizes is higher when XCM level of performance is low (average relative drop in accuracy: 13.1% when XCM accuracy < 50% versus 3.0% when XCM accuracy \u2265 90%).", "mentionContextAttributes": {"used": {"value": true, "score": 0.9327999949455261}, "created": {"value": false, "score": 2.8252601623535156e-05}, "shared": {"value": false, "score": 5.960464477539062e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999932050704956}, "created": {"value": true, "score": 0.9999338388442993}, "shared": {"value": false, "score": 5.4836273193359375e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MTEX", "normalizedForm": "MTEX", "offsetStart": 117, "offsetEnd": 121}, "context": "However, the red color gradient is due to the upsampling processes needed to match the 2D/1D output features maps of MTEX-CNN to the size of the input data when applying Grad-CAM.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9689474105834961}, "created": {"value": false, "score": 9.655952453613281e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997316002845764}, "created": {"value": true, "score": 0.9856033325195312}, "shared": {"value": false, "score": 1.430511474609375e-06}}, "references": [{"label": "[12]", "normalizedForm": "[12]", "refKey": 12}, {"label": "[12]", "normalizedForm": "[12]", "refKey": 12}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CNN", "normalizedForm": "CNN", "offsetStart": 118, "offsetEnd": 121}, "context": "MLSTM-FCN consists of the concatenation of a Long Short-Term Memory (LSTM) block with a Convolutional Neural Network (CNN) block composed of three convolutional sub-blocks.", "mentionContextAttributes": {"used": {"value": false, "score": 0.018637657165527344}, "created": {"value": false, "score": 3.3736228942871094e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997316002845764}, "created": {"value": true, "score": 0.9998825788497925}, "shared": {"value": false, "score": 1.430511474609375e-06}}, "references": [{"label": "[12]", "normalizedForm": "[12]", "refKey": 12}, {"label": "[12]", "normalizedForm": "[12]", "refKey": 12}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "WEASEL+MUSE", "normalizedForm": "WEASEL+MUSE", "offsetStart": 119, "offsetEnd": 130}, "context": "4. Dense layer dimension 128 and L2 regularization 0.2) and with the following hyperparameter: batch size {1, 8, 32};\u2022 WEASEL+MUSE: we used the implementation available (https://github.com/patrickzib/", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999145269393921}, "created": {"value": false, "score": 1.4185905456542969e-05}, "shared": {"value": false, "score": 1.6689300537109375e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999837875366211}, "created": {"value": false, "score": 3.218650817871094e-05}, "shared": {"value": false, "score": 1.6689300537109375e-06}}, "references": [{"label": "[6]", "normalizedForm": "[6]", "refKey": 6}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "WEASEL+MUSE", "normalizedForm": "WEASEL+MUSE", "offsetStart": 119, "offsetEnd": 130}, "context": "4. Dense layer dimension 128 and L2 regularization 0.2) and with the following hyperparameter: batch size {1, 8, 32};\u2022 WEASEL+MUSE: we used the implementation available (https://github.com/patrickzib/", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999145269393921}, "created": {"value": false, "score": 1.4185905456542969e-05}, "shared": {"value": false, "score": 1.6689300537109375e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999837875366211}, "created": {"value": false, "score": 3.218650817871094e-05}, "shared": {"value": false, "score": 1.6689300537109375e-06}}, "references": [{"label": "[6]", "normalizedForm": "[6]", "refKey": 6}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "WEASEL+MUSE", "normalizedForm": "WEASEL+MUSE", "offsetStart": 119, "offsetEnd": 130}, "context": "4. Dense layer dimension 128 and L2 regularization 0.2) and with the following hyperparameter: batch size {1, 8, 32};\u2022 WEASEL+MUSE: we used the implementation available (https://github.com/patrickzib/", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999145269393921}, "created": {"value": false, "score": 1.4185905456542969e-05}, "shared": {"value": false, "score": 1.6689300537109375e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999837875366211}, "created": {"value": false, "score": 3.218650817871094e-05}, "shared": {"value": false, "score": 1.6689300537109375e-06}}, "references": [{"label": "[6]", "normalizedForm": "[6]", "refKey": 6}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CNN", "normalizedForm": "CNN", "offsetStart": 120, "offsetEnd": 123}, "context": "We observe that XCM and MTEX-CNN obtain the same performance whereas XCM has around 10 times fewer parameters than MTEX-CNN (trainable parameters: XCM 17k, MTEX-CNN 232k).", "mentionContextAttributes": {"used": {"value": true, "score": 0.6832642555236816}, "created": {"value": false, "score": 3.5762786865234375e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997316002845764}, "created": {"value": true, "score": 0.9998825788497925}, "shared": {"value": false, "score": 1.430511474609375e-06}}, "references": [{"label": "[12]", "normalizedForm": "[12]", "refKey": 12}, {"label": "[12]", "normalizedForm": "[12]", "refKey": 12}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "XCM", "normalizedForm": "XCM", "offsetStart": 122, "offsetEnd": 125}, "context": "In this section, we present our new eXplainable Convolutional neural network for Multivariate time series classification (XCM).", "mentionContextAttributes": {"used": {"value": false, "score": 0.00015664100646972656}, "created": {"value": true, "score": 0.999921441078186}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999932050704956}, "created": {"value": true, "score": 0.9999338388442993}, "shared": {"value": false, "score": 5.4836273193359375e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CNN", "normalizedForm": "CNN", "offsetStart": 122, "offsetEnd": 125}, "context": "However, the red color gradient is due to the upsampling processes needed to match the 2D/1D output features maps of MTEX-CNN to the size of the input data when applying Grad-CAM.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9689474105834961}, "created": {"value": false, "score": 9.655952453613281e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997316002845764}, "created": {"value": true, "score": 0.9998825788497925}, "shared": {"value": false, "score": 1.430511474609375e-06}}, "references": [{"label": "[12]", "normalizedForm": "[12]", "refKey": 12}, {"label": "[12]", "normalizedForm": "[12]", "refKey": 12}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MTEX", "normalizedForm": "MTEX", "offsetStart": 127, "offsetEnd": 131}, "context": "Figure 5 shows one MTS sample belonging to the positive class, and the time and observed variables attribution maps supporting MTEX-CNN and XCM predictions.", "mentionContextAttributes": {"used": {"value": true, "score": 0.998267650604248}, "created": {"value": false, "score": 4.172325134277344e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997316002845764}, "created": {"value": true, "score": 0.9856033325195312}, "shared": {"value": false, "score": 1.430511474609375e-06}}, "references": [{"label": "[12]", "normalizedForm": "[12]", "refKey": 12}, {"label": "[12]", "normalizedForm": "[12]", "refKey": 12}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MTEX", "normalizedForm": "MTEX", "offsetStart": 127, "offsetEnd": 131}, "context": "As MTEX-CNN attribution maps exhibit a red color gradient, the precision of identification of the regions of the input data on MTEX-CNN attribution maps could be enhanced by setting a higher threshold than 0.6 for the attribution values.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9993818998336792}, "created": {"value": false, "score": 2.086162567138672e-05}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997316002845764}, "created": {"value": true, "score": 0.9856033325195312}, "shared": {"value": false, "score": 1.430511474609375e-06}}, "references": [{"label": "[12]", "normalizedForm": "[12]", "refKey": 12}, {"label": "[12]", "normalizedForm": "[12]", "refKey": 12}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "XCM", "normalizedForm": "XCM", "offsetStart": 132, "offsetEnd": 135}, "context": "Table 1 presents an overview of the challenges addressed by the state-of-the-art MTS classifiers and how we position our new method XCM.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00014328956604003906}, "created": {"value": true, "score": 0.5738491415977478}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999932050704956}, "created": {"value": true, "score": 0.9999338388442993}, "shared": {"value": false, "score": 5.4836273193359375e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CNN", "normalizedForm": "CNN", "offsetStart": 132, "offsetEnd": 135}, "context": "Figure 5 shows one MTS sample belonging to the positive class, and the time and observed variables attribution maps supporting MTEX-CNN and XCM predictions.", "mentionContextAttributes": {"used": {"value": true, "score": 0.998267650604248}, "created": {"value": false, "score": 4.172325134277344e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997316002845764}, "created": {"value": true, "score": 0.9998825788497925}, "shared": {"value": false, "score": 1.430511474609375e-06}}, "references": [{"label": "[12]", "normalizedForm": "[12]", "refKey": 12}, {"label": "[12]", "normalizedForm": "[12]", "refKey": 12}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CNN", "normalizedForm": "CNN", "offsetStart": 132, "offsetEnd": 135}, "context": "As MTEX-CNN attribution maps exhibit a red color gradient, the precision of identification of the regions of the input data on MTEX-CNN attribution maps could be enhanced by setting a higher threshold than 0.6 for the attribution values.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9993818998336792}, "created": {"value": false, "score": 2.086162567138672e-05}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997316002845764}, "created": {"value": true, "score": 0.9998825788497925}, "shared": {"value": false, "score": 1.430511474609375e-06}}, "references": [{"label": "[12]", "normalizedForm": "[12]", "refKey": 12}, {"label": "[12]", "normalizedForm": "[12]", "refKey": 12}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "WEASEL+MUSE", "normalizedForm": "WEASEL+MUSE", "offsetStart": 134, "offsetEnd": 145}, "context": "More specifically, XCM exhibits better performance than MLSTM-FCN and WEASEL +MUSE on both the large (rank: 1.9, MLSTM-FCN rank: 2.1, WEASEL+MUSE rank: 4.6-train size \u2265 500, 23% of the datasets) and small datasets (rank: 2.4, MLSTM-FCN rank: 4.0, WEASEL+MUSE rank: 3.9-train size < 500, 77% of the datasets).", "mentionContextAttributes": {"used": {"value": true, "score": 0.6560125350952148}, "created": {"value": false, "score": 2.1457672119140625e-06}, "shared": {"value": false, "score": 7.152557373046875e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999837875366211}, "created": {"value": false, "score": 3.218650817871094e-05}, "shared": {"value": false, "score": 1.6689300537109375e-06}}, "references": [{"label": "[6]", "normalizedForm": "[6]", "refKey": 6}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "XCM", "normalizedForm": "XCM", "offsetStart": 135, "offsetEnd": 138}, "context": "Finally, the performance-explainability framework introduced in the previous paragraph can also be used to identify the limitations of XCM, which point to the directions to improve our approach.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0002675652503967285}, "created": {"value": false, "score": 0.024364113807678223}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999932050704956}, "created": {"value": true, "score": 0.9999338388442993}, "shared": {"value": false, "score": 5.4836273193359375e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "XCM", "normalizedForm": "XCM", "offsetStart": 137, "offsetEnd": 140}, "context": "In order to evaluate the relative impact with respect to the range of performance, we defined four categories of datasets: datasets with XCM original accuracy< 50%, datasets with 50% \u2264 accuracy < 75%, datasets with 75% \u2264 accuracy < 90% and datasets with accuracy \u2265 90%.", "mentionContextAttributes": {"used": {"value": true, "score": 0.999047577381134}, "created": {"value": false, "score": 2.8371810913085938e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999932050704956}, "created": {"value": true, "score": 0.9999338388442993}, "shared": {"value": false, "score": 5.4836273193359375e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "XCM", "normalizedForm": "XCM", "offsetStart": 140, "offsetEnd": 143}, "context": "Figure 5 shows one MTS sample belonging to the positive class, and the time and observed variables attribution maps supporting MTEX-CNN and XCM predictions.", "mentionContextAttributes": {"used": {"value": true, "score": 0.998267650604248}, "created": {"value": false, "score": 4.172325134277344e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999932050704956}, "created": {"value": true, "score": 0.9999338388442993}, "shared": {"value": false, "score": 5.4836273193359375e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "XCM", "normalizedForm": "XCM", "offsetStart": 147, "offsetEnd": 150}, "context": "We observe that XCM and MTEX-CNN obtain the same performance whereas XCM has around 10 times fewer parameters than MTEX-CNN (trainable parameters: XCM 17k, MTEX-CNN 232k).", "mentionContextAttributes": {"used": {"value": true, "score": 0.6832642555236816}, "created": {"value": false, "score": 3.5762786865234375e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999932050704956}, "created": {"value": true, "score": 0.9999338388442993}, "shared": {"value": false, "score": 5.4836273193359375e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MTEX", "normalizedForm": "MTEX", "offsetStart": 150, "offsetEnd": 154}, "context": "Grad-CAM is applied at a local level, which means that we would need to potentially set a different threshold for each instance and that would render MTEX-CNN explainability method impractical.", "mentionContextAttributes": {"used": {"value": true, "score": 0.732130229473114}, "created": {"value": false, "score": 1.5020370483398438e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997316002845764}, "created": {"value": true, "score": 0.9856033325195312}, "shared": {"value": false, "score": 1.430511474609375e-06}}, "references": [{"label": "[12]", "normalizedForm": "[12]", "refKey": 12}, {"label": "[12]", "normalizedForm": "[12]", "refKey": 12}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CNN", "normalizedForm": "CNN", "offsetStart": 151, "offsetEnd": 154}, "context": "However, the precision of the explanations provided by Grad-CAM, i.e., the fraction of explanations that are relevant to a prediction, can vary across CNN architectures as Grad-CAM is sensitive to the upsampling processes on feature maps to match the input data dimensions.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0003802776336669922}, "created": {"value": false, "score": 1.3828277587890625e-05}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997316002845764}, "created": {"value": true, "score": 0.9998825788497925}, "shared": {"value": false, "score": 1.430511474609375e-06}}, "references": [{"label": "[12]", "normalizedForm": "[12]", "refKey": 12}, {"label": "[12]", "normalizedForm": "[12]", "refKey": 12}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "XCM", "normalizedForm": "XCM", "offsetStart": 152, "offsetEnd": 155}, "context": "The rest of this paper is organized as follows: Section 2 presents the related work concerning MTS classification and explainability; Section 3 details XCM architecture; Section 4 presents our evaluation method; and finally, Section 5 discusses our results.", "mentionContextAttributes": {"used": {"value": false, "score": 0.010324180126190186}, "created": {"value": false, "score": 0.015016019344329834}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999932050704956}, "created": {"value": true, "score": 0.9999338388442993}, "shared": {"value": false, "score": 5.4836273193359375e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CNN", "normalizedForm": "CNN", "offsetStart": 155, "offsetEnd": 158}, "context": "Grad-CAM is applied at a local level, which means that we would need to potentially set a different threshold for each instance and that would render MTEX-CNN explainability method impractical.", "mentionContextAttributes": {"used": {"value": true, "score": 0.732130229473114}, "created": {"value": false, "score": 1.5020370483398438e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997316002845764}, "created": {"value": true, "score": 0.9998825788497925}, "shared": {"value": false, "score": 1.430511474609375e-06}}, "references": [{"label": "[12]", "normalizedForm": "[12]", "refKey": 12}, {"label": "[12]", "normalizedForm": "[12]", "refKey": 12}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "XCM", "normalizedForm": "XCM", "offsetStart": 156, "offsetEnd": 159}, "context": "We show that XCM outperforms the state-of-the-art MTS classifiers on both the large and small UEA datasets [7]; \u2022 We illustrate on a synthetic dataset that XCM enables a more precise identification of the regions of the input data that are important for predictions compared to the current faithfully explainable deep learning MTS classifier MTEX-CNN; \u2022", "mentionContextAttributes": {"used": {"value": false, "score": 0.03140699863433838}, "created": {"value": false, "score": 0.0006378293037414551}, "shared": {"value": false, "score": 5.960464477539062e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999932050704956}, "created": {"value": true, "score": 0.9999338388442993}, "shared": {"value": false, "score": 5.4836273193359375e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MTEX", "normalizedForm": "MTEX", "offsetStart": 156, "offsetEnd": 160}, "context": "We observe that XCM and MTEX-CNN obtain the same performance whereas XCM has around 10 times fewer parameters than MTEX-CNN (trainable parameters: XCM 17k, MTEX-CNN 232k).", "mentionContextAttributes": {"used": {"value": true, "score": 0.6832642555236816}, "created": {"value": false, "score": 3.5762786865234375e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997316002845764}, "created": {"value": true, "score": 0.9856033325195312}, "shared": {"value": false, "score": 1.430511474609375e-06}}, "references": [{"label": "[12]", "normalizedForm": "[12]", "refKey": 12}, {"label": "[12]", "normalizedForm": "[12]", "refKey": 12}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "WEASEL+ MUSE", "normalizedForm": "WEASEL+ MUSE", "offsetStart": 157, "offsetEnd": 169}, "context": "Therefore, in this work, we choose to benchmark XCM to the best-in-class for each similarity-based, feature-based and deep learning category (DTW D /DTW I , WEASEL+ MUSE and MLSTM-FCN classifiers).", "mentionContextAttributes": {"used": {"value": false, "score": 0.03093045949935913}, "created": {"value": true, "score": 0.9970675110816956}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.12179362773895264}, "created": {"value": true, "score": 0.9970675110816956}, "shared": {"value": false, "score": 1.1920928955078125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CNN", "normalizedForm": "CNN", "offsetStart": 161, "offsetEnd": 164}, "context": "We observe that XCM and MTEX-CNN obtain the same performance whereas XCM has around 10 times fewer parameters than MTEX-CNN (trainable parameters: XCM 17k, MTEX-CNN 232k).", "mentionContextAttributes": {"used": {"value": true, "score": 0.6832642555236816}, "created": {"value": false, "score": 3.5762786865234375e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997316002845764}, "created": {"value": true, "score": 0.9998825788497925}, "shared": {"value": false, "score": 1.430511474609375e-06}}, "references": [{"label": "[12]", "normalizedForm": "[12]", "refKey": 12}, {"label": "[12]", "normalizedForm": "[12]", "refKey": 12}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CNN", "normalizedForm": "CNN", "offsetStart": 165, "offsetEnd": 168}, "context": "According to the results published and our experiments, the current state-of-the-art model (MLSTM-FCN) is proposed in [5] and consists of a LSTM layer and a stacked CNN layer along with squeeze-and-excitation blocks to generate latent features.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00030601024627685547}, "created": {"value": true, "score": 0.5827941298484802}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997316002845764}, "created": {"value": true, "score": 0.9998825788497925}, "shared": {"value": false, "score": 1.430511474609375e-06}}, "references": [{"label": "[12]", "normalizedForm": "[12]", "refKey": 12}, {"label": "[12]", "normalizedForm": "[12]", "refKey": 12}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "XCM", "normalizedForm": "XCM", "offsetStart": 166, "offsetEnd": 169}, "context": "We observe that the attribution maps drawn from XCM are more precise than the ones from MTEX-CNN, i.e., the intersection-over-union of the explanations is higher for XCM than for MTEX-CNN (intersection-over-union: XCM 0.65 versus MTEX-CNN 0.4).", "mentionContextAttributes": {"used": {"value": true, "score": 0.9954714775085449}, "created": {"value": false, "score": 1.6689300537109375e-06}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999932050704956}, "created": {"value": true, "score": 0.9999338388442993}, "shared": {"value": false, "score": 5.4836273193359375e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MTEX", "normalizedForm": "MTEX", "offsetStart": 167, "offsetEnd": 171}, "context": "Thus, based on the same attribution threshold (0.6), XCM allows a more precise identification of the regions of the input data that are important for predictions than MTEX-CNN.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0002937912940979004}, "created": {"value": false, "score": 3.933906555175781e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997316002845764}, "created": {"value": true, "score": 0.9856033325195312}, "shared": {"value": false, "score": 1.430511474609375e-06}}, "references": [{"label": "[12]", "normalizedForm": "[12]", "refKey": 12}, {"label": "[12]", "normalizedForm": "[12]", "refKey": 12}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MTEX-CNN", "normalizedForm": "MTEX-CNN", "offsetStart": 167, "offsetEnd": 175}, "context": "Then, a CNN architecture using fully connected layers to perform classification, especially with the size of the first layer depending on the time series length as in MTEX-CNN, is prone to overfitting and can lead to the explosion of the number of trainable parameters. ", "mentionContextAttributes": {"used": {"value": false, "score": 6.0439109802246094e-05}, "created": {"value": false, "score": 0.000517725944519043}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.03140699863433838}, "created": {"value": false, "score": 0.0006378293037414551}, "shared": {"value": false, "score": 5.960464477539062e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "XCM", "normalizedForm": "XCM", "offsetStart": 170, "offsetEnd": 173}, "context": "(accessed on 1 November 2021)), we do not see any influence from the different train set sizes, MTS lengths, number of dimensions, number of classes and dataset types on XCM performance relative to the other classifiers on the UEA datasets.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9595663547515869}, "created": {"value": false, "score": 3.8743019104003906e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999932050704956}, "created": {"value": true, "score": 0.9999338388442993}, "shared": {"value": false, "score": 5.4836273193359375e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CNN", "normalizedForm": "CNN", "offsetStart": 172, "offsetEnd": 175}, "context": "Thus, based on the same attribution threshold (0.6), XCM allows a more precise identification of the regions of the input data that are important for predictions than MTEX-CNN.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0002937912940979004}, "created": {"value": false, "score": 3.933906555175781e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997316002845764}, "created": {"value": true, "score": 0.9998825788497925}, "shared": {"value": false, "score": 1.430511474609375e-06}}, "references": [{"label": "[12]", "normalizedForm": "[12]", "refKey": 12}, {"label": "[12]", "normalizedForm": "[12]", "refKey": 12}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CNN", "normalizedForm": "CNN", "offsetStart": 177, "offsetEnd": 180}, "context": "Finally, deep learning methods (FCN [26], MLSTM-FCN [5], MTEX-CNN [12], ResNet [27], TapNet [28] and TST [29]) use Long-Short Term Memory (LSTM), Convolutional Neural Networks (CNN) or Transformers.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0006260275840759277}, "created": {"value": false, "score": 2.5033950805664062e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997316002845764}, "created": {"value": true, "score": 0.9998825788497925}, "shared": {"value": false, "score": 1.430511474609375e-06}}, "references": [{"label": "[12]", "normalizedForm": "[12]", "refKey": 12}, {"label": "[12]", "normalizedForm": "[12]", "refKey": 12}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MTEX", "normalizedForm": "MTEX", "offsetStart": 179, "offsetEnd": 183}, "context": "We observe that the attribution maps drawn from XCM are more precise than the ones from MTEX-CNN, i.e., the intersection-over-union of the explanations is higher for XCM than for MTEX-CNN (intersection-over-union: XCM 0.65 versus MTEX-CNN 0.4). ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9954714775085449}, "created": {"value": false, "score": 1.6689300537109375e-06}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997316002845764}, "created": {"value": true, "score": 0.9856033325195312}, "shared": {"value": false, "score": 1.430511474609375e-06}}, "references": [{"label": "[12]", "normalizedForm": "[12]", "refKey": 12}, {"label": "[12]", "normalizedForm": "[12]", "refKey": 12}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Grad-CAM", "normalizedForm": "Grad-CAM", "offsetStart": 183, "offsetEnd": 191}, "context": "Finally, the use of non fully padded convolution filters as in MTEX-CNN can lead to an imprecise identification of the regions of the input data that are important for predictions as Grad-CAM is sensitive to upsampling processes. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.00019294023513793945}, "created": {"value": false, "score": 3.612041473388672e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9186117053031921}, "created": {"value": false, "score": 3.612041473388672e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CNN", "normalizedForm": "CNN", "offsetStart": 184, "offsetEnd": 187}, "context": "We observe that the attribution maps drawn from XCM are more precise than the ones from MTEX-CNN, i.e., the intersection-over-union of the explanations is higher for XCM than for MTEX-CNN (intersection-over-union: XCM 0.65 versus MTEX-CNN 0.4).", "mentionContextAttributes": {"used": {"value": true, "score": 0.9954714775085449}, "created": {"value": false, "score": 1.6689300537109375e-06}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997316002845764}, "created": {"value": true, "score": 0.9998825788497925}, "shared": {"value": false, "score": 1.430511474609375e-06}}, "references": [{"label": "[12]", "normalizedForm": "[12]", "refKey": 12}, {"label": "[12]", "normalizedForm": "[12]", "refKey": 12}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MTEX", "normalizedForm": "MTEX", "offsetStart": 184, "offsetEnd": 188}, "context": "On the time attribution map, high attribution values (above 0.6) for XCM begin on timestamp 63 and end on timestamp 76 (expected: [60, 80], intersection-over-union: 0.65), whereas for MTEX-CNN they begin later (timestamp 68, intersection-over-union: 0.4). ", "mentionContextAttributes": {"used": {"value": true, "score": 0.5550888180732727}, "created": {"value": false, "score": 1.5497207641601562e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997316002845764}, "created": {"value": true, "score": 0.9856033325195312}, "shared": {"value": false, "score": 1.430511474609375e-06}}, "references": [{"label": "[12]", "normalizedForm": "[12]", "refKey": 12}, {"label": "[12]", "normalizedForm": "[12]", "refKey": 12}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CNN", "normalizedForm": "CNN", "offsetStart": 189, "offsetEnd": 192}, "context": "On the time attribution map, high attribution values (above 0.6) for XCM begin on timestamp 63 and end on timestamp 76 (expected: [60, 80], intersection-over-union: 0.65), whereas for MTEX-CNN they begin later (timestamp 68, intersection-over-union: 0.4).", "mentionContextAttributes": {"used": {"value": true, "score": 0.5550888180732727}, "created": {"value": false, "score": 1.5497207641601562e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997316002845764}, "created": {"value": true, "score": 0.9998825788497925}, "shared": {"value": false, "score": 1.430511474609375e-06}}, "references": [{"label": "[12]", "normalizedForm": "[12]", "refKey": 12}, {"label": "[12]", "normalizedForm": "[12]", "refKey": 12}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "XCM", "normalizedForm": "XCM", "offsetStart": 196, "offsetEnd": 199}, "context": "First, as expected, we observe that the average relative impact of using suboptimal time window sizes is higher when XCM level of performance is low (average relative drop in accuracy: 13.1% when XCM accuracy < 50% versus 3.0% when XCM accuracy \u2265 90%).", "mentionContextAttributes": {"used": {"value": true, "score": 0.9327999949455261}, "created": {"value": false, "score": 2.8252601623535156e-05}, "shared": {"value": false, "score": 5.960464477539062e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999932050704956}, "created": {"value": true, "score": 0.9999338388442993}, "shared": {"value": false, "score": 5.4836273193359375e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "XCM", "normalizedForm": "XCM", "offsetStart": 197, "offsetEnd": 200}, "context": "In our future work, we would like to automate XCM hyperparameter setting (Window Size) and evaluate the impact of different fusion methods of the 2D and 1D feature maps (e.g., weighting scheme) on XCM performance.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0007912516593933105}, "created": {"value": true, "score": 0.9997808337211609}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999932050704956}, "created": {"value": true, "score": 0.9999338388442993}, "shared": {"value": false, "score": 5.4836273193359375e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MTEX", "normalizedForm": "MTEX", "offsetStart": 197, "offsetEnd": 201}, "context": "Therefore, considering that XCM-Seq attributions maps are the same as XCM ones, we can assume that the use of half padding on the different convolution layers to reduce the number of parameters in MTEX-CNN, i.e., the use of upsampling to retrieve the input data dimensions on the attribution maps, can lead to a less precise identification of the regions of the input data that are important for predictions.", "mentionContextAttributes": {"used": {"value": true, "score": 0.715061366558075}, "created": {"value": false, "score": 1.990795135498047e-05}, "shared": {"value": false, "score": 1.430511474609375e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997316002845764}, "created": {"value": true, "score": 0.9856033325195312}, "shared": {"value": false, "score": 1.430511474609375e-06}}, "references": [{"label": "[12]", "normalizedForm": "[12]", "refKey": 12}, {"label": "[12]", "normalizedForm": "[12]", "refKey": 12}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CNN", "normalizedForm": "CNN", "offsetStart": 202, "offsetEnd": 205}, "context": "Therefore, considering that XCM-Seq attributions maps are the same as XCM ones, we can assume that the use of half padding on the different convolution layers to reduce the number of parameters in MTEX-CNN, i.e., the use of upsampling to retrieve the input data dimensions on the attribution maps, can lead to a less precise identification of the regions of the input data that are important for predictions.", "mentionContextAttributes": {"used": {"value": true, "score": 0.715061366558075}, "created": {"value": false, "score": 1.990795135498047e-05}, "shared": {"value": false, "score": 1.430511474609375e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997316002845764}, "created": {"value": true, "score": 0.9998825788497925}, "shared": {"value": false, "score": 1.430511474609375e-06}}, "references": [{"label": "[12]", "normalizedForm": "[12]", "refKey": 12}, {"label": "[12]", "normalizedForm": "[12]", "refKey": 12}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "WEASEL+MUSE", "normalizedForm": "WEASEL+MUSE", "offsetStart": 207, "offsetEnd": 218}, "context": "As far as we have seen, an architecture concatenating a LSTM network with a CNN such as MLSTM-FCN, or a classifier based on unigrams/bigrams extraction following a Symbolic Fourier Approximation [8] such as WEASEL+MUSE, cannot provide perfectly faithful explanations as they rely solely on post hoc model-agnostic explainability methods [9], which could prevent their use in numerous applications. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.03177952766418457}, "created": {"value": false, "score": 3.218650817871094e-05}, "shared": {"value": false, "score": 7.152557373046875e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999837875366211}, "created": {"value": false, "score": 3.218650817871094e-05}, "shared": {"value": false, "score": 1.6689300537109375e-06}}, "references": [{"label": "[6]", "normalizedForm": "[6]", "refKey": 6}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "XCM", "normalizedForm": "XCM", "offsetStart": 209, "offsetEnd": 212}, "context": "Finally, we presented the critical difference diagram [47], the statistical comparison of multiple classifiers on multiple datasets based on the nonparametric Friedman test, to show the overall performance of XCM. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.99998939037323}, "created": {"value": false, "score": 0.0009236335754394531}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999932050704956}, "created": {"value": true, "score": 0.9999338388442993}, "shared": {"value": false, "score": 5.4836273193359375e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "XCM", "normalizedForm": "XCM", "offsetStart": 214, "offsetEnd": 217}, "context": "We observe that the attribution maps drawn from XCM are more precise than the ones from MTEX-CNN, i.e., the intersection-over-union of the explanations is higher for XCM than for MTEX-CNN (intersection-over-union: XCM 0.65 versus MTEX-CNN 0.4).", "mentionContextAttributes": {"used": {"value": true, "score": 0.9954714775085449}, "created": {"value": false, "score": 1.6689300537109375e-06}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999932050704956}, "created": {"value": true, "score": 0.9999338388442993}, "shared": {"value": false, "score": 5.4836273193359375e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "XCM", "normalizedForm": "XCM", "offsetStart": 218, "offsetEnd": 221}, "context": "We can assume that the more compact architecture of XCM compared to the other deep learning classifiers provides a better generalization ability on the UEA datasets (average rank on the number of trainable parameters: XCM 1.7, MLSTM-FCN: 1.9, MTEX-CNN: 2.0).", "mentionContextAttributes": {"used": {"value": false, "score": 0.00446319580078125}, "created": {"value": false, "score": 3.2186508178710938e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999932050704956}, "created": {"value": true, "score": 0.9999338388442993}, "shared": {"value": false, "score": 5.4836273193359375e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MTEX", "normalizedForm": "MTEX", "offsetStart": 218, "offsetEnd": 222}, "context": "In order to assess the potential advantage of concatenating the 2D and 1D convolution blocks instead of having them in sequence, independently from the choice of the classification layers (fully connected layers as in MTEX-CNN versus 1D global average pooling with a softmax layer in XCM), we include in our experiments in Section 5.1 a variant of XCM (XCM-Seq).", "mentionContextAttributes": {"used": {"value": false, "score": 0.0205497145652771}, "created": {"value": false, "score": 3.135204315185547e-05}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997316002845764}, "created": {"value": true, "score": 0.9856033325195312}, "shared": {"value": false, "score": 1.430511474609375e-06}}, "references": [{"label": "[12]", "normalizedForm": "[12]", "refKey": 12}, {"label": "[12]", "normalizedForm": "[12]", "refKey": 12}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "GeForce", "normalizedForm": "GeForce", "offsetStart": 220, "offsetEnd": 227}, "context": "All the networks that we implemented (XCM, XCM-Seq and MTEX-CNN) were trained with 100 epochs, the categorical crossentropy loss and the Adam optimization (computing infrastructure: Debian 8 operating system, GPU NVIDIA GeForce RTX 2080 Ti with 11Gb GRAM and 96Gb of RAM). ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9997316002845764}, "created": {"value": false, "score": 1.2278556823730469e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997316002845764}, "created": {"value": false, "score": 1.2278556823730469e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CNN", "normalizedForm": "CNN", "offsetStart": 223, "offsetEnd": 226}, "context": "In order to assess the potential advantage of concatenating the 2D and 1D convolution blocks instead of having them in sequence, independently from the choice of the classification layers (fully connected layers as in MTEX-CNN versus 1D global average pooling with a softmax layer in XCM), we include in our experiments in Section 5.1 a variant of XCM (XCM-Seq).", "mentionContextAttributes": {"used": {"value": false, "score": 0.0205497145652771}, "created": {"value": false, "score": 3.135204315185547e-05}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997316002845764}, "created": {"value": true, "score": 0.9998825788497925}, "shared": {"value": false, "score": 1.430511474609375e-06}}, "references": [{"label": "[12]", "normalizedForm": "[12]", "refKey": 12}, {"label": "[12]", "normalizedForm": "[12]", "refKey": 12}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "WEASEL+MUSE", "normalizedForm": "WEASEL+MUSE", "offsetStart": 223, "offsetEnd": 234}, "context": "Firstly, we observe that XCM obtains the best average rank and the lowest rank variability across the datasets (rank: 2.3, standard error: 0.4), followed by MLSTM-FCN in second position (rank: 3.5, standard error: 0.5) and WEASEL+MUSE in third position (rank: 4.0, standard error: 0.5).", "mentionContextAttributes": {"used": {"value": true, "score": 0.6182391047477722}, "created": {"value": false, "score": 2.0265579223632812e-06}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999837875366211}, "created": {"value": false, "score": 3.218650817871094e-05}, "shared": {"value": false, "score": 1.6689300537109375e-06}}, "references": [{"label": "[6]", "normalizedForm": "[6]", "refKey": 6}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MTEX", "normalizedForm": "MTEX", "offsetStart": 230, "offsetEnd": 234}, "context": "We observe that the attribution maps drawn from XCM are more precise than the ones from MTEX-CNN, i.e., the intersection-over-union of the explanations is higher for XCM than for MTEX-CNN (intersection-over-union: XCM 0.65 versus MTEX-CNN 0.4). ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9954714775085449}, "created": {"value": false, "score": 1.6689300537109375e-06}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997316002845764}, "created": {"value": true, "score": 0.9856033325195312}, "shared": {"value": false, "score": 1.430511474609375e-06}}, "references": [{"label": "[12]", "normalizedForm": "[12]", "refKey": 12}, {"label": "[12]", "normalizedForm": "[12]", "refKey": 12}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "XCM", "normalizedForm": "XCM", "offsetStart": 232, "offsetEnd": 235}, "context": "First, as expected, we observe that the average relative impact of using suboptimal time window sizes is higher when XCM level of performance is low (average relative drop in accuracy: 13.1% when XCM accuracy < 50% versus 3.0% when XCM accuracy \u2265 90%).", "mentionContextAttributes": {"used": {"value": true, "score": 0.9327999949455261}, "created": {"value": false, "score": 2.8252601623535156e-05}, "shared": {"value": false, "score": 5.960464477539062e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999932050704956}, "created": {"value": true, "score": 0.9999338388442993}, "shared": {"value": false, "score": 5.4836273193359375e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CNN", "normalizedForm": "CNN", "offsetStart": 235, "offsetEnd": 238}, "context": "We observe that the attribution maps drawn from XCM are more precise than the ones from MTEX-CNN, i.e., the intersection-over-union of the explanations is higher for XCM than for MTEX-CNN (intersection-over-union: XCM 0.65 versus MTEX-CNN 0.4).", "mentionContextAttributes": {"used": {"value": true, "score": 0.9954714775085449}, "created": {"value": false, "score": 1.6689300537109375e-06}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997316002845764}, "created": {"value": true, "score": 0.9998825788497925}, "shared": {"value": false, "score": 1.430511474609375e-06}}, "references": [{"label": "[12]", "normalizedForm": "[12]", "refKey": 12}, {"label": "[12]", "normalizedForm": "[12]", "refKey": 12}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "XCM", "normalizedForm": "XCM", "offsetStart": 243, "offsetEnd": 246}, "context": "Concerning the attribution map of the observed variables, as expected, we see that high attributions values on the discriminative dimension (dimension 1) appear at the same timestamps as high attribution values on the time attribution map for XCM (timestamps 63 and 76, intersection-over-union: 0.65).", "mentionContextAttributes": {"used": {"value": true, "score": 0.9994243383407593}, "created": {"value": false, "score": 2.5033950805664062e-06}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999932050704956}, "created": {"value": true, "score": 0.9999338388442993}, "shared": {"value": false, "score": 5.4836273193359375e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MTEX", "normalizedForm": "MTEX", "offsetStart": 243, "offsetEnd": 247}, "context": "We can assume that the more compact architecture of XCM compared to the other deep learning classifiers provides a better generalization ability on the UEA datasets (average rank on the number of trainable parameters: XCM 1.7, MLSTM-FCN: 1.9, MTEX-CNN: 2.0). ", "mentionContextAttributes": {"used": {"value": false, "score": 0.00446319580078125}, "created": {"value": false, "score": 3.2186508178710938e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997316002845764}, "created": {"value": true, "score": 0.9856033325195312}, "shared": {"value": false, "score": 1.430511474609375e-06}}, "references": [{"label": "[12]", "normalizedForm": "[12]", "refKey": 12}, {"label": "[12]", "normalizedForm": "[12]", "refKey": 12}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "WEASEL+MUSE", "normalizedForm": "WEASEL+MUSE", "offsetStart": 247, "offsetEnd": 258}, "context": "More specifically, XCM exhibits better performance than MLSTM-FCN and WEASEL +MUSE on both the large (rank: 1.9, MLSTM-FCN rank: 2.1, WEASEL+MUSE rank: 4.6-train size \u2265 500, 23% of the datasets) and small datasets (rank: 2.4, MLSTM-FCN rank: 4.0, WEASEL+MUSE rank: 3.9-train size < 500, 77% of the datasets).", "mentionContextAttributes": {"used": {"value": true, "score": 0.6560124158859253}, "created": {"value": false, "score": 2.1457672119140625e-06}, "shared": {"value": false, "score": 7.152557373046875e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999837875366211}, "created": {"value": false, "score": 3.218650817871094e-05}, "shared": {"value": false, "score": 1.6689300537109375e-06}}, "references": [{"label": "[6]", "normalizedForm": "[6]", "refKey": 6}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CNN", "normalizedForm": "CNN", "offsetStart": 248, "offsetEnd": 251}, "context": "We can assume that the more compact architecture of XCM compared to the other deep learning classifiers provides a better generalization ability on the UEA datasets (average rank on the number of trainable parameters: XCM 1.7, MLSTM-FCN: 1.9, MTEX-CNN: 2.0).", "mentionContextAttributes": {"used": {"value": false, "score": 0.00446319580078125}, "created": {"value": false, "score": 3.2186508178710938e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997316002845764}, "created": {"value": true, "score": 0.9998825788497925}, "shared": {"value": false, "score": 1.430511474609375e-06}}, "references": [{"label": "[12]", "normalizedForm": "[12]", "refKey": 12}, {"label": "[12]", "normalizedForm": "[12]", "refKey": 12}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "XCM", "normalizedForm": "XCM", "offsetStart": 250, "offsetEnd": 253}, "context": "Furthermore, unlike MLSTM-FCN with SHAP and as discussed in Section 2.3, XCM with Grad-CAM approach provides faithful explanations, which is a prerequisite to reduce solution mistrust from the farmers (Faithfulness: MLSTM-FCN with SHAP-Imperfect and XCM with Grad-CAM-Perfect).", "mentionContextAttributes": {"used": {"value": false, "score": 0.0018808245658874512}, "created": {"value": false, "score": 3.4570693969726562e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999932050704956}, "created": {"value": true, "score": 0.9999338388442993}, "shared": {"value": false, "score": 5.4836273193359375e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "XCM", "normalizedForm": "XCM", "offsetStart": 264, "offsetEnd": 267}, "context": "However, in addition to giving the relative importance of observed variables and time as MLSTM-FCN with SHAP, XCM with Grad-CAM provides more informative explanations by supplying the corresponding sample values (Information: MLSTM-FCN with SHAP-Features+Time and XCM with Grad-CAM-Features+Time+Values).", "mentionContextAttributes": {"used": {"value": false, "score": 0.02050602436065674}, "created": {"value": false, "score": 1.5497207641601562e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999932050704956}, "created": {"value": true, "score": 0.9999338388442993}, "shared": {"value": false, "score": 5.4836273193359375e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MTEX", "normalizedForm": "MTEX", "offsetStart": 279, "offsetEnd": 283}, "context": "The design of our network architecture avoids upsampling processes and enables Grad-CAM to identify the observed variables and timestamps of the input data that are important for predictions more precisely as compared to what the current explainable deep learning MTS classifier MTEX-CNN give.", "mentionContextAttributes": {"used": {"value": false, "score": 5.519390106201172e-05}, "created": {"value": true, "score": 0.9856033325195312}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997316002845764}, "created": {"value": true, "score": 0.9856033325195312}, "shared": {"value": false, "score": 1.430511474609375e-06}}, "references": [{"label": "[12]", "normalizedForm": "[12]", "refKey": 12}, {"label": "[12]", "normalizedForm": "[12]", "refKey": 12}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CNN", "normalizedForm": "CNN", "offsetStart": 284, "offsetEnd": 287}, "context": "The design of our network architecture avoids upsampling processes and enables Grad-CAM to identify the observed variables and timestamps of the input data that are important for predictions more precisely as compared to what the current explainable deep learning MTS classifier MTEX-CNN give.", "mentionContextAttributes": {"used": {"value": false, "score": 5.519390106201172e-05}, "created": {"value": true, "score": 0.9856033325195312}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997316002845764}, "created": {"value": true, "score": 0.9998825788497925}, "shared": {"value": false, "score": 1.430511474609375e-06}}, "references": [{"label": "[12]", "normalizedForm": "[12]", "refKey": 12}, {"label": "[12]", "normalizedForm": "[12]", "refKey": 12}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "XCM", "normalizedForm": "XCM", "offsetStart": 284, "offsetEnd": 287}, "context": "In order to assess the potential advantage of concatenating the 2D and 1D convolution blocks instead of having them in sequence, independently from the choice of the classification layers (fully connected layers as in MTEX-CNN versus 1D global average pooling with a softmax layer in XCM), we include in our experiments in Section 5.1 a variant of XCM (XCM-Seq).", "mentionContextAttributes": {"used": {"value": false, "score": 0.0205497145652771}, "created": {"value": false, "score": 3.135204315185547e-05}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999932050704956}, "created": {"value": true, "score": 0.9999338388442993}, "shared": {"value": false, "score": 5.4836273193359375e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MTEX", "normalizedForm": "MTEX", "offsetStart": 310, "offsetEnd": 314}, "context": "In this section, we illustrate how our approach XCM reconciles performance and explainability and show that XCM enables a more precise identification of the regions of the input data that are important for predictions compared to the current deep learning MTS classifier also providing faithful explainability-MTEX-CNN.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0005757808685302734}, "created": {"value": false, "score": 0.49708884954452515}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997316002845764}, "created": {"value": true, "score": 0.9856033325195312}, "shared": {"value": false, "score": 1.430511474609375e-06}}, "references": [{"label": "[12]", "normalizedForm": "[12]", "refKey": 12}, {"label": "[12]", "normalizedForm": "[12]", "refKey": 12}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CNN", "normalizedForm": "CNN", "offsetStart": 315, "offsetEnd": 318}, "context": "In this section, we illustrate how our approach XCM reconciles performance and explainability and show that XCM enables a more precise identification of the regions of the input data that are important for predictions compared to the current deep learning MTS classifier also providing faithful explainability-MTEX-CNN.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0005757808685302734}, "created": {"value": false, "score": 0.49708884954452515}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997316002845764}, "created": {"value": true, "score": 0.9998825788497925}, "shared": {"value": false, "score": 1.430511474609375e-06}}, "references": [{"label": "[12]", "normalizedForm": "[12]", "refKey": 12}, {"label": "[12]", "normalizedForm": "[12]", "refKey": 12}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MTEX-CNN", "normalizedForm": "MTEX-CNN", "offsetStart": 342, "offsetEnd": 350}, "context": "We show that XCM outperforms the state-of-the-art MTS classifiers on both the large and small UEA datasets [7]; \u2022 We illustrate on a synthetic dataset that XCM enables a more precise identification of the regions of the input data that are important for predictions compared to the current faithfully explainable deep learning MTS classifier MTEX-CNN; \u2022", "mentionContextAttributes": {"used": {"value": false, "score": 0.03140699863433838}, "created": {"value": false, "score": 0.0006378293037414551}, "shared": {"value": false, "score": 5.960464477539062e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.03140699863433838}, "created": {"value": false, "score": 0.0006378293037414551}, "shared": {"value": false, "score": 5.960464477539062e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "XCM", "normalizedForm": "XCM", "offsetStart": 348, "offsetEnd": 351}, "context": "In order to assess the potential advantage of concatenating the 2D and 1D convolution blocks instead of having them in sequence, independently from the choice of the classification layers (fully connected layers as in MTEX-CNN versus 1D global average pooling with a softmax layer in XCM), we include in our experiments in Section 5.1 a variant of XCM (XCM-Seq).", "mentionContextAttributes": {"used": {"value": false, "score": 0.0205497145652771}, "created": {"value": false, "score": 3.135204315185547e-05}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999932050704956}, "created": {"value": true, "score": 0.9999338388442993}, "shared": {"value": false, "score": 5.4836273193359375e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "XCM", "normalizedForm": "XCM", "offsetStart": 353, "offsetEnd": 356}, "context": "In order to assess the potential advantage of concatenating the 2D and 1D convolution blocks instead of having them in sequence, independently from the choice of the classification layers (fully connected layers as in MTEX-CNN versus 1D global average pooling with a softmax layer in XCM), we include in our experiments in Section 5.1 a variant of XCM (XCM-Seq).", "mentionContextAttributes": {"used": {"value": false, "score": 0.0205497145652771}, "created": {"value": false, "score": 3.135204315185547e-05}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999932050704956}, "created": {"value": true, "score": 0.9999338388442993}, "shared": {"value": false, "score": 5.4836273193359375e-06}}}], "references": [{"refKey": 6, "tei": "<biblStruct xml:id=\"b6\">\n\t<monogr>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">P</forename><surname>Sch\u00e4fer</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">U</forename><surname>Leser</surname></persName>\n\t\t</author>\n\t\t<idno>arXiv</idno>\n\t\t<title level=\"m\">Multivariate Time Series Classification with WEASEL + MUSE</title>\n\t\t<imprint>\n\t\t\t<date>2017</date>\n\t\t</imprint>\n\t</monogr>\n</biblStruct>\n"}, {"refKey": 12, "tei": "<biblStruct xml:id=\"b12\">\n\t<analytic>\n\t\t<title level=\"a\" type=\"main\">MTEX-CNN: Multivariate Time Series EXplanations for Predictions with Convolutional Neural Networks</title>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Roy</forename><surname>Assaf</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Ioana</forename><surname>Giurgiu</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Frank</forename><surname>Bagehorn</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Anika</forename><surname>Schumann</surname></persName>\n\t\t</author>\n\t\t<idno type=\"DOI\">10.1109/icdm.2019.00106</idno>\n\t</analytic>\n\t<monogr>\n\t\t<title level=\"m\">2019 IEEE International Conference on Data Mining (ICDM)</title>\n\t\t<imprint>\n\t\t\t<publisher>IEEE</publisher>\n\t\t\t<date type=\"published\" when=\"2019-11\">November 8-11, 2019</date>\n\t\t</imprint>\n\t</monogr>\n</biblStruct>\n"}], "runtime": 14207, "id": "56dd3a72be1401781cfb20420acfec2338d004f9", "metadata": {"id": "56dd3a72be1401781cfb20420acfec2338d004f9"}, "original_file_path": "../../datalake/Samuel/SOFTware-Sync/downloads/xml/hal-03469487.grobid.tei.xml", "file_name": "hal-03469487.grobid.tei.xml"}