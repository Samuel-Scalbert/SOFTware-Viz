{"application": "software-mentions", "version": "0.8.0", "date": "2024-04-12T16:23+0000", "md5": "8166FFC33AED8F96D0D689B404D3F3BB", "mentions": [{"type": "software", "software-type": "software", "software-name": {"rawForm": "WEASEL+MUSE", "normalizedForm": "WEASEL+MUSE", "offsetStart": 0, "offsetEnd": 11}, "context": "WEASEL+MUSE generates a BoW representation by applying various sliding windows with different sizes on each discretized dimension (Symbolic Fourier Approximation) to capture features (unigrams, bigrams and dimension identification).", "mentionContextAttributes": {"used": {"value": false, "score": 0.0006836056709289551}, "created": {"value": false, "score": 1.2814998626708984e-05}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999837279319763}, "created": {"value": false, "score": 3.224611282348633e-05}, "shared": {"value": false, "score": 1.7285346984863281e-06}}, "references": [{"label": "[6]", "normalizedForm": "[6]", "refKey": 6}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "WEASEL+ MUSE", "normalizedForm": "WEASEL+ MUSE", "offsetStart": 0, "offsetEnd": 12}, "context": "WEASEL+ MUSE shows better results compared to gRSF, LPS, mv-ARF, SMTS and UFS on average (20 MTS datasets).", "mentionContextAttributes": {"used": {"value": false, "score": 0.12179416418075562}, "created": {"value": false, "score": 8.64267349243164e-06}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.12179416418075562}, "created": {"value": true, "score": 0.997067391872406}, "shared": {"value": false, "score": 1.7881393432617188e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "WEASEL+MUSE", "normalizedForm": "WEASEL+MUSE", "offsetStart": 2, "offsetEnd": 13}, "context": " with the following hyperparameter: batch size {1, 8, 32};\u2022 WEASEL+MUSE: we used the", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999837279319763}, "created": {"value": false, "score": 3.159046173095703e-06}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999837279319763}, "created": {"value": false, "score": 3.224611282348633e-05}, "shared": {"value": false, "score": 1.7285346984863281e-06}}, "references": [{"label": "[6]", "normalizedForm": "[6]", "refKey": 6}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MTEX", "normalizedForm": "MTEX", "offsetStart": 3, "offsetEnd": 7}, "context": "As MTEX-CNN attribution maps exhibit a red color gradient, the precision of identification of the regions of the input data on MTEX-CNN attribution maps could be enhanced by setting a higher threshold than 0.6 for the attribution values.", "mentionContextAttributes": {"used": {"value": true, "score": 0.999381959438324}, "created": {"value": false, "score": 2.092123031616211e-05}, "shared": {"value": false, "score": 4.172325134277344e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997316598892212}, "created": {"value": true, "score": 0.9856031537055969}, "shared": {"value": false, "score": 1.4901161193847656e-06}}, "references": [{"label": "[12]", "normalizedForm": "[12]", "refKey": 12}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MTEX", "normalizedForm": "MTEX", "offsetStart": 5, "offsetEnd": 9}, "context": "Both MTEX-CNN and XCM have periodically high attribution values on dimension 2 of the observed variables attribution maps.", "mentionContextAttributes": {"used": {"value": false, "score": 0.11591577529907227}, "created": {"value": false, "score": 3.993511199951172e-06}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997316598892212}, "created": {"value": true, "score": 0.9856031537055969}, "shared": {"value": false, "score": 1.4901161193847656e-06}}, "references": [{"label": "[12]", "normalizedForm": "[12]", "refKey": 12}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MTEX", "normalizedForm": "MTEX", "offsetStart": 7, "offsetEnd": 11}, "context": "First, MTEX-CNN and XCM (Batch Size: 1, Window Size: 20%) correctly predict the 10 MTS of the test set (accuracy 100%).", "mentionContextAttributes": {"used": {"value": true, "score": 0.9993665814399719}, "created": {"value": false, "score": 4.112720489501953e-06}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997316598892212}, "created": {"value": true, "score": 0.9856031537055969}, "shared": {"value": false, "score": 1.4901161193847656e-06}}, "references": [{"label": "[12]", "normalizedForm": "[12]", "refKey": 12}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MTEX", "normalizedForm": "MTEX", "offsetStart": 9, "offsetEnd": 13}, "context": "Finally, MTEX-CNN requires upsampling processes on feature maps when applying Grad-CAM, which can lead to an imprecise identification of the regions of the input data that are important for predictions.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00012636184692382812}, "created": {"value": false, "score": 3.272294998168945e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997316598892212}, "created": {"value": true, "score": 0.9856031537055969}, "shared": {"value": false, "score": 1.4901161193847656e-06}}, "references": [{"label": "[12]", "normalizedForm": "[12]", "refKey": 12}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MTEX", "normalizedForm": "MTEX", "offsetStart": 10, "offsetEnd": 14}, "context": "Moreover, MTEX-CNN and XCM with Grad-CAM all correctly identify the discriminative time window. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9979332089424133}, "created": {"value": false, "score": 3.874301910400391e-06}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997316598892212}, "created": {"value": true, "score": 0.9856031537055969}, "shared": {"value": false, "score": 1.4901161193847656e-06}}, "references": [{"label": "[12]", "normalizedForm": "[12]", "refKey": 12}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "-CAM", "normalizedForm": "-CAM", "offsetStart": 12, "offsetEnd": 16}, "context": "Indeed, Grad-CAM can also offer global explainability by averaging the attribution maps values per class. ", "mentionContextAttributes": {"used": {"value": false, "score": 2.378225326538086e-05}, "created": {"value": false, "score": 2.8073787689208984e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997252225875854}, "created": {"value": false, "score": 0.0027207136154174805}, "shared": {"value": false, "score": 0.25354528427124023}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MTEX", "normalizedForm": "MTEX", "offsetStart": 14, "offsetEnd": 18}, "context": "A recent CNN, MTEX-CNN [12] proposes using 2D and 1D convolution filters in sequence to extract key MTS information, i.e., information relative to the observed variables and time, respectively. ", "mentionContextAttributes": {"used": {"value": false, "score": 9.900331497192383e-05}, "created": {"value": false, "score": 0.00010687112808227539}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997316598892212}, "created": {"value": true, "score": 0.9856031537055969}, "shared": {"value": false, "score": 1.4901161193847656e-06}}, "references": [{"label": "[12]", "normalizedForm": "[12]", "refKey": 12, "offsetStart": 3015, "offsetEnd": 3019}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "-CAM", "normalizedForm": "-CAM", "offsetStart": 15, "offsetEnd": 19}, "context": "Concerning Grad-CAM, we used the implementation available for Keras (https://github.com/jacobgil/keras-grad-cam ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9997252225875854}, "created": {"value": false, "score": 0.0027207136154174805}, "shared": {"value": false, "score": 0.25354528427124023}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997252225875854}, "created": {"value": false, "score": 0.0027207136154174805}, "shared": {"value": false, "score": 0.25354528427124023}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MTEX", "normalizedForm": "MTEX", "offsetStart": 16, "offsetEnd": 20}, "context": "We also include MTEX-CNN in the benchmark to demonstrate the superiority of our approach as MTEX-CNN has not been evaluated on the public UEA datasets.", "mentionContextAttributes": {"used": {"value": false, "score": 0.21564364433288574}, "created": {"value": false, "score": 0.031333208084106445}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997316598892212}, "created": {"value": true, "score": 0.9856031537055969}, "shared": {"value": false, "score": 1.4901161193847656e-06}}, "references": [{"label": "[12]", "normalizedForm": "[12]", "refKey": 12}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Grad-CAM", "normalizedForm": "Grad-CAM", "offsetStart": 20, "offsetEnd": 28}, "context": "We compare XCM with Grad-CAM to a reference commercial solution (HeatPhone [53]) and the most accurate state-of-the-art MTS classifier of our benchmark (see Section 4.2) on this real-world application-MLSTM-FCN-with SHAP [32]. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9186108708381653}, "created": {"value": false, "score": 2.0682811737060547e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9186108708381653}, "created": {"value": false, "score": 3.618001937866211e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MTEX", "normalizedForm": "MTEX", "offsetStart": 24, "offsetEnd": 28}, "context": "We observe that XCM and MTEX-CNN obtain the same performance whereas XCM has around 10 times fewer parameters than MTEX-CNN (trainable parameters: XCM 17k, MTEX-CNN 232k).", "mentionContextAttributes": {"used": {"value": true, "score": 0.6832627058029175}, "created": {"value": false, "score": 3.635883331298828e-06}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997316598892212}, "created": {"value": true, "score": 0.9856031537055969}, "shared": {"value": false, "score": 1.4901161193847656e-06}}, "references": [{"label": "[12]", "normalizedForm": "[12]", "refKey": 12}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MTEX", "normalizedForm": "MTEX", "offsetStart": 28, "offsetEnd": 32}, "context": "As illustrated in Figure 1, MTEX-CNN is a two-stage CNN network which first extracts information relative to each feature with 2D convolution filters and then extracts information relative to time with 1D convolution filters.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0010302066802978516}, "created": {"value": false, "score": 0.0003025531768798828}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997316598892212}, "created": {"value": true, "score": 0.9856031537055969}, "shared": {"value": false, "score": 1.4901161193847656e-06}}, "references": [{"label": "[12]", "normalizedForm": "[12]", "refKey": 12}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MTEX", "normalizedForm": "MTEX", "offsetStart": 33, "offsetEnd": 37}, "context": "XCM outperforms both XCM-Seq and MTEX-CNN on average on the UEA datasets (rank: 2.3, XCM-Seq: 5.0, MTEX-CNN: 7.2).", "mentionContextAttributes": {"used": {"value": false, "score": 0.06691521406173706}, "created": {"value": false, "score": 3.057718276977539e-05}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997316598892212}, "created": {"value": true, "score": 0.9856031537055969}, "shared": {"value": false, "score": 1.4901161193847656e-06}}, "references": [{"label": "[12]", "normalizedForm": "[12]", "refKey": 12}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MTEX-CNN", "normalizedForm": "MTEX-CNN", "offsetStart": 35, "offsetEnd": 43}, "context": "However, CNN architectures such as MTEX-CNN have significant limitations. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.00012302398681640625}, "created": {"value": false, "score": 3.165006637573242e-05}, "shared": {"value": false, "score": 4.172325134277344e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.03140681982040405}, "created": {"value": false, "score": 0.0006378293037414551}, "shared": {"value": false, "score": 5.960464477539062e-07}}}, {"type": "software", "software-type": "component", "software-name": {"rawForm": "scmamp", "normalizedForm": "scmamp", "offsetStart": 50, "offsetEnd": 56}, "context": "We used the implementation available in R package scmamp (https://www.rdocumentation.org/packages/scmamp/ ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9998044967651367}, "created": {"value": false, "score": 0.0005258917808532715}, "shared": {"value": false, "score": 0.3549807667732239}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9998044967651367}, "created": {"value": false, "score": 0.0005258917808532715}, "shared": {"value": false, "score": 0.3549807667732239}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MTEX", "normalizedForm": "MTEX", "offsetStart": 51, "offsetEnd": 55}, "context": "There is no basis of comparison for MLSTM-FCN with MTEX-CNN [12] as MTEX-CNN has not been evaluated on public datasets.", "mentionContextAttributes": {"used": {"value": false, "score": 0.18324202299118042}, "created": {"value": false, "score": 4.708766937255859e-06}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997316598892212}, "created": {"value": true, "score": 0.9856031537055969}, "shared": {"value": false, "score": 1.4901161193847656e-06}}, "references": [{"label": "[12]", "normalizedForm": "[12]", "refKey": 12, "offsetStart": 10978, "offsetEnd": 10982}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MTEX-CNN", "normalizedForm": "MTEX-CNN", "offsetStart": 54, "offsetEnd": 66}, "context": "As illustrated in Figure 1, a recent explainable CNN, MTEX-CNN [12], proposes to use 2D and 1D convolution filters in sequence to extract key MTS information, i.e., information relative to the observed variables and time, respectively. ", "mentionContextAttributes": {"used": {"value": false, "score": 6.61015510559082e-05}, "created": {"value": false, "score": 0.00017333030700683594}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.03140681982040405}, "created": {"value": false, "score": 0.0006378293037414551}, "shared": {"value": false, "score": 5.960464477539062e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MTEX", "normalizedForm": "MTEX", "offsetStart": 55, "offsetEnd": 59}, "context": "All the networks that we implemented (XCM, XCM-Seq and MTEX-CNN) were trained with 100 epochs, the categorical crossentropy loss and the Adam optimization (computing infrastructure: Debian 8 operating system, GPU NVIDIA GeForce RTX 2080 Ti with 11Gb GRAM and 96Gb of RAM). ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9997316598892212}, "created": {"value": false, "score": 1.233816146850586e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997316598892212}, "created": {"value": true, "score": 0.9856031537055969}, "shared": {"value": false, "score": 1.4901161193847656e-06}}, "references": [{"label": "[12]", "normalizedForm": "[12]", "refKey": 12}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MTEX", "normalizedForm": "MTEX", "offsetStart": 55, "offsetEnd": 59}, "context": "However, as shown in Figure 5, the attribution maps of MTEX-CNN and XCM with the same explainability method (Grad-CAM) are different.", "mentionContextAttributes": {"used": {"value": false, "score": 0.29940932989120483}, "created": {"value": false, "score": 3.3974647521972656e-06}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997316598892212}, "created": {"value": true, "score": 0.9856031537055969}, "shared": {"value": false, "score": 1.4901161193847656e-06}}, "references": [{"label": "[12]", "normalizedForm": "[12]", "refKey": 12}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MTEX", "normalizedForm": "MTEX", "offsetStart": 55, "offsetEnd": 59}, "context": "Nonetheless, the observed variables attribution map of MTEX-CNN shows high attribution values on a window larger than the discriminative one (timestamps range [34,83], intersection-over-union: 0.41).", "mentionContextAttributes": {"used": {"value": false, "score": 0.47457355260849}, "created": {"value": false, "score": 8.52346420288086e-06}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997316598892212}, "created": {"value": true, "score": 0.9856031537055969}, "shared": {"value": false, "score": 1.4901161193847656e-06}}, "references": [{"label": "[12]", "normalizedForm": "[12]", "refKey": 12}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MTEX", "normalizedForm": "MTEX", "offsetStart": 57, "offsetEnd": 61}, "context": "Finally, deep learning methods (FCN [26], MLSTM-FCN [5], MTEX-CNN [12], ResNet [27], TapNet [28] and TST [29]) use Long-Short Term Memory (LSTM), Convolutional Neural Networks (CNN) or Transformers.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0006260275840759277}, "created": {"value": false, "score": 2.562999725341797e-06}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997316598892212}, "created": {"value": true, "score": 0.9856031537055969}, "shared": {"value": false, "score": 1.4901161193847656e-06}}, "references": [{"label": "[12]", "normalizedForm": "[12]", "refKey": 12}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MTEX", "normalizedForm": "MTEX", "offsetStart": 63, "offsetEnd": 67}, "context": "In addition, the significant number of trainable parameters of MTEX-CNN affects its generalization ability on small datasets. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.00031626224517822266}, "created": {"value": false, "score": 6.002187728881836e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997316598892212}, "created": {"value": true, "score": 0.9856031537055969}, "shared": {"value": false, "score": 1.4901161193847656e-06}}, "references": [{"label": "[12]", "normalizedForm": "[12]", "refKey": 12}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MTEX-CNN", "normalizedForm": "MTEX-CNN", "offsetStart": 63, "offsetEnd": 71}, "context": "Finally, the use of non fully padded convolution filters as in MTEX-CNN can lead to an imprecise identification of the regions of the input data that are important for predictions as Grad-CAM is sensitive to upsampling processes. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.00019288063049316406}, "created": {"value": false, "score": 3.618001937866211e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.03140681982040405}, "created": {"value": false, "score": 0.0006378293037414551}, "shared": {"value": false, "score": 5.960464477539062e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MTEX", "normalizedForm": "MTEX", "offsetStart": 68, "offsetEnd": 72}, "context": "There is no basis of comparison for MLSTM-FCN with MTEX-CNN [12] as MTEX-CNN has not been evaluated on public datasets.", "mentionContextAttributes": {"used": {"value": false, "score": 0.18324202299118042}, "created": {"value": false, "score": 4.708766937255859e-06}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997316598892212}, "created": {"value": true, "score": 0.9856031537055969}, "shared": {"value": false, "score": 1.4901161193847656e-06}}, "references": [{"label": "[12]", "normalizedForm": "[12]", "refKey": 12}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "WEASEL+MUSE", "normalizedForm": "WEASEL+MUSE", "offsetStart": 68, "offsetEnd": 79}, "context": "On the other hand, BoW models (LPS [23], mv-ARF [24], SMTS [25] and WEASEL+MUSE [6]) convert time series into a bag of discrete words and use a histogram of words representation to perform the classification.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0009886622428894043}, "created": {"value": false, "score": 1.3768672943115234e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999837279319763}, "created": {"value": false, "score": 3.224611282348633e-05}, "shared": {"value": false, "score": 1.7285346984863281e-06}}, "references": [{"label": "[6]", "normalizedForm": "[6]", "refKey": 6, "offsetStart": 9491, "offsetEnd": 9494}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "WEASEL +MUSE", "normalizedForm": "WEASEL +MUSE", "offsetStart": 70, "offsetEnd": 82}, "context": "More specifically, XCM exhibits better performance than MLSTM-FCN and WEASEL +MUSE on both the large (rank: 1.9, MLSTM-FCN rank: 2.1, WEASEL+MUSE rank: 4.6-train size \u2265 500, 23% of the datasets) and small datasets (rank: 2.4, MLSTM-FCN rank: 4.0, WEASEL+MUSE rank: 3.9-train size < 500, 77% of the datasets).", "mentionContextAttributes": {"used": {"value": true, "score": 0.656013011932373}, "created": {"value": false, "score": 2.205371856689453e-06}, "shared": {"value": false, "score": 7.748603820800781e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.656013011932373}, "created": {"value": false, "score": 2.205371856689453e-06}, "shared": {"value": false, "score": 7.748603820800781e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "WEASEL+MUSE", "normalizedForm": "WEASEL+MUSE", "offsetStart": 83, "offsetEnd": 94}, "context": "However, MLSTM-FCN outperforms the second-best MTS classifier (Bag-of-Words method WEASEL+MUSE [6]) only on the large datasets (relatively to the public UEA archive [7]training set size \u2265 500).", "mentionContextAttributes": {"used": {"value": false, "score": 0.006712496280670166}, "created": {"value": false, "score": 9.119510650634766e-06}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999837279319763}, "created": {"value": false, "score": 3.224611282348633e-05}, "shared": {"value": false, "score": 1.7285346984863281e-06}}, "references": [{"label": "[6]", "normalizedForm": "[6]", "refKey": 6, "offsetStart": 1107, "offsetEnd": 1110}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "WEASEL+MUSE", "normalizedForm": "WEASEL+MUSE", "offsetStart": 87, "offsetEnd": 98}, "context": "The plot confirms the top three ranking as presented before (XCM: 1, MLSTM-FCN: 2, and WEASEL+MUSE: 3), without showing a statistically significant difference between each other.", "mentionContextAttributes": {"used": {"value": true, "score": 0.891534149646759}, "created": {"value": false, "score": 2.1159648895263672e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999837279319763}, "created": {"value": false, "score": 3.224611282348633e-05}, "shared": {"value": false, "score": 1.7285346984863281e-06}}, "references": [{"label": "[6]", "normalizedForm": "[6]", "refKey": 6}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MTEX", "normalizedForm": "MTEX", "offsetStart": 88, "offsetEnd": 92}, "context": "We observe that the attribution maps drawn from XCM are more precise than the ones from MTEX-CNN, i.e., the intersection-over-union of the explanations is higher for XCM than for MTEX-CNN (intersection-over-union: XCM 0.65 versus MTEX-CNN 0.4).", "mentionContextAttributes": {"used": {"value": true, "score": 0.9954714179039001}, "created": {"value": false, "score": 1.7285346984863281e-06}, "shared": {"value": false, "score": 5.364418029785156e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997316598892212}, "created": {"value": true, "score": 0.9856031537055969}, "shared": {"value": false, "score": 1.4901161193847656e-06}}, "references": [{"label": "[12]", "normalizedForm": "[12]", "refKey": 12}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MTEX", "normalizedForm": "MTEX", "offsetStart": 92, "offsetEnd": 96}, "context": "We also include MTEX-CNN in the benchmark to demonstrate the superiority of our approach as MTEX-CNN has not been evaluated on the public UEA datasets.", "mentionContextAttributes": {"used": {"value": false, "score": 0.21564364433288574}, "created": {"value": false, "score": 0.031333208084106445}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997316598892212}, "created": {"value": true, "score": 0.9856031537055969}, "shared": {"value": false, "score": 1.4901161193847656e-06}}, "references": [{"label": "[12]", "normalizedForm": "[12]", "refKey": 12}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "scmamp", "normalizedForm": "scmamp", "offsetStart": 98, "offsetEnd": 104}, "context": "We used the implementation available in R package scmamp (https://www.rdocumentation.org/packages/scmamp/", "mentionContextAttributes": {"used": {"value": true, "score": 0.9998044967651367}, "created": {"value": false, "score": 0.0005258917808532715}, "shared": {"value": false, "score": 0.3549807667732239}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9998044967651367}, "created": {"value": false, "score": 0.0005258917808532715}, "shared": {"value": false, "score": 0.3549807667732239}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MTEX", "normalizedForm": "MTEX", "offsetStart": 99, "offsetEnd": 103}, "context": "XCM outperforms both XCM-Seq and MTEX-CNN on average on the UEA datasets (rank: 2.3, XCM-Seq: 5.0, MTEX-CNN: 7.2).", "mentionContextAttributes": {"used": {"value": false, "score": 0.06691521406173706}, "created": {"value": false, "score": 3.057718276977539e-05}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997316598892212}, "created": {"value": true, "score": 0.9856031537055969}, "shared": {"value": false, "score": 1.4901161193847656e-06}}, "references": [{"label": "[12]", "normalizedForm": "[12]", "refKey": 12}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MTEX", "normalizedForm": "MTEX", "offsetStart": 106, "offsetEnd": 110}, "context": "Therefore, we propose a new faithfully eXplainable CNN method for MTS classification (XCM) which improves MTEX-CNN in three substantial ways: (i) it generates features by extracting information relative to the observed variables and timestamps in parallel and directly from the input data; (ii) it enhances the generalization ability by adopting a compact architecture (in terms of the number of parameters); and (iii) it allows precise identification of the observed variables and timestamps of the input data that are important for predictions by avoiding upsampling processes.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0003489255905151367}, "created": {"value": false, "score": 0.18037736415863037}, "shared": {"value": false, "score": 1.2516975402832031e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997316598892212}, "created": {"value": true, "score": 0.9856031537055969}, "shared": {"value": false, "score": 1.4901161193847656e-06}}, "references": [{"label": "[12]", "normalizedForm": "[12]", "refKey": 12}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "-CAM", "normalizedForm": "-CAM", "offsetStart": 112, "offsetEnd": 116}, "context": "We chose the state-of-the-art explainability method SHAP as its granularity of explanation is comparable to Grad-CAM (both global and local). ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9987967014312744}, "created": {"value": false, "score": 0.0009434819221496582}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997252225875854}, "created": {"value": false, "score": 0.0027207136154174805}, "shared": {"value": false, "score": 0.25354528427124023}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MTEX", "normalizedForm": "MTEX", "offsetStart": 115, "offsetEnd": 119}, "context": "We observe that XCM and MTEX-CNN obtain the same performance whereas XCM has around 10 times fewer parameters than MTEX-CNN (trainable parameters: XCM 17k, MTEX-CNN 232k).", "mentionContextAttributes": {"used": {"value": true, "score": 0.6832627058029175}, "created": {"value": false, "score": 3.635883331298828e-06}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997316598892212}, "created": {"value": true, "score": 0.9856031537055969}, "shared": {"value": false, "score": 1.4901161193847656e-06}}, "references": [{"label": "[12]", "normalizedForm": "[12]", "refKey": 12}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MTEX", "normalizedForm": "MTEX", "offsetStart": 117, "offsetEnd": 121}, "context": "However, the red color gradient is due to the upsampling processes needed to match the 2D/1D output features maps of MTEX-CNN to the size of the input data when applying Grad-CAM.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9689474701881409}, "created": {"value": false, "score": 9.715557098388672e-06}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997316598892212}, "created": {"value": true, "score": 0.9856031537055969}, "shared": {"value": false, "score": 1.4901161193847656e-06}}, "references": [{"label": "[12]", "normalizedForm": "[12]", "refKey": 12}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "WEASEL+MUSE", "normalizedForm": "WEASEL+MUSE", "offsetStart": 119, "offsetEnd": 130}, "context": "4. Dense layer dimension 128 and L2 regularization 0.2) and with the following hyperparameter: batch size {1, 8, 32};\u2022 WEASEL+MUSE: we used the implementation available (https://github.com/patrickzib/", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999144673347473}, "created": {"value": false, "score": 1.424551010131836e-05}, "shared": {"value": false, "score": 1.7285346984863281e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999837279319763}, "created": {"value": false, "score": 3.224611282348633e-05}, "shared": {"value": false, "score": 1.7285346984863281e-06}}, "references": [{"label": "[6]", "normalizedForm": "[6]", "refKey": 6}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "WEASEL+MUSE", "normalizedForm": "WEASEL+MUSE", "offsetStart": 119, "offsetEnd": 130}, "context": "4. Dense layer dimension 128 and L2 regularization 0.2) and with the following hyperparameter: batch size {1, 8, 32};\u2022 WEASEL+MUSE: we used the implementation available (https://github.com/patrickzib/", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999144673347473}, "created": {"value": false, "score": 1.424551010131836e-05}, "shared": {"value": false, "score": 1.7285346984863281e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999837279319763}, "created": {"value": false, "score": 3.224611282348633e-05}, "shared": {"value": false, "score": 1.7285346984863281e-06}}, "references": [{"label": "[6]", "normalizedForm": "[6]", "refKey": 6}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "WEASEL+MUSE", "normalizedForm": "WEASEL+MUSE", "offsetStart": 119, "offsetEnd": 130}, "context": "4. Dense layer dimension 128 and L2 regularization 0.2) and with the following hyperparameter: batch size {1, 8, 32};\u2022 WEASEL+MUSE: we used the implementation available (https://github.com/patrickzib/", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999144673347473}, "created": {"value": false, "score": 1.424551010131836e-05}, "shared": {"value": false, "score": 1.7285346984863281e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999837279319763}, "created": {"value": false, "score": 3.224611282348633e-05}, "shared": {"value": false, "score": 1.7285346984863281e-06}}, "references": [{"label": "[6]", "normalizedForm": "[6]", "refKey": 6}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MTEX", "normalizedForm": "MTEX", "offsetStart": 127, "offsetEnd": 131}, "context": "Figure 5 shows one MTS sample belonging to the positive class, and the time and observed variables attribution maps supporting MTEX-CNN and XCM predictions.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9982677102088928}, "created": {"value": false, "score": 4.231929779052734e-06}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997316598892212}, "created": {"value": true, "score": 0.9856031537055969}, "shared": {"value": false, "score": 1.4901161193847656e-06}}, "references": [{"label": "[12]", "normalizedForm": "[12]", "refKey": 12}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MTEX", "normalizedForm": "MTEX", "offsetStart": 127, "offsetEnd": 131}, "context": "As MTEX-CNN attribution maps exhibit a red color gradient, the precision of identification of the regions of the input data on MTEX-CNN attribution maps could be enhanced by setting a higher threshold than 0.6 for the attribution values.", "mentionContextAttributes": {"used": {"value": true, "score": 0.999381959438324}, "created": {"value": false, "score": 2.092123031616211e-05}, "shared": {"value": false, "score": 4.172325134277344e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997316598892212}, "created": {"value": true, "score": 0.9856031537055969}, "shared": {"value": false, "score": 1.4901161193847656e-06}}, "references": [{"label": "[12]", "normalizedForm": "[12]", "refKey": 12}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "WEASEL+MUSE", "normalizedForm": "WEASEL+MUSE", "offsetStart": 134, "offsetEnd": 145}, "context": "More specifically, XCM exhibits better performance than MLSTM-FCN and WEASEL +MUSE on both the large (rank: 1.9, MLSTM-FCN rank: 2.1, WEASEL+MUSE rank: 4.6-train size \u2265 500, 23% of the datasets) and small datasets (rank: 2.4, MLSTM-FCN rank: 4.0, WEASEL+MUSE rank: 3.9-train size < 500, 77% of the datasets).", "mentionContextAttributes": {"used": {"value": true, "score": 0.656012773513794}, "created": {"value": false, "score": 2.205371856689453e-06}, "shared": {"value": false, "score": 7.748603820800781e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999837279319763}, "created": {"value": false, "score": 3.224611282348633e-05}, "shared": {"value": false, "score": 1.7285346984863281e-06}}, "references": [{"label": "[6]", "normalizedForm": "[6]", "refKey": 6}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MTEX", "normalizedForm": "MTEX", "offsetStart": 150, "offsetEnd": 154}, "context": "Grad-CAM is applied at a local level, which means that we would need to potentially set a different threshold for each instance and that would render MTEX-CNN explainability method impractical.", "mentionContextAttributes": {"used": {"value": true, "score": 0.7321299910545349}, "created": {"value": false, "score": 1.5079975128173828e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997316598892212}, "created": {"value": true, "score": 0.9856031537055969}, "shared": {"value": false, "score": 1.4901161193847656e-06}}, "references": [{"label": "[12]", "normalizedForm": "[12]", "refKey": 12}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MTEX", "normalizedForm": "MTEX", "offsetStart": 156, "offsetEnd": 160}, "context": "We observe that XCM and MTEX-CNN obtain the same performance whereas XCM has around 10 times fewer parameters than MTEX-CNN (trainable parameters: XCM 17k, MTEX-CNN 232k).", "mentionContextAttributes": {"used": {"value": true, "score": 0.6832627058029175}, "created": {"value": false, "score": 3.635883331298828e-06}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997316598892212}, "created": {"value": true, "score": 0.9856031537055969}, "shared": {"value": false, "score": 1.4901161193847656e-06}}, "references": [{"label": "[12]", "normalizedForm": "[12]", "refKey": 12}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "WEASEL+ MUSE", "normalizedForm": "WEASEL+ MUSE", "offsetStart": 157, "offsetEnd": 169}, "context": "Therefore, in this work, we choose to benchmark XCM to the best-in-class for each similarity-based, feature-based and deep learning category (DTW D /DTW I , WEASEL+ MUSE and MLSTM-FCN classifiers).", "mentionContextAttributes": {"used": {"value": false, "score": 0.030930519104003906}, "created": {"value": true, "score": 0.997067391872406}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.12179416418075562}, "created": {"value": true, "score": 0.997067391872406}, "shared": {"value": false, "score": 1.7881393432617188e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MTEX", "normalizedForm": "MTEX", "offsetStart": 167, "offsetEnd": 171}, "context": "Thus, based on the same attribution threshold (0.6), XCM allows a more precise identification of the regions of the input data that are important for predictions than MTEX-CNN.", "mentionContextAttributes": {"used": {"value": false, "score": 0.000293731689453125}, "created": {"value": false, "score": 3.993511199951172e-06}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997316598892212}, "created": {"value": true, "score": 0.9856031537055969}, "shared": {"value": false, "score": 1.4901161193847656e-06}}, "references": [{"label": "[12]", "normalizedForm": "[12]", "refKey": 12}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MTEX-CNN", "normalizedForm": "MTEX-CNN", "offsetStart": 167, "offsetEnd": 175}, "context": "Then, a CNN architecture using fully connected layers to perform classification, especially with the size of the first layer depending on the time series length as in MTEX-CNN, is prone to overfitting and can lead to the explosion of the number of trainable parameters. ", "mentionContextAttributes": {"used": {"value": false, "score": 6.0498714447021484e-05}, "created": {"value": false, "score": 0.0005177855491638184}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.03140681982040405}, "created": {"value": false, "score": 0.0006378293037414551}, "shared": {"value": false, "score": 5.960464477539062e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MTEX", "normalizedForm": "MTEX", "offsetStart": 179, "offsetEnd": 183}, "context": "We observe that the attribution maps drawn from XCM are more precise than the ones from MTEX-CNN, i.e., the intersection-over-union of the explanations is higher for XCM than for MTEX-CNN (intersection-over-union: XCM 0.65 versus MTEX-CNN 0.4). ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9954714179039001}, "created": {"value": false, "score": 1.7285346984863281e-06}, "shared": {"value": false, "score": 5.364418029785156e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997316598892212}, "created": {"value": true, "score": 0.9856031537055969}, "shared": {"value": false, "score": 1.4901161193847656e-06}}, "references": [{"label": "[12]", "normalizedForm": "[12]", "refKey": 12}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Grad-CAM", "normalizedForm": "Grad-CAM", "offsetStart": 183, "offsetEnd": 191}, "context": "Finally, the use of non fully padded convolution filters as in MTEX-CNN can lead to an imprecise identification of the regions of the input data that are important for predictions as Grad-CAM is sensitive to upsampling processes. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.00019288063049316406}, "created": {"value": false, "score": 3.618001937866211e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9186108708381653}, "created": {"value": false, "score": 3.618001937866211e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MTEX", "normalizedForm": "MTEX", "offsetStart": 184, "offsetEnd": 188}, "context": "On the time attribution map, high attribution values (above 0.6) for XCM begin on timestamp 63 and end on timestamp 76 (expected: [60, 80], intersection-over-union: 0.65), whereas for MTEX-CNN they begin later (timestamp 68, intersection-over-union: 0.4). ", "mentionContextAttributes": {"used": {"value": true, "score": 0.5550867319107056}, "created": {"value": false, "score": 1.6093254089355469e-06}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997316598892212}, "created": {"value": true, "score": 0.9856031537055969}, "shared": {"value": false, "score": 1.4901161193847656e-06}}, "references": [{"label": "[12]", "normalizedForm": "[12]", "refKey": 12}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MTEX", "normalizedForm": "MTEX", "offsetStart": 197, "offsetEnd": 201}, "context": "Therefore, considering that XCM-Seq attributions maps are the same as XCM ones, we can assume that the use of half padding on the different convolution layers to reduce the number of parameters in MTEX-CNN, i.e., the use of upsampling to retrieve the input data dimensions on the attribution maps, can lead to a less precise identification of the regions of the input data that are important for predictions.", "mentionContextAttributes": {"used": {"value": true, "score": 0.7150605916976929}, "created": {"value": false, "score": 1.996755599975586e-05}, "shared": {"value": false, "score": 1.4901161193847656e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997316598892212}, "created": {"value": true, "score": 0.9856031537055969}, "shared": {"value": false, "score": 1.4901161193847656e-06}}, "references": [{"label": "[12]", "normalizedForm": "[12]", "refKey": 12}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "WEASEL+MUSE", "normalizedForm": "WEASEL+MUSE", "offsetStart": 207, "offsetEnd": 218}, "context": "As far as we have seen, an architecture concatenating a LSTM network with a CNN such as MLSTM-FCN, or a classifier based on unigrams/bigrams extraction following a Symbolic Fourier Approximation [8] such as WEASEL+MUSE, cannot provide perfectly faithful explanations as they rely solely on post hoc model-agnostic explainability methods [9], which could prevent their use in numerous applications. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.031779587268829346}, "created": {"value": false, "score": 3.224611282348633e-05}, "shared": {"value": false, "score": 7.748603820800781e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999837279319763}, "created": {"value": false, "score": 3.224611282348633e-05}, "shared": {"value": false, "score": 1.7285346984863281e-06}}, "references": [{"label": "[6]", "normalizedForm": "[6]", "refKey": 6}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MTEX", "normalizedForm": "MTEX", "offsetStart": 218, "offsetEnd": 222}, "context": "In order to assess the potential advantage of concatenating the 2D and 1D convolution blocks instead of having them in sequence, independently from the choice of the classification layers (fully connected layers as in MTEX-CNN versus 1D global average pooling with a softmax layer in XCM), we include in our experiments in Section 5.1 a variant of XCM (XCM-Seq).", "mentionContextAttributes": {"used": {"value": false, "score": 0.02054959535598755}, "created": {"value": false, "score": 3.141164779663086e-05}, "shared": {"value": false, "score": 4.172325134277344e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997316598892212}, "created": {"value": true, "score": 0.9856031537055969}, "shared": {"value": false, "score": 1.4901161193847656e-06}}, "references": [{"label": "[12]", "normalizedForm": "[12]", "refKey": 12}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "WEASEL+MUSE", "normalizedForm": "WEASEL+MUSE", "offsetStart": 223, "offsetEnd": 234}, "context": "Firstly, we observe that XCM obtains the best average rank and the lowest rank variability across the datasets (rank: 2.3, standard error: 0.4), followed by MLSTM-FCN in second position (rank: 3.5, standard error: 0.5) and WEASEL+MUSE in third position (rank: 4.0, standard error: 0.5).", "mentionContextAttributes": {"used": {"value": true, "score": 0.61823970079422}, "created": {"value": false, "score": 2.086162567138672e-06}, "shared": {"value": false, "score": 5.364418029785156e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999837279319763}, "created": {"value": false, "score": 3.224611282348633e-05}, "shared": {"value": false, "score": 1.7285346984863281e-06}}, "references": [{"label": "[6]", "normalizedForm": "[6]", "refKey": 6}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MTEX", "normalizedForm": "MTEX", "offsetStart": 230, "offsetEnd": 234}, "context": "We observe that the attribution maps drawn from XCM are more precise than the ones from MTEX-CNN, i.e., the intersection-over-union of the explanations is higher for XCM than for MTEX-CNN (intersection-over-union: XCM 0.65 versus MTEX-CNN 0.4). ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9954714179039001}, "created": {"value": false, "score": 1.7285346984863281e-06}, "shared": {"value": false, "score": 5.364418029785156e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997316598892212}, "created": {"value": true, "score": 0.9856031537055969}, "shared": {"value": false, "score": 1.4901161193847656e-06}}, "references": [{"label": "[12]", "normalizedForm": "[12]", "refKey": 12}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MTEX", "normalizedForm": "MTEX", "offsetStart": 243, "offsetEnd": 247}, "context": "We can assume that the more compact architecture of XCM compared to the other deep learning classifiers provides a better generalization ability on the UEA datasets (average rank on the number of trainable parameters: XCM 1.7, MLSTM-FCN: 1.9, MTEX-CNN: 2.0). ", "mentionContextAttributes": {"used": {"value": false, "score": 0.004463315010070801}, "created": {"value": false, "score": 3.2782554626464844e-06}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997316598892212}, "created": {"value": true, "score": 0.9856031537055969}, "shared": {"value": false, "score": 1.4901161193847656e-06}}, "references": [{"label": "[12]", "normalizedForm": "[12]", "refKey": 12}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "WEASEL+MUSE", "normalizedForm": "WEASEL+MUSE", "offsetStart": 247, "offsetEnd": 258}, "context": "More specifically, XCM exhibits better performance than MLSTM-FCN and WEASEL +MUSE on both the large (rank: 1.9, MLSTM-FCN rank: 2.1, WEASEL+MUSE rank: 4.6-train size \u2265 500, 23% of the datasets) and small datasets (rank: 2.4, MLSTM-FCN rank: 4.0, WEASEL+MUSE rank: 3.9-train size < 500, 77% of the datasets).", "mentionContextAttributes": {"used": {"value": true, "score": 0.656012773513794}, "created": {"value": false, "score": 2.205371856689453e-06}, "shared": {"value": false, "score": 7.748603820800781e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999837279319763}, "created": {"value": false, "score": 3.224611282348633e-05}, "shared": {"value": false, "score": 1.7285346984863281e-06}}, "references": [{"label": "[6]", "normalizedForm": "[6]", "refKey": 6}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MTEX", "normalizedForm": "MTEX", "offsetStart": 279, "offsetEnd": 283}, "context": "The design of our network architecture avoids upsampling processes and enables Grad-CAM to identify the observed variables and timestamps of the input data that are important for predictions more precisely as compared to what the current explainable deep learning MTS classifier MTEX-CNN give.", "mentionContextAttributes": {"used": {"value": false, "score": 5.525350570678711e-05}, "created": {"value": true, "score": 0.9856031537055969}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997316598892212}, "created": {"value": true, "score": 0.9856031537055969}, "shared": {"value": false, "score": 1.4901161193847656e-06}}, "references": [{"label": "[12]", "normalizedForm": "[12]", "refKey": 12}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MTEX", "normalizedForm": "MTEX", "offsetStart": 310, "offsetEnd": 314}, "context": "In this section, we illustrate how our approach XCM reconciles performance and explainability and show that XCM enables a more precise identification of the regions of the input data that are important for predictions compared to the current deep learning MTS classifier also providing faithful explainability-MTEX-CNN.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0005757808685302734}, "created": {"value": false, "score": 0.49708986282348633}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997316598892212}, "created": {"value": true, "score": 0.9856031537055969}, "shared": {"value": false, "score": 1.4901161193847656e-06}}, "references": [{"label": "[12]", "normalizedForm": "[12]", "refKey": 12}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MTEX-CNN", "normalizedForm": "MTEX-CNN", "offsetStart": 342, "offsetEnd": 350}, "context": "We show that XCM outperforms the state-of-the-art MTS classifiers on both the large and small UEA datasets [7]; \u2022 We illustrate on a synthetic dataset that XCM enables a more precise identification of the regions of the input data that are important for predictions compared to the current faithfully explainable deep learning MTS classifier MTEX-CNN; \u2022", "mentionContextAttributes": {"used": {"value": false, "score": 0.03140681982040405}, "created": {"value": false, "score": 0.0006378293037414551}, "shared": {"value": false, "score": 5.960464477539062e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.03140681982040405}, "created": {"value": false, "score": 0.0006378293037414551}, "shared": {"value": false, "score": 5.960464477539062e-07}}}], "references": [{"refKey": 6, "tei": "<biblStruct xml:id=\"b6\">\n\t<monogr>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">P</forename><surname>Sch\u00e4fer</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">U</forename><surname>Leser</surname></persName>\n\t\t</author>\n\t\t<idno>arXiv</idno>\n\t\t<title level=\"m\">Multivariate Time Series Classification with WEASEL + MUSE</title>\n\t\t<imprint>\n\t\t\t<date>2017</date>\n\t\t</imprint>\n\t</monogr>\n</biblStruct>\n"}, {"refKey": 12, "tei": "<biblStruct xml:id=\"b12\">\n\t<analytic>\n\t\t<title level=\"a\" type=\"main\">MTEX-CNN: Multivariate Time Series EXplanations for Predictions with Convolutional Neural Networks</title>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Roy</forename><surname>Assaf</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Ioana</forename><surname>Giurgiu</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Frank</forename><surname>Bagehorn</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Anika</forename><surname>Schumann</surname></persName>\n\t\t</author>\n\t\t<idno type=\"DOI\">10.1109/icdm.2019.00106</idno>\n\t</analytic>\n\t<monogr>\n\t\t<title level=\"m\">2019 IEEE International Conference on Data Mining (ICDM)</title>\n\t\t<imprint>\n\t\t\t<publisher>IEEE</publisher>\n\t\t\t<date type=\"published\" when=\"2019-11\">November 8-11, 2019</date>\n\t\t</imprint>\n\t</monogr>\n</biblStruct>\n"}], "runtime": 75092, "id": "7e96e68a0354d4c923fe0b8ef8c2b4bc13ce0e25", "metadata": {"id": "7e96e68a0354d4c923fe0b8ef8c2b4bc13ce0e25"}, "original_file_path": "../../datalake/Samuel/SOFTware-Sync/data/xml_files/hal-03469487.grobid.tei.xml", "file_name": "hal-03469487.grobid.tei.xml"}