{"application": "software-mentions", "version": "0.8.0", "date": "2024-10-07T12:01+0000", "md5": "93BAA0D04D8A13942847810592099DFB", "mentions": [{"type": "software", "software-type": "software", "software-name": {"rawForm": "ELMo", "normalizedForm": "ELMo", "offsetStart": 0, "offsetEnd": 4}, "context": "ELMo also computes a context-independent token representation via a CNN over characters.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0001266002655029297}, "created": {"value": false, "score": 7.987022399902344e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999902248382568}, "created": {"value": true, "score": 0.9998936653137207}, "shared": {"value": false, "score": 3.337860107421875e-06}}, "references": [{"label": "(Peters et al., 2018)", "normalizedForm": "Peters et al., 2018", "refKey": 29}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ELMo", "normalizedForm": "ELMo", "offsetStart": 0, "offsetEnd": 4}, "context": "ELMo OSCAR models exhibit exactly the same behavior as ELMo Wikipedia models where the scores continue to improve the longer they are pre-trained, except for the case of Finnish.", "mentionContextAttributes": {"used": {"value": false, "score": 0.000523984432220459}, "created": {"value": false, "score": 4.649162292480469e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999902248382568}, "created": {"value": true, "score": 0.9998936653137207}, "shared": {"value": false, "score": 3.337860107421875e-06}}, "references": [{"label": "(Peters et al., 2018)", "normalizedForm": "Peters et al., 2018", "refKey": 29}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "UDify", "normalizedForm": "UDify", "offsetStart": 0, "offsetEnd": 5}, "context": "UDify is actually trained by concatenating the training sets of 124 different UD treebanks, creating a single POS tagging and dependency parsing model that works across 75 different languages.", "mentionContextAttributes": {"used": {"value": false, "score": 0.010743439197540283}, "created": {"value": false, "score": 0.00030994415283203125}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9995203018188477}, "created": {"value": false, "score": 0.00030994415283203125}, "shared": {"value": false, "score": 1.1920928955078125e-06}}, "references": [{"label": "(Kondratyuk and Straka, 2019)", "normalizedForm": "Kondratyuk and Straka, 2019", "refKey": 17}, {"label": "(Kondratyuk and Straka, 2019)", "normalizedForm": "Kondratyuk and Straka, 2019", "refKey": 17}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "UDPipe", "normalizedForm": "UDPipe", "offsetStart": 0, "offsetEnd": 6}, "version": {"rawForm": "2.0", "normalizedForm": "2.0", "offsetStart": 7, "offsetEnd": 10}, "context": "UDPipe 2.0 is a multi-task model that predicts POS tags, lemmas and dependency trees jointly.", "mentionContextAttributes": {"used": {"value": false, "score": 2.849102020263672e-05}, "created": {"value": false, "score": 0.0002015233039855957}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999147653579712}, "created": {"value": false, "score": 0.005289673805236816}, "shared": {"value": false, "score": 0.002932727336883545}}, "references": [{"label": "(Straka, 2018;", "normalizedForm": "(Straka, 2018", "refKey": 35}, {"label": "Straka et al., 2019)", "normalizedForm": "Straka et al., 2019)", "refKey": 37}, {"label": "(Straka, 2018;", "normalizedForm": "(Straka, 2018", "refKey": 35}, {"label": "Straka et al., 2019)", "normalizedForm": "Straka et al., 2019)", "refKey": 37}]}, {"type": "software", "software-type": "implicit", "software-name": {"rawForm": "script", "normalizedForm": "script", "offsetStart": 0, "offsetEnd": 7}, "context": "script8 from Giuseppe Attardi. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9856539368629456}, "created": {"value": false, "score": 2.5987625122070312e-05}, "shared": {"value": false, "score": 9.5367431640625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9856539368629456}, "created": {"value": false, "score": 2.5987625122070312e-05}, "shared": {"value": false, "score": 9.5367431640625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ELMo", "normalizedForm": "ELMo", "offsetStart": 4, "offsetEnd": 8}, "context": "The ELMo authors have expressed that increasing the number of training epochs is generally better, as they argue that training the ELMo model for longer reduces held-out perplexity and further improves downstream task performance.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0005105733871459961}, "created": {"value": false, "score": 0.00020200014114379883}, "shared": {"value": false, "score": 5.960464477539062e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999902248382568}, "created": {"value": true, "score": 0.9998936653137207}, "shared": {"value": false, "score": 3.337860107421875e-06}}, "references": [{"label": "(Peters et al., 2018)", "normalizedForm": "Peters et al., 2018", "refKey": 29}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "UDPipe", "normalizedForm": "UDPipe", "offsetStart": 7, "offsetEnd": 13}, "version": {"rawForm": "2.0", "normalizedForm": "2.0", "offsetStart": 14, "offsetEnd": 17}, "context": "We use UDPipe 2.0 without contextualized embeddings as our baseline for POS tagging and dependency parsing. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.2757298946380615}, "created": {"value": false, "score": 1.1324882507324219e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999147653579712}, "created": {"value": false, "score": 0.005289673805236816}, "shared": {"value": false, "score": 0.002932727336883545}}, "references": [{"label": "(Straka, 2018;", "normalizedForm": "(Straka, 2018", "refKey": 35}, {"label": "Straka et al., 2019)", "normalizedForm": "Straka et al., 2019)", "refKey": 37}, {"label": "(Straka, 2018;", "normalizedForm": "(Straka, 2018", "refKey": 35}, {"label": "Straka et al., 2019)", "normalizedForm": "Straka et al., 2019)", "refKey": 37}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "UDPipe", "normalizedForm": "UDPipe", "offsetStart": 7, "offsetEnd": 13}, "version": {"rawForm": "2.0", "normalizedForm": "2.0"}, "context": "12 4.2 UDPipe 2.0", "mentionContextAttributes": {"used": {"value": true, "score": 0.9957550764083862}, "created": {"value": false, "score": 8.702278137207031e-05}, "shared": {"value": false, "score": 5.960464477539062e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999147653579712}, "created": {"value": false, "score": 0.005289673805236816}, "shared": {"value": false, "score": 0.002932727336883545}}, "references": [{"label": "(Straka, 2018;", "normalizedForm": "(Straka, 2018", "refKey": 35}, {"label": "Straka et al., 2019)", "normalizedForm": "Straka et al., 2019)", "refKey": 37}, {"label": "(Straka, 2018;", "normalizedForm": "(Straka, 2018", "refKey": 35}, {"label": "Straka et al., 2019)", "normalizedForm": "Straka et al., 2019)", "refKey": 37}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ELMo", "normalizedForm": "ELMo", "offsetStart": 9, "offsetEnd": 13}, "context": "We train ELMo contextualized word embeddings for 5 languages: Bulgarian, Catalan, Danish, Finnish and Indonesian. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.004957795143127441}, "created": {"value": true, "score": 0.9813149571418762}, "shared": {"value": false, "score": 5.960464477539062e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999902248382568}, "created": {"value": true, "score": 0.9998936653137207}, "shared": {"value": false, "score": 3.337860107421875e-06}}, "references": [{"label": "(Peters et al., 2018)", "normalizedForm": "Peters et al., 2018", "refKey": 29}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ELMo", "normalizedForm": "ELMo", "offsetStart": 9, "offsetEnd": 13}, "context": "We train ELMo models for Bulgarian, Catalan, Danish, Finnish and Indonesian using the OSCAR corpora on the one hand and the Wikipedia corpora on the other.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0003726482391357422}, "created": {"value": false, "score": 0.20287036895751953}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999902248382568}, "created": {"value": true, "score": 0.9998936653137207}, "shared": {"value": false, "score": 3.337860107421875e-06}}, "references": [{"label": "(Peters et al., 2018)", "normalizedForm": "Peters et al., 2018", "refKey": 29}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "UDPipe", "normalizedForm": "UDPipe", "offsetStart": 9, "offsetEnd": 15}, "version": {"rawForm": "2.0", "normalizedForm": "2.0", "offsetStart": 16, "offsetEnd": 19}, "context": "We train UDPipe 2.0 using gold tokenization and segmentation for each of our ELMo models, the only thing that changes from training to training is the ELMo model as hyperparameters always remain at the default values (except for number of training tokens) (Peters et al., 2018).", "mentionContextAttributes": {"used": {"value": false, "score": 0.09617096185684204}, "created": {"value": false, "score": 0.0001304149627685547}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999147653579712}, "created": {"value": false, "score": 0.005289673805236816}, "shared": {"value": false, "score": 0.002932727336883545}}, "references": [{"label": "(Straka, 2018;", "normalizedForm": "(Straka, 2018", "refKey": 35}, {"label": "Straka et al., 2019)", "normalizedForm": "Straka et al., 2019)", "refKey": 37}, {"label": "(Straka, 2018;", "normalizedForm": "(Straka, 2018", "refKey": 35}, {"label": "Straka et al., 2019)", "normalizedForm": "Straka et al., 2019)", "refKey": 37}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ELMo", "normalizedForm": "ELMo", "offsetStart": 12, "offsetEnd": 16}, "context": "each of our ELMo model at the 1, 3, 5 and 10 epoch marks so that we can properly probe for overfitting.", "mentionContextAttributes": {"used": {"value": false, "score": 0.012753963470458984}, "created": {"value": false, "score": 0.03320974111557007}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999902248382568}, "created": {"value": true, "score": 0.9998936653137207}, "shared": {"value": false, "score": 3.337860107421875e-06}}, "references": [{"label": "(Peters et al., 2018)", "normalizedForm": "Peters et al., 2018", "refKey": 29}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "UDPipe", "normalizedForm": "UDPipe", "offsetStart": 12, "offsetEnd": 18}, "version": {"rawForm": "2.0", "normalizedForm": "2.0", "offsetStart": 19, "offsetEnd": 22}, "context": "Scores from UDPipe 2.0 (from", "mentionContextAttributes": {"used": {"value": true, "score": 0.9950685501098633}, "created": {"value": false, "score": 4.482269287109375e-05}, "shared": {"value": false, "score": 7.152557373046875e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999147653579712}, "created": {"value": false, "score": 0.005289673805236816}, "shared": {"value": false, "score": 0.002932727336883545}}, "references": [{"label": "Kondratyuk and Straka, 2019)", "normalizedForm": "Kondratyuk and Straka, 2019)", "refKey": 17, "offsetStart": 30379, "offsetEnd": 30407}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "UDPipe", "normalizedForm": "UDPipe", "offsetStart": 12, "offsetEnd": 18}, "version": {"rawForm": "2.0", "normalizedForm": "2.0", "offsetStart": 19, "offsetEnd": 22}, "context": "Scores from UDPipe 2.0 (from", "mentionContextAttributes": {"used": {"value": true, "score": 0.9950685501098633}, "created": {"value": false, "score": 4.482269287109375e-05}, "shared": {"value": false, "score": 7.152557373046875e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999147653579712}, "created": {"value": false, "score": 0.005289673805236816}, "shared": {"value": false, "score": 0.002932727336883545}}, "references": [{"label": "(Straka, 2018;", "normalizedForm": "(Straka, 2018", "refKey": 35}, {"label": "Straka et al., 2019)", "normalizedForm": "Straka et al., 2019)", "refKey": 37}, {"label": "(Straka, 2018;", "normalizedForm": "(Straka, 2018", "refKey": 35}, {"label": "Straka et al., 2019)", "normalizedForm": "Straka et al., 2019)", "refKey": 37}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "UDPipe", "normalizedForm": "UDPipe", "offsetStart": 12, "offsetEnd": 18}, "version": {"rawForm": "2.0", "normalizedForm": "2.0"}, "context": "Scores from UDPipe 2.0 (fromKondratyuk and Straka, 2019), the previous state-of-the-art models UDPipe 2.0+mBERT(Straka et al., 2019) and UDify(Kondratyuk and Straka, 2019), and our ELMoenhanced UDPipe 2.0 models.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9885595440864563}, "created": {"value": false, "score": 7.987022399902344e-06}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999147653579712}, "created": {"value": false, "score": 0.005289673805236816}, "shared": {"value": false, "score": 0.002932727336883545}}, "references": [{"label": "(Straka, 2018;", "normalizedForm": "(Straka, 2018", "refKey": 35}, {"label": "Straka et al., 2019)", "normalizedForm": "Straka et al., 2019)", "refKey": 37}, {"label": "(Straka, 2018;", "normalizedForm": "(Straka, 2018", "refKey": 35}, {"label": "Straka et al., 2019)", "normalizedForm": "Straka et al., 2019)", "refKey": 37}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "UDPipe", "normalizedForm": "UDPipe", "offsetStart": 12, "offsetEnd": 18}, "version": {"rawForm": "2.0", "normalizedForm": "2.0"}, "context": "Scores from UDPipe 2.0 (fromKondratyuk and Straka, 2019), the previous state-of-the-art models UDPipe 2.0+mBERT(Straka et al., 2019) and UDify(Kondratyuk and Straka, 2019)", "mentionContextAttributes": {"used": {"value": true, "score": 0.963176965713501}, "created": {"value": false, "score": 2.5033950805664062e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999147653579712}, "created": {"value": false, "score": 0.005289673805236816}, "shared": {"value": false, "score": 0.002932727336883545}}, "references": [{"label": "(Straka, 2018;", "normalizedForm": "(Straka, 2018", "refKey": 35}, {"label": "Straka et al., 2019)", "normalizedForm": "Straka et al., 2019)", "refKey": 37}, {"label": "(Straka, 2018;", "normalizedForm": "(Straka, 2018", "refKey": 35}, {"label": "Straka et al., 2019)", "normalizedForm": "Straka et al., 2019)", "refKey": 37}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "UDPipe", "normalizedForm": "UDPipe", "offsetStart": 12, "offsetEnd": 18}, "version": {"rawForm": "2.0", "normalizedForm": "2.0"}, "context": "Scores from UDPipe 2.0 (fromKondratyuk and Straka, 2019), the previous state-of-the-art models UDPipe 2.0+mBERT(Straka et al., 2019) and UDify", "mentionContextAttributes": {"used": {"value": true, "score": 0.9575042724609375}, "created": {"value": false, "score": 8.821487426757812e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999147653579712}, "created": {"value": false, "score": 0.005289673805236816}, "shared": {"value": false, "score": 0.002932727336883545}}, "references": [{"label": "(Straka, 2018;", "normalizedForm": "(Straka, 2018", "refKey": 35}, {"label": "Straka et al., 2019)", "normalizedForm": "Straka et al., 2019)", "refKey": 37}, {"label": "(Straka, 2018;", "normalizedForm": "(Straka, 2018", "refKey": 35}, {"label": "Straka et al., 2019)", "normalizedForm": "Straka et al., 2019)", "refKey": 37}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "UDPipe", "normalizedForm": "UDPipe", "offsetStart": 12, "offsetEnd": 18}, "version": {"rawForm": "2.0", "normalizedForm": "2.0"}, "context": "Scores from UDPipe 2.0 (fromKondratyuk and Straka, 2019), the previous state-of-the-art models UDPipe 2.0+mBERT(Straka et al., 2019)", "mentionContextAttributes": {"used": {"value": true, "score": 0.9947285056114197}, "created": {"value": false, "score": 1.5974044799804688e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999147653579712}, "created": {"value": false, "score": 0.005289673805236816}, "shared": {"value": false, "score": 0.002932727336883545}}, "references": [{"label": "(Straka, 2018;", "normalizedForm": "(Straka, 2018", "refKey": 35}, {"label": "Straka et al., 2019)", "normalizedForm": "Straka et al., 2019)", "refKey": 37}, {"label": "(Straka, 2018;", "normalizedForm": "(Straka, 2018", "refKey": 35}, {"label": "Straka et al., 2019)", "normalizedForm": "Straka et al., 2019)", "refKey": 37}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "UDPipe", "normalizedForm": "UDPipe", "offsetStart": 12, "offsetEnd": 18}, "version": {"rawForm": "2.0", "normalizedForm": "2.0"}, "context": "Scores from UDPipe 2.0 (fromKondratyuk and Straka, 2019), the previous state-of-the-art models UDPipe 2.0+mBERT", "mentionContextAttributes": {"used": {"value": true, "score": 0.9918982982635498}, "created": {"value": false, "score": 3.0040740966796875e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999147653579712}, "created": {"value": false, "score": 0.005289673805236816}, "shared": {"value": false, "score": 0.002932727336883545}}, "references": [{"label": "(Straka, 2018;", "normalizedForm": "(Straka, 2018", "refKey": 35}, {"label": "Straka et al., 2019)", "normalizedForm": "Straka et al., 2019)", "refKey": 37}, {"label": "(Straka, 2018;", "normalizedForm": "(Straka, 2018", "refKey": 35}, {"label": "Straka et al., 2019)", "normalizedForm": "Straka et al., 2019)", "refKey": 37}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "UDPipe", "normalizedForm": "UDPipe", "offsetStart": 12, "offsetEnd": 18}, "version": {"rawForm": "2.0", "normalizedForm": "2.0"}, "context": "Scores from UDPipe 2.0 (fromKondratyuk and Straka, 2019)", "mentionContextAttributes": {"used": {"value": true, "score": 0.9741300344467163}, "created": {"value": false, "score": 2.09808349609375e-05}, "shared": {"value": false, "score": 1.6689300537109375e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999147653579712}, "created": {"value": false, "score": 0.005289673805236816}, "shared": {"value": false, "score": 0.002932727336883545}}, "references": [{"label": "(Straka, 2018;", "normalizedForm": "(Straka, 2018", "refKey": 35}, {"label": "Straka et al., 2019)", "normalizedForm": "Straka et al., 2019)", "refKey": 37}, {"label": "(Straka, 2018;", "normalizedForm": "(Straka, 2018", "refKey": 35}, {"label": "Straka et al., 2019)", "normalizedForm": "Straka et al., 2019)", "refKey": 37}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "UDPipe", "normalizedForm": "UDPipe", "offsetStart": 12, "offsetEnd": 18}, "version": {"rawForm": "2.0", "normalizedForm": "2.0"}, "context": "Scores from UDPipe 2.0 (from", "mentionContextAttributes": {"used": {"value": true, "score": 0.9950685501098633}, "created": {"value": false, "score": 4.482269287109375e-05}, "shared": {"value": false, "score": 7.152557373046875e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999147653579712}, "created": {"value": false, "score": 0.005289673805236816}, "shared": {"value": false, "score": 0.002932727336883545}}, "references": [{"label": "(Straka, 2018;", "normalizedForm": "(Straka, 2018", "refKey": 35}, {"label": "Straka et al., 2019)", "normalizedForm": "Straka et al., 2019)", "refKey": 37}, {"label": "(Straka, 2018;", "normalizedForm": "(Straka, 2018", "refKey": 35}, {"label": "Straka et al., 2019)", "normalizedForm": "Straka et al., 2019)", "refKey": 37}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "UDPipe", "normalizedForm": "UDPipe", "offsetStart": 13, "offsetEnd": 19}, "version": {"rawForm": "2.0", "normalizedForm": "2.0", "offsetStart": 20, "offsetEnd": 23}, "context": "The original UDPipe 2.0 implementation calculates 3 different embeddings, namely:", "mentionContextAttributes": {"used": {"value": false, "score": 0.0005523562431335449}, "created": {"value": false, "score": 3.0159950256347656e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999147653579712}, "created": {"value": false, "score": 0.005289673805236816}, "shared": {"value": false, "score": 0.002932727336883545}}, "references": [{"label": "(Straka, 2018;", "normalizedForm": "(Straka, 2018", "refKey": 35}, {"label": "Straka et al., 2019)", "normalizedForm": "Straka et al., 2019)", "refKey": 37}, {"label": "(Straka, 2018;", "normalizedForm": "(Straka, 2018", "refKey": 35}, {"label": "Straka et al., 2019)", "normalizedForm": "Straka et al., 2019)", "refKey": 37}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ELMo", "normalizedForm": "ELMo", "offsetStart": 17, "offsetEnd": 21}, "context": "However training ELMo is computationally costly, and one way to estimate this cost, as pointed out by Strubell et al. (2019), is by using the training times of each model to compute both power consumption and CO 2 emissions.", "mentionContextAttributes": {"used": {"value": false, "score": 0.000339508056640625}, "created": {"value": false, "score": 9.703636169433594e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999902248382568}, "created": {"value": true, "score": 0.9998936653137207}, "shared": {"value": false, "score": 3.337860107421875e-06}}, "references": [{"label": "(Peters et al., 2018)", "normalizedForm": "Peters et al., 2018", "refKey": 29}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "UDPipe", "normalizedForm": "UDPipe", "offsetStart": 20, "offsetEnd": 26}, "version": {"rawForm": "2.0", "normalizedForm": "2.0"}, "context": "We also compare our UDPipe 2.0 + ELMo models against the state-of-the-art results (assuming gold tokenization) for these languages, which are either UDify (Kondratyuk and Straka, 2019) or UDPipe 2.0 + mBERT (Straka et al., 2019).", "mentionContextAttributes": {"used": {"value": true, "score": 0.9877712726593018}, "created": {"value": false, "score": 3.6954879760742188e-06}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999147653579712}, "created": {"value": false, "score": 0.005289673805236816}, "shared": {"value": false, "score": 0.002932727336883545}}, "references": [{"label": "(Straka, 2018;", "normalizedForm": "(Straka, 2018", "refKey": 35}, {"label": "Straka et al., 2019)", "normalizedForm": "Straka et al., 2019)", "refKey": 37}, {"label": "(Straka, 2018;", "normalizedForm": "(Straka, 2018", "refKey": 35}, {"label": "Straka et al., 2019)", "normalizedForm": "Straka et al., 2019)", "refKey": 37}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ELMo", "normalizedForm": "ELMo", "offsetStart": 24, "offsetEnd": 28}, "context": "However we believe that ELMo contextualized word embeddings remain a useful model that still provide an extremely good trade-off between performance to training cost, even setting new state-of-the-art scores in parsing and POS tagging for our five chosen languages, performing even better than the multilingual mBERT model.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00040012598037719727}, "created": {"value": false, "score": 0.0046517252922058105}, "shared": {"value": false, "score": 7.152557373046875e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999902248382568}, "created": {"value": true, "score": 0.9998936653137207}, "shared": {"value": false, "score": 3.337860107421875e-06}}, "references": [{"label": "(Peters et al., 2018)", "normalizedForm": "Peters et al., 2018", "refKey": 29}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "UDPipe", "normalizedForm": "UDPipe", "offsetStart": 24, "offsetEnd": 30}, "version": {"rawForm": "2", "normalizedForm": "2", "offsetStart": 31, "offsetEnd": 32}, "context": "In fact, the results of UDPipe 2.0 + ELMo Wikipedia give better than previous state-of-the-art results in all metrics for the Finnish-FTB and in UPOS for the Finnish-TDT. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9995976090431213}, "created": {"value": false, "score": 1.1563301086425781e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999147653579712}, "created": {"value": false, "score": 0.005289673805236816}, "shared": {"value": false, "score": 0.002932727336883545}}, "references": [{"label": "(Straka, 2018;", "normalizedForm": "(Straka, 2018", "refKey": 35}, {"label": "Straka et al., 2019)", "normalizedForm": "Straka et al., 2019)", "refKey": 37}, {"label": "(Straka, 2018;", "normalizedForm": "(Straka, 2018", "refKey": 35}, {"label": "Straka et al., 2019)", "normalizedForm": "Straka et al., 2019)", "refKey": 37}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ELMo", "normalizedForm": "ELMo", "offsetStart": 28, "offsetEnd": 32}, "context": "We take each of the trained ELMo models and use them in conjunction with the UDPipe 2.0 (Straka, 2018;Straka et al., 2019) architecture for dependency parsing and POS-tagging to test our models.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9679586887359619}, "created": {"value": false, "score": 0.0003072023391723633}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999902248382568}, "created": {"value": true, "score": 0.9998936653137207}, "shared": {"value": false, "score": 3.337860107421875e-06}}, "references": [{"label": "(Peters et al., 2018)", "normalizedForm": "Peters et al., 2018", "refKey": 29}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ELMo", "normalizedForm": "ELMo", "offsetStart": 31, "offsetEnd": 35}, "context": "Four monolingual fully trained ELMo models have been distributed for Japanese, Portuguese, German and Basque5 ; 44 monolingual ELMo models6 where also released by the HIT-SCIR team (Che et al., 2018) during the CoNLL 2018 Shared Task (Zeman et al., 2018), but their training sets where capped at 20 million words.", "mentionContextAttributes": {"used": {"value": true, "score": 0.7782601118087769}, "created": {"value": false, "score": 2.682209014892578e-05}, "shared": {"value": false, "score": 1.0728836059570312e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999902248382568}, "created": {"value": true, "score": 0.9998936653137207}, "shared": {"value": false, "score": 3.337860107421875e-06}}, "references": [{"label": "(Peters et al., 2018)", "normalizedForm": "Peters et al., 2018", "refKey": 29}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "UDPipe", "normalizedForm": "UDPipe", "offsetStart": 31, "offsetEnd": 37}, "version": {"rawForm": "2.0", "normalizedForm": "2.0"}, "context": "Here again we do not train the UDPipe 2.0 baselines without embedding, we just report the scores published in Kondratyuk and Straka (2019).", "mentionContextAttributes": {"used": {"value": true, "score": 0.9899499416351318}, "created": {"value": false, "score": 0.00023287534713745117}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999147653579712}, "created": {"value": false, "score": 0.005289673805236816}, "shared": {"value": false, "score": 0.002932727336883545}}, "references": [{"label": "(Straka, 2018;", "normalizedForm": "(Straka, 2018", "refKey": 35}, {"label": "Straka et al., 2019)", "normalizedForm": "Straka et al., 2019)", "refKey": 37}, {"label": "(Straka, 2018;", "normalizedForm": "(Straka, 2018", "refKey": 35}, {"label": "Straka et al., 2019)", "normalizedForm": "Straka et al., 2019)", "refKey": 37}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ELMo", "normalizedForm": "ELMo", "offsetStart": 32, "offsetEnd": 36}, "context": "This is the case for all of our ELMo Wikipedia models as we never see any evidence of a negative impact when we add them to the baseline model.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0014366507530212402}, "created": {"value": false, "score": 0.00024121999740600586}, "shared": {"value": false, "score": 7.152557373046875e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999902248382568}, "created": {"value": true, "score": 0.9998936653137207}, "shared": {"value": false, "score": 3.337860107421875e-06}}, "references": [{"label": "(Peters et al., 2018)", "normalizedForm": "Peters et al., 2018", "refKey": 29}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ELMo", "normalizedForm": "ELMo", "offsetStart": 33, "offsetEnd": 37}, "context": "Embeddings from Language Models (ELMo) (Peters et al., 2018) is an LSTM-based language model.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0002041459083557129}, "created": {"value": false, "score": 0.003460407257080078}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999902248382568}, "created": {"value": true, "score": 0.9998936653137207}, "shared": {"value": false, "score": 3.337860107421875e-06}}, "references": [{"label": "(Peters et al., 2018", "normalizedForm": "(Peters et al., 2018", "refKey": 29, "offsetStart": 14884, "offsetEnd": 14904}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ELMo", "normalizedForm": "ELMo", "offsetStart": 33, "offsetEnd": 37}, "context": "We also compare our UDPipe 2.0 + ELMo models against the state-of-the-art results (assuming gold tokenization) for these languages, which are either UDify (Kondratyuk and Straka, 2019) or UDPipe 2.0 + mBERT (Straka et al., 2019).", "mentionContextAttributes": {"used": {"value": true, "score": 0.9877712726593018}, "created": {"value": false, "score": 3.6954879760742188e-06}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999902248382568}, "created": {"value": true, "score": 0.9998936653137207}, "shared": {"value": false, "score": 3.337860107421875e-06}}, "references": [{"label": "(Peters et al., 2018)", "normalizedForm": "Peters et al., 2018", "refKey": 29}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ELMo", "normalizedForm": "ELMo", "offsetStart": 37, "offsetEnd": 41}, "context": "In fact, the results of UDPipe 2.0 + ELMo Wikipedia give better than previous state-of-the-art results in all metrics for the Finnish-FTB and in UPOS for the Finnish-TDT.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9995976090431213}, "created": {"value": false, "score": 1.1563301086425781e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999902248382568}, "created": {"value": true, "score": 0.9998936653137207}, "shared": {"value": false, "score": 3.337860107421875e-06}}, "references": [{"label": "(Peters et al., 2018)", "normalizedForm": "Peters et al., 2018", "refKey": 29}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ELMo", "normalizedForm": "ELMo", "offsetStart": 40, "offsetEnd": 44}, "context": "CO 2 e = 0.051p t All emissions for the ELMo models are also reported in table 7.", "mentionContextAttributes": {"used": {"value": true, "score": 0.989655613899231}, "created": {"value": false, "score": 4.887580871582031e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999902248382568}, "created": {"value": true, "score": 0.9998936653137207}, "shared": {"value": false, "score": 3.337860107421875e-06}}, "references": [{"label": "(Peters et al., 2018)", "normalizedForm": "Peters et al., 2018", "refKey": 29}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "UDPipe", "normalizedForm": "UDPipe", "offsetStart": 42, "offsetEnd": 48}, "version": {"rawForm": "2.0", "normalizedForm": "2.0"}, "context": "We also see that in every single case the UDPipe 2.0 + ELMo OSCAR result surpasses the UDPipe 2.0 + ELMo Wikipedia one, suggesting that the size of the pre-training data plays an important role in downstream task results.", "mentionContextAttributes": {"used": {"value": true, "score": 0.762699544429779}, "created": {"value": false, "score": 9.691715240478516e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999147653579712}, "created": {"value": false, "score": 0.005289673805236816}, "shared": {"value": false, "score": 0.002932727336883545}}, "references": [{"label": "(Straka, 2018;", "normalizedForm": "(Straka, 2018", "refKey": 35}, {"label": "Straka et al., 2019)", "normalizedForm": "Straka et al., 2019)", "refKey": 37}, {"label": "(Straka, 2018;", "normalizedForm": "(Straka, 2018", "refKey": 35}, {"label": "Straka et al., 2019)", "normalizedForm": "Straka et al., 2019)", "refKey": 37}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ELMo", "normalizedForm": "ELMo", "offsetStart": 43, "offsetEnd": 47}, "context": "We have compared them with Wikipedia-based ELMo embeddings on two classical NLP tasks, POS tagging and parsing, using state-of-the-art neural architectures.", "mentionContextAttributes": {"used": {"value": false, "score": 0.15561515092849731}, "created": {"value": false, "score": 0.0017876625061035156}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999902248382568}, "created": {"value": true, "score": 0.9998936653137207}, "shared": {"value": false, "score": 3.337860107421875e-06}}, "references": [{"label": "(Peters et al., 2018)", "normalizedForm": "Peters et al., 2018", "refKey": 29}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "UDPipe", "normalizedForm": "UDPipe", "offsetStart": 43, "offsetEnd": 49}, "version": {"rawForm": "0", "normalizedForm": "0", "offsetStart": 52, "offsetEnd": 53}, "context": "In contrast, our monolingual approach with UDPipe 2.0 + ELMo OSCAR improves the previous SOTA considerably, by more than 2 points for some metrics. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.00019890069961547852}, "created": {"value": false, "score": 0.00026994943618774414}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999147653579712}, "created": {"value": false, "score": 0.005289673805236816}, "shared": {"value": false, "score": 0.002932727336883545}}, "references": [{"label": "(Straka, 2018;", "normalizedForm": "(Straka, 2018", "refKey": 35}, {"label": "Straka et al., 2019)", "normalizedForm": "Straka et al., 2019)", "refKey": 37}, {"label": "(Straka, 2018;", "normalizedForm": "(Straka, 2018", "refKey": 35}, {"label": "Straka et al., 2019)", "normalizedForm": "Straka et al., 2019)", "refKey": 37}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "UDPipe", "normalizedForm": "UDPipe", "offsetStart": 44, "offsetEnd": 50}, "version": {"rawForm": "2.0", "normalizedForm": "2.0"}, "context": "In fact, we can see in Table 6 that all the UDPipe 2.0 + ELMo OSCAR(1) perform better than the UDPipe 2.0 + ELMo Wikipedia(1) models across all metrics.", "mentionContextAttributes": {"used": {"value": true, "score": 0.5668095946311951}, "created": {"value": false, "score": 9.059906005859375e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999147653579712}, "created": {"value": false, "score": 0.005289673805236816}, "shared": {"value": false, "score": 0.002932727336883545}}, "references": [{"label": "(Straka, 2018;", "normalizedForm": "(Straka, 2018", "refKey": 35}, {"label": "Straka et al., 2019)", "normalizedForm": "Straka et al., 2019)", "refKey": 37}, {"label": "(Straka, 2018;", "normalizedForm": "(Straka, 2018", "refKey": 35}, {"label": "Straka et al., 2019)", "normalizedForm": "Straka et al., 2019)", "refKey": 37}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ELMo", "normalizedForm": "ELMo", "offsetStart": 45, "offsetEnd": 49}, "context": "We then train OSCARbased and Wikipedia-based ELMo contextualized word embeddings (Peters et al., 2018) for 5 languages: Bulgarian, Catalan, Danish, Finnish and Indonesian. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.22507327795028687}, "created": {"value": true, "score": 0.9989014863967896}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999902248382568}, "created": {"value": true, "score": 0.9998936653137207}, "shared": {"value": false, "score": 3.337860107421875e-06}}, "references": [{"label": "(Peters et al., 2018)", "normalizedForm": "Peters et al., 2018", "refKey": 29}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ELMo", "normalizedForm": "ELMo", "offsetStart": 46, "offsetEnd": 50}, "context": "We show that the models using the OSCAR-based ELMo embeddings consistently outperform the Wikipediabased ones, suggesting that big high-coverage noisy corpora might be better than small high-quality narrow-coverage corpora for training contextualized language representations 4 .", "mentionContextAttributes": {"used": {"value": false, "score": 0.1274750828742981}, "created": {"value": false, "score": 0.00010538101196289062}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999902248382568}, "created": {"value": true, "score": 0.9998936653137207}, "shared": {"value": false, "score": 3.337860107421875e-06}}, "references": [{"label": "(Peters et al., 2018)", "normalizedForm": "Peters et al., 2018", "refKey": 29}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "UDPipe", "normalizedForm": "UDPipe", "offsetStart": 51, "offsetEnd": 57}, "version": {"rawForm": "2.0", "normalizedForm": "2.0"}, "context": "We evaluate the models by attaching them to the to UDPipe 2.0 architecture (Straka, 2018;Straka et al., 2019) for dependency parsing and part-of-speech (POS) tagging.", "mentionContextAttributes": {"used": {"value": true, "score": 0.8890167474746704}, "created": {"value": false, "score": 2.181529998779297e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999147653579712}, "created": {"value": false, "score": 0.005289673805236816}, "shared": {"value": false, "score": 0.002932727336883545}}, "references": [{"label": "(Straka, 2018;", "normalizedForm": "(Straka, 2018", "refKey": 35}, {"label": "Straka et al., 2019)", "normalizedForm": "Straka et al., 2019)", "refKey": 37}, {"label": "(Straka, 2018;", "normalizedForm": "(Straka, 2018", "refKey": 35}, {"label": "Straka et al., 2019)", "normalizedForm": "Straka et al., 2019)", "refKey": 37}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ELMo", "normalizedForm": "ELMo", "offsetStart": 54, "offsetEnd": 58}, "context": "16 This is why we intentionally fully pre-trained the ELMo Wikipedia to the 10 epochs of the original ELMo paper, as its authors also expressed concern over the possibility of overfitting for smaller corpora.", "mentionContextAttributes": {"used": {"value": true, "score": 0.969847559928894}, "created": {"value": false, "score": 0.1553792953491211}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999902248382568}, "created": {"value": true, "score": 0.9998936653137207}, "shared": {"value": false, "score": 3.337860107421875e-06}}, "references": [{"label": "(Peters et al., 2018)", "normalizedForm": "Peters et al., 2018", "refKey": 29}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ELMo", "normalizedForm": "ELMo", "offsetStart": 55, "offsetEnd": 59}, "context": "We also see that in every single case the UDPipe 2.0 + ELMo OSCAR result surpasses the UDPipe 2.0 + ELMo Wikipedia one, suggesting that the size of the pre-training data plays an important role in downstream task results.", "mentionContextAttributes": {"used": {"value": true, "score": 0.762699544429779}, "created": {"value": false, "score": 9.691715240478516e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999902248382568}, "created": {"value": true, "score": 0.9998936653137207}, "shared": {"value": false, "score": 3.337860107421875e-06}}, "references": [{"label": "(Peters et al., 2018)", "normalizedForm": "Peters et al., 2018", "refKey": 29}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ELMo", "normalizedForm": "ELMo", "offsetStart": 55, "offsetEnd": 59}, "context": "ELMo OSCAR models exhibit exactly the same behavior as ELMo Wikipedia models where the scores continue to improve the longer they are pre-trained, except for the case of Finnish.", "mentionContextAttributes": {"used": {"value": false, "score": 0.000523984432220459}, "created": {"value": false, "score": 4.649162292480469e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999902248382568}, "created": {"value": true, "score": 0.9998936653137207}, "shared": {"value": false, "score": 3.337860107421875e-06}}, "references": [{"label": "(Peters et al., 2018)", "normalizedForm": "Peters et al., 2018", "refKey": 29}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ELMo", "normalizedForm": "ELMo", "offsetStart": 56, "offsetEnd": 60}, "context": "In contrast, our monolingual approach with UDPipe 2.0 + ELMo OSCAR improves the previous SOTA considerably, by more than 2 points for some metrics.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00019890069961547852}, "created": {"value": false, "score": 0.00026994943618774414}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999902248382568}, "created": {"value": true, "score": 0.9998936653137207}, "shared": {"value": false, "score": 3.337860107421875e-06}}, "references": [{"label": "(Peters et al., 2018)", "normalizedForm": "Peters et al., 2018", "refKey": 29}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ELMo", "normalizedForm": "ELMo", "offsetStart": 57, "offsetEnd": 61}, "context": "In fact, we can see in Table 6 that all the UDPipe 2.0 + ELMo OSCAR(1) perform better than the UDPipe 2.0 + ELMo Wikipedia(1) models across all metrics.", "mentionContextAttributes": {"used": {"value": true, "score": 0.5668095946311951}, "created": {"value": false, "score": 9.059906005859375e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999902248382568}, "created": {"value": true, "score": 0.9998936653137207}, "shared": {"value": false, "score": 3.337860107421875e-06}}, "references": [{"label": "(Peters et al., 2018)", "normalizedForm": "Peters et al., 2018", "refKey": 29}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "mBERT", "normalizedForm": "mBERT", "offsetStart": 59, "offsetEnd": 64}, "context": "The results for Finnish are actually quite interesting, as mBERT was pre-trained on Wikipedia and here we see that the multilingual setting in which UDify was fine-tuned exhibits subbaseline results for all metrics, and that the UD-Pipe + mBERT scores are often lower than those of our UDPipe 2.0 + ELMo Wikipedia .", "mentionContextAttributes": {"used": {"value": true, "score": 0.9460902810096741}, "created": {"value": false, "score": 5.7220458984375e-06}, "shared": {"value": false, "score": 7.152557373046875e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9995203018188477}, "created": {"value": false, "score": 0.0046517252922058105}, "shared": {"value": false, "score": 1.1920928955078125e-06}}, "references": [{"label": "(Devlin et al., 2018)", "normalizedForm": "Devlin et al., 2018", "refKey": 0}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ELMo", "normalizedForm": "ELMo", "offsetStart": 60, "offsetEnd": 64}, "context": "Taking a closer look at the results for Danish, we see that ELMo Wikipedia , which was trained with a mere 300MB corpus, does not show any sign  of overfitting, as the UDPipe 2.0 + ELMo Wikipedia results considerably improve the UDPipe 2.0 baseline.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9063400030136108}, "created": {"value": false, "score": 1.2993812561035156e-05}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999902248382568}, "created": {"value": true, "score": 0.9998936653137207}, "shared": {"value": false, "score": 3.337860107421875e-06}}, "references": [{"label": "(Peters et al., 2018)", "normalizedForm": "Peters et al., 2018", "refKey": 29}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ELMo", "normalizedForm": "ELMo", "offsetStart": 62, "offsetEnd": 66}, "context": "html formation to compute the total power consumption of each ELMo, also reported in table 7.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999902248382568}, "created": {"value": false, "score": 5.602836608886719e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999902248382568}, "created": {"value": true, "score": 0.9998936653137207}, "shared": {"value": false, "score": 3.337860107421875e-06}}, "references": [{"label": "(Peters et al., 2018)", "normalizedForm": "Peters et al., 2018", "refKey": 29}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "UDPipe", "normalizedForm": "UDPipe", "offsetStart": 62, "offsetEnd": 68}, "version": {"rawForm": "2.0", "normalizedForm": "2.0", "offsetStart": 69, "offsetEnd": 72}, "context": "For our POS tagging and dependency parsing evaluation, we use UDPipe 2.0, which has a freely available and ready to use implementation. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9856148958206177}, "created": {"value": false, "score": 0.005289673805236816}, "shared": {"value": false, "score": 0.002932727336883545}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999147653579712}, "created": {"value": false, "score": 0.005289673805236816}, "shared": {"value": false, "score": 0.002932727336883545}}, "references": [{"label": "(Straka, 2018;", "normalizedForm": "(Straka, 2018", "refKey": 35}, {"label": "Straka et al., 2019)", "normalizedForm": "Straka et al., 2019)", "refKey": 37}, {"label": "(Straka, 2018;", "normalizedForm": "(Straka, 2018", "refKey": 35}, {"label": "Straka et al., 2019)", "normalizedForm": "Straka et al., 2019)", "refKey": 37}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ELMo", "normalizedForm": "ELMo", "offsetStart": 66, "offsetEnd": 70}, "context": "We then compare the performance of OSCARbased and Wikipedia-based ELMo embeddings for these languages on the part-ofspeech tagging and parsing tasks.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9934147596359253}, "created": {"value": false, "score": 2.1457672119140625e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999902248382568}, "created": {"value": true, "score": 0.9998936653137207}, "shared": {"value": false, "score": 3.337860107421875e-06}}, "references": [{"label": "(Peters et al., 2018)", "normalizedForm": "Peters et al., 2018", "refKey": 29}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "mBERT", "normalizedForm": "mBERT", "offsetStart": 69, "offsetEnd": 74}, "context": "This actually suggests that even though the multilingual approach of mBERT (in pre-training) or UDify (in pre-training and fine-tuning) leads to better performance for high-resource languages or languages that are closely related to high-resource languages, it might also significantly degrade the representations for more isolated or even simply more morphologically rich languages like Finnish.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0006914138793945312}, "created": {"value": false, "score": 0.0001201629638671875}, "shared": {"value": false, "score": 1.1920928955078125e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9995203018188477}, "created": {"value": false, "score": 0.0046517252922058105}, "shared": {"value": false, "score": 1.1920928955078125e-06}}, "references": [{"label": "(Devlin et al., 2018)", "normalizedForm": "Devlin et al., 2018", "refKey": 0}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ELMo", "normalizedForm": "ELMo", "offsetStart": 72, "offsetEnd": 76}, "context": "We train each model for 10 epochs, as was done for the original English ELMo (Peters et al., 2018).", "mentionContextAttributes": {"used": {"value": false, "score": 0.024875938892364502}, "created": {"value": false, "score": 0.1481373906135559}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999902248382568}, "created": {"value": true, "score": 0.9998936653137207}, "shared": {"value": false, "score": 3.337860107421875e-06}}, "references": [{"label": "(Peters et al., 2018)", "normalizedForm": "Peters et al., 2018", "refKey": 29, "offsetStart": 15383, "offsetEnd": 15404}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ELMo", "normalizedForm": "ELMo", "offsetStart": 77, "offsetEnd": 81}, "context": "We train UDPipe 2.0 using gold tokenization and segmentation for each of our ELMo models, the only thing that changes from training to training is the ELMo model as hyperparameters always remain at the default values (except for number of training tokens) (Peters et al., 2018).", "mentionContextAttributes": {"used": {"value": false, "score": 0.09617096185684204}, "created": {"value": false, "score": 0.0001304149627685547}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999902248382568}, "created": {"value": true, "score": 0.9998936653137207}, "shared": {"value": false, "score": 3.337860107421875e-06}}, "references": [{"label": "(Peters et al., 2018)", "normalizedForm": "Peters et al., 2018", "refKey": 29}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "UDPipe", "normalizedForm": "UDPipe", "offsetStart": 77, "offsetEnd": 83}, "version": {"rawForm": "2.0", "normalizedForm": "2.0"}, "context": "We take each of the trained ELMo models and use them in conjunction with the UDPipe 2.0 (Straka, 2018;Straka et al., 2019) architecture for dependency parsing and POS-tagging to test our models. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9679586887359619}, "created": {"value": false, "score": 0.0003072023391723633}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999147653579712}, "created": {"value": false, "score": 0.005289673805236816}, "shared": {"value": false, "score": 0.002932727336883545}}, "references": [{"label": "(Straka, 2018;", "normalizedForm": "(Straka, 2018", "refKey": 35, "offsetStart": 14460, "offsetEnd": 14474}, {"label": "Straka et al., 2019)", "normalizedForm": "Straka et al., 2019)", "refKey": 37, "offsetStart": 14474, "offsetEnd": 14494}, {"label": "(Straka, 2018;", "normalizedForm": "(Straka, 2018", "refKey": 35, "offsetStart": 14460, "offsetEnd": 14474}, {"label": "Straka et al., 2019)", "normalizedForm": "Straka et al., 2019)", "refKey": 37, "offsetStart": 14474, "offsetEnd": 14494}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "UDPipe", "normalizedForm": "UDPipe", "offsetStart": 79, "offsetEnd": 85}, "version": {"rawForm": "2.0", "normalizedForm": "2.0"}, "context": "We do not report the power consumption or the carbon footprint of training the UDPipe 2.0 architecture, as each model took less than 4 hours to train on a machine using a single NVIDIA Tesla V100 card.", "mentionContextAttributes": {"used": {"value": true, "score": 0.996093213558197}, "created": {"value": false, "score": 0.00017815828323364258}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999147653579712}, "created": {"value": false, "score": 0.005289673805236816}, "shared": {"value": false, "score": 0.002932727336883545}}, "references": [{"label": "(Straka, 2018;", "normalizedForm": "(Straka, 2018", "refKey": 35}, {"label": "Straka et al., 2019)", "normalizedForm": "Straka et al., 2019)", "refKey": 37}, {"label": "(Straka, 2018;", "normalizedForm": "(Straka, 2018", "refKey": 35}, {"label": "Straka et al., 2019)", "normalizedForm": "Straka et al., 2019)", "refKey": 37}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ELMo", "normalizedForm": "ELMo", "offsetStart": 81, "offsetEnd": 85}, "context": "To this end, we train different versions of the Embeddings from Language Models (ELMo) (Peters et al., 2018) for both the Wikipedia and OSCAR corpora, for each of our selected 5 languages.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0010637640953063965}, "created": {"value": true, "score": 0.9981999397277832}, "shared": {"value": false, "score": 9.5367431640625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999902248382568}, "created": {"value": true, "score": 0.9998936653137207}, "shared": {"value": false, "score": 3.337860107421875e-06}}, "references": [{"label": "(Peters et al., 2018)", "normalizedForm": "Peters et al., 2018", "refKey": 29, "offsetStart": 14052, "offsetEnd": 14073}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "UDPipe", "normalizedForm": "UDPipe", "offsetStart": 87, "offsetEnd": 93}, "version": {"rawForm": "2.0", "normalizedForm": "2.0", "offsetStart": 94, "offsetEnd": 97}, "context": "We also see that in every single case the UDPipe 2.0 + ELMo OSCAR result surpasses the UDPipe 2.0 + ELMo Wikipedia one, suggesting that the size of the pre-training data plays an important role in downstream task results. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.762699544429779}, "created": {"value": false, "score": 9.691715240478516e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999147653579712}, "created": {"value": false, "score": 0.005289673805236816}, "shared": {"value": false, "score": 0.002932727336883545}}, "references": [{"label": "(Straka, 2018;", "normalizedForm": "(Straka, 2018", "refKey": 35}, {"label": "Straka et al., 2019)", "normalizedForm": "Straka et al., 2019)", "refKey": 37}, {"label": "(Straka, 2018;", "normalizedForm": "(Straka, 2018", "refKey": 35}, {"label": "Straka et al., 2019)", "normalizedForm": "Straka et al., 2019)", "refKey": 37}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "UDPipe", "normalizedForm": "UDPipe", "offsetStart": 87, "offsetEnd": 93}, "version": {"rawForm": "2.0", "normalizedForm": "2.0"}, "context": "We obtain the state of the art for the three metrics in each of the languages with the UDPipe 2.0 + ELMo OSCAR models.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999147653579712}, "created": {"value": false, "score": 4.9591064453125e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999147653579712}, "created": {"value": false, "score": 0.005289673805236816}, "shared": {"value": false, "score": 0.002932727336883545}}, "references": [{"label": "(Straka, 2018;", "normalizedForm": "(Straka, 2018", "refKey": 35}, {"label": "Straka et al., 2019)", "normalizedForm": "Straka et al., 2019)", "refKey": 37}, {"label": "(Straka, 2018;", "normalizedForm": "(Straka, 2018", "refKey": 35}, {"label": "Straka et al., 2019)", "normalizedForm": "Straka et al., 2019)", "refKey": 37}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ELMo", "normalizedForm": "ELMo", "offsetStart": 89, "offsetEnd": 93}, "context": "In this paper, we have explored the use of the Common-Crawl-based OSCAR corpora to train ELMo contextualized embeddings for five typologically diverse mid-resource languages.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00048422813415527344}, "created": {"value": true, "score": 0.9998936653137207}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999902248382568}, "created": {"value": true, "score": 0.9998936653137207}, "shared": {"value": false, "score": 3.337860107421875e-06}}, "references": [{"label": "(Peters et al., 2018)", "normalizedForm": "Peters et al., 2018", "refKey": 29}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "UDPipe", "normalizedForm": "UDPipe", "offsetStart": 95, "offsetEnd": 101}, "version": {"rawForm": "2.0", "normalizedForm": "2.0"}, "context": "In fact, we can see in Table 6 that all the UDPipe 2.0 + ELMo OSCAR(1) perform better than the UDPipe 2.0 + ELMo Wikipedia(1) models across all metrics.", "mentionContextAttributes": {"used": {"value": true, "score": 0.5668095946311951}, "created": {"value": false, "score": 9.059906005859375e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999147653579712}, "created": {"value": false, "score": 0.005289673805236816}, "shared": {"value": false, "score": 0.002932727336883545}}, "references": [{"label": "(Straka, 2018;", "normalizedForm": "(Straka, 2018", "refKey": 35}, {"label": "Straka et al., 2019)", "normalizedForm": "Straka et al., 2019)", "refKey": 37}, {"label": "(Straka, 2018;", "normalizedForm": "(Straka, 2018", "refKey": 35}, {"label": "Straka et al., 2019)", "normalizedForm": "Straka et al., 2019)", "refKey": 37}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "UDPipe", "normalizedForm": "UDPipe", "offsetStart": 95, "offsetEnd": 101}, "version": {"rawForm": "2.0", "normalizedForm": "2.0"}, "context": "Scores from UDPipe 2.0 (fromKondratyuk and Straka, 2019), the previous state-of-the-art models UDPipe 2.0+mBERT(Straka et al., 2019) and UDify(Kondratyuk and Straka, 2019), and our ELMoenhanced UDPipe 2.0 models.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9885595440864563}, "created": {"value": false, "score": 7.987022399902344e-06}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999147653579712}, "created": {"value": false, "score": 0.005289673805236816}, "shared": {"value": false, "score": 0.002932727336883545}}, "references": [{"label": "(Straka, 2018;", "normalizedForm": "(Straka, 2018", "refKey": 35}, {"label": "Straka et al., 2019)", "normalizedForm": "Straka et al., 2019)", "refKey": 37}, {"label": "(Straka, 2018;", "normalizedForm": "(Straka, 2018", "refKey": 35}, {"label": "Straka et al., 2019)", "normalizedForm": "Straka et al., 2019)", "refKey": 37}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "UDPipe", "normalizedForm": "UDPipe", "offsetStart": 95, "offsetEnd": 101}, "version": {"rawForm": "2.0", "normalizedForm": "2.0"}, "context": "Scores from UDPipe 2.0 (fromKondratyuk and Straka, 2019), the previous state-of-the-art models UDPipe 2.0+mBERT(Straka et al., 2019) and UDify(Kondratyuk and Straka, 2019)", "mentionContextAttributes": {"used": {"value": true, "score": 0.963176965713501}, "created": {"value": false, "score": 2.5033950805664062e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999147653579712}, "created": {"value": false, "score": 0.005289673805236816}, "shared": {"value": false, "score": 0.002932727336883545}}, "references": [{"label": "(Straka, 2018;", "normalizedForm": "(Straka, 2018", "refKey": 35}, {"label": "Straka et al., 2019)", "normalizedForm": "Straka et al., 2019)", "refKey": 37}, {"label": "(Straka, 2018;", "normalizedForm": "(Straka, 2018", "refKey": 35}, {"label": "Straka et al., 2019)", "normalizedForm": "Straka et al., 2019)", "refKey": 37}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "UDPipe", "normalizedForm": "UDPipe", "offsetStart": 95, "offsetEnd": 101}, "version": {"rawForm": "2.0", "normalizedForm": "2.0"}, "context": "Scores from UDPipe 2.0 (fromKondratyuk and Straka, 2019), the previous state-of-the-art models UDPipe 2.0+mBERT(Straka et al., 2019) and UDify", "mentionContextAttributes": {"used": {"value": true, "score": 0.9575042724609375}, "created": {"value": false, "score": 8.821487426757812e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999147653579712}, "created": {"value": false, "score": 0.005289673805236816}, "shared": {"value": false, "score": 0.002932727336883545}}, "references": [{"label": "(Straka, 2018;", "normalizedForm": "(Straka, 2018", "refKey": 35}, {"label": "Straka et al., 2019)", "normalizedForm": "Straka et al., 2019)", "refKey": 37}, {"label": "(Straka, 2018;", "normalizedForm": "(Straka, 2018", "refKey": 35}, {"label": "Straka et al., 2019)", "normalizedForm": "Straka et al., 2019)", "refKey": 37}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "UDPipe", "normalizedForm": "UDPipe", "offsetStart": 95, "offsetEnd": 101}, "version": {"rawForm": "2.0", "normalizedForm": "2.0"}, "context": "Scores from UDPipe 2.0 (fromKondratyuk and Straka, 2019), the previous state-of-the-art models UDPipe 2.0+mBERT(Straka et al., 2019)", "mentionContextAttributes": {"used": {"value": true, "score": 0.9947285056114197}, "created": {"value": false, "score": 1.5974044799804688e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999147653579712}, "created": {"value": false, "score": 0.005289673805236816}, "shared": {"value": false, "score": 0.002932727336883545}}, "references": [{"label": "(Straka, 2018;", "normalizedForm": "(Straka, 2018", "refKey": 35}, {"label": "Straka et al., 2019)", "normalizedForm": "Straka et al., 2019)", "refKey": 37}, {"label": "(Straka, 2018;", "normalizedForm": "(Straka, 2018", "refKey": 35}, {"label": "Straka et al., 2019)", "normalizedForm": "Straka et al., 2019)", "refKey": 37}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "UDPipe", "normalizedForm": "UDPipe", "offsetStart": 95, "offsetEnd": 101}, "version": {"rawForm": "2.0", "normalizedForm": "2.0"}, "context": "Scores from UDPipe 2.0 (fromKondratyuk and Straka, 2019), the previous state-of-the-art models UDPipe 2.0+mBERT", "mentionContextAttributes": {"used": {"value": true, "score": 0.9918982982635498}, "created": {"value": false, "score": 3.0040740966796875e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999147653579712}, "created": {"value": false, "score": 0.005289673805236816}, "shared": {"value": false, "score": 0.002932727336883545}}, "references": [{"label": "(Straka, 2018;", "normalizedForm": "(Straka, 2018", "refKey": 35}, {"label": "Straka et al., 2019)", "normalizedForm": "Straka et al., 2019)", "refKey": 37}, {"label": "(Straka, 2018;", "normalizedForm": "(Straka, 2018", "refKey": 35}, {"label": "Straka et al., 2019)", "normalizedForm": "Straka et al., 2019)", "refKey": 37}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "mBERT", "normalizedForm": "mBERT", "offsetStart": 96, "offsetEnd": 101}, "context": "Regarding contextualized models, the most notable non-English contribution has been that of the mBERT (Devlin et al., 2018), which is distributed as (i) a single multilingual model for 100 different languages trained on Wikipedia data, and as (ii) a single multilingual model for both Simplified and Traditional Chinese.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0004214644432067871}, "created": {"value": false, "score": 0.0003452301025390625}, "shared": {"value": false, "score": 7.152557373046875e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9995203018188477}, "created": {"value": false, "score": 0.0046517252922058105}, "shared": {"value": false, "score": 1.1920928955078125e-06}}, "references": [{"label": "(Devlin et al., 2018)", "normalizedForm": "Devlin et al., 2018", "refKey": 0, "offsetStart": 7131, "offsetEnd": 7152}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "UDify", "normalizedForm": "UDify", "offsetStart": 96, "offsetEnd": 101}, "context": "This actually suggests that even though the multilingual approach of mBERT (in pre-training) or UDify (in pre-training and fine-tuning) leads to better performance for high-resource languages or languages that are closely related to high-resource languages, it might also significantly degrade the representations for more isolated or even simply more morphologically rich languages like Finnish.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0006914138793945312}, "created": {"value": false, "score": 0.0001201629638671875}, "shared": {"value": false, "score": 1.1920928955078125e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9995203018188477}, "created": {"value": false, "score": 0.00030994415283203125}, "shared": {"value": false, "score": 1.1920928955078125e-06}}, "references": [{"label": "(Kondratyuk and Straka, 2019)", "normalizedForm": "Kondratyuk and Straka, 2019", "refKey": 17}, {"label": "(Kondratyuk and Straka, 2019)", "normalizedForm": "Kondratyuk and Straka, 2019", "refKey": 17}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ELMo", "normalizedForm": "ELMo", "offsetStart": 100, "offsetEnd": 104}, "context": "We obtain the state of the art for the three metrics in each of the languages with the UDPipe 2.0 + ELMo OSCAR models.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999147653579712}, "created": {"value": false, "score": 4.9591064453125e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999902248382568}, "created": {"value": true, "score": 0.9998936653137207}, "shared": {"value": false, "score": 3.337860107421875e-06}}, "references": [{"label": "(Peters et al., 2018)", "normalizedForm": "Peters et al., 2018", "refKey": 29}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ELMo", "normalizedForm": "ELMo", "offsetStart": 100, "offsetEnd": 104}, "context": "We also see that in every single case the UDPipe 2.0 + ELMo OSCAR result surpasses the UDPipe 2.0 + ELMo Wikipedia one, suggesting that the size of the pre-training data plays an important role in downstream task results.", "mentionContextAttributes": {"used": {"value": true, "score": 0.762699544429779}, "created": {"value": false, "score": 9.691715240478516e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999902248382568}, "created": {"value": true, "score": 0.9998936653137207}, "shared": {"value": false, "score": 3.337860107421875e-06}}, "references": [{"label": "(Peters et al., 2018)", "normalizedForm": "Peters et al., 2018", "refKey": 29}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "UDPipe", "normalizedForm": "UDPipe", "offsetStart": 100, "offsetEnd": 106}, "version": {"rawForm": "2.0", "normalizedForm": "2.0"}, "context": "As we did for Wikipedia, we tokenize OSCAR corpora for the 5 languages we chose for our study using UDPipe. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9972844123840332}, "created": {"value": false, "score": 0.00023406744003295898}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999147653579712}, "created": {"value": false, "score": 0.005289673805236816}, "shared": {"value": false, "score": 0.002932727336883545}}, "references": [{"label": "(Straka, 2018;", "normalizedForm": "(Straka, 2018", "refKey": 35}, {"label": "Straka et al., 2019)", "normalizedForm": "Straka et al., 2019)", "refKey": 37}, {"label": "(Straka, 2018;", "normalizedForm": "(Straka, 2018", "refKey": 35}, {"label": "Straka et al., 2019)", "normalizedForm": "Straka et al., 2019)", "refKey": 37}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ELMo", "normalizedForm": "ELMo", "offsetStart": 102, "offsetEnd": 106}, "context": "16 This is why we intentionally fully pre-trained the ELMo Wikipedia to the 10 epochs of the original ELMo paper, as its authors also expressed concern over the possibility of overfitting for smaller corpora.", "mentionContextAttributes": {"used": {"value": true, "score": 0.969847559928894}, "created": {"value": false, "score": 0.1553792953491211}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999902248382568}, "created": {"value": true, "score": 0.9998936653137207}, "shared": {"value": false, "score": 3.337860107421875e-06}}, "references": [{"label": "(Peters et al., 2018)", "normalizedForm": "Peters et al., 2018", "refKey": 29}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ELMo", "normalizedForm": "ELMo", "offsetStart": 103, "offsetEnd": 107}, "context": "As previously mentioned Finnish is morphologically richer than the other languages in which we trained ELMo, we hypothesize that the representation space given by the ELMo embeddings might not be sufficiently big to extract more features from the Finnish OSCAR corpus beyond the 5 th epoch mark, however in order to test this we would need to train a larger language model like BERT which is sadly beyond our computing infrastructure limits (cf.", "mentionContextAttributes": {"used": {"value": true, "score": 0.7353690266609192}, "created": {"value": false, "score": 0.00011408329010009766}, "shared": {"value": false, "score": 2.6226043701171875e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999902248382568}, "created": {"value": true, "score": 0.9998936653137207}, "shared": {"value": false, "score": 3.337860107421875e-06}}, "references": [{"label": "(Peters et al., 2018)", "normalizedForm": "Peters et al., 2018", "refKey": 29}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "mBERT", "normalizedForm": "mBERT", "offsetStart": 106, "offsetEnd": 111}, "context": "Scores from UDPipe 2.0 (fromKondratyuk and Straka, 2019), the previous state-of-the-art models UDPipe 2.0+mBERT(Straka et al., 2019) and UDify(Kondratyuk and Straka, 2019), and our ELMoenhanced UDPipe 2.0 models.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9885595440864563}, "created": {"value": false, "score": 7.987022399902344e-06}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9995203018188477}, "created": {"value": false, "score": 0.0046517252922058105}, "shared": {"value": false, "score": 1.1920928955078125e-06}}, "references": [{"label": "(Devlin et al., 2018)", "normalizedForm": "Devlin et al., 2018", "refKey": 0}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "mBERT", "normalizedForm": "mBERT", "offsetStart": 106, "offsetEnd": 111}, "context": "Scores from UDPipe 2.0 (fromKondratyuk and Straka, 2019), the previous state-of-the-art models UDPipe 2.0+mBERT(Straka et al., 2019) and UDify(Kondratyuk and Straka, 2019)", "mentionContextAttributes": {"used": {"value": true, "score": 0.963176965713501}, "created": {"value": false, "score": 2.5033950805664062e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9995203018188477}, "created": {"value": false, "score": 0.0046517252922058105}, "shared": {"value": false, "score": 1.1920928955078125e-06}}, "references": [{"label": "(Devlin et al., 2018)", "normalizedForm": "Devlin et al., 2018", "refKey": 0}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "mBERT", "normalizedForm": "mBERT", "offsetStart": 106, "offsetEnd": 111}, "context": "Scores from UDPipe 2.0 (fromKondratyuk and Straka, 2019), the previous state-of-the-art models UDPipe 2.0+mBERT(Straka et al., 2019) and UDify", "mentionContextAttributes": {"used": {"value": true, "score": 0.9575042724609375}, "created": {"value": false, "score": 8.821487426757812e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9995203018188477}, "created": {"value": false, "score": 0.0046517252922058105}, "shared": {"value": false, "score": 1.1920928955078125e-06}}, "references": [{"label": "(Devlin et al., 2018)", "normalizedForm": "Devlin et al., 2018", "refKey": 0}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "mBERT", "normalizedForm": "mBERT", "offsetStart": 106, "offsetEnd": 111}, "context": "Scores from UDPipe 2.0 (fromKondratyuk and Straka, 2019), the previous state-of-the-art models UDPipe 2.0+mBERT(Straka et al., 2019)", "mentionContextAttributes": {"used": {"value": true, "score": 0.9947285056114197}, "created": {"value": false, "score": 1.5974044799804688e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9995203018188477}, "created": {"value": false, "score": 0.0046517252922058105}, "shared": {"value": false, "score": 1.1920928955078125e-06}}, "references": [{"label": "(Devlin et al., 2018)", "normalizedForm": "Devlin et al., 2018", "refKey": 0}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "mBERT", "normalizedForm": "mBERT", "offsetStart": 106, "offsetEnd": 111}, "context": "Scores from UDPipe 2.0 (fromKondratyuk and Straka, 2019), the previous state-of-the-art models UDPipe 2.0+mBERT", "mentionContextAttributes": {"used": {"value": true, "score": 0.9918982982635498}, "created": {"value": false, "score": 3.0040740966796875e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9995203018188477}, "created": {"value": false, "score": 0.0046517252922058105}, "shared": {"value": false, "score": 1.1920928955078125e-06}}, "references": [{"label": "(Devlin et al., 2018)", "normalizedForm": "Devlin et al., 2018", "refKey": 0}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ELMo", "normalizedForm": "ELMo", "offsetStart": 108, "offsetEnd": 112}, "context": "In fact, we can see in Table 6 that all the UDPipe 2.0 + ELMo OSCAR(1) perform better than the UDPipe 2.0 + ELMo Wikipedia(1) models across all metrics.", "mentionContextAttributes": {"used": {"value": true, "score": 0.5668095946311951}, "created": {"value": false, "score": 9.059906005859375e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999902248382568}, "created": {"value": true, "score": 0.9998936653137207}, "shared": {"value": false, "score": 3.337860107421875e-06}}, "references": [{"label": "(Peters et al., 2018)", "normalizedForm": "Peters et al., 2018", "refKey": 29}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ELMo", "normalizedForm": "ELMo", "offsetStart": 111, "offsetEnd": 115}, "context": "Considering the discussion above, we believe an interesting follow-up to our experiments would be training the ELMo models for more of the languages included in the OSCAR corpus.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0005043745040893555}, "created": {"value": true, "score": 0.8043647408485413}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999902248382568}, "created": {"value": true, "score": 0.9998936653137207}, "shared": {"value": false, "score": 3.337860107421875e-06}}, "references": [{"label": "(Peters et al., 2018)", "normalizedForm": "Peters et al., 2018", "refKey": 29}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ELMo", "normalizedForm": "ELMo", "offsetStart": 127, "offsetEnd": 131}, "context": "Four monolingual fully trained ELMo models have been distributed for Japanese, Portuguese, German and Basque5 ; 44 monolingual ELMo models6 where also released by the HIT-SCIR team (Che et al., 2018) during the CoNLL 2018 Shared Task (Zeman et al., 2018), but their training sets where capped at 20 million words.", "mentionContextAttributes": {"used": {"value": true, "score": 0.7782601118087769}, "created": {"value": false, "score": 2.682209014892578e-05}, "shared": {"value": false, "score": 1.0728836059570312e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999902248382568}, "created": {"value": true, "score": 0.9998936653137207}, "shared": {"value": false, "score": 3.337860107421875e-06}}, "references": [{"label": "(Peters et al., 2018)", "normalizedForm": "Peters et al., 2018", "refKey": 29}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ELMo", "normalizedForm": "ELMo", "offsetStart": 131, "offsetEnd": 135}, "context": "The ELMo authors have expressed that increasing the number of training epochs is generally better, as they argue that training the ELMo model for longer reduces held-out perplexity and further improves downstream task performance.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0005105733871459961}, "created": {"value": false, "score": 0.00020200014114379883}, "shared": {"value": false, "score": 5.960464477539062e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999902248382568}, "created": {"value": true, "score": 0.9998936653137207}, "shared": {"value": false, "score": 3.337860107421875e-06}}, "references": [{"label": "(Peters et al., 2018)", "normalizedForm": "Peters et al., 2018", "refKey": 29}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ELMo", "normalizedForm": "ELMo", "offsetStart": 135, "offsetEnd": 139}, "context": "One last thing that it is important to note with respect to the number of training epochs is that even though we fully pre-trained our ELMo Wikipedia 's and ELMo OSCAR 's to the recommended 10 epoch mark, and then compared them against one another, the number of training steps between both pre-trained models differs drastically due to the big difference in corpus size (for Indonesian, for instance, 10 epochs correspond to 78K steps for ELMo Wikipedia and to 2.6M steps for OSCAR; the complete picture is provided in the Appendix, in Table 8).", "mentionContextAttributes": {"used": {"value": true, "score": 0.999956488609314}, "created": {"value": false, "score": 3.0994415283203125e-06}, "shared": {"value": false, "score": 7.152557373046875e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999902248382568}, "created": {"value": true, "score": 0.9998936653137207}, "shared": {"value": false, "score": 3.337860107421875e-06}}, "references": [{"label": "(Peters et al., 2018)", "normalizedForm": "Peters et al., 2018", "refKey": 29}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "UDify", "normalizedForm": "UDify", "offsetStart": 137, "offsetEnd": 142}, "context": "Scores from UDPipe 2.0 (fromKondratyuk and Straka, 2019), the previous state-of-the-art models UDPipe 2.0+mBERT(Straka et al., 2019) and UDify(Kondratyuk and Straka, 2019), and our ELMoenhanced UDPipe 2.0 models.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9885595440864563}, "created": {"value": false, "score": 7.987022399902344e-06}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9995203018188477}, "created": {"value": false, "score": 0.00030994415283203125}, "shared": {"value": false, "score": 1.1920928955078125e-06}}, "references": [{"label": "(Kondratyuk and Straka, 2019)", "normalizedForm": "Kondratyuk and Straka, 2019", "refKey": 17}, {"label": "(Kondratyuk and Straka, 2019)", "normalizedForm": "Kondratyuk and Straka, 2019", "refKey": 17}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "UDify", "normalizedForm": "UDify", "offsetStart": 137, "offsetEnd": 142}, "context": "Scores from UDPipe 2.0 (fromKondratyuk and Straka, 2019), the previous state-of-the-art models UDPipe 2.0+mBERT(Straka et al., 2019) and UDify(Kondratyuk and Straka, 2019)", "mentionContextAttributes": {"used": {"value": true, "score": 0.963176965713501}, "created": {"value": false, "score": 2.5033950805664062e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9995203018188477}, "created": {"value": false, "score": 0.00030994415283203125}, "shared": {"value": false, "score": 1.1920928955078125e-06}}, "references": [{"label": "(Kondratyuk and Straka, 2019)", "normalizedForm": "Kondratyuk and Straka, 2019", "refKey": 17}, {"label": "(Kondratyuk and Straka, 2019)", "normalizedForm": "Kondratyuk and Straka, 2019", "refKey": 17}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "UDify", "normalizedForm": "UDify", "offsetStart": 137, "offsetEnd": 142}, "context": "Scores from UDPipe 2.0 (fromKondratyuk and Straka, 2019), the previous state-of-the-art models UDPipe 2.0+mBERT(Straka et al., 2019) and UDify", "mentionContextAttributes": {"used": {"value": true, "score": 0.9575042724609375}, "created": {"value": false, "score": 8.821487426757812e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9995203018188477}, "created": {"value": false, "score": 0.00030994415283203125}, "shared": {"value": false, "score": 1.1920928955078125e-06}}, "references": [{"label": "(Kondratyuk and Straka, 2019)", "normalizedForm": "Kondratyuk and Straka, 2019", "refKey": 17}, {"label": "(Kondratyuk and Straka, 2019)", "normalizedForm": "Kondratyuk and Straka, 2019", "refKey": 17}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ELMo", "normalizedForm": "ELMo", "offsetStart": 138, "offsetEnd": 142}, "context": "The first striking finding is that even though all our Wikipedia data sets are smaller than 1GB in size (except for Catalan), none of the ELMo Wikipedia models show any sign of overfitting, as the results continue to improve for all metrics the more we train the ELMo models, with the best results consistently being those of the fully trained 10 epoch ELMos.", "mentionContextAttributes": {"used": {"value": false, "score": 0.1299871802330017}, "created": {"value": false, "score": 9.965896606445312e-05}, "shared": {"value": false, "score": 5.960464477539062e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999902248382568}, "created": {"value": true, "score": 0.9998936653137207}, "shared": {"value": false, "score": 3.337860107421875e-06}}, "references": [{"label": "(Peters et al., 2018)", "normalizedForm": "Peters et al., 2018", "refKey": 29}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "UDify", "normalizedForm": "UDify", "offsetStart": 149, "offsetEnd": 154}, "context": "We also compare our UDPipe 2.0 + ELMo models against the state-of-the-art results (assuming gold tokenization) for these languages, which are either UDify (Kondratyuk and Straka, 2019) or UDPipe 2.0 + mBERT (Straka et al., 2019).", "mentionContextAttributes": {"used": {"value": true, "score": 0.9877712726593018}, "created": {"value": false, "score": 3.6954879760742188e-06}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9995203018188477}, "created": {"value": false, "score": 0.00030994415283203125}, "shared": {"value": false, "score": 1.1920928955078125e-06}}, "references": [{"label": "(Kondratyuk and Straka, 2019)", "normalizedForm": "Kondratyuk and Straka, 2019", "refKey": 17, "offsetStart": 19574, "offsetEnd": 19603}, {"label": "(Kondratyuk and Straka, 2019)", "normalizedForm": "Kondratyuk and Straka, 2019", "refKey": 17, "offsetStart": 19574, "offsetEnd": 19603}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "UDify", "normalizedForm": "UDify", "offsetStart": 149, "offsetEnd": 154}, "context": "The results for Finnish are actually quite interesting, as mBERT was pre-trained on Wikipedia and here we see that the multilingual setting in which UDify was fine-tuned exhibits subbaseline results for all metrics, and that the UD-Pipe + mBERT scores are often lower than those of our UDPipe 2.0 + ELMo Wikipedia .", "mentionContextAttributes": {"used": {"value": true, "score": 0.9460902810096741}, "created": {"value": false, "score": 5.7220458984375e-06}, "shared": {"value": false, "score": 7.152557373046875e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9995203018188477}, "created": {"value": false, "score": 0.00030994415283203125}, "shared": {"value": false, "score": 1.1920928955078125e-06}}, "references": [{"label": "(Kondratyuk and Straka, 2019)", "normalizedForm": "Kondratyuk and Straka, 2019", "refKey": 17}, {"label": "(Kondratyuk and Straka, 2019)", "normalizedForm": "Kondratyuk and Straka, 2019", "refKey": 17}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ELMo", "normalizedForm": "ELMo", "offsetStart": 151, "offsetEnd": 155}, "context": "We train UDPipe 2.0 using gold tokenization and segmentation for each of our ELMo models, the only thing that changes from training to training is the ELMo model as hyperparameters always remain at the default values (except for number of training tokens) (Peters et al., 2018).", "mentionContextAttributes": {"used": {"value": false, "score": 0.09617096185684204}, "created": {"value": false, "score": 0.0001304149627685547}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999902248382568}, "created": {"value": true, "score": 0.9998936653137207}, "shared": {"value": false, "score": 3.337860107421875e-06}}, "references": [{"label": "(Peters et al., 2018)", "normalizedForm": "Peters et al., 2018", "refKey": 29}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ELMo", "normalizedForm": "ELMo", "offsetStart": 151, "offsetEnd": 155}, "context": "In table 7 we report the training times in both hours and days, as well as the total power draw (in Watts) of the system used to train each individual ELMo model.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9966854453086853}, "created": {"value": false, "score": 3.504753112792969e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999902248382568}, "created": {"value": true, "score": 0.9998936653137207}, "shared": {"value": false, "score": 3.337860107421875e-06}}, "references": [{"label": "(Peters et al., 2018)", "normalizedForm": "Peters et al., 2018", "refKey": 29}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ELMo", "normalizedForm": "ELMo", "offsetStart": 157, "offsetEnd": 161}, "context": "One last thing that it is important to note with respect to the number of training epochs is that even though we fully pre-trained our ELMo Wikipedia 's and ELMo OSCAR 's to the recommended 10 epoch mark, and then compared them against one another, the number of training steps between both pre-trained models differs drastically due to the big difference in corpus size (for Indonesian, for instance, 10 epochs correspond to 78K steps for ELMo Wikipedia and to 2.6M steps for OSCAR; the complete picture is provided in the Appendix, in Table 8).", "mentionContextAttributes": {"used": {"value": true, "score": 0.999956488609314}, "created": {"value": false, "score": 3.0994415283203125e-06}, "shared": {"value": false, "score": 7.152557373046875e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999902248382568}, "created": {"value": true, "score": 0.9998936653137207}, "shared": {"value": false, "score": 3.337860107421875e-06}}, "references": [{"label": "(Peters et al., 2018)", "normalizedForm": "Peters et al., 2018", "refKey": 29}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "mBERT", "normalizedForm": "mBERT", "offsetStart": 163, "offsetEnd": 168}, "context": "It has been used to train fixed embeddings (Al-Rfou et al., 2013;Bojanowski et al., 2017) and more recently the multilingual BERT (Devlin et al., 2018), hereafter mBERT.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0008170008659362793}, "created": {"value": false, "score": 0.00036346912384033203}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9995203018188477}, "created": {"value": false, "score": 0.0046517252922058105}, "shared": {"value": false, "score": 1.1920928955078125e-06}}, "references": [{"label": "(Devlin et al., 2018)", "normalizedForm": "Devlin et al., 2018", "refKey": 0}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ELMo", "normalizedForm": "ELMo", "offsetStart": 166, "offsetEnd": 170}, "context": "On the other hand, contextualized word representations and language models have been developed using both featurebased architectures, the most notable examples being ELMo and Flair (Peters et al., 2018;Akbik et al., 2018), and transformer based architectures, that are commonly used in a fine-tune setting, as is the case of GPT-1, GPT-2 (Radford et al., 2018(Radford et al., , 2019)), BERT and its derivatives (Devlin et al., 2018;Liu et al., 2019;Lan et al., 2019) and more recently T5 (Raffel et al., 2019).", "mentionContextAttributes": {"used": {"value": false, "score": 0.005272090435028076}, "created": {"value": false, "score": 0.0012322664260864258}, "shared": {"value": false, "score": 2.5033950805664062e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999902248382568}, "created": {"value": true, "score": 0.9998936653137207}, "shared": {"value": false, "score": 3.337860107421875e-06}}, "references": [{"label": "(Peters et al., 2018)", "normalizedForm": "Peters et al., 2018", "refKey": 29}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ELMo", "normalizedForm": "ELMo", "offsetStart": 167, "offsetEnd": 171}, "context": "As previously mentioned Finnish is morphologically richer than the other languages in which we trained ELMo, we hypothesize that the representation space given by the ELMo embeddings might not be sufficiently big to extract more features from the Finnish OSCAR corpus beyond the 5 th epoch mark, however in order to test this we would need to train a larger language model like BERT which is sadly beyond our computing infrastructure limits (cf.", "mentionContextAttributes": {"used": {"value": true, "score": 0.7353690266609192}, "created": {"value": false, "score": 0.00011408329010009766}, "shared": {"value": false, "score": 2.6226043701171875e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999902248382568}, "created": {"value": true, "score": 0.9998936653137207}, "shared": {"value": false, "score": 3.337860107421875e-06}}, "references": [{"label": "(Peters et al., 2018)", "normalizedForm": "Peters et al., 2018", "refKey": 29}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "UDPipe", "normalizedForm": "UDPipe", "offsetStart": 168, "offsetEnd": 174}, "version": {"rawForm": "2.0", "normalizedForm": "2.0"}, "context": "Taking a closer look at the results for Danish, we see that ELMo Wikipedia , which was trained with a mere 300MB corpus, does not show any sign  of overfitting, as the UDPipe 2.0 + ELMo Wikipedia results considerably improve the UDPipe 2.0 baseline.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9063400030136108}, "created": {"value": false, "score": 1.2993812561035156e-05}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999147653579712}, "created": {"value": false, "score": 0.005289673805236816}, "shared": {"value": false, "score": 0.002932727336883545}}, "references": [{"label": "(Straka, 2018;", "normalizedForm": "(Straka, 2018", "refKey": 35}, {"label": "Straka et al., 2019)", "normalizedForm": "Straka et al., 2019)", "refKey": 37}, {"label": "(Straka, 2018;", "normalizedForm": "(Straka, 2018", "refKey": 35}, {"label": "Straka et al., 2019)", "normalizedForm": "Straka et al., 2019)", "refKey": 37}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ELMo", "normalizedForm": "ELMo", "offsetStart": 172, "offsetEnd": 176}, "context": "We use the multilingual OSCAR corpus, extracted from Common Crawl via language classification, filtering and cleaning, to train monolingual contextualized word embeddings (ELMo) for five mid-resource languages.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9847906231880188}, "created": {"value": false, "score": 2.8252601623535156e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999902248382568}, "created": {"value": true, "score": 0.9998936653137207}, "shared": {"value": false, "score": 3.337860107421875e-06}}, "references": [{"label": "(Peters et al., 2018)", "normalizedForm": "Peters et al., 2018", "refKey": 29}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ELMo", "normalizedForm": "ELMo", "offsetStart": 181, "offsetEnd": 185}, "context": "Taking a closer look at the results for Danish, we see that ELMo Wikipedia , which was trained with a mere 300MB corpus, does not show any sign  of overfitting, as the UDPipe 2.0 + ELMo Wikipedia results considerably improve the UDPipe 2.0 baseline.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9063400030136108}, "created": {"value": false, "score": 1.2993812561035156e-05}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999902248382568}, "created": {"value": true, "score": 0.9998936653137207}, "shared": {"value": false, "score": 3.337860107421875e-06}}, "references": [{"label": "(Peters et al., 2018)", "normalizedForm": "Peters et al., 2018", "refKey": 29}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ELMo", "normalizedForm": "ELMo", "offsetStart": 183, "offsetEnd": 187}, "context": "We save checkpoints at 1 st , 3 rd and 5 th epoch in order to investigate some concerns about possible overfitting for smaller corpora (Wikipedia in this case) raised by the original ELMo authors.", "mentionContextAttributes": {"used": {"value": false, "score": 0.10432243347167969}, "created": {"value": false, "score": 0.00011265277862548828}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999902248382568}, "created": {"value": true, "score": 0.9998936653137207}, "shared": {"value": false, "score": 3.337860107421875e-06}}, "references": [{"label": "(Peters et al., 2018)", "normalizedForm": "Peters et al., 2018", "refKey": 29}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "UDPipe", "normalizedForm": "UDPipe", "offsetStart": 188, "offsetEnd": 194}, "version": {"rawForm": "2.0 +", "normalizedForm": "2.0 +", "offsetStart": 195, "offsetEnd": 200}, "context": "We also compare our UDPipe 2.0 + ELMo models against the state-of-the-art results (assuming gold tokenization) for these languages, which are either UDify (Kondratyuk and Straka, 2019) or UDPipe 2.0 + mBERT (Straka et al., 2019). ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9877712726593018}, "created": {"value": false, "score": 3.6954879760742188e-06}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999147653579712}, "created": {"value": false, "score": 0.005289673805236816}, "shared": {"value": false, "score": 0.002932727336883545}}, "references": [{"label": "(Straka et al., 2019)", "normalizedForm": "Straka et al., 2019", "refKey": 37, "offsetStart": 19626, "offsetEnd": 19647}, {"label": "(Straka et al., 2019)", "normalizedForm": "Straka et al., 2019", "refKey": 37, "offsetStart": 19626, "offsetEnd": 19647}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "UDPipe", "normalizedForm": "UDPipe", "offsetStart": 194, "offsetEnd": 200}, "version": {"rawForm": "2.0", "normalizedForm": "2.0"}, "context": "Scores from UDPipe 2.0 (fromKondratyuk and Straka, 2019), the previous state-of-the-art models UDPipe 2.0+mBERT(Straka et al., 2019) and UDify(Kondratyuk and Straka, 2019), and our ELMoenhanced UDPipe 2.0 models.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9885595440864563}, "created": {"value": false, "score": 7.987022399902344e-06}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999147653579712}, "created": {"value": false, "score": 0.005289673805236816}, "shared": {"value": false, "score": 0.002932727336883545}}, "references": [{"label": "(Straka, 2018;", "normalizedForm": "(Straka, 2018", "refKey": 35}, {"label": "Straka et al., 2019)", "normalizedForm": "Straka et al., 2019)", "refKey": 37}, {"label": "(Straka, 2018;", "normalizedForm": "(Straka, 2018", "refKey": 35}, {"label": "Straka et al., 2019)", "normalizedForm": "Straka et al., 2019)", "refKey": 37}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "mBERT", "normalizedForm": "mBERT", "offsetStart": 201, "offsetEnd": 206}, "context": "We also compare our UDPipe 2.0 + ELMo models against the state-of-the-art results (assuming gold tokenization) for these languages, which are either UDify (Kondratyuk and Straka, 2019) or UDPipe 2.0 + mBERT (Straka et al., 2019).", "mentionContextAttributes": {"used": {"value": true, "score": 0.9877712726593018}, "created": {"value": false, "score": 3.6954879760742188e-06}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9995203018188477}, "created": {"value": false, "score": 0.0046517252922058105}, "shared": {"value": false, "score": 1.1920928955078125e-06}}, "references": [{"label": "(Straka et al., 2019)", "normalizedForm": "Straka et al., 2019", "refKey": 37, "offsetStart": 19626, "offsetEnd": 19647}, {"label": "(Straka et al., 2019)", "normalizedForm": "Straka et al., 2019", "refKey": 37, "offsetStart": 19626, "offsetEnd": 19647}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "UDPipe", "normalizedForm": "UDPipe", "offsetStart": 229, "offsetEnd": 235}, "version": {"rawForm": "2.0", "normalizedForm": "2.0"}, "context": "Taking a closer look at the results for Danish, we see that ELMo Wikipedia , which was trained with a mere 300MB corpus, does not show any sign  of overfitting, as the UDPipe 2.0 + ELMo Wikipedia results considerably improve the UDPipe 2.0 baseline.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9063400030136108}, "created": {"value": false, "score": 1.2993812561035156e-05}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999147653579712}, "created": {"value": false, "score": 0.005289673805236816}, "shared": {"value": false, "score": 0.002932727336883545}}, "references": [{"label": "(Straka, 2018;", "normalizedForm": "(Straka, 2018", "refKey": 35}, {"label": "Straka et al., 2019)", "normalizedForm": "Straka et al., 2019)", "refKey": 37}, {"label": "(Straka, 2018;", "normalizedForm": "(Straka, 2018", "refKey": 35}, {"label": "Straka et al., 2019)", "normalizedForm": "Straka et al., 2019)", "refKey": 37}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ELMo", "normalizedForm": "ELMo", "offsetStart": 230, "offsetEnd": 234}, "context": "We chose these languages primarily because they are morphologically and typologically different from one another, but also because all of the OSCAR datasets for these languages were of a sufficiently manageable size such that the ELMo pre-training was doable in less than one month. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.998100221157074}, "created": {"value": false, "score": 0.0001093149185180664}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999902248382568}, "created": {"value": true, "score": 0.9998936653137207}, "shared": {"value": false, "score": 3.337860107421875e-06}}, "references": [{"label": "(Peters et al., 2018)", "normalizedForm": "Peters et al., 2018", "refKey": 29}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "mBERT", "normalizedForm": "mBERT", "offsetStart": 239, "offsetEnd": 244}, "context": "The results for Finnish are actually quite interesting, as mBERT was pre-trained on Wikipedia and here we see that the multilingual setting in which UDify was fine-tuned exhibits subbaseline results for all metrics, and that the UD-Pipe + mBERT scores are often lower than those of our UDPipe 2.0 + ELMo Wikipedia .", "mentionContextAttributes": {"used": {"value": true, "score": 0.9460902810096741}, "created": {"value": false, "score": 5.7220458984375e-06}, "shared": {"value": false, "score": 7.152557373046875e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9995203018188477}, "created": {"value": false, "score": 0.0046517252922058105}, "shared": {"value": false, "score": 1.1920928955078125e-06}}, "references": [{"label": "(Devlin et al., 2018)", "normalizedForm": "Devlin et al., 2018", "refKey": 0}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ELMo", "normalizedForm": "ELMo", "offsetStart": 263, "offsetEnd": 267}, "context": "The first striking finding is that even though all our Wikipedia data sets are smaller than 1GB in size (except for Catalan), none of the ELMo Wikipedia models show any sign of overfitting, as the results continue to improve for all metrics the more we train the ELMo models, with the best results consistently being those of the fully trained 10 epoch ELMos.", "mentionContextAttributes": {"used": {"value": false, "score": 0.12998723983764648}, "created": {"value": false, "score": 9.965896606445312e-05}, "shared": {"value": false, "score": 5.960464477539062e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999902248382568}, "created": {"value": true, "score": 0.9998936653137207}, "shared": {"value": false, "score": 3.337860107421875e-06}}, "references": [{"label": "(Peters et al., 2018)", "normalizedForm": "Peters et al., 2018", "refKey": 29}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ELMo", "normalizedForm": "ELMo", "offsetStart": 269, "offsetEnd": 273}, "context": "After the CoNLL 2018 Shared Task, the UD-Pipe 2.0 authors added the option to concatenate contextualized representations to the embedding section of the network (Straka et al., 2019), we use this new implementation and we concatenate our pretrained deep contextualized ELMo embeddings to the three embeddings mentioned above.", "mentionContextAttributes": {"used": {"value": false, "score": 0.010661303997039795}, "created": {"value": false, "score": 0.01735067367553711}, "shared": {"value": false, "score": 3.337860107421875e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999902248382568}, "created": {"value": true, "score": 0.9998936653137207}, "shared": {"value": false, "score": 3.337860107421875e-06}}, "references": [{"label": "(Peters et al., 2018)", "normalizedForm": "Peters et al., 2018", "refKey": 29}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "UDPipe", "normalizedForm": "UDPipe", "offsetStart": 286, "offsetEnd": 292}, "version": {"rawForm": "2.0", "normalizedForm": "2.0"}, "context": "The results for Finnish are actually quite interesting, as mBERT was pre-trained on Wikipedia and here we see that the multilingual setting in which UDify was fine-tuned exhibits subbaseline results for all metrics, and that the UD-Pipe + mBERT scores are often lower than those of our UDPipe 2.0 + ELMo Wikipedia . ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9460902810096741}, "created": {"value": false, "score": 5.7220458984375e-06}, "shared": {"value": false, "score": 7.152557373046875e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999147653579712}, "created": {"value": false, "score": 0.005289673805236816}, "shared": {"value": false, "score": 0.002932727336883545}}, "references": [{"label": "(Straka, 2018;", "normalizedForm": "(Straka, 2018", "refKey": 35}, {"label": "Straka et al., 2019)", "normalizedForm": "Straka et al., 2019)", "refKey": 37}, {"label": "(Straka, 2018;", "normalizedForm": "(Straka, 2018", "refKey": 35}, {"label": "Straka et al., 2019)", "normalizedForm": "Straka et al., 2019)", "refKey": 37}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ELMo", "normalizedForm": "ELMo", "offsetStart": 299, "offsetEnd": 303}, "context": "The results for Finnish are actually quite interesting, as mBERT was pre-trained on Wikipedia and here we see that the multilingual setting in which UDify was fine-tuned exhibits subbaseline results for all metrics, and that the UD-Pipe + mBERT scores are often lower than those of our UDPipe 2.0 + ELMo Wikipedia .", "mentionContextAttributes": {"used": {"value": true, "score": 0.9460902810096741}, "created": {"value": false, "score": 5.7220458984375e-06}, "shared": {"value": false, "score": 7.152557373046875e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999902248382568}, "created": {"value": true, "score": 0.9998936653137207}, "shared": {"value": false, "score": 3.337860107421875e-06}}, "references": [{"label": "(Peters et al., 2018)", "normalizedForm": "Peters et al., 2018", "refKey": 29}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "mBERT", "normalizedForm": "mBERT", "offsetStart": 311, "offsetEnd": 316}, "context": "However we believe that ELMo contextualized word embeddings remain a useful model that still provide an extremely good trade-off between performance to training cost, even setting new state-of-the-art scores in parsing and POS tagging for our five chosen languages, performing even better than the multilingual mBERT model.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00040012598037719727}, "created": {"value": false, "score": 0.0046517252922058105}, "shared": {"value": false, "score": 7.152557373046875e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9995203018188477}, "created": {"value": false, "score": 0.0046517252922058105}, "shared": {"value": false, "score": 1.1920928955078125e-06}}, "references": [{"label": "(Devlin et al., 2018)", "normalizedForm": "Devlin et al., 2018", "refKey": 0}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ELMo", "normalizedForm": "ELMo", "offsetStart": 380, "offsetEnd": 384}, "context": "For dependency parsing and POS tagging the most notable non-English specific contribution is that of the CoNLL 2018 Shared Task (Zeman et al., 2018), where the 1 st place (LAS Ranking) was awarded to the HIT-SCIR team (Che et al., 2018) who used Dozat and Manning (2017)'s Deep Biaffine parser and its extension described in (Dozat et al., 2017), coupled with deep contextualized ELMo embeddings (Peters et al., 2018)   (Straka, 2018), with mBERT greatly improving the scores of the original model, and UDify (Kondratyuk and Straka, 2019), which adds an extra attention layer on top of mBERT plus a Deep Bi-affine attention layer for dependency parsing and a Softmax layer for POS tagging. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9995203018188477}, "created": {"value": false, "score": 3.814697265625e-06}, "shared": {"value": false, "score": 7.152557373046875e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999902248382568}, "created": {"value": true, "score": 0.9998936653137207}, "shared": {"value": false, "score": 3.337860107421875e-06}}, "references": [{"label": "(Peters et al., 2018)", "normalizedForm": "Peters et al., 2018", "refKey": 29}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ELMo", "normalizedForm": "ELMo", "offsetStart": 440, "offsetEnd": 444}, "context": "One last thing that it is important to note with respect to the number of training epochs is that even though we fully pre-trained our ELMo Wikipedia 's and ELMo OSCAR 's to the recommended 10 epoch mark, and then compared them against one another, the number of training steps between both pre-trained models differs drastically due to the big difference in corpus size (for Indonesian, for instance, 10 epochs correspond to 78K steps for ELMo Wikipedia and to 2.6M steps for OSCAR; the complete picture is provided in the Appendix, in Table 8).", "mentionContextAttributes": {"used": {"value": true, "score": 0.999956488609314}, "created": {"value": false, "score": 3.0994415283203125e-06}, "shared": {"value": false, "score": 7.152557373046875e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999902248382568}, "created": {"value": true, "score": 0.9998936653137207}, "shared": {"value": false, "score": 3.337860107421875e-06}}, "references": [{"label": "(Peters et al., 2018)", "normalizedForm": "Peters et al., 2018", "refKey": 29}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "mBERT", "normalizedForm": "mBERT", "offsetStart": 441, "offsetEnd": 446}, "context": "For dependency parsing and POS tagging the most notable non-English specific contribution is that of the CoNLL 2018 Shared Task (Zeman et al., 2018), where the 1 st place (LAS Ranking) was awarded to the HIT-SCIR team (Che et al., 2018) who used Dozat and Manning (2017)'s Deep Biaffine parser and its extension described in (Dozat et al., 2017), coupled with deep contextualized ELMo embeddings (Peters et al., 2018)   (Straka, 2018), with mBERT greatly improving the scores of the original model, and UDify (Kondratyuk and Straka, 2019), which adds an extra attention layer on top of mBERT plus a Deep Bi-affine attention layer for dependency parsing and a Softmax layer for POS tagging. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9995203018188477}, "created": {"value": false, "score": 3.814697265625e-06}, "shared": {"value": false, "score": 7.152557373046875e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9995203018188477}, "created": {"value": false, "score": 0.0046517252922058105}, "shared": {"value": false, "score": 1.1920928955078125e-06}}, "references": [{"label": "(Devlin et al., 2018)", "normalizedForm": "Devlin et al., 2018", "refKey": 0}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "UDify", "normalizedForm": "UDify", "offsetStart": 503, "offsetEnd": 537}, "context": "For dependency parsing and POS tagging the most notable non-English specific contribution is that of the CoNLL 2018 Shared Task (Zeman et al., 2018), where the 1 st place (LAS Ranking) was awarded to the HIT-SCIR team (Che et al., 2018) who used Dozat and Manning (2017)'s Deep Biaffine parser and its extension described in (Dozat et al., 2017), coupled with deep contextualized ELMo embeddings (Peters et al., 2018)   (Straka, 2018), with mBERT greatly improving the scores of the original model, and UDify (Kondratyuk and Straka, 2019), which adds an extra attention layer on top of mBERT plus a Deep Bi-affine attention layer for dependency parsing and a Softmax layer for POS tagging. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9995203018188477}, "created": {"value": false, "score": 3.814697265625e-06}, "shared": {"value": false, "score": 7.152557373046875e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9995203018188477}, "created": {"value": false, "score": 0.00030994415283203125}, "shared": {"value": false, "score": 1.1920928955078125e-06}}, "references": [{"label": "(Kondratyuk and Straka, 2019)", "normalizedForm": "Kondratyuk and Straka, 2019", "refKey": 17}, {"label": "(Kondratyuk and Straka, 2019)", "normalizedForm": "Kondratyuk and Straka, 2019", "refKey": 17}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "mBERT", "normalizedForm": "mBERT", "offsetStart": 586, "offsetEnd": 591}, "context": "For dependency parsing and POS tagging the most notable non-English specific contribution is that of the CoNLL 2018 Shared Task (Zeman et al., 2018), where the 1 st place (LAS Ranking) was awarded to the HIT-SCIR team (Che et al., 2018) who used Dozat and Manning (2017)'s Deep Biaffine parser and its extension described in (Dozat et al., 2017), coupled with deep contextualized ELMo embeddings (Peters et al., 2018)   (Straka, 2018), with mBERT greatly improving the scores of the original model, and UDify (Kondratyuk and Straka, 2019), which adds an extra attention layer on top of mBERT plus a Deep Bi-affine attention layer for dependency parsing and a Softmax layer for POS tagging. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9995203018188477}, "created": {"value": false, "score": 3.814697265625e-06}, "shared": {"value": false, "score": 7.152557373046875e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9995203018188477}, "created": {"value": false, "score": 0.0046517252922058105}, "shared": {"value": false, "score": 1.1920928955078125e-06}}, "references": [{"label": "(Devlin et al., 2018)", "normalizedForm": "Devlin et al., 2018", "refKey": 0}]}], "references": [{"refKey": 29, "tei": "<biblStruct xml:id=\"b29\">\n\t<analytic>\n\t\t<title level=\"a\" type=\"main\">Deep Contextualized Word Representations</title>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Matthew</forename><surname>Peters</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Mark</forename><surname>Neumann</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Mohit</forename><surname>Iyyer</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Matt</forename><surname>Gardner</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Christopher</forename><surname>Clark</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Kenton</forename><surname>Lee</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Luke</forename><surname>Zettlemoyer</surname></persName>\n\t\t</author>\n\t\t<idno type=\"DOI\">10.18653/v1/n18-1202</idno>\n\t</analytic>\n\t<monogr>\n\t\t<title level=\"m\">Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)</title>\n\t\t<meeting>the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)</meeting>\n\t\t<imprint>\n\t\t\t<publisher>Association for Computational Linguistics</publisher>\n\t\t\t<date type=\"published\" when=\"2018\">2018</date>\n\t\t\t<biblScope unit=\"volume\">1</biblScope>\n\t\t\t<biblScope unit=\"page\">2237</biblScope>\n\t\t</imprint>\n\t</monogr>\n</biblStruct>\n"}, {"refKey": 17, "tei": "<biblStruct xml:id=\"b17\">\n\t<monogr>\n\t\t<title/>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Dan</forename><surname>Kondratyuk</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Milan</forename><surname>Straka</surname></persName>\n\t\t</author>\n\t\t<imprint>\n\t\t\t<date>2019</date>\n\t\t\t<biblScope unit=\"page\">75</biblScope>\n\t\t</imprint>\n\t</monogr>\n</biblStruct>\n"}, {"refKey": 35, "tei": "<biblStruct xml:id=\"b35\">\n\t<analytic>\n\t\t<title level=\"a\" type=\"main\"></title>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Milan</forename><surname>Straka</surname></persName>\n\t\t</author>\n\t\t<idno type=\"DOI\">10.18653/v1/k18-2020</idno>\n\t</analytic>\n\t<monogr>\n\t\t<title level=\"m\">Proceedings of the</title>\n\t\t<meeting>the</meeting>\n\t\t<imprint>\n\t\t\t<publisher>Association for Computational Linguistics</publisher>\n\t\t\t<date type=\"published\" when=\"2018\">2018</date>\n\t\t\t<biblScope unit=\"page\">207</biblScope>\n\t\t</imprint>\n\t</monogr>\n</biblStruct>\n"}, {"refKey": 37, "tei": "<biblStruct xml:id=\"b37\">\n\t<monogr>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Milan</forename><surname>Straka</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Jana</forename><surname>Strakov\u00e1</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Jan</forename><surname>Hajic</surname></persName>\n\t\t</author>\n\t\t<idno>CoRR, abs/1908.07448</idno>\n\t\t<title level=\"m\">Evaluating contextualized embeddings on 54 languages in POS tagging, lemmatization and dependency parsing</title>\n\t\t<imprint>\n\t\t\t<date>2019</date>\n\t\t</imprint>\n\t</monogr>\n</biblStruct>\n"}, {"refKey": 0, "tei": "<biblStruct xml:id=\"b0\">\n\t<monogr>\n\t\t<title level=\"m\" type=\"main\">A Monolingual Approach to Contextualized Word Embeddings for Mid-Resource Languages</title>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Pedro</forename><forename type=\"middle\">Javier</forename><surname>Ortiz Su\u00e1rez</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Laurent</forename><surname>Romary</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Beno\u00eet</forename><surname>Sagot</surname></persName>\n\t\t</author>\n\t\t<idno type=\"DOI\">10.18653/v1/2020.acl-</idno>\n\t\t<idno>0A8500EBED2520763030A8BBA8F8379C</idno>\n\t\t<imprint>\n\t\t\t<date></date>\n\t\t</imprint>\n\t</monogr>\n</biblStruct>\n"}], "runtime": 10083, "id": "f8336fcafca40a6232fcfc6259bb03f94195f504", "metadata": {"id": "f8336fcafca40a6232fcfc6259bb03f94195f504"}, "original_file_path": "../../datalake/Samuel/SOFTware-Sync/downloads/xml/hal-02863875.grobid.tei.xml", "file_name": "hal-02863875.grobid.tei.xml"}