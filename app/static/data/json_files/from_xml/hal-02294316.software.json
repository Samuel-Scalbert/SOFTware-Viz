{"application": "software-mentions", "version": "0.8.0", "date": "2024-10-07T11:57+0000", "md5": "8C26359B9CB44C4797315D2772B7E620", "mentions": [{"type": "software", "software-type": "software", "software-name": {"rawForm": "WordPiece", "normalizedForm": "WordPiece", "offsetStart": 4, "offsetEnd": 13}, "context": "The WordPiece vocabulary is computed based on the observed frequency of each sequence of characters of the corpus BERT is pre-trained on: Wikipedia and the BookCorpus.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9996486902236938}, "created": {"value": false, "score": 4.5299530029296875e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999786615371704}, "created": {"value": true, "score": 0.9999271631240845}, "shared": {"value": false, "score": 1.7881393432617188e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "WordPiece", "normalizedForm": "WordPiece", "offsetStart": 9, "offsetEnd": 18}, "context": "For each WordPiece met, we start the tokenization on the gold side, starting and ending from the same character positions.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9087255001068115}, "created": {"value": false, "score": 0.0013614296913146973}, "shared": {"value": false, "score": 9.5367431640625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999786615371704}, "created": {"value": true, "score": 0.9999271631240845}, "shared": {"value": false, "score": 1.7881393432617188e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MoNoise", "normalizedForm": "MoNoise", "offsetStart": 13, "offsetEnd": 20}, "context": "In 2016, the MoNoise model (van der Goot and van Noord, 2017) significantly improved the Stateof-the-art with a feature-based Random Forest. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0004188418388366699}, "created": {"value": false, "score": 0.0007377266883850098}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.7022147178649902}, "created": {"value": true, "score": 0.9067897796630859}, "shared": {"value": false, "score": 5.960464477539062e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "WordPiece", "normalizedForm": "WordPiece", "offsetStart": 14, "offsetEnd": 23}, "context": "\u2022 We design a WordPiece tokenizer that enforces alignment between canonical and noisy tokens. ", "mentionContextAttributes": {"used": {"value": false, "score": 5.698204040527344e-05}, "created": {"value": true, "score": 0.9999271631240845}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999786615371704}, "created": {"value": true, "score": 0.9999271631240845}, "shared": {"value": false, "score": 1.7881393432617188e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "WordPiece", "normalizedForm": "WordPiece", "offsetStart": 15, "offsetEnd": 24}, "context": "It takes noisy WordPiece tokens as input.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0009469389915466309}, "created": {"value": false, "score": 7.581710815429688e-05}, "shared": {"value": false, "score": 5.960464477539062e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999786615371704}, "created": {"value": true, "score": 0.9999271631240845}, "shared": {"value": false, "score": 1.7881393432617188e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "WordPiece", "normalizedForm": "WordPiece", "offsetStart": 18, "offsetEnd": 27}, "context": "As we work at the WordPiece level this does not bring any issue.", "mentionContextAttributes": {"used": {"value": false, "score": 0.002331078052520752}, "created": {"value": false, "score": 0.1285300850868225}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999786615371704}, "created": {"value": true, "score": 0.9999271631240845}, "shared": {"value": false, "score": 1.7881393432617188e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MoNoise", "normalizedForm": "MoNoise", "offsetStart": 27, "offsetEnd": 34}, "context": "However, we emphasize that MoNoise is a feature-based Random Forest based on external modules. ", "mentionContextAttributes": {"used": {"value": false, "score": 9.02414321899414e-05}, "created": {"value": true, "score": 0.9067897796630859}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.7022147178649902}, "created": {"value": true, "score": 0.9067897796630859}, "shared": {"value": false, "score": 5.960464477539062e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "WordPiece", "normalizedForm": "WordPiece", "offsetStart": 30, "offsetEnd": 39}, "context": "Still, it is not in BERT-base WordPiece vocabulary.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0074007511138916016}, "created": {"value": false, "score": 3.6597251892089844e-05}, "shared": {"value": false, "score": 1.0728836059570312e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999786615371704}, "created": {"value": true, "score": 0.9999271631240845}, "shared": {"value": false, "score": 1.7881393432617188e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "WordPiece", "normalizedForm": "WordPiece", "offsetStart": 30, "offsetEnd": 39}, "context": "The first is that it requires WordPiece alignment (cf.", "mentionContextAttributes": {"used": {"value": false, "score": 0.2668015956878662}, "created": {"value": false, "score": 2.6702880859375e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999786615371704}, "created": {"value": true, "score": 0.9999271631240845}, "shared": {"value": false, "score": 1.7881393432617188e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MoNoise", "normalizedForm": "MoNoise", "offsetStart": 33, "offsetEnd": 40}, "context": "Our model is 6 times faster than MoNoise at prediction time.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0013422966003417969}, "created": {"value": false, "score": 0.05524253845214844}, "shared": {"value": false, "score": 5.960464477539062e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.7022147178649902}, "created": {"value": true, "score": 0.9067897796630859}, "shared": {"value": false, "score": 5.960464477539062e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "WordPiece", "normalizedForm": "WordPiece", "offsetStart": 35, "offsetEnd": 44}, "context": "We frame normalization as a 1-to-1 WordPiece token mapping.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9814190864562988}, "created": {"value": false, "score": 0.01467043161392212}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999786615371704}, "created": {"value": true, "score": 0.9999271631240845}, "shared": {"value": false, "score": 1.7881393432617188e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "WordPiece", "normalizedForm": "WordPiece", "offsetStart": 40, "offsetEnd": 49}, "context": "We will refer to the process of getting WordPiece tokens from word tokens simply as tokenization for brievety.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0015241503715515137}, "created": {"value": true, "score": 0.9994179010391235}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999786615371704}, "created": {"value": true, "score": 0.9999271631240845}, "shared": {"value": false, "score": 1.7881393432617188e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "WordPiece", "normalizedForm": "WordPiece", "offsetStart": 46, "offsetEnd": 55}, "context": "By doing so, for each word we get non-aligned WordPiece tokens.", "mentionContextAttributes": {"used": {"value": false, "score": 0.025352120399475098}, "created": {"value": false, "score": 0.012955844402313232}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999786615371704}, "created": {"value": true, "score": 0.9999271631240845}, "shared": {"value": false, "score": 1.7881393432617188e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MoNoise", "normalizedForm": "MoNoise", "offsetStart": 49, "offsetEnd": 56}, "context": "In this setting, we significantly outperform the MoNoise model (+1.78 improvement) (Table 8).", "mentionContextAttributes": {"used": {"value": true, "score": 0.7022147178649902}, "created": {"value": false, "score": 1.4781951904296875e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.7022147178649902}, "created": {"value": true, "score": 0.9067897796630859}, "shared": {"value": false, "score": 5.960464477539062e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "WordPiece", "normalizedForm": "WordPiece", "offsetStart": 49, "offsetEnd": 58}, "context": "By doing so, we ensure a closer alignment at the WordPiece level.", "mentionContextAttributes": {"used": {"value": false, "score": 0.03769952058792114}, "created": {"value": true, "score": 0.9240649342536926}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999786615371704}, "created": {"value": true, "score": 0.9999271631240845}, "shared": {"value": false, "score": 1.7881393432617188e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "WordPiece", "normalizedForm": "WordPiece", "offsetStart": 49, "offsetEnd": 58}, "context": "We therefore introduce a new label in our output WordPiece vocabulary as well as a new vector in the last softmax layer.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0001856684684753418}, "created": {"value": true, "score": 0.9994155168533325}, "shared": {"value": false, "score": 5.960464477539062e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999786615371704}, "created": {"value": true, "score": 0.9999271631240845}, "shared": {"value": false, "score": 1.7881393432617188e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "WordPiece", "normalizedForm": "WordPiece", "offsetStart": 50, "offsetEnd": 59}, "context": "BERT takes as input sub-word units in the form of WordPiece tokens originally introduced in Schuster and Nakajima (2012).", "mentionContextAttributes": {"used": {"value": false, "score": 0.00012934207916259766}, "created": {"value": false, "score": 0.0009630918502807617}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999786615371704}, "created": {"value": true, "score": 0.9999271631240845}, "shared": {"value": false, "score": 1.7881393432617188e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "WordPiece", "normalizedForm": "WordPiece", "offsetStart": 50, "offsetEnd": 59}, "context": "As gold labels, it takes on the one side the gold WordPiece tokens and on the other side the number of [MASK] to append next to each source WordPiece tokens.", "mentionContextAttributes": {"used": {"value": false, "score": 0.08004671335220337}, "created": {"value": false, "score": 3.2901763916015625e-05}, "shared": {"value": false, "score": 5.960464477539062e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999786615371704}, "created": {"value": true, "score": 0.9999271631240845}, "shared": {"value": false, "score": 1.7881393432617188e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "WordPiece", "normalizedForm": "WordPiece", "offsetStart": 55, "offsetEnd": 64}, "context": "Reusing BERT, in any way, requires to use its original WordPiece vocabulary.", "mentionContextAttributes": {"used": {"value": false, "score": 0.08990252017974854}, "created": {"value": false, "score": 9.715557098388672e-05}, "shared": {"value": false, "score": 1.7881393432617188e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999786615371704}, "created": {"value": true, "score": 0.9999271631240845}, "shared": {"value": false, "score": 1.7881393432617188e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "WordPiece", "normalizedForm": "WordPiece", "offsetStart": 58, "offsetEnd": 67}, "context": "This module takes as input BERT last hidden state of each WordPiece tokens and predict the number of [MASK]   At test time, we first predict the number of next masks to introduce in the noisy sequence.", "mentionContextAttributes": {"used": {"value": false, "score": 0.4849793314933777}, "created": {"value": false, "score": 0.0067024827003479}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999786615371704}, "created": {"value": true, "score": 0.9999271631240845}, "shared": {"value": false, "score": 1.7881393432617188e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "WordPiece", "normalizedForm": "WordPiece", "offsetStart": 65, "offsetEnd": 74}, "context": "Based on the word level alignment, we present two methods to get WordPiece alignment : an Independent Alignment approach and a Parallel Alignment one.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00014710426330566406}, "created": {"value": true, "score": 0.9627631306648254}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999786615371704}, "created": {"value": true, "score": 0.9999271631240845}, "shared": {"value": false, "score": 1.7881393432617188e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "WordPiece", "normalizedForm": "WordPiece", "offsetStart": 67, "offsetEnd": 76}, "context": "each dimension v d \u223c N (meani(x d ), \u03c3 2 i (x d )) (i indexing the WordPiece vocabulary and d the dense dimension of BERT output layer), meani (resp.", "mentionContextAttributes": {"used": {"value": true, "score": 0.999954104423523}, "created": {"value": false, "score": 3.4570693969726562e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999786615371704}, "created": {"value": true, "score": 0.9999271631240845}, "shared": {"value": false, "score": 1.7881393432617188e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "WordPiece", "normalizedForm": "WordPiece", "offsetStart": 73, "offsetEnd": 82}, "context": "On the other hand, it was trained on For each input sequence, 15% of the WordPiece tokens are either replaced with the special token [MASK] (80% of the time), replaced by a random token (10% of the time) or untouched (10% of the time).", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999786615371704}, "created": {"value": false, "score": 1.52587890625e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999786615371704}, "created": {"value": true, "score": 0.9999271631240845}, "shared": {"value": false, "score": 1.7881393432617188e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MoNoise", "normalizedForm": "MoNoise", "offsetStart": 74, "offsetEnd": 81}, "context": "In order to have a more balanced comparison, we compare our system to the MoNoise model after removing the feature that has the most impact, according to the original paper: the n-gram module (referred as MoNoise no n-gram). ", "mentionContextAttributes": {"used": {"value": false, "score": 0.40360909700393677}, "created": {"value": false, "score": 0.002656280994415283}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.7022147178649902}, "created": {"value": true, "score": 0.9067897796630859}, "shared": {"value": false, "score": 5.960464477539062e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "aspell", "normalizedForm": "aspell", "offsetStart": 75, "offsetEnd": 81}, "context": "The model ranks candidates provided by modules such as a spelling checker (aspell), a n-gram based language model and word embeddings trained on millions of tweets.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00011372566223144531}, "created": {"value": false, "score": 0.00042814016342163086}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.00011372566223144531}, "created": {"value": false, "score": 0.00042814016342163086}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MoNoise", "normalizedForm": "MoNoise", "offsetStart": 80, "offsetEnd": 87}, "context": "As we see in Table 8, our non-UGC system is far from the State-of-the-Art model MoNoise (van der Goot and van Noord, 2017) in terms of F1 score. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0005214810371398926}, "created": {"value": false, "score": 0.014661192893981934}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.7022147178649902}, "created": {"value": true, "score": 0.9067897796630859}, "shared": {"value": false, "score": 5.960464477539062e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "WordPiece", "normalizedForm": "WordPiece", "offsetStart": 81, "offsetEnd": 90}, "context": "Generally speaking, we found that optimizing BERT for lexical normalisation with WordPiece alignment is extremely sensitive to hyper-parameters.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9997010231018066}, "created": {"value": false, "score": 8.499622344970703e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999786615371704}, "created": {"value": true, "score": 0.9999271631240845}, "shared": {"value": false, "score": 1.7881393432617188e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "WordPiece", "normalizedForm": "WordPiece", "offsetStart": 140, "offsetEnd": 149}, "context": "As gold labels, it takes on the one side the gold WordPiece tokens and on the other side the number of [MASK] to append next to each source WordPiece tokens.", "mentionContextAttributes": {"used": {"value": false, "score": 0.08004671335220337}, "created": {"value": false, "score": 3.2901763916015625e-05}, "shared": {"value": false, "score": 5.960464477539062e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999786615371704}, "created": {"value": true, "score": 0.9999271631240845}, "shared": {"value": false, "score": 1.7881393432617188e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MoNoise", "normalizedForm": "MoNoise", "offsetStart": 205, "offsetEnd": 212}, "context": "In order to have a more balanced comparison, we compare our system to the MoNoise model after removing the feature that has the most impact, according to the original paper: the n-gram module (referred as MoNoise no n-gram). ", "mentionContextAttributes": {"used": {"value": false, "score": 0.40360909700393677}, "created": {"value": false, "score": 0.002656280994415283}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.7022147178649902}, "created": {"value": true, "score": 0.9067897796630859}, "shared": {"value": false, "score": 5.960464477539062e-07}}}], "references": [], "runtime": 5948, "id": "602d9aa28538d0b49af899b502fdfd189d78b800", "metadata": {"id": "602d9aa28538d0b49af899b502fdfd189d78b800"}, "original_file_path": "../../datalake/Samuel/SOFTware-Sync/downloads/xml/hal-02294316.grobid.tei.xml", "file_name": "hal-02294316.grobid.tei.xml"}