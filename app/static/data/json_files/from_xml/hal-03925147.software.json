{"application": "software-mentions", "version": "0.8.0", "date": "2024-04-15T07:22+0000", "md5": "FFF6E93C0F986D3B336E4FD72CB37E52", "mentions": [{"type": "software", "software-type": "software", "software-name": {"rawForm": "SpaCy", "normalizedForm": "SpaCy", "offsetStart": 7, "offsetEnd": 12}, "context": "We use SpaCy to identify tokens' parents, and SpanBERT Large encoder to acquire tokens' embeddings. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999673962593079}, "created": {"value": false, "score": 2.4378299713134766e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999876618385315}, "created": {"value": false, "score": 0.009006142616271973}, "shared": {"value": false, "score": 5.364418029785156e-07}}}, {"type": "software", "software-type": "software", "wikidataId": "Q22826110", "wikipediaExternalRef": 49489032, "lang": "en", "confidence": 0.4586, "software-name": {"rawForm": "GloVe", "normalizedForm": "GloVe", "wikidataId": "Q22826110", "wikipediaExternalRef": 49489032, "lang": "en", "confidence": 0.4586, "offsetStart": 9, "offsetEnd": 14}, "context": "Removing GloVe embeddings and leaving only BERT, SpanBERT and Numberbatch or training on more data samples also did not help.", "mentionContextAttributes": {"used": {"value": false, "score": 0.11148703098297119}, "created": {"value": false, "score": 7.450580596923828e-06}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9998912215232849}, "created": {"value": false, "score": 0.00039511919021606445}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "references": [{"label": "(Pennington et al., 2014)", "normalizedForm": "Pennington et al., 2014", "refKey": 16}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SpanBERT", "normalizedForm": "SpanBERT", "offsetStart": 11, "offsetEnd": 19}, "context": "E.g., with SpanBERT we generated clusters that included mentions like 'war' and 'peace' or 'the jamaica tourist board' and 'jamaican'. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9997333288192749}, "created": {"value": false, "score": 0.011809468269348145}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999673962593079}, "created": {"value": false, "score": 0.014082133769989014}, "shared": {"value": false, "score": 2.980232238769531e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SpaCy", "normalizedForm": "SpaCy", "offsetStart": 14, "offsetEnd": 19}, "context": "Again, we use SpaCy to extract part of speech (POS) and dependency edge (DEP) tags for tokens in segments, and Berkeley Neural Parser (Kitaev et al., 2019) to get syntactic constituents (nominal, verbal, or other). ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9964597225189209}, "created": {"value": false, "score": 2.9146671295166016e-05}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999876618385315}, "created": {"value": false, "score": 0.009006142616271973}, "shared": {"value": false, "score": 5.364418029785156e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SpaCy", "normalizedForm": "SpaCy", "offsetStart": 15, "offsetEnd": 20}, "context": "Moreover, both SpaCy and Berkeley Neural Parser may not function properly on dialogue data. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0005301237106323242}, "created": {"value": false, "score": 1.8298625946044922e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999876618385315}, "created": {"value": false, "score": 0.009006142616271973}, "shared": {"value": false, "score": 5.364418029785156e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SpanBERT", "normalizedForm": "SpanBERT", "offsetStart": 16, "offsetEnd": 24}, "context": "After replacing SpanBERT with standard BERT and simply averaging span embeddings we achieved 67.23% CoNLL F1 score on the same data. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999238848686218}, "created": {"value": false, "score": 5.781650543212891e-06}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999673962593079}, "created": {"value": false, "score": 0.014082133769989014}, "shared": {"value": false, "score": 2.980232238769531e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SpanBERT", "normalizedForm": "SpanBERT", "offsetStart": 20, "offsetEnd": 28}, "context": "We use a pretrained SpanBERT Large model to initialize the base language model.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9974535703659058}, "created": {"value": false, "score": 0.014082133769989014}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999673962593079}, "created": {"value": false, "score": 0.014082133769989014}, "shared": {"value": false, "score": 2.980232238769531e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SpanBERT", "normalizedForm": "SpanBERT", "offsetStart": 22, "offsetEnd": 30}, "context": "We suspect that since SpanBERT embeddings have high dimensionality (representing span start, span end and span head) they dominate mention representation in WCS and allow some vague semantic matches. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0002523660659790039}, "created": {"value": false, "score": 4.07099723815918e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999673962593079}, "created": {"value": false, "score": 0.014082133769989014}, "shared": {"value": false, "score": 2.980232238769531e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Berkeley", "normalizedForm": "Berkeley", "offsetStart": 25, "offsetEnd": 33}, "context": "Moreover, both SpaCy and Berkeley Neural Parser may not function properly on dialogue data. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0005301237106323242}, "created": {"value": false, "score": 1.8298625946044922e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9964597225189209}, "created": {"value": false, "score": 0.0007200241088867188}, "shared": {"value": false, "score": 2.980232238769531e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SpanBERT", "normalizedForm": "SpanBERT", "offsetStart": 26, "offsetEnd": 34}, "context": "We also experimented with SpanBERT embeddings but did not observe any improvements. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9978070259094238}, "created": {"value": false, "score": 0.002765178680419922}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999673962593079}, "created": {"value": false, "score": 0.014082133769989014}, "shared": {"value": false, "score": 2.980232238769531e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SpanBERT", "normalizedForm": "SpanBERT", "offsetStart": 26, "offsetEnd": 34}, "context": "Interestingly, when using SpanBERT instead of GloVe and standard BERT for span encoding we observed that many generated clusters contain mentions with spurious connections (e.g., 'the spirits of our people' and 'such dark superstitions' or 'the executive' and 'the company').", "mentionContextAttributes": {"used": {"value": true, "score": 0.9998912215232849}, "created": {"value": false, "score": 2.3186206817626953e-05}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999673962593079}, "created": {"value": false, "score": 0.014082133769989014}, "shared": {"value": false, "score": 2.980232238769531e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Parser", "normalizedForm": "Parser", "offsetStart": 41, "offsetEnd": 47}, "context": "Moreover, both SpaCy and Berkeley Neural Parser may not function properly on dialogue data.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0005301237106323242}, "created": {"value": false, "score": 1.8298625946044922e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9964597225189209}, "created": {"value": false, "score": 0.0007199645042419434}, "shared": {"value": false, "score": 2.980232238769531e-07}}}, {"type": "software", "software-type": "software", "wikidataId": "Q22826110", "wikipediaExternalRef": 49489032, "lang": "en", "confidence": 0.4586, "software-name": {"rawForm": "GloVe", "normalizedForm": "GloVe", "wikidataId": "Q22826110", "wikipediaExternalRef": 49489032, "lang": "en", "confidence": 0.4586, "offsetStart": 46, "offsetEnd": 51}, "context": "Interestingly, when using SpanBERT instead of GloVe and standard BERT for span encoding we observed that many generated clusters contain mentions with spurious connections (e.g., 'the spirits of our people' and 'such dark superstitions' or 'the executive' and 'the company').", "mentionContextAttributes": {"used": {"value": true, "score": 0.9998912215232849}, "created": {"value": false, "score": 2.3186206817626953e-05}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9998912215232849}, "created": {"value": false, "score": 0.00039511919021606445}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "references": [{"label": "(Pennington et al., 2014)", "normalizedForm": "Pennington et al., 2014", "refKey": 16}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SpanBERT", "normalizedForm": "SpanBERT", "offsetStart": 46, "offsetEnd": 54}, "context": "We use SpaCy to identify tokens' parents, and SpanBERT Large encoder to acquire tokens' embeddings.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999673962593079}, "created": {"value": false, "score": 2.4378299713134766e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999673962593079}, "created": {"value": false, "score": 0.014082133769989014}, "shared": {"value": false, "score": 2.980232238769531e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SpanBERT", "normalizedForm": "SpanBERT", "offsetStart": 48, "offsetEnd": 56}, "context": "E.g., when we replaced our span embeddings with SpanBERT and left the rest of the system unchanged we achieved 66.68% CoNLL F1 score when training and evaluating on the Light dataset. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9997994899749756}, "created": {"value": false, "score": 3.5703182220458984e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999673962593079}, "created": {"value": false, "score": 0.014082133769989014}, "shared": {"value": false, "score": 2.980232238769531e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SpanBERT", "normalizedForm": "SpanBERT", "offsetStart": 49, "offsetEnd": 57}, "context": "Removing GloVe embeddings and leaving only BERT, SpanBERT and Numberbatch or training on more data samples also did not help. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.11148703098297119}, "created": {"value": false, "score": 7.450580596923828e-06}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999673962593079}, "created": {"value": false, "score": 0.014082133769989014}, "shared": {"value": false, "score": 2.980232238769531e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SpaCy", "normalizedForm": "SpaCy", "offsetStart": 54, "offsetEnd": 59}, "context": "It is needed since not all mention spans extracted by SpaCy are valid referring expressions.", "mentionContextAttributes": {"used": {"value": false, "score": 0.25211501121520996}, "created": {"value": false, "score": 6.347894668579102e-05}, "shared": {"value": false, "score": 4.172325134277344e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999876618385315}, "created": {"value": false, "score": 0.009006142616271973}, "shared": {"value": false, "score": 5.364418029785156e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "OntoNotes", "normalizedForm": "OntoNotes", "offsetStart": 84, "offsetEnd": 93}, "context": "Hence, in one of the experiments we combined the output of the CCS model trained on OntoNotes that uses MiniLM (Wang et al., 2020) for mention representation with the outputs of WCS trained on the shared task data. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999255537986755}, "created": {"value": false, "score": 5.131959915161133e-05}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999851584434509}, "created": {"value": false, "score": 5.131959915161133e-05}, "shared": {"value": false, "score": 2.980232238769531e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "OntoNotes", "normalizedForm": "OntoNotes", "offsetStart": 87, "offsetEnd": 96}, "context": "We also tested a combination of WCS trained on the shared task data and CCS trained on OntoNotes as well as coref-hoi trained on a combination of dialogue and non-dialogue datasets. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999851584434509}, "created": {"value": false, "score": 3.629922866821289e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999851584434509}, "created": {"value": false, "score": 5.131959915161133e-05}, "shared": {"value": false, "score": 2.980232238769531e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "AllenNLP", "normalizedForm": "AllenNLP", "offsetStart": 96, "offsetEnd": 104}, "context": "We have also evaluated WCS in combination with a Crosslingual Coreference System (CCS) based on AllenNLP and SpaCy pipelines4 . ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9994918704032898}, "created": {"value": false, "score": 0.009006142616271973}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9994918704032898}, "created": {"value": false, "score": 0.009006142616271973}, "shared": {"value": false, "score": 2.980232238769531e-07}}}, {"type": "software", "software-type": "software", "wikidataId": "Q22826110", "wikipediaExternalRef": 49489032, "lang": "en", "confidence": 0.4586, "software-name": {"rawForm": "GloVe", "normalizedForm": "GloVe", "wikidataId": "Q22826110", "wikipediaExternalRef": 49489032, "lang": "en", "confidence": 0.4586, "offsetStart": 103, "offsetEnd": 108}, "context": "In order to represent the spans we take an average of all individual word embeddings based on BERT and GloVe correspondingly.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9993820786476135}, "created": {"value": false, "score": 9.119510650634766e-06}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9998912215232849}, "created": {"value": false, "score": 0.00039511919021606445}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "references": [{"label": "(Pennington et al., 2014)", "normalizedForm": "Pennington et al., 2014", "refKey": 16}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MiniLM", "normalizedForm": "MiniLM", "offsetStart": 104, "offsetEnd": 130}, "context": "Hence, in one of the experiments we combined the output of the CCS model trained on OntoNotes that uses MiniLM (Wang et al., 2020) for mention representation with the outputs of WCS trained on the shared task data. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999255537986755}, "created": {"value": false, "score": 5.131959915161133e-05}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999255537986755}, "created": {"value": false, "score": 5.131959915161133e-05}, "shared": {"value": false, "score": 2.980232238769531e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SpaCy", "normalizedForm": "SpaCy", "offsetStart": 109, "offsetEnd": 114}, "context": "We have also evaluated WCS in combination with a Crosslingual Coreference System (CCS) based on AllenNLP and SpaCy pipelines4 . ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9994918704032898}, "created": {"value": false, "score": 0.009006142616271973}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999876618385315}, "created": {"value": false, "score": 0.009006142616271973}, "shared": {"value": false, "score": 5.364418029785156e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Berkeley", "normalizedForm": "Berkeley", "offsetStart": 111, "offsetEnd": 119}, "context": "Again, we use SpaCy to extract part of speech (POS) and dependency edge (DEP) tags for tokens in segments, and Berkeley Neural Parser (Kitaev et al., 2019) to get syntactic constituents (nominal, verbal, or other).", "mentionContextAttributes": {"used": {"value": true, "score": 0.9964597225189209}, "created": {"value": false, "score": 2.9146671295166016e-05}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9964597225189209}, "created": {"value": false, "score": 0.0007200241088867188}, "shared": {"value": false, "score": 2.980232238769531e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SpaCy", "normalizedForm": "SpaCy", "offsetStart": 126, "offsetEnd": 155}, "context": "We trained our system using the gold mention spans to avoid any mistakes introduced by the mention extraction module and used SpaCy (Honnibal et al., 2020) for mention extraction during the test phase.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999876618385315}, "created": {"value": false, "score": 0.004514575004577637}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999876618385315}, "created": {"value": false, "score": 0.009006142616271973}, "shared": {"value": false, "score": 5.364418029785156e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Parser", "normalizedForm": "Parser", "offsetStart": 127, "offsetEnd": 155}, "context": "Again, we use SpaCy to extract part of speech (POS) and dependency edge (DEP) tags for tokens in segments, and Berkeley Neural Parser (Kitaev et al., 2019) to get syntactic constituents (nominal, verbal, or other). ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9964597225189209}, "created": {"value": false, "score": 2.9146671295166016e-05}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9964597225189209}, "created": {"value": false, "score": 0.0007199645042419434}, "shared": {"value": false, "score": 2.980232238769531e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SpaCy", "normalizedForm": "SpaCy", "offsetStart": 133, "offsetEnd": 138}, "context": "Furthermore, an investigation of the quality of the constituent types, POS and DEP tags would be beneficial, considering that we use SpaCy and Berkeley Neural Parser on dialogue data, while they were trained on text corpora.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9911592602729797}, "created": {"value": false, "score": 0.0007200241088867188}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999876618385315}, "created": {"value": false, "score": 0.009006142616271973}, "shared": {"value": false, "score": 5.364418029785156e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SpaCy", "normalizedForm": "SpaCy", "offsetStart": 140, "offsetEnd": 145}, "context": "Predicted mentions Baseline WCS (Anikina et al., 2021) and coref-hoi model (Xu and Choi, 2020) Approach 1) Extract all nominal phrases with SpaCy 2) Run WCS trained on the Shared Task dialogue data 3) Run coref-hoi with cluster merging trained on the CoNLL 2012 data 4) Combine the outputs of WCS and coref-hoi  the probability of being in that cluster is defined as the ratio of mentions that are in the same gold cluster and the current cluster over all mentions in that cluster.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9977362155914307}, "created": {"value": false, "score": 1.9669532775878906e-06}, "shared": {"value": false, "score": 5.364418029785156e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999876618385315}, "created": {"value": false, "score": 0.009006142616271973}, "shared": {"value": false, "score": 5.364418029785156e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Berkeley", "normalizedForm": "Berkeley", "offsetStart": 143, "offsetEnd": 151}, "context": "Furthermore, an investigation of the quality of the constituent types, POS and DEP tags would be beneficial, considering that we use SpaCy and Berkeley Neural Parser on dialogue data, while they were trained on text corpora.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9911592602729797}, "created": {"value": false, "score": 0.0007200241088867188}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9964597225189209}, "created": {"value": false, "score": 0.0007200241088867188}, "shared": {"value": false, "score": 2.980232238769531e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SpanBERT", "normalizedForm": "SpanBERT", "offsetStart": 144, "offsetEnd": 152}, "context": "When experimenting with WCS we tested different settings and tried replacing and adding different embeddings for mention representations (e.g., SpanBERT). ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9521916508674622}, "created": {"value": false, "score": 0.00035119056701660156}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999673962593079}, "created": {"value": false, "score": 0.014082133769989014}, "shared": {"value": false, "score": 2.980232238769531e-07}}}, {"type": "software", "software-type": "software", "wikidataId": "Q22826110", "wikipediaExternalRef": 49489032, "lang": "en", "confidence": 0.4586, "software-name": {"rawForm": "GloVe", "normalizedForm": "GloVe", "wikidataId": "Q22826110", "wikipediaExternalRef": 49489032, "lang": "en", "confidence": 0.4586, "offsetStart": 150, "offsetEnd": 155}, "context": "Unlike Anikina et al. (2021) we do not generate a new random embedding for each unknown word, but take an average embedding based on all words in the GloVe and Numberbatch vocabularies.", "mentionContextAttributes": {"used": {"value": false, "score": 0.013101458549499512}, "created": {"value": false, "score": 0.00039511919021606445}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9998912215232849}, "created": {"value": false, "score": 0.00039511919021606445}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "references": [{"label": "(Pennington et al., 2014)", "normalizedForm": "Pennington et al., 2014", "refKey": 16}]}, {"type": "software", "software-type": "software", "wikidataId": "Q22826110", "wikipediaExternalRef": 49489032, "lang": "en", "confidence": 0.4586, "software-name": {"rawForm": "GloVe", "normalizedForm": "GloVe", "wikidataId": "Q22826110", "wikipediaExternalRef": 49489032, "lang": "en", "confidence": 0.4586, "offsetStart": 157, "offsetEnd": 162}, "context": "For each mention it extracts the head and encodes it with a combination of contextual BERT embeddings (Devlin et al., 2018)  (bert-base-cased) together with GloVe (Pennington et al., 2014) and Numberbatch (Speer et al., 2017) embeddings.", "mentionContextAttributes": {"used": {"value": true, "score": 0.5818202495574951}, "created": {"value": false, "score": 1.7285346984863281e-06}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9998912215232849}, "created": {"value": false, "score": 0.00039511919021606445}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "references": [{"label": "(Pennington et al., 2014)", "normalizedForm": "Pennington et al., 2014", "refKey": 16, "offsetStart": 5791, "offsetEnd": 5816}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Parser", "normalizedForm": "Parser", "offsetStart": 159, "offsetEnd": 165}, "context": "Furthermore, an investigation of the quality of the constituent types, POS and DEP tags would be beneficial, considering that we use SpaCy and Berkeley Neural Parser on dialogue data, while they were trained on text corpora.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9911592602729797}, "created": {"value": false, "score": 0.0007199645042419434}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9964597225189209}, "created": {"value": false, "score": 0.0007199645042419434}, "shared": {"value": false, "score": 2.980232238769531e-07}}}], "references": [{"refKey": 16, "tei": "<biblStruct xml:id=\"b16\">\n\t<analytic>\n\t\t<title level=\"a\" type=\"main\">Glove: Global Vectors for Word Representation</title>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Jeffrey</forename><surname>Pennington</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Richard</forename><surname>Socher</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Christopher</forename><surname>Manning</surname></persName>\n\t\t</author>\n\t\t<idno type=\"DOI\">10.3115/v1/d14-1162</idno>\n\t</analytic>\n\t<monogr>\n\t\t<title level=\"m\">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>\n\t\t<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>\n\t\t<imprint>\n\t\t\t<publisher>Association for Computational Linguistics</publisher>\n\t\t\t<date type=\"published\" when=\"2014\">2014</date>\n\t\t\t<biblScope unit=\"page\">1543</biblScope>\n\t\t</imprint>\n\t</monogr>\n</biblStruct>\n"}], "runtime": 57577, "id": "2ab6a6e722922c67a192a27fe51812b61f131b65", "metadata": {"id": "2ab6a6e722922c67a192a27fe51812b61f131b65"}, "original_file_path": "../../datalake/Samuel/SOFTware-Sync/data/xml_not_sofctied/hal-03925147.grobid.tei.xml", "file_name": "hal-03925147.grobid.tei.xml"}