{"application": "software-mentions", "version": "0.8.0", "date": "2024-10-07T11:50+0000", "md5": "5435617B18694A2E0E4DAA49A1355219", "mentions": [{"type": "software", "software-type": "software", "software-name": {"rawForm": "SubstanReview", "normalizedForm": "SubstanReview", "offsetStart": 0, "offsetEnd": 13}, "context": "SubstanReview consists of 550 reviews from NLP conferences annotated by domain experts.", "mentionContextAttributes": {"used": {"value": false, "score": 0.2997846007347107}, "created": {"value": false, "score": 1.0728836059570312e-05}, "shared": {"value": false, "score": 9.5367431640625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999872446060181}, "created": {"value": true, "score": 0.9999120235443115}, "shared": {"value": false, "score": 4.00543212890625e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SpanBERT", "normalizedForm": "SpanBERT", "offsetStart": 0, "offsetEnd": 29}, "context": "SpanBERT (Joshi et al., 2020) modifies the pretraining objectives of BERT to better represent and predict spans of text. ", "mentionContextAttributes": {"used": {"value": false, "score": 6.246566772460938e-05}, "created": {"value": false, "score": 8.797645568847656e-05}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.6322406530380249}, "created": {"value": true, "score": 0.9904415607452393}, "shared": {"value": true, "score": 0.5894609689712524}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SciBERT", "normalizedForm": "SciBERT", "offsetStart": 0, "offsetEnd": 30}, "context": "SciBERT (Beltagy et al., 2019) uses the original BERT architecture and is pretrained on a random sample of 1.14M papers from Semantic Scholar, demonstrating strong performance on tasks from the computer science domain. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.09577065706253052}, "created": {"value": false, "score": 2.8967857360839844e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.09577065706253052}, "created": {"value": false, "score": 4.458427429199219e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SciBERT", "normalizedForm": "SciBERT", "offsetStart": 9, "offsetEnd": 16}, "context": "Although SciBERT and Span-BERT bring considerable improvements in performance compared to the original BERT, they are not able to yield as significant of a gain as RoBERTa.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00024265050888061523}, "created": {"value": false, "score": 4.458427429199219e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.09577065706253052}, "created": {"value": false, "score": 4.458427429199219e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SubstanReview", "normalizedForm": "SubstanReview", "offsetStart": 11, "offsetEnd": 24}, "context": "We release SubstanReview, a dataset of 550 peer reviews with paired claim and evidence spans annotated by domain experts. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.00040906667709350586}, "created": {"value": true, "score": 0.9937546253204346}, "shared": {"value": false, "score": 5.960464477539062e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999872446060181}, "created": {"value": true, "score": 0.9999120235443115}, "shared": {"value": false, "score": 4.00543212890625e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "lstm", "normalizedForm": "lstm", "offsetStart": 14, "offsetEnd": 18}, "context": "Bidirectional lstm-crf models for sequence tagging.", "mentionContextAttributes": {"used": {"value": false, "score": 6.413459777832031e-05}, "created": {"value": false, "score": 3.933906555175781e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.19220083951950073}, "created": {"value": false, "score": 1.2874603271484375e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "lstm", "normalizedForm": "lstm", "offsetStart": 14, "offsetEnd": 18}, "context": "Bidirectional lstm-crf models for sequence tagging.", "mentionContextAttributes": {"used": {"value": false, "score": 6.413459777832031e-05}, "created": {"value": false, "score": 3.933906555175781e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.19220083951950073}, "created": {"value": false, "score": 1.2874603271484375e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ChatGPT", "normalizedForm": "ChatGPT", "offsetStart": 14, "offsetEnd": 21}, "context": "In this case, ChatGPT is directly inquired to deal with the tasks of claim extraction and evidence linkage, without providing any prior information, results can be found in Table 6 andTable 7, respectively.", "mentionContextAttributes": {"used": {"value": false, "score": 0.025658905506134033}, "created": {"value": false, "score": 1.2159347534179688e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.99874347448349}, "created": {"value": true, "score": 0.9543251991271973}, "shared": {"value": false, "score": 1.800060272216797e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ChatGPT", "normalizedForm": "ChatGPT", "offsetStart": 18, "offsetEnd": 25}, "context": "It's evident that ChatGPT struggles to differentiate between claims and evidence and to denote their relationships.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0011730790138244629}, "created": {"value": false, "score": 0.0005058050155639648}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.99874347448349}, "created": {"value": true, "score": 0.9543251991271973}, "shared": {"value": false, "score": 1.800060272216797e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SubstanReview", "normalizedForm": "SubstanReview", "offsetStart": 20, "offsetEnd": 33}, "context": "Finally, we use the SubstanReview dataset to analyze the substantiation patterns in recent conferences.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999872446060181}, "created": {"value": false, "score": 7.510185241699219e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999872446060181}, "created": {"value": true, "score": 0.9999120235443115}, "shared": {"value": false, "score": 4.00543212890625e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ChatGPT", "normalizedForm": "ChatGPT", "offsetStart": 23, "offsetEnd": 30}, "context": "Table 7: An example of ChatGPT performing the evidence linkage task (zero-shot prompting).", "mentionContextAttributes": {"used": {"value": false, "score": 0.003199338912963867}, "created": {"value": false, "score": 9.059906005859375e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.99874347448349}, "created": {"value": true, "score": 0.9543251991271973}, "shared": {"value": false, "score": 1.800060272216797e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SpanBERT", "normalizedForm": "SpanBERT", "offsetStart": 23, "offsetEnd": 31}, "context": "https://huggingface.co/SpanBERT/ spanbert-large-cased", "mentionContextAttributes": {"used": {"value": false, "score": 0.00023025274276733398}, "created": {"value": false, "score": 2.086162567138672e-05}, "shared": {"value": true, "score": 0.5894609689712524}}, "documentContextAttributes": {"used": {"value": true, "score": 0.6322406530380249}, "created": {"value": true, "score": 0.9904415607452393}, "shared": {"value": true, "score": 0.5894609689712524}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ChatGPT", "normalizedForm": "ChatGPT", "offsetStart": 24, "offsetEnd": 31}, "context": "Table 11: An example of ChatGPT performing the evidence linkage task (few-shot prompting with task descriptions).", "mentionContextAttributes": {"used": {"value": false, "score": 0.001843869686126709}, "created": {"value": false, "score": 1.0132789611816406e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.99874347448349}, "created": {"value": true, "score": 0.9543251991271973}, "shared": {"value": false, "score": 1.800060272216797e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SubstanReview", "normalizedForm": "SubstanReview", "offsetStart": 28, "offsetEnd": 41}, "context": "We perform data analysis on SubstanReview and show interesting patterns in the substantiation level of peer reviews over recent years. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9983506202697754}, "created": {"value": false, "score": 0.0014032721519470215}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999872446060181}, "created": {"value": true, "score": 0.9999120235443115}, "shared": {"value": false, "score": 4.00543212890625e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ChatGPT", "normalizedForm": "ChatGPT", "offsetStart": 29, "offsetEnd": 36}, "context": "Results in Table 8 show that ChatGPT achieved a much better performance on the claim extraction task than the previous zero-shot case, all negative claims are correctly extracted.", "mentionContextAttributes": {"used": {"value": true, "score": 0.99874347448349}, "created": {"value": false, "score": 1.2636184692382812e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.99874347448349}, "created": {"value": true, "score": 0.9543251991271973}, "shared": {"value": false, "score": 1.800060272216797e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SpanBERT", "normalizedForm": "SpanBERT", "offsetStart": 30, "offsetEnd": 38}, "context": "Different from claim tagging, SpanBERT obtains the best results on this subtask. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.009994566440582275}, "created": {"value": false, "score": 7.033348083496094e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.6322406530380249}, "created": {"value": true, "score": 0.9904415607452393}, "shared": {"value": true, "score": 0.5894609689712524}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SubstanReview", "normalizedForm": "SubstanReview", "offsetStart": 30, "offsetEnd": 43}, "context": "In this section, we introduce SubstanReview, the first human annotated dataset for the task of claimevidence pair extraction in scientific peer reviews.", "mentionContextAttributes": {"used": {"value": false, "score": 4.4226646423339844e-05}, "created": {"value": true, "score": 0.9999120235443115}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999872446060181}, "created": {"value": true, "score": 0.9999120235443115}, "shared": {"value": false, "score": 4.00543212890625e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ChatGPT", "normalizedForm": "ChatGPT", "offsetStart": 31, "offsetEnd": 38}, "context": "For the evidence linkage task, ChatGPT fails completely. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0043634772300720215}, "created": {"value": false, "score": 2.6226043701171875e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.99874347448349}, "created": {"value": true, "score": 0.9543251991271973}, "shared": {"value": false, "score": 1.800060272216797e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ChatGPT", "normalizedForm": "ChatGPT", "offsetStart": 36, "offsetEnd": 43}, "context": "The above examples demonstrate that ChatGPT is not able to achieve a satisfactory performance, with both specifically designed zero-shot and few-shot prompts, which highlights the need of our annotated data for instruction-tuning, and the persistent superiority of classical task-specific fine-tuned model as proposed in our work.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0002116560935974121}, "created": {"value": false, "score": 0.020639240741729736}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.99874347448349}, "created": {"value": true, "score": 0.9543251991271973}, "shared": {"value": false, "score": 1.800060272216797e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SpanBERT", "normalizedForm": "SpanBERT", "offsetStart": 36, "offsetEnd": 44}, "context": "We choose to include the fine-tuned SpanBERT model for evidence linkage in our final system.", "mentionContextAttributes": {"used": {"value": true, "score": 0.6322406530380249}, "created": {"value": true, "score": 0.9904415607452393}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.6322406530380249}, "created": {"value": true, "score": 0.9904415607452393}, "shared": {"value": true, "score": 0.5894609689712524}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SubstanReview", "normalizedForm": "SubstanReview", "offsetStart": 37, "offsetEnd": 50}, "context": "We also perform data analysis on the SubstanReview dataset to obtain meaningful insights on peer reviewing quality in NLP conferences over recent years.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9754676222801208}, "created": {"value": false, "score": 0.11818128824234009}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999872446060181}, "created": {"value": true, "score": 0.9999120235443115}, "shared": {"value": false, "score": 4.00543212890625e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "doccano 3", "normalizedForm": "doccano 3", "offsetStart": 40, "offsetEnd": 49}, "context": "with the open-source data labeling tool doccano 3 . ", "mentionContextAttributes": {"used": {"value": false, "score": 0.1558026671409607}, "created": {"value": false, "score": 0.00010859966278076172}, "shared": {"value": false, "score": 1.4901161193847656e-05}}, "documentContextAttributes": {"used": {"value": false, "score": 0.1558026671409607}, "created": {"value": false, "score": 0.00010859966278076172}, "shared": {"value": false, "score": 1.4901161193847656e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ChatGPT", "normalizedForm": "ChatGPT", "offsetStart": 44, "offsetEnd": 51}, "context": "The examples in Appendix C demonstrate that ChatGPT is not able to achieve satisfactory performance, with both specifically designed zero-shot and few-shot prompts, which highlights the need of our annotated data for instruction-tuning, and the superiority of classical task-specific fine-tuned models as proposed in our work.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0008018612861633301}, "created": {"value": false, "score": 0.023555994033813477}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.99874347448349}, "created": {"value": true, "score": 0.9543251991271973}, "shared": {"value": false, "score": 1.800060272216797e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ChatGPT", "normalizedForm": "ChatGPT", "offsetStart": 47, "offsetEnd": 54}, "context": "In this section, we conduct a case study using ChatGPT (May 24, 2023 version) through the platform10 provided by OpenAI. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9942150712013245}, "created": {"value": false, "score": 0.027338624000549316}, "shared": {"value": false, "score": 1.800060272216797e-05}}, "documentContextAttributes": {"used": {"value": true, "score": 0.99874347448349}, "created": {"value": true, "score": 0.9543251991271973}, "shared": {"value": false, "score": 1.800060272216797e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ChatGPT", "normalizedForm": "ChatGPT", "offsetStart": 47, "offsetEnd": 54}, "context": "For the claim extraction task, we observe that ChatGPT cannot distinguish between subjective claims and evidence.", "mentionContextAttributes": {"used": {"value": false, "score": 0.21476298570632935}, "created": {"value": false, "score": 0.0002754330635070801}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.99874347448349}, "created": {"value": true, "score": 0.9543251991271973}, "shared": {"value": false, "score": 1.800060272216797e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "lstm", "normalizedForm": "lstm", "offsetStart": 48, "offsetEnd": 52}, "context": "End-to-end sequence labeling via bi-directional lstm-cnnscrf. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.19220083951950073}, "created": {"value": false, "score": 1.2874603271484375e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.19220083951950073}, "created": {"value": false, "score": 1.2874603271484375e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SubstanReview", "normalizedForm": "SubstanReview", "offsetStart": 54, "offsetEnd": 67}, "context": "Table 1: Example of an annotated peer review from the SubstanReview dataset.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0870504379272461}, "created": {"value": false, "score": 1.8596649169921875e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999872446060181}, "created": {"value": true, "score": 0.9999120235443115}, "shared": {"value": false, "score": 4.00543212890625e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SubstanReview", "normalizedForm": "SubstanReview", "offsetStart": 57, "offsetEnd": 70}, "context": "In addition to the transformer-based models finetuned on SubstanReview, we also compute a baseline for both of the subtasks. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.6530514359474182}, "created": {"value": false, "score": 0.00014126300811767578}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999872446060181}, "created": {"value": true, "score": 0.9999120235443115}, "shared": {"value": false, "score": 4.00543212890625e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ChatGPT", "normalizedForm": "ChatGPT", "offsetStart": 60, "offsetEnd": 67}, "context": "In this case, on the basis of the previous prompts, we give ChatGPT more information by providing expected claim and evidence extractions for one example review (see Table 13).", "mentionContextAttributes": {"used": {"value": false, "score": 0.056713223457336426}, "created": {"value": false, "score": 2.8014183044433594e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.99874347448349}, "created": {"value": true, "score": 0.9543251991271973}, "shared": {"value": false, "score": 1.800060272216797e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SubstanReview", "normalizedForm": "SubstanReview", "offsetStart": 62, "offsetEnd": 75}, "context": "We then annotate and release the first dataset for this task: SubstanReview. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0014235973358154297}, "created": {"value": true, "score": 0.9575852751731873}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999872446060181}, "created": {"value": true, "score": 0.9999120235443115}, "shared": {"value": false, "score": 4.00543212890625e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ChatGPT", "normalizedForm": "ChatGPT", "offsetStart": 67, "offsetEnd": 98}, "context": "Therefore, we complete our work by providing a case study of using ChatGPT9  (Ouyang et al., 2022) to tackle our claim-evidence pair extraction task. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.1209714412689209}, "created": {"value": true, "score": 0.9543251991271973}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.99874347448349}, "created": {"value": true, "score": 0.9543251991271973}, "shared": {"value": false, "score": 1.800060272216797e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SubstanReview", "normalizedForm": "SubstanReview", "offsetStart": 78, "offsetEnd": 91}, "context": "For this purpose, we ask all annotators to participate in the creation of the SubstanReview dataset, which will eventually be publicly released for research purposes.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0010595917701721191}, "created": {"value": true, "score": 0.8311378955841064}, "shared": {"value": false, "score": 4.00543212890625e-05}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999872446060181}, "created": {"value": true, "score": 0.9999120235443115}, "shared": {"value": false, "score": 4.00543212890625e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SubstanReview", "normalizedForm": "SubstanReview", "offsetStart": 110, "offsetEnd": 123}, "context": "We tackle the claim-evidence pair extraction task formulated in Section 3.2 and construct a benchmark for the SubstanReview dataset.", "mentionContextAttributes": {"used": {"value": true, "score": 0.6522906422615051}, "created": {"value": true, "score": 0.9236936569213867}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999872446060181}, "created": {"value": true, "score": 0.9999120235443115}, "shared": {"value": false, "score": 4.00543212890625e-05}}}], "references": [], "runtime": 7290, "id": "7bb25223cae15295a0b6e146adbe2d5bbe8e289e", "metadata": {"id": "7bb25223cae15295a0b6e146adbe2d5bbe8e289e"}, "original_file_path": "../../datalake/Samuel/SOFTware-Sync/downloads/xml/hal-04593403.grobid.tei.xml", "file_name": "hal-04593403.grobid.tei.xml"}