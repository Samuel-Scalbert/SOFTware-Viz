{"application": "software-mentions", "version": "0.8.0", "date": "2024-10-07T12:48+0000", "md5": "F686BD4655256CEF08DFD0E26306270D", "mentions": [{"type": "software", "software-type": "software", "software-name": {"rawForm": "VoxCeleb", "normalizedForm": "VoxCeleb", "offsetStart": 0, "offsetEnd": 8}, "context": "VoxCeleb 1 (Nagrani et al. 2017 Before scoring with Gaussian PLDA model (Prince and Elder 2007) trained from the x-vectors extracted from VoxCeleb, conversation-dependent PCA (Zhu and Pelecanos 2016) preserving 30% of the total variability is used for dimensionality reduction. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999099969863892}, "created": {"value": false, "score": 1.9073486328125e-06}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999872446060181}, "created": {"value": false, "score": 6.794929504394531e-06}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "references": [{"label": "(Nagrani et al. 2017", "normalizedForm": "(Nagrani et al. 2017", "refKey": 29, "offsetStart": 16675, "offsetEnd": 16695}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "OpenL3", "normalizedForm": "OpenL3", "offsetStart": 36, "offsetEnd": 42}, "context": "Our study reveals that i-vector and OpenL3 embedding based method achieves considerably better performance than x-vector based approach in the third DIHARD challenge dataset.", "mentionContextAttributes": {"used": {"value": false, "score": 0.006108283996582031}, "created": {"value": false, "score": 0.0065531134605407715}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999247789382935}, "created": {"value": false, "score": 0.0065531134605407715}, "shared": {"value": true, "score": 0.6718413829803467}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "OpenL3", "normalizedForm": "OpenL3", "offsetStart": 39, "offsetEnd": 45}, "context": "The figure shows that the i-vector and OpenL3 systems are substantially better than the x-vector system for ADI on the DI-HARD III dataset.", "mentionContextAttributes": {"used": {"value": true, "score": 0.6263412237167358}, "created": {"value": false, "score": 5.793571472167969e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999247789382935}, "created": {"value": false, "score": 0.0065531134605407715}, "shared": {"value": true, "score": 0.6718413829803467}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "L3-net", "normalizedForm": "L3-net", "offsetStart": 83, "offsetEnd": 89}, "context": "Without needing annotated data and a relatively simple convolutional architecture, L3-net successfully produced powerful embeddings that led to state-of-the-art sound classification performance. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.002581357955932617}, "created": {"value": false, "score": 0.0025727152824401855}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.002581357955932617}, "created": {"value": false, "score": 0.0025727152824401855}, "shared": {"value": false, "score": 1.1920928955078125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "VoxCeleb", "normalizedForm": "VoxCeleb", "offsetStart": 115, "offsetEnd": 123}, "context": "To extract utterance-level embeddings for the ADI task, we used pretrained x-vector and i-vector models trained on VoxCeleb audio-data2 .", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999872446060181}, "created": {"value": false, "score": 6.794929504394531e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999872446060181}, "created": {"value": false, "score": 6.794929504394531e-06}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "references": [{"label": "(Nagrani et al. 2017", "normalizedForm": "(Nagrani et al. 2017", "refKey": 29}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "OpenL3", "normalizedForm": "OpenL3", "offsetStart": 120, "offsetEnd": 127}, "context": "Pretrained versions of the L3-Net variants studied in (Cramer et al. 2019) are made freely available online by the name OpenL33 . ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0013898611068725586}, "created": {"value": false, "score": 0.003101348876953125}, "shared": {"value": true, "score": 0.6718413829803467}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999247789382935}, "created": {"value": false, "score": 0.0065531134605407715}, "shared": {"value": true, "score": 0.6718413829803467}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "OpenL3", "normalizedForm": "OpenL3", "offsetStart": 138, "offsetEnd": 144}, "context": "For instance, the average domain classification accuracy over 1000 repetitions was 91.11%, 72.98%, and 89.64% for i-vector, x-vector, and OpenL3 systems, respectively.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9958698153495789}, "created": {"value": false, "score": 4.029273986816406e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999247789382935}, "created": {"value": false, "score": 0.0065531134605407715}, "shared": {"value": true, "score": 0.6718413829803467}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "VoxCeleb", "normalizedForm": "VoxCeleb", "offsetStart": 138, "offsetEnd": 146}, "context": "VoxCeleb 1 (Nagrani et al. 2017 Before scoring with Gaussian PLDA model (Prince and Elder 2007) trained from the x-vectors extracted from VoxCeleb, conversation-dependent PCA (Zhu and Pelecanos 2016) preserving 30% of the total variability is used for dimensionality reduction. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999099969863892}, "created": {"value": false, "score": 1.9073486328125e-06}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999872446060181}, "created": {"value": false, "score": 6.794929504394531e-06}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "references": [{"label": "(Nagrani et al. 2017", "normalizedForm": "(Nagrani et al. 2017", "refKey": 29}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "OpenL3", "normalizedForm": "OpenL3", "offsetStart": 351, "offsetEnd": 357}, "context": "The baseline systems provided with the ASC task of the DCASE challenges have ranged from Mel-frequency cepstral coefficients (MFCC)-GMM based systems (Giannoulis et al. 2013;Mesaros et al. 2016), log mel-band energy with mulltilayer perceptron (MLP) (Mesaros et al. 2018a), with convolutional neural network (CNN) (Mesaros et al. 2018b, Oct. 2019) to OpenL3 embeddings with two fully-connected feed-forward layers (Heittola et al. 2020).", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999247789382935}, "created": {"value": false, "score": 5.364418029785156e-06}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999247789382935}, "created": {"value": false, "score": 0.0065531134605407715}, "shared": {"value": true, "score": 0.6718413829803467}}}], "references": [{"refKey": 29, "tei": "<biblStruct xml:id=\"b29\">\n\t<analytic>\n\t\t<title level=\"a\" type=\"main\">VoxCeleb: A Large-Scale Speaker Identification Dataset</title>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Arsha</forename><surname>Nagrani</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Joon</forename><forename type=\"middle\">Son</forename><surname>Chung</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Andrew</forename><surname>Zisserman</surname></persName>\n\t\t</author>\n\t\t<idno type=\"DOI\">10.21437/interspeech.2017-950</idno>\n\t</analytic>\n\t<monogr>\n\t\t<title level=\"m\">Interspeech 2017</title>\n\t\t<imprint>\n\t\t\t<publisher>ISCA</publisher>\n\t\t\t<date type=\"published\" when=\"2017-08-20\">2017</date>\n\t\t\t<biblScope unit=\"page\">2620</biblScope>\n\t\t</imprint>\n\t</monogr>\n</biblStruct>\n"}], "runtime": 6993, "id": "2e7c325f65bf1f2f1bd5e891b9f390380ce55370", "metadata": {"id": "2e7c325f65bf1f2f1bd5e891b9f390380ce55370"}, "original_file_path": "../../datalake/Samuel/SOFTware-Sync/downloads/xml/hal-03719697.grobid.tei.xml", "file_name": "hal-03719697.grobid.tei.xml"}