{"application": "software-mentions", "version": "0.8.0", "date": "2024-04-12T16:17+0000", "md5": "C9D97ED9B89DAF1ADD29B3D089D60A52", "mentions": [{"type": "software", "software-type": "software", "software-name": {"rawForm": "BirdCLEF", "normalizedForm": "BirdCLEF", "offsetStart": 3, "offsetEnd": 11}, "context": "2. BirdCLEF 2021: Bird species recognition in audio soundscapes.", "mentionContextAttributes": {"used": {"value": false, "score": 0.000644981861114502}, "created": {"value": false, "score": 0.0001304149627685547}, "shared": {"value": false, "score": 5.364418029785156e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9994792342185974}, "created": {"value": false, "score": 0.026143431663513184}, "shared": {"value": false, "score": 2.205371856689453e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SnakeCLEF", "normalizedForm": "SnakeCLEF", "offsetStart": 3, "offsetEnd": 12}, "version": {"rawForm": "2021", "normalizedForm": "2021", "offsetStart": 13, "offsetEnd": 17}, "context": "4. SnakeCLEF 2021: Automated snake species identification with Country-Level Focus.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0011778473854064941}, "created": {"value": false, "score": 2.0444393157958984e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9994792342185974}, "created": {"value": false, "score": 0.015550613403320312}, "shared": {"value": false, "score": 4.172325134277344e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LifeCLEF", "normalizedForm": "LifeCLEF", "offsetStart": 4, "offsetEnd": 12}, "version": {"rawForm": "2021", "normalizedForm": "2021"}, "context": "The LifeCLEF Bird Recognition Challenge (BirdCLEF) launched in 2014 and has since become the largest bird sound recognition challenge in terms of dataset size and species diversity with multiple tens of thousands of recordings covering up to 1,500 species [17,30,32].", "mentionContextAttributes": {"used": {"value": false, "score": 0.0022464990615844727}, "created": {"value": false, "score": 0.0005173087120056152}, "shared": {"value": false, "score": 1.3709068298339844e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997944831848145}, "created": {"value": false, "score": 0.012605786323547363}, "shared": {"value": false, "score": 1.8477439880371094e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LifeCLEF", "normalizedForm": "LifeCLEF", "offsetStart": 12, "offsetEnd": 20}, "version": {"rawForm": "2021", "normalizedForm": "2021"}, "context": "Since 2014, LifeCLEF expanded the challenge by considering animals in addition to plants, and including audio and video content in addition to images [23,24,25,26,27,28,29]. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0002695322036743164}, "created": {"value": false, "score": 0.00010067224502563477}, "shared": {"value": false, "score": 4.172325134277344e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997944831848145}, "created": {"value": false, "score": 0.012605786323547363}, "shared": {"value": false, "score": 1.8477439880371094e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LifeCLEF", "normalizedForm": "LifeCLEF", "offsetStart": 18, "offsetEnd": 26}, "version": {"rawForm": "2018", "normalizedForm": "2018", "offsetStart": 27, "offsetEnd": 31}, "context": "In the context of LifeCLEF 2018, we measured a top-1 classification accuracy over 10K species up to 90 % and we showed that automated systems are not so far from human expertise [23]. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9997944831848145}, "created": {"value": false, "score": 2.2590160369873047e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997944831848145}, "created": {"value": false, "score": 0.012605786323547363}, "shared": {"value": false, "score": 1.8477439880371094e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "PlantCLEF", "normalizedForm": "PlantCLEF", "offsetStart": 19, "offsetEnd": 28}, "version": {"rawForm": "2021", "normalizedForm": "2021"}, "context": "The most difficult PlantCLEF challenge ever. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.01563858985900879}, "created": {"value": false, "score": 0.00016641616821289062}, "shared": {"value": false, "score": 1.2516975402832031e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999504685401917}, "created": {"value": false, "score": 0.05250817537307739}, "shared": {"value": false, "score": 1.2516975402832031e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "BirdCLEF", "normalizedForm": "BirdCLEF", "offsetStart": 28, "offsetEnd": 36}, "context": "Xenocanto data was used for BirdCLEF in all past editions to provide researchers with large and diverse datasets for training and testing.", "mentionContextAttributes": {"used": {"value": true, "score": 0.6625871062278748}, "created": {"value": false, "score": 3.737211227416992e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9994792342185974}, "created": {"value": false, "score": 0.026143431663513184}, "shared": {"value": false, "score": 2.205371856689453e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "PlantCLEF", "normalizedForm": "PlantCLEF", "offsetStart": 34, "offsetEnd": 43}, "version": {"rawForm": "2021", "normalizedForm": "2021", "offsetStart": 54, "offsetEnd": 58}, "context": "About 40 teams registered for the PlantCLEF challenge 2021 (PC21) and 4 of them finally submitted runs, i.e. files containing the predictions of the system(s) they ran. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9947588443756104}, "created": {"value": false, "score": 5.561113357543945e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999504685401917}, "created": {"value": false, "score": 0.05250817537307739}, "shared": {"value": false, "score": 1.2516975402832031e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MobileNet", "normalizedForm": "MobileNet", "offsetStart": 34, "offsetEnd": 43}, "context": "Off-the-shelve architectures like MobileNet, EfficientNet, or DenseNet all seem to perform well on this task. ", "mentionContextAttributes": {"used": {"value": false, "score": 6.347894668579102e-05}, "created": {"value": false, "score": 0.00255739688873291}, "shared": {"value": false, "score": 5.364418029785156e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 6.347894668579102e-05}, "created": {"value": false, "score": 0.00255739688873291}, "shared": {"value": false, "score": 5.364418029785156e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "BirdCLEF", "normalizedForm": "BirdCLEF", "offsetStart": 37, "offsetEnd": 45}, "context": "The main goal of the 2021 edition of BirdCLEF was to open the field of bird song identification to a broader audience by providing both a challenging research task and a low barrier to entry. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0014020204544067383}, "created": {"value": false, "score": 0.026143431663513184}, "shared": {"value": false, "score": 2.205371856689453e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9994792342185974}, "created": {"value": false, "score": 0.026143431663513184}, "shared": {"value": false, "score": 2.205371856689453e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SnakeCLEF", "normalizedForm": "SnakeCLEF", "offsetStart": 39, "offsetEnd": 48}, "version": {"rawForm": "2021", "normalizedForm": "2021"}, "context": "A total of 7 teams participated in the SnakeCLEF 2021 challenge and submitted a total of 46 runs. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9848153591156006}, "created": {"value": false, "score": 0.0005106329917907715}, "shared": {"value": false, "score": 4.172325134277344e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9994792342185974}, "created": {"value": false, "score": 0.015550613403320312}, "shared": {"value": false, "score": 4.172325134277344e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "PlantCLEF", "normalizedForm": "PlantCLEF", "offsetStart": 40, "offsetEnd": 49}, "version": {"rawForm": "2021", "normalizedForm": "2021"}, "context": "Thus, the 2020 and 2021 editions of the PlantCLEF challenge were designed to evaluate to what extent automated plant species identification on tropical data deficient regions can be improved by the use of herbarium sheets.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00025665760040283203}, "created": {"value": false, "score": 0.05250817537307739}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999504685401917}, "created": {"value": false, "score": 0.05250817537307739}, "shared": {"value": false, "score": 1.2516975402832031e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "BirdCLEF", "normalizedForm": "BirdCLEF", "offsetStart": 41, "offsetEnd": 49}, "context": "The LifeCLEF Bird Recognition Challenge (BirdCLEF) launched in 2014 and has since become the largest bird sound recognition challenge in terms of dataset size and species diversity with multiple tens of thousands of recordings covering up to 1,500 species [17,30,32].", "mentionContextAttributes": {"used": {"value": false, "score": 0.0022464990615844727}, "created": {"value": false, "score": 0.0005173087120056152}, "shared": {"value": false, "score": 1.3709068298339844e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9994792342185974}, "created": {"value": false, "score": 0.026143431663513184}, "shared": {"value": false, "score": 2.205371856689453e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "BirdCLEF", "normalizedForm": "BirdCLEF", "offsetStart": 44, "offsetEnd": 52}, "context": "On the contrary, the 50 best methods of the BirdCLEF sound recognition task are solely based on convolutional neural networks ensembles. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0024541616439819336}, "created": {"value": false, "score": 6.181001663208008e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9994792342185974}, "created": {"value": false, "score": 0.026143431663513184}, "shared": {"value": false, "score": 2.205371856689453e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LifeCLEF", "normalizedForm": "LifeCLEF", "offsetStart": 44, "offsetEnd": 52}, "version": {"rawForm": "2021", "normalizedForm": "2021"}, "context": "In total, 834 teams/persons participated to LifeCLEF 2021 edition by submitting runs to at least one of the four challenges.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9875909686088562}, "created": {"value": false, "score": 0.00016689300537109375}, "shared": {"value": false, "score": 7.748603820800781e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997944831848145}, "created": {"value": false, "score": 0.012605786323547363}, "shared": {"value": false, "score": 1.8477439880371094e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LifeCLEF", "normalizedForm": "LifeCLEF", "offsetStart": 48, "offsetEnd": 56}, "version": {"rawForm": "2021", "normalizedForm": "2021"}, "context": "One of the main new outcomes of this edition of LifeCLEF is the appearance of Visual Transformers among the best models of the SnakeCLEF task, which is the most straightforward task of LifeCLEF to experiment this new type of models. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0005394220352172852}, "created": {"value": false, "score": 0.012605786323547363}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997944831848145}, "created": {"value": false, "score": 0.012605786323547363}, "shared": {"value": false, "score": 1.8477439880371094e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LifeCLEF", "normalizedForm": "LifeCLEF", "offsetStart": 49, "offsetEnd": 57}, "version": {"rawForm": "2021", "normalizedForm": "2021", "offsetStart": 58, "offsetEnd": 62}, "context": "Four challenges were evaluated in the context of LifeCLEF 2021 edition: 1. PlantCLEF 2021: Identifying plant pictures from herbarium sheets. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9903839826583862}, "created": {"value": false, "score": 4.947185516357422e-06}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997944831848145}, "created": {"value": false, "score": 0.012605786323547363}, "shared": {"value": false, "score": 1.8477439880371094e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "BirdCLEF", "normalizedForm": "BirdCLEF", "offsetStart": 62, "offsetEnd": 70}, "context": "1,004 participants from 70 countries on 816 teams entered the BirdCLEF 2021 competition and submitted a total of 9,307 runs.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9876531362533569}, "created": {"value": false, "score": 4.571676254272461e-05}, "shared": {"value": false, "score": 7.748603820800781e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9994792342185974}, "created": {"value": false, "score": 0.026143431663513184}, "shared": {"value": false, "score": 2.205371856689453e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "PlantCLEF", "normalizedForm": "PlantCLEF", "offsetStart": 64, "offsetEnd": 73}, "version": {"rawForm": "2020", "normalizedForm": "2020", "offsetStart": 73, "offsetEnd": 77}, "context": "Complementary runs based on the best performing approach during PlantCLEF2020 (a Few Shot Adversarial Domain Adaptation approach -FSADA - [53]) were also submitted by the organisers. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9985294938087463}, "created": {"value": false, "score": 1.0192394256591797e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999504685401917}, "created": {"value": false, "score": 0.05250817537307739}, "shared": {"value": false, "score": 1.2516975402832031e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LifeCLEF", "normalizedForm": "LifeCLEF", "offsetStart": 70, "offsetEnd": 79}, "version": {"rawForm": "2021", "normalizedForm": "2021"}, "context": "In order to measure progress in a sustainable and repeatable way, the LifeCLEF2 research platform was created in 2014 as a continuation and extension of the plant identification task that had been run within the ImageCLEF lab 3 since 2011 [14,15,16]. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0009108781814575195}, "created": {"value": false, "score": 0.010536909103393555}, "shared": {"value": false, "score": 1.8477439880371094e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997944831848145}, "created": {"value": false, "score": 0.012605786323547363}, "shared": {"value": false, "score": 1.8477439880371094e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "PlantCLEF", "normalizedForm": "PlantCLEF", "offsetStart": 75, "offsetEnd": 84}, "version": {"rawForm": "2021", "normalizedForm": "2021", "offsetStart": 85, "offsetEnd": 89}, "context": "Four challenges were evaluated in the context of LifeCLEF 2021 edition: 1. PlantCLEF 2021: Identifying plant pictures from herbarium sheets. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9903839826583862}, "created": {"value": false, "score": 4.947185516357422e-06}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999504685401917}, "created": {"value": false, "score": 0.05250817537307739}, "shared": {"value": false, "score": 1.2516975402832031e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "PlantCLEF", "normalizedForm": "PlantCLEF", "offsetStart": 75, "offsetEnd": 84}, "version": {"rawForm": "2021", "normalizedForm": "2021", "offsetStart": 84, "offsetEnd": 88}, "context": "Fig. 2: Density grid maps of the number of species of geolocated plants in PlantCLEF2021. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9980475306510925}, "created": {"value": false, "score": 9.47713851928711e-06}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999504685401917}, "created": {"value": false, "score": 0.05250817537307739}, "shared": {"value": false, "score": 1.2516975402832031e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "PlantCLEF", "normalizedForm": "PlantCLEF", "offsetStart": 119, "offsetEnd": 128}, "version": {"rawForm": "2021", "normalizedForm": "2021"}, "context": "The system used to run the challenges (registration, submission, leaderboard, etc.) was the AICrowd platform 4 for the PlantCLEF and ths SnakeCLEF challenge and the Kaggle platform 5 for GeoLifeCLEF and BirdCLEF challenges.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9994792342185974}, "created": {"value": false, "score": 0.0001323223114013672}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999504685401917}, "created": {"value": false, "score": 0.05250817537307739}, "shared": {"value": false, "score": 1.2516975402832031e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SnakeCLEF", "normalizedForm": "SnakeCLEF", "offsetStart": 127, "offsetEnd": 136}, "version": {"rawForm": "2021", "normalizedForm": "2021"}, "context": "One of the main new outcomes of this edition of LifeCLEF is the appearance of Visual Transformers among the best models of the SnakeCLEF task, which is the most straightforward task of LifeCLEF to experiment this new type of models. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0005394220352172852}, "created": {"value": false, "score": 0.012605786323547363}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9994792342185974}, "created": {"value": false, "score": 0.015550613403320312}, "shared": {"value": false, "score": 4.172325134277344e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SnakeCLEF", "normalizedForm": "SnakeCLEF", "offsetStart": 137, "offsetEnd": 146}, "version": {"rawForm": "2021", "normalizedForm": "2021"}, "context": "The system used to run the challenges (registration, submission, leaderboard, etc.) was the AICrowd platform 4 for the PlantCLEF and ths SnakeCLEF challenge and the Kaggle platform 5 for GeoLifeCLEF and BirdCLEF challenges.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9994792342185974}, "created": {"value": false, "score": 0.0001323223114013672}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9994792342185974}, "created": {"value": false, "score": 0.015550613403320312}, "shared": {"value": false, "score": 4.172325134277344e-07}}}, {"type": "software", "software-type": "software", "wikidataId": "Q182496", "wikipediaExternalRef": 4325491, "lang": "en", "confidence": 0.566, "software-name": {"rawForm": "Bing", "normalizedForm": "Bing", "wikidataId": "Q182496", "wikipediaExternalRef": 4325491, "lang": "en", "confidence": 0.566, "offsetStart": 169, "offsetEnd": 173}, "context": "They were selected based on the most comprehensive estimates of the available amount of field pictures from different data sources (IdigBio, GBIF, Encyclopedia of Life, Bing and Google Image search engines, previous datasets related to PlantCLEF and ExpertCLEF challenges). ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999504685401917}, "created": {"value": false, "score": 7.301568984985352e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999504685401917}, "created": {"value": false, "score": 7.301568984985352e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LifeCLEF", "normalizedForm": "LifeCLEF", "offsetStart": 185, "offsetEnd": 193}, "version": {"rawForm": "2021", "normalizedForm": "2021"}, "context": "One of the main new outcomes of this edition of LifeCLEF is the appearance of Visual Transformers among the best models of the SnakeCLEF task, which is the most straightforward task of LifeCLEF to experiment this new type of models. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0005394220352172852}, "created": {"value": false, "score": 0.012605786323547363}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997944831848145}, "created": {"value": false, "score": 0.012605786323547363}, "shared": {"value": false, "score": 1.8477439880371094e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SnakeCLEF", "normalizedForm": "SnakeCLEF", "offsetStart": 200, "offsetEnd": 209}, "version": {"rawForm": "2021", "normalizedForm": "2021"}, "context": "The main goal of this challenge was to build a system that is capable of recognizing 772 snake species based on the given unseen image and Fig. 11: Percentage of snake species per country included in SnakeCLEF2021.", "mentionContextAttributes": {"used": {"value": false, "score": 0.07810848951339722}, "created": {"value": false, "score": 0.015550613403320312}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9994792342185974}, "created": {"value": false, "score": 0.015550613403320312}, "shared": {"value": false, "score": 4.172325134277344e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LifeCLEF", "normalizedForm": "LifeCLEF", "offsetStart": 201, "offsetEnd": 209}, "version": {"rawForm": "2021", "normalizedForm": "2021", "offsetStart": 210, "offsetEnd": 214}, "context": "The micro F1-score as harmonic mean of the micro-precision and micro-recall for each segment is defined as: Fig. 5: Scores achieved by the best systems evaluated within the bird identification task of LifeCLEF 2021.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9996682405471802}, "created": {"value": false, "score": 4.470348358154297e-06}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997944831848145}, "created": {"value": false, "score": 0.012605786323547363}, "shared": {"value": false, "score": 1.8477439880371094e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "BirdCLEF", "normalizedForm": "BirdCLEF", "offsetStart": 203, "offsetEnd": 211}, "context": "The system used to run the challenges (registration, submission, leaderboard, etc.) was the AICrowd platform 4 for the PlantCLEF and ths SnakeCLEF challenge and the Kaggle platform 5 for GeoLifeCLEF and BirdCLEF challenges.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9994792342185974}, "created": {"value": false, "score": 0.0001323223114013672}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9994792342185974}, "created": {"value": false, "score": 0.026143431663513184}, "shared": {"value": false, "score": 2.205371856689453e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ImageCLEF", "normalizedForm": "ImageCLEF", "offsetStart": 212, "offsetEnd": 221}, "context": "In order to measure progress in a sustainable and repeatable way, the LifeCLEF2 research platform was created in 2014 as a continuation and extension of the plant identification task that had been run within the ImageCLEF lab 3 since 2011 [14,15,16]. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0009108781814575195}, "created": {"value": false, "score": 0.010536909103393555}, "shared": {"value": false, "score": 1.8477439880371094e-06}}, "documentContextAttributes": {"used": {"value": false, "score": 0.0009108781814575195}, "created": {"value": false, "score": 0.010536909103393555}, "shared": {"value": false, "score": 1.8477439880371094e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "PlantCLEF", "normalizedForm": "PlantCLEF", "offsetStart": 236, "offsetEnd": 245}, "version": {"rawForm": "2021", "normalizedForm": "2021"}, "context": "They were selected based on the most comprehensive estimates of the available amount of field pictures from different data sources (IdigBio, GBIF, Encyclopedia of Life, Bing and Google Image search engines, previous datasets related to PlantCLEF and ExpertCLEF challenges). ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999504685401917}, "created": {"value": false, "score": 7.301568984985352e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999504685401917}, "created": {"value": false, "score": 0.05250817537307739}, "shared": {"value": false, "score": 1.2516975402832031e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ExpertCLEF", "normalizedForm": "ExpertCLEF", "offsetStart": 250, "offsetEnd": 260}, "context": "They were selected based on the most comprehensive estimates of the available amount of field pictures from different data sources (IdigBio, GBIF, Encyclopedia of Life, Bing and Google Image search engines, previous datasets related to PlantCLEF and ExpertCLEF challenges). ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999505281448364}, "created": {"value": false, "score": 7.295608520507812e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999505281448364}, "created": {"value": false, "score": 7.295608520507812e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}}], "references": [], "runtime": 99267, "id": "3835250ab509b3788c76e0ce9adda388d04b3864", "metadata": {"id": "3835250ab509b3788c76e0ce9adda388d04b3864"}, "original_file_path": "../../datalake/Samuel/SOFTware-Sync/data/xml_files/hal-03415990.grobid.tei.xml", "file_name": "hal-03415990.grobid.tei.xml"}