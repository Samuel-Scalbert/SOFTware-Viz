{"application": "software-mentions", "version": "0.8.0", "date": "2024-10-07T11:37+0000", "md5": "FE39DD2353A119D159D9876C7929DCDB", "mentions": [{"type": "software", "software-type": "software", "software-name": {"rawForm": "fastText", "normalizedForm": "fastText", "offsetStart": 4, "offsetEnd": 12}, "context": "The fastText linear classifier works by repre-   senting sentences for classification as Bags of Words (BoW) and training a linear classifier.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00023251771926879883}, "created": {"value": false, "score": 0.00018960237503051758}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997872710227966}, "created": {"value": true, "score": 0.9997637867927551}, "shared": {"value": false, "score": 2.2292137145996094e-05}}, "references": [{"label": "(Mikolov et al., 2018)", "normalizedForm": "Mikolov et al., 2018", "refKey": 11}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "pipeline", "normalizedForm": "pipeline", "offsetStart": 6, "offsetEnd": 14}, "context": "Their pipeline first launches multiple process, preferably as many as available cores.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00014531612396240234}, "created": {"value": true, "score": 0.5642503499984741}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9996787309646606}, "created": {"value": true, "score": 0.9998445510864258}, "shared": {"value": false, "score": 0.0010630488395690918}}, "references": [{"label": "Grave et al. (2018)", "normalizedForm": "Grave et al. (2018)", "refKey": 8}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "UNIX", "normalizedForm": "UNIX", "offsetStart": 9, "offsetEnd": 13}, "context": "Standard UNIX humanreadable notation is used for the size in byte. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.8139258027076721}, "created": {"value": false, "score": 8.106231689453125e-06}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.8139258027076721}, "created": {"value": false, "score": 0.004471957683563232}, "shared": {"value": false, "score": 3.5762786865234375e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "pipeline", "normalizedForm": "pipeline", "offsetStart": 12, "offsetEnd": 20}, "context": "Thus in our pipeline we don't have to wait for a whole WET file to download, decompress and classify in order to start downloading and processing the next one, a new file will start downloading and processing as soon as the scheduler is able to allocate a new process.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00040835142135620117}, "created": {"value": false, "score": 0.14900600910186768}, "shared": {"value": false, "score": 2.1338462829589844e-05}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9996787309646606}, "created": {"value": true, "score": 0.9998445510864258}, "shared": {"value": false, "score": 0.0010630488395690918}}, "references": [{"label": "Grave et al. (2018)", "normalizedForm": "Grave et al. (2018)", "refKey": 8}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "fastText", "normalizedForm": "fastText", "offsetStart": 14, "offsetEnd": 22}, "context": "They used the fastText linear classifier (Joulin et al., 2016(Joulin et al., , 2017) ) to classify each line of Common Crawl by language, and downloaded the initial corpus and schedule the I/O using some simple Bash scripts.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9997872710227966}, "created": {"value": false, "score": 3.123283386230469e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997872710227966}, "created": {"value": true, "score": 0.9997637867927551}, "shared": {"value": false, "score": 2.2292137145996094e-05}}, "references": [{"label": "(Mikolov et al., 2018)", "normalizedForm": "Mikolov et al., 2018", "refKey": 11}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "pipeline", "normalizedForm": "pipeline", "offsetStart": 15, "offsetEnd": 23}, "context": "We develop the pipeline so that it can be easily reapplied to any kind of heterogeneous corpus and so that it can be parameterised to a wide range of infrastructures.", "mentionContextAttributes": {"used": {"value": false, "score": 9.357929229736328e-05}, "created": {"value": true, "score": 0.9995125532150269}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9996787309646606}, "created": {"value": true, "score": 0.9998445510864258}, "shared": {"value": false, "score": 0.0010630488395690918}}, "references": [{"label": "Grave et al. (2018)", "normalizedForm": "Grave et al. (2018)", "refKey": 8}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "pipeline", "normalizedForm": "pipeline", "offsetStart": 16, "offsetEnd": 24}, "context": "We optimise the pipeline so that the process can be completed in a sensible amount of time even in infrastructures where Input/Output (I/O) speeds become the main bottleneck.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00044149160385131836}, "created": {"value": false, "score": 0.01984989643096924}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9996787309646606}, "created": {"value": true, "score": 0.9998445510864258}, "shared": {"value": false, "score": 0.0010630488395690918}}, "references": [{"label": "Grave et al. (2018)", "normalizedForm": "Grave et al. (2018)", "refKey": 8}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "pipeline", "normalizedForm": "pipeline", "offsetStart": 17, "offsetEnd": 25}, "context": "We propose a new pipeline derived from the fast-Text one which we call goclassy, we reuse the fastText linear classifier (Joulin et al., 2016(Joulin et al., , 2017) ) and the pre-trained fastText model for language recognition (Grave et al., 2018), but we 11 https://tatoeba.org/", "mentionContextAttributes": {"used": {"value": false, "score": 0.0006170272827148438}, "created": {"value": false, "score": 0.01089012622833252}, "shared": {"value": false, "score": 2.2292137145996094e-05}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9996787309646606}, "created": {"value": true, "score": 0.9998445510864258}, "shared": {"value": false, "score": 0.0010630488395690918}}, "references": [{"label": "Grave et al. (2018)", "normalizedForm": "Grave et al. (2018)", "refKey": 8}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "fastText", "normalizedForm": "fastText", "offsetStart": 19, "offsetEnd": 27}, "context": "They followed the \"fastText pre-processing pipeline\" but they removed all copies of Wikipedia inside Common Crawl.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9996787309646606}, "created": {"value": false, "score": 2.4080276489257812e-05}, "shared": {"value": false, "score": 7.152557373046875e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997872710227966}, "created": {"value": true, "score": 0.9997637867927551}, "shared": {"value": false, "score": 2.2292137145996094e-05}}, "references": [{"label": "(Mikolov et al., 2018)", "normalizedForm": "Mikolov et al., 2018", "refKey": 11}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "pipeline", "normalizedForm": "pipeline", "offsetStart": 19, "offsetEnd": 27}, "context": "Figure 1 shows the pipeline up to this point.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9699212312698364}, "created": {"value": false, "score": 0.0002072453498840332}, "shared": {"value": false, "score": 9.5367431640625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9996787309646606}, "created": {"value": true, "score": 0.9998445510864258}, "shared": {"value": false, "score": 0.0010630488395690918}}, "references": [{"label": "Grave et al. (2018)", "normalizedForm": "Grave et al. (2018)", "refKey": 8}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "pipeline", "normalizedForm": "pipeline", "offsetStart": 20, "offsetEnd": 28}, "context": "Furthermore, as our pipeline speeds-up and simplifies the treatment of Common Crawl, we believe that our contribution can be further parallelised and adapted to treat multiple snapshots of Common Crawl opening the door to what would be otherwise costly diachronic studies of the use of a given language throughout the internet.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00033164024353027344}, "created": {"value": true, "score": 0.9507238268852234}, "shared": {"value": false, "score": 1.6689300537109375e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9996787309646606}, "created": {"value": true, "score": 0.9998445510864258}, "shared": {"value": false, "score": 0.0010630488395690918}}, "references": [{"label": "Grave et al. (2018)", "normalizedForm": "Grave et al. (2018)", "refKey": 8}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "fastText", "normalizedForm": "fastText", "offsetStart": 25, "offsetEnd": 33}, "context": "ward modification on the fastText pre-processing pipeline assures we take into account the multiple languages present in Common Crawl that use non-ASCII encoded characters.", "mentionContextAttributes": {"used": {"value": false, "score": 0.019858121871948242}, "created": {"value": false, "score": 0.002270638942718506}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997872710227966}, "created": {"value": true, "score": 0.9997637867927551}, "shared": {"value": false, "score": 2.2292137145996094e-05}}, "references": [{"label": "(Mikolov et al., 2018)", "normalizedForm": "Mikolov et al., 2018", "refKey": 11}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "pipeline", "normalizedForm": "pipeline", "offsetStart": 28, "offsetEnd": 36}, "context": "This improvement allows our pipeline to better take into account the multilingual nature of Common Crawl; that is, we count UTF-8 characters instead of bytes for setting the lower admissible bound for the length of a line to be fed into the classifier.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0001436471939086914}, "created": {"value": false, "score": 0.09689503908157349}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9996787309646606}, "created": {"value": true, "score": 0.9998445510864258}, "shared": {"value": false, "score": 0.0010630488395690918}}, "references": [{"label": "Grave et al. (2018)", "normalizedForm": "Grave et al. (2018)", "refKey": 8}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "pipeline", "normalizedForm": "pipeline", "offsetStart": 30, "offsetEnd": 38}, "context": "Knowing that even running our pipeline will not always be feasible, we also commit to publishing our own version of a classified by language, filtered and ready to use Common Crawl corpus upon publication of this article.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00019103288650512695}, "created": {"value": false, "score": 0.2176532745361328}, "shared": {"value": false, "score": 0.0010630488395690918}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9996787309646606}, "created": {"value": true, "score": 0.9998445510864258}, "shared": {"value": false, "score": 0.0010630488395690918}}, "references": [{"label": "Grave et al. (2018)", "normalizedForm": "Grave et al. (2018)", "refKey": 8}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Go", "normalizedForm": "Go", "offsetStart": 32, "offsetEnd": 34}, "context": "We implement goclassy using the Go programming language12 so we let the Go runtime13 handle the scheduling of the processes.", "mentionContextAttributes": {"used": {"value": true, "score": 0.695134162902832}, "created": {"value": true, "score": 0.9989410042762756}, "shared": {"value": false, "score": 5.960464477539062e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.695134162902832}, "created": {"value": true, "score": 0.9997115731239319}, "shared": {"value": false, "score": 1.5497207641601562e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "pipeline", "normalizedForm": "pipeline", "offsetStart": 36, "offsetEnd": 44}, "context": "We add both tools to our concurrent pipeline, executing multiple instances of them in parallel, in order to ensure we use the most of our available resources at a given time.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0014601945877075195}, "created": {"value": true, "score": 0.919776976108551}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9996787309646606}, "created": {"value": true, "score": 0.9998445510864258}, "shared": {"value": false, "score": 0.0010630488395690918}}, "references": [{"label": "Grave et al. (2018)", "normalizedForm": "Grave et al. (2018)", "refKey": 8}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "pipeline", "normalizedForm": "pipeline", "offsetStart": 38, "offsetEnd": 46}, "context": "Benchmarks in table 1 of our goclassy pipeline show a drastic reduction in processing time compared to the original fastText prepossessing pipeline.", "mentionContextAttributes": {"used": {"value": true, "score": 0.7935367822647095}, "created": {"value": false, "score": 0.0011979341506958008}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9996787309646606}, "created": {"value": true, "score": 0.9998445510864258}, "shared": {"value": false, "score": 0.0010630488395690918}}, "references": [{"label": "Grave et al. (2018)", "normalizedForm": "Grave et al. (2018)", "refKey": 8}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "pipeline", "normalizedForm": "pipeline", "offsetStart": 39, "offsetEnd": 47}, "context": "In fact Grave et al. (2018) proposed a pipeline to filter, clean and classify their fastText multilingual word embeddings, which we shall call the \"fastText pre-processing pipeline.\"", "mentionContextAttributes": {"used": {"value": false, "score": 0.00015366077423095703}, "created": {"value": true, "score": 0.9208086133003235}, "shared": {"value": false, "score": 5.960464477539062e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9996787309646606}, "created": {"value": true, "score": 0.9998445510864258}, "shared": {"value": false, "score": 0.0010630488395690918}}, "references": [{"label": "Grave et al. (2018)", "normalizedForm": "Grave et al. (2018)", "refKey": 8}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "fastText", "normalizedForm": "fastText", "offsetStart": 40, "offsetEnd": 48}, "context": "After decompressing, an instance of the fastText linear classifier (Joulin et al., 2016(Joulin et al., , 2017) ) is launched, the classifier processes each WET file line by line, generating a language tag for each line.", "mentionContextAttributes": {"used": {"value": false, "score": 0.016651451587677002}, "created": {"value": false, "score": 0.00033545494079589844}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997872710227966}, "created": {"value": true, "score": 0.9997637867927551}, "shared": {"value": false, "score": 2.2292137145996094e-05}}, "references": [{"label": "(Mikolov et al., 2018)", "normalizedForm": "Mikolov et al., 2018", "refKey": 11}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "pipeline", "normalizedForm": "pipeline", "offsetStart": 40, "offsetEnd": 48}, "context": "Finally, we note that both our proposed pipeline is data independent, which means that they can be reused to process, clean and classify any sort of big multilingual corpus that is available in plain text form and that is UTF-8 encoded; meaning that the impact of our work goes way beyond a single corpus.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00016868114471435547}, "created": {"value": true, "score": 0.9423345923423767}, "shared": {"value": false, "score": 4.172325134277344e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9996787309646606}, "created": {"value": true, "score": 0.9998445510864258}, "shared": {"value": false, "score": 0.0010630488395690918}}, "references": [{"label": "Grave et al. (2018)", "normalizedForm": "Grave et al. (2018)", "refKey": 8}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "pipeline", "normalizedForm": "pipeline", "offsetStart": 41, "offsetEnd": 49}, "context": "completely rewrite and parallelise their pipeline in an asynchronous manner.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00021022558212280273}, "created": {"value": false, "score": 0.00014078617095947266}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9996787309646606}, "created": {"value": true, "score": 0.9998445510864258}, "shared": {"value": false, "score": 0.0010630488395690918}}, "references": [{"label": "Grave et al. (2018)", "normalizedForm": "Grave et al. (2018)", "refKey": 8}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "pipeline", "normalizedForm": "pipeline", "offsetStart": 43, "offsetEnd": 51}, "context": "They followed the \"fastText pre-processing pipeline\" but they removed all copies of Wikipedia inside Common Crawl.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9996787309646606}, "created": {"value": false, "score": 2.4080276489257812e-05}, "shared": {"value": false, "score": 7.152557373046875e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9996787309646606}, "created": {"value": true, "score": 0.9998445510864258}, "shared": {"value": false, "score": 0.0010630488395690918}}, "references": [{"label": "Grave et al. (2018)", "normalizedForm": "Grave et al. (2018)", "refKey": 8}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Go", "normalizedForm": "Go", "offsetStart": 44, "offsetEnd": 46}, "context": "Given that our implementation is written in Go, we release binary distributions 17 of goclassy for all major operating systems.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0017351508140563965}, "created": {"value": true, "score": 0.9997115731239319}, "shared": {"value": false, "score": 1.5497207641601562e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.695134162902832}, "created": {"value": true, "score": 0.9997115731239319}, "shared": {"value": false, "score": 1.5497207641601562e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "pipeline", "normalizedForm": "pipeline", "offsetStart": 49, "offsetEnd": 57}, "context": "ward modification on the fastText pre-processing pipeline assures we take into account the multiple languages present in Common Crawl that use non-ASCII encoded characters.", "mentionContextAttributes": {"used": {"value": false, "score": 0.019858121871948242}, "created": {"value": false, "score": 0.002270638942718506}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9996787309646606}, "created": {"value": true, "score": 0.9998445510864258}, "shared": {"value": false, "score": 0.0010630488395690918}}, "references": [{"label": "Grave et al. (2018)", "normalizedForm": "Grave et al. (2018)", "refKey": 8}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "pipeline", "normalizedForm": "pipeline", "offsetStart": 53, "offsetEnd": 61}, "context": "We propose a general, highly parallel, multithreaded pipeline to clean and classify Common Crawl by language; we specifically design it so that it runs efficiently on medium to low resource infrastructures where I/O speeds are the main constraint.", "mentionContextAttributes": {"used": {"value": false, "score": 9.560585021972656e-05}, "created": {"value": true, "score": 0.9998445510864258}, "shared": {"value": false, "score": 5.960464477539062e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9996787309646606}, "created": {"value": true, "score": 0.9998445510864258}, "shared": {"value": false, "score": 0.0010630488395690918}}, "references": [{"label": "Grave et al. (2018)", "normalizedForm": "Grave et al. (2018)", "refKey": 8}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "fastText", "normalizedForm": "fastText", "offsetStart": 59, "offsetEnd": 67}, "context": "The order of operations is more or less the same as in the fastText pre-processing pipeline but instead of clustering multiple operations into a single blocking process, we launch a worker for each operation and we bound the number of possible parallel operations at a given time by the number of available threads instead of the number of CPUs.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9053453803062439}, "created": {"value": false, "score": 0.00024121999740600586}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997872710227966}, "created": {"value": true, "score": 0.9997637867927551}, "shared": {"value": false, "score": 2.2292137145996094e-05}}, "references": [{"label": "(Mikolov et al., 2018)", "normalizedForm": "Mikolov et al., 2018", "refKey": 11}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "pipeline", "normalizedForm": "pipeline", "offsetStart": 61, "offsetEnd": 69}, "context": "Their solution, however, proved to be a synchronous blocking pipeline that works well on infrastructures having the necessary hardware to assure high I/O speeds even when storing tens of terabytes of data at a time.", "mentionContextAttributes": {"used": {"value": false, "score": 4.303455352783203e-05}, "created": {"value": false, "score": 0.20744037628173828}, "shared": {"value": false, "score": 5.960464477539062e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9996787309646606}, "created": {"value": true, "score": 0.9998445510864258}, "shared": {"value": false, "score": 0.0010630488395690918}}, "references": [{"label": "Grave et al. (2018)", "normalizedForm": "Grave et al. (2018)", "refKey": 8}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Linux", "normalizedForm": "Linux", "offsetStart": 70, "offsetEnd": 75}, "context": "We make sure that no other processes apart from the benchmark and the Linux system processes are run. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0010911226272583008}, "created": {"value": false, "score": 0.015713989734649658}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.0010911226272583008}, "created": {"value": false, "score": 0.015713989734649658}, "shared": {"value": false, "score": 3.5762786865234375e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Go", "normalizedForm": "Go", "offsetStart": 72, "offsetEnd": 74}, "context": "We implement goclassy using the Go programming language12 so we let the Go runtime13 handle the scheduling of the processes. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.695134162902832}, "created": {"value": true, "score": 0.9989410042762756}, "shared": {"value": false, "score": 5.960464477539062e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.695134162902832}, "created": {"value": true, "score": 0.9997115731239319}, "shared": {"value": false, "score": 1.5497207641601562e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "pipeline", "normalizedForm": "pipeline", "offsetStart": 83, "offsetEnd": 91}, "context": "The order of operations is more or less the same as in the fastText pre-processing pipeline but instead of clustering multiple operations into a single blocking process, we launch a worker for each operation and we bound the number of possible parallel operations at a given time by the number of available threads instead of the number of CPUs.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9053453803062439}, "created": {"value": false, "score": 0.00024121999740600586}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9996787309646606}, "created": {"value": true, "score": 0.9998445510864258}, "shared": {"value": false, "score": 0.0010630488395690918}}, "references": [{"label": "Grave et al. (2018)", "normalizedForm": "Grave et al. (2018)", "refKey": 8}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "fastText", "normalizedForm": "fastText", "offsetStart": 84, "offsetEnd": 92}, "context": "In fact Grave et al. (2018) proposed a pipeline to filter, clean and classify their fastText multilingual word embeddings, which we shall call the \"fastText pre-processing pipeline.\"", "mentionContextAttributes": {"used": {"value": false, "score": 0.00015366077423095703}, "created": {"value": true, "score": 0.9208086133003235}, "shared": {"value": false, "score": 5.960464477539062e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997872710227966}, "created": {"value": true, "score": 0.9997637867927551}, "shared": {"value": false, "score": 2.2292137145996094e-05}}, "references": [{"label": "(Mikolov et al., 2018)", "normalizedForm": "Mikolov et al., 2018", "refKey": 11}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "UNIX", "normalizedForm": "UNIX", "offsetStart": 90, "offsetEnd": 94}, "context": "We finally use the Mark Adler's pigz 16 for data compression, as opposed to the canonical UNIX tools proposed in the original fastText pipeline. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.7693437337875366}, "created": {"value": false, "score": 0.004471957683563232}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.8139258027076721}, "created": {"value": false, "score": 0.004471957683563232}, "shared": {"value": false, "score": 3.5762786865234375e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "fastText", "normalizedForm": "fastText", "offsetStart": 90, "offsetEnd": 98}, "context": "We also create, from the start, a file for each of the 176 languages that the pre-trained fastText language classifier is capable of recognising, and we always leave them open, as we find that getting a file descriptor to each time we want to write, if we wanted leave them open just when needed, introduces a big overhead. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.00024360418319702148}, "created": {"value": true, "score": 0.9510340094566345}, "shared": {"value": false, "score": 5.245208740234375e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997872710227966}, "created": {"value": true, "score": 0.9997637867927551}, "shared": {"value": false, "score": 2.2292137145996094e-05}}, "references": [{"label": "(Mikolov et al., 2018)", "normalizedForm": "Mikolov et al., 2018", "refKey": 11}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "fastText", "normalizedForm": "fastText", "offsetStart": 94, "offsetEnd": 102}, "context": "We propose a new pipeline derived from the fast-Text one which we call goclassy, we reuse the fastText linear classifier (Joulin et al., 2016(Joulin et al., , 2017) ) and the pre-trained fastText model for language recognition (Grave et al., 2018), but we 11 https://tatoeba.org/", "mentionContextAttributes": {"used": {"value": false, "score": 0.0006170272827148438}, "created": {"value": false, "score": 0.01089012622833252}, "shared": {"value": false, "score": 2.2292137145996094e-05}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997872710227966}, "created": {"value": true, "score": 0.9997637867927551}, "shared": {"value": false, "score": 2.2292137145996094e-05}}, "references": [{"label": "(Mikolov et al., 2018)", "normalizedForm": "Mikolov et al., 2018", "refKey": 11}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "fastText", "normalizedForm": "fastText", "offsetStart": 97, "offsetEnd": 105}, "context": "In order to download, extract, filter, clean and classify Common Crawl we base ourselves on the \"fastText pre-processing pipeline\" used by Grave et al. (2018).", "mentionContextAttributes": {"used": {"value": false, "score": 0.2768111228942871}, "created": {"value": false, "score": 0.0077095627784729}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997872710227966}, "created": {"value": true, "score": 0.9997637867927551}, "shared": {"value": false, "score": 2.2292137145996094e-05}}, "references": [{"label": "(Mikolov et al., 2018)", "normalizedForm": "Mikolov et al., 2018", "refKey": 11}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "fastText", "normalizedForm": "fastText", "offsetStart": 104, "offsetEnd": 112}, "context": "To overcome this, we introduced buffers in all our I/O operations, a feature that is not present in the fastText pre-processing pipeline. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.00016117095947265625}, "created": {"value": true, "score": 0.9997637867927551}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997872710227966}, "created": {"value": true, "score": 0.9997637867927551}, "shared": {"value": false, "score": 2.2292137145996094e-05}}, "references": [{"label": "(Mikolov et al., 2018)", "normalizedForm": "Mikolov et al., 2018", "refKey": 11}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "fastText", "normalizedForm": "fastText", "offsetStart": 116, "offsetEnd": 124}, "context": "Some notorious examples of word embeddings are word2vec (Mikolov et al., 2013), GloVe (Pennington et al., 2014) and fastText (Mikolov et al., 2018).", "mentionContextAttributes": {"used": {"value": false, "score": 0.0005131959915161133}, "created": {"value": false, "score": 6.902217864990234e-05}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997872710227966}, "created": {"value": true, "score": 0.9997637867927551}, "shared": {"value": false, "score": 2.2292137145996094e-05}}, "references": [{"label": "(Mikolov et al., 2018)", "normalizedForm": "Mikolov et al., 2018", "refKey": 11, "offsetStart": 2511, "offsetEnd": 2533}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "fastText", "normalizedForm": "fastText", "offsetStart": 116, "offsetEnd": 124}, "context": "Benchmarks in table 1 of our goclassy pipeline show a drastic reduction in processing time compared to the original fastText prepossessing pipeline.", "mentionContextAttributes": {"used": {"value": true, "score": 0.7935359477996826}, "created": {"value": false, "score": 0.0011979341506958008}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997872710227966}, "created": {"value": true, "score": 0.9997637867927551}, "shared": {"value": false, "score": 2.2292137145996094e-05}}, "references": [{"label": "(Mikolov et al., 2018)", "normalizedForm": "Mikolov et al., 2018", "refKey": 11}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "pipeline", "normalizedForm": "pipeline", "offsetStart": 121, "offsetEnd": 129}, "context": "In order to download, extract, filter, clean and classify Common Crawl we base ourselves on the \"fastText pre-processing pipeline\" used by Grave et al. (2018).", "mentionContextAttributes": {"used": {"value": false, "score": 0.2768111228942871}, "created": {"value": false, "score": 0.0077095627784729}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9996787309646606}, "created": {"value": true, "score": 0.9998445510864258}, "shared": {"value": false, "score": 0.0010630488395690918}}, "references": [{"label": "Grave et al. (2018)", "normalizedForm": "Grave et al. (2018)", "refKey": 8, "offsetStart": 10477, "offsetEnd": 10496}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "fastText", "normalizedForm": "fastText", "offsetStart": 126, "offsetEnd": 134}, "context": "We finally use the Mark Adler's pigz 16 for data compression, as opposed to the canonical UNIX tools proposed in the original fastText pipeline.", "mentionContextAttributes": {"used": {"value": true, "score": 0.7693451642990112}, "created": {"value": false, "score": 0.004471957683563232}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997872710227966}, "created": {"value": true, "score": 0.9997637867927551}, "shared": {"value": false, "score": 2.2292137145996094e-05}}, "references": [{"label": "(Mikolov et al., 2018)", "normalizedForm": "Mikolov et al., 2018", "refKey": 11}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "pipeline", "normalizedForm": "pipeline", "offsetStart": 128, "offsetEnd": 136}, "context": "To overcome this, we introduced buffers in all our I/O operations, a feature that is not present in the fastText pre-processing pipeline.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00016117095947265625}, "created": {"value": true, "score": 0.9997637867927551}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9996787309646606}, "created": {"value": true, "score": 0.9998445510864258}, "shared": {"value": false, "score": 0.0010630488395690918}}, "references": [{"label": "Grave et al. (2018)", "normalizedForm": "Grave et al. (2018)", "refKey": 8}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "pipeline", "normalizedForm": "pipeline", "offsetStart": 135, "offsetEnd": 143}, "context": "We finally use the Mark Adler's pigz 16 for data compression, as opposed to the canonical UNIX tools proposed in the original fastText pipeline. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.7693451642990112}, "created": {"value": false, "score": 0.004471957683563232}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9996787309646606}, "created": {"value": true, "score": 0.9998445510864258}, "shared": {"value": false, "score": 0.0010630488395690918}}, "references": [{"label": "Grave et al. (2018)", "normalizedForm": "Grave et al. (2018)", "refKey": 8}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "fastText", "normalizedForm": "fastText", "offsetStart": 136, "offsetEnd": 144}, "context": "Later Al-Rfou et al. (2013) and then Bojanowski et al. (2017) used the plain text from Wikipedia to train distributions of word2vec and fastText respectively, for languages other than English.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9978645443916321}, "created": {"value": false, "score": 4.887580871582031e-06}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997872710227966}, "created": {"value": true, "score": 0.9997637867927551}, "shared": {"value": false, "score": 2.2292137145996094e-05}}, "references": [{"label": "(Mikolov et al., 2018)", "normalizedForm": "Mikolov et al., 2018", "refKey": 11}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "pipeline", "normalizedForm": "pipeline", "offsetStart": 139, "offsetEnd": 147}, "context": "Benchmarks in table 1 of our goclassy pipeline show a drastic reduction in processing time compared to the original fastText prepossessing pipeline.", "mentionContextAttributes": {"used": {"value": true, "score": 0.7935359477996826}, "created": {"value": false, "score": 0.0011979341506958008}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9996787309646606}, "created": {"value": true, "score": 0.9998445510864258}, "shared": {"value": false, "score": 0.0010630488395690918}}, "references": [{"label": "Grave et al. (2018)", "normalizedForm": "Grave et al. (2018)", "refKey": 8}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "fastText", "normalizedForm": "fastText", "offsetStart": 148, "offsetEnd": 156}, "context": "In fact Grave et al. (2018) proposed a pipeline to filter, clean and classify their fastText multilingual word embeddings, which we shall call the \"fastText pre-processing pipeline.\"", "mentionContextAttributes": {"used": {"value": false, "score": 0.00015366077423095703}, "created": {"value": true, "score": 0.9208080172538757}, "shared": {"value": false, "score": 5.960464477539062e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997872710227966}, "created": {"value": true, "score": 0.9997637867927551}, "shared": {"value": false, "score": 2.2292137145996094e-05}}, "references": [{"label": "(Mikolov et al., 2018)", "normalizedForm": "Mikolov et al., 2018", "refKey": 11}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "pipeline", "normalizedForm": "pipeline", "offsetStart": 161, "offsetEnd": 169}, "context": "Beyond improving the computational time required to classify this corpus, we propose a simple improvement on the cleaning scheme in the fast-Text pre-processing pipeline.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00022774934768676758}, "created": {"value": true, "score": 0.9980006814002991}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9996787309646606}, "created": {"value": true, "score": 0.9998445510864258}, "shared": {"value": false, "score": 0.0010630488395690918}}, "references": [{"label": "Grave et al. (2018)", "normalizedForm": "Grave et al. (2018)", "refKey": 8}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "pipeline", "normalizedForm": "pipeline", "offsetStart": 163, "offsetEnd": 171}, "context": "The user time which represents the amount of CPU time spent in user-mode code (outside the kernel) within the process is almost three times lower for our goclassy pipeline, this particular benchmark strongly suggest a substantial reduction in energy consumption of goclassy with respect to the fastText pipeline.", "mentionContextAttributes": {"used": {"value": false, "score": 0.18439263105392456}, "created": {"value": false, "score": 7.367134094238281e-05}, "shared": {"value": false, "score": 5.960464477539062e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9996787309646606}, "created": {"value": true, "score": 0.9998445510864258}, "shared": {"value": false, "score": 0.0010630488395690918}}, "references": [{"label": "Grave et al. (2018)", "normalizedForm": "Grave et al. (2018)", "refKey": 8}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "pipeline", "normalizedForm": "pipeline", "offsetStart": 172, "offsetEnd": 180}, "context": "In fact Grave et al. (2018) proposed a pipeline to filter, clean and classify their fastText multilingual word embeddings, which we shall call the \"fastText pre-processing pipeline.\"", "mentionContextAttributes": {"used": {"value": false, "score": 0.00015366077423095703}, "created": {"value": true, "score": 0.9208080172538757}, "shared": {"value": false, "score": 5.960464477539062e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9996787309646606}, "created": {"value": true, "score": 0.9998445510864258}, "shared": {"value": false, "score": 0.0010630488395690918}}, "references": [{"label": "Grave et al. (2018)", "normalizedForm": "Grave et al. (2018)", "refKey": 8}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "fastText", "normalizedForm": "fastText", "offsetStart": 187, "offsetEnd": 195}, "context": "We propose a new pipeline derived from the fast-Text one which we call goclassy, we reuse the fastText linear classifier (Joulin et al., 2016(Joulin et al., , 2017) ) and the pre-trained fastText model for language recognition (Grave et al., 2018), but we 11 https://tatoeba.org/", "mentionContextAttributes": {"used": {"value": false, "score": 0.0006170272827148438}, "created": {"value": false, "score": 0.01089012622833252}, "shared": {"value": false, "score": 2.2292137145996094e-05}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997872710227966}, "created": {"value": true, "score": 0.9997637867927551}, "shared": {"value": false, "score": 2.2292137145996094e-05}}, "references": [{"label": "(Mikolov et al., 2018)", "normalizedForm": "Mikolov et al., 2018", "refKey": 11}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "pipeline", "normalizedForm": "pipeline", "offsetStart": 196, "offsetEnd": 204}, "context": "As we understand that even an infrastructure with more than 20TB of free space in traditional electromechanical storage is not available to everyone and we propose a simple parametrization in our pipeline that actively deletes already processed data and that only downloads and decompresses files when needed, thus ensuring that no more than 10TB of storage are used at a given time.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0002619624137878418}, "created": {"value": true, "score": 0.953545331954956}, "shared": {"value": false, "score": 6.4373016357421875e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9996787309646606}, "created": {"value": true, "score": 0.9998445510864258}, "shared": {"value": false, "score": 0.0010630488395690918}}, "references": [{"label": "Grave et al. (2018)", "normalizedForm": "Grave et al. (2018)", "refKey": 8}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "pipeline", "normalizedForm": "pipeline", "offsetStart": 205, "offsetEnd": 213}, "context": "To address this problem, we choose Common Crawl,6 which is a 20TB mutilingual free to use corpus composed of crawled websites from the internet, and we propose a highly parallel multithreaded asynchronous pipeline that applies wellknown concurrency patterns, to clean and classify by language the whole Common Crawl corpus to a point where it is usable for Machine Learning and in particular for neural NLP applications.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00015842914581298828}, "created": {"value": true, "score": 0.8571973443031311}, "shared": {"value": false, "score": 3.0040740966796875e-05}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9996787309646606}, "created": {"value": true, "score": 0.9998445510864258}, "shared": {"value": false, "score": 0.0010630488395690918}}, "references": [{"label": "Grave et al. (2018)", "normalizedForm": "Grave et al. (2018)", "refKey": 8}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "scripts", "normalizedForm": "scripts", "offsetStart": 216, "offsetEnd": 223}, "context": "They used the fastText linear classifier (Joulin et al., 2016(Joulin et al., , 2017) ) to classify each line of Common Crawl by language, and downloaded the initial corpus and schedule the I/O using some simple Bash scripts. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9997872710227966}, "created": {"value": false, "score": 3.123283386230469e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997872710227966}, "created": {"value": false, "score": 3.123283386230469e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "pipeline", "normalizedForm": "pipeline", "offsetStart": 226, "offsetEnd": 234}, "context": "Particularly for Common Crawl, Yang et al. (2019) say they use \"heuristics to aggressively filter out short or low-quality articles\" from Common Crawl, however they don't give any detail about these \"heuristics\" nor about the pipeline they use to classify and extract the English part of Common Crawl.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0049048662185668945}, "created": {"value": false, "score": 0.0007075071334838867}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9996787309646606}, "created": {"value": true, "score": 0.9998445510864258}, "shared": {"value": false, "score": 0.0010630488395690918}}, "references": [{"label": "Grave et al. (2018)", "normalizedForm": "Grave et al. (2018)", "refKey": 8}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "coRpus", "normalizedForm": "coRpus", "offsetStart": 258, "offsetEnd": 264}, "context": "Thus we decide to publish a pre-processed version of the November 2018 copy of Common Crawl which is comprised of usable data in 166 different languages, we publish 18 our version under the name OSCAR which is short for Open Super-large Crawled AL-MAnaCH 19 coRpus.", "mentionContextAttributes": {"used": {"value": false, "score": 0.007562577724456787}, "created": {"value": false, "score": 0.008027791976928711}, "shared": {"value": false, "score": 0.00015115737915039062}}, "documentContextAttributes": {"used": {"value": false, "score": 0.007562577724456787}, "created": {"value": false, "score": 0.008027791976928711}, "shared": {"value": false, "score": 0.00015115737915039062}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "fastText", "normalizedForm": "fastText", "offsetStart": 294, "offsetEnd": 302}, "context": "The user time which represents the amount of CPU time spent in user-mode code (outside the kernel) within the process is almost three times lower for our goclassy pipeline, this particular benchmark strongly suggest a substantial reduction in energy consumption of goclassy with respect to the fastText pipeline.", "mentionContextAttributes": {"used": {"value": false, "score": 0.18439263105392456}, "created": {"value": false, "score": 7.367134094238281e-05}, "shared": {"value": false, "score": 5.960464477539062e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997872710227966}, "created": {"value": true, "score": 0.9997637867927551}, "shared": {"value": false, "score": 2.2292137145996094e-05}}, "references": [{"label": "(Mikolov et al., 2018)", "normalizedForm": "Mikolov et al., 2018", "refKey": 11}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "pipeline", "normalizedForm": "pipeline", "offsetStart": 303, "offsetEnd": 311}, "context": "The user time which represents the amount of CPU time spent in user-mode code (outside the kernel) within the process is almost three times lower for our goclassy pipeline, this particular benchmark strongly suggest a substantial reduction in energy consumption of goclassy with respect to the fastText pipeline.", "mentionContextAttributes": {"used": {"value": false, "score": 0.18439263105392456}, "created": {"value": false, "score": 7.367134094238281e-05}, "shared": {"value": false, "score": 5.960464477539062e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9996787309646606}, "created": {"value": true, "score": 0.9998445510864258}, "shared": {"value": false, "score": 0.0010630488395690918}}, "references": [{"label": "Grave et al. (2018)", "normalizedForm": "Grave et al. (2018)", "refKey": 8}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "fastText", "normalizedForm": "fastText", "offsetStart": 324, "offsetEnd": 332}, "context": "We also do the filtering and cleaning processes at line level before feeding each line to the classifier, which makes us create a new filtered file so that we can have a correspondence with the tag file, which in turn will consume more space, but that will also reduce the amount of unnecessary classifications performed by fastText. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.005566895008087158}, "created": {"value": false, "score": 0.004283249378204346}, "shared": {"value": false, "score": 8.344650268554688e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997872710227966}, "created": {"value": true, "score": 0.9997637867927551}, "shared": {"value": false, "score": 2.2292137145996094e-05}}, "references": [{"label": "(Mikolov et al., 2018)", "normalizedForm": "Mikolov et al., 2018", "refKey": 11}]}], "references": [{"refKey": 11, "tei": "<biblStruct xml:id=\"b11\">\n\t<analytic>\n\t\t<title level=\"a\" type=\"main\">Advances in pre-training distributed word representations</title>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Tomas</forename><surname>Mikolov</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Edouard</forename><surname>Grave</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Piotr</forename><surname>Bojanowski</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Christian</forename><surname>Puhrsch</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Armand</forename><surname>Joulin</surname></persName>\n\t\t</author>\n\t</analytic>\n\t<monogr>\n\t\t<title level=\"m\">Proceedings of the Eleventh International Conference on Language Resources and Evaluation, LREC 2018</title>\n\t\t<meeting>the Eleventh International Conference on Language Resources and Evaluation, LREC 2018</meeting>\n\t\t<imprint>\n\t\t\t<date>2018. May 7-12, 2018</date>\n\t\t</imprint>\n\t</monogr>\n</biblStruct>\n"}, {"refKey": 8, "tei": "<biblStruct xml:id=\"b8\">\n\t<analytic>\n\t\t<title level=\"a\" type=\"main\">Learning word vectors for 157 languages</title>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Edouard</forename><surname>Grave</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Piotr</forename><surname>Bojanowski</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Prakhar</forename><surname>Gupta</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Armand</forename><surname>Joulin</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Tomas</forename><surname>Mikolov</surname></persName>\n\t\t</author>\n\t</analytic>\n\t<monogr>\n\t\t<title level=\"m\">Proceedings of the 11th Language Resources and Evaluation Conference</title>\n\t\t<meeting>the 11th Language Resources and Evaluation Conference</meeting>\n\t\t<imprint>\n\t\t\t<publisher>European Language Resource Association</publisher>\n\t\t\t<date>2018</date>\n\t\t</imprint>\n\t</monogr>\n</biblStruct>\n"}], "runtime": 9912, "id": "a6e580c27b44b279a6dc7720de830955588b0f3b", "metadata": {"id": "a6e580c27b44b279a6dc7720de830955588b0f3b"}, "original_file_path": "../../datalake/Samuel/SOFTware-Sync/downloads/xml/hal-02148693.grobid.tei.xml", "file_name": "hal-02148693.grobid.tei.xml"}