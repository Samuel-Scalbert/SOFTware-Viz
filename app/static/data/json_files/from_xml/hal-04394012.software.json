{"application": "software-mentions", "version": "0.8.0", "date": "2024-10-07T11:53+0000", "md5": "6F2924D5356C59A861CA7D6DC9509BD5", "mentions": [{"type": "software", "software-type": "software", "software-name": {"rawForm": "InstructGPT", "normalizedForm": "InstructGPT", "offsetStart": 0, "offsetEnd": 11}, "version": {"rawForm": "3", "normalizedForm": "3"}, "context": "InstructGPT-3 Prediction Analysis For silver, we observe that InstructGPT-3 extracts more entities than original extraction (Table 2).", "mentionContextAttributes": {"used": {"value": true, "score": 0.9802712202072144}, "created": {"value": false, "score": 2.7418136596679688e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999905824661255}, "created": {"value": true, "score": 0.9951485991477966}, "shared": {"value": false, "score": 5.960464477539062e-07}}, "references": [{"label": "(Ouyang et al., 2022)", "normalizedForm": "Ouyang et al., 2022", "refKey": 28}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "InstructGPT", "normalizedForm": "InstructGPT", "offsetStart": 14, "offsetEnd": 25}, "version": {"rawForm": "3", "normalizedForm": "3"}, "context": "The output of InstructGPT-3 is a string of characters that we must structure to align the predicted clinical entities with the initial text (Figure 2).", "mentionContextAttributes": {"used": {"value": false, "score": 0.32377690076828003}, "created": {"value": false, "score": 0.0005748271942138672}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999905824661255}, "created": {"value": true, "score": 0.9951485991477966}, "shared": {"value": false, "score": 5.960464477539062e-07}}, "references": [{"label": "(Ouyang et al., 2022)", "normalizedForm": "Ouyang et al., 2022", "refKey": 28}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "InstructGPT", "normalizedForm": "InstructGPT", "offsetStart": 15, "offsetEnd": 26}, "version": {"rawForm": "3", "normalizedForm": "3"}, "context": "They show that InstructGPT-3 performs well in several clinical tasks. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9658775925636292}, "created": {"value": false, "score": 2.9921531677246094e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999905824661255}, "created": {"value": true, "score": 0.9951485991477966}, "shared": {"value": false, "score": 5.960464477539062e-07}}, "references": [{"label": "(Ouyang et al., 2022)", "normalizedForm": "Ouyang et al., 2022", "refKey": 28}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "-base", "normalizedForm": "-base", "offsetStart": 18, "offsetEnd": 23}, "context": "We use xlm-roberta-base.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9987874627113342}, "created": {"value": false, "score": 4.410743713378906e-06}, "shared": {"value": false, "score": 7.152557373046875e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9987874627113342}, "created": {"value": false, "score": 4.410743713378906e-06}, "shared": {"value": false, "score": 7.152557373046875e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "InstructGPT", "normalizedForm": "InstructGPT", "offsetStart": 24, "offsetEnd": 35}, "version": {"rawForm": "3", "normalizedForm": "3"}, "context": "So, a small part of the InstructGPT-3 prediction annotations and the dictionary extraction annotations has been replaced by manual annotations;", "mentionContextAttributes": {"used": {"value": false, "score": 0.30598878860473633}, "created": {"value": false, "score": 3.3020973205566406e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999905824661255}, "created": {"value": true, "score": 0.9951485991477966}, "shared": {"value": false, "score": 5.960464477539062e-07}}, "references": [{"label": "(Ouyang et al., 2022)", "normalizedForm": "Ouyang et al., 2022", "refKey": 28}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "InstructGPT", "normalizedForm": "InstructGPT", "offsetStart": 26, "offsetEnd": 37}, "version": {"rawForm": "3", "normalizedForm": "3"}, "context": "Their works benchmark how InstructGPT-3 (Ouyang et al., 2022) per-form clinical NLP tasks in English. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0331043004989624}, "created": {"value": false, "score": 0.01474905014038086}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999905824661255}, "created": {"value": true, "score": 0.9951485991477966}, "shared": {"value": false, "score": 5.960464477539062e-07}}, "references": [{"label": "(Ouyang et al., 2022)", "normalizedForm": "Ouyang et al., 2022", "refKey": 28, "offsetStart": 9445, "offsetEnd": 9466}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "InstructGPT", "normalizedForm": "InstructGPT", "offsetStart": 35, "offsetEnd": 46}, "version": {"rawForm": "3", "normalizedForm": "3"}, "context": "We compare the distilled model and InstructGPT-3 on the gold standard (Table 3).", "mentionContextAttributes": {"used": {"value": true, "score": 0.9985759258270264}, "created": {"value": false, "score": 4.0531158447265625e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999905824661255}, "created": {"value": true, "score": 0.9951485991477966}, "shared": {"value": false, "score": 5.960464477539062e-07}}, "references": [{"label": "(Ouyang et al., 2022)", "normalizedForm": "Ouyang et al., 2022", "refKey": 28}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "InstructGPT", "normalizedForm": "InstructGPT", "offsetStart": 37, "offsetEnd": 48}, "version": {"rawForm": "3", "normalizedForm": "3"}, "context": "tated, in contrast to 482 tokens for InstructGPT-3 annotations.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9996391534805298}, "created": {"value": false, "score": 9.655952453613281e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999905824661255}, "created": {"value": true, "score": 0.9951485991477966}, "shared": {"value": false, "score": 5.960464477539062e-07}}, "references": [{"label": "(Ouyang et al., 2022)", "normalizedForm": "Ouyang et al., 2022", "refKey": 28}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "InstructGPT", "normalizedForm": "InstructGPT", "offsetStart": 40, "offsetEnd": 51}, "version": {"rawForm": "3", "normalizedForm": "3"}, "context": "The last workflow used a combination of InstructGPT-3 and dictionary annotations; we tested different proportions of these annotations as described in 5.2. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999892711639404}, "created": {"value": false, "score": 3.5762786865234375e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999905824661255}, "created": {"value": true, "score": 0.9951485991477966}, "shared": {"value": false, "score": 5.960464477539062e-07}}, "references": [{"label": "(Ouyang et al., 2022)", "normalizedForm": "Ouyang et al., 2022", "refKey": 28}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "InstructGPT", "normalizedForm": "InstructGPT", "offsetStart": 40, "offsetEnd": 51}, "version": {"rawForm": "3", "normalizedForm": "3"}, "context": "Another interesting observation is that InstructGPT-3 extracts almost twice as many entities as the original extraction method (Figure 2).", "mentionContextAttributes": {"used": {"value": false, "score": 0.0028651952743530273}, "created": {"value": false, "score": 1.621246337890625e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999905824661255}, "created": {"value": true, "score": 0.9951485991477966}, "shared": {"value": false, "score": 5.960464477539062e-07}}, "references": [{"label": "(Ouyang et al., 2022)", "normalizedForm": "Ouyang et al., 2022", "refKey": 28}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "InstructGPT", "normalizedForm": "InstructGPT", "offsetStart": 42, "offsetEnd": 53}, "version": {"rawForm": "3", "normalizedForm": "3"}, "context": "Spanish and English have reversed trends: InstructGPT-3 performs better than distilled models.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0008094906806945801}, "created": {"value": false, "score": 1.0609626770019531e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999905824661255}, "created": {"value": true, "score": 0.9951485991477966}, "shared": {"value": false, "score": 5.960464477539062e-07}}, "references": [{"label": "(Ouyang et al., 2022)", "normalizedForm": "Ouyang et al., 2022", "refKey": 28}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "InstructGPT", "normalizedForm": "InstructGPT", "offsetStart": 44, "offsetEnd": 55}, "version": {"rawForm": "3", "normalizedForm": "3"}, "context": "If r = 1, the models are trained using only InstructGPT-3 annotations, while if r = 0, the models are trained exclusively with dictionary extraction annotations.", "mentionContextAttributes": {"used": {"value": true, "score": 0.8388227820396423}, "created": {"value": false, "score": 2.968311309814453e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999905824661255}, "created": {"value": true, "score": 0.9951485991477966}, "shared": {"value": false, "score": 5.960464477539062e-07}}, "references": [{"label": "(Ouyang et al., 2022)", "normalizedForm": "Ouyang et al., 2022", "refKey": 28}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "InstructGPT", "normalizedForm": "InstructGPT", "offsetStart": 45, "offsetEnd": 56}, "version": {"rawForm": "3", "normalizedForm": "3"}, "context": "Moreover, we denote a remarkable gap between InstructGPT-3 (0.63) and distilled models (0.75) in Italian.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9966951608657837}, "created": {"value": false, "score": 1.895427703857422e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999905824661255}, "created": {"value": true, "score": 0.9951485991477966}, "shared": {"value": false, "score": 5.960464477539062e-07}}, "references": [{"label": "(Ouyang et al., 2022)", "normalizedForm": "Ouyang et al., 2022", "refKey": 28}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "InstructGPT", "normalizedForm": "InstructGPT", "offsetStart": 45, "offsetEnd": 56}, "version": {"rawForm": "3", "normalizedForm": "3"}, "context": "This echoed the exception we observed in the InstructGPT-3 Prediction Analysis paragraph.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999656677246094}, "created": {"value": false, "score": 1.6808509826660156e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999905824661255}, "created": {"value": true, "score": 0.9951485991477966}, "shared": {"value": false, "score": 5.960464477539062e-07}}, "references": [{"label": "(Ouyang et al., 2022)", "normalizedForm": "Ouyang et al., 2022", "refKey": 28}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "InstructGPT", "normalizedForm": "InstructGPT", "offsetStart": 52, "offsetEnd": 63}, "version": {"rawForm": "3", "normalizedForm": "3"}, "context": "This difference could be explained by the fact that InstructGPT-3 has no access to the guidelines, and the prompt mentioned to extract \"disorders,\" \"disease,\" or \"symptoms\" is less restrictive than the E3C guideline annotation.", "mentionContextAttributes": {"used": {"value": false, "score": 0.4666898846626282}, "created": {"value": false, "score": 3.266334533691406e-05}, "shared": {"value": false, "score": 5.960464477539062e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999905824661255}, "created": {"value": true, "score": 0.9951485991477966}, "shared": {"value": false, "score": 5.960464477539062e-07}}, "references": [{"label": "(Ouyang et al., 2022)", "normalizedForm": "Ouyang et al., 2022", "refKey": 28}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "InstructGPT", "normalizedForm": "InstructGPT", "offsetStart": 54, "offsetEnd": 65}, "version": {"rawForm": "3", "normalizedForm": "3", "offsetStart": 66, "offsetEnd": 67}, "context": "For each of them, we test the F1-Score performance of InstructGPT-3 on the test dataset (gold standard), and we select the set with the best F1-Score to perform prediction on the unannotated dataset. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9997434020042419}, "created": {"value": false, "score": 2.0384788513183594e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999905824661255}, "created": {"value": true, "score": 0.9951485991477966}, "shared": {"value": false, "score": 5.960464477539062e-07}}, "references": [{"label": "(Ouyang et al., 2022)", "normalizedForm": "Ouyang et al., 2022", "refKey": 28}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "InstructGPT", "normalizedForm": "InstructGPT", "offsetStart": 55, "offsetEnd": 66}, "version": {"rawForm": "3", "normalizedForm": "3"}, "context": "Finally, we propose to combine annotations provided by InstructGPT-3 and the dictionary extraction method.", "mentionContextAttributes": {"used": {"value": false, "score": 0.2586323022842407}, "created": {"value": true, "score": 0.9565781950950623}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999905824661255}, "created": {"value": true, "score": 0.9951485991477966}, "shared": {"value": false, "score": 5.960464477539062e-07}}, "references": [{"label": "(Ouyang et al., 2022)", "normalizedForm": "Ouyang et al., 2022", "refKey": 28}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "InstructGPT", "normalizedForm": "InstructGPT", "offsetStart": 61, "offsetEnd": 72}, "version": {"rawForm": "3", "normalizedForm": "3"}, "context": "Additionally, in-context learning with agnostic LLMs such as InstructGPT-3 (Ouyang et al., 2022) where no weight is modified shows good results (Agrawal et al., 2022;Brown et al., 2020) and outperforms specialized smaller models on several clinical tasks.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0003046989440917969}, "created": {"value": false, "score": 3.337860107421875e-06}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999905824661255}, "created": {"value": true, "score": 0.9951485991477966}, "shared": {"value": false, "score": 5.960464477539062e-07}}, "references": [{"label": "(Ouyang et al., 2022)", "normalizedForm": "Ouyang et al., 2022", "refKey": 28, "offsetStart": 6907, "offsetEnd": 6928}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "InstructGPT", "normalizedForm": "InstructGPT", "offsetStart": 61, "offsetEnd": 72}, "version": {"rawForm": "3", "normalizedForm": "3"}, "context": "Our results demonstrate that the knowledge distillation with InstructGPT-3 outperforms the dictionary supervision for extracting clinical entities.", "mentionContextAttributes": {"used": {"value": true, "score": 0.999988317489624}, "created": {"value": false, "score": 2.2411346435546875e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999905824661255}, "created": {"value": true, "score": 0.9951485991477966}, "shared": {"value": false, "score": 5.960464477539062e-07}}, "references": [{"label": "(Ouyang et al., 2022)", "normalizedForm": "Ouyang et al., 2022", "refKey": 28}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "InstructGPT", "normalizedForm": "InstructGPT", "offsetStart": 62, "offsetEnd": 73}, "version": {"rawForm": "3", "normalizedForm": "3"}, "context": "InstructGPT-3 Prediction Analysis For silver, we observe that InstructGPT-3 extracts more entities than original extraction (Table 2).", "mentionContextAttributes": {"used": {"value": true, "score": 0.9802712202072144}, "created": {"value": false, "score": 2.7418136596679688e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999905824661255}, "created": {"value": true, "score": 0.9951485991477966}, "shared": {"value": false, "score": 5.960464477539062e-07}}, "references": [{"label": "(Ouyang et al., 2022)", "normalizedForm": "Ouyang et al., 2022", "refKey": 28}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "InstructGPT", "normalizedForm": "InstructGPT", "offsetStart": 64, "offsetEnd": 75}, "version": {"rawForm": "3", "normalizedForm": "3"}, "context": "The Basque doesn't follow this trend; using a dataset with only InstructGPT-3 annotations (where r = 1) gives the best result among all tried r values.", "mentionContextAttributes": {"used": {"value": false, "score": 0.164781391620636}, "created": {"value": false, "score": 1.9073486328125e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999905824661255}, "created": {"value": true, "score": 0.9951485991477966}, "shared": {"value": false, "score": 5.960464477539062e-07}}, "references": [{"label": "(Ouyang et al., 2022)", "normalizedForm": "Ouyang et al., 2022", "refKey": 28}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "InstructGPT", "normalizedForm": "InstructGPT", "offsetStart": 83, "offsetEnd": 94}, "version": {"rawForm": "3", "normalizedForm": "3"}, "context": "Knowledge Distillation via Weak Supervision Finally, the annotations generated via InstructGPT-3 prediction are used as a training dataset to fine-tune a smaller language model to a NER downstream task.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9643927216529846}, "created": {"value": false, "score": 2.0265579223632812e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999905824661255}, "created": {"value": true, "score": 0.9951485991477966}, "shared": {"value": false, "score": 5.960464477539062e-07}}, "references": [{"label": "(Ouyang et al., 2022)", "normalizedForm": "Ouyang et al., 2022", "refKey": 28}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "InstructGPT", "normalizedForm": "InstructGPT", "offsetStart": 85, "offsetEnd": 96}, "version": {"rawForm": "3", "normalizedForm": "3"}, "context": "For silver with fixed annotations, the quantity of tokens annotated by both methods (InstructGPT-3 vs  We evaluate the direct output of InstructGPT-3 and the aggregated mean score of each model for each language listed in Table 1 using S M onoSilver with r \u2208 {0, 1} and InstructGPT-3 annotation as a train set.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9997220635414124}, "created": {"value": false, "score": 1.7881393432617188e-06}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999905824661255}, "created": {"value": true, "score": 0.9951485991477966}, "shared": {"value": false, "score": 5.960464477539062e-07}}, "references": [{"label": "(Ouyang et al., 2022)", "normalizedForm": "Ouyang et al., 2022", "refKey": 28}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "InstructGPT", "normalizedForm": "InstructGPT", "offsetStart": 93, "offsetEnd": 104}, "version": {"rawForm": "3", "normalizedForm": "3"}, "context": "Furthermore, S M onoSilver reveals that combining annotations from Dictionary extraction and InstructGPT-3 marginally outperforms when r = 1.", "mentionContextAttributes": {"used": {"value": true, "score": 0.6926801800727844}, "created": {"value": false, "score": 2.6226043701171875e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999905824661255}, "created": {"value": true, "score": 0.9951485991477966}, "shared": {"value": false, "score": 5.960464477539062e-07}}, "references": [{"label": "(Ouyang et al., 2022)", "normalizedForm": "Ouyang et al., 2022", "refKey": 28}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "InstructGPT", "normalizedForm": "InstructGPT", "offsetStart": 96, "offsetEnd": 107}, "version": {"rawForm": "3", "normalizedForm": "3"}, "context": "However, in the case of Basque, S M onoSilver does not yield the best results when we have only InstructGPT-3 annotations (r = 1).", "mentionContextAttributes": {"used": {"value": true, "score": 0.9235726594924927}, "created": {"value": false, "score": 2.384185791015625e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999905824661255}, "created": {"value": true, "score": 0.9951485991477966}, "shared": {"value": false, "score": 5.960464477539062e-07}}, "references": [{"label": "(Ouyang et al., 2022)", "normalizedForm": "Ouyang et al., 2022", "refKey": 28}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "InstructGPT", "normalizedForm": "InstructGPT", "offsetStart": 101, "offsetEnd": 112}, "version": {"rawForm": "3", "normalizedForm": "3"}, "context": "So as not to penalize repetitions, we set the presence penalty and frequency penalty to 0. We use an InstructGPT-3 model (text-davinci-003) (Ouyang et al., 2022) to infer the whole annotations for all our experiments.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999791383743286}, "created": {"value": false, "score": 8.726119995117188e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999905824661255}, "created": {"value": true, "score": 0.9951485991477966}, "shared": {"value": false, "score": 5.960464477539062e-07}}, "references": [{"label": "(Ouyang et al., 2022)", "normalizedForm": "Ouyang et al., 2022", "refKey": 28}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "InstructGPT", "normalizedForm": "InstructGPT", "offsetStart": 103, "offsetEnd": 114}, "version": {"rawForm": "3", "normalizedForm": "3"}, "context": "We extend the Agrawal et al. (2022) study in the sense that we propose an in-depth study of the use of InstructGPT-3 to annotate a training dataset. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0004264712333679199}, "created": {"value": true, "score": 0.9951485991477966}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999905824661255}, "created": {"value": true, "score": 0.9951485991477966}, "shared": {"value": false, "score": 5.960464477539062e-07}}, "references": [{"label": "(Ouyang et al., 2022)", "normalizedForm": "Ouyang et al., 2022", "refKey": 28}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "InstructGPT", "normalizedForm": "InstructGPT", "offsetStart": 108, "offsetEnd": 119}, "version": {"rawForm": "3", "normalizedForm": "3"}, "context": "S M onoSilver For all languages except Basque, we obtained better results when we mixed weak supervised and InstructGPT-3 annotations.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999905824661255}, "created": {"value": false, "score": 3.5762786865234375e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999905824661255}, "created": {"value": true, "score": 0.9951485991477966}, "shared": {"value": false, "score": 5.960464477539062e-07}}, "references": [{"label": "(Ouyang et al., 2022)", "normalizedForm": "Ouyang et al., 2022", "refKey": 28}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "InstructGPT", "normalizedForm": "InstructGPT", "offsetStart": 122, "offsetEnd": 133}, "version": {"rawForm": "3", "normalizedForm": "3"}, "context": "A ratio of r = 0 indicates the presence of only dictionary annotations, while a ratio of r = 1 corresponds to exclusively InstructGPT-3 annotations.", "mentionContextAttributes": {"used": {"value": true, "score": 0.8968971967697144}, "created": {"value": false, "score": 8.821487426757812e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999905824661255}, "created": {"value": true, "score": 0.9951485991477966}, "shared": {"value": false, "score": 5.960464477539062e-07}}, "references": [{"label": "(Ouyang et al., 2022)", "normalizedForm": "Ouyang et al., 2022", "refKey": 28}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "InstructGPT", "normalizedForm": "InstructGPT", "offsetStart": 124, "offsetEnd": 135}, "version": {"rawForm": "3", "normalizedForm": "3"}, "context": "This trend is reduced in English and Spanish even if we observed a more important quantity of I clin in tokens annotated by InstructGPT-3 for all languages.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9994210004806519}, "created": {"value": false, "score": 5.0902366638183594e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999905824661255}, "created": {"value": true, "score": 0.9951485991477966}, "shared": {"value": false, "score": 5.960464477539062e-07}}, "references": [{"label": "(Ouyang et al., 2022)", "normalizedForm": "Ouyang et al., 2022", "refKey": 28}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "InstructGPT", "normalizedForm": "InstructGPT", "offsetStart": 136, "offsetEnd": 147}, "version": {"rawForm": "3", "normalizedForm": "3"}, "context": "For silver with fixed annotations, the quantity of tokens annotated by both methods (InstructGPT-3 vs  We evaluate the direct output of InstructGPT-3 and the aggregated mean score of each model for each language listed in Table 1 using S M onoSilver with r \u2208 {0, 1} and InstructGPT-3 annotation as a train set.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9997220635414124}, "created": {"value": false, "score": 1.7881393432617188e-06}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999905824661255}, "created": {"value": true, "score": 0.9951485991477966}, "shared": {"value": false, "score": 5.960464477539062e-07}}, "references": [{"label": "(Ouyang et al., 2022)", "normalizedForm": "Ouyang et al., 2022", "refKey": 28}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "InstructGPT", "normalizedForm": "InstructGPT", "offsetStart": 149, "offsetEnd": 160}, "version": {"rawForm": "3", "normalizedForm": "3"}, "context": "\u2022 The second layer consists of semi-automatic annotation; we use this layer as a train set with the initial annotation or the annotation inferred by InstructGPT-3. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.04760169982910156}, "created": {"value": false, "score": 1.0848045349121094e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999905824661255}, "created": {"value": true, "score": 0.9951485991477966}, "shared": {"value": false, "score": 5.960464477539062e-07}}, "references": [{"label": "(Ouyang et al., 2022)", "normalizedForm": "Ouyang et al., 2022", "refKey": 28}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "InstructGPT", "normalizedForm": "InstructGPT", "offsetStart": 156, "offsetEnd": 167}, "version": {"rawForm": "3", "normalizedForm": "3"}, "context": "This takes form in these contributions: \u2022 We propose a weak supervision approach (Figure 1 bottom) that combines annotations from dictionary extraction and InstructGPT-3, which outperform the approach with only InstructGPT-3 annotation.", "mentionContextAttributes": {"used": {"value": false, "score": 9.131431579589844e-05}, "created": {"value": true, "score": 0.9651966691017151}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999905824661255}, "created": {"value": true, "score": 0.9951485991477966}, "shared": {"value": false, "score": 5.960464477539062e-07}}, "references": [{"label": "(Ouyang et al., 2022)", "normalizedForm": "Ouyang et al., 2022", "refKey": 28}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "InstructGPT", "normalizedForm": "InstructGPT", "offsetStart": 211, "offsetEnd": 222}, "version": {"rawForm": "3", "normalizedForm": "3"}, "context": "This takes form in these contributions: \u2022 We propose a weak supervision approach (Figure 1 bottom) that combines annotations from dictionary extraction and InstructGPT-3, which outperform the approach with only InstructGPT-3 annotation.", "mentionContextAttributes": {"used": {"value": false, "score": 9.131431579589844e-05}, "created": {"value": true, "score": 0.9651966691017151}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999905824661255}, "created": {"value": true, "score": 0.9951485991477966}, "shared": {"value": false, "score": 5.960464477539062e-07}}, "references": [{"label": "(Ouyang et al., 2022)", "normalizedForm": "Ouyang et al., 2022", "refKey": 28}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "InstructGPT", "normalizedForm": "InstructGPT", "offsetStart": 223, "offsetEnd": 234}, "version": {"rawForm": "3", "normalizedForm": "3", "offsetStart": 235, "offsetEnd": 236}, "context": "\u2022 Gold Setting (S M onoGold ): we use silver with fixed annotations as the train set, and we compare encoder models trained on manually corrected annotation (r = 0) and an encoder model trained on the same subset but using InstructGPT-3 prediction annotations (r = 1);", "mentionContextAttributes": {"used": {"value": true, "score": 0.9995355606079102}, "created": {"value": false, "score": 2.0265579223632812e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999905824661255}, "created": {"value": true, "score": 0.9951485991477966}, "shared": {"value": false, "score": 5.960464477539062e-07}}, "references": [{"label": "(Ouyang et al., 2022)", "normalizedForm": "Ouyang et al., 2022", "refKey": 28}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "InstructGPT", "normalizedForm": "InstructGPT", "offsetStart": 226, "offsetEnd": 237}, "version": {"rawForm": "3", "normalizedForm": "3"}, "context": "\u2022 Monolingual Setting (S M onoSilver ): We use a ratio r to control the mix of annotations, with r representing the proportion of annotations from dictionary extraction and (1r) representing the proportion of annotations from InstructGPT-3.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9932757616043091}, "created": {"value": false, "score": 6.318092346191406e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999905824661255}, "created": {"value": true, "score": 0.9951485991477966}, "shared": {"value": false, "score": 5.960464477539062e-07}}, "references": [{"label": "(Ouyang et al., 2022)", "normalizedForm": "Ouyang et al., 2022", "refKey": 28}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "InstructGPT", "normalizedForm": "InstructGPT", "offsetStart": 270, "offsetEnd": 281}, "version": {"rawForm": "3", "normalizedForm": "3"}, "context": "For silver with fixed annotations, the quantity of tokens annotated by both methods (InstructGPT-3 vs  We evaluate the direct output of InstructGPT-3 and the aggregated mean score of each model for each language listed in Table 1 using S M onoSilver with r \u2208 {0, 1} and InstructGPT-3 annotation as a train set.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9997220635414124}, "created": {"value": false, "score": 1.7881393432617188e-06}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999905824661255}, "created": {"value": true, "score": 0.9951485991477966}, "shared": {"value": false, "score": 5.960464477539062e-07}}, "references": [{"label": "(Ouyang et al., 2022)", "normalizedForm": "Ouyang et al., 2022", "refKey": 28}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "InstructGPT", "normalizedForm": "InstructGPT", "offsetStart": 303, "offsetEnd": 314}, "version": {"rawForm": "3", "normalizedForm": "3"}, "context": "The English lexicon resource (supplied by the UMLS meta-thesaurus and terms extracted in gold standard) employed for mapping clinical entities in the text is likely more exten- The line plots with the mean F1-score of the models on the y-axis and the ratio of dictionary annotations and annotations via InstructGPT-3 on the x-axis for S M onoSilver and S M ultiSilver as described in 5.2.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999291896820068}, "created": {"value": false, "score": 1.430511474609375e-06}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999905824661255}, "created": {"value": true, "score": 0.9951485991477966}, "shared": {"value": false, "score": 5.960464477539062e-07}}, "references": [{"label": "(Ouyang et al., 2022)", "normalizedForm": "Ouyang et al., 2022", "refKey": 28}]}], "references": [{"refKey": 28, "tei": "<biblStruct xml:id=\"b28\">\n\t<analytic>\n\t\t<title level=\"a\" type=\"main\">Training language models to follow instructions with human feedback</title>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Long</forename><surname>Ouyang</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Jeff</forename><surname>Wu</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Xu</forename><surname>Jiang</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Diogo</forename><surname>Almeida</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Carroll</forename><forename type=\"middle\">L</forename><surname>Wainwright</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Pamela</forename><surname>Mishkin</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Chong</forename><surname>Zhang</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Sandhini</forename><surname>Agarwal</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Katarina</forename><surname>Slama</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Alex</forename><surname>Ray</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">John</forename><surname>Schulman</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Jacob</forename><surname>Hilton</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Fraser</forename><surname>Kelton</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Luke</forename><surname>Miller</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Maddie</forename><surname>Simens</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Amanda</forename><surname>Askell</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Peter</forename><surname>Welinder</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Paul</forename><surname>Christiano</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Jan</forename><surname>Leike</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Ryan</forename><surname>Lowe</surname></persName>\n\t\t</author>\n\t\t<idno type=\"DOI\">10.48550/arxiv.2203.02155</idno>\n\t</analytic>\n\t<monogr>\n\t\t<title level=\"j\">Advances in Neural Information Processing Systems</title>\n\t\t<imprint>\n\t\t\t<date>2022</date>\n\t\t</imprint>\n\t</monogr>\n</biblStruct>\n"}], "runtime": 13652, "id": "2f3319ebf1dd93c4ab62ca5ff2830ebfc4a960f5", "metadata": {"id": "2f3319ebf1dd93c4ab62ca5ff2830ebfc4a960f5"}, "original_file_path": "../../datalake/Samuel/SOFTware-Sync/downloads/xml/hal-04394012.grobid.tei.xml", "file_name": "hal-04394012.grobid.tei.xml"}