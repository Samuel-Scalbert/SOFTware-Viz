{"application": "software-mentions", "version": "0.8.0", "date": "2024-10-07T11:58+0000", "md5": "5C50B33B7B6014C5DFADB2427C1F674B", "mentions": [{"type": "software", "software-type": "software", "software-name": {"rawForm": "gpuRIR", "normalizedForm": "gpuRIR", "offsetStart": 11, "offsetEnd": 44}, "context": "We use the gpuRIR (Diaz-Guerra et al., 2018) toolkit for room simulation with a T60 reverberation time uniformly sampled between 0.2 and 0.6 s. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9965468049049377}, "created": {"value": false, "score": 3.5762786865234375e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9965468049049377}, "created": {"value": false, "score": 3.5762786865234375e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "BeamformIt", "normalizedForm": "BeamformIt", "offsetStart": 41, "offsetEnd": 51}, "context": "This could be explained by the fact that BeamformIt tends to enhance the source with the highest energy and attenuate the rest.", "mentionContextAttributes": {"used": {"value": false, "score": 0.43449318408966064}, "created": {"value": false, "score": 3.457069396972656e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.43449318408966064}, "created": {"value": false, "score": 3.457069396972656e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Pyannote", "normalizedForm": "Pyannote", "offsetStart": 43, "offsetEnd": 73}, "context": "Popular speech processing toolkits such as Pyannote (Bredin et al., 2020) use this approach. ", "mentionContextAttributes": {"used": {"value": false, "score": 7.033348083496094e-05}, "created": {"value": false, "score": 9.143352508544922e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 7.033348083496094e-05}, "created": {"value": false, "score": 9.143352508544922e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SpecAugment", "normalizedForm": "SpecAugment", "offsetStart": 52, "offsetEnd": 83}, "context": "In parallel, to improve generalization, we also use SpecAugment (Park et al., 2019) on both single-channel and spatial features separately.", "mentionContextAttributes": {"used": {"value": true, "score": 0.8305065631866455}, "created": {"value": false, "score": 4.8279762268066406e-05}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.8305065631866455}, "created": {"value": false, "score": 4.8279762268066406e-05}, "shared": {"value": false, "score": 3.5762786865234375e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Pytorch", "normalizedForm": "Pytorch", "offsetStart": 87, "offsetEnd": 94}, "context": "These computational footprint figures are estimated using the built-in profiler in the Pytorch toolkit and the Performance Application Programming Interface (Terpstra et al., 2009). ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9998102784156799}, "created": {"value": false, "score": 5.245208740234375e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9998102784156799}, "created": {"value": false, "score": 5.245208740234375e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Performance Application Programming Interface", "normalizedForm": "Performance Application Programming Interface", "offsetStart": 111, "offsetEnd": 179}, "context": "These computational footprint figures are estimated using the built-in profiler in the Pytorch toolkit and the Performance Application Programming Interface (Terpstra et al., 2009). ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9998102784156799}, "created": {"value": false, "score": 5.245208740234375e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9998102784156799}, "created": {"value": false, "score": 5.245208740234375e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "BeamformIt", "normalizedForm": "BeamformIt", "offsetStart": 255, "offsetEnd": 287}, "context": "We also include in the comparison of a single-channel ensemble system with no spatial features, where ensembling is done by averaging the OSDC network outputs over all microphones in the array and a single-channel system trained on beamformed audio using BeamformIt (Anguera et al. (2007)). ", "mentionContextAttributes": {"used": {"value": false, "score": 0.020769774913787842}, "created": {"value": false, "score": 2.682209014892578e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.43449318408966064}, "created": {"value": false, "score": 3.457069396972656e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}}], "references": [], "runtime": 9489, "id": "62de9132a476123a3ebfbe803ecb4e40a77d2965", "metadata": {"id": "62de9132a476123a3ebfbe803ecb4e40a77d2965"}, "original_file_path": "../../datalake/Samuel/SOFTware-Sync/downloads/xml/hal-03375681.grobid.tei.xml", "file_name": "hal-03375681.grobid.tei.xml"}