{"application": "software-mentions", "version": "0.8.0", "date": "2024-10-07T11:51+0000", "md5": "79B0F56A59405CF3F28A3CF35715215C", "mentions": [{"type": "software", "software-type": "software", "software-name": {"rawForm": "librispeech", "normalizedForm": "librispeech", "offsetStart": 7, "offsetEnd": 18}, "context": "We use librispeech 960h for all pretraining experiments, and the 10h supervised subset of the Libri-light dataset [32] for fine-tuning. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9985350370407104}, "created": {"value": false, "score": 1.6689300537109375e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9985350370407104}, "created": {"value": false, "score": 1.6689300537109375e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "HuBERT", "normalizedForm": "HuBERT", "offsetStart": 11, "offsetEnd": 17}, "context": "We use the HuBERT selfsupervised approach [3] as our test bed in this paper, both with encoder-only and encoder-decoder pre-training setups.", "mentionContextAttributes": {"used": {"value": false, "score": 0.010287284851074219}, "created": {"value": false, "score": 0.018986165523529053}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9998762607574463}, "created": {"value": true, "score": 0.7403507232666016}, "shared": {"value": false, "score": 5.960464477539062e-07}}, "references": [{"label": "[3]", "normalizedForm": "[3]", "refKey": 3}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "HuBERT", "normalizedForm": "HuBERT", "offsetStart": 16, "offsetEnd": 22}, "context": "We stick to the HuBERT BASE architecture for our encoders with the same training recipe for both pretraining and fine-tuning.", "mentionContextAttributes": {"used": {"value": false, "score": 0.14872246980667114}, "created": {"value": true, "score": 0.7403507232666016}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9998762607574463}, "created": {"value": true, "score": 0.7403507232666016}, "shared": {"value": false, "score": 5.960464477539062e-07}}, "references": [{"label": "[3]", "normalizedForm": "[3]", "refKey": 3}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "HuBERT", "normalizedForm": "HuBERT", "offsetStart": 22, "offsetEnd": 28}, "context": "The Hidden Unit BERT (HuBERT) model [3] discretizes the input audio first, then apply the MLM to predict the audio tokens given masked continuous input representations.", "mentionContextAttributes": {"used": {"value": false, "score": 0.055298447608947754}, "created": {"value": false, "score": 3.337860107421875e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9998762607574463}, "created": {"value": true, "score": 0.7403507232666016}, "shared": {"value": false, "score": 5.960464477539062e-07}}, "references": [{"label": "[3]", "normalizedForm": "[3]", "refKey": 3, "offsetStart": 4423, "offsetEnd": 4426}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "HuBERT", "normalizedForm": "HuBERT", "offsetStart": 24, "offsetEnd": 30}, "context": "Since we use the public HuBERT model for generating units with different strategies and using them for another round of pretraining, we trained a baseline model which uses the default k-means clustering for training.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9982872605323792}, "created": {"value": false, "score": 2.2292137145996094e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9998762607574463}, "created": {"value": true, "score": 0.7403507232666016}, "shared": {"value": false, "score": 5.960464477539062e-07}}, "references": [{"label": "[3]", "normalizedForm": "[3]", "refKey": 3}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "HuBERT", "normalizedForm": "HuBERT", "offsetStart": 29, "offsetEnd": 35}, "context": "The WavLM model [23] extends HuBERT by mixing speakers and different types of noise to the input while extending the model to denoise inputs in addition to the masked prediction.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00010752677917480469}, "created": {"value": false, "score": 5.364418029785156e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9998762607574463}, "created": {"value": true, "score": 0.7403507232666016}, "shared": {"value": false, "score": 5.960464477539062e-07}}, "references": [{"label": "[3]", "normalizedForm": "[3]", "refKey": 3}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "HuBERT", "normalizedForm": "HuBERT", "offsetStart": 30, "offsetEnd": 36}, "context": "[4] extended the encoder-only HuBERT model and showed a solid performance for speech translation and other NLP tasks.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9995488524436951}, "created": {"value": false, "score": 2.4318695068359375e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9998762607574463}, "created": {"value": true, "score": 0.7403507232666016}, "shared": {"value": false, "score": 5.960464477539062e-07}}, "references": [{"label": "[3]", "normalizedForm": "[3]", "refKey": 3}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "HuBERT", "normalizedForm": "HuBERT", "offsetStart": 33, "offsetEnd": 39}, "context": "The discovered units by baseline HuBERT models are mainly at the phonetic or sub-phonetic level. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.3447325825691223}, "created": {"value": false, "score": 9.107589721679688e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9998762607574463}, "created": {"value": true, "score": 0.7403507232666016}, "shared": {"value": false, "score": 5.960464477539062e-07}}, "references": [{"label": "[3]", "normalizedForm": "[3]", "refKey": 3}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "HuBERT", "normalizedForm": "HuBERT", "offsetStart": 34, "offsetEnd": 40}, "context": "Both proposals rely on a baseline HuBERT model to estimate discrete acoustic units for each input utterance.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0002676844596862793}, "created": {"value": false, "score": 0.00010919570922851562}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9998762607574463}, "created": {"value": true, "score": 0.7403507232666016}, "shared": {"value": false, "score": 5.960464477539062e-07}}, "references": [{"label": "[3]", "normalizedForm": "[3]", "refKey": 3}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "HuBERT", "normalizedForm": "HuBERT", "offsetStart": 36, "offsetEnd": 42}, "context": "Clustering is done using the public HuBERT BASE model. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9316164255142212}, "created": {"value": false, "score": 0.00012373924255371094}, "shared": {"value": false, "score": 5.960464477539062e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9998762607574463}, "created": {"value": true, "score": 0.7403507232666016}, "shared": {"value": false, "score": 5.960464477539062e-07}}, "references": [{"label": "[3]", "normalizedForm": "[3]", "refKey": 3}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Huggingface", "normalizedForm": "Huggingface", "offsetStart": 46, "offsetEnd": 57}, "context": "For BPE training, we use the BPE encoder from Huggingface tokenizer vocabulary size of 30,000.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9977602958679199}, "created": {"value": false, "score": 4.5299530029296875e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9977602958679199}, "created": {"value": false, "score": 4.5299530029296875e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "HuBERT", "normalizedForm": "HuBERT", "offsetStart": 47, "offsetEnd": 53}, "context": "All these models represent third iterations of HuBERT training. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.02642291784286499}, "created": {"value": false, "score": 0.0001531839370727539}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9998762607574463}, "created": {"value": true, "score": 0.7403507232666016}, "shared": {"value": false, "score": 5.960464477539062e-07}}, "references": [{"label": "[3]", "normalizedForm": "[3]", "refKey": 3}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "HuBERT", "normalizedForm": "HuBERT", "offsetStart": 48, "offsetEnd": 54}, "context": "In the experiments, we reason about the learned HuBERT units using these metrics rather than relying solely on the downstream ASR performance.", "mentionContextAttributes": {"used": {"value": true, "score": 0.999218225479126}, "created": {"value": false, "score": 0.00025981664657592773}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9998762607574463}, "created": {"value": true, "score": 0.7403507232666016}, "shared": {"value": false, "score": 5.960464477539062e-07}}, "references": [{"label": "[3]", "normalizedForm": "[3]", "refKey": 3}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "HuBERT", "normalizedForm": "HuBERT", "offsetStart": 54, "offsetEnd": 60}, "context": "As found in other studies [33], the topmost layers of HuBERT are not the best feature representations. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0014057755470275879}, "created": {"value": false, "score": 5.4836273193359375e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9998762607574463}, "created": {"value": true, "score": 0.7403507232666016}, "shared": {"value": false, "score": 5.960464477539062e-07}}, "references": [{"label": "[3]", "normalizedForm": "[3]", "refKey": 3}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "HuBERT", "normalizedForm": "HuBERT", "offsetStart": 65, "offsetEnd": 71}, "context": "Using an order of magnitude more discrete units, compared to the HuBERT model, [24] showed that the masked prediction loss would still yield competitive performance with randomly assigned and fixed clusters.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9998762607574463}, "created": {"value": false, "score": 1.1563301086425781e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9998762607574463}, "created": {"value": true, "score": 0.7403507232666016}, "shared": {"value": false, "score": 5.960464477539062e-07}}, "references": [{"label": "[24]", "normalizedForm": "[24]", "refKey": 24, "offsetStart": 5238, "offsetEnd": 5242}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "HuBERT", "normalizedForm": "HuBERT", "offsetStart": 79, "offsetEnd": 85}, "context": "Conducting seq2seq pretraining through adding an autoregressive decoder to the HuBERT model was proposed in [4,12] as an extension of the standard encoder-only Hubert pretraining.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00034499168395996094}, "created": {"value": false, "score": 0.001030564308166504}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9998762607574463}, "created": {"value": true, "score": 0.7403507232666016}, "shared": {"value": false, "score": 5.960464477539062e-07}}, "references": [{"label": "[3]", "normalizedForm": "[3]", "refKey": 3}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "HuBERT", "normalizedForm": "HuBERT", "offsetStart": 118, "offsetEnd": 124}, "context": "They then deduplicate units to represent an input segment rather than a 20ms frame (the output frame rate of baseline HuBERT model) and use this unit sequence as the target for label-smoothed cross-entropy loss of the decoder.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9898762106895447}, "created": {"value": false, "score": 1.049041748046875e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9998762607574463}, "created": {"value": true, "score": 0.7403507232666016}, "shared": {"value": false, "score": 5.960464477539062e-07}}, "references": [{"label": "[3]", "normalizedForm": "[3]", "refKey": 3}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "HuBERT", "normalizedForm": "HuBERT", "offsetStart": 120, "offsetEnd": 126}, "context": "Acoustic piece [25] proposed to learn longer-range units by applying the SentencePiece algorithm [26] on top of learned HuBERT units.", "mentionContextAttributes": {"used": {"value": false, "score": 0.009465038776397705}, "created": {"value": false, "score": 8.726119995117188e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9998762607574463}, "created": {"value": true, "score": 0.7403507232666016}, "shared": {"value": false, "score": 5.960464477539062e-07}}, "references": [{"label": "[3]", "normalizedForm": "[3]", "refKey": 3}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "HuBERT", "normalizedForm": "HuBERT", "offsetStart": 152, "offsetEnd": 158}, "context": "We add a 6-layer decoder for encoder-decoder models and train the whole model for 100k updates for pretraining (with encoder initialization from public HuBERT) and 10k updates for fine-tuning. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0003688335418701172}, "created": {"value": false, "score": 0.025228679180145264}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9998762607574463}, "created": {"value": true, "score": 0.7403507232666016}, "shared": {"value": false, "score": 5.960464477539062e-07}}, "references": [{"label": "[3]", "normalizedForm": "[3]", "refKey": 3}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "HuBERT", "normalizedForm": "HuBERT", "offsetStart": 194, "offsetEnd": 200}, "context": "During their training, many approaches benefited from auxiliary discrete acoustic units derived from latent continuous representations to facilitate learning, e.g., VQ-VAE [1], Wav2vec 2.0 [2], HuBERT [3].", "mentionContextAttributes": {"used": {"value": false, "score": 0.1205018162727356}, "created": {"value": false, "score": 7.128715515136719e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9998762607574463}, "created": {"value": true, "score": 0.7403507232666016}, "shared": {"value": false, "score": 5.960464477539062e-07}}, "references": [{"label": "[3]", "normalizedForm": "[3]", "refKey": 3}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "HuBERT", "normalizedForm": "HuBERT", "offsetStart": 210, "offsetEnd": 216}, "context": "The original Hubert paper [3] used a single latent layer of representations to train discrete codebooks; however, multiple layers of representations were used in [29] to represent the distillation targets of a HuBERT model.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9984816908836365}, "created": {"value": false, "score": 8.821487426757812e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9998762607574463}, "created": {"value": true, "score": 0.7403507232666016}, "shared": {"value": false, "score": 5.960464477539062e-07}}, "references": [{"label": "[3]", "normalizedForm": "[3]", "refKey": 3}]}], "references": [{"refKey": 3, "tei": "<biblStruct xml:id=\"b3\">\n\t<analytic>\n\t\t<title level=\"a\" type=\"main\">HuBERT: Self-Supervised Speech Representation Learning by Masked Prediction of Hidden Units</title>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Wei-Ning</forename><surname>Hsu</surname></persName>\n\t\t\t<idno type=\"ORCID\">0000-0001-5546-5217</idno>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Benjamin</forename><surname>Bolte</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Yao-Hung Hubert</forename><surname>Tsai</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Kushal</forename><surname>Lakhotia</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Ruslan</forename><surname>Salakhutdinov</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Abdelrahman</forename><surname>Mohamed</surname></persName>\n\t\t</author>\n\t\t<idno type=\"DOI\">10.1109/taslp.2021.3122291</idno>\n\t</analytic>\n\t<monogr>\n\t\t<title level=\"j\">IEEE/ACM Transactions on Audio, Speech, and Language Processing</title>\n\t\t<title level=\"j\" type=\"abbrev\">IEEE/ACM Trans. Audio Speech Lang. Process.</title>\n\t\t<idno type=\"ISSN\">2329-9290</idno>\n\t\t<idno type=\"ISSNe\">2329-9304</idno>\n\t\t<imprint>\n\t\t\t<biblScope unit=\"volume\">29</biblScope>\n\t\t\t<biblScope unit=\"page\" from=\"3451\" to=\"3460\" />\n\t\t\t<date type=\"published\" when=\"2021\">2021</date>\n\t\t\t<publisher>Institute of Electrical and Electronics Engineers (IEEE)</publisher>\n\t\t</imprint>\n\t</monogr>\n</biblStruct>\n"}, {"refKey": 24, "tei": "<biblStruct xml:id=\"b24\">\n\t<monogr>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Chung-Cheng</forename><surname>Chiu</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">James</forename><surname>Qin</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Yu</forename><surname>Zhang</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Jiahui</forename><surname>Yu</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Yonghui</forename><surname>Wu</surname></persName>\n\t\t</author>\n\t\t<title level=\"m\">Self-supervised learning with randomprojection quantizer for speech recognition</title>\n\t\t<imprint>\n\t\t\t<date>2022</date>\n\t\t</imprint>\n\t</monogr>\n</biblStruct>\n"}], "runtime": 2928, "id": "d0796fdf166bd0f0307ad1fa878f110ca6658430", "metadata": {"id": "d0796fdf166bd0f0307ad1fa878f110ca6658430"}, "original_file_path": "../../datalake/Samuel/SOFTware-Sync/downloads/xml/hal-04208427.grobid.tei.xml", "file_name": "hal-04208427.grobid.tei.xml"}