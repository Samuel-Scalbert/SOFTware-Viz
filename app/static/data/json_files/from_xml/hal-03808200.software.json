{"application": "software-mentions", "version": "0.8.0", "date": "2024-10-07T12:50+0000", "md5": "D02CF379ED5372E9DB5B6BA5A8113302", "mentions": [{"type": "software", "software-type": "software", "software-name": {"rawForm": "Wav2vec", "normalizedForm": "Wav2vec", "offsetStart": 0, "offsetEnd": 7}, "version": {"rawForm": "2", "normalizedForm": "2", "offsetStart": 8, "offsetEnd": 9}, "context": "Wav2vec 2.0 consists of three main modules. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.004112184047698975}, "created": {"value": false, "score": 1.1563301086425781e-05}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999383687973022}, "created": {"value": false, "score": 1.3828277587890625e-05}, "shared": {"value": false, "score": 7.152557373046875e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Wav2vec", "normalizedForm": "Wav2vec", "offsetStart": 0, "offsetEnd": 7}, "version": {"rawForm": "2", "normalizedForm": "2"}, "context": "Wav2vec 2.0 maps onto brain responses to speech.", "mentionContextAttributes": {"used": {"value": false, "score": 0.30156785249710083}, "created": {"value": false, "score": 5.125999450683594e-06}, "shared": {"value": false, "score": 5.960464477539062e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999383687973022}, "created": {"value": false, "score": 1.3828277587890625e-05}, "shared": {"value": false, "score": 7.152557373046875e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Wav2vec", "normalizedForm": "Wav2vec", "offsetStart": 0, "offsetEnd": 7}, "version": {"rawForm": "2", "normalizedForm": "2"}, "context": "Wav2vec 2.0 and the brain learn language specific representations.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999383687973022}, "created": {"value": false, "score": 1.3828277587890625e-05}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999383687973022}, "created": {"value": false, "score": 1.3828277587890625e-05}, "shared": {"value": false, "score": 7.152557373046875e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "spaCy", "normalizedForm": "spaCy", "offsetStart": 7, "offsetEnd": 12}, "context": "We use spaCy to compute the word embedding (medium model, d=300), and their part-of-speech (categorical feature, d=19).", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999816417694092}, "created": {"value": false, "score": 3.4570693969726562e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999934434890747}, "created": {"value": false, "score": 3.4570693969726562e-06}, "shared": {"value": false, "score": 7.152557373046875e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Wav2vec", "normalizedForm": "Wav2vec", "offsetStart": 33, "offsetEnd": 40}, "version": {"rawForm": "2", "normalizedForm": "2"}, "context": "A.1 Self-supervised loss formula Wav2vec 2.0, when trained in a self-supervised way, uses a loss (L) which is the weighted combination of two losses: one diversity loss (L d ), which pushes the quantization module to contain representations that are as diverse as possible, and one Contrastive Predictive Coding loss (L m ), which pushes the model to choose, from the context network output c, the right quantized representation (q) of some masked input, among other possible representations.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9318897724151611}, "created": {"value": false, "score": 2.7418136596679688e-06}, "shared": {"value": false, "score": 7.152557373046875e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999383687973022}, "created": {"value": false, "score": 1.3828277587890625e-05}, "shared": {"value": false, "score": 7.152557373046875e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "eS-peakNG", "normalizedForm": "eS-peakNG", "offsetStart": 37, "offsetEnd": 47}, "context": "We phonemize these annotations using eS-peakNG2 . ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999861717224121}, "created": {"value": false, "score": 1.9073486328125e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999861717224121}, "created": {"value": false, "score": 1.9073486328125e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Timit", "normalizedForm": "Timit", "offsetStart": 38, "offsetEnd": 43}, "context": "We use a subset of 1,680 samples from Timit, each sample being an audio recording of a short sentence (<10 seconds) from 24 speakers.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9982900023460388}, "created": {"value": false, "score": 7.3909759521484375e-06}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999802112579346}, "created": {"value": false, "score": 0.012276291847229004}, "shared": {"value": false, "score": 7.748603820800781e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Timit", "normalizedForm": "Timit", "offsetStart": 46, "offsetEnd": 51}, "context": "The time alignments for words are provided by Timit.", "mentionContextAttributes": {"used": {"value": true, "score": 0.988206684589386}, "created": {"value": false, "score": 7.104873657226562e-05}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999802112579346}, "created": {"value": false, "score": 0.012276291847229004}, "shared": {"value": false, "score": 7.748603820800781e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Timit", "normalizedForm": "Timit", "offsetStart": 47, "offsetEnd": 52}, "context": "For this, we perform a ridge regression on the Timit dataset7 to predict five auditory and linguistic features from the activation functions of each layer and model of the present paper.", "mentionContextAttributes": {"used": {"value": true, "score": 0.999664306640625}, "created": {"value": false, "score": 0.0050424933433532715}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999802112579346}, "created": {"value": false, "score": 0.012276291847229004}, "shared": {"value": false, "score": 7.748603820800781e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Timit", "normalizedForm": "Timit", "offsetStart": 50, "offsetEnd": 55}, "context": "We use the transcripts and alignments provided in Timit.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9967085123062134}, "created": {"value": false, "score": 1.8358230590820312e-05}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999802112579346}, "created": {"value": false, "score": 0.012276291847229004}, "shared": {"value": false, "score": 7.748603820800781e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Timit", "normalizedForm": "Timit", "offsetStart": 50, "offsetEnd": 55}, "context": "We train and test the linear probe on a subset of Timit data (https://catalog.ldc.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999802112579346}, "created": {"value": false, "score": 0.012276291847229004}, "shared": {"value": false, "score": 7.748603820800781e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999802112579346}, "created": {"value": false, "score": 0.012276291847229004}, "shared": {"value": false, "score": 7.748603820800781e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Laser", "normalizedForm": "Laser", "offsetStart": 53, "offsetEnd": 58}, "context": "\u2022 the sentence embedding of each sample, provided by Laser.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999905824661255}, "created": {"value": false, "score": 2.2292137145996094e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999934434890747}, "created": {"value": false, "score": 2.2292137145996094e-05}, "shared": {"value": false, "score": 7.152557373046875e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "spaCy", "normalizedForm": "spaCy", "offsetStart": 72, "offsetEnd": 77}, "context": "English model, d=300), the Part-Of-Speech (POS) of the word provided by spaCy (categorical feature, n=19), and the embedding of the sentence, computed using Laser (https://github.com/facebookresearch/LASER)", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999934434890747}, "created": {"value": false, "score": 1.6689300537109375e-06}, "shared": {"value": false, "score": 7.152557373046875e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999934434890747}, "created": {"value": false, "score": 3.4570693969726562e-06}, "shared": {"value": false, "score": 7.152557373046875e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "scikit-learn", "normalizedForm": "scikit-learn", "offsetStart": 94, "offsetEnd": 131}, "context": "Precisely, for each For each layer of each network, we train a l2-penalized linear model from scikit-learn [Pedregosa et al., 2011] to predict several linguistic categories given the embedding. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.3602043390274048}, "created": {"value": false, "score": 7.092952728271484e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.3602043390274048}, "created": {"value": false, "score": 7.092952728271484e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Sox", "normalizedForm": "Sox", "offsetStart": 143, "offsetEnd": 146}, "context": "All the audio datasets were randomly subsampled to have an approximate size of 600 hours, downsampled to 16 kHz and converted to mono with the Sox software1 . ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999723434448242}, "created": {"value": false, "score": 4.410743713378906e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999723434448242}, "created": {"value": false, "score": 4.410743713378906e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "fsaverage", "normalizedForm": "fsaverage", "offsetStart": 145, "offsetEnd": 154}, "context": "These voxels are then projected onto a brain surface using nilearn's vol_to_surf function with defaults parameters [Abraham et al., 2014] and a 'fsaverage6' template surface [Fischl, 2012]. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9998568296432495}, "created": {"value": false, "score": 4.291534423828125e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9998568296432495}, "created": {"value": false, "score": 4.291534423828125e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "fsaverage6", "normalizedForm": "fsaverage6", "offsetStart": 149, "offsetEnd": 159}, "context": "For Narratives, we did not perform additional preprocessing: we use the public preprocessing of the dataset already projected on the surface space (\"fsaverage6\") without spatial smoothing (labelled \"afni-nosmooth\" in the data repository). ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9921370148658752}, "created": {"value": false, "score": 2.2649765014648438e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9921370148658752}, "created": {"value": false, "score": 2.2649765014648438e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Laser", "normalizedForm": "Laser", "offsetStart": 157, "offsetEnd": 162}, "context": "English model, d=300), the Part-Of-Speech (POS) of the word provided by spaCy (categorical feature, n=19), and the embedding of the sentence, computed using Laser (https://github.com/facebookresearch/LASER) ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999934434890747}, "created": {"value": false, "score": 1.6689300537109375e-06}, "shared": {"value": false, "score": 7.152557373046875e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999934434890747}, "created": {"value": false, "score": 2.2292137145996094e-05}, "shared": {"value": false, "score": 7.152557373046875e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LibriSpeech", "normalizedForm": "LibriSpeech", "offsetStart": 173, "offsetEnd": 208}, "context": "In each case, the training was performed using the same configuration file (namely, the base configuration provided in the fairseq repository for pretraining wav2vec 2.0 on LibriSpeech [Panayotov et al., 2015]). ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9997386336326599}, "created": {"value": false, "score": 6.9141387939453125e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997386336326599}, "created": {"value": false, "score": 6.9141387939453125e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "spaCy", "normalizedForm": "spaCy", "offsetStart": 174, "offsetEnd": 179}, "context": "The tested categories are the following: MEL (the MEL spectrogram of the audio, d=128), phone (the phoneme, categorical, d=39), the word embedding of the word (computed with spaCy (https://spacy.io)", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999618530273438}, "created": {"value": false, "score": 1.6689300537109375e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999934434890747}, "created": {"value": false, "score": 3.4570693969726562e-06}, "shared": {"value": false, "score": 7.152557373046875e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Freesurfer", "normalizedForm": "Freesurfer", "offsetStart": 207, "offsetEnd": 231}, "context": "Consequently, for each language condition separately, we subselected the cortical voxels by computing a brain mask using the average of all participants' fMRI data realigned onto a common template brain via Freesurfer [Fischl, 2012]. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999911785125732}, "created": {"value": false, "score": 8.940696716308594e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999911785125732}, "created": {"value": false, "score": 8.940696716308594e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}}], "references": [], "runtime": 4561, "id": "6e82198a9991258886d03d871f341d63b722379c", "metadata": {"id": "6e82198a9991258886d03d871f341d63b722379c"}, "original_file_path": "../../datalake/Samuel/SOFTware-Sync/downloads/xml/hal-03808200.grobid.tei.xml", "file_name": "hal-03808200.grobid.tei.xml"}