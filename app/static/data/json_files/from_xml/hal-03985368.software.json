{"application": "software-mentions", "version": "0.8.0", "date": "2024-10-07T11:55+0000", "md5": "20AAA38ACFD145EE043635EFEEED6519", "mentions": [{"type": "software", "software-type": "software", "software-name": {"rawForm": "fairseq", "normalizedForm": "fairseq", "offsetStart": 1, "offsetEnd": 8}, "context": "/fairseq", "mentionContextAttributes": {"used": {"value": false, "score": 0.0012406110763549805}, "created": {"value": false, "score": 6.961822509765625e-05}, "shared": {"value": false, "score": 5.960464477539062e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.03405636548995972}, "created": {"value": false, "score": 0.0022846460342407227}, "shared": {"value": false, "score": 5.960464477539062e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CrowdMOS", "normalizedForm": "CrowdMOS", "offsetStart": 4, "offsetEnd": 12}, "context": "The CrowdMOS package (Ribeiro et al., 2011) was used for all subjective evaluations using the recommended recipes for detecting and discarding inaccurate scores. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.999976396560669}, "created": {"value": false, "score": 5.841255187988281e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999976396560669}, "created": {"value": false, "score": 5.841255187988281e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "references": [{"label": "(Ribeiro et al., 2011)", "normalizedForm": "Ribeiro et al., 2011", "refKey": 41, "offsetStart": 27197, "offsetEnd": 27219}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "HuBERT", "normalizedForm": "HuBERT", "offsetStart": 11, "offsetEnd": 17}, "context": "We train a HuBERT Base model (Hsu et al., 2021a) from raw audio.", "mentionContextAttributes": {"used": {"value": false, "score": 0.049079298973083496}, "created": {"value": true, "score": 0.9035272598266602}, "shared": {"value": false, "score": 9.5367431640625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999871253967285}, "created": {"value": true, "score": 0.9655576944351196}, "shared": {"value": false, "score": 9.5367431640625e-07}}, "references": [{"label": "(Hsu et al., 2021a)", "normalizedForm": "Hsu et al., 2021a", "refKey": 0}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "HifiGAN", "normalizedForm": "HifiGAN", "offsetStart": 13, "offsetEnd": 20}, "context": "We train the HifiGAN model on a small subset of the Fisher dataset segments consisting of 120 speakers with 10 minutes each.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9868826270103455}, "created": {"value": false, "score": 0.482607901096344}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9868826270103455}, "created": {"value": false, "score": 0.482607901096344}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "pyannote", "normalizedForm": "pyannote", "offsetStart": 19, "offsetEnd": 27}, "context": "https://github.com/pyannote/pyannote", "mentionContextAttributes": {"used": {"value": false, "score": 0.00031006336212158203}, "created": {"value": false, "score": 1.9073486328125e-05}, "shared": {"value": true, "score": 0.9866710305213928}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9994146823883057}, "created": {"value": false, "score": 1.9073486328125e-05}, "shared": {"value": true, "score": 0.9866710305213928}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Google TTS API", "normalizedForm": "Google TTS API", "offsetStart": 20, "offsetEnd": 34}, "context": "Finally, we use the Google TTS API to synthesize generated conversations, with two different voices indicating two different speakers.", "mentionContextAttributes": {"used": {"value": true, "score": 0.999962568283081}, "created": {"value": false, "score": 7.164478302001953e-05}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999962568283081}, "created": {"value": false, "score": 7.164478302001953e-05}, "shared": {"value": false, "score": 4.76837158203125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "HuBERT", "normalizedForm": "HuBERT", "offsetStart": 21, "offsetEnd": 27}, "context": "We therefore train a HuBERT model (Hsu et al., 2021a) directly on our conversation dataset in order to obtain domain-appropriate phonetic representation (see Appendix Section A for an analysis).", "mentionContextAttributes": {"used": {"value": false, "score": 0.0004177689552307129}, "created": {"value": true, "score": 0.9655576944351196}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999871253967285}, "created": {"value": true, "score": 0.9655576944351196}, "shared": {"value": false, "score": 9.5367431640625e-07}}, "references": [{"label": "(Hsu et al., 2021a)", "normalizedForm": "Hsu et al., 2021a", "refKey": 0, "offsetStart": 10322, "offsetEnd": 10341}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "HuBERT", "normalizedForm": "HuBERT", "offsetStart": 23, "offsetEnd": 29}, "context": "4  For the training of HuBERT and HifiGAN models, we follow the preprocessing steps of Kuchaiev et al. (2019) 5 to obtain a collection of single-channel voice segments of the Fisher dataset.", "mentionContextAttributes": {"used": {"value": false, "score": 0.3403477072715759}, "created": {"value": false, "score": 7.092952728271484e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999871253967285}, "created": {"value": true, "score": 0.9655576944351196}, "shared": {"value": false, "score": 9.5367431640625e-07}}, "references": [{"label": "(Hsu et al., 2021a)", "normalizedForm": "Hsu et al., 2021a", "refKey": 0}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "HuBERT", "normalizedForm": "HuBERT", "offsetStart": 25, "offsetEnd": 31}, "context": "For the encoder we adopt HuBERT, (Hsu et al., 2021a) followed by k-means clustering; for the decoder network we use a modified Hifi-GAN neural vocoder (Kong et al., 2020), similarly to Polyak et al. (2021). ", "mentionContextAttributes": {"used": {"value": true, "score": 0.8406689763069153}, "created": {"value": false, "score": 2.8014183044433594e-05}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999871253967285}, "created": {"value": true, "score": 0.9655576944351196}, "shared": {"value": false, "score": 9.5367431640625e-07}}, "references": [{"label": "(Hsu et al., 2021a)", "normalizedForm": "Hsu et al., 2021a", "refKey": 0, "offsetStart": 9481, "offsetEnd": 9500}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "DialoGPT", "normalizedForm": "DialoGPT", "offsetStart": 26, "offsetEnd": 34}, "context": "We employ the open-source DialoGPT model9  (Zhang et al., 2019) to compute the perplexity on the turn-based sequences.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999397993087769}, "created": {"value": false, "score": 0.010425031185150146}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999397993087769}, "created": {"value": false, "score": 0.010425031185150146}, "shared": {"value": true, "score": 0.9351137280464172}}, "references": [{"label": "(Zhang et al., 2019)", "normalizedForm": "Zhang et al., 2019", "refKey": 64, "offsetStart": 25506, "offsetEnd": 25526}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "HuBERT", "normalizedForm": "HuBERT", "offsetStart": 28, "offsetEnd": 34}, "context": "In Table A1, we compare the HuBERT Base model (Hsu et al., 2021a) trained on 2000 hours of Fisher dataset versus 1000 hours of Librispeech dataset on the machine-ABX phonetic test.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9960572719573975}, "created": {"value": false, "score": 5.364418029785156e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999871253967285}, "created": {"value": true, "score": 0.9655576944351196}, "shared": {"value": false, "score": 9.5367431640625e-07}}, "references": [{"label": "(Hsu et al., 2021a)", "normalizedForm": "Hsu et al., 2021a", "refKey": 0}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "pyannote", "normalizedForm": "pyannote", "offsetStart": 28, "offsetEnd": 36}, "context": "https://github.com/pyannote/pyannote", "mentionContextAttributes": {"used": {"value": false, "score": 0.00031006336212158203}, "created": {"value": false, "score": 1.9073486328125e-05}, "shared": {"value": true, "score": 0.9866710305213928}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9994146823883057}, "created": {"value": false, "score": 1.9073486328125e-05}, "shared": {"value": true, "score": 0.9866710305213928}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "DialoGPT", "normalizedForm": "DialoGPT", "offsetStart": 33, "offsetEnd": 41}, "context": "https://huggingface.co/microsoft/DialoGPT -medium.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00019913911819458008}, "created": {"value": false, "score": 2.3245811462402344e-05}, "shared": {"value": true, "score": 0.9351137280464172}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999397993087769}, "created": {"value": false, "score": 0.010425031185150146}, "shared": {"value": true, "score": 0.9351137280464172}}, "references": [{"label": "(Zhang et al., 2019)", "normalizedForm": "Zhang et al., 2019", "refKey": 64}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "HifiGAN", "normalizedForm": "HifiGAN", "offsetStart": 34, "offsetEnd": 41}, "context": "4  For the training of HuBERT and HifiGAN models, we follow the preprocessing steps of Kuchaiev et al. (2019) 5 to obtain a collection of single-channel voice segments of the Fisher dataset.", "mentionContextAttributes": {"used": {"value": false, "score": 0.3403477072715759}, "created": {"value": false, "score": 7.092952728271484e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9868826270103455}, "created": {"value": false, "score": 0.482607901096344}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "fairseq", "normalizedForm": "fairseq", "offsetStart": 54, "offsetEnd": 80}, "context": "The implementation of the DLM model is done using the fairseq (Ott et al., 2019) toolkit. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.03405636548995972}, "created": {"value": false, "score": 0.0022846460342407227}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.03405636548995972}, "created": {"value": false, "score": 0.0022846460342407227}, "shared": {"value": false, "score": 5.960464477539062e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "HifiGAN", "normalizedForm": "HifiGAN", "offsetStart": 71, "offsetEnd": 78}, "context": "Voices for the waveform generation are chosen from the speakers in the HifiGAN training set.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9552057981491089}, "created": {"value": false, "score": 0.001976490020751953}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9868826270103455}, "created": {"value": false, "score": 0.482607901096344}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "HuBERT", "normalizedForm": "HuBERT", "offsetStart": 77, "offsetEnd": 83}, "context": "The discrete units are then obtained by clustering the representation of the HuBERT model using the k-means algorithm.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999793767929077}, "created": {"value": false, "score": 9.5367431640625e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999871253967285}, "created": {"value": true, "score": 0.9655576944351196}, "shared": {"value": false, "score": 9.5367431640625e-07}}, "references": [{"label": "(Hsu et al., 2021a)", "normalizedForm": "Hsu et al., 2021a", "refKey": 0}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "HuBERT", "normalizedForm": "HuBERT", "offsetStart": 115, "offsetEnd": 121}, "context": "Here, we only used the transcriptions to obtain speech segments containing vocal activity to train the HifiGan and HuBERT model.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999871253967285}, "created": {"value": false, "score": 1.0848045349121094e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999871253967285}, "created": {"value": true, "score": 0.9655576944351196}, "shared": {"value": false, "score": 9.5367431640625e-07}}, "references": [{"label": "(Hsu et al., 2021a)", "normalizedForm": "Hsu et al., 2021a", "refKey": 0}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "pyannote", "normalizedForm": "pyannote", "offsetStart": 121, "offsetEnd": 129}, "context": "We compute the turn-taking events as defined in Section 3.4 using the samples generated by the models with VAD using the pyannote library7  (Bredin et al., 2020).", "mentionContextAttributes": {"used": {"value": true, "score": 0.9994146823883057}, "created": {"value": false, "score": 3.337860107421875e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9994146823883057}, "created": {"value": false, "score": 1.9073486328125e-05}, "shared": {"value": true, "score": 0.9866710305213928}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "DialoGPT", "normalizedForm": "DialoGPT", "offsetStart": 143, "offsetEnd": 151}, "context": "PPL), which is the perplexity of the generated sequence given the concatenation of the prompt sequence  and generated sequence as input to the DialoGPT model.", "mentionContextAttributes": {"used": {"value": true, "score": 0.811488151550293}, "created": {"value": false, "score": 4.291534423828125e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999397993087769}, "created": {"value": false, "score": 0.010425031185150146}, "shared": {"value": true, "score": 0.9351137280464172}}, "references": [{"label": "(Zhang et al., 2019)", "normalizedForm": "Zhang et al., 2019", "refKey": 64}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "HuBERT", "normalizedForm": "HuBERT", "offsetStart": 163, "offsetEnd": 169}, "context": "We show in Table A1 that our Hu-BERT model trained on the Fisher dataset learns better phonetic information suitable for conversations than the publicly available HuBERT model trained on audiobooks (Hsu et al., 2021a).", "mentionContextAttributes": {"used": {"value": false, "score": 0.06310725212097168}, "created": {"value": true, "score": 0.7481251955032349}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999871253967285}, "created": {"value": true, "score": 0.9655576944351196}, "shared": {"value": false, "score": 9.5367431640625e-07}}, "references": [{"label": "(Hsu et al., 2021a)", "normalizedForm": "Hsu et al., 2021a", "refKey": 0}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "HuBERT", "normalizedForm": "HuBERT", "offsetStart": 191, "offsetEnd": 197}, "context": "We used the k-means algorithm with codebook sizes of 100, 500, and 500 to quantize the MFCC features, the 6th transformer layer features, and the 9th transformer layer features for the three HuBERT training iterations. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999251365661621}, "created": {"value": false, "score": 9.679794311523438e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999871253967285}, "created": {"value": true, "score": 0.9655576944351196}, "shared": {"value": false, "score": 9.5367431640625e-07}}, "references": [{"label": "(Hsu et al., 2021a)", "normalizedForm": "Hsu et al., 2021a", "refKey": 0}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "HuBERT", "normalizedForm": "HuBERT", "offsetStart": 213, "offsetEnd": 219}, "context": "Models trained with either autoencoder objectives (Ondel et al., 2016;van den Oord et al., 2017) or masked objectives (CPC: van den Oord et al., 2018; APC: Chung and Glass, 2020; wav2vec 2.0: Baevski et al., 2020;HuBERT: Hsu et al., 2021a;MockingJay: Liu et al., 2020) from raw speech can learn audio representation that can be used for a variety of downstream tasks (Yang et al., 2021), see Borgholt et al. (2022) for a review.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999243021011353}, "created": {"value": false, "score": 2.5033950805664062e-06}, "shared": {"value": false, "score": 9.5367431640625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999871253967285}, "created": {"value": true, "score": 0.9655576944351196}, "shared": {"value": false, "score": 9.5367431640625e-07}}, "references": [{"label": "(Hsu et al., 2021a)", "normalizedForm": "Hsu et al., 2021a", "refKey": 0}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "HuBERT", "normalizedForm": "HuBERT", "offsetStart": 244, "offsetEnd": 250}, "context": "For the waveform generation, we used the discrete unit-based HiFi-GAN vocoder from Polyak et al. (2021) trained on a small subset of high-quality single-channel voice segments of our conversation dataset, using discrete units obtained from the HuBERT model and 1-hot speaker information from the dataset.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999334812164307}, "created": {"value": false, "score": 1.9311904907226562e-05}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999871253967285}, "created": {"value": true, "score": 0.9655576944351196}, "shared": {"value": false, "score": 9.5367431640625e-07}}, "references": [{"label": "(Hsu et al., 2021a)", "normalizedForm": "Hsu et al., 2021a", "refKey": 0}]}], "references": [{"refKey": 41, "tei": "<biblStruct xml:id=\"b41\">\n\t<analytic>\n\t\t<title level=\"a\" type=\"main\">CROWDMOS: An approach for crowdsourcing mean opinion score studies</title>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Flavio</forename><surname>Ribeiro</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Dinei</forename><surname>Florencio</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Cha</forename><surname>Zhang</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Michael</forename><surname>Seltzer</surname></persName>\n\t\t</author>\n\t\t<idno type=\"DOI\">10.1109/icassp.2011.5946971</idno>\n\t</analytic>\n\t<monogr>\n\t\t<title level=\"m\">2011 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</title>\n\t\t<imprint>\n\t\t\t<publisher>IEEE</publisher>\n\t\t\t<date type=\"published\" when=\"2011-05\">2011. 2011</date>\n\t\t\t<biblScope unit=\"page\" from=\"2416\" to=\"2419\" />\n\t\t</imprint>\n\t</monogr>\n</biblStruct>\n"}, {"refKey": 0, "tei": "<biblStruct xml:id=\"b0\">\n\t<analytic>\n\t\t<title level=\"a\" type=\"main\">Generative Spoken Dialogue Language Modeling</title>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Tu</forename><forename type=\"middle\">Anh</forename><surname>Nguyen</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Eugene</forename><surname>Kharitonov</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Jade</forename><surname>Copet</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Yossi</forename><surname>Adi</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Wei-Ning</forename><surname>Hsu</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Ali</forename><surname>Elkahky</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Paden</forename><surname>Tomasello</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Robin</forename><surname>Algayres</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Beno\u00eet</forename><surname>Sagot</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Abdelrahman</forename><surname>Mohamed</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Emmanuel</forename><surname>Dupoux</surname></persName>\n\t\t</author>\n\t\t<idno type=\"DOI\">10.1162/tacl_a_00545</idno>\n\t\t<idno>E71237BDB5924F585976C40956DA1358</idno>\n\t</analytic>\n\t<monogr>\n\t\t<title level=\"j\">Transactions of the Association for Computational Linguistics</title>\n\t\t<idno type=\"ISSNe\">2307-387X</idno>\n\t\t<imprint>\n\t\t\t<biblScope unit=\"volume\">11</biblScope>\n\t\t\t<biblScope unit=\"page\" from=\"250\" to=\"266\" />\n\t\t\t<date type=\"published\" when=\"2023\" />\n\t\t\t<publisher>MIT Press</publisher>\n\t\t</imprint>\n\t</monogr>\n</biblStruct>\n"}, {"refKey": 64, "tei": "<biblStruct xml:id=\"b64\">\n\t<monogr>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Yizhe</forename><surname>Zhang</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Siqi</forename><surname>Sun</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Michel</forename><surname>Galley</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Yen-Chun</forename><surname>Chen</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Chris</forename><surname>Brockett</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Xiang</forename><surname>Gao</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Jianfeng</forename><surname>Gao</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Jingjing</forename><surname>Liu</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Bill</forename><surname>Dolan</surname></persName>\n\t\t</author>\n\t\t<idno>CoRR, abs/1911.00536</idno>\n\t\t<title level=\"m\">Dialogpt: Large-scale generative pre-training for conversational response generation</title>\n\t\t<imprint>\n\t\t\t<date>2019</date>\n\t\t</imprint>\n\t</monogr>\n</biblStruct>\n"}], "runtime": 10349, "id": "447d2c276bd78502f0ded7917ed6138daf5d816f", "metadata": {"id": "447d2c276bd78502f0ded7917ed6138daf5d816f"}, "original_file_path": "../../datalake/Samuel/SOFTware-Sync/downloads/xml/hal-03985368.grobid.tei.xml", "file_name": "hal-03985368.grobid.tei.xml"}