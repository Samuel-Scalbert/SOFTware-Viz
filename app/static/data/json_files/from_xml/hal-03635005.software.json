{"application": "software-mentions", "version": "0.8.0", "date": "2024-10-07T11:42+0000", "md5": "E990B8CDE98F9034F6737130D10B051E", "mentions": [{"type": "software", "software-type": "software", "software-name": {"rawForm": "FastText", "normalizedForm": "FastText", "offsetStart": 4, "offsetEnd": 12}, "context": "For FastText , the average similarity between item and meaning (l. 4 and 5) varies considerably from one language pair to another, which indicates variation in embedding alignment quality between English and other languages. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.002548515796661377}, "created": {"value": false, "score": 3.4689903259277344e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9992344379425049}, "created": {"value": false, "score": 0.0015559792518615723}, "shared": {"value": false, "score": 9.5367431640625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "FastText", "normalizedForm": "FastText", "offsetStart": 9, "offsetEnd": 17}, "context": "Training FastText embeddings.", "mentionContextAttributes": {"used": {"value": false, "score": 2.849102020263672e-05}, "created": {"value": false, "score": 1.1444091796875e-05}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9992344379425049}, "created": {"value": false, "score": 0.0015559792518615723}, "shared": {"value": false, "score": 9.5367431640625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "mBERT", "normalizedForm": "mBERT", "offsetStart": 10, "offsetEnd": 17}, "context": "We use an mBERT10 model trained on 104 languages, including Latin and all our contemporary languages, from the transformers library (Wolf et al., 2020). ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9716037511825562}, "created": {"value": false, "score": 0.000533759593963623}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999731779098511}, "created": {"value": false, "score": 0.007880926132202148}, "shared": {"value": false, "score": 4.76837158203125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "FastText", "normalizedForm": "FastText", "offsetStart": 10, "offsetEnd": 18}, "context": "Available FastText embeddings.", "mentionContextAttributes": {"used": {"value": false, "score": 5.412101745605469e-05}, "created": {"value": false, "score": 6.4373016357421875e-06}, "shared": {"value": false, "score": 7.152557373046875e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9992344379425049}, "created": {"value": false, "score": 0.0015559792518615723}, "shared": {"value": false, "score": 9.5367431640625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "OpenMedFr", "normalizedForm": "OpenMedFr", "offsetStart": 12, "offsetEnd": 21}, "context": "Lastly, the OpenMedFr were already in raw text format, and we only had to remove the comment lines and page indications. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9990205764770508}, "created": {"value": false, "score": 7.832050323486328e-05}, "shared": {"value": false, "score": 2.5033950805664062e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9990205764770508}, "created": {"value": false, "score": 7.832050323486328e-05}, "shared": {"value": false, "score": 2.5033950805664062e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "mBERT", "normalizedForm": "mBERT", "offsetStart": 16, "offsetEnd": 21}, "context": "Thus, we expect mBERT to perform well on OSP and FRM, but we also compare fine-tuning it on our FRM and OSP corpora using the masked language modelling task. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9992849230766296}, "created": {"value": false, "score": 0.000966191291809082}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999731779098511}, "created": {"value": false, "score": 0.007880926132202148}, "shared": {"value": false, "score": 4.76837158203125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "FastText", "normalizedForm": "FastText", "offsetStart": 16, "offsetEnd": 24}, "context": "As a side note, FastText embeddings would have shown that cognates are more similar than borrowings, and a word is more similar to its parent than to its siblings: a hasty analysis using bad quality embeddings could have lead us to draw seductive but erroneous conclusions from the FastText embeddings.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9176746606826782}, "created": {"value": false, "score": 8.225440979003906e-06}, "shared": {"value": false, "score": 9.5367431640625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9992344379425049}, "created": {"value": false, "score": 0.0015559792518615723}, "shared": {"value": false, "score": 9.5367431640625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "mBERT", "normalizedForm": "mBERT", "offsetStart": 18, "offsetEnd": 23}, "context": "item(a) \u2194 item(b) mBERT similarity (%).", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999731779098511}, "created": {"value": false, "score": 2.7418136596679688e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999731779098511}, "created": {"value": false, "score": 0.007880926132202148}, "shared": {"value": false, "score": 4.76837158203125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "mBERT", "normalizedForm": "mBERT", "offsetStart": 23, "offsetEnd": 28}, "context": "On the other hand, for mBERT embeddings, this similarity score is constant (with a slight variation between cognates and borrowings, likely explained by the fact that language pairs distribution between cognates and borrowings is different), which reflects a high embedding alignment quality. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.02064824104309082}, "created": {"value": false, "score": 1.4781951904296875e-05}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999731779098511}, "created": {"value": false, "score": 0.007880926132202148}, "shared": {"value": false, "score": 4.76837158203125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "mBERT", "normalizedForm": "mBERT", "offsetStart": 24, "offsetEnd": 29}, "context": "Global comparison Using mBERT embeddings, the only difference in similarity scores for items occurs between un-shifted and shifted word embeddings, with un-shifted pairs similarity being on average 4 points higher than shifted pairs (not necessarily statistically significant). ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9482412934303284}, "created": {"value": false, "score": 6.079673767089844e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999731779098511}, "created": {"value": false, "score": 0.007880926132202148}, "shared": {"value": false, "score": 4.76837158203125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "FastText", "normalizedForm": "FastText", "offsetStart": 29, "offsetEnd": 63}, "context": "The former are trained using FastText (Bojanowski et al., 2016) and aligned a posteriori, while the latter are extracted using the multilingual language model mBERT (Devlin et al., 2019) from corpora in the all languages under study. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9992344379425049}, "created": {"value": false, "score": 2.9087066650390625e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9992344379425049}, "created": {"value": false, "score": 0.0015559792518615723}, "shared": {"value": false, "score": 9.5367431640625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "mBERT", "normalizedForm": "mBERT", "offsetStart": 31, "offsetEnd": 36}, "context": "Table 8: Statistics when using mBERT embeddings, with OSP/FRM finetuning ( f t -) or without, for Old Spanish and Medieval French cognates.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9983856678009033}, "created": {"value": false, "score": 1.049041748046875e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999731779098511}, "created": {"value": false, "score": 0.007880926132202148}, "shared": {"value": false, "score": 4.76837158203125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "mBERT", "normalizedForm": "mBERT", "offsetStart": 31, "offsetEnd": 36}, "context": "Table 9: Statistics when using mBERT embeddings, with OSP/FRM finetuning ( f t ) or without, for Old Spanish and Medieval French borrowings with shifted and unshifted pairs.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9946451187133789}, "created": {"value": false, "score": 1.3113021850585938e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999731779098511}, "created": {"value": false, "score": 0.007880926132202148}, "shared": {"value": false, "score": 4.76837158203125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "mBERT", "normalizedForm": "mBERT", "offsetStart": 48, "offsetEnd": 53}, "context": "We will therefore draw conclusions only us- ing mBERT.", "mentionContextAttributes": {"used": {"value": true, "score": 0.8688682913780212}, "created": {"value": false, "score": 0.007880926132202148}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999731779098511}, "created": {"value": false, "score": 0.007880926132202148}, "shared": {"value": false, "score": 4.76837158203125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "mBERT", "normalizedForm": "mBERT", "offsetStart": 52, "offsetEnd": 57}, "context": "We also compared vanilla and fine-tuned OSP and FRM mBERT embeddings (Tables 8 and9 in App.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9998687505722046}, "created": {"value": false, "score": 4.0531158447265625e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999731779098511}, "created": {"value": false, "score": 0.007880926132202148}, "shared": {"value": false, "score": 4.76837158203125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "FastText", "normalizedForm": "FastText", "offsetStart": 66, "offsetEnd": 74}, "context": "Its training on Wikipedia data, allows for fairer comparison with FastText embeddings.", "mentionContextAttributes": {"used": {"value": false, "score": 7.939338684082031e-05}, "created": {"value": false, "score": 0.0015559792518615723}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9992344379425049}, "created": {"value": false, "score": 0.0015559792518615723}, "shared": {"value": false, "score": 9.5367431640625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "FastText", "normalizedForm": "FastText", "offsetStart": 67, "offsetEnd": 75}, "context": "One should therefore be wary of conclusions drawn from the aligned FastText embeddings, even publicly available pre-aligned ones, which might lead to incorrect assumptions by introducing hidden factors into play. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0005136728286743164}, "created": {"value": false, "score": 0.00018924474716186523}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9992344379425049}, "created": {"value": false, "score": 0.0015559792518615723}, "shared": {"value": false, "score": 9.5367431640625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "mBERT", "normalizedForm": "mBERT", "offsetStart": 77, "offsetEnd": 82}, "context": "Focus In order to investigate differences at the language pair level for the mBERT embeddings, we focus on two language pairs which have at least 20 samples for both shifted and un-shifted pairs of cognates and of borrowings: FR-ES and FR-IT (Table 2).", "mentionContextAttributes": {"used": {"value": true, "score": 0.6268662810325623}, "created": {"value": false, "score": 0.00017058849334716797}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999731779098511}, "created": {"value": false, "score": 0.007880926132202148}, "shared": {"value": false, "score": 4.76837158203125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "mBERT", "normalizedForm": "mBERT", "offsetStart": 146, "offsetEnd": 151}, "context": "When assessing embedding quality and alignment, we show that Fast-Text embeddings, even when already pre-trained and aligned, are poorer than the mBERT ones on all respects.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0506134033203125}, "created": {"value": false, "score": 0.0003478527069091797}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999731779098511}, "created": {"value": false, "score": 0.007880926132202148}, "shared": {"value": false, "score": 4.76837158203125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "mBERT", "normalizedForm": "mBERT", "offsetStart": 159, "offsetEnd": 186}, "context": "The former are trained using FastText (Bojanowski et al., 2016) and aligned a posteriori, while the latter are extracted using the multilingual language model mBERT (Devlin et al., 2019) from corpora in the all languages under study. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9992344379425049}, "created": {"value": false, "score": 2.9087066650390625e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999731779098511}, "created": {"value": false, "score": 0.007880926132202148}, "shared": {"value": false, "score": 4.76837158203125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "mBERT", "normalizedForm": "mBERT", "offsetStart": 249, "offsetEnd": 254}, "context": "B); fine-tuning shows no significant improvement, though for some edge cases, it seems to increase semantic shift sensitivity slightly while decreasing similarity with other embedding spaces; consequently, we keep the simplest approach, the vanilla mBERT model.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0003813505172729492}, "created": {"value": false, "score": 6.890296936035156e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999731779098511}, "created": {"value": false, "score": 0.007880926132202148}, "shared": {"value": false, "score": 4.76837158203125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "FastText", "normalizedForm": "FastText", "offsetStart": 282, "offsetEnd": 290}, "context": "As a side note, FastText embeddings would have shown that cognates are more similar than borrowings, and a word is more similar to its parent than to its siblings: a hasty analysis using bad quality embeddings could have lead us to draw seductive but erroneous conclusions from the FastText embeddings.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9176746606826782}, "created": {"value": false, "score": 8.225440979003906e-06}, "shared": {"value": false, "score": 9.5367431640625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9992344379425049}, "created": {"value": false, "score": 0.0015559792518615723}, "shared": {"value": false, "score": 9.5367431640625e-07}}}], "references": [], "runtime": 6183, "id": "e22266dc6c713e488649ba0e0009ae63c0abd580", "metadata": {"id": "e22266dc6c713e488649ba0e0009ae63c0abd580"}, "original_file_path": "../../datalake/Samuel/SOFTware-Sync/downloads/xml/hal-03635005.grobid.tei.xml", "file_name": "hal-03635005.grobid.tei.xml"}