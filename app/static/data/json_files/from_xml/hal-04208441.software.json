{"application": "software-mentions", "version": "0.8.0", "date": "2024-10-07T12:04+0000", "md5": "1BCD2A5B10F906581C9A1AD9337EB611", "mentions": [{"type": "software", "software-type": "software", "software-name": {"rawForm": "HuBERT", "normalizedForm": "HuBERT", "offsetStart": 0, "offsetEnd": 6}, "context": "HuBERT-LS960 was trained on LibriSpeech 960 as in [3].", "mentionContextAttributes": {"used": {"value": true, "score": 0.9643470644950867}, "created": {"value": false, "score": 2.5033950805664062e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999762773513794}, "created": {"value": true, "score": 0.9959405660629272}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "references": [{"label": "[1]", "normalizedForm": "[1]", "refKey": 1}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "HuBERT", "normalizedForm": "HuBERT", "offsetStart": 4, "offsetEnd": 10}, "context": "The HuBERT models use the same architecture (HuBERT base with 12 Tranformer layers), but are trained on different corpora.", "mentionContextAttributes": {"used": {"value": false, "score": 0.03623718023300171}, "created": {"value": false, "score": 8.344650268554688e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999762773513794}, "created": {"value": true, "score": 0.9959405660629272}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "references": [{"label": "[1]", "normalizedForm": "[1]", "refKey": 1}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "HuBERT", "normalizedForm": "HuBERT", "offsetStart": 4, "offsetEnd": 10}, "context": "For HuBERT units, we produce the waveform using HiFiGAN, which we train on the units presented above.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9922602772712708}, "created": {"value": false, "score": 0.0008047223091125488}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999762773513794}, "created": {"value": true, "score": 0.9959405660629272}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "references": [{"label": "[1]", "normalizedForm": "[1]", "refKey": 1}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "HuBERT", "normalizedForm": "HuBERT", "offsetStart": 4, "offsetEnd": 10}, "context": "The HuBERT encoders trained on the larger and noisier corpus (Mix1) tend to have overall better results than when trained on LS960 only, especially when tested on Fisher.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9823377132415771}, "created": {"value": false, "score": 2.6226043701171875e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999762773513794}, "created": {"value": true, "score": 0.9959405660629272}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "references": [{"label": "[1]", "normalizedForm": "[1]", "refKey": 1}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "HuBERT", "normalizedForm": "HuBERT", "offsetStart": 7, "offsetEnd": 13}, "context": "We use HuBERT-Mix1 from [24], which was trained with a more varied mixture of datasets: an 8 language subset of VoxPopuli [25] (167K h), Common Voice [26] (4K h) and Multilingual LibriSpeech (MLS) [27] (50K h), totalling 221K hours. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.999508261680603}, "created": {"value": false, "score": 2.9802322387695312e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999762773513794}, "created": {"value": true, "score": 0.9959405660629272}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "references": [{"label": "[1]", "normalizedForm": "[1]", "refKey": 1}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Mix", "normalizedForm": "Mix", "offsetStart": 14, "offsetEnd": 17}, "context": "We use HuBERT-Mix1 from [24], which was trained with a more varied mixture of datasets: an 8 language subset of VoxPopuli [25] (167K h), Common Voice [26] (4K h) and Multilingual LibriSpeech (MLS) [27] (50K h), totalling 221K hours. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.999508261680603}, "created": {"value": false, "score": 2.9802322387695312e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999508261680603}, "created": {"value": false, "score": 7.987022399902344e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "references": [{"label": "[24]", "normalizedForm": "[24]", "refKey": 24, "offsetStart": 10313, "offsetEnd": 10317}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "HuBERT", "normalizedForm": "HuBERT", "offsetStart": 16, "offsetEnd": 22}, "context": "On average, the HuBERT units trained on Mix1 give better performances (about 10% relative) than units trained on LS960, a result consistent with the phonetic quality metrics.", "mentionContextAttributes": {"used": {"value": true, "score": 0.7910751104354858}, "created": {"value": false, "score": 7.987022399902344e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999762773513794}, "created": {"value": true, "score": 0.9959405660629272}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "references": [{"label": "[1]", "normalizedForm": "[1]", "refKey": 1}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "HuBERT", "normalizedForm": "HuBERT", "offsetStart": 18, "offsetEnd": 24}, "context": "Overall, the best HuBERT results on the same speaker showed a drop in performance compared to the original audio files (between 30% relative to more than double the error), and compared to the Encodec-8 units.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9998987913131714}, "created": {"value": false, "score": 1.9788742065429688e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999762773513794}, "created": {"value": true, "score": 0.9959405660629272}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "references": [{"label": "[1]", "normalizedForm": "[1]", "refKey": 1}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "HuBERT", "normalizedForm": "HuBERT", "offsetStart": 34, "offsetEnd": 40}, "context": "Further work is needed to improve HuBERT-based expressive resynthesis, and reach the quality of Encodec units, while retaining controllability.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00015044212341308594}, "created": {"value": true, "score": 0.5600588321685791}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999762773513794}, "created": {"value": true, "score": 0.9959405660629272}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "references": [{"label": "[1]", "normalizedForm": "[1]", "refKey": 1}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Mix", "normalizedForm": "Mix", "offsetStart": 40, "offsetEnd": 43}, "context": "On average, the HuBERT units trained on Mix1 give better performances (about 10% relative) than units trained on LS960, a result consistent with the phonetic quality metrics.", "mentionContextAttributes": {"used": {"value": true, "score": 0.7910751104354858}, "created": {"value": false, "score": 7.987022399902344e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999508261680603}, "created": {"value": false, "score": 7.987022399902344e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "references": [{"label": "[24]", "normalizedForm": "[24]", "refKey": 24}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "HuBERT", "normalizedForm": "HuBERT", "offsetStart": 40, "offsetEnd": 46}, "context": "Regarding outof-domain resynthesis, the HuBERT-Mix1 units again generally outperform the HuBERT-LS960 units (19% relative).", "mentionContextAttributes": {"used": {"value": true, "score": 0.9979661703109741}, "created": {"value": false, "score": 3.6954879760742188e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999762773513794}, "created": {"value": true, "score": 0.9959405660629272}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "references": [{"label": "[1]", "normalizedForm": "[1]", "refKey": 1}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "HuBERT", "normalizedForm": "HuBERT", "offsetStart": 45, "offsetEnd": 51}, "context": "The HuBERT models use the same architecture (HuBERT base with 12 Tranformer layers), but are trained on different corpora. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.03623718023300171}, "created": {"value": false, "score": 8.344650268554688e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999762773513794}, "created": {"value": true, "score": 0.9959405660629272}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "references": [{"label": "[1]", "normalizedForm": "[1]", "refKey": 1}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Mix", "normalizedForm": "Mix", "offsetStart": 47, "offsetEnd": 50}, "context": "Regarding outof-domain resynthesis, the HuBERT-Mix1 units again generally outperform the HuBERT-LS960 units (19% relative).", "mentionContextAttributes": {"used": {"value": true, "score": 0.9979661703109741}, "created": {"value": false, "score": 3.6954879760742188e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999508261680603}, "created": {"value": false, "score": 7.987022399902344e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "references": [{"label": "[24]", "normalizedForm": "[24]", "refKey": 24}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "HuBERT", "normalizedForm": "HuBERT", "offsetStart": 47, "offsetEnd": 53}, "context": "For quantization, we trained k-means models on HuBERT features either on a subset of HuBERT pre-training dataset or on EXPRESSO, with k=500 on LS960 or k=2000 on other datasets.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999762773513794}, "created": {"value": false, "score": 3.4928321838378906e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999762773513794}, "created": {"value": true, "score": 0.9959405660629272}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "references": [{"label": "[1]", "normalizedForm": "[1]", "refKey": 1}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "HiFiGAN", "normalizedForm": "HiFiGAN", "offsetStart": 48, "offsetEnd": 55}, "context": "For HuBERT units, we produce the waveform using HiFiGAN, which we train on the units presented above. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9922602772712708}, "created": {"value": false, "score": 0.0008047223091125488}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9922602772712708}, "created": {"value": false, "score": 0.0008047223091125488}, "shared": {"value": false, "score": 1.1920928955078125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "HuBERT", "normalizedForm": "HuBERT", "offsetStart": 49, "offsetEnd": 55}, "context": "We compare different pretraining sources for the HuBERT units based on public datasets of read speech and/or spontaneous speech.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9995676875114441}, "created": {"value": false, "score": 3.4570693969726562e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999762773513794}, "created": {"value": true, "score": 0.9959405660629272}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "references": [{"label": "[1]", "normalizedForm": "[1]", "refKey": 1}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Mix", "normalizedForm": "Mix", "offsetStart": 62, "offsetEnd": 65}, "context": "The HuBERT encoders trained on the larger and noisier corpus (Mix1) tend to have overall better results than when trained on LS960 only, especially when tested on Fisher.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9823377132415771}, "created": {"value": false, "score": 2.6226043701171875e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999508261680603}, "created": {"value": false, "score": 7.987022399902344e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "references": [{"label": "[24]", "normalizedForm": "[24]", "refKey": 24}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "HuBERT", "normalizedForm": "HuBERT", "offsetStart": 75, "offsetEnd": 81}, "context": "Globally, the style scores of Encodec-8 are on par or better than the best HuBERT resynthesis models, but much better for pitch preservation (6-fold).", "mentionContextAttributes": {"used": {"value": false, "score": 0.2685977816581726}, "created": {"value": false, "score": 1.8715858459472656e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999762773513794}, "created": {"value": true, "score": 0.9959405660629272}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "references": [{"label": "[1]", "normalizedForm": "[1]", "refKey": 1}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "HuBERT", "normalizedForm": "HuBERT", "offsetStart": 81, "offsetEnd": 87}, "context": "We introduce automatic metrics for content and style preservation and evaluate a HuBERT [1] encoder trained on a masked prediction objective followed by k-means clustering, which we compare to Encodec [8], a compression model which acts as a high bitrate baseline.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00010311603546142578}, "created": {"value": true, "score": 0.9959405660629272}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999762773513794}, "created": {"value": true, "score": 0.9959405660629272}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "references": [{"label": "[1]", "normalizedForm": "[1]", "refKey": 1, "offsetStart": 3771, "offsetEnd": 3774}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "HuBERT", "normalizedForm": "HuBERT", "offsetStart": 85, "offsetEnd": 91}, "context": "For quantization, we trained k-means models on HuBERT features either on a subset of HuBERT pre-training dataset or on EXPRESSO, with k=500 on LS960 or k=2000 on other datasets. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999762773513794}, "created": {"value": false, "score": 3.4928321838378906e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999762773513794}, "created": {"value": true, "score": 0.9959405660629272}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "references": [{"label": "[1]", "normalizedForm": "[1]", "refKey": 1}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "HuBERT", "normalizedForm": "HuBERT", "offsetStart": 89, "offsetEnd": 95}, "context": "Regarding outof-domain resynthesis, the HuBERT-Mix1 units again generally outperform the HuBERT-LS960 units (19% relative).", "mentionContextAttributes": {"used": {"value": true, "score": 0.9979661703109741}, "created": {"value": false, "score": 3.6954879760742188e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999762773513794}, "created": {"value": true, "score": 0.9959405660629272}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "references": [{"label": "[1]", "normalizedForm": "[1]", "refKey": 1}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Huggingface", "normalizedForm": "Huggingface", "offsetStart": 163, "offsetEnd": 174}, "context": "wav2vec/wav2vec_vox_960h_pl.pt 3 We fine-tune the wav2vec2 base model [20] on a 26 style classes audio classification task (as in the SUPERB benchmark [21]) using Huggingface transformers library [22]).", "mentionContextAttributes": {"used": {"value": true, "score": 0.8915594816207886}, "created": {"value": false, "score": 1.3113021850585938e-06}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.8915594816207886}, "created": {"value": false, "score": 1.3113021850585938e-06}, "shared": {"value": false, "score": 4.76837158203125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "HuBERT", "normalizedForm": "HuBERT", "offsetStart": 184, "offsetEnd": 190}, "context": "The ABX-centroid and PNMI metrics gave better results when kmeans clustering was run on EXPRESSO (a small high quality, high diversity dataset) than on the large dataset used to train HuBERT itself. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999291896820068}, "created": {"value": false, "score": 1.1086463928222656e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999762773513794}, "created": {"value": true, "score": 0.9959405660629272}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "references": [{"label": "[1]", "normalizedForm": "[1]", "refKey": 1}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "HuBERT", "normalizedForm": "HuBERT", "offsetStart": 194, "offsetEnd": 200}, "context": "The Encodec units gave poor results, which is not surprising given that Encodec units are generic representations trained for audio compression that also encodes non-phonetic variations whereas HuBERT units are trained with a masked language modeling objective.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9996175765991211}, "created": {"value": false, "score": 5.9604644775390625e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999762773513794}, "created": {"value": true, "score": 0.9959405660629272}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "references": [{"label": "[1]", "normalizedForm": "[1]", "refKey": 1}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "HuBERT", "normalizedForm": "HuBERT", "offsetStart": 215, "offsetEnd": 221}, "context": "We showed that Encodec systems which are designed for general audio compression are generally better for resynthesis, although they lack the controllability in output voices and style made possible by the fact that HuBERT units are disentangled from speaker identity and (partially) from expressivity.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0015982985496520996}, "created": {"value": false, "score": 0.0014601945877075195}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999762773513794}, "created": {"value": true, "score": 0.9959405660629272}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "references": [{"label": "[1]", "normalizedForm": "[1]", "refKey": 1}]}], "references": [{"refKey": 1, "tei": "<biblStruct xml:id=\"b1\">\n\t<analytic>\n\t\t<title level=\"a\" type=\"main\">HuBERT: Self-supervised speech representation learning by masked prediction of hidden units</title>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">W.-N</forename><surname>Hsu</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">B</forename><surname>Bolte</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Y.-H</forename><forename type=\"middle\">H</forename><surname>Tsai</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">K</forename><surname>Lakhotia</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">R</forename><surname>Salakhutdinov</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">A</forename><surname>Mohamed</surname></persName>\n\t\t</author>\n\t</analytic>\n\t<monogr>\n\t\t<title level=\"j\">IEEE/ACM Trans. Audio, Speech, Language Process. (TASLP)</title>\n\t\t<imprint>\n\t\t\t<biblScope unit=\"volume\">29</biblScope>\n\t\t\t<biblScope unit=\"page\">3460</biblScope>\n\t\t\t<date>2021</date>\n\t\t</imprint>\n\t</monogr>\n</biblStruct>\n"}, {"refKey": 24, "tei": "<biblStruct xml:id=\"b24\">\n\t<monogr>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">W.-N</forename><surname>Hsu</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">T</forename><surname>Remez</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">B</forename><surname>Shi</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">J</forename><surname>Donley</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Y</forename><surname>Adi</surname></persName>\n\t\t</author>\n\t\t<idno>arXiv:2212.11377</idno>\n\t\t<title level=\"m\">Revise: Self-supervised speech resynthesis with visual input for universal and generalized speech enhancement</title>\n\t\t<imprint>\n\t\t\t<date>2022</date>\n\t\t</imprint>\n\t</monogr>\n</biblStruct>\n"}], "runtime": 16965, "id": "43a0e51005011f0ef67875f90e65d69a63ae6b65", "metadata": {"id": "43a0e51005011f0ef67875f90e65d69a63ae6b65"}, "original_file_path": "../../datalake/Samuel/SOFTware-Sync/downloads/xml/hal-04208441.grobid.tei.xml", "file_name": "hal-04208441.grobid.tei.xml"}