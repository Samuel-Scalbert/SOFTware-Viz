{"application": "software-mentions", "version": "0.8.0", "date": "2024-10-07T12:49+0000", "md5": "3016DF83AB70271CFB9AED0F028BCA15", "mentions": [{"type": "software", "software-type": "software", "software-name": {"rawForm": "LifeCLEF", "normalizedForm": "LifeCLEF", "offsetStart": 4, "offsetEnd": 12}, "context": "The LifeCLEF 2019 Plant Identification challenge (or \"PlantCLEF 2019\") was designed to evaluate automated identification on the flora of data deficient regions.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0005444884300231934}, "created": {"value": false, "score": 0.332378625869751}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999098777770996}, "created": {"value": true, "score": 0.9764200448989868}, "shared": {"value": false, "score": 7.05718994140625e-05}}, "references": [{"label": "[8]", "normalizedForm": "[8]", "refKey": 8}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LifeCLEF", "normalizedForm": "LifeCLEF", "offsetStart": 4, "offsetEnd": 12}, "context": "The LifeCLEF 2019 Plant Identification challenge (or \"PlantCLEF 2019\") presented in this paper was designed to evaluate automated identification on the flora of such data deficient regions.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00041872262954711914}, "created": {"value": true, "score": 0.9764200448989868}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999098777770996}, "created": {"value": true, "score": 0.9764200448989868}, "shared": {"value": false, "score": 7.05718994140625e-05}}, "references": [{"label": "[8]", "normalizedForm": "[8]", "refKey": 8}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LifeCLEF", "normalizedForm": "LifeCLEF", "offsetStart": 16, "offsetEnd": 24}, "context": "In the scope of LifeCLEF 2017 [8] in particular, we measured impressive identification performance achieved thanks to recent deep learning models (e.g. up to 90 % classification accuracy over 10K species). ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999098777770996}, "created": {"value": false, "score": 0.0001035928726196289}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999098777770996}, "created": {"value": true, "score": 0.9764200448989868}, "shared": {"value": false, "score": 7.05718994140625e-05}}, "references": [{"label": "[8]", "normalizedForm": "[8]", "refKey": 8, "offsetStart": 1088, "offsetEnd": 1091}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "PlantCLEF", "normalizedForm": "PlantCLEF", "offsetStart": 29, "offsetEnd": 38}, "version": {"rawForm": "2019", "normalizedForm": "2019"}, "context": "As in the 2018-th edition of PlantCLEF, a comparison of the performance of the systems evaluated with the best tropical flora experts was carried out for PlantCLEF 2019. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999291896820068}, "created": {"value": false, "score": 7.510185241699219e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999798536300659}, "created": {"value": true, "score": 0.9764200448989868}, "shared": {"value": false, "score": 4.76837158203125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LifeCLEF", "normalizedForm": "LifeCLEF", "offsetStart": 42, "offsetEnd": 50}, "context": "It has been shown in previous editions of LifeCLEF, however, that training deep learning models on such raw big data can be as effective as training models on cleaner but smaller expert data [4], [5]. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.00016200542449951172}, "created": {"value": false, "score": 0.0003044605255126953}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999098777770996}, "created": {"value": true, "score": 0.9764200448989868}, "shared": {"value": false, "score": 7.05718994140625e-05}}, "references": [{"label": "[8]", "normalizedForm": "[8]", "refKey": 8}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "PlantCLEF", "normalizedForm": "PlantCLEF", "offsetStart": 54, "offsetEnd": 63}, "version": {"rawForm": "2019", "normalizedForm": "2019"}, "context": "The LifeCLEF 2019 Plant Identification challenge (or \"PlantCLEF 2019\") presented in this paper was designed to evaluate automated identification on the flora of such data deficient regions. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.00041872262954711914}, "created": {"value": true, "score": 0.9764200448989868}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999798536300659}, "created": {"value": true, "score": 0.9764200448989868}, "shared": {"value": false, "score": 4.76837158203125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "PlantCLEF", "normalizedForm": "PlantCLEF", "offsetStart": 54, "offsetEnd": 63}, "version": {"rawForm": "2019", "normalizedForm": "2019"}, "context": "The LifeCLEF 2019 Plant Identification challenge (or \"PlantCLEF 2019\") was designed to evaluate automated identification on the flora of data deficient regions.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0005444884300231934}, "created": {"value": false, "score": 0.332378625869751}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999798536300659}, "created": {"value": true, "score": 0.9764200448989868}, "shared": {"value": false, "score": 4.76837158203125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LifeCLEF", "normalizedForm": "LifeCLEF", "offsetStart": 57, "offsetEnd": 65}, "context": "This paper presented the overview and the results of the LifeCLEF 2019 plant identification challenge following the eight previous editions conducted within CLEF evaluation forum.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9976515173912048}, "created": {"value": false, "score": 0.04253125190734863}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999098777770996}, "created": {"value": true, "score": 0.9764200448989868}, "shared": {"value": false, "score": 7.05718994140625e-05}}, "references": [{"label": "[8]", "normalizedForm": "[8]", "refKey": 8}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LifeCLEF", "normalizedForm": "LifeCLEF", "offsetStart": 61, "offsetEnd": 69}, "context": "Results are significantly lower than the previous edition of LifeCLEF confirming the assumption that the tropical flora is inherently more difficult to identify than the more generalist flora.", "mentionContextAttributes": {"used": {"value": false, "score": 0.35442841053009033}, "created": {"value": false, "score": 6.210803985595703e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999098777770996}, "created": {"value": true, "score": 0.9764200448989868}, "shared": {"value": false, "score": 7.05718994140625e-05}}, "references": [{"label": "[8]", "normalizedForm": "[8]", "refKey": 8}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "PlantCLEF", "normalizedForm": "PlantCLEF", "offsetStart": 63, "offsetEnd": 72}, "version": {"rawForm": "2019", "normalizedForm": "2019"}, "context": "4 Participants and methods 167 participants registered for the PlantCLEF challenge 2019 and downloaded the data set, but only 6 research groups succeeded in submitting run files. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.999065101146698}, "created": {"value": false, "score": 2.1696090698242188e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999798536300659}, "created": {"value": true, "score": 0.9764200448989868}, "shared": {"value": false, "score": 4.76837158203125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ExpertCLEF", "normalizedForm": "ExpertCLEF", "offsetStart": 78, "offsetEnd": 88}, "version": {"rawForm": "2018", "normalizedForm": "2018", "offsetStart": 88, "offsetEnd": 97}, "context": "The CNNs were initialized with weights pre-trained on the dataset used during ExpertCLEF2018 [11] and then fine-tuned with different hyper-parameters and with the use of data augmentation (random horizontal flip, color distortions and random crops). ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999881982803345}, "created": {"value": false, "score": 4.5299530029296875e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999881982803345}, "created": {"value": false, "score": 4.5299530029296875e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "references": [{"label": "[11]", "normalizedForm": "[11]", "refKey": 11, "offsetStart": 10245, "offsetEnd": 10249}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ExpertCLEF", "normalizedForm": "ExpertCLEF", "offsetStart": 100, "offsetEnd": 110}, "version": {"rawForm": "2018", "normalizedForm": "2018", "offsetStart": 110, "offsetEnd": 119}, "context": "In their case, however, the CNNs were initialized with weights pre-trained on Im-ageNet rather than ExpertCLEF2018 [11] and they did not use any additional training data. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999576807022095}, "created": {"value": false, "score": 2.384185791015625e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999881982803345}, "created": {"value": false, "score": 4.5299530029296875e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "references": [{"label": "[11]", "normalizedForm": "[11]", "refKey": 11, "offsetStart": 11988, "offsetEnd": 11992}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "PlantCLEF", "normalizedForm": "PlantCLEF", "offsetStart": 138, "offsetEnd": 151}, "version": {"rawForm": "2019", "normalizedForm": "2019"}, "context": "The average number of images per species in that new dataset is significantly lower than the last dataset used in the previous edition of PlantCLEF [6] (about 1 vs. 3), and many species contain very few images or may even contain only one image. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.005305230617523193}, "created": {"value": false, "score": 1.6808509826660156e-05}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999798536300659}, "created": {"value": true, "score": 0.9764200448989868}, "shared": {"value": false, "score": 4.76837158203125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "PlantCLEF", "normalizedForm": "PlantCLEF", "offsetStart": 145, "offsetEnd": 154}, "version": {"rawForm": "2019", "normalizedForm": "2019"}, "context": "Scores achieved by all systems evaluated on the two test sets (DensetNet, ResNet, Inception-ResNet-V2, Inception-V4), while during the last four PlantCLEF editions the homogenization of high results forming a \"skyline\" had often been observed. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999798536300659}, "created": {"value": false, "score": 1.5616416931152344e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999798536300659}, "created": {"value": true, "score": 0.9764200448989868}, "shared": {"value": false, "score": 4.76837158203125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LifeCLEF", "normalizedForm": "LifeCLEF", "offsetStart": 152, "offsetEnd": 160}, "context": "We also we would like to thank the University of Montpellier and the Floris'Tic project (ANRU) who contributed to the funding of the 2019-th edition of LifeCLEF.", "mentionContextAttributes": {"used": {"value": false, "score": 0.09992635250091553}, "created": {"value": false, "score": 0.02283543348312378}, "shared": {"value": false, "score": 7.05718994140625e-05}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999098777770996}, "created": {"value": true, "score": 0.9764200448989868}, "shared": {"value": false, "score": 7.05718994140625e-05}}, "references": [{"label": "[8]", "normalizedForm": "[8]", "refKey": 8}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "PlantCLEF", "normalizedForm": "PlantCLEF", "offsetStart": 154, "offsetEnd": 163}, "version": {"rawForm": "2019", "normalizedForm": "2019", "offsetStart": 164, "offsetEnd": 168}, "context": "As in the 2018-th edition of PlantCLEF, a comparison of the performance of the systems evaluated with the best tropical flora experts was carried out for PlantCLEF 2019. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999291896820068}, "created": {"value": false, "score": 7.510185241699219e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999798536300659}, "created": {"value": true, "score": 0.9764200448989868}, "shared": {"value": false, "score": 4.76837158203125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Bing", "normalizedForm": "Bing", "offsetStart": 311, "offsetEnd": 315}, "context": "As for the two previous years, this training data was mainly aggregated by bringing together images from complementary types of available sources, including expert data from the international platform Encyclopedia of Life (EoL5 ) and images automatically retrieved from the web using industrial search engines (Bing and Google) that were queried with the binomial Latin name of the targeted species. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9994495511054993}, "created": {"value": false, "score": 0.00026363134384155273}, "shared": {"value": false, "score": 7.152557373046875e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9994495511054993}, "created": {"value": false, "score": 0.00026363134384155273}, "shared": {"value": false, "score": 7.152557373046875e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Google", "normalizedForm": "Google", "offsetStart": 320, "offsetEnd": 326}, "context": "As for the two previous years, this training data was mainly aggregated by bringing together images from complementary types of available sources, including expert data from the international platform Encyclopedia of Life (EoL5 ) and images automatically retrieved from the web using industrial search engines (Bing and Google) that were queried with the binomial Latin name of the targeted species. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9994495511054993}, "created": {"value": false, "score": 0.00026363134384155273}, "shared": {"value": false, "score": 7.152557373046875e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9994495511054993}, "created": {"value": false, "score": 0.00026363134384155273}, "shared": {"value": false, "score": 7.152557373046875e-07}}}], "references": [{"refKey": 8, "tei": "<biblStruct xml:id=\"b8\">\n\t<analytic>\n\t\t<title level=\"a\" type=\"main\">LifeCLEF 2017 Lab Overview: Multimedia Species Identification Challenges</title>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Alexis</forename><surname>Joly</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Herv\u00e9</forename><surname>Go\u00ebau</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Herv\u00e9</forename><surname>Glotin</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Concetto</forename><surname>Spampinato</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Pierre</forename><surname>Bonnet</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Willem-Pier</forename><surname>Vellinga</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Jean-Christophe</forename><surname>Lombardo</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Robert</forename><surname>Planqu\u00e9</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Simone</forename><surname>Palazzo</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Henning</forename><surname>M\u00fcller</surname></persName>\n\t\t</author>\n\t\t<idno type=\"DOI\">10.1007/978-3-319-65813-1_24</idno>\n\t</analytic>\n\t<monogr>\n\t\t<title level=\"m\">Lecture Notes in Computer Science</title>\n\t\t<imprint>\n\t\t\t<publisher>Springer International Publishing</publisher>\n\t\t\t<date type=\"published\" when=\"2017\">2017</date>\n\t\t\t<biblScope unit=\"page\" from=\"255\" to=\"274\" />\n\t\t</imprint>\n\t</monogr>\n</biblStruct>\n"}, {"refKey": 11, "tei": "<biblStruct xml:id=\"b11\">\n\t<analytic>\n\t\t<title level=\"a\" type=\"main\">Plant recognition by inception networks with testtime class prior estimation</title>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">M</forename><surname>Sulc</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">L</forename><surname>Picek</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">J</forename><surname>Matas</surname></persName>\n\t\t</author>\n\t</analytic>\n\t<monogr>\n\t\t<title level=\"m\">Working Notes of CLEF 2018 (Cross Language Evaluation Forum</title>\n\t\t<imprint>\n\t\t\t<date>2018</date>\n\t\t</imprint>\n\t</monogr>\n</biblStruct>\n"}], "runtime": 4265, "id": "8b094a6a3e1e769adea6a4b09c6bcdf421243907", "metadata": {"id": "8b094a6a3e1e769adea6a4b09c6bcdf421243907"}, "original_file_path": "../../datalake/Samuel/SOFTware-Sync/downloads/xml/hal-02283184.grobid.tei.xml", "file_name": "hal-02283184.grobid.tei.xml"}