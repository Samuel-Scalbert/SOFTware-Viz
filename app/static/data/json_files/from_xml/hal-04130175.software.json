{"application": "software-mentions", "version": "0.8.0", "date": "2024-10-07T12:01+0000", "md5": "ED477B7FF3BCA60E0C3CCE6431A013BD", "mentions": [{"type": "software", "software-type": "software", "software-name": {"rawForm": "MuRIL", "normalizedForm": "MuRIL", "offsetStart": 2, "offsetEnd": 7}, "context": "\u2022 MuRIL with EP on all dialects (MuRIL+EP ABBM M +ft): Finally, we choose the best performing large pretrained model from the previous set of experiments (namely, MuRIL), and extended-pretrain it with all low-resource dialects, followed by separate finetuning and evaluation in each dialect. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9869772791862488}, "created": {"value": false, "score": 6.318092346191406e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9979165196418762}, "created": {"value": false, "score": 0.4246795177459717}, "shared": {"value": false, "score": 3.0994415283203125e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "mBERT", "normalizedForm": "mBERT", "offsetStart": 2, "offsetEnd": 7}, "context": "\u2022 mBERT (Devlin et al., 2019): 14 Finally, we also finetune mBERT for each dialect; mBERT is trained on the MLM and Next Sentence Prediction (NSP) objectives, on 104 languages, including Indic languages, but also several other languages and language families.", "mentionContextAttributes": {"used": {"value": false, "score": 0.05774945020675659}, "created": {"value": false, "score": 1.6450881958007812e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9863835573196411}, "created": {"value": false, "score": 0.00033032894134521484}, "shared": {"value": false, "score": 3.0994415283203125e-06}}, "references": [{"label": "(Devlin et al., 2019)", "normalizedForm": "Devlin et al., 2019", "refKey": 9, "offsetStart": 15291, "offsetEnd": 15312}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MuRIL", "normalizedForm": "MuRIL", "offsetStart": 4, "offsetEnd": 9}, "context": "The MuRIL model was chosen over mBERT due to its better initial performance.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9696885347366333}, "created": {"value": false, "score": 0.00033032894134521484}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9979165196418762}, "created": {"value": false, "score": 0.4246795177459717}, "shared": {"value": false, "score": 3.0994415283203125e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "HuggingFace", "normalizedForm": "HuggingFace", "offsetStart": 11, "offsetEnd": 22}, "context": "We use the HuggingFace transformers library (Wolf et al., 2020) for training and accessing publicly available pretrained models. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.09744685888290405}, "created": {"value": false, "score": 0.00021439790725708008}, "shared": {"value": false, "score": 0.0002509951591491699}}, "documentContextAttributes": {"used": {"value": false, "score": 0.09744685888290405}, "created": {"value": false, "score": 0.00021439790725708008}, "shared": {"value": false, "score": 0.0002509951591491699}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "mBERT", "normalizedForm": "mBERT", "offsetStart": 24, "offsetEnd": 29}, "context": "Early papers found that mBERT performed remarkably well in the zero-shot setting (Pires et al., 2019;Wu & Dredze, 2019) under certain conditions, such as similar typologies of source and target languages, but regardless of others, such as script and common vocabulary.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9863835573196411}, "created": {"value": false, "score": 1.4543533325195312e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9863835573196411}, "created": {"value": false, "score": 0.00033032894134521484}, "shared": {"value": false, "score": 3.0994415283203125e-06}}, "references": [{"label": "(Devlin et al., 2019;", "normalizedForm": "(Devlin et al., 2019", "refKey": 9}, {"label": "Conneau et al., 2020)", "normalizedForm": "Conneau et al., 2020)", "refKey": 6}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "mBERT", "normalizedForm": "mBERT", "offsetStart": 30, "offsetEnd": 35}, "context": "We also see that Hin-BERT and mBERT seem to perform on par, with perhaps a slight edge to Hin-BERT, although mBERT is pretrained on much more data.", "mentionContextAttributes": {"used": {"value": false, "score": 0.08916372060775757}, "created": {"value": false, "score": 3.3855438232421875e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9863835573196411}, "created": {"value": false, "score": 0.00033032894134521484}, "shared": {"value": false, "score": 3.0994415283203125e-06}}, "references": [{"label": "(Devlin et al., 2019;", "normalizedForm": "(Devlin et al., 2019", "refKey": 9}, {"label": "Conneau et al., 2020)", "normalizedForm": "Conneau et al., 2020)", "refKey": 6}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "mBERT", "normalizedForm": "mBERT", "offsetStart": 31, "offsetEnd": 36}, "context": "Note that the training data of mBERT does include Hindi and other Indic languages; however, these are naturally accorded less \"space\" or percentage of training data as compared to with MuRIL or simply a Hindi pretrained model.", "mentionContextAttributes": {"used": {"value": false, "score": 0.062377333641052246}, "created": {"value": false, "score": 3.4689903259277344e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9863835573196411}, "created": {"value": false, "score": 0.00033032894134521484}, "shared": {"value": false, "score": 3.0994415283203125e-06}}, "references": [{"label": "(Devlin et al., 2019;", "normalizedForm": "(Devlin et al., 2019", "refKey": 9}, {"label": "Conneau et al., 2020)", "normalizedForm": "Conneau et al., 2020)", "refKey": 6}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "mBERT", "normalizedForm": "mBERT", "offsetStart": 32, "offsetEnd": 37}, "context": "The MuRIL model was chosen over mBERT due to its better initial performance.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9696885347366333}, "created": {"value": false, "score": 0.00033032894134521484}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9863835573196411}, "created": {"value": false, "score": 0.00033032894134521484}, "shared": {"value": false, "score": 3.0994415283203125e-06}}, "references": [{"label": "(Devlin et al., 2019;", "normalizedForm": "(Devlin et al., 2019", "refKey": 9}, {"label": "Conneau et al., 2020)", "normalizedForm": "Conneau et al., 2020)", "refKey": 6}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MuRIL", "normalizedForm": "MuRIL", "offsetStart": 33, "offsetEnd": 38}, "context": "\u2022 MuRIL with EP on all dialects (MuRIL+EP ABBM M +ft): Finally, we choose the best performing large pretrained model from the previous set of experiments (namely, MuRIL), and extended-pretrain it with all low-resource dialects, followed by separate finetuning and evaluation in each dialect. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9869772791862488}, "created": {"value": false, "score": 6.318092346191406e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9979165196418762}, "created": {"value": false, "score": 0.4246795177459717}, "shared": {"value": false, "score": 3.0994415283203125e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MuRIL", "normalizedForm": "MuRIL", "offsetStart": 40, "offsetEnd": 45}, "context": "Pretrained models Comparing {Hin-BERT | MuRIL | mBERT}+ft, we observe that MuRIL-based models do better than mBERT-based models on four out of six dialects.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9705139398574829}, "created": {"value": false, "score": 2.9802322387695312e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9979165196418762}, "created": {"value": false, "score": 0.4246795177459717}, "shared": {"value": false, "score": 3.0994415283203125e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MuRIL", "normalizedForm": "MuRIL", "offsetStart": 45, "offsetEnd": 50}, "context": "We also perform extended pretraining for the MuRIL and Hin-BERT models to observe potential benefits.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9979165196418762}, "created": {"value": false, "score": 0.4246795177459717}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9979165196418762}, "created": {"value": false, "score": 0.4246795177459717}, "shared": {"value": false, "score": 3.0994415283203125e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MuRIL}", "normalizedForm": "MuRIL}", "offsetStart": 54, "offsetEnd": 60}, "context": "We also observe that ABBMM+ft is on par with {mBERT | MuRIL}+ft even for dialects without much monolingual data; again, this indicates that models pretrained on roughly of a few million tokens, even from closely related dialects, perform comparably with much larger (language family or other) multilingual models (pretrained on three orders of magnitude more data) for a downstream POS-tagging task. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.6447257995605469}, "created": {"value": false, "score": 3.6954879760742188e-06}, "shared": {"value": false, "score": 1.0728836059570312e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.6447257995605469}, "created": {"value": false, "score": 3.6954879760742188e-06}, "shared": {"value": false, "score": 1.0728836059570312e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "mBERT", "normalizedForm": "mBERT", "offsetStart": 58, "offsetEnd": 63}, "context": "Transformer-based pre-trained multilingual models such as mBERT (Devlin et al., 2019;Conneau et al., 2020) are often claimed to show multilingual generalization (Pires et al., 2019).", "mentionContextAttributes": {"used": {"value": false, "score": 8.559226989746094e-05}, "created": {"value": false, "score": 6.961822509765625e-05}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9863835573196411}, "created": {"value": false, "score": 0.00033032894134521484}, "shared": {"value": false, "score": 3.0994415283203125e-06}}, "references": [{"label": "(Devlin et al., 2019;", "normalizedForm": "(Devlin et al., 2019", "refKey": 9, "offsetStart": 6425, "offsetEnd": 6446}, {"label": "Conneau et al., 2020)", "normalizedForm": "Conneau et al., 2020)", "refKey": 6, "offsetStart": 6446, "offsetEnd": 6467}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "mBERT", "normalizedForm": "mBERT", "offsetStart": 60, "offsetEnd": 65}, "context": "\u2022 mBERT (Devlin et al., 2019): 14 Finally, we also finetune mBERT for each dialect; mBERT is trained on the MLM and Next Sentence Prediction (NSP) objectives, on 104 languages, including Indic languages, but also several other languages and language families.", "mentionContextAttributes": {"used": {"value": false, "score": 0.05774945020675659}, "created": {"value": false, "score": 1.6450881958007812e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9863835573196411}, "created": {"value": false, "score": 0.00033032894134521484}, "shared": {"value": false, "score": 3.0994415283203125e-06}}, "references": [{"label": "(Devlin et al., 2019;", "normalizedForm": "(Devlin et al., 2019", "refKey": 9}, {"label": "Conneau et al., 2020)", "normalizedForm": "Conneau et al., 2020)", "refKey": 6}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MuRIL", "normalizedForm": "MuRIL", "offsetStart": 64, "offsetEnd": 69}, "context": "The best performing models are obtained by extended pretraining MuRIL with either monolingual data (for Bhojpuri and Braj) or all dialect data together (for Awadhi, Maithili, and Magahi).", "mentionContextAttributes": {"used": {"value": true, "score": 0.9530753493309021}, "created": {"value": false, "score": 2.181529998779297e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9979165196418762}, "created": {"value": false, "score": 0.4246795177459717}, "shared": {"value": false, "score": 3.0994415283203125e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MuRIL", "normalizedForm": "MuRIL", "offsetStart": 75, "offsetEnd": 80}, "context": "Pretrained models Comparing {Hin-BERT | MuRIL | mBERT}+ft, we observe that MuRIL-based models do better than mBERT-based models on four out of six dialects.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9705139398574829}, "created": {"value": false, "score": 2.9802322387695312e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9979165196418762}, "created": {"value": false, "score": 0.4246795177459717}, "shared": {"value": false, "score": 3.0994415283203125e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MuRIL", "normalizedForm": "MuRIL", "offsetStart": 78, "offsetEnd": 83}, "context": "This extends the results shown by Khanuja et al. (2021) that demonstrate that MuRIL outperforms mBERT consistently on its 17 pretraining languages.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9596191644668579}, "created": {"value": false, "score": 1.4066696166992188e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9979165196418762}, "created": {"value": false, "score": 0.4246795177459717}, "shared": {"value": false, "score": 3.0994415283203125e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "mBERT", "normalizedForm": "mBERT", "offsetStart": 84, "offsetEnd": 89}, "context": "\u2022 mBERT (Devlin et al., 2019): 14 Finally, we also finetune mBERT for each dialect; mBERT is trained on the MLM and Next Sentence Prediction (NSP) objectives, on 104 languages, including Indic languages, but also several other languages and language families.", "mentionContextAttributes": {"used": {"value": false, "score": 0.05774945020675659}, "created": {"value": false, "score": 1.6450881958007812e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9863835573196411}, "created": {"value": false, "score": 0.00033032894134521484}, "shared": {"value": false, "score": 3.0994415283203125e-06}}, "references": [{"label": "(Devlin et al., 2019;", "normalizedForm": "(Devlin et al., 2019", "refKey": 9}, {"label": "Conneau et al., 2020)", "normalizedForm": "Conneau et al., 2020)", "refKey": 6}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "script", "normalizedForm": "script", "offsetStart": 86, "offsetEnd": 92}, "context": "We are working with six of these dialects, all of which are written in the Devanagari script, namely Awadhi, Bhojpuri, Braj, Magahi, Maithili, and the high-resource standardized dialect, i.e. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0010395050048828125}, "created": {"value": false, "score": 0.22241854667663574}, "shared": {"value": false, "score": 1.7881393432617188e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9863835573196411}, "created": {"value": false, "score": 0.22241854667663574}, "shared": {"value": false, "score": 4.0531158447265625e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "mBERT", "normalizedForm": "mBERT", "offsetStart": 96, "offsetEnd": 101}, "context": "This extends the results shown by Khanuja et al. (2021) that demonstrate that MuRIL outperforms mBERT consistently on its 17 pretraining languages.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9596191644668579}, "created": {"value": false, "score": 1.4066696166992188e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9863835573196411}, "created": {"value": false, "score": 0.00033032894134521484}, "shared": {"value": false, "score": 3.0994415283203125e-06}}, "references": [{"label": "(Devlin et al., 2019;", "normalizedForm": "(Devlin et al., 2019", "refKey": 9}, {"label": "Conneau et al., 2020)", "normalizedForm": "Conneau et al., 2020)", "refKey": 6}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "mBERT", "normalizedForm": "mBERT", "offsetStart": 109, "offsetEnd": 114}, "context": "Pretrained models Comparing {Hin-BERT | MuRIL | mBERT}+ft, we observe that MuRIL-based models do better than mBERT-based models on four out of six dialects.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9705139398574829}, "created": {"value": false, "score": 2.9802322387695312e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9863835573196411}, "created": {"value": false, "score": 0.00033032894134521484}, "shared": {"value": false, "score": 3.0994415283203125e-06}}, "references": [{"label": "(Devlin et al., 2019;", "normalizedForm": "(Devlin et al., 2019", "refKey": 9}, {"label": "Conneau et al., 2020)", "normalizedForm": "Conneau et al., 2020)", "refKey": 6}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "mBERT", "normalizedForm": "mBERT", "offsetStart": 109, "offsetEnd": 114}, "context": "We also see that Hin-BERT and mBERT seem to perform on par, with perhaps a slight edge to Hin-BERT, although mBERT is pretrained on much more data.", "mentionContextAttributes": {"used": {"value": false, "score": 0.08916372060775757}, "created": {"value": false, "score": 3.3855438232421875e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9863835573196411}, "created": {"value": false, "score": 0.00033032894134521484}, "shared": {"value": false, "score": 3.0994415283203125e-06}}, "references": [{"label": "(Devlin et al., 2019;", "normalizedForm": "(Devlin et al., 2019", "refKey": 9}, {"label": "Conneau et al., 2020)", "normalizedForm": "Conneau et al., 2020)", "refKey": 6}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MuRIL}", "normalizedForm": "MuRIL}", "offsetStart": 109, "offsetEnd": 115}, "context": "Bhojpuri and Magahi, the highest resourced dialects, have baseline performances roughly on par with {mBERT | MuRIL}+ft. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.06644934415817261}, "created": {"value": false, "score": 3.337860107421875e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.6447257995605469}, "created": {"value": false, "score": 3.6954879760742188e-06}, "shared": {"value": false, "score": 1.0728836059570312e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MuRIL", "normalizedForm": "MuRIL", "offsetStart": 120, "offsetEnd": 125}, "context": "The only performance drop is observed for Maithili; monolingual EP slightly worsens performance in both Hin-BERT+ft and MuRIL+ft.", "mentionContextAttributes": {"used": {"value": false, "score": 0.09224045276641846}, "created": {"value": false, "score": 8.106231689453125e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9979165196418762}, "created": {"value": false, "score": 0.4246795177459717}, "shared": {"value": false, "score": 3.0994415283203125e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MuRIL", "normalizedForm": "MuRIL", "offsetStart": 163, "offsetEnd": 168}, "context": "\u2022 MuRIL with EP on all dialects (MuRIL+EP ABBM M +ft): Finally, we choose the best performing large pretrained model from the previous set of experiments (namely, MuRIL), and extended-pretrain it with all low-resource dialects, followed by separate finetuning and evaluation in each dialect. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9869772791862488}, "created": {"value": false, "score": 6.318092346191406e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9979165196418762}, "created": {"value": false, "score": 0.4246795177459717}, "shared": {"value": false, "score": 3.0994415283203125e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MuRIL", "normalizedForm": "MuRIL", "offsetStart": 165, "offsetEnd": 170}, "context": "We compared conventional pretraining and cross-lingual transfer methods, and concluded that large pretrained models trained on the same language family (in our case MuRIL, for the Indic language family) are particularly successful as base models, especially if followed by extended pretraining, either monolingually or on closely related dialect data.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9922583699226379}, "created": {"value": false, "score": 3.266334533691406e-05}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9979165196418762}, "created": {"value": false, "score": 0.4246795177459717}, "shared": {"value": false, "score": 3.0994415283203125e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "script", "normalizedForm": "script", "offsetStart": 168, "offsetEnd": 174}, "context": "Since then, many studies, such as (Chai et al., 2022;Ri & Tsuruoka, 2022), have attempted to explore these conditions; notably, Muller et al. (2021) show that a common script indeed facilitates transfer, along with shared typological features, and Khemchandani et al. (2021) show the same for Indic languages.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0025371313095092773}, "created": {"value": false, "score": 0.012703657150268555}, "shared": {"value": false, "score": 4.0531158447265625e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9863835573196411}, "created": {"value": false, "score": 0.22241854667663574}, "shared": {"value": false, "score": 4.0531158447265625e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MuRIL", "normalizedForm": "MuRIL", "offsetStart": 185, "offsetEnd": 190}, "context": "Note that the training data of mBERT does include Hindi and other Indic languages; however, these are naturally accorded less \"space\" or percentage of training data as compared to with MuRIL or simply a Hindi pretrained model.", "mentionContextAttributes": {"used": {"value": false, "score": 0.062377333641052246}, "created": {"value": false, "score": 3.4689903259277344e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9979165196418762}, "created": {"value": false, "score": 0.4246795177459717}, "shared": {"value": false, "score": 3.0994415283203125e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MuRIL", "normalizedForm": "MuRIL", "offsetStart": 198, "offsetEnd": 203}, "context": "14 https://huggingface.co/bert-base-multilingual-cased/tree/main 15 We do not perform this experiment for Hindi, i.e. we do not do extended pretraining on Hindi data, for two reasons: firstly, both MuRIL and mBERT have already seen Hindi data, therefore rendering this a different experiment to that with the dialects, and secondly, in our work, our focus is on the low-resource dialects. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.14763832092285156}, "created": {"value": false, "score": 4.410743713378906e-06}, "shared": {"value": false, "score": 3.0994415283203125e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9979165196418762}, "created": {"value": false, "score": 0.4246795177459717}, "shared": {"value": false, "score": 3.0994415283203125e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "mBERT", "normalizedForm": "mBERT", "offsetStart": 208, "offsetEnd": 213}, "context": "14 https://huggingface.co/bert-base-multilingual-cased/tree/main 15 We do not perform this experiment for Hindi, i.e. we do not do extended pretraining on Hindi data, for two reasons: firstly, both MuRIL and mBERT have already seen Hindi data, therefore rendering this a different experiment to that with the dialects, and secondly, in our work, our focus is on the low-resource dialects. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.14763832092285156}, "created": {"value": false, "score": 4.410743713378906e-06}, "shared": {"value": false, "score": 3.0994415283203125e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9863835573196411}, "created": {"value": false, "score": 0.00033032894134521484}, "shared": {"value": false, "score": 3.0994415283203125e-06}}, "references": [{"label": "(Devlin et al., 2019;", "normalizedForm": "(Devlin et al., 2019", "refKey": 9}, {"label": "Conneau et al., 2020)", "normalizedForm": "Conneau et al., 2020)", "refKey": 6}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "script", "normalizedForm": "script", "offsetStart": 239, "offsetEnd": 245}, "context": "Early papers found that mBERT performed remarkably well in the zero-shot setting (Pires et al., 2019;Wu & Dredze, 2019) under certain conditions, such as similar typologies of source and target languages, but regardless of others, such as script and common vocabulary.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9863835573196411}, "created": {"value": false, "score": 1.4543533325195312e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9863835573196411}, "created": {"value": false, "score": 0.22241854667663574}, "shared": {"value": false, "score": 4.0531158447265625e-06}}}], "references": [{"refKey": 9, "tei": "<biblStruct xml:id=\"b9\">\n\t<analytic>\n\t\t<title level=\"a\" type=\"main\">BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</title>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">J</forename><surname>Devlin</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Chang M.-W</forename><surname>Lee</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">K</forename><surname>Toutanova</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">K</forename></persName>\n\t\t</author>\n\t\t<idno type=\"DOI\">{10.18653/v1/N19-1423}</idno>\n\t</analytic>\n\t<monogr>\n\t\t<title level=\"m\">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>\n\t\t<title level=\"s\">Association for Computational Linguistics</title>\n\t\t<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>\n\t\t<imprint>\n\t\t\t<date>2019</date>\n\t\t\t<biblScope unit=\"volume\">1</biblScope>\n\t\t\t<biblScope unit=\"page\">4186</biblScope>\n\t\t</imprint>\n\t</monogr>\n</biblStruct>\n"}, {"refKey": 6, "tei": "<biblStruct xml:id=\"b6\">\n\t<analytic>\n\t\t<title level=\"a\" type=\"main\">Unsupervised Cross-lingual Representation Learning at Scale</title>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">A</forename><surname>Conneau</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">K</forename><surname>Khandelwal</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">N</forename><surname>Goyal</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">V</forename><surname>Chaudhary</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">G</forename><surname>Wenzek</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">F</forename><surname>Guzm\u00e1n</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">E</forename><surname>Grave</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">M</forename><surname>Ott</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">L</forename><surname>Zettlemoyer</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">V</forename><surname>Stoyanov</surname></persName>\n\t\t</author>\n\t\t<idno type=\"DOI\">{10.18653/v1/2020.acl-main.747}</idno>\n\t</analytic>\n\t<monogr>\n\t\t<title level=\"m\">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>\n\t\t<title level=\"s\">Association for Computational Linguistics</title>\n\t\t<meeting>the 58th Annual Meeting of the Association for Computational Linguistics</meeting>\n\t\t<imprint>\n\t\t\t<date>2020</date>\n\t\t\t<biblScope unit=\"page\">8451</biblScope>\n\t\t</imprint>\n\t</monogr>\n</biblStruct>\n"}], "runtime": 3639, "id": "9a65c142562de6eed468df87740f203976c3c9b6", "metadata": {"id": "9a65c142562de6eed468df87740f203976c3c9b6"}, "original_file_path": "../../datalake/Samuel/SOFTware-Sync/downloads/xml/hal-04130175.grobid.tei.xml", "file_name": "hal-04130175.grobid.tei.xml"}