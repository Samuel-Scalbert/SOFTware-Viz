{"application": "software-mentions", "version": "0.8.0", "date": "2024-10-07T11:57+0000", "md5": "E76EBBE9A09A23C3BE5986C405788677", "mentions": [{"type": "software", "software-type": "software", "software-name": {"rawForm": "Lighter", "normalizedForm": "Lighter", "offsetStart": 0, "offsetEnd": 7}, "context": "Lighter [15] also uses Bloom filters but bypasses the k-mer counting phase by only looking at a subset of the k-mers in a given data set, therefore achieving greater speed.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0018050074577331543}, "created": {"value": false, "score": 4.315376281738281e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999948740005493}, "created": {"value": false, "score": 0.002133190631866455}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "references": [{"label": "[15]", "normalizedForm": "[15]", "refKey": 15, "offsetStart": 5266, "offsetEnd": 5270}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LoRMA", "normalizedForm": "LoRMA", "offsetStart": 3, "offsetEnd": 8}, "context": "In LoRMA, the de Bruijn graph is built from the very same long reads that the program is attempting to correct. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.09056347608566284}, "created": {"value": false, "score": 0.003140091896057129}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.09056347608566284}, "created": {"value": false, "score": 0.003140091896057129}, "shared": {"value": false, "score": 1.1920928955078125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Btrim", "normalizedForm": "Btrim", "offsetStart": 4, "offsetEnd": 14}, "context": "The Btrim [25] module cleans the graph, and the reads are finally mapped back on the de Bruijn graph using Bgreat2 [26].", "mentionContextAttributes": {"used": {"value": true, "score": 0.9975958466529846}, "created": {"value": false, "score": 5.602836608886719e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9975958466529846}, "created": {"value": false, "score": 5.602836608886719e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LoRDEC", "normalizedForm": "LoRDEC", "offsetStart": 7, "offsetEnd": 13}, "context": "In the LoRDEC approach, this de Bruijn graph is built from highly accurate short reads and used to correct long reads.", "mentionContextAttributes": {"used": {"value": false, "score": 0.029959142208099365}, "created": {"value": false, "score": 6.0558319091796875e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999927282333374}, "created": {"value": false, "score": 0.00022464990615844727}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "references": [{"label": "[20]", "normalizedForm": "[20]", "refKey": 20}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LoRDEC", "normalizedForm": "LoRDEC", "offsetStart": 9, "offsetEnd": 15}, "context": "Applying LoRDEC using non-corrected short reads lead to a 3.04% error rate on corrected long reads.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9114876985549927}, "created": {"value": false, "score": 9.5367431640625e-07}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999927282333374}, "created": {"value": false, "score": 0.00022464990615844727}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "references": [{"label": "[20]", "normalizedForm": "[20]", "refKey": 20}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LoRDEC", "normalizedForm": "LoRDEC", "offsetStart": 18, "offsetEnd": 24}, "context": "The efficiency of LoRDEC [20] and Bcool, respectively on long and short reads, suggests that such DBG-based correction is a general approach that can be applied to various kind of data sets.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0019277334213256836}, "created": {"value": false, "score": 4.649162292480469e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999927282333374}, "created": {"value": false, "score": 0.00022464990615844727}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "references": [{"label": "[20]", "normalizedForm": "[20]", "refKey": 20, "offsetStart": 28119, "offsetEnd": 28123}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LoRDEC", "normalizedForm": "LoRDEC", "offsetStart": 20, "offsetEnd": 26}, "context": "We tried to include LoRDEC in our benchmark (since this long-read corrector rests on a principle similar to Bcool) but we finally let it out as we did not manage to obtain results on par with programs designed for correcting short reads.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9295011758804321}, "created": {"value": false, "score": 0.00022464990615844727}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999927282333374}, "created": {"value": false, "score": 0.00022464990615844727}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "references": [{"label": "[20]", "normalizedForm": "[20]", "refKey": 20}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Bgreat2", "normalizedForm": "Bgreat2", "offsetStart": 31, "offsetEnd": 38}, "context": "The main improvements are that Bgreat2 has no third-party dependencies (in contrary to the published version) and that it outputs optimal alignments among the candidates. ", "mentionContextAttributes": {"used": {"value": false, "score": 6.99758529663086e-05}, "created": {"value": false, "score": 0.00014030933380126953}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999840259552002}, "created": {"value": false, "score": 0.0015968680381774902}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Bgreat2", "normalizedForm": "Bgreat2", "offsetStart": 35, "offsetEnd": 42}, "context": "In order to keep memory usage low, Bgreat2 uses a minimal perfect hash function [28] for indexing seeds. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0008767247200012207}, "created": {"value": false, "score": 2.5033950805664062e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999840259552002}, "created": {"value": false, "score": 0.0015968680381774902}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Bcalm2", "normalizedForm": "Bcalm2", "offsetStart": 39, "offsetEnd": 45}, "context": "In Bcool, the DBG is constructed using Bcalm2 [24], a resource-efficient method to build a compacted DBG.", "mentionContextAttributes": {"used": {"value": false, "score": 0.07096582651138306}, "created": {"value": false, "score": 0.009360790252685547}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9880297780036926}, "created": {"value": false, "score": 0.009360790252685547}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "references": [{"label": "[24]", "normalizedForm": "[24]", "refKey": 24, "offsetStart": 13010, "offsetEnd": 13014}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LoRDEC", "normalizedForm": "LoRDEC", "offsetStart": 56, "offsetEnd": 67}, "context": "Yet another approach for correcting reads, pioneered by LoRDEC [20] then by LoRMA [21], is to use de Bruijn graphs instead of strings as a basis for correction. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.00020891427993774414}, "created": {"value": false, "score": 3.170967102050781e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999927282333374}, "created": {"value": false, "score": 0.00022464990615844727}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "references": [{"label": "[20]", "normalizedForm": "[20]", "refKey": 20}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "k-merGenie", "normalizedForm": "k-merGenie", "offsetStart": 65, "offsetEnd": 79}, "context": "Therefore, we implemented an automated tool, somewhat similar to k-merGenie [29], that uses ntCard to estimate the k-mer spectrum of the data set for several values of k. ", "mentionContextAttributes": {"used": {"value": false, "score": 4.291534423828125e-05}, "created": {"value": true, "score": 0.9995424747467041}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 4.291534423828125e-05}, "created": {"value": true, "score": 0.9995424747467041}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Minia", "normalizedForm": "Minia", "offsetStart": 69, "offsetEnd": 74}, "context": "For each assembly, we tested several k-values (the main parameter of Minia), from k = 21 to k = 141 with a step of 10. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999964237213135}, "created": {"value": false, "score": 6.079673767089844e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999964237213135}, "created": {"value": false, "score": 6.079673767089844e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Bgreat2", "normalizedForm": "Bgreat2", "offsetStart": 73, "offsetEnd": 80}, "context": "For instance, by indexing only one out of ten seeds, we were able to run Bgreat2 on a human data set using around 30GB of RAM at the price of only a slight decrease in correction efficiency (see Table 1).", "mentionContextAttributes": {"used": {"value": true, "score": 0.999840259552002}, "created": {"value": false, "score": 2.765655517578125e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999840259552002}, "created": {"value": false, "score": 0.0015968680381774902}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Minia      assembler", "normalizedForm": "Minia assembler", "offsetStart": 74, "offsetEnd": 94}, "context": "In order to evaluate the impact of the correction on assembly, we ran the Minia [30] assembler on uncorrected reads and on read sets corrected with each of the correctors included in our benchmark. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999954700469971}, "created": {"value": false, "score": 1.704692840576172e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999954700469971}, "created": {"value": false, "score": 1.704692840576172e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "k-merGenie", "normalizedForm": "k-merGenie", "offsetStart": 75, "offsetEnd": 85}, "context": "This approach is more conservative and simpler than the one implemented in k-merGenie, which attempts to fit the k-mer spectrum on a haploid or diploid model with the aim of finding the k value most suitable for assembling the reads.", "mentionContextAttributes": {"used": {"value": false, "score": 3.4809112548828125e-05}, "created": {"value": false, "score": 0.0461878776550293}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 4.291534423828125e-05}, "created": {"value": true, "score": 0.9995424747467041}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LoRMA", "normalizedForm": "LoRMA", "offsetStart": 76, "offsetEnd": 85}, "context": "Yet another approach for correcting reads, pioneered by LoRDEC [20] then by LoRMA [21], is to use de Bruijn graphs instead of strings as a basis for correction. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.00020891427993774414}, "created": {"value": false, "score": 3.170967102050781e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.09056347608566284}, "created": {"value": false, "score": 0.003140091896057129}, "shared": {"value": false, "score": 1.1920928955078125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Bgreat", "normalizedForm": "Bgreat", "offsetStart": 78, "offsetEnd": 89}, "context": "For mapping reads on the DBG, we use an improved, yet unpublished, version of Bgreat [27] called \"Bgreat2\". ", "mentionContextAttributes": {"used": {"value": false, "score": 0.2797667384147644}, "created": {"value": false, "score": 0.0015968680381774902}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.2797667384147644}, "created": {"value": false, "score": 0.0015968680381774902}, "shared": {"value": false, "score": 1.1920928955078125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ntCard", "normalizedForm": "ntCard", "offsetStart": 92, "offsetEnd": 98}, "context": "Therefore, we implemented an automated tool, somewhat similar to k-merGenie [29], that uses ntCard to estimate the k-mer spectrum of the data set for several values of k. ", "mentionContextAttributes": {"used": {"value": false, "score": 4.291534423828125e-05}, "created": {"value": true, "score": 0.9995424747467041}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 4.291534423828125e-05}, "created": {"value": true, "score": 0.9995424747467041}, "shared": {"value": false, "score": 1.1920928955078125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Lighter", "normalizedForm": "Lighter", "offsetStart": 96, "offsetEnd": 103}, "context": "The de Bruijn graph construction could implement techniques similar to the sub-sampling used by Lighter in order to reduce its reliance on disk and therefore improve its running time. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.08601832389831543}, "created": {"value": false, "score": 0.002133190631866455}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999948740005493}, "created": {"value": false, "score": 0.002133190631866455}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "references": [{"label": "[15]", "normalizedForm": "[15]", "refKey": 15}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Bgreat2", "normalizedForm": "Bgreat2", "offsetStart": 98, "offsetEnd": 105}, "context": "For mapping reads on the DBG, we use an improved, yet unpublished, version of Bgreat [27] called \"Bgreat2\". ", "mentionContextAttributes": {"used": {"value": false, "score": 0.2797667384147644}, "created": {"value": false, "score": 0.0015968680381774902}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999840259552002}, "created": {"value": false, "score": 0.0015968680381774902}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "BWA", "normalizedForm": "BWA", "offsetStart": 107, "offsetEnd": 115}, "context": "Besides, our mapping method is still naive, and implementing efficient heuristics such as the ones used by BWA [33] and Bowtie2 [34] could greatly improve the throughput of Bcool without decreasing the quality of the alignment. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0007520318031311035}, "created": {"value": true, "score": 0.5544798374176025}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999927282333374}, "created": {"value": true, "score": 0.5544798374176025}, "shared": {"value": false, "score": 1.1920928955078125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Bgreat2", "normalizedForm": "Bgreat2", "offsetStart": 107, "offsetEnd": 118}, "context": "The Btrim [25] module cleans the graph, and the reads are finally mapped back on the de Bruijn graph using Bgreat2 [26].", "mentionContextAttributes": {"used": {"value": true, "score": 0.9975958466529846}, "created": {"value": false, "score": 5.602836608886719e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999840259552002}, "created": {"value": false, "score": 0.0015968680381774902}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Bowtie2", "normalizedForm": "Bowtie2", "offsetStart": 120, "offsetEnd": 132}, "context": "Besides, our mapping method is still naive, and implementing efficient heuristics such as the ones used by BWA [33] and Bowtie2 [34] could greatly improve the throughput of Bcool without decreasing the quality of the alignment. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0007520318031311035}, "created": {"value": true, "score": 0.5544798374176025}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.0007520318031311035}, "created": {"value": true, "score": 0.5544798374176025}, "shared": {"value": false, "score": 1.1920928955078125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Lighter", "normalizedForm": "Lighter", "offsetStart": 130, "offsetEnd": 137}, "context": "For instance, our human-genome experiment with 100x coverage of 150bp reads yielded a precision of 95.33% for Bloocoo, 96.74% for Lighter and 99.61% for Bcool.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999085664749146}, "created": {"value": false, "score": 0.0004164576530456543}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999948740005493}, "created": {"value": false, "score": 0.002133190631866455}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "references": [{"label": "[15]", "normalizedForm": "[15]", "refKey": 15}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Lighter", "normalizedForm": "Lighter", "offsetStart": 135, "offsetEnd": 142}, "context": "As an example, for the C. elegans genome with 250-bp reads the best k-mer size was 91 for the raw reads, 131 for reads corrected using Lighter or Musket, 141 for reads corrected using Bloocoo and 171 for reads corrected using Bcool.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9998579025268555}, "created": {"value": false, "score": 3.337860107421875e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999948740005493}, "created": {"value": false, "score": 0.002133190631866455}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "references": [{"label": "[15]", "normalizedForm": "[15]", "refKey": 15}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Lighter", "normalizedForm": "Lighter", "offsetStart": 140, "offsetEnd": 147}, "context": "Our results are compared with those obtained using several state-of-the-art short-read correctors: Bloocoo [14], Musket [13], BFC [16], and Lighter [15].", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999948740005493}, "created": {"value": false, "score": 7.748603820800781e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999948740005493}, "created": {"value": false, "score": 0.002133190631866455}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "references": [{"label": "[15]", "normalizedForm": "[15]", "refKey": 15, "offsetStart": 20576, "offsetEnd": 20580}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Bcalm2", "normalizedForm": "Bcalm2", "offsetStart": 142, "offsetEnd": 152}, "context": "These cleaning steps are applied several time in an iterative manner for handling complex scenarios A compacted DBG is then constructed using Bcalm2 [24]. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9880297780036926}, "created": {"value": false, "score": 1.1682510375976562e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9880297780036926}, "created": {"value": false, "score": 0.009360790252685547}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "references": [{"label": "[24]", "normalizedForm": "[24]", "refKey": 24}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LoRDEC", "normalizedForm": "LoRDEC", "offsetStart": 159, "offsetEnd": 165}, "context": "To test it, we simulated both short and long reads from the C.elegans reference genome and compared the amount of errors still present in the long reads after LoRDEC hybrid correction by mapping them on the reference with BWA.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999927282333374}, "created": {"value": false, "score": 6.556510925292969e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999927282333374}, "created": {"value": false, "score": 0.00022464990615844727}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "references": [{"label": "[20]", "normalizedForm": "[20]", "refKey": 20}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "BWA", "normalizedForm": "BWA", "offsetStart": 222, "offsetEnd": 225}, "context": "To test it, we simulated both short and long reads from the C.elegans reference genome and compared the amount of errors still present in the long reads after LoRDEC hybrid correction by mapping them on the reference with BWA.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999927282333374}, "created": {"value": false, "score": 6.556510925292969e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999927282333374}, "created": {"value": true, "score": 0.5544798374176025}, "shared": {"value": false, "score": 1.1920928955078125e-07}}}], "references": [{"refKey": 15, "tei": "<biblStruct xml:id=\"b15\">\n\t<analytic>\n\t\t<title level=\"a\" type=\"main\">Lighter: fast and memory-efficient sequencing error correction without counting</title>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Li</forename><surname>Song</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Liliana</forename><surname>Florea</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Ben</forename><surname>Langmead</surname></persName>\n\t\t</author>\n\t</analytic>\n\t<monogr>\n\t\t<title level=\"j\">Genome biology</title>\n\t\t<imprint>\n\t\t\t<biblScope unit=\"volume\">15</biblScope>\n\t\t\t<biblScope unit=\"issue\">11</biblScope>\n\t\t\t<biblScope unit=\"page\">509</biblScope>\n\t\t\t<date>2014</date>\n\t\t</imprint>\n\t</monogr>\n</biblStruct>\n"}, {"refKey": 20, "tei": "<biblStruct xml:id=\"b20\">\n\t<analytic>\n\t\t<title level=\"a\" type=\"main\">LoRDEC: accurate and efficient long read error correction</title>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Leena</forename><surname>Salmela</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Eric</forename><surname>Rivals</surname></persName>\n\t\t</author>\n\t</analytic>\n\t<monogr>\n\t\t<title level=\"j\">Bioinformatics</title>\n\t\t<imprint>\n\t\t\t<biblScope unit=\"volume\">30</biblScope>\n\t\t\t<biblScope unit=\"issue\">24</biblScope>\n\t\t\t<biblScope unit=\"page\">3514</biblScope>\n\t\t\t<date>2014</date>\n\t\t</imprint>\n\t</monogr>\n</biblStruct>\n"}, {"refKey": 24, "tei": "<biblStruct xml:id=\"b24\">\n\t<analytic>\n\t\t<title level=\"a\" type=\"main\">Compacting de Bruijn graphs from sequencing data quickly and in low memory</title>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Rayan</forename><surname>Chikhi</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Antoine</forename><surname>Limasset</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Paul</forename><surname>Medvedev</surname></persName>\n\t\t</author>\n\t</analytic>\n\t<monogr>\n\t\t<title level=\"j\">Bioinformatics</title>\n\t\t<imprint>\n\t\t\t<biblScope unit=\"volume\">32</biblScope>\n\t\t\t<biblScope unit=\"issue\">12</biblScope>\n\t\t\t<biblScope unit=\"page\">208</biblScope>\n\t\t\t<date>2016</date>\n\t\t</imprint>\n\t</monogr>\n</biblStruct>\n"}], "runtime": 20580, "id": "f0be3538faf0530567fc0ccd4b3b500a17076132", "metadata": {"id": "f0be3538faf0530567fc0ccd4b3b500a17076132"}, "original_file_path": "../../datalake/Samuel/SOFTware-Sync/downloads/xml/hal-02407243.grobid.tei.xml", "file_name": "hal-02407243.grobid.tei.xml"}