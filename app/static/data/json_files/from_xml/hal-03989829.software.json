{"application": "software-mentions", "version": "0.8.0", "date": "2024-10-07T11:38+0000", "md5": "D682FFEC6C91A600B27B170ECF17A67A", "mentions": [{"type": "software", "software-type": "software", "software-name": {"rawForm": "HuBERT", "normalizedForm": "HuBERT", "offsetStart": 4, "offsetEnd": 10}, "context": "and HuBERT have almost twice the EM accuracy for both valid and test sets.", "mentionContextAttributes": {"used": {"value": false, "score": 0.09241390228271484}, "created": {"value": false, "score": 8.821487426757812e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999968409538269}, "created": {"value": true, "score": 0.6238584518432617}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "references": [{"label": "[24]", "normalizedForm": "[24]", "refKey": 24}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "HuBERT", "normalizedForm": "HuBERT", "offsetStart": 4, "offsetEnd": 10}, "context": "and HuBERT improve upon the randomly initialized model by roughly 25% points.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0013854503631591797}, "created": {"value": false, "score": 7.82012939453125e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999968409538269}, "created": {"value": true, "score": 0.6238584518432617}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "references": [{"label": "[24]", "normalizedForm": "[24]", "refKey": 24}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "HuBERT", "normalizedForm": "HuBERT", "offsetStart": 9, "offsetEnd": 15}, "context": "[14] and HuBERT [24] pre-trained models, fine-tuned using a CTC loss [25] on Librispeech 960h and evaluated them on the STOP eval and test set in addition to the Libripeech test and dev sets.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999300241470337}, "created": {"value": false, "score": 2.1457672119140625e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999968409538269}, "created": {"value": true, "score": 0.6238584518432617}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "references": [{"label": "[24]", "normalizedForm": "[24]", "refKey": 24, "offsetStart": 11361, "offsetEnd": 11365}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "HuBERT", "normalizedForm": "HuBERT", "offsetStart": 24, "offsetEnd": 30}, "context": "To this end, we train a HuBERT encoder on the Librispeech training set, then fine-tune it on the held-in domain (either Weather or Reminder).", "mentionContextAttributes": {"used": {"value": false, "score": 0.11033272743225098}, "created": {"value": false, "score": 0.31318199634552}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999968409538269}, "created": {"value": true, "score": 0.6238584518432617}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "references": [{"label": "[24]", "normalizedForm": "[24]", "refKey": 24}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LibriSpeech", "normalizedForm": "LibriSpeech", "offsetStart": 35, "offsetEnd": 46}, "context": "As can be seen, training purely on LibriSpeech performs quite poorly on the STOP eval and test sets, with WER above 25%. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.001534104347229004}, "created": {"value": false, "score": 7.152557373046875e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.001534104347229004}, "created": {"value": false, "score": 7.152557373046875e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "HuBERT", "normalizedForm": "HuBERT", "offsetStart": 41, "offsetEnd": 47}, "context": "We study this method by first taking the HuBERT encoder trained on Librispeech then source training on all data samples from \"held-in\" TOPv2 domains -all domains aside from Weather and Reminder as described in Section 3.3.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9509033560752869}, "created": {"value": false, "score": 0.0001341104507446289}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999968409538269}, "created": {"value": true, "score": 0.6238584518432617}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "references": [{"label": "[24]", "normalizedForm": "[24]", "refKey": 24}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Reminder", "normalizedForm": "Reminder", "offsetStart": 41, "offsetEnd": 49}, "context": "EM and EM-tree trend together, though in Reminder, EM benefits more from scaling up training data than EM-tree.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00021797418594360352}, "created": {"value": false, "score": 1.8477439880371094e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9992475509643555}, "created": {"value": false, "score": 0.4412001967430115}, "shared": {"value": false, "score": 3.5762786865234375e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Reminder", "normalizedForm": "Reminder", "offsetStart": 50, "offsetEnd": 58}, "context": "Interestingly, in the higher resource setting for Reminder, sometimes not performing source training performs better than source training. ", "mentionContextAttributes": {"used": {"value": false, "score": 5.245208740234375e-05}, "created": {"value": false, "score": 0.00015282630920410156}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9992475509643555}, "created": {"value": false, "score": 0.4412001967430115}, "shared": {"value": false, "score": 3.5762786865234375e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Reminder", "normalizedForm": "Reminder", "offsetStart": 54, "offsetEnd": 62}, "context": "We again observe a difference between the Weather and Reminder domains: the gap between (1) and ( 3) is larger in Weather than Reminder, whereas adding natural speech to TTS improves Reminder more than Weather.", "mentionContextAttributes": {"used": {"value": false, "score": 0.01621788740158081}, "created": {"value": false, "score": 0.00016427040100097656}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9992475509643555}, "created": {"value": false, "score": 0.4412001967430115}, "shared": {"value": false, "score": 3.5762786865234375e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Reminder", "normalizedForm": "Reminder", "offsetStart": 56, "offsetEnd": 64}, "context": "This may be a result of the compositional nature of the Reminder domain, as opposed to Weather, which has a more flat semantic structures.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0004686117172241211}, "created": {"value": false, "score": 0.00013148784637451172}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9992475509643555}, "created": {"value": false, "score": 0.4412001967430115}, "shared": {"value": false, "score": 3.5762786865234375e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "HuggingFace", "normalizedForm": "HuggingFace", "offsetStart": 68, "offsetEnd": 84}, "context": "In our case, it is the fine-tuned wav2vec 2.0 [14] ASR model in the HuggingFace [15] library. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.05230003595352173}, "created": {"value": false, "score": 3.0994415283203125e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.05230003595352173}, "created": {"value": false, "score": 3.0994415283203125e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Reminder", "normalizedForm": "Reminder", "offsetStart": 78, "offsetEnd": 86}, "context": "In this analysis, all data is from the held-out domain considered (Weather or Reminder).", "mentionContextAttributes": {"used": {"value": true, "score": 0.9670142531394958}, "created": {"value": false, "score": 7.62939453125e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9992475509643555}, "created": {"value": false, "score": 0.4412001967430115}, "shared": {"value": false, "score": 3.5762786865234375e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "HuBERT", "normalizedForm": "HuBERT", "offsetStart": 81, "offsetEnd": 87}, "context": "This work evaluates two speech pre-training methods, namely Wav2Vec 2.0 [14] and HuBERT [24].", "mentionContextAttributes": {"used": {"value": false, "score": 9.131431579589844e-05}, "created": {"value": true, "score": 0.6238584518432617}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999968409538269}, "created": {"value": true, "score": 0.6238584518432617}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "references": [{"label": "[24]", "normalizedForm": "[24]", "refKey": 24, "offsetStart": 11850, "offsetEnd": 11854}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Reminder", "normalizedForm": "Reminder", "offsetStart": 88, "offsetEnd": 96}, "context": "A comparison of low-resource and domain adaptation ablation studies for the Weather and Reminder domains.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9992475509643555}, "created": {"value": false, "score": 8.821487426757812e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9992475509643555}, "created": {"value": false, "score": 0.4412001967430115}, "shared": {"value": false, "score": 3.5762786865234375e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "HuBERT", "normalizedForm": "HuBERT", "offsetStart": 101, "offsetEnd": 107}, "context": "In Table 7, we compare the results of performing ASR pretraining across Librspeech and STOP for both HuBERT and Wav2Vec2.0", "mentionContextAttributes": {"used": {"value": true, "score": 0.9995001554489136}, "created": {"value": false, "score": 1.537799835205078e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999968409538269}, "created": {"value": true, "score": 0.6238584518432617}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "references": [{"label": "[24]", "normalizedForm": "[24]", "refKey": 24}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Mechanical Turk", "normalizedForm": "Mechanical Turk", "offsetStart": 104, "offsetEnd": 119}, "publisher": {"rawForm": "Amazon", "normalizedForm": "Amazon"}, "context": "In the event that the recording does not match the utterance it is discarded and recollected by another Mechanical Turk worker.", "mentionContextAttributes": {"used": {"value": false, "score": 0.2536132335662842}, "created": {"value": false, "score": 0.00011324882507324219}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9910085797309875}, "created": {"value": false, "score": 0.0005846023559570312}, "shared": {"value": false, "score": 5.960464477539062e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Reminder", "normalizedForm": "Reminder", "offsetStart": 116, "offsetEnd": 124}, "context": "We then fine-tune our model using the low-resource splits with varying amounts of data for both the Weather and the Reminder domain.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9886208176612854}, "created": {"value": false, "score": 0.4412001967430115}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9992475509643555}, "created": {"value": false, "score": 0.4412001967430115}, "shared": {"value": false, "score": 3.5762786865234375e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Reminder", "normalizedForm": "Reminder", "offsetStart": 127, "offsetEnd": 135}, "context": "We again observe a difference between the Weather and Reminder domains: the gap between (1) and ( 3) is larger in Weather than Reminder, whereas adding natural speech to TTS improves Reminder more than Weather.", "mentionContextAttributes": {"used": {"value": false, "score": 0.01621788740158081}, "created": {"value": false, "score": 0.00016427040100097656}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9992475509643555}, "created": {"value": false, "score": 0.4412001967430115}, "shared": {"value": false, "score": 3.5762786865234375e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Reminder", "normalizedForm": "Reminder", "offsetStart": 131, "offsetEnd": 139}, "context": "To this end, we train a HuBERT encoder on the Librispeech training set, then fine-tune it on the held-in domain (either Weather or Reminder).", "mentionContextAttributes": {"used": {"value": false, "score": 0.11033272743225098}, "created": {"value": false, "score": 0.31318199634552}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9992475509643555}, "created": {"value": false, "score": 0.4412001967430115}, "shared": {"value": false, "score": 3.5762786865234375e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Mechanical Turk", "normalizedForm": "Mechanical Turk", "offsetStart": 133, "offsetEnd": 148}, "publisher": {"rawForm": "Amazon", "normalizedForm": "Amazon", "offsetStart": 124, "offsetEnd": 130}, "context": "For every utterance-semantic parse pair, we collect an audio recording of the input utterance by requesting workers through Amazon's Mechanical Turk to record themselves. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9910085797309875}, "created": {"value": false, "score": 0.0005846023559570312}, "shared": {"value": false, "score": 5.960464477539062e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9910085797309875}, "created": {"value": false, "score": 0.0005846023559570312}, "shared": {"value": false, "score": 5.960464477539062e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "HuBERT", "normalizedForm": "HuBERT", "offsetStart": 154, "offsetEnd": 160}, "context": "By finetuning on the STOP training set however, we are able to achieve the best WERs on the STOP eval and test sets of 4.29 and 4.26 respectively using a HuBERT encoder model. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.999968409538269}, "created": {"value": false, "score": 3.266334533691406e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999968409538269}, "created": {"value": true, "score": 0.6238584518432617}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "references": [{"label": "[24]", "normalizedForm": "[24]", "refKey": 24}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Reminder", "normalizedForm": "Reminder", "offsetStart": 183, "offsetEnd": 191}, "context": "We again observe a difference between the Weather and Reminder domains: the gap between (1) and ( 3) is larger in Weather than Reminder, whereas adding natural speech to TTS improves Reminder more than Weather.", "mentionContextAttributes": {"used": {"value": false, "score": 0.01621788740158081}, "created": {"value": false, "score": 0.00016427040100097656}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9992475509643555}, "created": {"value": false, "score": 0.4412001967430115}, "shared": {"value": false, "score": 3.5762786865234375e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Reminder", "normalizedForm": "Reminder", "offsetStart": 185, "offsetEnd": 193}, "context": "We study this method by first taking the HuBERT encoder trained on Librispeech then source training on all data samples from \"held-in\" TOPv2 domains -all domains aside from Weather and Reminder as described in Section 3.3.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9509033560752869}, "created": {"value": false, "score": 0.0001341104507446289}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9992475509643555}, "created": {"value": false, "score": 0.4412001967430115}, "shared": {"value": false, "score": 3.5762786865234375e-07}}}], "references": [{"refKey": 24, "tei": "<biblStruct xml:id=\"b24\">\n\t<analytic>\n\t\t<title level=\"a\" type=\"main\">HuBERT: Self-Supervised Speech Representation Learning by Masked Prediction of Hidden Units</title>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Wei-Ning</forename><surname>Hsu</surname></persName>\n\t\t\t<idno type=\"ORCID\">0000-0001-5546-5217</idno>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Benjamin</forename><surname>Bolte</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Yao-Hung Hubert</forename><surname>Tsai</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Kushal</forename><surname>Lakhotia</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Ruslan</forename><surname>Salakhutdinov</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Abdelrahman</forename><surname>Mohamed</surname></persName>\n\t\t</author>\n\t\t<idno type=\"DOI\">10.1109/taslp.2021.3122291</idno>\n\t\t<idno>abs/2106.07447</idno>\n\t</analytic>\n\t<monogr>\n\t\t<title level=\"j\">IEEE/ACM Transactions on Audio, Speech, and Language Processing</title>\n\t\t<title level=\"j\" type=\"abbrev\">IEEE/ACM Trans. Audio Speech Lang. Process.</title>\n\t\t<idno type=\"ISSN\">2329-9290</idno>\n\t\t<idno type=\"ISSNe\">2329-9304</idno>\n\t\t<imprint>\n\t\t\t<biblScope unit=\"volume\">29</biblScope>\n\t\t\t<biblScope unit=\"page\" from=\"3451\" to=\"3460\" />\n\t\t\t<date type=\"published\" when=\"2021\">2021</date>\n\t\t\t<publisher>Institute of Electrical and Electronics Engineers (IEEE)</publisher>\n\t\t</imprint>\n\t</monogr>\n</biblStruct>\n"}], "runtime": 14607, "id": "078ef07d5419f23e5c22ae45da42c48ed6fe3400", "metadata": {"id": "078ef07d5419f23e5c22ae45da42c48ed6fe3400"}, "original_file_path": "../../datalake/Samuel/SOFTware-Sync/downloads/xml/hal-03989829.grobid.tei.xml", "file_name": "hal-03989829.grobid.tei.xml"}